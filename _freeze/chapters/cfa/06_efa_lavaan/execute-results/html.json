{
  "hash": "3fc433e431c22078fdfac0ee7a661f12",
  "result": {
    "engine": "knitr",
    "markdown": "# Exploratory Structural Equation Modeling {#sec-cfa-esem}\n\n**Prerequisiti**\n\n**Concetti e Competenze Chiave**\n\n**Preparazione del Notebook**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |>\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  lavaan, psych, BifactorIndicesCalculator, semPlot, semTools, \n  esemComp, kableExtra\n)\n```\n:::\n\n\n\n\n## Introduzione\n\nL'*Exploratory Structural Equation Modeling* (ESEM) rappresenta un framework analitico innovativo che combina i vantaggi dell'Analisi Fattoriale Esplorativa (EFA) con il rigore della *Confirmatory Factor Analysis* (CFA). Questo approccio integrato consente di mantenere la flessibilità tipica dell'EFA, che permette di considerare le saturazioni incrociate tra i fattori, pur preservando la specificità e il controllo strutturale offerti dalla CFA. In particolare, l'ESEM si distingue per la sua capacità di bilanciare rigore metodologico e adattabilità, rendendolo adatto sia a contesti esplorativi che confermativi.\n\nUn aspetto chiave dell'ESEM è l'introduzione della *rotazione target*, una tecnica che facilita la definizione a priori dei carichi fattoriali principali, pur consentendo ai carichi incrociati di rimanere il più possibile vicini a zero, ma senza imporre vincoli rigidi. Questa caratteristica permette di applicare il modello in modo confermativo, basandosi su una struttura fattoriale predefinita, ma con una flessibilità tipicamente associata all'EFA. Di conseguenza, l'ESEM si presta efficacemente a contesti in cui è necessario convalidare ipotesi preesistenti, pur lasciando spazio all'esplorazione di relazioni inattese tra variabili.\n\nNella tradizionale *Confirmatory Factor Analysis* (CFA), ampiamente utilizzata in ambito psicologico, la struttura fattoriale è definita a priori: si assume che ogni indicatore carichi esclusivamente sul proprio fattore latente di riferimento, con saturazioni incrociate fissate a zero. Questo approccio, sebbene metodologicamente rigoroso, presenta limitazioni significative. In particolare, i modelli CFA tendono a essere eccessivamente restrittivi, presupponendo \"fattori puri\" in cui ogni item contribuisce solo al proprio costrutto latente. Tuttavia, nella pratica psicologica, molti item riflettono più di un costrutto, rendendo questa assunzione spesso irrealistica. Ignorare le saturazioni incrociate può portare a una rappresentazione distorta delle relazioni tra item e fattori, con conseguenti sovrastime delle statistiche di adattamento del modello e distorsioni positive nelle correlazioni tra fattori. Studi di simulazione hanno dimostrato che anche piccole saturazioni incrociate, se non considerate, possono alterare significativamente le stime dei parametri.\n\nUn ulteriore problema della CFA riguarda gli indici di bontà di adattamento, che risultano spesso troppo rigidi per strumenti psicologici multifattoriali. Questa rigidità rende difficile ottenere un adattamento soddisfacente senza apportare modifiche sostanziali ai modelli. Tuttavia, è importante notare che modelli con indici di adattamento non ottimali possono comunque presentare saturazioni ragionevoli e alti livelli di affidabilità quando analizzati a livello di item.\n\nProprio per superare queste limitazioni, l'ESEM si è affermato come un approccio più flessibile e robusto, in grado di cogliere la complessità delle misure psicologiche senza sacrificare il rigore metodologico. Grazie alla sua capacità di integrare i punti di forza dell'EFA e della CFA, l'ESEM offre un quadro analitico più realistico e adattabile, rendendolo uno strumento prezioso per la ricerca in ambito psicologico.\n\n## Exploratory Structural Equation Modeling\n\nL'ESEM combina elementi delle CFA e dell'Exploratory Factor Analysis (EFA) all'interno del tradizionale framework delle Equazioni Strutturali (SEM). Questo approccio rappresenta un compromesso tra la ricerca iterativa di soluzioni fattoriali ottimali, tipica dell'EFA, e la modellazione teorica restrittiva delle CFA. \n\nL'ESEM è essenzialmente un metodo confermativo che permette anche un'esplorazione attraverso l'uso di rotazioni mirate, mantenendo la presenza di caricamenti incrociati, seppur minimizzati. All'interno dell'ESEM, il ricercatore può prevedere a priori una struttura fattoriale, similmente a quanto avviene nelle CFA, ma con una maggiore flessibilità permessa dalla possibilità di modellare saturazioni incrociate.\n\nNell'ESEM, i fattori generali e specifici devono essere specificati come totalmente indipendenti, e le rotazioni ortogonali sono comuni nei modelli bifattoriali. I metodi di rotazione più usati nell'ESEM includono le rotazioni geomin e target, con rotazioni ortogonali adatte ai modelli più complessi.\n\nLe analisi di simulazione indicano che le correlazioni tra i fattori latenti ottenute con l'ESEM sono generalmente meno distorte e più vicine alle vere associazioni, rendendo i modelli ESEM più coerenti con le teorie sottostanti e le intenzioni degli strumenti psicometrici misurati. \n\nQuando un modello ESEM include solo una parte di misurazione, viene definito come \"analisi fattoriale esplorativa\" o EFA. Se il modello include anche una parte strutturale, come regressioni tra variabili latenti, è classificato come \"modello di equazioni strutturali esplorativo\" o ESEM.\n\n## Un Esempio Pratico\n\nIn questo esempio pratico analizzeremo nuovamente i dati di @brown2015confirmatory, ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Utilizzeremo un'analisi EFA mediante la funzione `efa()` di `lavaan`.  \n\nGli item sono i seguenti:\n\n- anxiety (N1), \n- hostility (N2), \n- depression (N3), \n- self-consciousness (N4), \n- warmth (E1), \n- gregariousness (E2), \n- assertiveness (E3), \n- positive emotions (E4). \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvarnames <- c(\"N1\", \"N2\", \"N3\", \"N4\", \"E1\", \"E2\", \"E3\", \"E4\")\nsds <- \"5.7  5.6  6.4  5.7  6.0  6.2  5.7  5.6\"\n\ncors <- \"\n 1.000\n 0.767  1.000\n 0.731  0.709  1.000\n 0.778  0.738  0.762  1.000\n-0.351  -0.302  -0.356  -0.318  1.000\n-0.316  -0.280  -0.300  -0.267  0.675  1.000\n-0.296  -0.289  -0.297  -0.296  0.634  0.651  1.000\n-0.282  -0.254  -0.292  -0.245  0.534  0.593  0.566  1.000\"\n\npsychot_cor_mat <- getCov(cors, names = varnames)\nn <- 250\n```\n:::\n\n\n\n\nDefiniamo un modello ad un solo fattore comune.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1-factor model\nf1 <- '\n    efa(\"efa\")*f1 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4\n'\n```\n:::\n\n\n\n\nDefiniamo un modello con due fattori comuni.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 2-factor model\nf2 <- '\n    efa(\"efa\")*f1 +\n    efa(\"efa\")*f2 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4\n'\n```\n:::\n\n\n\n\nAdattiamo ai dati il modello ad un fattore comune.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefa_f1 <-cfa(\n    model = f1,\n    sample.cov = psychot_cor_mat,\n    sample.nobs = 250,\n    rotation = \"oblimin\"\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    efa_f1,\n    what = \"col\", whatLabels = \"no\", style = \"mx\",\n    layout = \"tree\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 5, sizeMan2 = 4\n)\n```\n\n::: {.cell-output-display}\n![](06_efa_lavaan_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo la soluzione ottenuta.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(\n    efa_f1,\n    fit.measures = TRUE,\n    standardized = TRUE,\n    rsquare = TRUE\n) |> \n    print()\n#> lavaan 0.6-19 ended normally after 2 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        16\n#> \n#>   Rotation method                      OBLIMIN OBLIQUE\n#>   Oblimin gamma                                      0\n#>   Rotation algorithm (rstarts)                GPA (30)\n#>   Standardized metric                             TRUE\n#>   Row weights                                     None\n#> \n#>   Number of observations                           250\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               375.327\n#>   Degrees of freedom                                20\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              1253.791\n#>   Degrees of freedom                                28\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.710\n#>   Tucker-Lewis Index (TLI)                       0.594\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2394.637\n#>   Loglikelihood unrestricted model (H1)      -2206.974\n#>                                                       \n#>   Akaike (AIC)                                4821.275\n#>   Bayesian (BIC)                              4877.618\n#>   Sample-size adjusted Bayesian (SABIC)       4826.897\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.267\n#>   90 Percent confidence interval - lower         0.243\n#>   90 Percent confidence interval - upper         0.291\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    1.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.187\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~ efa                                                             \n#>     N1                0.879    0.051   17.333    0.000    0.879    0.880\n#>     N2                0.841    0.052   16.154    0.000    0.841    0.842\n#>     N3                0.841    0.052   16.175    0.000    0.841    0.843\n#>     N4                0.870    0.051   17.065    0.000    0.870    0.872\n#>     E1               -0.438    0.062   -7.041    0.000   -0.438   -0.439\n#>     E2               -0.398    0.063   -6.327    0.000   -0.398   -0.398\n#>     E3               -0.398    0.063   -6.342    0.000   -0.398   -0.399\n#>     E4               -0.364    0.063   -5.746    0.000   -0.364   -0.364\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .N1                0.224    0.028    7.915    0.000    0.224    0.225\n#>    .N2                0.289    0.033    8.880    0.000    0.289    0.290\n#>    .N3                0.288    0.032    8.866    0.000    0.288    0.289\n#>    .N4                0.239    0.029    8.174    0.000    0.239    0.240\n#>    .E1                0.804    0.073   10.963    0.000    0.804    0.807\n#>    .E2                0.838    0.076   11.008    0.000    0.838    0.841\n#>    .E3                0.837    0.076   11.007    0.000    0.837    0.841\n#>    .E4                0.864    0.078   11.041    0.000    0.864    0.867\n#>     f1                1.000                               1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     N1                0.775\n#>     N2                0.710\n#>     N3                0.711\n#>     N4                0.760\n#>     E1                0.193\n#>     E2                0.159\n#>     E3                0.159\n#>     E4                0.133\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstandardizedSolution(efa_f1) |> print()\n#>    lhs op rhs est.std    se     z pvalue ci.lower ci.upper\n#> 1   f1 =~  N1   0.880 0.018 48.29      0    0.845    0.916\n#> 2   f1 =~  N2   0.842 0.022 38.61      0    0.800    0.885\n#> 3   f1 =~  N3   0.843 0.022 38.76      0    0.800    0.886\n#> 4   f1 =~  N4   0.872 0.019 45.88      0    0.835    0.909\n#> 5   f1 =~  E1  -0.439 0.054 -8.18      0   -0.544   -0.334\n#> 6   f1 =~  E2  -0.398 0.056 -7.14      0   -0.508   -0.289\n#> 7   f1 =~  E3  -0.399 0.056 -7.16      0   -0.508   -0.290\n#> 8   f1 =~  E4  -0.364 0.057 -6.35      0   -0.477   -0.252\n#> 9   N1 ~~  N1   0.225 0.032  7.01      0    0.162    0.288\n#> 10  N2 ~~  N2   0.290 0.037  7.90      0    0.218    0.362\n#> 11  N3 ~~  N3   0.289 0.037  7.88      0    0.217    0.361\n#> 12  N4 ~~  N4   0.240 0.033  7.23      0    0.175    0.305\n#> 13  E1 ~~  E1   0.807 0.047 17.14      0    0.715    0.900\n#> 14  E2 ~~  E2   0.841 0.044 18.93      0    0.754    0.928\n#> 15  E3 ~~  E3   0.841 0.045 18.89      0    0.753    0.928\n#> 16  E4 ~~  E4   0.867 0.042 20.72      0    0.785    0.949\n#> 17  f1 ~~  f1   1.000 0.000    NA     NA    1.000    1.000\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlavaan::residuals(efa_f1, type = \"cor\") |> print()\n#> $type\n#> [1] \"cor.bollen\"\n#> \n#> $cov\n#>        N1     N2     N3     N4     E1     E2     E3     E4\n#> N1  0.000                                                 \n#> N2  0.025  0.000                                          \n#> N3 -0.011 -0.001  0.000                                   \n#> N4  0.010  0.003  0.027  0.000                            \n#> E1  0.035  0.068  0.014  0.065  0.000                     \n#> E2  0.035  0.056  0.036  0.080  0.500  0.000              \n#> E3  0.055  0.047  0.040  0.052  0.459  0.492  0.000       \n#> E4  0.039  0.053  0.015  0.073  0.374  0.448  0.421  0.000\n```\n:::\n\n\n\n\nAdattiamo ai dati il modello a due fattori comuni.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefa_f2 <- cfa(\n    model = f2,\n    sample.cov = psychot_cor_mat,\n    sample.nobs = 250,\n    rotation = \"oblimin\"\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    efa_f2,\n    what = \"col\", whatLabels = \"no\", style = \"mx\",\n    layout = \"tree\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 5, sizeMan2 = 4\n)\n```\n\n::: {.cell-output-display}\n![](06_efa_lavaan_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo la soluzione ottenuta.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(\n    efa_f2,\n    fit.measures = TRUE,\n    standardized = TRUE,\n    rsquare = TRUE\n) |> print()\n#> lavaan 0.6-19 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        25\n#>   Row rank of the constraints matrix                 2\n#> \n#>   Rotation method                      OBLIMIN OBLIQUE\n#>   Oblimin gamma                                      0\n#>   Rotation algorithm (rstarts)                GPA (30)\n#>   Standardized metric                             TRUE\n#>   Row weights                                     None\n#> \n#>   Number of observations                           250\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 9.811\n#>   Degrees of freedom                                13\n#>   P-value (Chi-square)                           0.709\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              1253.791\n#>   Degrees of freedom                                28\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    1.000\n#>   Tucker-Lewis Index (TLI)                       1.006\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2211.879\n#>   Loglikelihood unrestricted model (H1)      -2206.974\n#>                                                       \n#>   Akaike (AIC)                                4469.758\n#>   Bayesian (BIC)                              4550.752\n#>   Sample-size adjusted Bayesian (SABIC)       4477.840\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.000\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.048\n#>   P-value H_0: RMSEA <= 0.050                    0.957\n#>   P-value H_0: RMSEA >= 0.080                    0.001\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.010\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~ efa                                                             \n#>     N1                0.874    0.053   16.592    0.000    0.874    0.876\n#>     N2                0.851    0.055   15.551    0.000    0.851    0.853\n#>     N3                0.826    0.054   15.179    0.000    0.826    0.828\n#>     N4                0.896    0.053   16.802    0.000    0.896    0.898\n#>     E1               -0.046    0.040   -1.138    0.255   -0.046   -0.046\n#>     E2                0.035    0.034    1.030    0.303    0.035    0.035\n#>     E3                0.000    0.040    0.010    0.992    0.000    0.000\n#>     E4               -0.006    0.049   -0.131    0.896   -0.006   -0.006\n#>   f2 =~ efa                                                             \n#>     N1               -0.017    0.032   -0.539    0.590   -0.017   -0.017\n#>     N2                0.011    0.035    0.322    0.748    0.011    0.011\n#>     N3               -0.035    0.036   -0.949    0.343   -0.035   -0.035\n#>     N4                0.031    0.031    0.994    0.320    0.031    0.031\n#>     E1                0.776    0.059   13.125    0.000    0.776    0.778\n#>     E2                0.854    0.058   14.677    0.000    0.854    0.855\n#>     E3                0.785    0.060   13.106    0.000    0.785    0.787\n#>     E4                0.695    0.063   10.955    0.000    0.695    0.697\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 ~~                                                                 \n#>     f2               -0.432    0.059   -7.345    0.000   -0.432   -0.432\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .N1                0.218    0.028    7.790    0.000    0.218    0.219\n#>    .N2                0.279    0.032    8.693    0.000    0.279    0.280\n#>    .N3                0.287    0.032    8.907    0.000    0.287    0.289\n#>    .N4                0.216    0.029    7.578    0.000    0.216    0.217\n#>    .E1                0.361    0.044    8.226    0.000    0.361    0.362\n#>    .E2                0.292    0.043    6.787    0.000    0.292    0.293\n#>    .E3                0.379    0.046    8.315    0.000    0.379    0.381\n#>    .E4                0.509    0.053    9.554    0.000    0.509    0.511\n#>     f1                1.000                               1.000    1.000\n#>     f2                1.000                               1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     N1                0.781\n#>     N2                0.720\n#>     N3                0.711\n#>     N4                0.783\n#>     E1                0.638\n#>     E2                0.707\n#>     E3                0.619\n#>     E4                0.489\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstandardizedSolution(efa_f2) |> print()\n#>    lhs op rhs est.std    se      z pvalue ci.lower ci.upper\n#> 1   f1 =~  N1   0.876 0.024 36.440  0.000    0.829    0.923\n#> 2   f1 =~  N2   0.853 0.027 31.403  0.000    0.800    0.906\n#> 3   f1 =~  N3   0.828 0.028 29.069  0.000    0.772    0.884\n#> 4   f1 =~  N4   0.898 0.023 38.383  0.000    0.852    0.944\n#> 5   f1 =~  E1  -0.046 0.040 -1.139  0.255   -0.125    0.033\n#> 6   f1 =~  E2   0.035 0.034  1.031  0.303   -0.031    0.101\n#> 7   f1 =~  E3   0.000 0.040  0.010  0.992   -0.078    0.079\n#> 8   f1 =~  E4  -0.006 0.049 -0.131  0.896   -0.103    0.090\n#> 9   f2 =~  N1  -0.017 0.032 -0.539  0.590   -0.079    0.045\n#> 10  f2 =~  N2   0.011 0.035  0.322  0.748   -0.058    0.080\n#> 11  f2 =~  N3  -0.035 0.037 -0.949  0.343   -0.106    0.037\n#> 12  f2 =~  N4   0.031 0.031  0.994  0.320   -0.030    0.092\n#> 13  f2 =~  E1   0.778 0.038 20.654  0.000    0.704    0.852\n#> 14  f2 =~  E2   0.855 0.033 26.036  0.000    0.791    0.920\n#> 15  f2 =~  E3   0.787 0.038 20.886  0.000    0.713    0.861\n#> 16  f2 =~  E4   0.697 0.046 15.282  0.000    0.607    0.786\n#> 17  N1 ~~  N1   0.219 0.032  6.905  0.000    0.157    0.281\n#> 18  N2 ~~  N2   0.280 0.036  7.727  0.000    0.209    0.351\n#> 19  N3 ~~  N3   0.289 0.036  7.909  0.000    0.217    0.360\n#> 20  N4 ~~  N4   0.217 0.032  6.751  0.000    0.154    0.280\n#> 21  E1 ~~  E1   0.362 0.047  7.673  0.000    0.269    0.454\n#> 22  E2 ~~  E2   0.293 0.046  6.322  0.000    0.202    0.384\n#> 23  E3 ~~  E3   0.381 0.049  7.816  0.000    0.285    0.476\n#> 24  E4 ~~  E4   0.511 0.053  9.631  0.000    0.407    0.615\n#> 25  f1 ~~  f1   1.000 0.000     NA     NA    1.000    1.000\n#> 26  f2 ~~  f2   1.000 0.000     NA     NA    1.000    1.000\n#> 27  f1 ~~  f2  -0.432 0.059 -7.345  0.000   -0.547   -0.317\n```\n:::\n\n\n\n\nAnche se abbiamo introdotto finora soltanto la misura di bontà di adattamento del chi-quadrato, aggiungiamo qui il calcolo di altre misure di bontà di adattamento che discuteremo in seguito.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_measures_robust <- c(\n    \"chisq\", \"df\", \"pvalue\", \"cfi\", \"rmsea\", \"srmr\"\n)\n```\n:::\n\n\n\n\nConfrontiamo le misure di bontà di adattamento del modello che ipotizza un solo fattore comune e il modello che ipotizza la presenza di due fattori comuni.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# collect them for each model\nrbind(\n    fitmeasures(efa_f1, fit_measures_robust),\n    fitmeasures(efa_f2, fit_measures_robust)\n) |>\n    # wrangle\n    data.frame() |>\n    mutate(\n        chisq = round(chisq, digits = 0),\n        df = as.integer(df),\n        pvalue = ifelse(pvalue == 0, \"< .001\", pvalue)\n    ) |>\n    mutate_at(vars(cfi:srmr), ~ round(., digits = 3)) |>\n    print()\n#>   chisq df            pvalue  cfi rmsea  srmr\n#> 1   375 20            < .001 0.71 0.267 0.187\n#> 2    10 13 0.709310449320098 1.00 0.000 0.010\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlavaan::residuals(efa_f2, type = \"cor\") |> print()\n#> $type\n#> [1] \"cor.bollen\"\n#> \n#> $cov\n#>        N1     N2     N3     N4     E1     E2     E3     E4\n#> N1  0.000                                                 \n#> N2  0.018  0.000                                          \n#> N3 -0.014 -0.006  0.000                                   \n#> N4 -0.003 -0.013  0.017  0.000                            \n#> E1 -0.003  0.015 -0.012  0.000  0.000                     \n#> E2 -0.009 -0.004  0.006  0.007  0.006  0.000              \n#> E3  0.015 -0.008  0.011 -0.016  0.006 -0.010  0.000       \n#> E4 -0.001  0.000 -0.013  0.009 -0.024  0.006  0.016  0.000\n```\n:::\n\n\n\n\nL'evidenza empirica supporta la superiorità del modello a due fattori rispetto a quello ad un solo fattore comune. In particolare, l'analisi fattoriale esplorativa svolta mediante la funzione `efa()` evidenzia la capacità del modello a due fattori di fornire una descrizione adeguata della struttura dei dati e di distinguere in modo sensato tra i due fattori ipotizzati.\n\n## ESEM-within-CFA \n\nUn approccio alternativo per eseguire un modello ESEM è quello proposto da @marsh2014exploratory, noto come *ESEM-within-CFA*. Questo metodo prevede di eseguire prima la parte esplorativa (EFA) e poi utilizzare i risultati ottenuti come valori iniziali per un modello CFA. In pratica, si combina la flessibilità dell'EFA con il rigore della CFA, sfruttando i vantaggi di entrambi gli approcci.\n\nPer illustrare questo metodo, seguiremo il tutorial di `esemComp` e utilizzeremo il dataset di Holzinger e Swineford (1939), disponibile nel pacchetto `lavaan` di R. Questo dataset contiene i risultati di 301 bambini in test che misurano tre abilità cognitive: \n\n- **Abilità visiva** (item x1-x3),  \n- **Abilità testuale** (item x4-x6),  \n- **Abilità di velocità** (item x7-x9).  \n\nPer iniziare, carichiamo il dataset e selezioniamo solo le colonne relative agli item di interesse. Questo ci permetterà di concentrarci sulle variabili rilevanti per l'analisi ESEM.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#load full data\nhw_data <- lavaan::HolzingerSwineford1939\n# keep all rows and only the item-columns\nhw_data <- hw_data[, c(7:15)]\n\n#take a look\nhead(hw_data)\n#>     x1   x2    x3   x4   x5    x6   x7   x8   x9\n#> 1 3.33 7.75 0.375 2.33 5.75 1.286 3.39 5.75 6.36\n#> 2 5.33 5.25 2.125 1.67 3.00 1.286 3.78 6.25 7.92\n#> 3 4.50 5.25 1.875 1.00 1.75 0.429 3.26 3.90 4.42\n#> 4 5.33 7.75 3.000 2.67 4.50 2.429 3.00 5.30 4.86\n#> 5 4.83 4.75 0.875 2.67 4.00 2.571 3.70 6.30 5.92\n#> 6 5.33 5.00 2.250 1.00 3.00 0.857 4.35 6.65 7.50\n```\n:::\n\n\n\n\n### Blocchi EFA (Analisi Fattoriale Esplorativa)\n\nPer eseguire un'Analisi Fattoriale Esplorativa (EFA) con una rotazione target, prima dobbiamo specificare la matrice di rotazione target. La funzione `make_target()` semplifica questo processo. Per far funzionare questa funzione, dobbiamo indicare la corrispondenza tra i fattori e i loro principali carichi (loadings), ovvero quali elementi ci aspettiamo che abbiano un carico elevato su ciascun fattore.\n\nQuesta informazione deve essere contenuta in una lista, dove il nome di ogni elemento è il nome del fattore, e il contenuto è un vettore numerico con il numero di colonna degli elementi che si riferiscono a quel fattore.\n\nSe controlliamo il dataset e i fattori, vediamo che la corrispondenza tra fattore e numero di colonna dell'elemento è piuttosto chiara in questo dataset. Le prime tre colonne si riferiscono agli elementi del primo fattore, le successive tre colonne sono gli elementi del secondo fattore, e così via. Tuttavia, **questo potrebbe non essere il caso nel tuo dataset!** Molte scale hanno elementi correlati a diversi fattori alternati, il che porta a elementi non sequenziali che si riferiscono allo stesso fattore.\n\nÈ importante ricordare che il numero dell'elemento per la matrice di rotazione si riferisce sempre alla posizione della colonna dell'elemento all'interno di un dataframe che contiene solo i dati degli elementi (ricorda che all'inizio di questa guida abbiamo creato un dataset separato contenente solo i dati degli elementi). Il numero più basso sarà sempre uno, e il numero più alto sarà il totale degli elementi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# list with mapping between factors and items\nmain_loadings_list <- list(visual = c(1:3),\n                           textual = c(4:6),\n                           speed = c(7:9))\ntarget_rot <- make_target(nitems = 9, mainloadings = main_loadings_list)\ntarget_rot\n#>       visual textual speed\n#>  [1,]     NA       0     0\n#>  [2,]     NA       0     0\n#>  [3,]     NA       0     0\n#>  [4,]      0      NA     0\n#>  [5,]      0      NA     0\n#>  [6,]      0      NA     0\n#>  [7,]      0       0    NA\n#>  [8,]      0       0    NA\n#>  [9,]      0       0    NA\n```\n:::\n\n\n\n\nNella matrice di rotazione target, i valori **NA** indicano carichi (loadings) che non devono essere avvicinati a zero durante la procedura di rotazione, mentre gli zeri indicano il contrario, ovvero che quei carichi dovrebbero essere avvicinati a zero.\n\nÈ altresì possibile realizzare facilmente una rotazione target per un modello bifattoriale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbifactor_target_rot <- make_target(nitems = 9,\n                                  mainloadings = main_loadings_list,\n                                  bifactor = TRUE)\nbifactor_target_rot\n#>       visual textual speed  G\n#>  [1,]     NA       0     0 NA\n#>  [2,]     NA       0     0 NA\n#>  [3,]     NA       0     0 NA\n#>  [4,]      0      NA     0 NA\n#>  [5,]      0      NA     0 NA\n#>  [6,]      0      NA     0 NA\n#>  [7,]      0       0    NA NA\n#>  [8,]      0       0    NA NA\n#>  [9,]      0       0    NA NA\n```\n:::\n\n\n\n\nOra, per l'estrazione dei carichi (loadings) utilizzando la funzione **esem_efa()**, dobbiamo fornire i dati, il numero di fattori da estrarre e la matrice di rotazione target.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Specify the efa block.\n# Note that if we continued with the bifactor model 'nfactors' would then be specified as 4 and not 3 due to the G factor being added\n\nefa_block <- esem_efa(data = hw_data,\n                      nfactors = 3,\n                      target = target_rot)\n#> Loading required namespace: GPArotation\nefa_block\n#> Factor Analysis using method =  pa\n#> Call: psych::fa(r = data, nfactors = nfactors, rotate = targetAlgorithm, \n#>     fm = fm, Target = target)\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>      PA2   PA3   PA1   h2   u2 com\n#> x1  0.18  0.08  0.58 0.48 0.52 1.2\n#> x2  0.03 -0.09  0.52 0.26 0.74 1.1\n#> x3 -0.08  0.08  0.67 0.45 0.55 1.1\n#> x4  0.85  0.01  0.02 0.73 0.27 1.0\n#> x5  0.89  0.00 -0.06 0.75 0.25 1.0\n#> x6  0.80 -0.01  0.08 0.69 0.31 1.0\n#> x7  0.04  0.75 -0.24 0.51 0.49 1.2\n#> x8 -0.05  0.72  0.03 0.52 0.48 1.0\n#> x9  0.01  0.50  0.32 0.46 0.54 1.7\n#> \n#>                        PA2  PA3  PA1\n#> SS loadings           2.22 1.38 1.26\n#> Proportion Var        0.25 0.15 0.14\n#> Cumulative Var        0.25 0.40 0.54\n#> Proportion Explained  0.46 0.28 0.26\n#> Cumulative Proportion 0.46 0.74 1.00\n#> \n#>  With factor correlations of \n#>      PA2  PA3  PA1\n#> PA2 1.00 0.26 0.34\n#> PA3 0.26 1.00 0.31\n#> PA1 0.34 0.31 1.00\n#> \n#> Mean item complexity =  1.1\n#> Test of the hypothesis that 3 factors are sufficient.\n#> \n#> df null model =  36  with the objective function =  3.05 with Chi Square =  904\n#> df of  the model are 12  and the objective function was  0.08 \n#> \n#> The root mean square of the residuals (RMSR) is  0.02 \n#> The df corrected root mean square of the residuals is  0.03 \n#> \n#> The harmonic n.obs is  301 with the empirical chi square  7.87  with prob <  0.8 \n#> The total n.obs was  301  with Likelihood Chi Square =  22.5  with prob <  0.032 \n#> \n#> Tucker Lewis Index of factoring reliability =  0.963\n#> RMSEA index =  0.054  and the 90 % confidence intervals are  0.016 0.088\n#> BIC =  -46\n#> Fit based upon off diagonal values = 1\n#> Measures of factor score adequacy             \n#>                                                    PA2  PA3  PA1\n#> Correlation of (regression) scores with factors   0.94 0.86 0.84\n#> Multiple R square of scores with factors          0.89 0.74 0.70\n#> Minimum correlation of possible factor scores     0.78 0.48 0.40\n```\n:::\n\n\n\n\nLa funzione **esem_efa()** è in realtà un wrapper intorno alla funzione **fa()** del pacchetto *psych*, utilizzata per l'analisi fattoriale esplorativa. Tutti i controlli disponibili in **fa()** possono essere specificati per una maggiore personalizzazione della procedura di estrazione dei fattori. Assicurati sempre di fornire gli argomenti della funzione originale utilizzando la sintassi `nome = valore`. Consulta la documentazione di **fa()** per ulteriori informazioni sui controlli e sui campi presenti nell'oggetto di output.\n\nPer impostazione predefinita, viene utilizzata una rotazione obliqua come rotazione target. L'utente può scegliere di passare a una rotazione ortogonale impostando il parametro **targetAlgorithm** su `TargetT`. Un'altra opzione è quella di eliminare completamente l'utilizzo della rotazione target e optare invece per una rotazione Geomin. In questo caso, basta non specificare il parametro **target**. Un'ultima possibilità è disponibile per i modelli bifattoriali: in questo caso, basta impostare `bifactor = TRUE`. Attualmente, i modelli bifattoriali sono supportati solo con la rotazione target. \n\nIl codice per ciascuno di questi casi è riportato di seguito (commentato).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# geomin rotation\nesem_efa(data = hw_data,\n         nfactors = 3)\n#> Factor Analysis using method =  pa\n#> Call: psych::fa(r = data, nfactors = nfactors, rotate = \"geominQ\", \n#>     fm = fm)\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>      PA1   PA3   PA2   h2   u2 com\n#> x1  0.19  0.59  0.03 0.48 0.52 1.2\n#> x2  0.04  0.51 -0.12 0.26 0.74 1.1\n#> x3 -0.07  0.69  0.02 0.45 0.55 1.0\n#> x4  0.84  0.02  0.01 0.73 0.27 1.0\n#> x5  0.88 -0.06  0.01 0.75 0.25 1.0\n#> x6  0.80  0.08 -0.01 0.69 0.31 1.0\n#> x7  0.03 -0.14  0.73 0.51 0.49 1.1\n#> x8 -0.04  0.14  0.69 0.52 0.48 1.1\n#> x9  0.02  0.39  0.45 0.46 0.54 2.0\n#> \n#>                        PA1  PA3  PA2\n#> SS loadings           2.23 1.36 1.27\n#> Proportion Var        0.25 0.15 0.14\n#> Cumulative Var        0.25 0.40 0.54\n#> Proportion Explained  0.46 0.28 0.26\n#> Cumulative Proportion 0.46 0.74 1.00\n#> \n#>  With factor correlations of \n#>      PA1  PA3  PA2\n#> PA1 1.00 0.32 0.22\n#> PA3 0.32 1.00 0.25\n#> PA2 0.22 0.25 1.00\n#> \n#> Mean item complexity =  1.2\n#> Test of the hypothesis that 3 factors are sufficient.\n#> \n#> df null model =  36  with the objective function =  3.05 with Chi Square =  904\n#> df of  the model are 12  and the objective function was  0.08 \n#> \n#> The root mean square of the residuals (RMSR) is  0.02 \n#> The df corrected root mean square of the residuals is  0.03 \n#> \n#> The harmonic n.obs is  301 with the empirical chi square  7.87  with prob <  0.8 \n#> The total n.obs was  301  with Likelihood Chi Square =  22.5  with prob <  0.032 \n#> \n#> Tucker Lewis Index of factoring reliability =  0.963\n#> RMSEA index =  0.054  and the 90 % confidence intervals are  0.016 0.088\n#> BIC =  -46\n#> Fit based upon off diagonal values = 1\n#> Measures of factor score adequacy             \n#>                                                    PA1  PA3  PA2\n#> Correlation of (regression) scores with factors   0.94 0.84 0.85\n#> Multiple R square of scores with factors          0.89 0.71 0.72\n#> Minimum correlation of possible factor scores     0.78 0.42 0.44\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# orthogonal target rotation\nesem_efa(data = hw_data,\n         nfactors = 3,\n         target = target_rot,\n         targetAlgorithm = \"TargetT\")\n#> Factor Analysis using method =  pa\n#> Call: psych::fa(r = data, nfactors = nfactors, rotate = targetAlgorithm, \n#>     fm = fm, Target = target)\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>     PA2   PA3   PA1   h2   u2 com\n#> x1 0.31  0.18  0.59 0.48 0.52 1.7\n#> x2 0.12 -0.01  0.49 0.26 0.74 1.1\n#> x3 0.07  0.16  0.65 0.45 0.55 1.2\n#> x4 0.84  0.09  0.12 0.73 0.27 1.1\n#> x5 0.86  0.08  0.05 0.75 0.25 1.0\n#> x6 0.81  0.08  0.18 0.69 0.31 1.1\n#> x7 0.10  0.70 -0.12 0.51 0.49 1.1\n#> x8 0.07  0.71  0.13 0.52 0.48 1.1\n#> x9 0.16  0.54  0.38 0.46 0.54 2.0\n#> \n#>                        PA2  PA3  PA1\n#> SS loadings           2.26 1.36 1.24\n#> Proportion Var        0.25 0.15 0.14\n#> Cumulative Var        0.25 0.40 0.54\n#> Proportion Explained  0.47 0.28 0.25\n#> Cumulative Proportion 0.47 0.75 1.00\n#> \n#> Mean item complexity =  1.3\n#> Test of the hypothesis that 3 factors are sufficient.\n#> \n#> df null model =  36  with the objective function =  3.05 with Chi Square =  904\n#> df of  the model are 12  and the objective function was  0.08 \n#> \n#> The root mean square of the residuals (RMSR) is  0.02 \n#> The df corrected root mean square of the residuals is  0.03 \n#> \n#> The harmonic n.obs is  301 with the empirical chi square  7.87  with prob <  0.8 \n#> The total n.obs was  301  with Likelihood Chi Square =  22.5  with prob <  0.032 \n#> \n#> Tucker Lewis Index of factoring reliability =  0.963\n#> RMSEA index =  0.054  and the 90 % confidence intervals are  0.016 0.088\n#> BIC =  -46\n#> Fit based upon off diagonal values = 1\n#> Measures of factor score adequacy             \n#>                                                    PA2  PA3  PA1\n#> Correlation of (regression) scores with factors   0.94 0.84 0.81\n#> Multiple R square of scores with factors          0.88 0.71 0.65\n#> Minimum correlation of possible factor scores     0.75 0.42 0.30\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# bifactor model\nesem_efa(data = hw_data,\n         nfactors = 4,\n         target = bifactor_target_rot,\n         SMC=FALSE,\n         bifactor = TRUE)\n#> Factor Analysis using method =  pa\n#> Call: psych::fa(r = data, nfactors = nfactors, rotate = \"TargetT\", \n#>     SMC = FALSE, fm = fm, Target = target)\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>     PA4   PA2   PA3   PA1   h2    u2 com\n#> x1 0.74  0.08 -0.02  0.00 0.55 0.449 1.0\n#> x2 0.41  0.01 -0.06  0.90 0.97 0.029 1.4\n#> x3 0.62 -0.12  0.01  0.10 0.41 0.593 1.1\n#> x4 0.40  0.75  0.02 -0.03 0.73 0.273 1.5\n#> x5 0.32  0.81  0.04  0.01 0.76 0.240 1.3\n#> x6 0.42  0.71  0.02  0.02 0.69 0.312 1.6\n#> x7 0.12  0.09  0.67 -0.10 0.48 0.519 1.1\n#> x8 0.30  0.00  0.67  0.01 0.55 0.453 1.4\n#> x9 0.53  0.01  0.42  0.02 0.46 0.543 1.9\n#> \n#>                        PA4  PA2  PA3  PA1\n#> SS loadings           1.92 1.76 1.09 0.82\n#> Proportion Var        0.21 0.20 0.12 0.09\n#> Cumulative Var        0.21 0.41 0.53 0.62\n#> Proportion Explained  0.34 0.31 0.19 0.15\n#> Cumulative Proportion 0.34 0.66 0.85 1.00\n#> \n#> Mean item complexity =  1.4\n#> Test of the hypothesis that 4 factors are sufficient.\n#> \n#> df null model =  36  with the objective function =  3.05 with Chi Square =  904\n#> df of  the model are 6  and the objective function was  0.06 \n#> \n#> The root mean square of the residuals (RMSR) is  0.02 \n#> The df corrected root mean square of the residuals is  0.04 \n#> \n#> The harmonic n.obs is  301 with the empirical chi square  5.13  with prob <  0.53 \n#> The total n.obs was  301  with Likelihood Chi Square =  18  with prob <  0.0064 \n#> \n#> Tucker Lewis Index of factoring reliability =  0.917\n#> RMSEA index =  0.081  and the 90 % confidence intervals are  0.04 0.126\n#> BIC =  -16.3\n#> Fit based upon off diagonal values = 1\n#> Measures of factor score adequacy             \n#>                                                    PA4  PA2  PA3  PA1\n#> Correlation of (regression) scores with factors   0.85 0.90 0.81 0.95\n#> Multiple R square of scores with factors          0.72 0.82 0.66 0.91\n#> Minimum correlation of possible factor scores     0.45 0.64 0.32 0.81\n```\n:::\n\n\n\n\nÈ certo utile poter eseguire queste analisi fattoriali utilizzando l'approccio ESEM (Exploratory Structural Equation Modeling), ma ciò non offre ancora la grande flessibilità ed estensibilità propria dei modelli CFA/SEM (Confirmatory Factor Analysis / Structural Equation Modeling). Per accedere a queste funzionalità, utilizzeremo successivamente l'approccio **ESEM-all'interno-del-CFA**.\n\n### ESEM-all-interno-del-CFA\n\nUna volta ottenuta un'analisi fattoriale esplorativa (EFA) realizzata con l'approccio ESEM, è sufficiente utilizzare la funzione **syntax_composer()** per \"comporre\" il modello ESEM-all-interno-del-CFA utilizzando la sintassi di *lavaan*. Successivamente, con la sintassi generata, possiamo eseguire il fitting del modello in *lavaan*.\n\nLa funzione **syntax_composer()** richiede come primo argomento una soluzione EFA e come secondo argomento una lista denominata che indica i referenti (indicatori di riferimento) per ciascun fattore. Ogni voce della lista deve avere il formato `fattore = \"nome_elemento\"`. È fondamentale che questa lista rispetti lo stesso ordine in cui i fattori appaiono nella matrice dei carichi fattoriali della soluzione EFA. Di solito, questo ordine non corrisponde a quello utilizzato nella lista per creare la rotazione target, poiché nella matrice EFA i fattori sono ordinati in base alla quantità di varianza spiegata, non in base all'ordine fornito dall'utente.\n\nPer esempio, controllando i carichi fattoriali, possiamo dedurre che nell'esempio in questione l'ordine nella matrice dei carichi fattoriali è \"testuale, velocità, visivo\". Questo ordine non coincide con quello utilizzato in **make_target()**, dove abbiamo specificato \"visivo, testuale, velocità\".\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefa_block$loadings\n#> \n#> Loadings:\n#>    PA2    PA3    PA1   \n#> x1  0.179         0.577\n#> x2                0.515\n#> x3                0.670\n#> x4  0.845              \n#> x5  0.886              \n#> x6  0.803              \n#> x7         0.745 -0.240\n#> x8         0.724       \n#> x9         0.504  0.317\n#> \n#>                  PA2   PA3   PA1\n#> SS loadings    2.189 1.354 1.218\n#> Proportion Var 0.243 0.150 0.135\n#> Cumulative Var 0.243 0.394 0.529\n```\n:::\n\n\n\n\nQuando esaminiamo la matrice dei carichi fattoriali, possiamo anche scegliere qual è il miglior referente (indicatore di riferimento) per ciascun fattore. Dovrebbe sempre essere un elemento che ha un carico elevato su un fattore e basso sugli altri. Quindi, per il fattore \"testuale\", il referente sarà x5, per il fattore \"velocità\" sarà x8 e per il fattore \"visivo\" sarà x3. Creeremo la lista con questi elementi in quest'ordine.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create named character vector of referents\nhw_referents <- list(textual = \"x5\",\n                     speed = \"x8\",\n                     visual = \"x3\")\n```\n:::\n\n\n\n\nAlternativamente, è possibile utilizzare la funzione **find_referents()** per selezionare automaticamente i referenti (indicatori di riferimento). Gli input richiesti sono il risultato della funzione **esem_efa()** e un vettore di caratteri con i nomi desiderati per i fattori. Ancora una volta, i nomi devono corrispondere all'ordine in cui i fattori appaiono nella soluzione esplorativa.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfind_referents(efa_block, c(\"textual\", \"speed\", \"visual\"))\n#> $textual\n#> [1] \"x5\"\n#> \n#> $speed\n#> [1] \"x7\"\n#> \n#> $visual\n#> [1] \"x3\"\n```\n:::\n\n\n\n\nSi dovrebbe notare che i referenti scelti dalla funzione non sono esattamente gli stessi di quelli selezionati manualmente esaminando i carichi fattoriali; il referente per il fattore \"velocità\" differisce. Ciò accade perché l'attuale implementazione della funzione **find_referents()** cerca solo l'elemento con il carico più alto per ciascun fattore, senza considerare quanto bene tale elemento carichi su altri fattori.\n\nInfine, compiliamo la sintassi per *lavaan* utilizzando la funzione **syntax_composer**:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# compose lavaan syntax\nmodel_syntax <- syntax_composer(efa_object = efa_block,\n                                referents = hw_referents)\n\n# altenatively, if you plan fit the model with free factor variance parameters\nmodel_syntax_free_var <- syntax_composer(efa_object = efa_block,\n                                referents = hw_referents,\n                                only_fix_crossloadings = FALSE)\n\nwriteLines(model_syntax)\n#> textual =~ start(0.179)*x1+\n#> start(0.03)*x2+\n#> -0.082*x3+\n#> start(0.845)*x4+\n#> start(0.886)*x5+\n#> start(0.803)*x6+\n#> start(0.037)*x7+\n#> -0.049*x8+\n#> start(0.014)*x9 \n#> \n#> speed =~ start(0.081)*x1+\n#> start(-0.085)*x2+\n#> 0.075*x3+\n#> start(0.01)*x4+\n#> 0.003*x5+\n#> start(-0.006)*x6+\n#> start(0.745)*x7+\n#> start(0.724)*x8+\n#> start(0.504)*x9 \n#> \n#> visual =~ start(0.577)*x1+\n#> start(0.515)*x2+\n#> start(0.67)*x3+\n#> start(0.016)*x4+\n#> -0.064*x5+\n#> start(0.08)*x6+\n#> start(-0.24)*x7+\n#> 0.035*x8+\n#> start(0.317)*x9\n```\n:::\n\n\n\n\nPossiamo confermare che ogni fattore ha due parametri fissati (i cross-loadings dagli altri fattori) e che tutti gli altri parametri hanno i carichi dell'EFA come punti di partenza.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncfa_fit <- lavaan::cfa(model = model_syntax, data = hw_data, std.lv =TRUE)\nlavaan::summary(cfa_fit, fit.measures = TRUE, std = TRUE)\n#> lavaan 0.6-19 ended normally after 28 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        33\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                22.897\n#>   Degrees of freedom                                12\n#>   P-value (Chi-square)                           0.029\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               918.852\n#>   Degrees of freedom                                36\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.988\n#>   Tucker-Lewis Index (TLI)                       0.963\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -3706.541\n#>   Loglikelihood unrestricted model (H1)      -3695.092\n#>                                                       \n#>   Akaike (AIC)                                7479.081\n#>   Bayesian (BIC)                              7601.416\n#>   Sample-size adjusted Bayesian (SABIC)       7496.758\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.055\n#>   90 Percent confidence interval - lower         0.017\n#>   90 Percent confidence interval - upper         0.089\n#>   P-value H_0: RMSEA <= 0.050                    0.365\n#>   P-value H_0: RMSEA >= 0.080                    0.120\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.017\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   textual =~                                                            \n#>     x1                0.218    0.080    2.728    0.006    0.218    0.187\n#>     x2                0.052    0.084    0.611    0.541    0.052    0.044\n#>     x3               -0.082                              -0.082   -0.073\n#>     x4                0.971    0.062   15.657    0.000    0.971    0.836\n#>     x5                1.138    0.063   18.018    0.000    1.138    0.883\n#>     x6                0.878    0.058   15.034    0.000    0.878    0.803\n#>     x7                0.030    0.078    0.391    0.696    0.030    0.028\n#>     x8               -0.049                              -0.049   -0.048\n#>     x9                0.023    0.064    0.359    0.720    0.023    0.023\n#>   speed =~                                                              \n#>     x1                0.080    0.087    0.917    0.359    0.080    0.069\n#>     x2               -0.105    0.093   -1.128    0.259   -0.105   -0.089\n#>     x3                0.075                               0.075    0.066\n#>     x4                0.006    0.062    0.104    0.917    0.006    0.006\n#>     x5                0.003                               0.003    0.002\n#>     x6               -0.008    0.060   -0.139    0.889   -0.008   -0.008\n#>     x7                0.800    0.098    8.140    0.000    0.800    0.736\n#>     x8                0.737    0.069   10.647    0.000    0.737    0.729\n#>     x9                0.503    0.068    7.394    0.000    0.503    0.500\n#>   visual =~                                                             \n#>     x1                0.689    0.088    7.834    0.000    0.689    0.591\n#>     x2                0.597    0.093    6.413    0.000    0.597    0.508\n#>     x3                0.759    0.077    9.829    0.000    0.759    0.672\n#>     x4                0.043    0.067    0.646    0.518    0.043    0.037\n#>     x5               -0.064                              -0.064   -0.050\n#>     x6                0.101    0.063    1.605    0.109    0.101    0.093\n#>     x7               -0.236    0.100   -2.355    0.019   -0.236   -0.217\n#>     x8                0.035                               0.035    0.035\n#>     x9                0.318    0.072    4.384    0.000    0.318    0.315\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   textual ~~                                                            \n#>     speed             0.258    0.087    2.977    0.003    0.258    0.258\n#>     visual            0.303    0.092    3.307    0.001    0.303    0.303\n#>   speed ~~                                                              \n#>     visual            0.307    0.115    2.670    0.008    0.307    0.307\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .x1                0.696    0.087    8.038    0.000    0.696    0.513\n#>    .x2                1.035    0.102   10.151    0.000    1.035    0.749\n#>    .x3                0.692    0.097    7.134    0.000    0.692    0.543\n#>    .x4                0.377    0.048    7.902    0.000    0.377    0.279\n#>    .x5                0.403    0.061    6.590    0.000    0.403    0.243\n#>    .x6                0.365    0.042    8.613    0.000    0.365    0.305\n#>    .x7                0.594    0.106    5.624    0.000    0.594    0.502\n#>    .x8                0.479    0.080    5.958    0.000    0.479    0.469\n#>    .x9                0.551    0.060    9.132    0.000    0.551    0.543\n#>     textual           1.000                               1.000    1.000\n#>     speed             1.000                               1.000    1.000\n#>     visual            1.000                               1.000    1.000\n```\n:::\n\n\n\n\nSe hai bisogno di adattare un modello con varianze residue dei fattori libere, dovrai utilizzare la funzione **fit_free_factor_var_esem()**. Questa funzione è un wrapper intorno alla funzione **lavaan()**, con gli stessi parametri impostati nella funzione **cfa()**, eccetto per il fatto che le varianze dei fattori sono libere di essere stimati e i primi indicatori in ciascun fattore non vengono fissati automaticamente. Assumiamo che l'identificazione sia garantita dai referenti fissati nella sintassi del modello, il che dovrebbe essere il caso se hai impostato **only_fix_crossloadings = FALSE** durante la composizione della sintassi con **syntax_composer**.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncfa_fit <- fit_free_factor_var_esem(model_syntax_free_var, hw_data)\nlavaan::summary(cfa_fit, fit.measures = TRUE, std = TRUE)\n#> lavaan 0.6-19 ended normally after 45 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        33\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                22.897\n#>   Degrees of freedom                                12\n#>   P-value (Chi-square)                           0.029\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               918.852\n#>   Degrees of freedom                                36\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.988\n#>   Tucker-Lewis Index (TLI)                       0.963\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -3706.541\n#>   Loglikelihood unrestricted model (H1)      -3695.092\n#>                                                       \n#>   Akaike (AIC)                                7479.081\n#>   Bayesian (BIC)                              7601.416\n#>   Sample-size adjusted Bayesian (SABIC)       7496.758\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.055\n#>   90 Percent confidence interval - lower         0.017\n#>   90 Percent confidence interval - upper         0.089\n#>   P-value H_0: RMSEA <= 0.050                    0.365\n#>   P-value H_0: RMSEA >= 0.080                    0.120\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.017\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   textual =~                                                            \n#>     x1                0.152    0.064    2.383    0.017    0.196    0.169\n#>     x2                0.028    0.067    0.418    0.676    0.036    0.031\n#>     x3               -0.082                              -0.106   -0.094\n#>     x4                0.754    0.051   14.677    0.000    0.972    0.836\n#>     x5                0.886                               1.143    0.887\n#>     x6                0.680    0.048   14.197    0.000    0.878    0.802\n#>     x7                0.018    0.061    0.293    0.769    0.023    0.021\n#>     x8               -0.049                              -0.063   -0.063\n#>     x9                0.004    0.051    0.073    0.942    0.005    0.005\n#>   speed =~                                                              \n#>     x1                0.080    0.086    0.933    0.351    0.082    0.070\n#>     x2               -0.102    0.092   -1.100    0.271   -0.104   -0.088\n#>     x3                0.075                               0.077    0.068\n#>     x4                0.007    0.061    0.108    0.914    0.007    0.006\n#>     x5                0.003                               0.003    0.002\n#>     x6               -0.008    0.059   -0.134    0.893   -0.008   -0.007\n#>     x7                0.785    0.137    5.739    0.000    0.802    0.737\n#>     x8                0.724                               0.739    0.731\n#>     x9                0.495    0.079    6.281    0.000    0.505    0.502\n#>   visual =~                                                             \n#>     x1                0.606    0.106    5.711    0.000    0.694    0.595\n#>     x2                0.525    0.101    5.210    0.000    0.601    0.511\n#>     x3                0.670                               0.767    0.679\n#>     x4                0.032    0.060    0.527    0.598    0.036    0.031\n#>     x5               -0.064                              -0.073   -0.057\n#>     x6                0.083    0.058    1.442    0.149    0.095    0.087\n#>     x7               -0.204    0.093   -2.196    0.028   -0.233   -0.215\n#>     x8                0.035                               0.040    0.040\n#>     x9                0.283    0.069    4.102    0.000    0.323    0.321\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   textual ~~                                                            \n#>     speed             0.362    0.119    3.029    0.002    0.275    0.275\n#>     visual            0.496    0.147    3.376    0.001    0.336    0.336\n#>   speed ~~                                                              \n#>     visual            0.361    0.133    2.719    0.007    0.309    0.309\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .x1                0.696    0.087    8.038    0.000    0.696    0.513\n#>    .x2                1.035    0.102   10.151    0.000    1.035    0.749\n#>    .x3                0.692    0.097    7.134    0.000    0.692    0.543\n#>    .x4                0.377    0.048    7.902    0.000    0.377    0.279\n#>    .x5                0.403    0.061    6.590    0.000    0.403    0.243\n#>    .x6                0.365    0.042    8.613    0.000    0.365    0.305\n#>    .x7                0.594    0.106    5.624    0.000    0.594    0.502\n#>    .x8                0.479    0.080    5.958    0.000    0.479    0.469\n#>    .x9                0.551    0.060    9.132    0.000    0.551    0.543\n#>     textual           1.663    0.186    8.963    0.000    1.000    1.000\n#>     speed             1.043    0.196    5.319    0.000    1.000    1.000\n#>     visual            1.311    0.267    4.917    0.000    1.000    1.000\n```\n:::\n\n\n\n\nUn diagramma di percorso si ottiene con la seguente istruzione:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    cfa_fit,\n    what = \"col\", whatLabels = \"no\", style = \"mx\",\n    layout = \"tree\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 5, sizeMan2 = 4\n)\n```\n\n::: {.cell-output-display}\n![](06_efa_lavaan_files/figure-html/unnamed-chunk-30-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n### Omega di McDonald  \n\nÈ possibile calcolare gli omega di McDonald utilizzando il modello adattato e la matrice di rotazione target. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nomega_esem(cfa_fit, target_rot)\n#>  visual textual   speed \n#>   0.639   0.885   0.719\n```\n:::\n\n\n\n\n## Sintassi ESEM in `lavaan`\n\nSpecifichiamo lo stesso modello descritto in precedenza con la sintassi offerta da lavaan per i modelli ESEM.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel <- '\n    # EFA block\n    efa(\"efa1\")*visual + \n    efa(\"efa1\")*textual + \n    efa(\"efa1\")*speed =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9\n'\n```\n:::\n\n\n\n\nAdattiamo il modello ai dati.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- sem(\n    model = model,\n    data = hw_data,\n    rotation = \"geomin\",  \n    rotation.args = list(\n        rstarts = 30,          # Number of random starts for rotation\n        algorithm = \"gpa\",      # Generalized Procrustes Analysis\n        std.ov = TRUE           # Standardize observed variables\n    )\n)\n```\n:::\n\n\n\n\nEsaminiamo la soluzione ottenuta.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit, standardized = TRUE, fit.measures = TRUE)\n#> lavaan 0.6-19 ended normally after 2 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        39\n#>   Row rank of the constraints matrix                 6\n#> \n#>   Rotation method                       GEOMIN OBLIQUE\n#>   Geomin epsilon                                 0.001\n#>   Rotation algorithm (rstarts)                GPA (30)\n#>   Standardized metric                             TRUE\n#>   Row weights                                     None\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                22.897\n#>   Degrees of freedom                                12\n#>   P-value (Chi-square)                           0.029\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               918.852\n#>   Degrees of freedom                                36\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.988\n#>   Tucker-Lewis Index (TLI)                       0.963\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -3706.541\n#>   Loglikelihood unrestricted model (H1)      -3695.092\n#>                                                       \n#>   Akaike (AIC)                                7479.081\n#>   Bayesian (BIC)                              7601.416\n#>   Sample-size adjusted Bayesian (SABIC)       7496.758\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.055\n#>   90 Percent confidence interval - lower         0.017\n#>   90 Percent confidence interval - upper         0.089\n#>   P-value H_0: RMSEA <= 0.050                    0.365\n#>   P-value H_0: RMSEA >= 0.080                    0.120\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.017\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   visual =~ efa1                                                        \n#>     x1                0.712    0.092    7.771    0.000    0.712    0.611\n#>     x2                0.628    0.104    6.063    0.000    0.628    0.534\n#>     x3                0.796    0.096    8.255    0.000    0.796    0.705\n#>     x4                0.011    0.011    0.944    0.345    0.011    0.009\n#>     x5               -0.107    0.089   -1.203    0.229   -0.107   -0.083\n#>     x6                0.076    0.073    1.028    0.304    0.076    0.069\n#>     x7               -0.278    0.109   -2.538    0.011   -0.278   -0.255\n#>     x8                0.012    0.008    1.371    0.170    0.012    0.011\n#>     x9                0.314    0.076    4.142    0.000    0.314    0.312\n#>   textual =~ efa1                                                       \n#>     x1                0.198    0.103    1.917    0.055    0.198    0.170\n#>     x2                0.039    0.092    0.424    0.672    0.039    0.033\n#>     x3               -0.106    0.111   -0.963    0.335   -0.106   -0.094\n#>     x4                0.981    0.058   16.850    0.000    0.981    0.844\n#>     x5                1.153    0.074   15.545    0.000    1.153    0.895\n#>     x6                0.886    0.062   14.338    0.000    0.886    0.810\n#>     x7                0.011    0.012    0.923    0.356    0.011    0.010\n#>     x8               -0.075    0.066   -1.135    0.256   -0.075   -0.074\n#>     x9               -0.002    0.007   -0.315    0.753   -0.002   -0.002\n#>   speed =~ efa1                                                         \n#>     x1                0.015    0.048    0.302    0.762    0.015    0.012\n#>     x2               -0.166    0.092   -1.813    0.070   -0.166   -0.141\n#>     x3                0.002    0.048    0.036    0.971    0.002    0.002\n#>     x4                0.004    0.047    0.091    0.927    0.004    0.004\n#>     x5                0.012    0.036    0.322    0.747    0.012    0.009\n#>     x6               -0.017    0.041   -0.409    0.683   -0.017   -0.015\n#>     x7                0.843    0.105    7.999    0.000    0.843    0.775\n#>     x8                0.752    0.076    9.893    0.000    0.752    0.744\n#>     x9                0.484    0.070    6.954    0.000    0.484    0.481\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   visual ~~                                                             \n#>     textual           0.373    0.118    3.173    0.002    0.373    0.373\n#>     speed             0.432    0.097    4.465    0.000    0.432    0.432\n#>   textual ~~                                                            \n#>     speed             0.306    0.081    3.775    0.000    0.306    0.306\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .x1                0.696    0.087    8.038    0.000    0.696    0.513\n#>    .x2                1.035    0.102   10.151    0.000    1.035    0.749\n#>    .x3                0.692    0.097    7.134    0.000    0.692    0.543\n#>    .x4                0.377    0.048    7.902    0.000    0.377    0.279\n#>    .x5                0.403    0.061    6.590    0.000    0.403    0.243\n#>    .x6                0.365    0.042    8.613    0.000    0.365    0.305\n#>    .x7                0.594    0.106    5.624    0.000    0.594    0.502\n#>    .x8                0.479    0.080    5.958    0.000    0.479    0.469\n#>    .x9                0.551    0.060    9.132    0.000    0.551    0.543\n#>     visual            1.000                               1.000    1.000\n#>     textual           1.000                               1.000    1.000\n#>     speed             1.000                               1.000    1.000\n```\n:::\n\n\n\n\nEseguiamo un confronto tra le soluzioni fornite dai due metodi: ESEM specificato in **lavaan** vs. ESEM-within-CFA.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Indici di Adattamento del Modello</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Metrica </th>\n   <th style=\"text-align:center;\"> ESEM </th>\n   <th style=\"text-align:center;\"> CFA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> CFI </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.988 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.988 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> TLI </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.963 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.963 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> RMSEA </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.055 (CI: 0.017–0.089) </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.055 (CI: 0.017–0.089) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> SRMR </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.017 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.017 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n**Conclusione**: entrambi i modelli mostrano un ottimo adattamento (CFI e TLI > 0.95, RMSEA accettabile).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Log-Likelihood e Criteri Informativi</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Metrica </th>\n   <th style=\"text-align:center;\"> ESEM </th>\n   <th style=\"text-align:center;\"> CFA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Loglikelihood (H0) </td>\n   <td style=\"text-align:center;width: 12em; \"> -3707 </td>\n   <td style=\"text-align:center;width: 12em; \"> -3707 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> AIC </td>\n   <td style=\"text-align:center;width: 12em; \"> 7479 </td>\n   <td style=\"text-align:center;width: 12em; \"> 7479 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> BIC </td>\n   <td style=\"text-align:center;width: 12em; \"> 7601 </td>\n   <td style=\"text-align:center;width: 12em; \"> 7601 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n**Conclusione**: nessuna differenza nei criteri informativi tra i due metodi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Caricamenti Fattoriali</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Item </th>\n   <th style=\"text-align:center;\"> Caricamento_ESEM </th>\n   <th style=\"text-align:center;\"> Caricamento_CFA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> x1 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.712 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.606 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> x2 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.628 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.525 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> x3 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.796 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.670 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> x4 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.011 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.032 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> x5 </td>\n   <td style=\"text-align:center;width: 10em; \"> -0.107 </td>\n   <td style=\"text-align:center;width: 10em; \"> -0.064 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n**Osservazione**: l'ESEM permette maggior flessibilità nel gestire i caricamenti e le cross-loadings, ottenendo una separazione più chiara dei fattori.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Covarianze tra i Fattori</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Covarianza </th>\n   <th style=\"text-align:center;\"> Stima_ESEM </th>\n   <th style=\"text-align:center;\"> Stima_CFA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Visual ~ Textual </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.373 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.496 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Visual ~ Speed </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.432 </td>\n   <td style=\"text-align:center;width: 10em; \"> 0.361 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n**Osservazione**: l’ESEM stima covarianze leggermente diverse, spesso più alte, rispetto alla CFA.\n\n\n**Interpretazione dei risultati.**\n\n- **ESEM**: offre una maggiore flessibilità e gestione delle cross-loadings, utile quando la struttura fattoriale non è chiara.\n- **CFA**: più rigido, adatto quando la struttura dei fattori è ben definita.\n\nIn sintesi, i due metodi producono risultati simili. Tuttavia, il metodo ESEM disponibile nel pacchetto `lavaan` offre informazioni aggiuntive sulle saturazioni incrociate e sulle relazioni tra i fattori, rendendolo una scelta più solida e completa per analisi di tipo esplorativo.\n\n## Riflessioni Conclusive\n\nL'ESEM rappresenta un ponte significativo tra i modelli di misurazione tradizionali dell'Exploratory Factor Analysis (EFA) e il più esteso quadro del Confirmatory Factor Analysis/Structural Equation Modeling (CFA/SEM). Grazie a questo, l'ESEM combina i benefici dell'EFA con quelli del CFA/SEM, fornendo un approccio più flessibile e inclusivo nell'analisi dei dati. Tale integrazione ha segnato un progresso notevole nella ricerca statistica, evidenziando l'importanza dell'EFA che precedentemente era sottovalutata.\n\nL'ESEM e il quadro bifattoriale-ESEM, in particolare, offrono una rappresentazione più fedele e precisa della multidimensionalità dei costrutti psicometrici, che è spesso presente nelle misurazioni. Questo approccio riconosce e gestisce meglio la natura multidimensionale dei costrutti, a differenza dell'approccio tradizionale del CFA, che tende a sovrastimare le correlazioni tra i fattori quando non considera adeguatamente la loro natura gerarchica e interconnessa (Asparouhov et al., 2015; Morin et al., 2020).\n\nNonostante questi vantaggi, l'ESEM presenta alcune limitazioni che devono essere considerate:\n\n1. **Complessità Computazionale**: L'ESEM può essere più complesso e richiedere maggiori risorse computazionali rispetto agli approcci tradizionali, soprattutto quando si gestiscono grandi set di dati o modelli con molti fattori.\n2. **Interpretazione dei Risultati**: A causa della sua flessibilità, l'ESEM può produrre risultati che sono più difficili da interpretare. Ad esempio, la sovrapposizione tra i fattori può complicare l'interpretazione dei costrutti.\n3. **Rischio di Overfitting**: La maggiore flessibilità dell'ESEM può anche portare a un rischio maggiore di overfitting, specialmente in campioni più piccoli o con modelli eccessivamente complessi.\n4. **Necessità di Esperienza e Conoscenza**: Per utilizzare efficacemente l'ESEM, è richiesta una comprensione approfondita della teoria sottostante e delle tecniche statistiche, che può essere una barriera per alcuni ricercatori.\n\nNonostante queste limitazioni, si prevede che i futuri sviluppi e le applicazioni dell'ESEM conducano a soluzioni più integrate e a un consenso più ampio sulle migliori pratiche nell'utilizzo di questo potente strumento statistico. Nel @sec-sem-esem esploreremo il set-ESEM, una recente evoluzione di questa metodologia.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] kableExtra_1.4.0                esemComp_0.2                   \n#>  [3] BifactorIndicesCalculator_0.2.2 ggokabeito_0.1.0               \n#>  [5] see_0.10.0                      MASS_7.3-64                    \n#>  [7] viridis_0.6.5                   viridisLite_0.4.2              \n#>  [9] ggpubr_0.6.0                    ggExtra_0.10.1                 \n#> [11] gridExtra_2.3                   patchwork_1.3.0                \n#> [13] bayesplot_1.11.1                semTools_0.5-6                 \n#> [15] semPlot_1.1.6                   lavaan_0.6-19                  \n#> [17] psych_2.4.12                    scales_1.3.0                   \n#> [19] markdown_1.13                   knitr_1.49                     \n#> [21] lubridate_1.9.4                 forcats_1.0.0                  \n#> [23] stringr_1.5.1                   dplyr_1.1.4                    \n#> [25] purrr_1.0.4                     readr_2.1.5                    \n#> [27] tidyr_1.3.1                     tibble_3.2.1                   \n#> [29] ggplot2_3.5.1                   tidyverse_2.0.0                \n#> [31] here_1.0.1                     \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1    jsonlite_1.8.9       magrittr_2.0.3      \n#>   [4] TH.data_1.1-3        estimability_1.5.1   farver_2.1.2        \n#>   [7] nloptr_2.1.1         rmarkdown_2.29       vctrs_0.6.5         \n#>  [10] minqa_1.2.8          base64enc_0.1-3      rstatix_0.7.2       \n#>  [13] htmltools_0.5.8.1    broom_1.0.7          Formula_1.2-5       \n#>  [16] htmlwidgets_1.6.4    plyr_1.8.9           sandwich_3.1-1      \n#>  [19] emmeans_1.10.7       zoo_1.8-12           igraph_2.1.4        \n#>  [22] mime_0.12            lifecycle_1.0.4      pkgconfig_2.0.3     \n#>  [25] Matrix_1.7-2         R6_2.6.1             fastmap_1.2.0       \n#>  [28] rbibutils_2.3        shiny_1.10.0         numDeriv_2016.8-1.1 \n#>  [31] digest_0.6.37        OpenMx_2.21.13       fdrtool_1.2.18      \n#>  [34] colorspace_2.1-1     rprojroot_2.0.4      Hmisc_5.2-2         \n#>  [37] timechange_0.3.0     abind_1.4-8          compiler_4.4.2      \n#>  [40] withr_3.0.2          glasso_1.11          htmlTable_2.4.3     \n#>  [43] backports_1.5.0      carData_3.0-5        ggsignif_0.6.4      \n#>  [46] GPArotation_2024.3-1 corpcor_1.6.10       gtools_3.9.5        \n#>  [49] tools_4.4.2          pbivnorm_0.6.0       foreign_0.8-88      \n#>  [52] zip_2.3.2            httpuv_1.6.15        nnet_7.3-20         \n#>  [55] glue_1.8.0           quadprog_1.5-8       nlme_3.1-167        \n#>  [58] promises_1.3.2       lisrelToR_0.3        grid_4.4.2          \n#>  [61] checkmate_2.3.2      cluster_2.1.8        reshape2_1.4.4      \n#>  [64] generics_0.1.3       gtable_0.3.6         tzdb_0.4.0          \n#>  [67] data.table_1.16.4    hms_1.1.3            xml2_1.3.6          \n#>  [70] car_3.1-3            sem_3.1-16           pillar_1.10.1       \n#>  [73] rockchalk_1.8.157    later_1.4.1          splines_4.4.2       \n#>  [76] lattice_0.22-6       survival_3.8-3       kutils_1.73         \n#>  [79] tidyselect_1.2.1     miniUI_0.1.1.1       pbapply_1.7-2       \n#>  [82] reformulas_0.4.0     svglite_2.1.3        stats4_4.4.2        \n#>  [85] xfun_0.50            qgraph_1.9.8         arm_1.14-4          \n#>  [88] stringi_1.8.4        yaml_2.3.10          pacman_0.5.1        \n#>  [91] boot_1.3-31          evaluate_1.0.3       codetools_0.2-20    \n#>  [94] mi_1.1               cli_3.6.4            RcppParallel_5.1.10 \n#>  [97] rpart_4.1.24         systemfonts_1.2.1    xtable_1.8-4        \n#> [100] Rdpack_2.6.2         munsell_0.5.1        Rcpp_1.0.14         \n#> [103] coda_0.19-4.1        png_0.1-8            XML_3.99-0.18       \n#> [106] parallel_4.4.2       jpeg_0.1-10          lme4_1.1-36         \n#> [109] mvtnorm_1.3-3        openxlsx_4.2.8       rlang_1.1.5         \n#> [112] multcomp_1.4-28      mnormt_2.1.1\n```\n:::\n\n\n\n\n## Bibliografia {.unnumbered}\n\n\n",
    "supporting": [
      "06_efa_lavaan_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
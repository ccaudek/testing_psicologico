{
  "hash": "c477e5600dc0a8b29480ecf7e50e1f2e",
  "result": {
    "engine": "knitr",
    "markdown": "# Strategia Integrata per un'Analisi Fattoriale {#sec-cfa-strategy}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- il flusso di lavoro per eseguire l'analisi fattoriale in R.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Factor Analysis in Education Research Using R* del testo di @saqr2024learning.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, psych, semPlot, semTools, effectsize, devtools)\n```\n:::\n\n\n\n:::\n\n\n## Introduzione\n\nQuesto capitolo propone un tutorial, ispirato al lavoro di @saqr2024learning, su come condurre un'**Analisi Fattoriale** utilizzando **R**. Secondo @saqr2024learning, la distinzione tra **Analisi Fattoriale Esplorativa (EFA)** e **Analisi Fattoriale Confermativa (CFA)** non è sempre netta. Nella pratica, entrambe le tecniche vengono spesso impiegate all'interno dello stesso studio per ottenere una comprensione più completa dei costrutti latenti.\n\nIn questa sezione viene presentata una strategia integrata per combinare EFA e CFA, articolata in tre fasi che i ricercatori possono seguire quando i costrutti latenti giocano un ruolo centrale nello studio. Questo approccio è utile sia quando i costrutti latenti sono il fulcro dello strumento in esame, sia quando vengono utilizzati come **predittori** o **esiti** nell'analisi.\n\n### I tre passaggi principali:\n\n1. **Esplorazione della struttura fattoriale**  \n   Identificare il numero e la natura dei fattori sottostanti attraverso l’EFA, per ottenere un modello iniziale della struttura dei dati.\n\n2. **Costruzione e valutazione del modello fattoriale**  \n   Utilizzare la CFA per confermare il modello individuato nell’EFA, valutando l’adattamento del modello ai dati raccolti.\n\n3. **Valutazione della generalizzabilità**  \n   Verificare se la struttura fattoriale individuata è replicabile e stabile in campioni diversi o in contesti differenti.\n\nQuesto capitolo assume che il ricercatore abbia già completato una fase preliminare di sviluppo dello strumento, concentrandosi su un costrutto di interesse. Inoltre, si presuppone che i dati utilizzati provengano da un **campione rappresentativo** della popolazione target.\n\n## Passo 1: Esplorazione della Struttura Fattoriale\n\nDopo aver selezionato le variabili di interesse e raccolto i relativi dati, il ricercatore dovrebbe avviare il processo con un'**Analisi Fattoriale Esplorativa (EFA)**. Se si utilizza uno strumento già validato o si dispone di ipotesi solide sulla struttura fattoriale sottostante, l’obiettivo iniziale sarà verificare se il numero di fattori e le saturazioni degli indicatori sui fattori corrispondono ai risultati attesi. In questa fase, alcune domande fondamentali da porsi includono:  \n- *Le variabili ipotizzate come influenzate da uno stesso fattore caricano effettivamente su un unico fattore?*  \n- *Se si presuppone l’esistenza di un unico fattore sottostante, le variabili mostrano effettivamente carichi elevati su quel fattore?*\n\nNel caso di strumenti nuovi, l’EFA serve a valutare se la struttura fattoriale emergente è interpretabile. In questo caso, è utile chiedersi:  \n- *Le variabili che saturano principalmente su un fattore condividono effettivamente un contenuto comune?*  \n- *Le variabili che saturano su fattori diversi riflettono differenze qualitative evidenti?*\n\nAd esempio, in un test di matematica, potrebbe emergere che compiti di addizione, sottrazione, divisione e moltiplicazione saturano su quattro fattori distinti, interpretabili rispettivamente come abilità specifiche in ciascuna operazione. \n\nIn questa fase, potrebbero rendersi necessari aggiustamenti. Per esempio, variabili che non presentano carichi fattoriali sufficientemente elevati (ad esempio inferiori a 0.3) su alcuna dimensione potrebbero essere rimosse, seguite da una nuova esecuzione dell’EFA. Tuttavia, è fondamentale riflettere attentamente sulle ragioni di eventuali carichi fattoriali bassi, che potrebbero dipendere, ad esempio, da una formulazione poco chiara di un item. La rimozione di variabili dovrebbe essere guidata da una motivazione teorica solida, evitando decisioni arbitrarie.\n\n## Passo 2: Costruzione del Modello Fattoriale e Valutazione dell’Adattamento\n\nDopo aver individuato un modello preliminare tramite l’EFA, il passo successivo consiste nel raffinare il modello e applicare la **CFA** per valutare quanto bene esso si adatti ai dati. Questo significa verificare se le covarianze previste dalla struttura fattoriale corrispondono alle covarianze osservate nel dataset. Nell’EFA, ogni variabile poteva caricare su tutti i fattori, ma con la CFA è possibile limitare i carichi fattoriali sulla base di considerazioni teoriche o empiriche.\n\nIn questa fase, è importante restringere il modello eliminando i carichi trasversali (cross-loadings) che non sono coerenti con la teoria o che risultano vicini allo zero. I carichi molto bassi possono essere rimossi senza introdurre problemi, ma quelli più alti richiedono una valutazione attenta. Anche se inizialmente sembrano privi di significato, la loro presenza potrebbe suggerire informazioni inattese sui dati. Pertanto, prima di rimuoverli, è fondamentale verificarne la coerenza con la teoria o le ipotesi iniziali. Se, dopo un’analisi approfondita, questi carichi possono essere giustificati teoricamente, è preferibile mantenerli. In caso contrario, si possono eliminare, procedendo poi a valutare l’adattamento del modello modificato ai dati.\n\nUna volta definite le relazioni tra variabili e fattori, si costruisce il modello CFA e lo si applica al dataset. Se l’adattamento del modello non risulta soddisfacente, è possibile tornare ai risultati dell’EFA per valutare l’inclusione di ulteriori carichi fattoriali o altre modifiche. Tuttavia, qualsiasi aggiunta o cambiamento deve essere giustificato teoricamente, evitando adattamenti puramente empirici.\n\n## Passo 3: Valutazione della Generalizzabilità\n\nDopo aver costruito e valutato il modello, l’obiettivo è verificarne la **generalizzabilità**. Questo passaggio è cruciale per garantire che il modello sia valido non solo per i dati attuali, ma anche per futuri studi sulla stessa popolazione. Tale verifica si effettua tramite la **validazione incrociata**, che consiste nel testare il modello su un dataset indipendente.\n\nIdealmente, sarebbe opportuno raccogliere un secondo dataset rappresentativo della stessa popolazione. Tuttavia, nella pratica, questa soluzione è spesso poco realizzabile a causa di limiti di tempo o risorse. Un’alternativa comune è dividere il dataset iniziale in due sottocampioni:  \n\n1. **Campione di sviluppo**: utilizzato per eseguire i Passi 1 (EFA) e 2 (CFA).  \n2. **Campione di validazione**: riservato al Passo 3 per testare la generalizzabilità.  \n\nSe il modello CFA si adatta bene anche al campione di validazione, si ottiene una maggiore certezza sulla sua applicabilità in futuri studi. Se invece emergono problemi di adattamento, occorre analizzarne le cause, verificare eventuali incoerenze tra teoria e dati, e aggiornare di conseguenza il modello e le ipotesi.\n\n### Considerazioni finali\n\nQuesta strategia, articolata in tre passaggi, rappresenta un approccio sistematico per l’analisi fattoriale in studi che utilizzano strumenti per misurare costrutti latenti. Anche quando si utilizza uno strumento già validato su una popolazione analoga, seguire questa procedura rimane una scelta prudente per evitare possibili distorsioni nei risultati.\n\n## Analisi Fattoriale in R\n\n@saqr2024learning propone un tutorial dettagliato sui passaggi essenziali per condurre un’**Analisi Fattoriale Esplorativa (EFA)** e un’**Analisi Fattoriale Confermativa (CFA)** utilizzando **R**. Il tutorial affronta i seguenti aspetti chiave:  \n\n- verifica preliminare delle caratteristiche dei dati per valutarne l’idoneità all’EFA/CFA,  \n- scelta del numero di fattori,  \n- valutazione dell’adattamento globale e locale del modello,  \n- verifica della generalizzabilità del modello fattoriale finale.\n\n### Struttura del tutorial\n\nIl tutorial inizia con la preparazione dei dati: importazione, controllo della loro idoneità per l’analisi fattoriale e suddivisione del dataset per riservare un campione per la validazione incrociata. Successivamente, vengono descritti i passaggi per condurre:  \n\n1. un’EFA per definire una struttura fattoriale preliminare (Passo 1),  \n2. una CFA per affinare e validare il modello (Passo 2),  \n3. la verifica della generalizzabilità del modello tramite validazione incrociata (Passo 3).  \n\n### Preparazione\n\nIl dataset utilizzato da @saqr2024learning raccoglie dati di un’indagine sul burnout degli insegnanti in Indonesia, con 876 rispondenti. Le domande sono organizzate in cinque ambiti teorici:  \n\n1. **Concetto di Sé dell’Insegnante (TSC)**: 5 item,  \n2. **Efficacia dell’Insegnante (TE)**: 5 item,  \n3. **Esaurimento Emotivo (EE)**: 5 item,  \n4. **Depersonalizzazione (DP)**: 3 item,  \n5. **Riduzione del Senso di Realizzazione Personale (RPA)**: 7 item.  \n\nIn totale, il dataset include **25 variabili**, ciascuna valutata su una scala Likert a 5 punti (da 1 = “mai” a 5 = “sempre”). Questa organizzazione rende il dataset ideale per un’analisi fattoriale, consentendo di esplorare la struttura latente delle dimensioni teoriche ipotizzate.\n\nPrima di procedere con l’EFA e la CFA, è necessario:  \n\n- verificare la **sufficienza del campione** (ad esempio, tramite il test di Kaiser-Meyer-Olkin, KMO),  \n- controllare la **normalità delle distribuzioni** o eventuali deviazioni,  \n- suddividere il dataset in due sottocampioni, uno per lo sviluppo del modello e uno per la validazione.\n\nQuesto approccio organizzato fornisce una base solida per esplorare e confermare la struttura fattoriale, testandone infine la replicabilità su un campione indipendente. La chiarezza dei passaggi rende il tutorial applicabile a una vasta gamma di contesti di ricerca.\n\nCarichiamo le funzioni di supporto definite da @saqr2024learning:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Source 'sleasy' functions\nsource(here::here(\"code\", \"sleasy.R\"))\n```\n:::\n\n\n\n\nImportiamo i dati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndataset <- rio::import(\"https://github.com/lamethods/data/raw/main/4_teachersBurnout/2.%20Response.xlsx\")\n```\n:::\n\n\n\n\n\n## I Dati Sono Adatti all'Analisi Fattoriale?\n\nPer condurre un’**Analisi Fattoriale Esplorativa (EFA)** o una **Analisi Fattoriale Confermativa (CFA)**, è fondamentale assicurarsi che i dati soddisfino determinati requisiti. Di seguito vengono descritti i principali aspetti da considerare.\n\n### Variabili continue o categoriche\n\nIdealmente, le variabili dovrebbero essere continue. Sebbene raramente le variabili siano perfettamente continue, è accettabile trattarle come tali se sono misurate su una scala con almeno cinque categorie di risposta e presentano una distribuzione ragionevolmente simmetrica. \n\nSe le variabili sono categoriche (ad esempio, binarie o ordinali), è comunque possibile condurre un’analisi fattoriale utilizzando metodi di stima specifici per questo tipo di dati. Inoltre, tutte le variabili dovrebbero preferibilmente essere misurate sulla stessa scala. In caso contrario, oppure se le variabili presentano intervalli di punteggio molto diversi (ad esempio, alcune con valori da 1 a 5 e altre da 2 a 4), è opportuno trasformare le variabili per uniformare le scale prima dell’analisi.\n\nL’intervallo di ciascuna variabile può essere verificato con il comando seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescribe(dataset)\n#>      vars   n mean   sd median trimmed  mad min max range  skew kurtosis\n#> TSC1    1 876 3.65 0.68      4    3.62 0.00   1   5     4 -0.09     0.06\n#> TSC2    2 876 3.81 0.64      4    3.78 0.00   2   5     3 -0.07    -0.14\n#> TSC3    3 876 3.73 0.64      4    3.71 0.00   2   5     3 -0.17    -0.02\n#> TSC4    4 876 3.71 0.67      4    3.67 0.00   2   5     3 -0.03    -0.25\n#> TSC5    5 876 3.82 0.65      4    3.79 0.00   2   5     3 -0.10    -0.13\n#> TE1     6 876 4.06 0.71      4    4.10 0.00   1   5     4 -0.47     0.38\n#> TE2     7 876 4.04 0.70      4    4.07 0.00   2   5     3 -0.22    -0.45\n#> TE3     8 876 4.12 0.71      4    4.17 0.00   1   5     4 -0.72     1.60\n#> TE4     9 876 4.11 0.69      4    4.15 0.00   1   5     4 -0.47     0.51\n#> TE5    10 876 3.90 0.75      4    3.92 0.00   1   5     4 -0.41     0.16\n#> EE1    11 876 3.81 0.76      4    3.81 0.00   1   5     4 -0.35     0.23\n#> EE2    12 876 3.73 0.85      4    3.75 1.48   1   5     4 -0.37     0.12\n#> EE3    13 876 3.88 0.83      4    3.91 1.48   1   5     4 -0.31    -0.40\n#> EE4    14 876 3.69 0.80      4    3.67 1.48   1   5     4 -0.03    -0.41\n#> EE5    15 876 3.99 0.81      4    4.03 1.48   1   5     4 -0.43    -0.27\n#> DE1    16 876 3.92 0.68      4    3.93 0.00   1   5     4 -0.53     1.25\n#> DE2    17 876 3.60 0.68      4    3.58 1.48   1   5     4 -0.22     0.64\n#> DE3    18 876 3.82 0.70      4    3.79 0.00   1   5     4 -0.14     0.01\n#> RPA1   19 876 3.93 0.83      4    3.97 1.48   1   5     4 -0.59     0.50\n#> RPA2   20 876 3.94 0.80      4    3.99 0.00   1   5     4 -0.79     1.22\n#> RPA3   21 876 3.88 0.79      4    3.91 0.00   1   5     4 -0.59     0.75\n#> RPA4   22 876 3.87 0.76      4    3.89 0.00   1   5     4 -0.48     0.33\n#> RPA5   23 876 3.84 0.79      4    3.86 0.00   1   5     4 -0.53     0.67\n#>        se\n#> TSC1 0.02\n#> TSC2 0.02\n#> TSC3 0.02\n#> TSC4 0.02\n#> TSC5 0.02\n#> TE1  0.02\n#> TE2  0.02\n#> TE3  0.02\n#> TE4  0.02\n#> TE5  0.03\n#> EE1  0.03\n#> EE2  0.03\n#> EE3  0.03\n#> EE4  0.03\n#> EE5  0.03\n#> DE1  0.02\n#> DE2  0.02\n#> DE3  0.02\n#> RPA1 0.03\n#> RPA2 0.03\n#> RPA3 0.03\n#> RPA4 0.03\n#> RPA5 0.03\n```\n:::\n\n\n\n\nNel dataset in esame, le variabili sono misurate su scale Likert a 5 punti con intervalli simili, per cui possono essere trattate come continue senza ulteriori trasformazioni.\n\n### Dimensione del campione\n\nLa dimensione del campione è un aspetto cruciale. Esistono diverse regole empiriche:\n- Una regola generale suggerisce un campione minimo di 200 osservazioni.\n- Per modelli semplici (pochi fattori, relazioni forti tra fattori e variabili), campioni più piccoli possono essere sufficienti. Per modelli complessi (molti fattori o relazioni più deboli), è necessario un campione più ampio.\n- Bentler e Chou raccomandano almeno 5 osservazioni per ogni parametro da stimare, mentre Jackson suggerisce almeno 10, preferibilmente 20 osservazioni per parametro.\n\nNel dataset di esempio, con 25 variabili che si presume misurino 5 costrutti latenti, i parametri da stimare includono:  \n\n- **25 intercetti**,  \n- **25 varianze residue**,  \n- **125 carichi fattoriali** (5 fattori × 25 variabili).  \n\nIn totale, si devono stimare 175 parametri. La dimensione del campione è verificabile con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnrow(dataset)\n#> [1] 876\n```\n:::\n\n\n\n\nCon 876 osservazioni, il campione è sufficiente secondo Bentler e Chou (5 × 175 = 875) ma non soddisfa il criterio di Jackson per modelli più robusti. Pertanto, non è consigliabile suddividere il dataset per la validazione incrociata. Tuttavia, a scopo didattico, sarà mostrato come creare un campione di riserva.\n\n### Correlazioni tra variabili\n\nUn presupposto fondamentale per l’analisi fattoriale è che le variabili siano correlate. Questo può essere verificato tramite il **test di Bartlett**, che controlla se la matrice di correlazione è una matrice identità (cioè con elementi fuori diagonale pari a zero). L’ipotesi nulla del test afferma che le variabili non sono correlate. Se l’ipotesi viene rifiutata, è possibile procedere con l’analisi fattoriale. Il comando seguente verifica il p-value del test:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar_names <- colnames(dataset)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(cortest.bartlett(\n    R = cor(dataset[, var_names]), \n    n = nrow(dataset)\n)$p.value) < 0.05\n#> [1] TRUE\n```\n:::\n\n\n\n\nNel nostro esempio, il p-value è inferiore a 0,05, indicando che le variabili sono sufficientemente correlate.\n\n### Adeguatezza della varianza comune\n\nUn altro requisito è che le variabili condividano una quantità sufficiente di varianza comune. Questo può essere valutato tramite il **test di Kaiser-Meyer-Olkin (KMO)**, che misura la proporzione di varianza totale attribuibile a varianza comune. Secondo Kaiser, un valore KMO di almeno 0,8 è adeguato, mentre un valore di 0,9 o superiore è eccellente. Per calcolare il valore KMO, si utilizza:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nKMO(dataset)\n#> Kaiser-Meyer-Olkin factor adequacy\n#> Call: KMO(r = dataset)\n#> Overall MSA =  0.94\n#> MSA for each item = \n#> TSC1 TSC2 TSC3 TSC4 TSC5  TE1  TE2  TE3  TE4  TE5  EE1  EE2  EE3  EE4  EE5 \n#> 0.96 0.96 0.95 0.94 0.96 0.93 0.96 0.94 0.94 0.96 0.95 0.94 0.95 0.94 0.97 \n#>  DE1  DE2  DE3 RPA1 RPA2 RPA3 RPA4 RPA5 \n#> 0.87 0.86 0.92 0.91 0.91 0.95 0.94 0.96\n```\n:::\n\n\n\n\nNel dataset in esame, il valore KMO è pari a 0.94, suggerendo un’eccellente adeguatezza per l’analisi fattoriale.\n\n### Normalità e dati mancanti\n\nLe distribuzioni delle variabili devono essere valutate per verificare la presenza di eventuali deviazioni dalla normalità. Sebbene l’analisi fattoriale possa gestire deviazioni moderate, in caso di non-normalità è necessario utilizzare metodi di stima robusti. La normalità può essere esaminata tramite istogrammi, come nel comando seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndataset |>\n    pivot_longer(2:ncol(dataset),\n        names_to = \"Variable\", values_to = \"Score\"\n    ) |>\n    ggplot(aes(x = Score)) +\n    geom_histogram(bins = 6) +\n    scale_x_continuous(\n        limits = c(0, 6), breaks = c(1, 2, 3, 4, 5)\n    ) +\n    facet_wrap(\"Variable\", ncol = 6, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](07_fa_in_r_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nInoltre, è necessario verificare la presenza di dati mancanti. La quantità di valori mancanti per variabile può essere calcolata con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncolSums(is.na(dataset)) \n#> TSC1 TSC2 TSC3 TSC4 TSC5  TE1  TE2  TE3  TE4  TE5  EE1  EE2  EE3  EE4  EE5 \n#>    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n#>  DE1  DE2  DE3 RPA1 RPA2 RPA3 RPA4 RPA5 \n#>    0    0    0    0    0    0    0    0\n```\n:::\n\n\n\n\nSe i dati mancanti sono presenti, è necessario adottare tecniche appropriate per gestirli, come l’imputazione o l’esclusione di osservazioni.\n\nQuesti controlli preliminari garantiscono che i dati siano adeguati per l’analisi fattoriale e pongono le basi per ottenere risultati affidabili e interpretabili.\n\n## Separare un Campione di Riserva\n\nDopo aver verificato che i dati siano adatti all'analisi fattoriale, è possibile considerare la creazione di un campione di riserva per valutare la **generalizzabilità** dei risultati. Tuttavia, questa decisione deve tenere conto della **dimensione del campione**. Come discusso in precedenza, la dimensione minima del campione deve essere almeno **5 volte il numero di parametri da stimare** (preferibilmente 10 o 20 volte per modelli più robusti). È importante non suddividere il dataset se il campione disponibile non è sufficientemente ampio da soddisfare i requisiti per entrambe le parti (campione di costruzione e campione di riserva), poiché ciò potrebbe compromettere la qualità del modello. In questi casi, la validazione del modello dovrebbe essere rimandata a studi futuri.\n\nÈ utile notare che il numero di parametri da stimare in un modello CFA è generalmente inferiore rispetto a un modello EFA. Pertanto, il campione di riserva può essere leggermente più piccolo rispetto a quello utilizzato per costruire il modello.\n\n### Considerazioni per il dataset di esempio\n\nNel nostro esempio, il campione totale di **876 osservazioni** non è due volte la dimensione minima richiesta per un modello con **25 variabili** e **5 fattori latenti**. Tuttavia, a scopo illustrativo, procederemo comunque alla creazione di un campione di riserva. Dividiamo il dataset in due parti uguali:  \n- **438 osservazioni** per la costruzione del modello (campione di costruzione).  \n- **438 osservazioni** per la validazione (campione di riserva).  \n\n### Procedura per la suddivisione\n\nLa suddivisione avviene in modo casuale attraverso i seguenti passaggi:\n\n1. **Impostazione del seed:**  \n   Il seed viene impostato con `set.seed()` per garantire che la divisione casuale sia replicabile. Questo è fondamentale per assicurare la coerenza dei risultati.\n\n2. **Creazione di un vettore di classificazione:**  \n   Si genera un vettore chiamato `ind`, contenente le etichette “model.building” e “holdout” ripetute 438 volte ciascuna, in ordine casuale. Ogni riga del dataset sarà quindi assegnata a uno dei due gruppi.\n\n3. **Divisione del dataset:**  \n   Utilizzando la funzione `split()`, il dataset viene suddiviso in due sottoinsiemi. Le righe vengono assegnate al campione di costruzione o al campione di riserva in base al valore corrispondente nel vettore `ind`.\n\n4. **Estrazione dei dataset finali:**  \n   I due nuovi dataset vengono estratti dalla lista creata con `split()` e memorizzati in due oggetti: `model.building` e `holdout`.\n\nEcco il codice per eseguire la suddivisione:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Imposta il seed per garantire la replicabilità\nset.seed(19)\n\n# Crea il vettore di classificazione\nind <- sample(\n    c(rep(\"model.building\", 438), rep(\"holdout\", 438))\n)\n\n# Suddividi il dataset in base al vettore di classificazione\ntmp <- split(dataset, ind)\n\n# Estrai i due dataset finali\nmodel.building <- tmp$model.building\nholdout <- tmp$holdout\n```\n:::\n\n\n\n\n### Spiegazione dei passaggi\n\n- **Impostazione del seed:**  \n   La funzione `set.seed(19)` garantisce che la suddivisione casuale produca sempre lo stesso risultato, facilitando il controllo e la replicabilità.\n\n- **Creazione del vettore `ind`:**  \n   Il vettore contiene un totale di 876 valori, con 438 assegnati a “model.building” e 438 a “holdout”, in ordine casuale. \n\n- **Divisione del dataset:**  \n   La funzione `split()` divide il dataset in base ai valori di `ind`, creando una lista contenente due sottoinsiemi: uno per il modello di costruzione (`model.building`) e uno per il campione di riserva (`holdout`).\n\n- **Estrazione dei dataset finali:**  \n   I due sottoinsiemi vengono estratti dalla lista `tmp` e assegnati agli oggetti finali per l’analisi.\n\n\n## Passo 1: Esplorare la Struttura Fattoriale\n\nIl primo passo per esplorare la struttura fattoriale consiste nel determinare il numero di dimensioni sottostanti al costrutto di interesse. Questo processo può essere condotto utilizzando due approcci complementari: **l’analisi parallela** e il **criterio di informazione bayesiano (BIC)**.  \n\n- L’**analisi parallela** fornisce un intervallo plausibile per il numero di dimensioni.  \n- Il **BIC** aiuta a scegliere il numero specifico di fattori che meglio si adatta ai dati, tenendo conto della parsimonia del modello.\n\n### Analisi Parallela\n\nL’analisi parallela è un metodo basato su simulazioni che confronta la varianza spiegata da un certo numero di fattori nei dati reali con la varianza spiegata dagli stessi fattori in dataset simulati (privi di correlazioni tra le variabili, ma con la stessa dimensione e struttura).  \n\nUn fattore viene considerato rilevante se la varianza spiegata nei dati reali supera quella osservata nei dati simulati, indicando che non si tratta di una struttura casuale. Il numero di fattori selezionato è quello in cui i valori osservati nei dati reali superano quelli simulati, fino a un punto in cui non si osserva più questa differenza.  \n\nDettagli tecnici sull’analisi parallela e la sua implementazione sono disponibili nella documentazione della funzione `fa.parallel()`.\n\n### Applicazione dell’Analisi Parallela\n\nPer applicare l’analisi parallela:  \n\n1. Specificare i dati di costruzione del modello e le colonne corrispondenti alle variabili di interesse.  \n2. Utilizzare l’argomento `fa = \"fa\"` per indicare che si desidera determinare il numero di fattori per l’analisi fattoriale (e non per l’analisi dei componenti principali).  \n\nIl risultato include:  \n\n- Un **messaggio** che suggerisce il numero plausibile di fattori sottostanti.\n- Un **grafico** che mostra come la varianza spiegata dai dati reali supera quella dei dati simulati fino a un certo numero di fattori.  \n\nAd esempio, nel nostro caso, il messaggio indica che sono probabilmente presenti **cinque fattori**. Nel grafico, si osserva che oltre cinque fattori la varianza spiegata nei dati reali è inferiore a quella dei dati simulati.  \n\nL’analisi parallela è un approccio **data-driven**: il numero di fattori suggerito è influenzato dal campione analizzato e deve essere considerato un punto di partenza. L’intervallo plausibile può includere più o meno un fattore rispetto a quello suggerito.\n\n### Criterio di Informazione Bayesiano (BIC)\n\nDopo aver determinato un intervallo plausibile di fattori con l’analisi parallela, è necessario scegliere il numero finale utilizzando: \n\n1. **L’interpretabilità teorica**: valutare se le relazioni tra variabili e fattori sono coerenti con il costrutto di interesse.  \n2. **L’adattamento del modello**: confrontare i modelli con diversi numeri di fattori utilizzando il BIC.\n\nIl **BIC** bilancia l’adattamento del modello ai dati con la semplicità del modello, penalizzando la complessità (cioè l’aggiunta di parametri). Un valore BIC più basso indica un migliore equilibrio tra adattamento e parsimonia.  \n\nAd esempio, se il modello con **cinque fattori** presenta il BIC più basso, ciò fornisce un supporto per questa soluzione. Tuttavia, la decisione finale dovrebbe integrare il valore del BIC con considerazioni teoriche.\n\n### Codice per l’analisi parallela\n\nDi seguito è riportato il comando per eseguire l’analisi parallela:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Determinare il numero di fattori con l'analisi parallela\nfa.parallel(x = model.building[, var_names], fa = \"fa\")\n#> Parallel analysis suggests that the number of factors =  5  and the number of components =  NA\n```\n\n::: {.cell-output-display}\n![](07_fa_in_r_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesto comando genera un grafico e un output testuale, fornendo indicazioni sul numero plausibile di fattori.\n\nIn sintesi, l’analisi parallela e il BIC sono strumenti potenti e complementari per esplorare la struttura fattoriale. L’analisi parallela suggerisce un intervallo plausibile, mentre il BIC aiuta a identificare la soluzione più parsimoniosa. Integrare questi metodi con considerazioni teoriche è fondamentale per ottenere un modello fattoriale solido e interpretabile.\n\n### Analisi Fattoriale Esplorativa\n\nL’**Analisi Fattoriale Esplorativa (EFA)** può essere eseguita utilizzando il comando seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nEFA <- efa(\n    data = model.building[, var_names],\n    nfactors = 4:6,\n    rotation = \"geomin\", \n    estimator = \"MLR\",\n    meanstructure = TRUE\n)\n```\n:::\n\n\n\n\nLa funzione `efa()` appartiene al pacchetto `lavaan` e consente di esplorare il numero e la struttura dei fattori latenti nei dati. Di seguito vengono spiegati gli argomenti principali della funzione.\n\n### Descrizione degli Argomenti\n\n1. **`data`**  \n   Specifica il dataset su cui eseguire l’EFA. In questo caso, include solo le colonne delle variabili di interesse.\n\n2. **`nfactors`**  \n   Indica l’intervallo di numeri di fattori da considerare. Qui, i modelli sono stimati con 4, 5 e 6 fattori.\n\n3. **`rotation`**  \n   Questo argomento determina il metodo di rotazione utilizzato per identificare il modello.  \n   - La rotazione è necessaria nell’EFA, poiché, in assenza di restrizioni, esistono infinite soluzioni matematiche equivalenti. Ruotare la matrice dei carichi fattoriali consente di semplificare l’interpretazione, orientando gli assi dei fattori latenti.  \n   - In questo esempio, viene utilizzata la rotazione **geomin**, che permette ai fattori di essere correlati, una scelta realistica in contesti educativi e psicologici.\n\n4. **`estimator`**  \n   Specifica il metodo di stima.  \n   - Il valore predefinito è \"ML\" (massima verosimiglianza), ma qui viene utilizzato \"MLR\" (massima verosimiglianza robusta), che gestisce meglio eventuali violazioni della normalità nei dati.\n\n5. **Dati mancanti**  \n   - Se i dati contengono valori mancanti, è possibile utilizzare l’argomento `missing = \"fiml\"`, che applica il metodo **Full Information Maximum Likelihood (FIML)**. Questo approccio sfrutta tutte le informazioni disponibili ed è appropriato quando i dati mancanti sono MAR (*Missing At Random*).  \n\n6. **`meanstructure`**  \n   Quando impostato su `TRUE`, stima anche gli intercetti delle variabili osservate, oltre a varianze e covarianze. Se si utilizza `missing = \"fiml\"`, l’opzione `meanstructure` è automaticamente attivata.\n\n### Interpretazione dei Risultati\n\nPer identificare il modello migliore, è possibile ordinare i valori del **BIC** (Criterio di Informazione Bayesiano) in ordine crescente con il comando seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsort(fitMeasures(EFA)[\"bic\", ]) \n#> nfactors = 5 nfactors = 4 nfactors = 6 \n#>        18142        18167        18189\n```\n:::\n\n\n\n\nL’output indica che il modello con **cinque fattori** è quello che ottiene il valore BIC più basso. Questo risultato è in linea sia con l’**analisi parallela** precedente sia con il numero di fattori atteso in base alla teoria (cinque fattori). Di conseguenza, il modello a cinque fattori è il più adatto per continuare l’analisi.\n\n### Estrarre i Carichi Fattoriali\n\nI carichi fattoriali per il modello a cinque fattori possono essere estratti con il comando seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nEFA$nf5\n#> \n#>          f1      f2      f3      f4      f5 \n#> TSC1  0.584*                       *      .*\n#> TSC2  0.487*                       *      .*\n#> TSC3  0.637*                      .*       *\n#> TSC4  0.578*      .*              .*       *\n#> TSC5  0.547*                              . \n#> TE1           0.728*              .         \n#> TE2       .   0.672*                        \n#> TE3           0.708*      .                 \n#> TE4           0.651*              .*        \n#> TE5           0.337*      .*      .*        \n#> EE1               .   0.469*      .         \n#> EE2       .*          0.689*                \n#> EE3                   0.768*                \n#> EE4       .*          0.732*              . \n#> EE5               .   0.479*      .*        \n#> DE1                  -0.353*  0.744*      . \n#> DE2               .*          0.821*        \n#> DE3                       .*  0.755*        \n#> RPA1                                  0.851*\n#> RPA2                                  0.906*\n#> RPA3                                  0.624*\n#> RPA4                      .       .   0.350*\n#> RPA5                      .       .   0.338*\n```\n:::\n\n\n\n\nL’output fornisce i carichi standardizzati, che possono essere interpretati come correlazioni tra le variabili osservate e i fattori latenti. Vengono mostrati solo i carichi assoluti superiori a 0.3. \n\n- **Osservazioni sulla struttura fattoriale**  \n   I risultati indicano una struttura semplice, in cui ciascuna variabile carica su un solo fattore, ad eccezione della variabile **DE1**.  \n   - **DE1** presenta un **cross-loading**: un carico positivo sul fattore 4 (insieme alle altre variabili DE) e un carico negativo sul fattore 3 (insieme alle variabili EE).  \n   - A parte questa eccezione, le variabili TSC, TE, EE, DE e RPA caricano rispettivamente su un unico fattore, confermando la coerenza con il modello teorico.\n\n### Passaggi Successivi\n\nIl modello può ora essere affinato nella sezione CFA. Poiché la teoria non prevede il cross-loading di **DE1**, nel modello CFA verrà impostato a zero il carico di questa variabile sul fattore 3. Tuttavia, se il modello CFA non dovesse adattarsi bene, il ripristino di questo cross-loading sarà la prima modifica da considerare.\n\nQuesta procedura consente di integrare i risultati dell’EFA con la teoria e di preparare il modello per la successiva conferma tramite l’analisi fattoriale confermativa.\n\n## Passo 2: Costruire il Modello Fattoriale e Valutare l'Adattamento\n\nIl primo passo per costruire il modello fattoriale è definirlo utilizzando la sintassi di `lavaan`. Nel modello seguente, vengono specificati i 5 fattori (**TSC**, **TE**, **EE**, **DE** e **RPA**) in base alle variabili osservate identificate dall’EFA. Si includono inoltre le correlazioni tra fattori, come indicato dalla teoria e dai risultati precedenti. Gli intercetti non sono esplicitamente definiti, ma possono essere stimati impostando l’argomento `meanstructure = TRUE`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCFA_model <- \"\n    # Relazioni tra variabili osservate e fattori\n    TSC =~ TSC1 + TSC2 + TSC3 + TSC5\n    TE =~ TE1 + TE2 + TE3 + TE5\n    EE =~ EE1 + EE2 + EE3 + EE4\n    DE =~ DE1 + DE2 + DE3\n    RPA =~ RPA1 + RPA2 + RPA3 + RPA4\n    # Correlazioni tra fattori\n    TSC ~~ TE + EE + DE + RPA\n    TE ~~ EE + DE + RPA\n    EE ~~ DE + RPA\n    DE ~~ RPA\n\"\n```\n:::\n\n\n\n\nIl modello viene stimato con il comando seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCFA <- cfa(\n    model = CFA_model, \n    data = model.building[, var_names],\n    estimator = \"MLR\", \n    std.lv = TRUE, \n    meanstructure = TRUE\n)\n```\n:::\n\n\n\n\n- **`estimator = \"MLR\"`**: utilizza la massima verosimiglianza robusta, che gestisce eventuali deviazioni dalla normalità.\n- **`std.lv = TRUE`**: standardizza i fattori latenti, rendendo i carichi interpretabili come correlazioni.\n- **`meanstructure = TRUE`**: stima anche gli intercetti delle variabili osservate.\n\nL’adattamento del modello si valuta attraverso due livelli: **adattamento globale** e **adattamento locale**.\n\n### Adattamento Globale\n\nL’adattamento globale verifica quanto bene l’intero modello rappresenti i dati. Le principali misure da considerare sono:\n\n1. **Test Chi-quadro**: verifica se il modello riproduce perfettamente le relazioni osservate. È sensibile alla dimensione del campione e tende a rifiutare l’adattamento perfetto con campioni ampi.\n2. **Indice di adattamento comparativo (CFI)**: valuta l’adattamento relativo del modello rispetto a un modello nullo (senza correlazioni tra le variabili).\n3. **Errore quadratico medio di approssimazione (RMSEA)**: quantifica l’adattamento approssimativo, penalizzando la complessità del modello.\n4. **Residuo quadratico medio standardizzato (SRMR)**: rappresenta la discrepanza media tra la matrice di covarianza campionaria e quella del modello.\n\n**Linee guida per l’interpretazione**:  \n\n- **Chi-quadro**: non significativo è preferibile, ma può essere ignorato in campioni ampi.  \n- **CFI**: > 0.90 indica un buon adattamento; > 0.95 è eccellente.  \n- **RMSEA**: < 0.05 è ottimale; < 0.08 è accettabile.  \n- **SRMR**: < 0.08 è raccomandato.  \n\nPuoi calcolare queste misure con il comando:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglobalFit(CFA)\n#> Results------------------------------------------------------------------------ \n#>  \n#> Chi-Square (142) = 319 with p-value\n#>           = 1.33e-15\n#> \n#> CFI = 0.948\n#> \n#> RMSEA = 0.0533; lower bound = 0.0459;\n#>       upper bound = 0.0608\n#> \n#> SRMR = 0.0435\n#> \n#> Interpretations--------------------------------------------------------------- \n#>  \n#> The hypothesis of perfect fit *is* rejected according to the Chi-\n#>           Square test statistics because the p-value is smaller than 0.05 \n#>  \n#> The hypothesis of approximate model fit *is not* rejected according\n#>           to the CFI because the value is larger than 0.9. \n#>  \n#> The hypothesis of approximate model fit *is* rejected according\n#>          to the RMSEA because the point estimate is larger or equal to\n#>          0.05. \n#>  \n#> The hypothesis of approximate model fit *is not* rejected according\n#>          to the SRMR because the value is smaller than 0.08. \n#> \n```\n:::\n\n\n\n\n- Il test Chi-quadro rifiuta l’adattamento perfetto, ma le altre misure (CFI, RMSEA, SRMR) indicano un buon adattamento approssimativo.  \n- Poiché almeno tre misure supportano il modello, è possibile procedere senza ulteriori modifiche.\n\n### Adattamento Locale\n\nL’adattamento locale verifica se ogni parte del modello si adatta bene ai dati. Ciò si ottiene confrontando le differenze assolute tra la matrice di covarianza campionaria e quella implicata dal modello. Questo consente di identificare problemi specifici, come variabili mal rappresentate.\n\nIl comando seguente calcola queste differenze per ogni coppia di variabili:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlocalFit(CFA) \n#> $local_misfit\n#>       TSC1  TSC2  TSC3  TSC5   TE1   TE2   TE3   TE5   EE1   EE2   EE3\n#> TSC1 0.000                                                            \n#> TSC2 0.012 0.000                                                      \n#> TSC3 0.007 0.012 0.000                                                \n#> TSC5 0.007 0.002 0.010 0.000                                          \n#> TE1  0.019 0.000 0.009 0.010 0.000                                    \n#> TE2  0.025 0.014 0.031 0.021 0.011 0.000                              \n#> TE3  0.013 0.010 0.048 0.005 0.003 0.008 0.000                        \n#> TE5  0.025 0.028 0.032 0.022 0.012 0.026 0.005 0.000                  \n#> EE1  0.013 0.010 0.004 0.016 0.042 0.044 0.001 0.072 0.000            \n#> EE2  0.004 0.009 0.025 0.003 0.029 0.050 0.027 0.043 0.002 0.000      \n#> EE3  0.013 0.015 0.039 0.013 0.021 0.042 0.006 0.081 0.012 0.001 0.000\n#> EE4  0.002 0.002 0.000 0.013 0.042 0.021 0.006 0.039 0.017 0.017 0.010\n#> DE1  0.011 0.019 0.015 0.002 0.010 0.026 0.011 0.036 0.010 0.048 0.042\n#> DE2  0.014 0.018 0.030 0.011 0.008 0.025 0.032 0.059 0.058 0.031 0.012\n#> DE3  0.000 0.008 0.041 0.021 0.023 0.006 0.012 0.019 0.048 0.015 0.022\n#> RPA1 0.008 0.015 0.034 0.011 0.013 0.022 0.001 0.012 0.011 0.018 0.019\n#> RPA2 0.006 0.008 0.044 0.007 0.021 0.004 0.009 0.008 0.015 0.016 0.002\n#> RPA3 0.041 0.016 0.012 0.003 0.006 0.010 0.017 0.034 0.035 0.008 0.022\n#> RPA4 0.020 0.000 0.003 0.031 0.001 0.027 0.031 0.039 0.042 0.035 0.031\n#>        EE4   DE1   DE2   DE3  RPA1  RPA2  RPA3  RPA4\n#> TSC1                                                \n#> TSC2                                                \n#> TSC3                                                \n#> TSC5                                                \n#> TE1                                                 \n#> TE2                                                 \n#> TE3                                                 \n#> TE5                                                 \n#> EE1                                                 \n#> EE2                                                 \n#> EE3                                                 \n#> EE4  0.000                                          \n#> DE1  0.040 0.000                                    \n#> DE2  0.052 0.004 0.000                              \n#> DE3  0.012 0.002 0.006 0.000                        \n#> RPA1 0.041 0.008 0.006 0.002 0.000                  \n#> RPA2 0.053 0.010 0.025 0.024 0.024 0.000            \n#> RPA3 0.009 0.002 0.016 0.021 0.009 0.017 0.000      \n#> RPA4 0.053 0.006 0.056 0.074 0.046 0.011 0.052 0.000\n#> \n#> $max_misfit\n#> [1] 0.0805\n```\n:::\n\n\n\n\nL’output mostra che la differenza massima tra le due matrici è 0,08, un valore trascurabile rispetto alla scala delle variabili. Non emergono problemi locali degni di nota.\n\n### Affinare il Modello\n\nSe fossero emersi problemi di adattamento locale, si potrebbero apportare modifiche mirate, come aggiungere covarianze tra variabili. Tuttavia, ogni modifica dovrebbe avere una solida giustificazione teorica. **Non introdurre parametri aggiuntivi solo per migliorare l’adattamento!**\n\nNel caso specifico, poiché il modello attuale non presenta problemi di adattamento, si può proseguire con la valutazione dei carichi fattoriali.\n\n### Esaminare i Carichi Fattoriali\n\nI carichi fattoriali standardizzati possono essere visualizzati con il seguente comando:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninspect(object = CFA, what = \"std\")$lambda\n#>        TSC    TE    EE    DE   RPA\n#> TSC1 0.657 0.000 0.000 0.000 0.000\n#> TSC2 0.692 0.000 0.000 0.000 0.000\n#> TSC3 0.628 0.000 0.000 0.000 0.000\n#> TSC5 0.726 0.000 0.000 0.000 0.000\n#> TE1  0.000 0.789 0.000 0.000 0.000\n#> TE2  0.000 0.745 0.000 0.000 0.000\n#> TE3  0.000 0.788 0.000 0.000 0.000\n#> TE5  0.000 0.649 0.000 0.000 0.000\n#> EE1  0.000 0.000 0.739 0.000 0.000\n#> EE2  0.000 0.000 0.802 0.000 0.000\n#> EE3  0.000 0.000 0.786 0.000 0.000\n#> EE4  0.000 0.000 0.760 0.000 0.000\n#> DE1  0.000 0.000 0.000 0.665 0.000\n#> DE2  0.000 0.000 0.000 0.640 0.000\n#> DE3  0.000 0.000 0.000 0.738 0.000\n#> RPA1 0.000 0.000 0.000 0.000 0.849\n#> RPA2 0.000 0.000 0.000 0.000 0.854\n#> RPA3 0.000 0.000 0.000 0.000 0.788\n#> RPA4 0.000 0.000 0.000 0.000 0.587\n```\n:::\n\n\n\n\nQuesti valori indicano la forza delle relazioni tra variabili osservate e fattori latenti. Carichi superiori a 0.3 (in valore assoluto) sono generalmente considerati rilevanti.\n\nIn sintesi, in questo passaggio, è stato costruito e valutato un modello CFA basato su teoria e risultati dell’EFA. Il modello presenta un buon adattamento sia globale sia locale, supportando la sua validità per rappresentare i dati. Il prossimo passo sarà interpretare e utilizzare i risultati del modello per ulteriori analisi o decisioni teoriche.\n\n## Passo 3: Valutare la Generalizzabilità\n\nL’ultimo passo consiste nel valutare la **generalizzabilità** del modello CFA definito nel Passo 2, adattandolo al campione di riserva. Questo consente di verificare se il modello è applicabile a dati indipendenti, aumentando la fiducia nella sua capacità di rappresentare in modo affidabile la struttura sottostante del costrutto in studi futuri e in campioni diversi.\n\n### Applicazione del Modello al Campione di Riserva\n\nIl modello viene applicato al campione di riserva utilizzando lo stesso codice del Passo 2, ma specificando il dataset di riserva nell’argomento `data`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCFA_holdout <- cfa(\n    model = CFA_model, \n    data = holdout[, var_names],\n    estimator = \"MLR\", \n    std.lv = TRUE, \n    meanstructure = TRUE\n)\n```\n:::\n\n\n\n\nCome nel Passo 2, le misure di adattamento globale possono essere calcolate con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglobalFit(CFA_holdout)\n#> Results------------------------------------------------------------------------ \n#>  \n#> Chi-Square (142) = 340 with p-value\n#>           = 0\n#> \n#> CFI = 0.943\n#> \n#> RMSEA = 0.0564; lower bound = 0.049;\n#>       upper bound = 0.0638\n#> \n#> SRMR = 0.0416\n#> \n#> Interpretations--------------------------------------------------------------- \n#>  \n#> The hypothesis of perfect fit *is* rejected according to the Chi-\n#>           Square test statistics because the p-value is smaller than 0.05 \n#>  \n#> The hypothesis of approximate model fit *is not* rejected according\n#>           to the CFI because the value is larger than 0.9. \n#>  \n#> The hypothesis of approximate model fit *is* rejected according\n#>          to the RMSEA because the point estimate is larger or equal to\n#>          0.05. \n#>  \n#> The hypothesis of approximate model fit *is not* rejected according\n#>          to the SRMR because the value is smaller than 0.08. \n#> \n```\n:::\n\n\n\n\nDall’output, emerge che:  \n\n- Il **test Chi-quadro** rifiuta l’adattamento perfetto (un risultato atteso con campioni ampi).  \n- Le misure di adattamento approssimativo, come **CFI** e **SRMR**, confermano un buon adattamento anche nel campione di riserva.  \n- Le stime del **RMSEA** rientrano nei valori accettabili, indicando che il modello si adatta sufficientemente bene ai dati di riserva.\n\nQuesti risultati sono comparabili a quelli ottenuti con il campione di costruzione, suggerendo che il modello presenta una generalizzabilità adeguata.\n\nPer verificare l’adattamento locale, utilizziamo il comando seguente, come fatto nel Passo 2:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlocalFit(CFA_holdout) \n#> $local_misfit\n#>       TSC1  TSC2  TSC3  TSC5   TE1   TE2   TE3   TE5   EE1   EE2   EE3\n#> TSC1 0.000                                                            \n#> TSC2 0.010 0.000                                                      \n#> TSC3 0.012 0.015 0.000                                                \n#> TSC5 0.007 0.007 0.005 0.000                                          \n#> TE1  0.023 0.023 0.003 0.014 0.000                                    \n#> TE2  0.027 0.012 0.019 0.008 0.008 0.000                              \n#> TE3  0.012 0.010 0.024 0.008 0.012 0.002 0.000                        \n#> TE5  0.019 0.014 0.008 0.002 0.046 0.006 0.013 0.000                  \n#> EE1  0.037 0.023 0.009 0.005 0.035 0.009 0.002 0.011 0.000            \n#> EE2  0.028 0.003 0.003 0.019 0.038 0.016 0.069 0.008 0.033 0.000      \n#> EE3  0.032 0.047 0.012 0.017 0.024 0.017 0.004 0.071 0.026 0.019 0.000\n#> EE4  0.006 0.033 0.003 0.002 0.027 0.002 0.002 0.048 0.015 0.020 0.004\n#> DE1  0.056 0.005 0.007 0.007 0.005 0.020 0.003 0.032 0.037 0.072 0.020\n#> DE2  0.005 0.029 0.032 0.061 0.012 0.014 0.046 0.006 0.024 0.038 0.034\n#> DE3  0.012 0.019 0.022 0.002 0.034 0.016 0.014 0.005 0.057 0.032 0.050\n#> RPA1 0.019 0.009 0.012 0.028 0.018 0.001 0.003 0.004 0.030 0.031 0.037\n#> RPA2 0.009 0.020 0.023 0.001 0.017 0.016 0.018 0.004 0.003 0.045 0.008\n#> RPA3 0.000 0.007 0.004 0.009 0.000 0.006 0.000 0.028 0.011 0.021 0.025\n#> RPA4 0.018 0.015 0.006 0.014 0.021 0.019 0.040 0.036 0.049 0.023 0.046\n#>        EE4   DE1   DE2   DE3  RPA1  RPA2  RPA3  RPA4\n#> TSC1                                                \n#> TSC2                                                \n#> TSC3                                                \n#> TSC5                                                \n#> TE1                                                 \n#> TE2                                                 \n#> TE3                                                 \n#> TE5                                                 \n#> EE1                                                 \n#> EE2                                                 \n#> EE3                                                 \n#> EE4  0.000                                          \n#> DE1  0.036 0.000                                    \n#> DE2  0.018 0.020 0.000                              \n#> DE3  0.020 0.019 0.006 0.000                        \n#> RPA1 0.003 0.014 0.029 0.004 0.000                  \n#> RPA2 0.051 0.006 0.010 0.005 0.020 0.000            \n#> RPA3 0.002 0.030 0.006 0.026 0.016 0.017 0.000      \n#> RPA4 0.023 0.008 0.028 0.046 0.057 0.005 0.093 0.000\n#> \n#> $max_misfit\n#> [1] 0.0931\n```\n:::\n\n\n\n\nL’analisi mostra che la **differenza massima** tra la matrice di covarianza campionaria e quella del modello è pari a **0,09**, un valore contenuto rispetto alla scala delle variabili osservate. Questo suggerisce che l’adattamento locale è soddisfacente anche per il campione di riserva, in linea con quanto osservato nel campione di costruzione.\n\n### Confronto dei Carichi Fattoriali\n\nI carichi fattoriali del modello adattato al campione di riserva possono essere esaminati con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninspect(object = CFA_holdout, what = \"std\")$lambda \n#>        TSC    TE    EE    DE   RPA\n#> TSC1 0.679 0.000 0.000 0.000 0.000\n#> TSC2 0.689 0.000 0.000 0.000 0.000\n#> TSC3 0.691 0.000 0.000 0.000 0.000\n#> TSC5 0.702 0.000 0.000 0.000 0.000\n#> TE1  0.000 0.694 0.000 0.000 0.000\n#> TE2  0.000 0.772 0.000 0.000 0.000\n#> TE3  0.000 0.819 0.000 0.000 0.000\n#> TE5  0.000 0.677 0.000 0.000 0.000\n#> EE1  0.000 0.000 0.749 0.000 0.000\n#> EE2  0.000 0.000 0.794 0.000 0.000\n#> EE3  0.000 0.000 0.781 0.000 0.000\n#> EE4  0.000 0.000 0.801 0.000 0.000\n#> DE1  0.000 0.000 0.000 0.677 0.000\n#> DE2  0.000 0.000 0.000 0.659 0.000\n#> DE3  0.000 0.000 0.000 0.766 0.000\n#> RPA1 0.000 0.000 0.000 0.000 0.851\n#> RPA2 0.000 0.000 0.000 0.000 0.867\n#> RPA3 0.000 0.000 0.000 0.000 0.700\n#> RPA4 0.000 0.000 0.000 0.000 0.618\n```\n:::\n\n\n\n\nI carichi fattoriali nel campione di riserva sono molto simili a quelli stimati nel campione di costruzione, confermando la stabilità della struttura fattoriale. Le differenze tra i due dataset sono trascurabili, supportando ulteriormente la generalizzabilità del modello.\n\nIn conclusione, il modello CFA si adatta bene sia al campione di costruzione sia a quello di riserva, con risultati simili in termini di misure di adattamento globale e locale, oltre che di carichi fattoriali. Questo supporta la conclusione che il modello ha una buona generalizzabilità e rappresenta in modo affidabile la struttura sottostante del costrutto analizzato.\n\nTuttavia, se il modello non si fosse adattato adeguatamente al campione di riserva (ad esempio, con misure di adattamento insufficienti o carichi fattoriali significativamente diversi), sarebbe stato necessario rivedere la struttura fattoriale. In tal caso:  \n\n1. Si dovrebbero identificare le aree problematiche, come indicato dall’analisi dell’adattamento locale.  \n2. Eventuali modifiche al modello dovrebbero essere teoricamente giustificate.\n3. Una nuova raccolta di dati sarebbe necessaria per ripetere i tre passaggi, suddividendo i dati in un nuovo campione di costruzione e uno di riserva.\n\n### Nota Pratica\n\nQuesto esempio dimostra l’importanza di suddividere i dati per testare la generalizzabilità. Tuttavia, nella pratica, raccogliere nuovi dati può essere complesso. Pertanto, è fondamentale progettare lo studio con un campione sufficientemente grande da consentire una suddivisione adeguata fin dall’inizio.\n\n## Riflessioni conclusive\n\nL’**analisi fattoriale** rappresenta uno strumento cruciale per lo studio e la comprensione di costrutti non direttamente osservabili, offrendo una metodologia rigorosa per identificare e validare strutture latenti nei dati. Questo approccio è particolarmente utile in campi come la psicologia, le scienze sociali, e molte altre discipline in cui i fenomeni di interesse non possono essere misurati direttamente, ma devono essere dedotti attraverso indicatori osservabili.\n\nLa versatilità dell’analisi fattoriale risiede nella sua capacità di sintetizzare informazioni complesse e di ridurre grandi insiemi di variabili a un numero limitato di fattori interpretabili. Questa caratteristica la rende particolarmente adatta per:\n\n- **Costruzione di strumenti di misura**: Identificare e validare le dimensioni sottostanti a questionari e scale psicometriche.\n- **Validazione teorica**: Verificare l’esistenza di costrutti teorici definiti o esplorarne di nuovi.\n- **Comparazione tra gruppi**: Esaminare se i costrutti latenti si manifestano allo stesso modo in diverse popolazioni o contesti.\n\nL’analisi fattoriale si estende oltre la semplice identificazione di fattori, includendo applicazioni avanzate come l’**analisi fattoriale multigruppo**, che consente di confrontare modelli in sottogruppi della popolazione, verificando l’invarianza di misura. Questo aspetto, fondamentale per garantire la comparabilità delle misurazioni, sarà discusso nel dettaglio nel capitolo successivo.\n\nNonostante i suoi punti di forza, l’analisi fattoriale presenta alcune sfide che richiedono attenzione:\n\n1. **Scelta del metodo appropriato**: Decidere tra EFA e CFA dipende dal livello di conoscenza teorica del costrutto.\n2. **Adeguatezza dei dati**: La qualità dell’analisi dipende dalla dimensione del campione, dalla normalità dei dati e dalla presenza di correlazioni sufficienti tra le variabili.\n3. **Interpretazione dei fattori**: Sebbene i carichi fattoriali forniscano indicazioni sulla struttura latente, l’interpretazione richiede una solida base teorica e non deve essere puramente data-driven.\n4. **Validazione incrociata**: È essenziale testare la generalizzabilità del modello su campioni indipendenti per evitare di sovradattare il modello ai dati specifici.\n\nQuesto capitolo ha introdotto i concetti fondamentali dell’analisi fattoriale con l’obiettivo di stimolare interesse e fornire le basi per un’applicazione autonoma. Tuttavia, per sfruttare appieno il potenziale di questa metodologia, si suggerisce di approfondire:\n\n- **Metodi avanzati di rotazione**: Come la rotazione obliqua o l’approccio procrustes per l’allineamento delle soluzioni.\n- **Analisi fattoriale esplorativa a livello bayesiano**: Un’alternativa moderna che incorpora incertezze nei modelli.\n- **Modelli di equazioni strutturali**: L’analisi fattoriale rappresenta il nucleo di questi modelli più complessi, che permettono di integrare relazioni causali tra fattori.\n\nIn conclusione, l’analisi fattoriale non si limita a essere un semplice metodo statistico, ma rappresenta un collegamento fondamentale tra la teoria e i dati, indispensabile per comprendere e validare costrutti complessi. Questo capitolo, pur introducendo solo i concetti di base, offre una solida piattaforma per approfondire le numerose applicazioni e potenzialità del metodo. \n\nUn tema cruciale, che sarà approfondito in un capitolo successivo, riguarda l’**analisi fattoriale multigruppo**. Questo approccio consente di esaminare l’**invarianza di misura**, un requisito essenziale per garantire che gli strumenti di misura siano equi e validi in contesti e gruppi diversi. Tale analisi sarà trattata in seguito all’interno del più ampio framework dei modelli di equazioni strutturali (SEM).\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] devtools_2.4.5    usethis_3.1.0     effectsize_1.0.0  ggokabeito_0.1.0 \n#>  [5] see_0.9.0         MASS_7.3-64       viridis_0.6.5     viridisLite_0.4.2\n#>  [9] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#> [13] bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-19    \n#> [17] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#> [21] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#> [25] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#> [29] ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2       later_1.4.1         cellranger_1.1.0   \n#>   [4] R.oo_1.27.0         datawizard_1.0.0    XML_3.99-0.18      \n#>   [7] rpart_4.1.24        lifecycle_1.0.4     Rdpack_2.6.2       \n#>  [10] rstatix_0.7.2       rprojroot_2.0.4     lattice_0.22-6     \n#>  [13] insight_1.0.1       rockchalk_1.8.157   backports_1.5.0    \n#>  [16] magrittr_2.0.3      openxlsx_4.2.8      Hmisc_5.2-2        \n#>  [19] rmarkdown_2.29      remotes_2.5.0       httpuv_1.6.15      \n#>  [22] qgraph_1.9.8        zip_2.3.1           sessioninfo_1.2.2  \n#>  [25] pkgbuild_1.4.6      pbapply_1.7-2       minqa_1.2.8        \n#>  [28] multcomp_1.4-26     abind_1.4-8         pkgload_1.4.0      \n#>  [31] quadprog_1.5-8      R.utils_2.12.3      nnet_7.3-20        \n#>  [34] TH.data_1.1-3       sandwich_3.1-1      arm_1.14-4         \n#>  [37] codetools_0.2-20    tidyselect_1.2.1    farver_2.1.2       \n#>  [40] lme4_1.1-36         stats4_4.4.2        base64enc_0.1-3    \n#>  [43] jsonlite_1.8.9      ellipsis_0.3.2      Formula_1.2-5      \n#>  [46] survival_3.8-3      emmeans_1.10.6      tools_4.4.2        \n#>  [49] rio_1.2.3           Rcpp_1.0.14         glue_1.8.0         \n#>  [52] mnormt_2.1.1        xfun_0.50           numDeriv_2016.8-1.1\n#>  [55] withr_3.0.2         fastmap_1.2.0       boot_1.3-31        \n#>  [58] digest_0.6.37       mi_1.1              timechange_0.3.0   \n#>  [61] R6_2.5.1            mime_0.12           estimability_1.5.1 \n#>  [64] colorspace_2.1-1    gtools_3.9.5        jpeg_0.1-10        \n#>  [67] R.methodsS3_1.8.2   generics_0.1.3      data.table_1.16.4  \n#>  [70] corpcor_1.6.10      htmlwidgets_1.6.4   parameters_0.24.1  \n#>  [73] pkgconfig_2.0.3     sem_3.1-16          gtable_0.3.6       \n#>  [76] htmltools_0.5.8.1   carData_3.0-5       profvis_0.4.0      \n#>  [79] png_0.1-8           reformulas_0.4.0    rstudioapi_0.17.1  \n#>  [82] tzdb_0.4.0          reshape2_1.4.4      curl_6.2.0         \n#>  [85] coda_0.19-4.1       checkmate_2.3.2     nlme_3.1-167       \n#>  [88] nloptr_2.1.1        zoo_1.8-12          cachem_1.1.0       \n#>  [91] parallel_4.4.2      miniUI_0.1.1.1      foreign_0.8-88     \n#>  [94] pillar_1.10.1       grid_4.4.2          vctrs_0.6.5        \n#>  [97] urlchecker_1.0.1    promises_1.3.2      car_3.1-3          \n#> [100] OpenMx_2.21.13      xtable_1.8-4        cluster_2.1.8      \n#> [103] htmlTable_2.4.3     evaluate_1.0.3      pbivnorm_0.6.0     \n#> [106] mvtnorm_1.3-3       cli_3.6.3           kutils_1.73        \n#> [109] compiler_4.4.2      rlang_1.1.5         ggsignif_0.6.4     \n#> [112] labeling_0.4.3      fdrtool_1.2.18      plyr_1.8.9         \n#> [115] fs_1.6.5            stringi_1.8.4       munsell_0.5.1      \n#> [118] lisrelToR_0.3       bayestestR_0.15.0   pacman_0.5.1       \n#> [121] Matrix_1.7-2        hms_1.1.3           glasso_1.11        \n#> [124] shiny_1.10.0        rbibutils_2.3       igraph_2.1.4       \n#> [127] broom_1.0.7         memoise_2.0.1       RcppParallel_5.1.10\n#> [130] readxl_1.4.3\n```\n:::\n",
    "supporting": [
      "07_fa_in_r_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
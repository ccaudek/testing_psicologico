{
  "hash": "9b14f4881972a13fd11975e0fb681404",
  "result": {
    "engine": "knitr",
    "markdown": "# Metodi di stima dell'affidabilità {#sec-ctt-methods-reliability}\n\n**Preparazione del Notebook**\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> source()\npacman::p_load(modelsummary, ltm)\n```\n:::\n\n\n\n\n\n## Introduzione\n\nI punteggi ottenuti da test psicologici possono variare per differenze tra item, occasioni di somministrazione o modalità di valutazione. La CTT affronta questo problema introducendo il concetto di affidabilità, intesa come stabilità e coerenza delle misure ottenute, distinguendo tra \"punteggio vero\" e \"errore di misurazione\".\n\nNel capitolo precedente abbiamo visto che l'affidabilità riflette la proporzione della varianza dovuta al punteggio vero rispetto alla varianza totale. Il problema successivo è stimare accuratamente l'affidabilità, considerando diverse modalità di errore.\n\n## Come stimare l'affidabilità\n\nPer stimare l'affidabilità ($\\rho$), dobbiamo affrontare la difficoltà legata all'impossibilità di osservare direttamente il punteggio vero o l'errore di misurazione. La strategia di stima dipende da come definiamo e interpretiamo l'errore di misurazione (σ²ₑ):\n  \n1. **Affidabilità delle Forme Parallele**:\n  - Considera l’errore come differenza tra punteggi ottenuti da forme equivalenti del test.\n\n2. **Consistenza Interna**:\n  - Valuta quanto gli item all’interno dello stesso test siano omogenei rispetto al costrutto misurato (es. Alpha di Cronbach).\n\n3. **Affidabilità Test-Retest (Coerenza Temporale)**:\n  - Misura l’errore come variazione dei punteggi nel tempo, attraverso somministrazioni ripetute dello stesso test.\n\nLa principale differenza tra questi metodi è nella definizione operativa e nel calcolo della varianza d’errore ($\\sigma^2_e$).\n\n\n## Affidabilità come Consistenza Interna\n  \n  La consistenza interna valuta l’omogeneità tra item. Esistono tre principali modelli teorici relativi alle relazioni tra item:\n  \n- **Item paralleli**: medie e varianze uguali, correlazione pari all’affidabilità.\n- **Item τ-equivalenti**: medie e varianze diverse, correlazione diversa dall’affidabilità.\n- **Item congenerici**: rapporti più complessi tra medie, varianze e correlazioni; la correlazione non equivale all'affidabilità.\n\nLa CTT propone due indici principali per misurare la consistenza interna:\n\n### Coefficiente Alpha di Cronbach\n\nIl coefficiente Alpha è adatto per item τ-equivalenti:\n\n$$ \\alpha = \\frac{k}{k-1} \\left(1 - \\frac{\\sum \\sigma_i^2}{\\sigma_X^2}\\right) $$\n\ndove:\n\n- $k$ è il numero di item,\n- $\\sigma_i^2$ è la varianza dell'item i,\n- $\\sigma_X^2$ è la varianza totale del test.\n\nUna derivazione della formula del coefficiente alpha di Cronbach è fornita nel capitolo @reliability-fa-notebook.\n\nL’Alpha di Cronbach fornisce una stima conservativa (limite inferiore) dell'affidabilità solo quando le assunzioni del modello τ-equivalente sono rispettate. In caso contrario, può sovrastimare l'affidabilità.\n\n::: {#exm-}\nPer illustrare la procedura di calcolo del coefficiente $\\alpha$, useremo i dati `bfi` contenuti nel pacchetto `psych`. Il dataframe `bfi` comprende 25 item di autovalutazione della personalità. Sono riportati i dati di 2800 soggetti. Ci concentreremo qui sulla sottoscala *Openness*:\n\n- O1: *Am full of ideas*; \n- O2: *Avoid difficult reading material*; \n- O3: *Carry the conversation to a higher level*; \n- O4: *Spend time reflecting on things*; \n- O5: *Will not probe deeply into a subject*. \n\nLeggiamo i dati in R.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(bfi, package = \"psych\")\nhead(bfi[c(\"O1\", \"O2\", \"O3\", \"O4\", \"O5\")])\n#>       O1 O2 O3 O4 O5\n#> 61617  3  6  3  4  3\n#> 61618  4  2  4  3  3\n#> 61620  4  2  5  5  2\n#> 61621  3  3  4  3  5\n#> 61622  3  3  4  3  3\n#> 61623  4  3  5  6  1\n```\n:::\n\n\n\n\n\nEsaminiamo la correlazione tra gli item della sottoscale Openness.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor(bfi[c(\"O1\", \"O2\", \"O3\", \"O4\", \"O5\")], use = \"pairwise.complete.obs\") |>\n    round(2)\n#>       O1    O2    O3    O4    O5\n#> O1  1.00 -0.21  0.40  0.18 -0.24\n#> O2 -0.21  1.00 -0.26 -0.07  0.32\n#> O3  0.40 -0.26  1.00  0.19 -0.31\n#> O4  0.18 -0.07  0.19  1.00 -0.18\n#> O5 -0.24  0.32 -0.31 -0.18  1.00\n```\n:::\n\n\n\n\n\nÈ necessario ricodificare due item.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbfi$O2r <- 7 - bfi$O2\nbfi$O5r <- 7 - bfi$O5\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\") |>\n    round(2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.00 0.21 0.40 0.18 0.24\n#> O2r 0.21 1.00 0.26 0.07 0.32\n#> O3  0.40 0.26 1.00 0.19 0.31\n#> O4  0.18 0.07 0.19 1.00 0.18\n#> O5r 0.24 0.32 0.31 0.18 1.00\n```\n:::\n\n\n\n\n\nConsideriamo la matrice di varianze e covarianze della sottoscala Openness. \n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nC <- cov(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nC |> round(2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.28 0.38 0.54 0.25 0.36\n#> O2r 0.38 2.45 0.50 0.13 0.67\n#> O3  0.54 0.50 1.49 0.29 0.50\n#> O4  0.25 0.13 0.29 1.49 0.29\n#> O5r 0.36 0.67 0.50 0.29 1.76\n```\n:::\n\n\n\n\n\nCalcoliamo alpha:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- 5\nalpha <- (p / (p - 1)) * (1 - tr(C) / sum(C))\nalpha\n#> [1] 0.6\n```\n:::\n\n\n\n\n\nLo stesso risultato si ottiene utilizzando la funzione `alpha()`\ncontenuta nel pacchetto `psych`:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npsych::alpha(C)\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = C)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N median_r\n#>        0.6      0.61    0.57      0.24 1.5     0.23\n#> \n#>     95% confidence boundaries \n#>       lower alpha upper\n#> Feldt -0.49   0.6  0.95\n#> \n#>  Reliability if an item is dropped:\n#>     raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\n#> O1       0.53      0.53    0.48      0.22 1.1 0.0092  0.23\n#> O2r      0.57      0.57    0.51      0.25 1.3 0.0076  0.22\n#> O3       0.50      0.50    0.44      0.20 1.0 0.0071  0.20\n#> O4       0.61      0.62    0.56      0.29 1.6 0.0044  0.29\n#> O5r      0.51      0.53    0.47      0.22 1.1 0.0115  0.20\n#> \n#>  Item statistics \n#>        r r.cor r.drop\n#> O1  0.65  0.52   0.39\n#> O2r 0.60  0.43   0.33\n#> O3  0.69  0.59   0.45\n#> O4  0.52  0.29   0.22\n#> O5r 0.66  0.52   0.42\n```\n:::\n\n\n\n\n:::\n\n### Coefficiente KR-20\n\nLa formula di Kuder-Richardson-20 (KR-20) è un caso particolare del coefficiente α. Se ogni item è dicotomico, il coefficiente α diventa il KR-20. Il coefficiente Coefficiente KR-20 si calcola con la formula:\n\n$$\nKR\\_20 = \\frac{{k}}{{k-1}} \\left( 1 - \\frac{{p(1-p)}}{{\\sigma_{X}^{2}}} \\right) \n$$\n\ndove:\n\n- $k$ è il numero di item nel test,\n- $p$ è la proporzione di individui che rispondono correttamente all'item,\n- $\\sigma_{X}^{2}$ è la varianza totale dei punteggi del test.\n\n::: {#exm-}\nConsideriamo il data-set `LSAT` contenuto nel pacchetto `ltm`.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nKR20 <- function(responses) {\n    # Get number of items (N) and individuals\n    n.items <- ncol(responses)\n    n.persons <- nrow(responses)\n    # get p_j for each item\n    p <- colMeans(responses)\n    # Get total scores (X)\n    x <- rowSums(responses)\n    # observed score variance\n    var.x <- var(x) * (n.persons - 1) / n.persons\n    # Apply KR-20 formula\n    rel <- (n.items / (n.items - 1)) * (1 - sum(p * (1 - p)) / var.x)\n    return(rel)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(LSAT)\nhead(LSAT)\n#>   Item 1 Item 2 Item 3 Item 4 Item 5\n#> 1      0      0      0      0      0\n#> 2      0      0      0      0      0\n#> 3      0      0      0      0      0\n#> 4      0      0      0      0      1\n#> 5      0      0      0      0      1\n#> 6      0      0      0      0      1\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nKR20(LSAT)\n#> [1] 0.295\n```\n:::\n\n\n\n\n:::\n\n#### Coefficiente KR-21\n\nIl coefficiente Coefficiente KR-21 si calcola con la formula:\n\n$$\nKR\\_21 = \\frac{{k}}{{k-1}} \\left( 1 - \\frac{{\\frac{{\\sum_{i=1}^{k} p_{i}(1-p_{i})}}{{\\sigma_{X}^{2}}}}}{{1 - \\frac{{\\sum_{i=1}^{k} p_{i}}}{k}}} \\right) \n$$\n\ndove:\n\n- $k$ è il numero di item nel test,\n- $p_{i}$ è la proporzione di individui che rispondono correttamente all'item $i$,\n- $\\sigma_{X}^{2}$ è la varianza totale dei punteggi del test.\n\n### Formula di Spearman-Brown\n\nLa formula di Spearman-Brown stima l'affidabilità nel caso di item paralleli:\n\n$$ \\rho_p = \\frac{p \\rho_1}{(p-1)\\rho_1 + 1} $$\n\ndove $\\rho_1$ è l'affidabilità media di un singolo item, e $p$ è il numero di item.\n\n::: {#exm-}\nPoniamoci il problema di calcolare l'attendibilità della sottoscala Openness utilizzando la formula di Spearman-Brown. Ipotizziamo dunque che gli item della scala Openness siano paralleli. La matrice di correlazione è:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nR <- cor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nR |> round(2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.00 0.21 0.40 0.18 0.24\n#> O2r 0.21 1.00 0.26 0.07 0.32\n#> O3  0.40 0.26 1.00 0.19 0.31\n#> O4  0.18 0.07 0.19 1.00 0.18\n#> O5r 0.24 0.32 0.31 0.18 1.00\n```\n:::\n\n\n\n\n\nSupponiamo di calcolare l'attendibilità di un singolo item ($\\rho_1$) come la correlazione media tra gli item:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr <- NULL\np <- 5\nk <- 1\nfor (i in 1:p) {\n    for (j in 1:p) {\n        if (j != i) {\n            rr[k] <- R[i, j]\n        }\n        k <- k + 1\n    }\n}\nro_1 <- mean(rr, na.rm = TRUE)\nro_1\n#> [1] 0.237\n```\n:::\n\n\n\n\n\nApplicando la formula di Spearman-Brown, la stima dell'attendibilità del\ntest diventa pari a\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(p * ro_1) / ((p - 1) * ro_1 + 1)\n#> [1] 0.608\n```\n:::\n\n\n\n\n:::\n\n## Affidabilità delle Forme Alternative\n  \n  Si riferisce alla coerenza tra punteggi ottenuti da versioni diverse ma equivalenti del test. Le forme alternative sono utilizzate per evitare effetti di pratica e memoria. Tuttavia, è fondamentale garantire che le forme siano realmente equivalenti per contenuto e difficoltà. L’affidabilità delle forme alternative viene valutata attraverso la correlazione tra le versioni.\n\n\n## Affidabilità Test-Retest\n  \nMisura la stabilità dei punteggi ottenuti dallo stesso test in momenti diversi. Questo approccio è utile per costrutti considerati stabili nel tempo (ad es. intelligenza, personalità). Non è appropriato per costrutti instabili o soggetti a cambiamenti frequenti.\n\n\n## Affidabilità dei Punteggi Compositi\n  \nSi riferisce alla stabilità di punteggi derivati dalla combinazione di più sottoscale o item. In generale, i punteggi compositi hanno un'affidabilità superiore ai punteggi singoli, poiché l’errore specifico di ciascuna misura viene mitigato dalla combinazione con altri punteggi correlati.\n\n::: {#exm-}\nPer esempio, dati due subtest con una varianza del vero punteggio di 25 ciascuno e una covarianza di 15 (dovuta al vero punteggio), la varianza del vero punteggio nel composito è data da:\n\n$$ \\text{Var}(Z_{vero}) = 25 + 25 + 2 \\cdot 15 = 80 $$\n\nLa varianza totale nel composito, tenendo conto anche della varianza dell'errore di misura, sarà:\n\n$$ \\text{Var}(Z_{totale}) = 35 + 35 + 2 \\cdot 15 = 100 $$\n\nIl rapporto tra la varianza del vero punteggio e la varianza totale nel composito è:\n\n$$ \\text{Rapporto} = \\frac{\\text{Var}(Z_{vero})}{\\text{Var}(Z_{totale})} = \\frac{80}{100} = 0.8 $$\n\n**Confronto con un Singolo Subtest.**\n\nLa varianza del vero punteggio in un singolo subtest è data (come da ipotesi) da 25.\n\nLa varianza totale in un singolo subtest è la somma della varianza del vero punteggio e quella dell'errore di misura, quindi 35 (25 di vero punteggio + 10 di errore).\n\nIl rapporto tra la varianza del vero punteggio e la varianza totale in un singolo subtest è:\n\n$$ \\text{Rapporto} = \\frac{\\text{Var}(X_{vero})}{\\text{Var}(X_{totale})} = \\frac{25}{35} \\approx 0.714 $$\n\nIl confronto mostra che l'affidabilità del punteggio composito (0.8) è maggiore di quella di un singolo subtest (circa 0.714). Questo esemplifica come la correlazione positiva tra i subtest possa effettivamente aumentare l'affidabilità del punteggio composito rispetto ai subtest individuali.\n\nQuindi, il vantaggio di combinare i punteggi dai subtest in un punteggio composito emerge principalmente quando i subtest sono in qualche modo correlati e/o quando la varianza dell'errore di misura è ridotta rispetto alla varianza del vero punteggio. In pratica, l'uso di punteggi compositi è spesso giustificato dall'idea che essi forniscono una misura più completa e rappresentativa del costrutto di interesse, riducendo l'impatto dell'errore di misura specifico di ciascun subtest.\n:::\n\n\n## Affidabilità dei Punteggi Differenza\n\nSi applica quando si analizzano differenze tra due punteggi, ad esempio per valutare l'efficacia di un trattamento (punteggi pre-post). Generalmente, l'affidabilità dei punteggi differenza è minore rispetto a quella delle singole misure, soprattutto quando queste ultime sono altamente correlate. La formula è:\n\n$$ r_{dd} = \\frac{0.5 (r_{xx} + r_{yy}) - r_{xy}}{1 - r_{xy}} $$\n\ndove:\n\n- $r_{xx}$ e $r_{yy}$ sono le affidabilità delle due misure,\n- $r_{xy}$ è la correlazione tra le due misure.\n\n::: {#exm-}\nFacciamo un esempio numerico varianza la correlazione tra le due componenti.\n\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nrdd <- function(rxx, ryy, rxy) {\n    (0.5 * (rxx + ryy) - rxy) / (1 - rxy)\n}\n\nseq(0.01, 0.81, by = 0.1)\n#> [1] 0.01 0.11 0.21 0.31 0.41 0.51 0.61 0.71 0.81\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nrxx <- 0.9\nryy <- 0.8\n\nrdd(rxx, ryy, seq(0.01, 0.81, by = 0.1))\n#> [1] 0.848 0.831 0.810 0.783 0.746 0.694 0.615 0.483 0.211\n```\n:::\n\n\n\n\n\nSi vede che, all'aumentare di $r_{xy}$, l'affidabilità del punteggio differenza diminuisce.\n:::\n\n## Scelta del Coefficiente di Affidabilità\n\nLa scelta del coefficiente appropriato dipende da vari fattori:\n\n- **Affidabilità Test-Retest**: per misurare stabilità nel tempo.\n- **Consistenza Interna** (Alpha, KR-20): per test con una sola somministrazione, ideali quando il test misura un singolo costrutto omogeneo.\n- **Affidabilità Forme Alternative**: per test con versioni diverse.\n- **Affidabilità Inter-Valutatori**: per giudizi soggettivi, valuta accordo tra valutatori.\n\n### Linee Guida Generali\n\n- Decisioni importanti (diagnosi): ≥ 0.90\n- Test di rendimento/personalità: ≥ 0.80\n- Screening didattici: ≥ 0.70\n- Ricerca di gruppo: ≥ 0.60 (con cautela sotto 0.70)\n\n\n## Riflessioni Conclusive\n\nLa valutazione dell’affidabilità richiede l’applicazione accurata di metodi che rispecchino il contesto d’uso, tenendo conto delle fonti di errore e del tipo di costrutto misurato. Una scelta informata dell’indice di affidabilità garantisce decisioni più precise e affidabili, migliorando la qualità complessiva delle misurazioni psicologiche.\n\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] ltm_1.2-0          polycor_0.8-1      msm_1.8.2         \n#>  [4] modelsummary_2.3.0 ggokabeito_0.1.0   see_0.10.0        \n#>  [7] MASS_7.3-65        viridis_0.6.5      viridisLite_0.4.2 \n#> [10] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#> [13] patchwork_1.3.0    bayesplot_1.11.1   semTools_0.5-6    \n#> [16] semPlot_1.1.6      lavaan_0.6-19      psych_2.4.12      \n#> [19] scales_1.3.0       markdown_1.13      knitr_1.49        \n#> [22] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1     \n#> [25] dplyr_1.1.4        purrr_1.0.4        readr_2.1.5       \n#> [28] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#> [31] tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.1      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          admisc_0.37        \n#>  [22] igraph_2.1.4        mime_0.12           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-2        R6_2.6.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] digest_0.6.37       OpenMx_2.21.13      fdrtool_1.2.18     \n#>  [34] colorspace_2.1-1    rprojroot_2.0.4     Hmisc_5.2-2        \n#>  [37] timechange_0.3.0    abind_1.4-8         compiler_4.4.2     \n#>  [40] withr_3.0.2         glasso_1.11         htmlTable_2.4.3    \n#>  [43] backports_1.5.0     carData_3.0-5       ggsignif_0.6.4     \n#>  [46] corpcor_1.6.10      gtools_3.9.5        tools_4.4.2        \n#>  [49] pbivnorm_0.6.0      foreign_0.8-88      zip_2.3.2          \n#>  [52] httpuv_1.6.15       nnet_7.3-20         glue_1.8.0         \n#>  [55] quadprog_1.5-8      nlme_3.1-167        promises_1.3.2     \n#>  [58] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [61] cluster_2.1.8       reshape2_1.4.4      generics_0.1.3     \n#>  [64] gtable_0.3.6        tzdb_0.4.0          data.table_1.17.0  \n#>  [67] hms_1.1.3           car_3.1-3           tables_0.9.31      \n#>  [70] sem_3.1-16          pillar_1.10.1       rockchalk_1.8.157  \n#>  [73] later_1.4.1         splines_4.4.2       lattice_0.22-6     \n#>  [76] survival_3.8-3      kutils_1.73         tidyselect_1.2.1   \n#>  [79] miniUI_0.1.1.1      pbapply_1.7-2       reformulas_0.4.0   \n#>  [82] stats4_4.4.2        xfun_0.51           expm_1.0-0         \n#>  [85] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [88] yaml_2.3.10         pacman_0.5.1        boot_1.3-31        \n#>  [91] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [94] cli_3.6.4           RcppParallel_5.1.10 rpart_4.1.24       \n#>  [97] xtable_1.8-4        Rdpack_2.6.2        munsell_0.5.1      \n#> [100] Rcpp_1.0.14         coda_0.19-4.1       png_0.1-8          \n#> [103] XML_3.99-0.18       parallel_4.4.2      jpeg_0.1-10        \n#> [106] lme4_1.1-36         mvtnorm_1.3-3       openxlsx_4.2.8     \n#> [109] rlang_1.1.5         multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "a46b143974b2d045917eb999ce901c81",
  "result": {
    "engine": "knitr",
    "markdown": "# Analisi dei percorsi {#sec-path-analysis-intro}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- Comprendere il ruolo delle visualizzazioni nell’analisi dei percorsi e la loro importanza per comunicare le relazioni tra variabili.\n- Identificare e distinguere le variabili esogene ed endogene in un path diagram.\n- Utilizzare i path diagram per rappresentare graficamente le relazioni dirette, indirette e totali tra le variabili.\n- Interpretare i parametri della path analysis.\n- Applicare le regole di Wright per decomporre correlazioni e covarianze in base ai percorsi causali.\n- Modellare le medie delle variabili in un’analisi dei percorsi, integrando le informazioni sulle medie nella struttura complessiva del modello.\n- Eseguire l'analisi dei percorsi con `lavaan`.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere *Path analysis in Mplus: A tutorial using a conceptual model of psychological and behavioral antecedents of bulimic symptoms in young adults* di @barbeau2019path.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, semPlot, tidyr)\n```\n:::\n\n\n\n:::\n\n\n## Introduzione\n\nLe visualizzazioni rivestono un ruolo fondamentale nel comunicare in modo chiaro e sintetico le relazioni tra variabili. Questo è particolarmente evidente quando si opera con modelli di equazioni strutturali (SEM) che delineano una rete di interconnessioni tra variabili sia osservabili che latenti. In tali contesti, i ricercatori frequentemente si avvalgono di strumenti grafici per agevolare la specificazione e l'esplicitazione del modello, oltre che per presentare in maniera comprensibile i risultati ottenuti.\n\nL'analisi del percorso, o *path analysis*, è una tecnica statistica multivariata utilizzata nell'ambito della ricerca quantitativa per esaminare e descrivere le relazioni causali tra un insieme di variabili. Questo metodo si avvale di modelli grafici, noti come diagrammi di percorso, che rappresentano le relazioni ipotizzate tra le variabili, illustrando graficamente le relazioni dirette, indirette e reciproche tra di esse.\n\nIl fulcro dell'analisi del percorso è la decomposizione e la quantificazione delle relazioni tra le variabili, permettendo agli analisti di distinguere tra effetti diretti, indiretti e totali. Gli effetti diretti corrispondono all'influenza immediata che una variabile esercita su un'altra, mentre gli effetti indiretti rappresentano l'impatto mediato attraverso una o più variabili intermedie. L'effetto totale è la somma degli effetti diretti e indiretti.\n\nSewall Wright, un genetista che operava presso il Dipartimento dell'Agricoltura degli Stati Uniti, fu il precursore nello sviluppo dei diagrammi di percorso per descrivere i modelli di equazioni strutturali già negli anni '20 del secolo scorso. Questa sua innovazione ha permesso di ottenere una rappresentazione visiva delle connessioni tra variabili, aprendo la strada all'analisi dei percorsi.\n\nCon il trascorrere del tempo, questa metodologia è stata adottata con successo come uno strumento efficace per discriminare gli effetti diretti da quelli indiretti nelle relazioni tra variabili. Inoltre, essa si è dimostrata di grande utilità nel valutare la solidità e la validità delle relazioni causali ipotizzate all'interno dei modelli di equazioni strutturali.\n\n## Path diagram\n\nNel *path diagram* è possibile distinguere due tipi di variabili: quelle che sono influenzate da altre variabili nel sistema e quelle che fungono da sorgenti di effetti. \n\n- **Variabili esogene**: rappresentano elementi esterni al sistema in esame. Esse agiscono come variabili indipendenti, generando effetti in modo causale senza essere influenzate da altre variabili presenti nel modello. Nel diagramma, le loro cause si trovano al di fuori del sistema rappresentato.\n\n- **Variabili endogene**: sono quelle che possono assumere il doppio ruolo di risultati (essendo influenzate da altre variabili) e di cause (influenzando ulteriori variabili). In alcuni casi, svolgono un ruolo esclusivamente dipendente. Le cause delle variabili endogene sono sempre incluse all’interno del path diagram.\n\nQuesta distinzione riflette quella tra variabili indipendenti e dipendenti nei modelli lineari, ma con una maggiore enfasi sulla natura causale e sulla posizione delle variabili nel sistema rappresentato.\n\nUn *path diagram* (diagramma di percorso) utilizza specifici simboli grafici per rappresentare le variabili e le loro relazioni:\n\n1. **Variabili osservate** (o indicatori): rappresentate con **quadrati** o **rettangoli**.\n2. **Variabili latenti** (come fattori comuni con più indicatori): rappresentate con **cerchi** o **ellissi**.\n\nIl *path diagram* evidenzia le interazioni tra le variabili di interesse, distinguendo i legami causali da quelli associativi:\n\n- **Frecce unidirezionali** ($\\rightarrow$): indicano relazioni causali. La variabile alla punta della freccia è influenzata da quella alla base.\n- **Frecce curve bidirezionali** ($\\leftrightarrow$): rappresentano relazioni associative, indicando covarianze (nella soluzione non standardizzata) o correlazioni (nella soluzione standardizzata), senza implicare una relazione causale diretta.\n\nL’assenza di una freccia tra due variabili implica che non vi è correlazione o relazione causale diretta tra esse nel modello. Il diagramma, quindi, sintetizza visivamente le ipotesi teoriche sulle relazioni tra le variabili.\n\nNella @fig-path-01, si illustrano le relazioni tra nove variabili osservate e tre variabili latenti mediante il path diagram. Una freccia curva bidirezionale che si collega a una singola variabile rappresenta la varianza residua della variabile, ovvero la quota di varianza non spiegata dalle relazioni causali illustrate nel diagramma di percorso. \n\n::: {#fig-path-01}\n![](../../figures/path_01.png){width=\"40%\"}\n\nDiagramma di percorso per un modello a tre fattori comuni.\n:::\n\nUn **triangolo** contenente il numero 1 simboleggia la media di una variabile (qui non presente).\n\n### Parametri nei Modelli di Equazioni Strutturali\n\nI parametri nei modelli di equazioni strutturali possono essere categorizzati come segue, quando le medie non sono oggetto di analisi:\n\n1. **Varianze e Covarianze delle Variabili Esogene:** \n   - Questi parametri rappresentano la variabilità intrinseca delle variabili esogene (quelle non influenzate da altre nel modello) e le relazioni reciproche tra di esse.\n\n2. **Effetti Diretti sulle Variabili Endogene da Altre Variabili:**\n   - Questi parametri descrivono come le variabili endogene sono influenzate direttamente da altre variabili nel modello.\n\nIn termini di specificazione, un parametro nel modello può essere classificato come libero, fisso o vincolato:\n\n- **Parametro Libero:** \n   - Questo tipo di parametro è stimato dal software statistico utilizzando i dati a disposizione.\n\n- **Parametro Fisso:** \n   - Un parametro fisso è definito per essere uguale a una costante specificata a priori. In questo caso, il software accetta il valore costante come stima, indipendentemente dai dati. Ad esempio, l'ipotesi che la variabile X non abbia effetti diretti su Y corrisponde alla specifica che il coefficiente per il percorso da X a Y sia fissato a zero.\n\n- **Parametro Vincolato:** \n   - In questo caso, il parametro segue certe restrizioni imposte nell'analisi, che possono essere basate su teorie o ipotesi precedenti. Ad esempio, l'analista può assumere che due parametri siano uguali.\n\n## Gradi di Libertà nei Modelli Parametrici\n\nIn statistica, la complessità di un modello parametrico è limitata dalla quantità di informazioni statistiche disponibili nei dati, ovvero il numero di varianze e covarianze uniche che possono essere derivate dalla matrice di covarianza campionaria. Questo numero non dipende dalla dimensione del campione ($N$), ma esclusivamente dal numero di variabili osservate ($v$).\n\n### Calcolo della Quantità di Informazioni\n\nLa quantità di informazioni statistiche in un modello è data dalla formula:\n\n$$\np = \\frac{v(v + 1)}{2},\n$$\n\ndove $v$ è il numero di variabili osservate. Questo conteggio include:\n\n- $v$: le varianze delle variabili osservate (i termini sulla diagonale della matrice di covarianza),\n- $\\frac{v(v - 1)}{2}$: le covarianze uniche tra coppie di variabili (i termini sotto la diagonale principale).\n\nAd esempio, se $v = 5$, la quantità di informazioni sarà:\n\n$$\np = \\frac{5 \\times 6}{2} = 15.\n$$\n\nIn questo caso, le 15 informazioni statistiche comprendono 5 varianze e 10 covarianze uniche. Quindi, un modello parametrico con 5 variabili osservate può stimare al massimo 15 parametri. Aggiungere più casi al campione non aumenta la quantità di informazioni, ma incrementare il numero di variabili osservate sì.\n\n### Gradi di Libertà del Modello\n\nI **gradi di libertà** del modello ($df_M$) rappresentano la differenza tra la quantità di informazioni disponibili ($p$) e il numero di parametri liberi ($q$) che il modello cerca di stimare:\n\n$$\ndf_M = p - q.\n$$\n\n- **Modello identificabile**: $df_M \\geq 0$. Il modello ha abbastanza informazioni per stimare i parametri in modo univoco.\n- **Modello non identificabile**: $df_M < 0$. Non ci sono sufficienti informazioni per stimare tutti i parametri, portando a infinite soluzioni possibili.\n\nSe $df_M < 0$, il modello deve essere modificato riducendo il numero di parametri liberi, ad esempio imponendo vincoli o fissando alcuni parametri a valori specifici. In caso contrario, i software di modellazione produrranno errori.\n\n### Interpretazione dei Gradi di Libertà\n\n1. **Modello con $df_M = 0$**: Si adatta perfettamente ai dati, ma questa perfetta aderenza è inevitabile e non garantisce che il modello sia generalizzabile o valido per altri campioni.\n\n2. **Modello con $df_M > 0$**: Consente un margine di discrepanza tra i dati osservati e le stime del modello. Modelli con più gradi di libertà sono più esposti al rischio di essere rifiutati, ma una loro validazione aumenta la fiducia nella loro generalizzabilità.\n\nRaykov e Marcoulides (2006) descrivono i gradi di libertà come \"dimensioni lungo cui un modello può essere rifiutato\". Un modello con più gradi di libertà che si adatta bene ai dati dimostra maggiore robustezza rispetto a un modello con pochi gradi di libertà.\n\n### Principio di Parsimonia\n\nNella scelta tra modelli, è preferibile optare per quello più semplice (con meno parametri liberi), a parità di adattamento ai dati, purché sia teoricamente plausibile. Questo principio di parsimonia è cruciale per evitare sovradattamento e garantire la generalizzabilità del modello.\n\n---\n\nIn sintesi, i gradi di libertà rappresentano un equilibrio tra la complessità del modello e le informazioni disponibili nei dati. La loro corretta interpretazione è essenziale per valutare l’identificabilità, la validità e la parsimonia di un modello parametrico.\n\n### Varianza Residua nelle Variabili Endogene\n\nLa @fig-kline_7_2 illustra la relazione tra due variabili osservabili e il modo in cui la varianza residua viene trattata nei modelli a percorsi. L'effetto totale di $X$ su $Y$ è rappresentato tramite un percorso diretto, che evidenzia l'effetto causale lineare di $X$ su $Y$. Nel diagramma:\n\n- La **varianza di $X$**, una variabile esogena, è un parametro libero e viene rappresentata da una freccia curva bidirezionale (secondo il simbolismo RAM), che indica una varianza.\n- La **varianza di $Y$**, una variabile endogena, non è libera, poiché include un termine di disturbo o errore ($D$), una variabile latente che rappresenta la porzione di varianza in $Y$ non spiegata da $X$.\n\n::: {#fig-kline_7_2}\n![](../../figures/kline_7_2.png){width=\"80%\"}\n\n**Diagramma di percorso**: (a) rappresentazione esplicita secondo il modello RAM; (b) versione semplificata. (Adattata da @kline2023principles).\n:::\n\nNel pannello **(a)**, il valore numerico \"1\" accanto al percorso tra il termine di disturbo ($D$) e $Y$ è una costante di scala. Questo valore fissa una metrica per il termine di disturbo, necessaria per stimare la varianza latente. Questo approccio è noto come vincolo di identificazione del carico unitario (*unit loading identification* constraint, ULI). Tale costante informa il software di suddividere la varianza totale di $Y$ in due componenti ortogonali:\n\n1. La varianza spiegata da $X$.\n2. La varianza residua, rappresentata dal termine di disturbo ($var_D$).\n\nNel pannello **(b)**, la stessa relazione è presentata in modo più sintetico. Qui, il termine di disturbo non è rappresentato esplicitamente, ma la varianza residua può essere descritta in modo equivalente con una freccia curva bidirezionale che denota $1 \\times var_D \\times 1$.\n\n### Rappresentazioni Alternative della Varianza Residua\n\nUn altro modo per rappresentare la varianza residua di $Y$ consiste nell’attribuire $1$ a $var_D$ e utilizzare il valore $\\sqrt{var_D}$ per la freccia causale da $D$ a $Y$. Il risultato finale resta invariato, poiché la varianza residua di $Y$ sarebbe comunque espressa come:\n\n$$\n\\sqrt{var_D} \\times 1 \\times \\sqrt{var_D}.\n$$\n\n### Fonti della Varianza Residua\n\nLa varianza residua ($var_D$) rappresenta la porzione di varianza in $Y$ non spiegata da $X$. Essa può derivare da diverse fonti, tra cui:\n\n1. **Variazione sistematica da cause non misurate**: Fattori non inclusi nel modello che influenzano sistematicamente $Y$.\n2. **Variazione casuale intrinseca**: Variabilità naturale che esiste indipendentemente dalle relazioni modellate.\n3. **Errore di misurazione casuale**: Errori nel processo di misurazione, stimabili tramite analisi di affidabilità degli strumenti.\n4. **Mancata specificazione della forma funzionale corretta**: Varianza dovuta a un’errata rappresentazione della relazione causale (ad esempio, una relazione modellata come lineare quando è in realtà non lineare).\n\nNel pannello **(a)**, il percorso da $D$ a $Y$ rappresenta l'effetto diretto cumulativo di queste fonti sulla variabile endogena $Y$. Sebbene teoricamente distinguibili, queste fonti spesso si sovrappongono o interagiscono nella pratica.\n\n### Gestione della Varianza Residua nei Software SEM\n\nNei software per l’analisi SEM, i termini di disturbo vengono gestiti automaticamente. Ad esempio, in **lavaan**, il comando:\n\n```R\nY ~ X\n```\n\nistruisce il software a regredire $Y$ su $X$ e a trattare il termine di disturbo come parametro libero. Questo comando:\n\n1. Definisce l'effetto causale di $X$ su $Y$.\n2. Stabilisce che la varianza di $X$ e quella del termine di disturbo di $Y$ siano parametri da stimare.\n\n### Requisiti per l’Identificazione del Modello\n\nPer garantire l’identificazione del modello, sono necessari due requisiti fondamentali:\n\n1. I **gradi di libertà** ($df_M$) devono essere maggiori o uguali a zero:\n   $$\n   df_M = p - q,\n   $$\n   dove $p$ è il numero di informazioni statistiche disponibili e $q$ il numero di parametri liberi.\n2. Ogni variabile latente, inclusi i termini di disturbo, deve avere una scala definita.\n\n### Confronto tra le Rappresentazioni\n\n- **Rappresentazione dettagliata (pannello a)**: Include tutti i termini espliciti, come il termine di disturbo e i vincoli di scala. È utile per comprendere la struttura completa del modello.\n- **Rappresentazione sintetica (pannello b)**: Ommette i simboli per i parametri di varianza e il termine di disturbo, fornendo una visione semplificata delle relazioni principali.\n\nIn sintesi, entrambe le rappresentazioni descrivono lo stesso modello, ma con diversi livelli di dettaglio. La scelta dipende dall'obiettivo: chiarezza concettuale o sintesi grafica.\n\n### Considerazioni sugli Errori di Misurazione nei Modelli a Percorsi\n\nRiprendendo la discussione sulla @fig-kline_7_2, possiamo delineare le seguenti ipotesi fondamentali:\n\n1. **Affidabilità della Variabile Esogena X**: Si assume che i punteggi sulla variabile esogena X siano privi di errore, ovvero perfettamente affidabili, con un coefficiente di affidabilità ($r_{XX}$) di 1.0.\n\n2. **Correttezza della Direzione Causale**: La relazione causale da X a Y è assunta come correttamente specificata e caratterizzata da una stretta linearità.\n\n3. **Indipendenza delle Cause Non Misurate di Y da X**: Si presume che le cause non misurate (latenti) di Y non siano correlate con X, escludendo quindi l'esistenza di cause comuni non misurate che influenzano simultaneamente entrambe le variabili -- ricordiamo la discusione precedente sull'errore di specificazione.\n\nIn ambito di modellazione dei percorsi, l'assunzione che le variabili esogene siano prive di errori di misurazione riflette un presupposto simile a quello adottato nelle regressioni multiple standard, dove i predittori sono considerati esenti da errori di misurazione. Questa assunzione è necessaria poiché le variabili esogene nei modelli a percorsi non includono termini di errore, rendendo impossibile incorporare l'errore casuale in tali modelli. Al contrario, nelle variabili endogene di tali modelli, la presenza di termini di errore permette di tenere conto dell'errore di misurazione.\n\nNel caso di una regressione bivariata, un errore di misurazione presente solo nella variabile dipendente Y influisce sul modello aumentando l'errore standard della stima di regressione, riducendo il valore di $R^2$ e diminuendo il valore assoluto del coefficiente di regressione standardizzato, a causa dell'incremento dell'errore di misurazione in Y. Invece, l'errore di misurazione presente solo nella variabile predittiva X (ma non in Y) tende a introdurre un bias negativo nei coefficienti di regressione -- cioè una sistematica sottostima dei veri valori dei coefficienti di regressione.\n\nQuando entrambe le variabili X e Y presentano errori di misurazione, la dinamica risultante è più complessa da prevedere. Se gli errori di misurazione in X e Y sono indipendenti, il risultato più comune è un bias negativo (ossia una sottostima dei coefficienti di regressione della popolazione). Tuttavia, se gli errori di misurazione sono comuni tra X e Y, la regressione potrebbe sovrastimare i coefficienti della popolazione, portando a un bias positivo. È essenziale riconoscere che l'errore di misurazione non causa sempre un bias negativo. Di conseguenza, la presenza di errori di misurazione non modellati nelle variabili esogene può significativamente distorcere i risultati, specialmente in presenza di forti correlazioni tra multiple variabili esogene. Per ridurre questi rischi, si raccomanda di valutare l'affidabilità dei punteggi associati alle variabili esogene. Questa pratica metodologica, che consiste nel verificare la precisione e la consistenza delle misure delle variabili predittive, aiuta a identificare e quantificare eventuali errori di misurazione. Un'accurata stima dell'affidabilità contribuisce a garantire l'integrità e la validità dei risultati dei modelli a percorsi, mitigando l'impatto che gli errori di misurazione possono avere sull'analisi.\n\n### Direzionalità Causale e Forma Funzionale della Relazione X-Y\n\nL'assunzione che la relazione tra le variabili X e Y sia lineare, come presentato nella @fig-kline_7_2, può essere esaminata attraverso l'analisi dei dati. Se si osserva che la relazione è significativamente curvilinea, si può adeguare l'analisi per attenuare il presupposto di linearità. Ciò può essere realizzato attraverso metodi come la regressione polinomiale o la regressione non parametrica, che permettono di modellare relazioni più complesse rispetto a un semplice modello lineare.\n\nTuttavia, la direzionalità dell'effetto causale rappresenta una sfida differente e non è direttamente testabile attraverso metodi statistici standard. Nell'ambito dei modelli SEM, le direzioni degli effetti causali sono generalmente ipotizzate piuttosto che empiricamente verificate. Questo perché è possibile costruire modelli SEM equivalenti che utilizzano le stesse variabili e hanno lo stesso numero di gradi di libertà ($df_M$), ma con direzioni inverse di alcuni effetti causali. Inoltre, entrambi i modelli, nonostante le differenze nelle direzionalità causali, mostreranno lo stesso grado di adattamento ai dati osservati.\n\nUn'ulteriore ragione per cui la direzionalità causale è tipicamente assunta piuttosto che testata in SEM risiede nella natura degli studi SEM stessi. La maggior parte degli studi SEM si basa su disegni trasversali, dove tutte le variabili sono misurate contemporaneamente, senza una chiara precedenza temporale. In questi contesti, l'unica base per definire la direzionalità causale è l'argomentazione teorica del ricercatore, che deve giustificare perché si presume che X influenzi Y e non viceversa, o perché non si considera una relazione di feedback o causazione reciproca tra le due variabili.\n\nDi conseguenza, la metodologia SEM non è intrinsecamente una tecnica per la scoperta di relazioni causali. Se un modello è corretto, SEM può essere utilizzato per stimare le direzioni, le dimensioni e la precisione degli effetti causali. Tuttavia, questo non è il modo in cui i ricercatori tipicamente impiegano le analisi SEM. Piuttosto, un modello causale viene ipotizzato e poi adattato ai dati basandosi sulle assunzioni delineate. Se queste assunzioni risultano essere errate, anche i risultati dell'analisi saranno invalidi. Questo enfatizza il punto sollevato da Pearl (2000), che sostiene che \n\n> le ipotesi causali sono un prerequisito essenziale per validare qualsiasi conclusione causale (p. 136). \n\nQuesto implica la necessità di una solida base teorica e concettuale nella formulazione di modelli causali nella modellazione SEM.\n\n### Confondimento nei Modelli Parametrici\n\nNella teoria dei modelli statistici, l'endogenità si riferisce a una situazione in cui una variabile all'interno di un modello è correlata con i termini di errore. Questo può creare problemi nella stima dei parametri del modello e può portare a conclusioni errate riguardo le relazioni causali tra le variabili. \n\nNel contesto del diagramma di una catena contratta della @fig-kline_7_2a, l'endogenità è visualizzata come una covarianza tra la variabile causale misurata X e il disturbo (termine di errore) di Y, indicata con un simbolo specifico. Questo simbolo mostra che c'è una relazione non spiegata tra la causa X e il disturbo associato a Y, suggerendo che X potrebbe non essere una variabile completamente indipendente, come idealmente dovrebbe essere in un modello causale chiaro.\n\nIl modello nella @fig-kline_7_2a (a) non è identificabile per due ragioni principali:\n\n1. **Gradi di libertà negativi (dfM = -1)**: Questo indica che ci sono più parametri da stimare nel modello rispetto al numero di informazioni (osservazioni) disponibili. In sostanza, il modello sta cercando di \"apprendere\" troppo da troppo pochi dati, il che lo rende statisticamente non identificabile.\n\n2. **Percorso di confondimento non chiuso tra X e D**: Il percorso di confondimento (o back-door) tra X e D indica che c'è una relazione non controllata o non misurata tra la variabile indipendente X e il disturbo D di Y. Poiché D è trattato come una variabile latente (cioè, una variabile non osservata direttamente), questo percorso non può essere chiuso o controllato nel modello. Ciò significa che non possiamo essere sicuri se la relazione osservata tra X e Y è effettivamente causata da X o se è influenzata da altri fattori non considerati nel modello.\n\nIn sintesi, l'endogenità in questo contesto si riferisce al problema di avere una variabile indipendente (X) che non è veramente indipendente a causa della sua relazione non spiegata con il termine di errore associato alla variabile dipendente (Y), compromettendo così la chiarezza delle relazioni causali nel modello.\n\n::: {#fig-kline_7_2a}\n![](../../figures/kline_7_2a.png){width=\"80%\"}\n\nEndogenità in una catena contratta (a). Identificazione del modello controllando un proxy (P) di una causa comune non misurata (b) e attraverso metodi di variabile strumentale (Z), che affrontano anche l'errore di misurazione nella variabile X (c). Tutti i diagrammi sono mostrati in simbolismo compatto. (Figura tratta da @kline2023principles)\n:::\n\nL'endogenità nei modelli parametrici può essere indotta dalle seguenti condizioni:\n\n1. Una causa comune non misurata di X e Y (cioè, un confonditore).\n2. Errore di misurazione casuale in X (cioè, $r_{XX} < 1.0$).\n3. Causalità reciproca, o X e Y si causano a vicenda (cioè, sono entrambe variabili endogene) in un ciclo di feedback.\n4. Errori autoregressivi, dove X è una versione ritardata di Y e gli errori persistono tra le due variabili.\n5. Autoregressione spaziale, che si verifica quando i punteggi di ciascun caso sono influenzati da quelli di casi vicini o adiacenti spazialmente.\n\nNel contesto dei modelli statistici, è possibile affrontare il problema dei confonditori non misurati in due modi principali: attraverso la selezione di covariate appropriate o utilizzando i metodi delle variabili strumentali. Per illustrare, la @fig-kline_7_2a (b) propone l'uso di un proxy (P) che funge da sostituto per un confonditore non misurato che influisce su entrambe le variabili X e Y. In questo contesto, la variabile X è considerata endogena, il che significa che è influenzata dal proxy P (che a sua volta influisce anche su Y), indicando una possibile relazione di causa-effetto tra P e X.\n\nPer chiarire, consideriamo il seguente esempio. Immaginiamo di essere interessati a studiare l'effetto dello stress sulle prestazioni accademiche degli studenti universitari. In questo esempio, \"stress\" è la variabile X e \"prestazioni accademiche\" è la variabile Y. Tuttavia, c'è un potenziale confonditore che potrebbe influenzare sia lo stress sia le prestazioni accademiche, ma che non è stato misurato o non può essere facilmente misurato. Questo confonditore potrebbe essere, ad esempio, il \"benessere psicologico generale\" degli studenti.\n\nIn questo caso, un proxy (P) per il benessere psicologico generale potrebbe essere \"l'attività fisica regolare\", che è più facilmente misurabile. La ricerca ha mostrato che l'attività fisica regolare può influenzare sia il benessere psicologico generale sia lo stress, rendendola un buon proxy per il nostro confonditore non misurato. \n\nNel modello, l'attività fisica (il nostro proxy P) presumibilmente influisce sia sulla variabile causale (lo stress) sia sulla variabile di esito (le prestazioni accademiche). Analizzando i dati con questo modello, possiamo cercare di isolare meglio l'effetto dello stress sulle prestazioni accademiche, controllando per l'effetto del benessere psicologico generale tramite il proxy dell'attività fisica. In questo modo, possiamo ottenere una stima più accurata dell'effetto diretto dello stress sulle prestazioni accademiche, riducendo la distorsione potenzialmente causata dal confonditore non misurato.\n\nI metodi delle variabili strumentali, come mostrato nella @fig-kline_7_2a (c), sono utilizzati per affrontare sia i confonditori non misurati sia gli errori di misurazione nella variabile esogena X. Questo viene fatto sostituendo X con una variabile strumentale XZ in un modello di regressione a due stadi (2SLS). In questo approccio, qualsiasi errore di misurazione casuale in X viene trasferito alla variabile strumentale XZ, seguendo le ipotesi standard dei metodi delle variabili strumentali. È importante notare che, nel pannello (c), la variabile X è considerata endogena, sebbene non tutti i ricercatori scelgano di includere variabili strumentali nei loro diagrammi di modelli statistici. Questo approccio consente di isolare meglio l'effetto di X su Y, controllando per le influenze esterne non misurate e gli errori di misurazione.\n\nPer chiarire ulteriormente questi concetti, esamineremo separatamente il modello autoregressivo e l'autoregressione spaziale.\n\n#### Modello Autoregressivo\n\nUn modello autoregressivo è un tipo di modello statistico utilizzato per analizzare dati sequenziali o temporali. In un modello autoregressivo, si prevedono i valori futuri di una variabile basandosi sui suoi valori passati. Questo è particolarmente utile in studi longitudinali o in serie temporali dove si misura la stessa variabile in diversi punti nel tempo.\n\nNell'esempio della @fig-kline_7_2a (a), immaginiamo che X e Y siano le stesse variabili misurate in due momenti diversi. Ad esempio, X potrebbe essere il livello di ansia di uno studente misurato all'inizio dell'anno scolastico, mentre Y potrebbe essere il livello di ansia dello stesso studente misurato alla fine dell'anno scolastico. In questo caso, stiamo cercando di prevedere i punteggi futuri di ansia (Y) basandoci sui punteggi passati (X).\n\nUn aspetto importante da considerare è che gli errori nelle misure ripetute (le variazioni nei punteggi che non sono spiegati dal modello) possono essere correlati. Ad esempio, se le misurazioni sono fatte in intervalli temporali ravvicinati, le circostanze o gli stati interni che hanno influenzato la prima misurazione potrebbero ancora essere presenti durante la seconda misurazione.\n\n#### Autoregressione Spaziale\n\nL'autoregressione spaziale, invece, si riferisce a un modello che considera le correlazioni spaziali tra dati. Questo tipo di analisi è particolarmente rilevante quando si studiano fenomeni geografici o ambientali. Ad esempio, la diffusione di una malattia in diverse località geografiche potrebbe non essere indipendente: le aree vicine geograficamente potrebbero mostrare pattern simili di diffusione della malattia a causa della loro vicinanza.\n\nIn quest'ultimo caso, non stiamo più parlando di misure ripetute nel tempo sulla stessa unità, ma piuttosto di misure effettuate in diverse unità in un contesto spaziale. Le variabili misurate in diverse località fisiche possono influenzarsi a vicenda, e un modello autoregressivo spaziale cerca di catturare queste interdipendenze.\n\n### Modelli con Cause Correlate o Effetti Indiretti\n\nIl modello parametrico mostrato nella @fig-kline_7_3 (a) suggerisce che la variabile Y sia influenzata da due variabili esogene correlate, X e W. Questo significa che X e W sono due fattori esterni che hanno un impatto su Y e tra loro esiste una relazione di covarianza, ovvero tendono a variare insieme in un certo modo. Tuttavia, il diagramma non spiega il motivo della relazione tra X e W, lasciando la loro interdipendenza non esaminata in termini causali. \n\n::: {#fig-kline_7_3}\n![](../../figures/kline_7_3.png){width=\"80%\"}\n\nModelli con cause correlate (a) e sia effetti diretti che indiretti (b). Tutti i diagrammi sono mostrati in simbolismo compatto. (Figura tratta da @kline2023principles)\n:::\n\nNell'analizzare questi dati con un software, si prenderanno in considerazione gli effetti sia di X che di W, tenendo conto della loro covarianza campionaria. Ciò significa che quando si stimano gli impatti di X e W su Y, si aggiusta per il fatto che X e W sono correlate tra loro. Alcuni software, come `lavaan`, presuppongono automaticamente che tutte le cause esogene misurate che influenzano lo stesso risultato (in questo caso Y) siano correlate. Utilizzando il comando\n\n`Y ~ X + W`\n\nin `lavaan`, si definisce il modello rappresentato nella @fig-kline_7_3 (a), permettendo al software di stimare gli effetti di X e W tenendo conto della loro covarianza osservata. Questo comando specifica inoltre che le varianze di X, W e il disturbo associato a Y sono tutti considerati parametri liberi da stimare.\n\nSe, invece, si ipotizza che le variabili esogene X e W siano indipendenti, ovvero che non ci sia una covarianza tra di loro, si può usare un comando aggiuntivo in `lavaan`\n\n`X ~~ 0*W`\n\nper impostare la covarianza tra X e W a zero. Questo comando mantiene le varianze di X e W come parametri liberi, ma specifica che non c'è una relazione di covarianza diretta tra queste due variabili. In questo modo, il modello considererà X e W come influenze separate e indipendenti su Y.\n\nNel modello presentato nella @fig-kline_7_3 (a), è importante notare come vengano trattate le interazioni tra le variabili causali X e W. In questo specifico caso, si presume che non ci sia alcuna interazione tra X e W; in altre parole, l'effetto di X sulla variabile di esito Y si assume essere costante a prescindere dai diversi livelli di W, e viceversa. Questa assunzione implica che l'effetto di X su Y è indipendente da W, e l'effetto di W su Y è indipendente da X.\n\nIn termini di modellazione, questo significa che stiamo considerando una causalità incondizionata, dove l'effetto di una causa su un esito è costante e non influenzato da altre variabili nel modello. Il modello non prevede, quindi, che l'effetto di X su Y cambi in funzione dei diversi livelli di W. Questo è in contrasto con l'ipotesi di causalità condizionale, dove gli effetti di una variabile su un'altra possono variare in base al livello di una terza variabile. In un modello di causalità condizionale, ad esempio, si potrebbe ipotizzare che l'effetto di X su Y vari a seconda dei diversi livelli di W.\n\nIn sintesi, la @fig-kline_7_3 (a) delinea un modello dove le relazioni causali tra X, W e Y sono considerate fisse e non influenzate da potenziali interazioni tra X e W. Questo tipo di modellazione fornisce una visione semplificata delle relazioni causali, che potrebbe essere appropriata in determinate circostanze, ma non tiene conto di possibili dinamiche più complesse tra le variabili.\n\nÈ fondamentale riconoscere che le ripercussioni degli errori di misurazione in modelli che includono cause correlate sono notevolmente intricate e imprevedibili. Questa complessità deriva principalmente dalla natura del bias che può emergere a seguito di errori di misurazione. In particolare, il bias introdotto da questi errori può manifestarsi in modi diversi, assumendo una forma sia negativa che positiva. Tale variazione dipende da diversi fattori, tra cui se l'errore di misurazione è distribuito in maniera uniforme tra molteplici variabili predittive o se è presente sia nelle variabili predittive che nella variabile di esito. Un altro elemento influente è la natura delle covarianze campionarie tra tutte le variabili coinvolte nel modello.\n\nData questa complessità, la capacità di modellare esplicitamente gli errori di misurazione all'interno dei modelli SEM rappresenta un vantaggio significativo. Questo approccio permette una maggiore precisione nell'analisi, consentendo di tenere conto delle varie modalità in cui gli errori di misurazione possono influenzare i risultati. La modellazione esplicita degli errori di misurazione in SEM offre quindi la possibilità di ottenere stime più accurate e affidabili, mitigando il rischio di trarre conclusioni errate a causa di bias non riconosciuti o non gestiti adeguatamente.\n\nNella @fig-kline_7_3 (b), il modello mostra come la variabile X abbia sia effetti diretti che indiretti sulla variabile di esito Y. L'effetto indiretto segue il percorso X → M → Y, dove M funge da variabile intermedia o mediatrice. Questo significa che M è il canale attraverso il quale gli effetti di X sono trasmessi a Y. In questo modello, M è una variabile endogena, nel senso che è influenzata da X (indicato dal percorso X → M), e allo stesso tempo agisce come una variabile causale nei confronti di Y (come indicato da M → Y).\n\nLa variabile M assume un doppio ruolo in termini di affidabilità e precisione della misurazione. Da una parte, essendo un esito di X, M è soggetta a disturbi, che includono potenziali errori di misurazione. Dall'altra, nel suo ruolo di causa per Y insieme a X, si presume nelle analisi di regressione che sia X che M siano prive di errore di misurazione. Questa assunzione non presenta problemi se l'affidabilità delle misure su M è elevata, ossia se i punteggi di M sono accurati e consistenti.\n\nIn aggiunta, il modello descritto nella @fig-kline_7_3 (b) include tre ipotesi importanti:\n\n1. X ha un effetto diretto su Y, oltre al suo effetto indiretto tramite M.\n2. Non ci sono interazioni negli effetti lineari di X e M su Y, il che significa che l'effetto di X su Y è lo stesso a prescindere dai livelli di M, e viceversa.\n3. Il modello non omette confonditori potenzialmente importanti tra le coppie di variabili X, M e Y. In altre parole, non ci sono fattori esterni non considerati nel modello che potrebbero influenzare le relazioni tra queste tre variabili.\n\nIn sintesi, la @fig-kline_7_3 (b) presenta un modello in cui X influisce su Y sia direttamente che indirettamente attraverso M, e queste relazioni sono considerate prive di interazioni complesse o di confonditori non rilevati.\n\nLa gestione degli errori di misurazione e dei confonditori non considerati in modelli che includono effetti causali indiretti rappresenta una sfida notevole, poiché i loro effetti sulle stime possono essere complessi e non sempre prevedibili. Per esemplificare, consideriamo il modello della @fig-kline_7_3 (b) dove si analizza l'effetto indiretto di X su Y attraverso la variabile intermedia M. \n\nSe assumiamo che non ci siano errori di misurazione nella variabile causale X, qualsiasi errore di misurazione presente nella variabile intermedia M può introdurre un bias negativo nelle stime dell'effetto indiretto di X su Y. Ciò significa che l'effetto indiretto potrebbe essere sottostimato a causa dell'errore in M. D'altro canto, se non si tiene conto dei confonditori tra M e Y, cioè se ci sono variabili o fattori non considerati che influenzano sia M che Y, ciò può portare a un bias positivo, sovrastimando l'effetto indiretto.\n\nQuando entrambe queste situazioni -- errori di misurazione in M e confonditori tra M e Y -- si verificano contemporaneamente, le conseguenze sulle stime dell'effetto indiretto possono variare ampiamente. Potrebbe verificarsi una sovrastima, una sottostima o, in rari casi, nessun bias significativo. Studi di simulazione hanno rivelato che tentare di correggere solo una fonte di bias (come l'errore di misurazione in M) in presenza di entrambi i tipi di bias può addirittura aggravare il problema, portando a stime più distorte rispetto a quelle che non tengono conto di alcun bias.\n\nIn sintesi, la valutazione accurata dell'effetto indiretto in un modello che comprende una variabile intermedia richiede un'attenta considerazione sia degli errori di misurazione che dei confonditori potenziali, poiché la loro interazione può influenzare in modi complessi e talvolta inaspettati la validità delle stime.\n\n### Modelli Ricorsivi, Non Ricorsivi e Parzialmente Ricorsivi\n\nTutti i modelli di percorso parametrici più complessi possono essere \"assemblati\" a partire dai modelli elementari mostrati nelle figure precedenti. Ci sono due tipi fondamentali di modelli: ricorsivi e non ricorsivi. I modelli ricorsivi hanno due caratteristiche essenziali: tutti gli effetti causali sono unidirezionali e i loro disturbi sono indipendenti. La @fig-kline_7_4 (a) è un esempio di un modello ricorsivo (Tutti i modelli considerati finora sono ricorsivi.) \n\nI modelli non ricorsivi, invece, hanno cicli causali (feedback) in cui ≥ 2 variabili endogene sono specificate come cause ed effetti l'una dell'altra, direttamente o indirettamente. Nella loro forma non parametrica, corrispondono a grafi ciclici diretti. La @fig-kline_7_4 (b) è un esempio di un modello parametrico non ricorsivo con causazione reciproca rappresentata come\n\n$Y1 \\overset{\\rightarrow}{\\underset{\\leftarrow}{}} Y2,$\n\nindicando che le variabili Y1 e Y2 hanno effetti simultanei l'una sull'altra. \n\n::: {#fig-kline_7_4}\n![](../../figures/kline_7_4.png){width=\"80%\"}\n\nEsempi di modelli ricorsivi, non ricorsivi e parzialmente ricorsivi con due diversi schemi di correlazione degli errori. Tutti i diagrammi sono mostrati in simbolismo compatto. (Figura tratta da @kline2023principles)\n:::\n\nI modelli che includono cicli causali possono presentare, o meno, covarianze tra i loro termini di disturbo. La presenza di errori correlati in questi modelli implica l'esistenza di ipotesi su cause comuni non misurate che influenzano le variabili in questione.\n\nAd esempio, nel modello rappresentato nella @fig-kline_7_4 (b), le variabili Y1 e Y2 sono definite come cause reciproche, ovvero ognuna influisce sull'altra. In aggiunta a ciò, se nel modello è specificata una covarianza tra i termini di disturbo $D_1$ e $D_2$, ciò suggerisce che Y1 e Y2 condividono almeno una causa comune non misurata. In altre parole, l'ipotesi è che esistano fattori non osservati che influenzano entrambe le variabili, $Y1$ e $Y2$, e questa influenza comune si manifesta attraverso la covarianza tra i loro termini di disturbo.\n\nEsiste anche un altro tipo di modello di percorso, quello che ha effetti unidirezionali e covarianze dei disturbi. I modelli parzialmente ricorsivi con un pattern di correlazioni dei disturbi senza \"archi\" possono essere trattati nell'analisi proprio come i modelli ricorsivi. Un pattern senza \"archi\" significa che gli errori correlati sono limitati a coppie di variabili endogene senza effetti diretti tra di loro, come Y1 e Y2 nella @fig-kline_7_4 (c).\n\nI modelli parzialmente ricorsivi che presentano un pattern di correlazioni dei disturbi caratterizzato dalla presenza di \"archi\" richiedono un trattamento analitico simile a quello dei modelli non ricorsivi. Un pattern con \"archi\" si verifica quando esiste una covarianza tra i termini di disturbo di due variabili endogene che sono collegate da un effetto diretto. Ad esempio, nella @fig-kline_7_4 (d), le variabili Y1 e Y2 sono collegate da un effetto diretto e presentano una covarianza tra i loro disturbi $D_1$ e $D_2$.\n\nLa presenza di un effetto diretto insieme a disturbi correlati tra due variabili crea un percorso di confondimento nel modello. Un percorso di confondimento è una via attraverso la quale può fluire l'influenza causale indiretta, potenzialmente distorcendo l'interpretazione dei rapporti causali diretti. In questi casi, la selezione di covariate (variabili aggiuntive che potrebbero spiegare parte della relazione osservata) non è sufficiente per \"chiudere\" o eliminare questo percorso di confondimento. Pertanto, questi modelli richiedono un'attenzione particolare nell'analisi per garantire che le stime degli effetti causali siano accurate e non siano influenzate in modo improprio da questi percorsi di confondimento.\n\nI modelli ricorsivi e quelli parzialmente ricorsivi che non includono cicli causali possono essere efficacemente rappresentati tramite grafi aciclici diretti (DAG). Questo tipo di rappresentazione grafica implica che è possibile applicare tutte le regole di identificazione grafica esposte in questo capitolo. Nei DAG, le relazioni causali sono rappresentate come flussi unidirezionali senza cicli, rendendo più chiaro e diretto l'analisi delle relazioni tra le variabili.\n\nD'altra parte, i modelli non ricorsivi che includono cicli causali, come quello illustrato nella @fig-kline_7_4 (b), sono rappresentati da grafi ciclici diretti. In questi grafi, le variabili possono influenzarsi a vicenda in un ciclo continuo, creando una struttura più complessa. A causa di questa complessità, le regole di identificazione grafica per i grafi ciclici diretti non sono sviluppate quanto quelle per i DAG. Questo significa che analizzare e interpretare i modelli non ricorsivi con cicli causali è più complesso e richiede l'uso di approcci analitici più avanzati o specifici per gestire correttamente le relazioni cicliche tra le variabili.\n\nPossiamo stabilire una regola generale per i modelli di percorso parametrici: i modelli ricorsivi o parzialmente ricorsivi, che presentano schemi di covarianze dei disturbi privi di \"archi\" e che soddisfano due condizioni specifiche, sono considerati identificati. Queste condizioni sono: (1) i gradi di libertà del modello (dfM) devono essere maggiori o uguali a zero e (2) ogni variabile non misurata, inclusi i termini di errore, deve essere associata a una scala metrica.\n\nInoltre, i modelli di equazioni strutturali che sono identificati e hanno un numero di osservazioni uguale al numero dei parametri liberi (dfM = 0) sono classificati come \"appena identificati\". Al contrario, i modelli con più osservazioni rispetto ai parametri liberi (dfM > 0) sono considerati \"sovraidentificati\".\n\nUn modello di equazioni strutturali può risultare sotto-identificato in due modi distinti: (1) se dfM è inferiore a zero, oppure (2) se, pur avendo un dfM maggiore o uguale a zero, alcuni parametri liberi rimangono sotto-identificati perché non vi sono sufficienti informazioni per la loro stima, anche se altri parametri all'interno dello stesso modello sono identificati. Nel secondo scenario, l'intero modello è considerato non identificato, anche se dfM è maggiore o uguale a zero. In generale, un modello si considera sotto-identificato quando non è possibile stimare in modo univoco tutti i suoi parametri liberi.\n\n## Analisi dei percorsi e regressione bivariata\n\nCominciamo esaminando l'analisi dei percorsi partendo dall'esempio più semplice, ovvero il modello di regressione lineare. Il modello di regressione bivariata si esprime tramite l'equazione seguente:\n\n$$y_1 = b_0 + b_1 x_1 + \\epsilon_1,$$\n\ndove $y$ rappresenta la variabile dipendente, $b_0$ rappresenta l'intercetta, $b_1$ rappresenta la pendenza della retta di regressione, $x$ è la variabile indipendente e $\\epsilon$ è il termine di errore.\n\nNell'ambito della descrizione delle relazioni tra variabili manifeste e latenti, si adotta spesso la notazione LISREL. In questa notazione, il modello presentato in precedenza può essere espresso come segue:\n\n$$y_1 = \\alpha + \\gamma x_1 + \\zeta_1,$$\n\ndove:\n\n- $x_1$: variabile esogena singola,\n- $y_1$: variabile endogena singola,\n- $\\alpha$: intercetta di $y_1$,\n- $\\gamma_1$: coefficiente di regressione,\n- $\\zeta_1$: termine di errore di $y_1$,\n- $\\phi$: varianza o covarianza della variabile esogena,\n- $\\psi$: varianza o covarianza residuale della variabile endogena.\n\nIl diagramma di percorso per il modello di regressione bivariata è illustrato nella @fig-lisrel_bivariate_reg.\n\n::: {#fig-lisrel_bivariate_reg}\n![](../../figures/lisrel_bivariate_reg.png){width=\"70%\"}\n\nDiagramma di percorso per il modello di regressione bivariato.\n:::\n\nFacciamo un esempio numerico. Simuliamo tre variabili: x1, x2, y.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(42)\nn <- 100\nx1 <- rnorm(n, 90, 20)\nx2 <- x1 + rnorm(n, 0, 30)\ny <- 25 + 0.5 * x1 + 1.0 * x2 + rnorm(n, 0, 30)\n\ndat <- data.frame(\n    y, x1, x2\n)\n\ncor(dat) |>\n    round(2)\n#>       y   x1   x2\n#> y  1.00 0.55 0.80\n#> x1 0.55 1.00 0.62\n#> x2 0.80 0.62 1.00\n```\n:::\n\n\n\n\nConsideriamo la relazione tra `x1` (variabile endogena) e `y` (variabile endogena). In R possiamo adattare ai dati un modello di regressione mediante la funzione `lm`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1a <- lm(y ~ x1, data = dat)\nsummary(m1a)\n#> \n#> Call:\n#> lm(formula = y ~ x1, data = dat)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -82.46 -29.54  -3.44  29.20 122.23 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)   37.597     18.984    1.98     0.05\n#> x1             1.329      0.204    6.51  3.3e-09\n#> \n#> Residual standard error: 42.3 on 98 degrees of freedom\n#> Multiple R-squared:  0.302,\tAdjusted R-squared:  0.295 \n#> F-statistic: 42.4 on 1 and 98 DF,  p-value: 3.25e-09\n```\n:::\n\n\n\n\nUsiamo ora lavaan per adattare lo stesso modello ai dati.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1b <- \"\n    y ~ 1 + x1\n\"\nfit1b <- sem(m1b, data = dat)\nparameterEstimates(fit1b) \n#>   lhs op rhs     est      se    z pvalue ci.lower ci.upper\n#> 1   y ~1       37.60  18.794 2.00  0.045    0.763    74.43\n#> 2   y  ~  x1    1.33   0.202 6.57  0.000    0.933     1.73\n#> 3   y ~~   y 1754.10 248.067 7.07  0.000 1267.897  2240.30\n#> 4  x1 ~~  x1  429.43   0.000   NA     NA  429.432   429.43\n#> 5  x1 ~1       90.65   0.000   NA     NA   90.650    90.65\n```\n:::\n\n\n\n\nL'intercetta di `y ~1` (37.597) e il coefficiente di regressione di `y ~ x1` (1.329) corrispondono all'output di `lm()` con piccoli errori di arrotondamento. L'intercetta per `x1 ~1` (90.650) e la sua varianza `x1 ~~ x1` (429.432) descrivono una media ed una varianza esogena e corrispondono alla media e alla varianza univariate:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(dat$x1)\n#> [1] 90.7\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(dat$x1) * (length(dat$x1) - 1) / length(dat$x1)\n#> [1] 429\n```\n:::\n\n\n\n\nLa varianza residua di `y`, `y ~~ y` corrisponde alla quota della varianza osservata della variabile `y` che non è spiegata dalla relazione lineare su `x1`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(dat$y) * 99 / 100 - (1.3286 * 429.432 * 1.3286)\n#> [1] 1754\n```\n:::\n\n\n\n\nLa funzione `semPaths` consente di creare un diagramma di percorso a partire dall'oggetto creato da `sem`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit1b,\n    layout = \"tree\", sizeMan = 7, sizeInt = 5, style = \"ram\", \n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 1.15,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Analisi dei percorsi e regressione multipla\n\nLa regressione semplice è limitata a una sola variabile esogena. Nella pratica, un ricercatore può essere interessato a studiare come un gruppo di variabili esogene possano predire una variabile di esito. Supponiamo di avere ancora una sola variabile di esito endogena ma due predittori esogeni; questo caso è noto come regressione multipla:\n\n$$\ny_1 = \\alpha_1 + \\gamma_1 x_1 + \\gamma_2 x_2 + \\zeta_1.\n$$\n\nIl diagramma di percorso mostra la relazione tra tutte le variabili, comprendendo anche i fattori di disturbo, e fornisce dunque la rappresentazione grafica dell'equazione precedente.\n\n::: {#fig-lisrel_mr}\n![](../../figures/lisrel_mr.png){width=\"80%\"}\n\nDiagramma di percorso per il modello di regressione multipla.\n:::\n\nI coefficienti di percorso associati alle frecce orientate esprimono la portata del nesso causale e corrispondono ai pesi beta (ovvero ai coefficienti parziali di regressione standardizzati). Le frecce non orientate esprimono la portata della pura associazione tra variabili e dunque corrispondono alle correlazioni/covarianze.\n\nIn un diagramma di percorso, il numero di equazioni corrisponde al numero di variabili endogene del modello. Nel caso specifico, poiché vi è una sola variabile endogena (ovvero $y$), esiste un'unica equazione che descrive le relazioni causalitiche interne al path diagram. All'interno di ciascuna equazione, inoltre, il numero di termini corrisponde al numero di frecce orientate che puntano verso la variabile endogena. Nell'esempio sopra citato, pertanto, la sola equazione del modello contiene tre termini, ciascuno associato ad una freccia orientata.\n\nUsando `lm` otteniamo la seguente stima dei coefficienti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2a <- lm(y ~ 1 + x1 + x2, data = dat)\nfit2a <- summary(m2a) \n```\n:::\n\n\n\n\nGli stessi risultati si ottengono con lavaan.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2b <- \"\n    y ~ 1 + x1 + x2\n    x1 ~~ x1\n    x2 ~~ x2\n    x1 ~~ x2\n\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit2b <- sem(m2b, data = dat)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameterEstimates(fit2b)\n#>   lhs op rhs      est      se     z pvalue ci.lower ci.upper\n#> 1   y ~1       44.454  13.457  3.30  0.001   18.078   70.830\n#> 2   y  ~  x1    0.199   0.185  1.08  0.282   -0.164    0.562\n#> 3   y  ~  x2    1.085   0.111  9.78  0.000    0.868    1.303\n#> 4  x1 ~~  x1  429.432  60.731  7.07  0.000  310.402  548.462\n#> 5  x2 ~~  x2 1192.840 168.693  7.07  0.000  862.208 1523.472\n#> 6  x1 ~~  x2  446.927  84.379  5.30  0.000  281.546  612.307\n#> 7   y ~~   y  896.963 126.850  7.07  0.000  648.342 1145.584\n#> 8  x1 ~1       90.650   2.072 43.74  0.000   86.589   94.712\n#> 9  x2 ~1       88.026   3.454 25.49  0.000   81.257   94.795\n```\n:::\n\n\n\n\nEsaminiamo il diagramma di percorso.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit2b,\n    layout = \"tree\", sizeMan = 7, sizeInt = 5, style = \"ram\",\n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 1.15,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Effetti diretti e indiretti\n\nL'analisi del percorso offre un metodo essenziale per distinguere tra diverse tipologie di effetti che influenzano le variabili in esame: l'effetto diretto, l'effetto indiretto e l'effetto totale. Gli effetti diretti rappresentano l'influenza che una variabile esercita su un'altra senza mediazione di altre variabili intermedie. Gli effetti indiretti, invece, operano attraverso l'intermediazione di almeno una variabile aggiuntiva nel processo. L'effetto totale è la somma cumulativa degli effetti diretti e indiretti.\n\nNella @fig-path_03, la variabile $y_1$ esercita un effetto diretto sulla variabile $y_2$. Allo stesso tempo, $y_1$ produce un effetto indiretto sulla variabile $y_3$, poiché non esiste una connessione causale diretta tra $y_1$ e $y_3$. Nel contesto rappresentato, la variabile $y_1$ agisce come variabile esogena, mentre le variabili $y_2$ e $y_3$ fungono da variabili endogene.\n\n::: {#fig-path_03}\n![](../../figures/path_03.png){width=\"40%\"}\n\nDiagramma di percorso per un modello a catena.\n:::\n\n## Le regole di Wright\n\nL'obiettivo primario dell'analisi del percorso consiste nella decomposizione della correlazione (o della covarianza) in base alla somma dei vari percorsi (diretti e indiretti) che collegano due variabili mediante coefficienti noti come \"path coefficients.\" Utilizzando il diagramma del percorso, Sewall Wright (1921, 1934) formulò le regole che, tramite le \"tracing rules,\" stabiliscono il collegamento tra le correlazioni (o covarianze) delle variabili e i parametri del modello. Le tracing rules si possono esprimere nei seguenti termini:\n\n- È possibile procedere in avanti lungo una freccia e poi a ritroso, seguendo la direzione della freccia, ma non è permesso muoversi in avanti e poi tornare indietro.\n- Un percorso composto non deve attraversare più di una volta la stessa variabile, cioè non possono esserci cicli.\n- Un percorso non può contenere più di una linea curva.\n\nIl termine \"percorso\" fa riferimento al tracciato che connette due variabili e si compone di sequenze di frecce unidirezionali e curve non direzionali. A ciascun percorso valido (cioè conforme alle regole di Wright) viene assegnato un valore numerico che rappresenta il prodotto dei coefficienti presenti lungo il percorso stesso. I coefficienti di percorso possono essere coefficienti parziali di regressione standardizzati se il legame è unidirezionale, oppure coefficienti di correlazione se il legame è bidirezionale.\n\n## Scomposizione delle correlazioni/covarianze\n\nIl principio fondamentale è stato formulato da Sewall Wright (1934) nel seguente modo:\n\n> Ogni correlazione tra variabili in una rete di relazioni sequenziali può essere analizzata nei contributi provenienti da tutti i percorsi (diretti o attraverso fattori comuni) con i quali le due variabili sono connesse. Ogni contributo ha un valore pari al prodotto dei coefficienti relativi ai percorsi elementari. Se sono presenti correlazioni residue (rappresentate da frecce bidirezionali), uno (ma mai più di uno) dei coefficienti moltiplicati per ottenere il contributo del percorso di connessione può essere un coefficiente di correlazione. Gli altri sono tutti coefficienti di percorso.\n\nDa questo principio possiamo derivare la regola di scomposizione della correlazione: la correlazione o covarianza tra due variabili può essere scomposta in un numero di termini uguale al numero di percorsi che le collegano. Ogni termine è ottenuto dal prodotto dei coefficienti associati alle variabili lungo il percorso. In altre parole, è possibile decomporre la correlazione o la covarianza tra due variabili in tanti contributi quanti sono i percorsi possibili che collegano le due variabili.\n\n### Scomposizione della varianza\n\nLa decomposizione della varianza di una variabile endogena può essere affrontata attraverso una suddivisione in due componenti: una componente spiegata, attribuibile alle variabili che esercitano un'influenza causale su di essa, e una componente non spiegata. La componente spiegata della varianza deriva dall'aggregazione degli effetti delle diverse variabili che sono connessi alla variabile endogena, rispettando le regole di tracciamento definite da Wright. Il numero di addendi corrisponde al numero di percorsi che collegano la variabile endogena a se stessa. In tal modo, la varianza spiegata rappresenta la parte della varianza totale della variabile endogena che può essere attribuita alle influenze delle variabili correlate attraverso i percorsi definibili all'interno del modello.\n\n### Relazioni tra variabili endogene e esogene\n\nComplessivamente, i concetti di varianza, covarianza e correlazione informano direttamente il calcolo dei coefficienti di percorso in un path diagram secondo le seguenti \"8 regole dei coefficienti di percorso\".\n\n- Regola 1: Le relazioni non specificate tra le variabili esogene sono semplicemente le loro correlazioni bivariate.\n- Regola 2: Quando due variabili sono collegate da un singolo percorso, il coefficiente di quel percorso è il coefficiente di regressione.\n- Regola 3: La forza di un percorso composto (che include più collegamenti) è il prodotto dei coefficienti individuali.\n- Regola 4: Quando le variabili sono collegate da più di un percorso, ciascun percorso è il coefficiente di regressione \"parziale\".\n- Regola 5: Gli errori sulle variabili endogene si riferiscono alle correlazioni o varianze non spiegate che derivano dalle variabili non misurate.\n- Regola 6: Le correlazioni non analizzate (residui) tra due variabili endogene sono le loro correlazioni parziali.\n- Regola 7: L'effetto totale che una variabile ha su un'altra è la somma dei suoi effetti diretti e indiretti.\n- Regola 8: L'effetto totale (compresi i percorsi non diretti) è equivalente alla correlazione totale.\n\n**Esempio.** Consideriamo nuovamente il modello di regressione multipla con due variabili esogene e una sola variabile endogena che è stato presentato sopra. \n\nLa la covarianza tra `y` e `x1` \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncov(dat$y, dat$x1) * 99 / 100\n#> [1] 571\n```\n:::\n\n\n\n\npuò essere ricavata usando le regole di Wright nel modo seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n0.199 * 429.43 + 1.085 * 446.93\n#> [1] 570\n```\n:::\n\n\n\n\nLa quota di varianza non spiegata della variabile endogena è:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(var(dat$y) * 99 / 100) - (\n    0.199^2 * 429.43 + (1.085)^2 * 1192.84 + 2 * (0.199 * 1.085 * 446.93)\n)\n#> [1] 898\n```\n:::\n\n\n\n\n\n\n## Oltre la Regressione Multipla\n\nPer comprendere come applicare la *path analysis* a strutture più complesse rispetto alla regressione multipla, esaminiamo uno studio esemplare di @barbeau2019path. Questo studio illustra l'utilizzo della *path analysis* attraverso due modelli: uno di mediazione e un altro più articolato.\n\nL'analisi di mediazione consente di studiare come una variabile indipendente ($X$) influenzi una variabile dipendente ($Y$) tramite una variabile intermedia, chiamata **mediatore** ($M$). Questo approccio offre una visione più approfondita rispetto alla regressione multipla, esplorando i meccanismi sottostanti le relazioni tra le variabili.\n\nUn esempio applicativo deriva dalla **Self-Determination Theory** (SDT) di Deci e Ryan (2000), che esamina come la soddisfazione e la frustrazione dei bisogni psicologici fondamentali influenzino i sintomi bulimici in giovani donne adulte. Secondo la SDT, i bisogni di autonomia, competenza e relazionalità sono cruciali per il benessere psicologico. La loro frustrazione può promuovere comportamenti disfunzionali, mentre la loro soddisfazione agisce da fattore protettivo (Vansteenkiste & Ryan, 2013).\n\nIl modello proposto è costituito dalle seguenti componenti.\n\n1. **Frustrazione dei bisogni psicologici**:\n   - Favorisce l'approvazione degli ideali culturali di magrezza.\n   - È associata a una maggiore inflessibilità negli schemi corporei.\n2. **Approvazione degli ideali di magrezza**:\n   - Predice l'inflessibilità negli schemi corporei.\n3. **Inflessibilità degli schemi corporei**:\n   - Media l'effetto della frustrazione dei bisogni sui sintomi bulimici.\n\nQuesto modello concettuale suggerisce che la frustrazione dei bisogni riduca le risorse psicologiche necessarie per resistere agli ideali culturali disfunzionali, aumentando la vulnerabilità psicologica e il rischio di sintomi patologici (Pelletier & Dion, 2007).\n\nIl modello teorico può essere formalizzato attraverso tre percorsi principali:\n\n1. **Effetto di $X$ su $M$ (coefficiente $a$):** Misura l'influenza della frustrazione dei bisogni ($X$) sull'approvazione degli ideali culturali ($M$).\n2. **Effetto di $M$ su $Y$ (coefficiente $b$):** Valuta come $M$ influenzi l'inflessibilità degli schemi corporei e i sintomi bulimici ($Y$).\n3. **Effetto diretto di $X$ su $Y$ (coefficiente $c'$):** Analizza l'effetto residuo di $X$ su $Y$, indipendentemente da $M$.\n\nMatematicamente, il modello è descritto dalle seguenti equazioni di regressione:\n\n1. **Equazione per il mediatore ($M$):**\n\n   $$\n   M = a_0 + a \\cdot X + e_M ,\n   $$\n\n   dove $a$ è l'effetto di $X$ su $M$; $e_M$ è il termine di errore.\n\n2. **Equazione per la variabile dipendente ($Y$):**\n\n   $$\n   Y = b_0 + b \\cdot M + c' \\cdot X + e_Y ,\n   $$\n\n   dove $b$ è l'effetto di $M$ su $Y$; $c'$ è l'effetto diretto di $X$ su $Y$.\n\nNel modello di mediazione, è possibile distinguere tre tipi di effetti, ciascuno quantificabile in modo specifico.\n\n- **Effetto diretto** ($c'$): rappresenta l'influenza della variabile indipendente ($X$) sulla variabile dipendente ($Y$) che non passa attraverso il mediatore ($M$).\n- **Effetto indiretto** ($a \\cdot b$): misura il contributo della variabile indipendente ($X$) alla variabile dipendente ($Y$) mediato dal percorso attraverso il mediatore ($M$).  \n- **Effetto totale** ($c' + a \\cdot b$): corrisponde alla somma degli effetti diretto e indiretto, rappresentando l'influenza complessiva di $X$ su $Y$.  \n\nQui, $a$, $b$ e $c'$ sono i coefficienti stimati nel modello di path analysis.\n\nLo studio di @barbeau2019path utilizza un campione di 192 partecipanti. Sono stati utilizzati i seguenti strumenti:\n\n- **Frustrazione e soddisfazione dei bisogni:** *Basic Psychological Needs Satisfaction and Frustration Scale* (Chen et al., 2015).\n- **Approvazione degli ideali di magrezza:** *Endorsement of Societal Beliefs Related to Thinness and Obesity* (Boyer, 1991).\n- **Inflessibilità degli schemi corporei:** *Body Image-Acceptance and Action Questionnaire* (Sandoz et al., 2013).\n- **Sintomi bulimici:** *Eating Disorders Inventory-2* (Garner, 1991).\n\nLa matrice di covarianza delle variabili è rappresentata come segue:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nupper <- '\n  1 0.44 -0.41 0.55 0.63\n  1 -0.37 0.45 0.44\n  1 -0.71 -0.39\n  1 0.47\n  1\n'\ndat_cov <- lavaan::getCov(\n    upper,\n    lower = FALSE,\n    names = c(\"BFLX\", \"END\", \"MNS\", \"MNF\", \"BULS\")\n)\ndat_cov\n#>       BFLX   END   MNS   MNF  BULS\n#> BFLX  1.00  0.44 -0.41  0.55  0.63\n#> END   0.44  1.00 -0.37  0.45  0.44\n#> MNS  -0.41 -0.37  1.00 -0.71 -0.39\n#> MNF   0.55  0.45 -0.71  1.00  0.47\n#> BULS  0.63  0.44 -0.39  0.47  1.00\n```\n:::\n\n\n\n\nNell'esempio, BFLX (*Body Inflexibility*) è la variabile endogena, MNF (*Mean Need Frustration*) è la variabile esogena, ed END (*Endorsement of Societal Beliefs about Thinness and Obesity*) è la variabile mediatrice. \n\n@barbeau2019path hanno utilizzato Mplus per stimare i coefficienti di percorso, ottenendo $a = 0.37$, $b = 0.29$ e $c = 0.34$. Esamineremo il medesimo modello utilizzando il pacchetto `lavaan` in R.\n\nIl modello di mediazione viene definito come segue:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- \"\n  # Effetto diretto\n  BFLX ~ c*MNF\n  # Mediatore\n  BFLX ~ b*END\n  END ~ a*MNF\n\n  # Effetto indiretto\n  ab := a*b\n  # Effetto totale\n  total := c + (a*b)\n\"\n```\n:::\n\n\n\n\nAdattiamo il modello ai dati osservati, utilizzando una matrice di covarianza e un campione di 192 partecipanti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- sem(\n    mod,\n    sample.cov = dat_cov,\n    sample.nobs = 192\n)\n```\n:::\n\n\n\n\nI risultati vengono analizzati con il seguente comando:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(\n  fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE\n) \n#> lavaan 0.6-19 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         5\n#> \n#>   Number of observations                           192\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 0.000\n#>   Degrees of freedom                                 0\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               125.849\n#>   Degrees of freedom                                 3\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    1.000\n#>   Tucker-Lewis Index (TLI)                       1.000\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)               -480.945\n#>   Loglikelihood unrestricted model (H1)       -480.945\n#>                                                       \n#>   Akaike (AIC)                                 971.890\n#>   Bayesian (BIC)                               988.178\n#>   Sample-size adjusted Bayesian (SABIC)        972.339\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.000\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.000\n#>   P-value H_0: RMSEA <= 0.050                       NA\n#>   P-value H_0: RMSEA >= 0.080                       NA\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.000\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   BFLX ~                                                                \n#>     MNF        (c)    0.441    0.065    6.769    0.000    0.441    0.441\n#>     END        (b)    0.241    0.065    3.702    0.000    0.241    0.241\n#>   END ~                                                                 \n#>     MNF        (a)    0.450    0.064    6.982    0.000    0.450    0.450\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .BFLX              0.648    0.066    9.798    0.000    0.648    0.651\n#>    .END               0.793    0.081    9.798    0.000    0.793    0.797\n#> \n#> R-Square:\n#>                    Estimate\n#>     BFLX              0.349\n#>     END               0.203\n#> \n#> Defined Parameters:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     ab                0.109    0.033    3.271    0.001    0.109    0.109\n#>     total             0.550    0.060    9.125    0.000    0.550    0.550\n```\n:::\n\n\n\n\nGeneriamo un diagramma per visualizzare il modello stimato:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit,\n    layout = \"tree\", sizeMan = 7, sizeInt = 5, style = \"ram\",\n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 1.15,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nI coefficienti stimati con `lavaan` sono simili ma non identici a quelli ottenuti con Mplus. Ad esempio:\n\n- **Effetto diretto di MNF su BFLX:** $c' = 0.44$\n- **Effetto indiretto:** $a \\cdot b = 0.45 \\cdot 0.24 = 0.109$\n- **Effetto totale:** $c' + a \\cdot b = 0.44 + 0.109 = 0.55$\n\nI valori riportati nell'output di `lavaan` includono anche gli errori standard e i test per verificare se gli effetti siano significativamente diversi da zero.\n\nLe correlazioni tra le variabili possono essere calcolate combinando i coefficienti di percorso. Ad esempio:\n\n- Correlazione tra BFLX e MNF:\n\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  .44 + .45 * .24\n  #> [1] 0.548\n  ```\n  :::\n\n\n\n- Correlazione tra BFLX e END:\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  .24 + .44 * .45\n  #> [1] 0.438\n  ```\n  :::\n\n\n\n\nLa varianza spiegata dalle variabili esogene per le due variabili endogene è riportata nell'output di `lavaan`. Ad esempio, la varianza spiegata di END è calcolata come:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n0.45^2\n#> [1] 0.203\n```\n:::\n\n\n\n\nConsideriamo ora un modello più complesso [Fig. 4 in @barbeau2019path], che include ulteriori relazioni tra variabili:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- \"\n  BULS ~ MNF + BFLX\n  BFLX ~ END + MNF\n  END ~ MNS + MNF\n\"\n```\n:::\n\n\n\n\nIl modello esteso viene adattato ai dati utilizzando il seguente codice:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit2 <- sem(\n    mod,\n    sample.cov = dat_cov,\n    sample.nobs = 192\n)\n```\n:::\n\n\n\n\nI risultati vengono analizzati e rappresentati graficamente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(\n  fit2, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE\n)\n#> lavaan 0.6-19 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         9\n#> \n#>   Number of observations                           192\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 8.229\n#>   Degrees of freedom                                 3\n#>   P-value (Chi-square)                           0.042\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               239.501\n#>   Degrees of freedom                                 9\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.977\n#>   Tucker-Lewis Index (TLI)                       0.932\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)               -700.169\n#>   Loglikelihood unrestricted model (H1)       -696.054\n#>                                                       \n#>   Akaike (AIC)                                1418.338\n#>   Bayesian (BIC)                              1447.655\n#>   Sample-size adjusted Bayesian (SABIC)       1419.146\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.095\n#>   90 Percent confidence interval - lower         0.017\n#>   90 Percent confidence interval - upper         0.176\n#>   P-value H_0: RMSEA <= 0.050                    0.130\n#>   P-value H_0: RMSEA >= 0.080                    0.696\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   BULS ~                                                                \n#>     MNF               0.177    0.066    2.688    0.007    0.177    0.177\n#>     BFLX              0.533    0.066    8.085    0.000    0.533    0.533\n#>   BFLX ~                                                                \n#>     END               0.241    0.065    3.702    0.000    0.241    0.241\n#>     MNF               0.441    0.065    6.769    0.000    0.441    0.441\n#>   END ~                                                                 \n#>     MNS              -0.102    0.091   -1.116    0.264   -0.102   -0.102\n#>     MNF               0.378    0.091    4.140    0.000    0.378    0.378\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .BULS              0.578    0.059    9.798    0.000    0.578    0.581\n#>    .BFLX              0.648    0.066    9.798    0.000    0.648    0.651\n#>    .END               0.788    0.080    9.798    0.000    0.788    0.792\n#> \n#> R-Square:\n#>                    Estimate\n#>     BULS              0.419\n#>     BFLX              0.349\n#>     END               0.208\n\nsemPlot::semPaths(\n    fit2,\n    layout = \"tree\", sizeMan = 7, sizeInt = 1, style = \"ram\",\n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 1.15,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nI coefficienti ottenuti con `lavaan` sono confrontati con quelli riportati da @barbeau2019path:\n\n- **Varianza spiegata di END:** `lavaan` = 0.208, @barbeau2019path = 0.209\n- **Varianza spiegata di BFLX:** `lavaan` = 0.349, @barbeau2019path = 0.292\n- **Varianza spiegata di BULS:** `lavaan` = 0.419, @barbeau2019path = 0.478\n\nAd esempio, la correlazione tra MNF e BULS può essere calcolata come somma degli effetti diretti e indiretti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n-.71 * -.10 * .24 * .53 +\n.38 * .24 * .53 +\n.44 * .53 +\n.18\n#> [1] 0.471\n```\n:::\n\n\n\n\nIl valore risultante corrisponde al valore osservato nel campione (0.47), confermando la coerenza del modello stimato.\n\n## Modellare le Medie con la Path Analysis\n\nLa modellazione delle medie in un'analisi dei percorsi (*path analysis*) si concentra sulla stima e sull'interpretazione delle medie delle variabili manifeste, oltre che sulle relazioni tra di esse. Questo approccio consente di integrare le informazioni sulle medie direttamente nella struttura complessiva del modello, offrendo una visione più completa dei dati.\n\n### Passaggi per Modellare le Medie\n\n1. **Raccolta dei Dati:**  \n   È necessario disporre di una matrice di covarianza o di correlazione che riassuma le relazioni tra le variabili, oltre alle medie delle variabili stesse. Le medie sono fondamentali per modellare la struttura media del sistema.\n\n2. **Specifica del Modello:**  \n   Il modello deve includere sia la struttura di covarianza (che descrive le relazioni tra le variabili) sia la struttura delle medie (che descrive i valori medi delle variabili). Questo garantisce che il modello consideri non solo le relazioni, ma anche il comportamento medio delle variabili in studio.\n\n3. **Integrazione delle Medie:**  \n   - Per le variabili **esogene** (quelle che non dipendono da altre variabili nel modello), vengono considerate direttamente le medie osservate.  \n   - Per le variabili **endogene** (quelle influenzate da altre variabili nel modello), è necessario includere le intercette, che rappresentano i valori medi previsti nel modello.\n\n4. **Costante \"1\" per le Medie:**  \n   Per modellare le medie, si aggiunge una costante \"1\" a tutte le equazioni che descrivono le variabili manifeste in `lavaan`. Questo passaggio permette di includere esplicitamente le medie nella struttura del modello.\n\n5. **Stima del Modello:**  \n   Durante la stima, il modello calcola le medie previste per ciascuna variabile endogena, basandosi sui valori medi delle variabili esogene e sui coefficienti di percorso. Questi calcoli consentono di confrontare le medie previste con quelle osservate, valutando l'aderenza del modello ai dati.\n\n### Calcolo delle Medie Previste \n\nLa path analysis permette di modellare non solo le relazioni tra variabili, ma anche le loro medie. Per una variabile dipendente $Y$, il modello base è:\n\n$$\nY = c_0 + \\sum_{i=1}^p b_i X_i + \\varepsilon ,\n$$\n\ndove:\n\n- $c_0$ è l'intercetta (il valore atteso di Y quando tutte le X sono zero),\n- $b_i$ sono i coefficiente di percorso che collegano $X_i$ a $Y$,\n- $X_i$ sono le variabili predittive,\n- $\\varepsilon$ è il termine di errore (con media zero).\n\nLa media prevista di $Y$, indicata con $\\mu_Y$, è calcolata come:\n\n$$\n\\mu_Y = c_0 + \\sum_{i=1}^p b_i \\mu_{X_i} ,\n$$\n\ndove $\\mu_{X_i}$ rappresenta la media osservata della variabile $X_i$.\n\nÈ importante notare che:\n\n- L'intercetta $c_0$ contribuisce direttamente alla media.\n- Ogni predittore contribuisce attraverso il prodotto $b_i \\mu_{X_i}$.\n- L'errore $\\varepsilon$ non influenza la media prevista poiché ha media zero.\n\nPer valutare l'accuratezza del modello rispetto alle medie, definiamo il residuo di media:\n\n$$\n\\text{Residuo di Media} = \\bar{Y} - \\mu_Y ,\n$$\n\ndove:\n\n- $\\bar{Y}$ è la media osservata nella variabile dipendente;\n- $\\mu_Y$ è la media prevista dal modello.\n\nEsaminiamo un esempio pratico. Consideriamo un modello modello con due predittori:\n\n$$Y = 2.5 + 0.6X_1 - 0.3X_2 + \\varepsilon$$\n\ncon:\n\n- $\\mu_{X_1} = 4$ (media di $X_1$);\n- $\\mu_{X_2} = 3$ (media di $X_2$).\n\nLa media prevista si calcola come:\n\n$$\\mu_Y = 2.5 + (0.6 \\cdot 4) + (-0.3 \\cdot 3) = 4.0 .$$\nInterpretazione dei componenti:\n\n- Intercetta: 2.5.\n- Contributo di $X_1$: $0.6 \\cdot 4 = 2.4$.\n- Contributo di $X_2$: $-0.3 \\cdot 3 = -0.9$.\n- Totale: $2.5 + 2.4 - 0.9 = 4.0$.\n\nSe la media osservata di $Y$ fosse $\\bar{Y} = 4.2$, il residuo di media sarebbe:\n\n$$\n\\text{Residuo di Media} = \\bar{Y} - \\mu_Y = 4.2 - 4.0 = 0.2 .\n$$\n\nI residui delle medie forniscono un'indicazione della bontà del modello in termini di previsione delle medie osservate. Se i residui sono grandi o sistematicamente devianti, ciò potrebbe indicare la necessità di rivedere la specificazione del modello, ad esempio aggiungendo variabili o ricalibrando i coefficienti.\n\nIn conclusione, il calcolo delle medie previste in un'analisi dei percorsi consente di integrare la struttura media nel modello e di confrontare queste previsioni con i dati osservati. Questo processo rappresenta uno strumento utile per valutare l'adeguatezza del modello e identificare eventuali aree di miglioramento.\n\n## Riflessioni Conclusive\n\nIl diagramma di un modello di *path analysis* rappresenta non solo uno strumento analitico, ma anche un mezzo di comunicazione. Un diagramma completo fornisce una rappresentazione visiva chiara delle relazioni tra le variabili e una guida diretta su come specificare il modello in termini computazionali. Ogni elemento del diagramma — come frecce, nodi e annotazioni — traduce i parametri del modello, sia liberi sia fissi, in istruzioni visive che possono essere facilmente codificate.\n\nQuesta rappresentazione grafica, spesso basata sul simbolismo RAM di McArdle e McDonald, permette ai ricercatori di comprendere rapidamente la struttura del modello. Ad esempio: \n\n- Le **frecce unidirezionali** rappresentano i coefficienti di percorso, indicando relazioni causali o di influenza diretta.  \n- Le **frecce bidirezionali** raffigurano le covarianze o correlazioni tra variabili.  \n- I **nodi** corrispondono alle variabili osservate o latenti.  \n\nOgni annotazione sul diagramma — come etichette per i parametri o costanti di scala — comunica informazioni essenziali su come ciascun componente del modello deve essere interpretato e implementato. Questo approccio facilita non solo la comprensione delle relazioni complesse tra variabili, ma rende anche più immediato il processo di traduzione del modello visivo in sintassi utilizzabile nei software statistici.\n\nLa *path analysis* offre uno strumento potente per decomporre e interpretare le relazioni tra variabili. Attraverso la decomposizione di correlazioni o covarianze, è possibile delineare in modo chiaro:\n\n- Le **relazioni dirette** tra variabili, espresse dai coefficienti di percorso.  \n- Le **relazioni indirette**, che emergono attraverso l'interazione di più percorsi nel modello.  \n- Le **associazioni complessive**, ottenute dalla combinazione degli effetti diretti e indiretti.\n\nQuesta capacità di mappare le potenziali connessioni causali e le interazioni tra le variabili rende la *path analysis* uno strumento prezioso non solo per l'analisi statistica, ma anche per l'interpretazione teorica. Grazie alla sua natura visiva e strutturata, essa facilita il processo di comprensione, comunicazione e applicazione delle relazioni modellate, consentendo ai ricercatori di descrivere in modo chiaro e accessibile le dinamiche complesse tra variabili in studio.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] ggokabeito_0.1.0  see_0.10.0        MASS_7.3-64       viridis_0.6.5    \n#>  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#>  [9] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n#> [13] lavaan_0.6-19     psych_2.4.12      scales_1.3.0      markdown_1.13    \n#> [17] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#> [25] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-12          igraph_2.1.4       \n#>  [22] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-2        R6_2.5.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-2         timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [46] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [49] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [52] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [55] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [58] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8      \n#>  [61] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [64] tzdb_0.4.0          data.table_1.16.4   hms_1.1.3          \n#>  [67] car_3.1-3           sem_3.1-16          pillar_1.10.1      \n#>  [70] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [73] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [76] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [79] reformulas_0.4.0    stats4_4.4.2        xfun_0.50          \n#>  [82] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [85] pacman_0.5.1        boot_1.3-31         evaluate_1.0.3     \n#>  [88] codetools_0.2-20    mi_1.1              cli_3.6.3          \n#>  [91] RcppParallel_5.1.10 rpart_4.1.24        xtable_1.8-4       \n#>  [94] Rdpack_2.6.2        munsell_0.5.1       Rcpp_1.0.14        \n#>  [97] coda_0.19-4.1       png_0.1-8           XML_3.99-0.18      \n#> [100] parallel_4.4.2      jpeg_0.1-10         lme4_1.1-36        \n#> [103] mvtnorm_1.3-3       openxlsx_4.2.8      rlang_1.1.5        \n#> [106] multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "01_path_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
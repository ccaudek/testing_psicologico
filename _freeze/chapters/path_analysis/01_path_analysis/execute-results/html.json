{
  "hash": "21d3c9e56bf1dfaa802e8acb41382c30",
  "result": {
    "engine": "knitr",
    "markdown": "# Analisi dei percorsi {#sec-path-analysis-intro}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- Comprendere il ruolo delle visualizzazioni nell‚Äôanalisi dei percorsi e la loro importanza per comunicare le relazioni tra variabili.\n- Identificare e distinguere le variabili esogene ed endogene in un path diagram.\n- Utilizzare i path diagram per rappresentare graficamente le relazioni dirette, indirette e totali tra le variabili.\n- Interpretare i parametri della path analysis.\n- Applicare le regole di Wright per decomporre correlazioni e covarianze in base ai percorsi causali.\n- Modellare le medie delle variabili in un‚Äôanalisi dei percorsi, integrando le informazioni sulle medie nella struttura complessiva del modello.\n- Eseguire l'analisi dei percorsi con `lavaan`.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere *Path analysis in Mplus: A tutorial using a conceptual model of psychological and behavioral antecedents of bulimic symptoms in young adults* di @barbeau2019path.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, semPlot, tidyr, ggdag, dagitty)\n```\n:::\n\n\n\n:::\n\n## Introduzione\n\nLe visualizzazioni rivestono un ruolo fondamentale nel comunicare in modo chiaro e sintetico le relazioni tra variabili. Questo √® particolarmente evidente quando si opera con modelli di equazioni strutturali (SEM) che delineano una rete di interconnessioni tra variabili sia osservabili che latenti. In tali contesti, i ricercatori frequentemente si avvalgono di strumenti grafici per agevolare la specificazione e l'esplicitazione del modello, oltre che per presentare in maniera comprensibile i risultati ottenuti.\n\nL'analisi del percorso, o *path analysis*, √® una tecnica statistica multivariata utilizzata per esaminare e descrivere le relazioni causali tra un insieme di variabili. Questo metodo si avvale di modelli grafici, noti come **diagrammi di percorso**, che rappresentano le relazioni ipotizzate tra le variabili, illustrando graficamente le relazioni dirette, indirette e reciproche tra di esse.\n\nIl fulcro dell'analisi del percorso √® la decomposizione e la quantificazione delle relazioni tra le variabili, permettendo agli analisti di distinguere tra effetti diretti, indiretti e totali: \n\n- gli **effetti diretti** corrispondono all'influenza immediata che una variabile esercita su un'altra, \n- gli **effetti indiretti** rappresentano l'impatto mediato attraverso una o pi√π variabili intermedie,\n- l'**effetto totale** √® la somma degli effetti diretti e indiretti.\n\n@wright1934method, genetista pionieristico attivo presso il Dipartimento dell'Agricoltura degli Stati Uniti (USDA) negli anni '30 del Novecento, svilupp√≤ negli anni '20 i primi diagrammi di percorso (*path diagrams*), strumenti innovativi per rappresentare visivamente relazioni causali all'interno di modelli di equazioni strutturali (SEM). Questa metodologia, inizialmente applicata in genetica quantitativa, si diffuse progressivamente in ambito multidisciplinare, affermandosi come uno strumento efficace per distinguere gli effetti diretti e indiretti tra variabili, oltre a fornire un quadro formale per testare la robustezza e la validit√† delle ipotesi teoriche sottostanti ai modelli. \n\n## Path diagram\n\nNel *path diagram* √® possibile distinguere due tipi di variabili: quelle che sono influenzate da altre variabili nel sistema e quelle che fungono da sorgenti di effetti. \n\n- **Variabili esogene**: rappresentano elementi esterni al sistema in esame. Esse agiscono come variabili indipendenti, generando effetti in modo causale senza essere influenzate da altre variabili presenti nel modello. Nel diagramma, le loro cause si trovano al di fuori del sistema rappresentato.\n\n- **Variabili endogene**: sono quelle che possono assumere il doppio ruolo di risultati (essendo influenzate da altre variabili) e di cause (influenzando ulteriori variabili). In alcuni casi, svolgono un ruolo esclusivamente dipendente. Le cause delle variabili endogene sono sempre incluse all‚Äôinterno del path diagram.\n\nQuesta distinzione riflette quella tra variabili indipendenti e dipendenti nei modelli lineari, ma con una maggiore enfasi sulla natura causale e sulla posizione delle variabili nel sistema rappresentato.\n\nUn *path diagram* (diagramma di percorso) utilizza specifici simboli grafici per rappresentare le variabili e le loro relazioni:\n\n1. **Variabili osservate** (o indicatori): rappresentate con **quadrati** o **rettangoli**.\n2. **Variabili latenti** (come fattori comuni con pi√π indicatori): rappresentate con **cerchi** o **ellissi**.\n\nIl *path diagram* evidenzia le interazioni tra le variabili di interesse, distinguendo i legami causali da quelli associativi:\n\n- **Frecce unidirezionali** ($\\rightarrow$): indicano relazioni causali. La variabile alla punta della freccia √® influenzata da quella alla base.\n- **Frecce curve bidirezionali** ($\\leftrightarrow$): rappresentano relazioni associative, indicando covarianze (nella soluzione non standardizzata) o correlazioni (nella soluzione standardizzata), senza implicare una relazione causale diretta.\n\nL‚Äôassenza di una freccia tra due variabili implica che non vi √® correlazione o relazione causale diretta tra esse nel modello. Il diagramma, quindi, sintetizza visivamente le ipotesi teoriche sulle relazioni tra le variabili.\n\nNella @fig-path-01, si illustrano le relazioni tra nove variabili osservate e tre variabili latenti mediante il path diagram. Una freccia curva bidirezionale che si collega a una singola variabile rappresenta la varianza residua della variabile, ovvero la quota di varianza non spiegata dalle relazioni causali illustrate nel diagramma di percorso. \n\n::: {#fig-path-01}\n![](../../figures/path_01.png){width=\"40%\"}\n\nDiagramma di percorso per un modello a tre fattori comuni.\n:::\n\nUn **triangolo** contenente il numero 1 simboleggia la media di una variabile (qui non presente).\n\n## Parametri nei Modelli di Equazioni Strutturali\n\nI parametri nei modelli di equazioni strutturali possono essere categorizzati come segue, quando le medie non sono oggetto di analisi:\n\n1. **Varianze e Covarianze delle Variabili Esogene:** \n   - Questi parametri rappresentano la variabilit√† intrinseca delle variabili esogene (quelle non influenzate da altre nel modello) e le relazioni reciproche tra di esse.\n\n2. **Effetti Diretti sulle Variabili Endogene da Altre Variabili:**\n   - Questi parametri descrivono come le variabili endogene sono influenzate direttamente da altre variabili nel modello.\n\nIn termini di specificazione, un parametro nel modello pu√≤ essere classificato come libero, fisso o vincolato:\n\n- un **parametro libero** √® stimato dal software statistico utilizzando i dati a disposizione.\n- un **parametro fisso**  √® definito per essere uguale a una costante specificata a priori. In questo caso, il software accetta il valore costante come stima, indipendentemente dai dati. Ad esempio, l'ipotesi che la variabile $X$ non abbia effetti diretti su $Y$ corrisponde alla specifica che il coefficiente per il percorso da $X$ a $Y$ sia fissato a zero.\n- un **parametro vincolato** segue certe restrizioni imposte nell'analisi, che possono essere basate su teorie o ipotesi precedenti. Ad esempio, l'analista pu√≤ assumere che due parametri siano uguali.\n\n## Gradi di libert√† nei modelli parametrici\n\nIn statistica, la complessit√† di un modello parametrico √® vincolata dalla quantit√† di **informazioni statistiche** disponibili nei dati, ossia dal numero di varianze e covarianze uniche che si possono calcolare a partire dalla matrice di covarianza campionaria. Questo numero **non dipende dalla dimensione del campione** ($N$), ma esclusivamente dal **numero di variabili osservate** ($\\nu$).\n\n### Calcolo delle informazioni disponibili\n\nLa quantit√† totale di informazioni statistiche ($p$) √® data dalla seguente formula:\n\n$$\np = \\frac{\\nu(\\nu + 1)}{2},\n$$ {#eq-degrees-of-freedom-def}\n\ndove $\\nu$ √® il numero di variabili osservate. Questo totale include:\n\n- $\\nu$ varianze (gli elementi sulla diagonale della matrice di covarianza),\n- $\\frac{\\nu(\\nu - 1)}{2}$ covarianze uniche (gli elementi sotto la diagonale).\n\n**Esempio:** Se $\\nu = 5$ variabili osservate, allora:\n\n$$\np = \\frac{5 \\times 6}{2} = 15.\n$$\n\nLe 15 informazioni statistiche disponibili comprendono quindi **5 varianze** e **10 covarianze uniche**. Un modello parametrico con 5 variabili osservate pu√≤ quindi stimare **al massimo 15 parametri liberi**. Aumentare la numerosit√† campionaria ($N$) **non incrementa** la quantit√† di informazioni statistiche, che √® invece determinata **solo** da $\\nu$. Per aumentare le informazioni disponibili, √® necessario includere **pi√π variabili osservate**.\n\n### Gradi di libert√† del modello\n\nI **gradi di libert√†** del modello, indicati con $df_M$, rappresentano la differenza tra le informazioni disponibili ($p$) e il numero di parametri liberi ($q$) che il modello cerca di stimare:\n\n$$\ndf_M = p - q.\n$$ {#eq-degrees-of-freedom-model-def}\n\nInterpretazioni possibili:\n\n- **$df_M \\geq 0$**: Il modello √® **identificabile**, cio√® i parametri possono essere stimati in modo univoco.\n- **$df_M < 0$**: Il modello √® **non identificabile**: ci sono pi√π parametri da stimare che informazioni disponibili, con conseguente molteplicit√† (infinita) di soluzioni.\n\nIn caso di $df_M < 0$, il modello deve essere modificato, ad esempio **riducendo il numero di parametri liberi** tramite vincoli o fissando alcuni parametri a valori noti. In caso contrario, il software di modellazione restituir√† errori di identificabilit√†.\n\n### Interpretazione dei gradi di libert√†\n\n1. **$df_M = 0$**: Il modello si adatta perfettamente ai dati, ma questa perfetta aderenza √® **meccanica** e **non garantisce validit√† o generalizzabilit√†**.\n\n2. **$df_M > 0$**: Il modello ammette una **discrepanza residua** tra dati osservati e stime. In tali condizioni, il modello pu√≤ essere testato e, in caso di mancanza di adattamento tra le predizioni del modello e i dati osservati, pu√≤ essere rifiutato.\n\nCome osservano Raykov e Marcoulides (2006), i gradi di libert√† rappresentano le ‚Äú**dimensioni lungo cui un modello pu√≤ essere rifiutato**‚Äù. Un modello con pi√π gradi di libert√† che si adatta bene ai dati offre quindi **maggiore credibilit√†**.\n\n### Principio di parsimonia\n\nNella scelta tra modelli, a parit√† di adattamento, √® preferibile selezionare il modello pi√π **parsimonioso**, cio√® quello con **meno parametri liberi**, purch√© **coerente con la teoria**. Questo principio √® fondamentale per evitare **sovradattamento** (overfitting) e migliorare la **generalizzabilit√†** del modello.\n\nIn sintesi, i **gradi di libert√†** costituiscono una misura chiave dell‚Äôequilibrio tra **complessit√† del modello** e **informazioni disponibili nei dati**. La loro corretta interpretazione √® essenziale per valutare l‚Äôidentificabilit√†, la validit√† e la parsimonia di un modello parametrico.\n\n\n## Varianza Residua nelle Variabili Endogene\n\nLa @fig-kline_7_2 illustra la relazione tra due variabili osservabili e il modo in cui la varianza residua viene trattata nei modelli a percorsi. L'effetto totale di $X$ su $Y$ √® rappresentato tramite un percorso diretto, che evidenzia l'effetto causale lineare di $X$ su $Y$. Nel diagramma:\n\n- la **varianza di $X$**, una variabile esogena, √® un parametro libero e viene rappresentata da una freccia curva bidirezionale (secondo il simbolismo RAM), che indica una varianza;\n- la **varianza di $Y$**, una variabile endogena, non √® libera, poich√© include un termine di disturbo o errore ($D$), una variabile latente che rappresenta la porzione di varianza in $Y$ non spiegata da $X$.\n\n::: {#fig-kline_7_2}\n![](../../figures/kline_7_2.png){width=\"80%\"}\n\n**Diagramma di percorso**: (a) rappresentazione esplicita secondo il modello RAM; (b) versione semplificata. (Adattata da @kline2023principles).\n:::\n\nNel pannello **(a)**, il valore numerico \"1\" accanto al percorso tra il termine di disturbo ($D$) e $Y$ √® una costante di scala. Questo valore fissa una metrica per il termine di disturbo, necessaria per stimare la varianza latente. Questo approccio √® noto come vincolo di identificazione del carico unitario (**unit loading identification** constraint, ULI). Tale costante informa il software di suddividere la varianza totale di $Y$ in due componenti ortogonali:\n\n1. la varianza spiegata da $X$;\n2. la varianza residua, rappresentata dal termine di disturbo ($var_D$).\n\nNel pannello **(b)**, la stessa relazione √® presentata in modo pi√π sintetico. Qui, il termine di disturbo non √® rappresentato esplicitamente, ma la varianza residua pu√≤ essere descritta in modo equivalente con una freccia curva bidirezionale che denota $1 \\times var_D \\times 1$.\n\nConfronto tra le rappresentazioni:\n\n- **rappresentazione dettagliata (@fig-kline_7_2 pannello a)**: include tutti i termini espliciti, come il termine di disturbo e i vincoli di scala. √à utile per comprendere la struttura completa del modello.\n- **rappresentazione sintetica (@fig-kline_7_2 pannello b)**: Ommette i simboli per i parametri di varianza e il termine di disturbo, fornendo una visione semplificata delle relazioni principali.\n\nEntrambe le rappresentazioni descrivono lo stesso modello, ma con diversi livelli di dettaglio. La scelta dipende dall'obiettivo: chiarezza concettuale o sintesi grafica.\n\n### Rappresentazioni Alternative della Varianza Residua\n\nUn altro modo per rappresentare la varianza residua di $Y$ consiste nell‚Äôattribuire $1$ a $var_D$ e utilizzare il valore $\\sqrt{var_D}$ per la freccia causale da $D$ a $Y$. Il risultato finale resta invariato, poich√© la varianza residua di $Y$ sarebbe comunque espressa come:\n\n$$\n\\sqrt{var_D} \\times 1 \\times \\sqrt{var_D}.\n$$\n\n### Fonti della Varianza Residua\n\nLa varianza residua ($var_D$) rappresenta la porzione di varianza in $Y$ non spiegata da $X$. Essa pu√≤ derivare da diverse fonti, tra cui:\n\n1. **variazione sistematica da cause non misurate**: Fattori non inclusi nel modello che influenzano sistematicamente $Y$;\n2. **variazione casuale intrinseca**: Variabilit√† naturale che esiste indipendentemente dalle relazioni modellate;\n3. **errore di misurazione casuale**: Errori nel processo di misurazione, stimabili tramite analisi di affidabilit√† degli strumenti;\n4. **mancata specificazione della forma funzionale corretta**: Varianza dovuta a un‚Äôerrata rappresentazione della relazione causale (ad esempio, una relazione modellata come lineare quando √® in realt√† non lineare).\n\nNel pannello **(a)**, il percorso da $D$ a $Y$ rappresenta l'effetto diretto cumulativo di queste fonti sulla variabile endogena $Y$. Sebbene teoricamente distinguibili, queste fonti spesso si sovrappongono o interagiscono nella pratica.\n\n### Gestione della Varianza Residua nei Software SEM\n\nNei software per l‚Äôanalisi SEM, i termini di disturbo vengono gestiti automaticamente. Ad esempio, in **lavaan**, il comando:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nY ~ X\n#> Y ~ X\n```\n:::\n\n\n\n\nistruisce il software a regredire $Y$ su $X$ e a trattare il termine di disturbo come parametro libero. Questo comando:\n\n1. definisce l'effetto causale di $X$ su $Y$;\n2. stabilisce che la varianza di $X$ e quella del termine di disturbo di $Y$ siano parametri da stimare.\n\n## Requisiti per l‚ÄôIdentificazione del Modello\n\nPer garantire l‚Äôidentificazione del modello, sono necessari due requisiti fondamentali:\n\n1. i **gradi di libert√†** ($df_M$) devono essere maggiori o uguali a zero:\n   $$\n   df_M = p - q,\n   $$\n   dove $p$ √® il numero di informazioni statistiche disponibili e $q$ il numero di parametri liberi;\n2. ogni variabile latente, inclusi i termini di disturbo, deve avere una **scala definita**.\n\n## Considerazioni sugli errori di misurazione nei modelli a percorsi\n\nRiprendendo la discussione relativa alla figura @fig-kline_7_2, possiamo evidenziare tre ipotesi fondamentali implicite nei modelli a percorsi:\n\n1. **Affidabilit√† della variabile esogena ($X$)**: si assume che la variabile esogena $X$ sia misurata senza errore, ovvero con un'affidabilit√† perfetta ($r_{XX} = 1.0$). In altre parole, i punteggi osservati riflettono esattamente il costrutto teorico, senza contaminazioni da errore casuale.\n2. **Corretta specificazione della direzione causale**: si presume che la relazione da $X$ a $Y$ sia correttamente specificata, unidirezionale e di natura strettamente lineare. Si esclude quindi che vi siano influenze inverse o non lineari non modellate.\n3. **Assenza di cause comuni non misurate**: si ipotizza che eventuali determinanti latenti di $Y$ siano indipendenti da $X$. Questa assunzione esclude la presenza di variabili non osservate che influenzano contemporaneamente sia $X$ che $Y$ ‚Äî situazione che costituirebbe un errore di specificazione del modello.\n\nQueste ipotesi sono coerenti con quelle adottate nei modelli di regressione multipla classici, dove si assume che le variabili indipendenti (i predittori) siano esenti da errore di misurazione. Nei modelli a percorsi, tale assunzione √® ancora pi√π stringente, poich√© le variabili esogene non includono termini di errore: non √® quindi possibile rappresentare direttamente l‚Äôerrore casuale associato a queste variabili all'interno del modello.\n\nAl contrario, le variabili **endogene** nei modelli a percorsi includono esplicitamente un termine di errore (o \"disturbo\"), che consente di tenere conto dell‚Äôerrore di misurazione o di altre influenze non modellate.\n\n### Effetti dell‚Äôerrore di misurazione\n\nNel caso pi√π semplice di una **regressione bivariata**, gli effetti dell‚Äôerrore di misurazione variano in base a quale variabile sia affetta:\n\n- Se **solo la variabile dipendente $Y$** √® misurata con errore, ci√≤ comporta un **aumento dell‚Äôerrore standard** della stima di regressione, una **riduzione del valore di $R^2$** e una **diminuzione del coefficiente di regressione standardizzato**, poich√© l‚Äôerrore in $Y$ introduce variabilit√† non spiegata.\n- se **solo la variabile indipendente $X$** √® misurata con errore (ma non $Y$), si osserva in genere un **bias negativo**: i coefficienti di regressione vengono **sottostimati sistematicamente**, avvicinandosi a zero rispetto ai loro valori reali nella popolazione.\n- se **entrambe le variabili ($X$ e $Y$)** presentano errore di misurazione, la situazione diventa pi√π complessa:\n  - Se gli errori sono **indipendenti**, si verifica solitamente un **bias negativo** sui coefficienti.\n  - se invece gli errori di misurazione sono **correlati** (cio√® condividono una componente comune), la stima del coefficiente pu√≤ risultare **sovrastimata**, generando un **bias positivo**.\n\nPertanto, **l‚Äôerrore di misurazione non genera necessariamente una sottostima**: la direzione e l‚Äôentit√† del bias dipendono dalla natura e dalla struttura degli errori.\n\nQuesti effetti sono particolarmente problematici nei modelli con pi√π predittori esogeni correlati tra loro: **errori di misurazione non modellati nelle variabili esogene possono distorcere in modo significativo le stime dei coefficienti di percorso**, compromettendo l‚Äôinterpretazione causale.\n\n### Raccomandazioni metodologiche\n\nPer limitare questi rischi, √® fondamentale **valutare l'affidabilit√† delle misure** utilizzate per le variabili esogene. Stimare in modo accurato l‚Äôaffidabilit√† (ad esempio tramite l‚Äôalfa di Cronbach o altre tecniche appropriate) consente di quantificare l‚Äôerrore di misurazione e, se necessario, **modellarlo esplicitamente** mediante approcci alternativi, come i **modelli di equazioni strutturali con variabili latenti**.\n\nIn conclusione, una valutazione attenta dell‚Äôaffidabilit√† dei predittori e una corretta gestione dell‚Äôerrore di misurazione sono condizioni essenziali per assicurare **l‚Äôintegrit√†, la validit√† e la generalizzabilit√†** dei risultati ottenuti dai modelli a percorsi.\n\n## Direzionalit√† Causale e Forma Funzionale della Relazione X-Y\n\nL'assunzione che la relazione tra le variabili $X$ e $Y$ sia lineare, come presentato nella @fig-kline_7_2, pu√≤ essere esaminata attraverso l'analisi dei dati. Se si osserva che la relazione √® curvilinea, si pu√≤ adeguare l'analisi per attenuare il presupposto di linearit√†. Ci√≤ pu√≤ essere realizzato attraverso metodi come la regressione polinomiale o la regressione non parametrica, che permettono di modellare relazioni pi√π complesse rispetto a un semplice modello lineare.\n\nTuttavia, **la direzionalit√† dell'effetto causale** rappresenta una sfida differente e **non √® direttamente testabile attraverso metodi statistici** standard. Nell'ambito dei modelli SEM, le direzioni degli effetti causali sono generalmente ipotizzate piuttosto che empiricamente verificate. Questo perch√© √® possibile costruire modelli SEM equivalenti che utilizzano le stesse variabili e hanno lo stesso numero di gradi di libert√† ($df_M$), ma con direzioni inverse di alcuni effetti causali. Inoltre, entrambi i modelli, nonostante le differenze nelle direzionalit√† causali, **mostreranno lo stesso grado di adattamento ai dati osservati**.\n\nUn'ulteriore ragione per cui la direzionalit√† causale √® tipicamente assunta piuttosto che testata in SEM risiede nella natura degli studi SEM stessi. La maggior parte degli studi SEM si basa su disegni trasversali, dove tutte le variabili sono misurate contemporaneamente, senza una chiara precedenza temporale. In questi contesti, l'unica base per definire la direzionalit√† causale √® l'argomentazione teorica del ricercatore, che deve giustificare perch√© si presume che $X$ influenzi $Y$ e non viceversa, o perch√© non si considera una relazione di feedback o causazione reciproca tra le due variabili.\n\nDi conseguenza, la metodologia SEM **non √®** intrinsecamente una tecnica per la scoperta di relazioni causali. Se un modello √® corretto, SEM pu√≤ essere utilizzato per stimare le direzioni, le dimensioni e la precisione degli effetti causali. Tuttavia, questo non √® il modo in cui i ricercatori tipicamente impiegano le analisi SEM. Piuttosto, un modello causale viene ipotizzato e poi adattato ai dati basandosi sulle assunzioni delineate. Se queste assunzioni risultano essere errate, anche i risultati dell'analisi saranno invalidi. Questo enfatizza il punto sollevato da Pearl (2000), che sostiene che \n\n> le ipotesi causali sono un prerequisito essenziale per validare qualsiasi conclusione causale (p. 136). \n\nQuesto implica la necessit√† di una solida base teorica e concettuale nella formulazione di modelli causali nella modellazione SEM.\n\n## Confondimento ed endogeneit√† nei modelli parametrici\n\nNel contesto della teoria dei modelli statistici, **l‚Äôendogeneit√†** si verifica quando una variabile all‚Äôinterno del modello √® **correlata con il termine di errore** della variabile dipendente. Questa condizione viola le assunzioni fondamentali della regressione lineare e dei modelli a percorsi, compromettendo la validit√† delle stime e portando a inferenze potenzialmente fuorvianti riguardo alle relazioni causali tra le variabili.\n\nNel diagramma a catena contratta mostrato in @fig-kline_7_2a (pannello a), l‚Äôendogeneit√† √® rappresentata graficamente da una **covarianza tra la variabile causale osservata $X$ e il termine di disturbo di $Y$**. Questo collegamento suggerisce che $X$ non √® realmente esogena: √® influenzata da fattori non modellati che agiscono anche su $Y$, violando cos√¨ l‚Äôassunzione di indipendenza tra predittore e disturbo.\n\nIl modello rappresentato in @fig-kline_7_2a (a) **non √® identificabile** per due motivi principali:\n\n1. **gradi di libert√† negativi ($df_M = -1$)**: Il numero di parametri da stimare supera il numero di informazioni statistiche disponibili. In termini pratici, il modello √® \"troppo complesso\" rispetto ai dati osservabili e non pu√≤ essere stimato in modo univoco.\n2. **percorso di confondimento non controllato tra $X$ e il disturbo di $Y$**: Il percorso \"back-door\" che collega $X$ al disturbo latente $D$ di $Y$ implica che esiste una **causa comune non misurata** che influenza entrambe le variabili. Poich√© $D$ √® latente, non √® possibile \"chiudere\" il percorso attraverso l‚Äôinclusione di covariate osservabili, lasciando la relazione tra $X$ e $Y$ potenzialmente distorta.\n\nIn questo contesto, **l‚Äôendogeneit√†** riflette una violazione dell‚Äôindipendenza tra la variabile indipendente e il termine di errore, condizione che impedisce di attribuire un‚Äôinterpretazione causale chiara ai coefficienti stimati.\n\n::: {#fig-kline_7_2a}\n![](../../figures/kline_7_2a.png){width=\"80%\"}\n\n**Endogeneit√† in una catena contratta (a)**. Identificazione del modello attraverso l‚Äôinclusione di un **proxy (P)** per una causa comune non misurata (b), e mediante l‚Äôuso di una **variabile strumentale (Z)** che corregge anche per l‚Äôerrore di misurazione in $X$ (c). Tutti i diagrammi utilizzano una rappresentazione compatta. (Figura tratta da @kline2023principles)\n:::\n\n### Cause dell‚Äôendogeneit√†\n\nL‚Äôendogeneit√† pu√≤ emergere da diverse condizioni:\n\n1. **confonditore non misurato**: esiste una variabile latente che influenza sia $X$ che $Y$;\n2. **errore di misurazione in $X$**: se $X$ √® misurata in modo imperfetto (ad esempio, $r_{XX} < 1.0$), le sue correlazioni con $Y$ possono risultare distorte;\n3. **causalit√† reciproca**: $X$ e $Y$ si influenzano a vicenda (feedback loop);\n4. **errori autoregressivi**: quando $X$ √® una versione ritardata di $Y$ e gli errori sono correlati nel tempo;\n5. **autoregressione spaziale**: i valori di $X$ o $Y$ per un caso dipendono da quelli di casi vicini nello spazio (es. nei dati geografici).\n\n### Strategie di correzione\n\nEsistono due principali strategie per affrontare l‚Äôendogeneit√†:\n\n1. **Uso di *proxy* per cause non misurate.**\n\n    Nel pannello **(b)** di @fig-kline_7_2a, il problema dell‚Äôendogeneit√† viene affrontato includendo una **variabile proxy ($P$)** che rappresenta una stima indiretta di una causa comune latente. \n    \n    **Esempio**: supponiamo di voler studiare l‚Äôeffetto dello **stress** ($X$) sulle **prestazioni accademiche** ($Y$). Una possibile causa comune non misurata √® il **benessere psicologico generale**, che potrebbe influenzare sia lo stress che le prestazioni. Se il benessere non √® misurabile direttamente, potremmo utilizzare un proxy come **l‚Äôattivit√† fisica regolare** ($P$), che la letteratura mostra essere associata al benessere e quindi, indirettamente, anche a stress e rendimento.\n    \n    Includere $P$ nel modello aiuta a \"controllare\" per questa causa comune, riducendo il bias nelle stime dell‚Äôeffetto di $X$ su $Y$.\n\n2. **Uso di *variabili strumentali* (strumenti, $Z$).**\n\n    Nel pannello **(c)** di @fig-kline_7_2a, si affrontano simultaneamente i problemi di confondimento e di **errore di misurazione in $X$** utilizzando una **variabile strumentale ($Z$)**. Questa tecnica √® tipica della **regressione a due stadi (2SLS)**.\n    \n    La variabile strumentale $Z$ deve soddisfare due condizioni:\n      - essere **correlata con $X$**, ma\n      - essere **indipendente dal disturbo** di $Y$ e da qualsiasi confonditore non osservato.\n\n    In questo approccio, $Z$ viene usata per stimare una componente \"purificata\" di $X$, denominata $X_Z$, che viene poi utilizzata nella seconda regressione per stimare l‚Äôeffetto su $Y$. Se le assunzioni dello strumento sono soddisfatte, questo metodo permette di ottenere stime **non distorte**, anche in presenza di errore di misurazione o confondimento latente.\n\n    > √à importante notare che, nel pannello (c), $X$ √® rappresentata come variabile endogena, ma **non tutti i ricercatori mostrano esplicitamente le variabili strumentali nei diagrammi dei modelli**, anche se sono incluse nelle analisi.\n\nIn conclusione, **l‚Äôendogeneit√† rappresenta una minaccia centrale alla validit√† causale nei modelli parametrici**. Quando una variabile indipendente √® influenzata da fattori non osservati o da errori di misurazione, le stime dei coefficienti possono risultare gravemente distorte. Strategie come l‚Äôinclusione di proxy o l‚Äôimpiego di variabili strumentali offrono soluzioni potenti, ma richiedono **accurata giustificazione teorica ed empirica** per essere valide.\n\nPer chiarire ulteriormente questi concetti, esamineremo separatamente il modello autoregressivo e l'autoregressione spaziale.\n\n### Modello Autoregressivo\n\nUn modello autoregressivo √® un tipo di modello statistico utilizzato per analizzare dati sequenziali o temporali. In un modello autoregressivo, si prevedono i valori futuri di una variabile basandosi sui suoi valori passati. Questo √® particolarmente utile in studi longitudinali o in serie temporali dove si misura la stessa variabile in diversi punti nel tempo.\n\nNell'esempio della @fig-kline_7_2a (a), immaginiamo che $X$ e $Y$ siano le stesse variabili misurate in due momenti diversi. Ad esempio, $X$ potrebbe essere il livello di ansia di uno studente misurato all'inizio dell'anno scolastico, mentre $Y$ potrebbe essere il livello di ansia dello stesso studente misurato alla fine dell'anno scolastico. In questo caso, stiamo cercando di prevedere i punteggi futuri di ansia (Y) basandoci sui punteggi passati (X).\n\nUn aspetto importante da considerare √® che gli errori nelle misure ripetute (le variazioni nei punteggi che non sono spiegati dal modello) possono essere correlati. Ad esempio, se le misurazioni sono fatte in intervalli temporali ravvicinati, le circostanze o gli stati interni che hanno influenzato la prima misurazione potrebbero ancora essere presenti durante la seconda misurazione.\n\n### Autoregressione Spaziale\n\nL'autoregressione spaziale, invece, si riferisce a un modello che considera le correlazioni spaziali tra dati. Questo tipo di analisi √® particolarmente rilevante quando si studiano fenomeni geografici o ambientali. Ad esempio, la diffusione di una malattia in diverse localit√† geografiche potrebbe non essere indipendente: le aree vicine geograficamente potrebbero mostrare pattern simili di diffusione della malattia a causa della loro vicinanza.\n\nIn quest'ultimo caso, non stiamo pi√π parlando di misure ripetute nel tempo sulla stessa unit√†, ma piuttosto di misure effettuate in diverse unit√† in un contesto spaziale. Le variabili misurate in diverse localit√† fisiche possono influenzarsi a vicenda, e un modello autoregressivo spaziale cerca di catturare queste interdipendenze.\n\n## Modelli con cause correlate ed effetti indiretti\n\n### Cause esogene correlate\n\nIl modello rappresentato in @fig-kline_7_3 (a) mostra una situazione in cui la variabile dipendente $Y$ √® influenzata da due variabili esogene, $X$ e $W$, le quali sono tra loro correlate. Questo significa che $X$ e $W$ agiscono entrambe come cause di $Y$, e condividono una certa variabilit√†, rappresentata graficamente tramite una covarianza. Tuttavia, il diagramma non specifica la natura causale di tale correlazione, lasciando aperta la questione sul perch√© $X$ e $W$ siano associati.\n\n::: {#fig-kline_7_3}\n![](../../figures/kline_7_3.png){width=\"80%\"}\n\nModelli con cause esogene correlate (a) e con effetti diretti e indiretti (b). Diagrammi in simbolismo compatto. (Figura tratta da @kline2023principles)\n:::\n\nIn termini operativi, software di modellazione come `lavaan` assumono per impostazione predefinita che tutte le variabili esogene che predicono la stessa variabile dipendente siano correlate. Il seguente comando in `lavaan`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nY ~ X + W\n#> Y ~ X + W\n```\n:::\n\n\n\n\nspecifica un modello come quello della figura (a), stimando gli effetti di $X$ e $W$ su $Y$, e includendo anche la covarianza tra $X$ e $W$ come parametro libero. Le varianze di $X$, $W$ e il disturbo associato a $Y$ sono anch‚Äôesse stimate.\n\nSe si desidera invece forzare l‚Äôipotesi di indipendenza tra $X$ e $W$, √® possibile usare:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nX ~~ 0*W\n#> X ~ ~0 * W\n```\n:::\n\n\n\n\nche impone che la covarianza tra $X$ e $W$ sia nulla, trattandole come cause indipendenti. Questa scelta dovrebbe riflettere una giustificazione teorica, poich√© cambia in modo sostanziale l‚Äôinterpretazione causale del modello.\n\n√à importante notare che nel modello di @fig-kline_7_3 (a) si assume **assenza di interazioni** tra $X$ e $W$: l‚Äôeffetto di $X$ su $Y$ √® costante a prescindere dai valori di $W$ e viceversa. Questo implica una struttura causale **incondizionata**, in cui gli effetti sono considerati fissi e lineari. Una formulazione alternativa, che ipotizzi **causalit√† condizionata**, includerebbe un termine d‚Äôinterazione (ad esempio `X:W`) per rappresentare l‚Äôipotesi che l‚Äôeffetto di una variabile dipenda dal livello dell‚Äôaltra.\n\n### Implicazioni dell‚Äôerrore di misurazione con cause correlate\n\nQuando le cause esogene sono correlate, l‚Äôeffetto dell‚Äôerrore di misurazione diventa particolarmente complesso. L‚Äôerrore pu√≤ introdurre bias sia negativi sia positivi nelle stime dei coefficienti, a seconda di:\n\n- come l‚Äôerrore √® distribuito tra le variabili esogene,\n- se √® presente anche nella variabile di esito,\n- e della struttura delle covarianze tra tutte le variabili.\n\nIn questi casi, i modelli a equazioni strutturali (SEM) offrono un notevole vantaggio, in quanto permettono di **modellare esplicitamente l‚Äôerrore di misurazione**, migliorando la precisione delle stime e la validit√† delle inferenze.\n\n### Effetti diretti e indiretti: mediazione causale\n\nNel modello della @fig-kline_7_3 (b), la variabile $X$ ha un effetto su $Y$ sia **direttamente**, sia **indirettamente** tramite una variabile mediatrice $M$. In questo caso:\n\n- $X \\rightarrow M \\rightarrow Y$ rappresenta il **percorso indiretto**,\n- $X \\rightarrow Y$ rappresenta il **percorso diretto**,\n- $M$ √® una variabile **endogena**, influenzata da $X$ e, a sua volta, causa di $Y$.\n\nL‚Äôaccuratezza nella stima dell‚Äôeffetto indiretto dipende criticamente dalla qualit√† della misurazione di $M$. Anche se si assume che $X$ sia misurata senza errore, la presenza di **errore di misurazione in $M$** pu√≤ portare a una **sottostima (bias negativo)** dell‚Äôeffetto indiretto. Viceversa, la presenza di **confonditori non modellati** tra $M$ e $Y$ pu√≤ causare una **sovrastima (bias positivo)**.\n\nQuando **entrambi** questi problemi si verificano (errore in $M$ e confondimento tra $M$ e $Y$), le conseguenze sulle stime possono essere imprevedibili: bias positivo, negativo, o nullo. Gli studi di simulazione hanno mostrato che **correggere solo uno dei due problemi** pu√≤ addirittura peggiorare la situazione, introducendo un bias maggiore rispetto a quello presente nel modello non corretto.\n\n### Assunzioni implicite nel modello della figura (b)\n\nIl modello rappresentato nella figura @fig-kline_7_3 (b) poggia su tre assunzioni fondamentali:\n\n1. $X$ ha sia un **effetto diretto** che un **effetto indiretto** su $Y$ attraverso $M$;\n2. gli **effetti di $X$ e $M$ su $Y$ sono additivi e lineari**, cio√® non esistono interazioni tra $X$ e $M$;\n3. non sono presenti **confonditori non osservati** tra $X$, $M$ e $Y$.\n\nSe una o pi√π di queste assunzioni sono violate, le stime degli effetti diretti e indiretti possono risultare distorte.\n\nIn sintesi, i modelli con **cause correlate** o **percorsi indiretti** come quelli illustrati nella @fig-kline_7_3 sono strumenti potenti per analizzare strutture causali complesse. Tuttavia, la loro validit√† dipende in modo cruciale da:\n\n- come vengono trattati gli **errori di misurazione**,\n- dall‚Äôeventuale presenza di **confonditori non inclusi nel modello**,\n- e dalle **assunzioni implicite** sui rapporti tra le variabili.\n\nL‚Äôuso dei modelli SEM permette di affrontare esplicitamente molti di questi problemi, ma richiede attenzione sia teorica che tecnica per evitare conclusioni distorte. \n\n## Modelli Ricorsivi, Non Ricorsivi e Parzialmente Ricorsivi\n\nI modelli di percorso complessi possono essere costruiti combinando configurazioni elementari come quelle illustrate nelle figure precedenti. Una distinzione fondamentale tra modelli √® quella tra **modelli ricorsivi** e **modelli non ricorsivi**. A questa si aggiunge una terza categoria intermedia: i **modelli parzialmente ricorsivi**.\n\n::: {#fig-kline_7_4}\n![](../../figures/kline_7_4.png){width=\"80%\"}\n\nEsempi di modelli ricorsivi, non ricorsivi e parzialmente ricorsivi con due diversi schemi di correlazione degli errori. Tutti i diagrammi sono mostrati in simbolismo compatto. (Figura tratta da @kline2023principles)\n:::\n\n### Modelli Ricorsivi\n\nUn **modello ricorsivo** presenta due caratteristiche fondamentali:\n\n1. tutti gli effetti causali sono **unidirezionali** (non vi sono cicli causali);\n2. i **termini di disturbo** associati alle variabili endogene sono **mutuamente indipendenti**, cio√® non correlati tra loro.\n\nIl modello in @fig-kline_7_4 (a) √® un esempio classico di modello ricorsivo. Tutti i modelli visti finora nel testo sono di questo tipo. Dal punto di vista grafico, un modello ricorsivo corrisponde a un **grafo aciclico diretto (DAG)**, dove le frecce rappresentano relazioni causali che non formano cicli.\n\n### Modelli Non Ricorsivi\n\nI **modelli non ricorsivi** contengono **cicli causali** (o feedback), in cui almeno due variabili endogene si influenzano reciprocamente, direttamente o indirettamente. Questo comporta che:\n\n- il grafo causale √® **ciclico**,\n- almeno una coppia di variabili endogene agisce sia come causa che come effetto.\n\nUn esempio di questo tipo √® mostrato in @fig-kline_7_4 (b), dove le variabili $Y_1$ e $Y_2$ sono collegate da **causalit√† reciproca**:\n\n$$\nY_1 \\leftrightarrow Y_2\n$$\n\nNel simbolismo compatto, questo tipo di relazione indica che $Y_1$ ha un effetto su $Y_2$ e viceversa. In presenza di una **covarianza tra i termini di disturbo** ($D_1$ e $D_2$), si assume anche l‚Äôesistenza di **cause comuni non misurate** che influenzano entrambe le variabili. Ci√≤ rende il modello pi√π complesso da identificare e stimare, poich√© introduce un **percorso di confondimento** non osservato.\n\n::: {.callout-important title=\"Nota\" collapse=\"true\"}\nIl termine ‚Äú**ricorsivo**‚Äù pu√≤ creare confusione, perch√© nel linguaggio informatico o matematico spesso indica **una funzione che richiama s√© stessa**, mentre **nei modelli a equazioni strutturali (SEM)** ha un significato diverso.\n\n‚úÖ **Modello ricorsivo**  \n√à **quello semplice**, in cui:\n\n- tutti gli effetti causali sono **unidirezionali** (senza retroazioni, o feedback loops),\n- non vi sono **correlazioni tra i termini di errore** delle variabili endogene.\n\nQuesti modelli sono ‚Äúpuliti‚Äù e lineari, e corrispondono a **grafi aciclici diretti (DAGs)**.  \nNel simbolismo compatto di Kline, questo √® il modello in **@fig-kline_7_4 (a)**.\n\n‚úÖ **Modello non ricorsivo**  \n√à **quello pi√π complesso**, dove:\n\n- esistono **cicli causali** (ad esempio, $Y_1$ causa $Y_2$ e $Y_2$ causa $Y_1$),\n- possono esserci **correlazioni tra i disturbi** delle variabili endogene.\n\nQuesti modelli corrispondono a **grafi ciclici diretti**, e richiedono condizioni aggiuntive per l‚Äôidentificabilit√†.  \nNel simbolismo compatto di Kline, √® il modello in **@fig-kline_7_4 (b)**.\n\n**Perch√© si chiama \"non ricorsivo\"?**\n\nIl termine viene dalla **teoria dei sistemi simultanei** (es., econometria). Un **modello ricorsivo** √® quello in cui puoi ordinare le equazioni in modo tale che ogni variabile endogena dipenda **solo da variabili che la precedono nell‚Äôordine** ‚Äî non c‚Äô√® \"ritorno\". Se invece esiste un ciclo, **l‚Äôordine si rompe**: per stimare $Y_1$ serve $Y_2$, e viceversa.\n:::\n\n### Modelli Parzialmente Ricorsivi\n\nUn **modello parzialmente ricorsivo** ha una struttura unidirezionale (quindi √® formalmente ricorsivo) ma **include covarianze tra i termini di disturbo**. La classificazione dipende dalla posizione di tali covarianze:\n\n- se le covarianze tra i disturbi riguardano **variabili non collegate da percorsi causali diretti**, come in @fig-kline_7_4 (c), il modello pu√≤ essere trattato come ricorsivo. In questo caso, gli errori correlati **non introducono cicli logici o percorsi di confondimento attivi**.\n- se invece le covarianze coinvolgono **variabili collegate da effetti diretti**, come in @fig-kline_7_4 (d), il modello assume una **struttura equivalente a quella di un modello non ricorsivo**. La combinazione di un effetto diretto ($Y_1 \\rightarrow Y_2$) con una correlazione tra i disturbi ($D_1 \\leftrightarrow D_2$) **attiva un percorso di confondimento**, rendendo la stima degli effetti causali pi√π problematica.\n\nIn quest‚Äôultimo caso, non √® sufficiente includere covariate per controllare il confondimento: la struttura del modello stesso richiede un trattamento analitico specifico, simile a quello dei modelli non ricorsivi.\n\n\n### Rappresentazioni grafiche: DAG e grafi ciclici\n\n- I **modelli ricorsivi** e i **modelli parzialmente ricorsivi senza \"archi\"** (cio√® senza percorsi di confondimento attivati da correlazioni tra errori) possono essere rappresentati come **grafi aciclici diretti (DAG)**. In questi grafi, tutte le relazioni causali sono unidirezionali e non formano cicli.\n  \n- I **modelli non ricorsivi**, invece, corrispondono a **grafi ciclici diretti**, nei quali almeno una coppia di variabili si influenzano reciprocamente. Le regole di identificazione e analisi per i DAG non si applicano direttamente a questi grafi ciclici, rendendo necessarie tecniche pi√π avanzate.\n\n::: {.callout-important title=\"Nota\" collapse=\"true\"}\nNon tutti i path diagram di Wright possono essere rappresentati come DAG. Solo i **modelli ricorsivi puri**, privi di cicli causali e di correlazioni tra i termini di errore, sono formalmente equivalenti a **grafi aciclici diretti (DAG)**.  \n\nAl contrario, i **modelli non ricorsivi** (con feedback) e i **modelli parzialmente ricorsivi** (con correlazioni tra disturbi) **non rispettano le condizioni di aciclicit√† o di assenza di archi non orientati** richieste dai DAG.  \n\nDi conseguenza, **le regole di identificazione grafica** sviluppate nell‚Äôambito della teoria dei DAG **non possono essere applicate direttamente** ai path diagram SEM pi√π generali.\n:::\n\n## Identificabilit√†\n\nUn modello √® detto **identificato** se tutti i suoi parametri liberi possono essere stimati **in modo univoco** a partire dai dati osservati.\n\nNei modelli **ricorsivi** e nei **parzialmente ricorsivi senza archi** (cio√® senza cicli causali n√© correlazioni tra errori che creano percorsi di confondimento), l‚Äôidentificabilit√† si verifica quando:\n\n1. I gradi di libert√† sono maggiori o uguali a zero:  \n   $$\n   df_M \\geq 0,\n   $$\n2. Ogni variabile **non osservata**, inclusi i termini di disturbo, √® associata a una **scala metrica definita** (es. fissazione della varianza o altro vincolo).\n\n## Tipi di identificabilit√†\n\n### üîπ Modello appena identificato\n\n- Il numero di parametri √® **esattamente pari** al numero di informazioni:\n  $$\n  df_M = 0\n  $$\n- Il modello si **adatta perfettamente ai dati**, ma questa aderenza √® **forzata**. Non √® possibile verificarne empiricamente la validit√†, n√© confrontarlo con modelli alternativi.\n- L‚Äôadattamento perfetto **non implica** che il modello sia corretto o generalizzabile.\n\n### üîπ Modello sovraidentificato\n\n- Il numero di informazioni **supera** il numero di parametri:\n  $$\n  df_M > 0\n  $$\n- Il modello pu√≤ essere **testato empiricamente**: √® possibile valutare se le stime sono coerenti con i dati (tramite indici come $\\chi^2$, RMSEA, CFI, ecc.).\n- Questi modelli sono generalmente preferibili, perch√© **offrono margine per la falsificazione**.\n\n### üîπ Modello sottoidentificato\n\nUn modello √® **sottoidentificato** se **non √® possibile ottenere stime univoche** per tutti i suoi parametri liberi. Questo pu√≤ avvenire in due casi:\n\n1. **$df_M < 0$**: il modello ha pi√π parametri da stimare che informazioni disponibili. In questo caso, √® chiaramente non stimabile.\n\n2. **$df_M \\geq 0$**, ma **uno o pi√π parametri non sono identificabili individualmente**. Anche se il conteggio globale dei gradi di libert√† √® positivo, alcune porzioni del modello possono essere mal specificate (es. variabili latenti senza ancoraggio), impedendo la stima di specifici parametri.\n\nIn entrambi i casi, l‚Äôintero modello viene considerato **non identificato**, poich√© non produce stime univoche per tutti i parametri.\n\nIn sintesi, i **gradi di libert√†** e l‚Äô**identificabilit√†** costituiscono due aspetti complementari della modellazione statistica. I gradi di libert√† indicano quanto ‚Äúspazio‚Äù ha il modello per essere testato, mentre l‚Äôidentificabilit√† stabilisce se le stime dei parametri sono determinate in modo univoco.  \n\n::: {.callout-important title=\"Nota\" collapse=\"true\"}\nEcco una rappresentazione schematica dei **tre casi di identificabilit√†**, adattata alla sintassi `lavaan`:\n\n1. **Modello appena identificato** ($df_M = 0$)\n\n```text\nX ‚Üí Y\n```\n\n- 2 variabili osservate  \n- 1 varianza per X  \n- 1 varianza residua per Y  \n- 1 coefficiente di regressione  \n- Totale: 3 parametri stimati, 3 informazioni ‚Üí $df_M = 0$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_justid <- '\n  Y ~ b*X\n'\n```\n:::\n\n\n\n\nüîé Si adatta perfettamente ai dati ma **non testabile** (modello saturo per 2 variabili).\n\n2. **Modello sovraidentificato** ($df_M > 0$)\n\n```text\nX1 ‚Üí Y ‚Üê X2\n```\n\n- 3 variabili osservate ‚Üí $p = 6$  \n- Parametri stimati:\n  - 2 regressioni: `Y ~ X1 + X2`\n  - 3 varianze (X1, X2, residuo Y)\n  - 1 covarianza tra X1 e X2  \n- Totale: 6 parametri  \n- Ma: se **si impone** `X1 ~~ 0*X2` (indipendenza), si stimano **solo 5 parametri** ‚Üí $df_M = 6 - 5 = 1$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_overid <- '\n  Y ~ b1*X1 + b2*X2\n  X1 ~~ 0*X2\n'\n```\n:::\n\n\n\n\n‚úÖ **Sovraidentificato**: pu√≤ essere testato con indici di adattamento.\n\n3. **Modello sottoidentificato** ($df_M \\geq 0$, ma non tutti i parametri stimabili)\n\n```text\nF1 ‚Üí Y1, Y2\nF2 ‚Üí Y2, Y3\n```\n\n- Due fattori latenti, ma **nessuna relazione specificata tra F1 e F2**\n- Y2 √® indicatore di **entrambi i fattori**, ma il modello non √® identificato senza ulteriori vincoli\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_underid <- '\n  F1 =~ Y1 + Y2\n  F2 =~ Y2 + Y3\n'\n```\n:::\n\n\n\n\n‚ö†Ô∏è Questo modello genera un errore: **sottoidentificato** perch√© non ci sono abbastanza vincoli per separare l'effetto di F1 e F2 su Y2.\n\n\n‚úÖ Suggerimenti per `lavaan`\n\nPer verificare **l'identificabilit√†** e i **gradi di libert√†**:\n\n```r\nsummary(fit, fit.measures = TRUE)\n```\n\nPer ispezionare **rank e struttura del modello**:\n\n```r\nlavInspect(fit, \"rank\")  # rango dell'information matrix\nlavInspect(fit, \"free\")  # numero di parametri liberi\nlavInspect(fit, \"df\")    # gradi di libert√†\n```\n\nSe il modello √® **sottoidentificato**, `lavaan` segnala un errore tipo:\n\n```\nlavaan WARNING: model has not been identified:  df = -1\n```\n\noppure\n\n```\nlavaan ERROR: the model is not identified.\n```\n\nüéì Riassunto visivo\n\n| Tipo                  | Esempio          | Gradi di libert√† | Testabile? | Note |\n|-----------------------|------------------|------------------|------------|------|\n| Appena identificato   | `Y ~ X`          | $df_M = 0$       | ‚úñ          | Modello saturo |\n| Sovraidentificato     | `Y ~ X1 + X2`, `X1 ~~ 0*X2` | $df_M > 0$ | ‚úî          | Preferibile |\n| Sottoidentificato     | 2 fattori ‚Üí Y2   | $df_M \\geq 0$ ma non stimabile | ‚úñ | Richiede pi√π vincoli |\n:::\n\n## Analisi dei percorsi e regressione bivariata\n\nL‚Äôanalisi dei percorsi (o *path analysis*) pu√≤ essere introdotta prendendo come punto di partenza il modello di regressione lineare pi√π semplice, quello bivariato, cos√¨ da evidenziare il passaggio naturale tra la regressione semplice e la rappresentazione LISREL. \n\nNel caso di una singola variabile indipendente (o *esogena*) $x$ e di una variabile dipendente (o *endogena*) $y$, il modello di regressione bivariata si esprime con la ben nota equazione:\n\n$$\ny = b_0 + b_1 x + e,\n$$\n\ndove:\n\n- $y$ √® la variabile dipendente;\n- $b_0$ √® l‚Äôintercetta del modello;\n- $b_1$ √® il coefficiente di regressione (la pendenza della retta);\n- $x$ √® la variabile indipendente;\n- $e$ √® il termine di errore.\n\nNel contesto dei modelli strutturali, si adottano spesso la notazione e l‚Äôimpostazione concettuale di LISREL. La stessa relazione, vista sotto questa lente, si scrive in forma leggermente diversa:\n\n$$\ny_1 = \\alpha + \\gamma_1 x_1 + \\zeta_1,\n$$\n\ndove:\n\n- $x_1$ √® la variabile esogena,\n- $y_1$ √® la variabile endogena,\n- $\\alpha$ √® l‚Äôintercetta (corrispondente a $b_0$),\n- $\\gamma_1$ √® il coefficiente di regressione (corrispondente a $b_1$),\n- $\\zeta_1$ √® l‚Äôerrore di $y_1$ (corrispondente a $e$).\n\nLe altre componenti tipicamente indicate in LISREL sono:\n\n- $\\phi$, che rappresenta la (co)varianza delle variabili esogene,\n- $\\psi$, che rappresenta la (co)varianza residua delle variabili endogene.\n\n### Diagramma di percorso\n\nLa @fig-lisrel_bivariate_reg illustra il diagramma di percorso relativo alla regressione bivariata: una freccia orientata collega la variabile esogena $x_1$ alla variabile endogena $y_1$, mentre un‚Äôarco curvo (o un doppio senso) fra la stessa variabile e se stessa (oppure un fattore di disturbo) rappresenta la sua varianza. Lo stesso avviene per $y_1$, la cui varianza residua (o errore) √® indicata con una freccia non orientata che circonda la variabile endogena.\n\n::: {#fig-lisrel_bivariate_reg}\n![](../../figures/lisrel_bivariate_reg.png){width=\"70%\"}\n\nDiagramma di percorso per il modello di regressione bivariata.\n:::\n\n### Esempio numerico in R\n\nSi riportano di seguito alcuni codici R come esempio. Supponiamo di generare casualmente 100 osservazioni per tre variabili: `x1`, `x2` e `y`. Per cominciare, consideriamo il semplice modello `y ~ x1`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(42)\nn <- 100\nx1 <- rnorm(n, 90, 20)\nx2 <- x1 + rnorm(n, 0, 30)\ny <- 25 + 0.5 * x1 + 1.0 * x2 + rnorm(n, 0, 30)\n\ndat <- data.frame(\n    y, x1, x2\n)\n\ncor(dat) |>\n    round(2)\n#>       y   x1   x2\n#> y  1.00 0.55 0.80\n#> x1 0.55 1.00 0.62\n#> x2 0.80 0.62 1.00\n```\n:::\n\n\n\n\n#### Regressione con `lm`\n\nConsideriamo la relazione tra `x1` (esogena) e `y` (endogena). Possiamo stimare i coefficienti del modello con la funzione `lm`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1a <- lm(y ~ x1, data = dat)\nsummary(m1a)\n#> \n#> Call:\n#> lm(formula = y ~ x1, data = dat)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -82.46 -29.54  -3.44  29.20 122.23 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)   37.597     18.984    1.98     0.05\n#> x1             1.329      0.204    6.51  3.3e-09\n#> \n#> Residual standard error: 42.3 on 98 degrees of freedom\n#> Multiple R-squared:  0.302,\tAdjusted R-squared:  0.295 \n#> F-statistic: 42.4 on 1 and 98 DF,  p-value: 3.25e-09\n```\n:::\n\n\n\n\n#### Stima con lavaan\n\nUsiamo quindi *lavaan* per stimare lo stesso modello:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1b <- \"\n    y ~ 1 + x1\n\"\nfit1b <- sem(m1b, data = dat)\nparameterEstimates(fit1b) \n#>   lhs op rhs      est      se     z pvalue ci.lower ci.upper\n#> 1   y ~1       37.597  18.794 2.001  0.045    0.763   74.432\n#> 2   y  ~  x1    1.329   0.202 6.574  0.000    0.933    1.725\n#> 3   y ~~   y 1754.100 248.067 7.071  0.000 1267.897 2240.303\n#> 4  x1 ~~  x1  429.432   0.000    NA     NA  429.432  429.432\n#> 5  x1 ~1       90.650   0.000    NA     NA   90.650   90.650\n```\n:::\n\n\n\n\nDall‚Äôoutput, notiamo come l‚Äôintercetta di `y` (~1) e il coefficiente di regressione di `y` (~ x1) corrispondano sostanzialmente a quelli ottenuti con `lm()`, al netto di minime differenze di arrotondamento. L‚Äôintercetta `x1 ~ 1` e la sua varianza `x1 ~~ x1` descrivono la media e la varianza della variabile esogena, risultando quindi equivalenti alla media e varianza univariata di `x1`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(dat$x1)\n#> [1] 90.65\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(dat$x1) * (length(dat$x1) - 1) / length(dat$x1)\n#> [1] 429.4\n```\n:::\n\n\n\n\nAnalogamente, la varianza residua di `y` (`y ~~ y`) corrisponde alla quota di varianza non spiegata dalla regressione su `x1`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(dat$y) * 99 / 100 - (1.3286 * 429.432 * 1.3286)\n#> [1] 1754\n```\n:::\n\n\n\n\nInfine, possiamo generare il diagramma di percorso relativo al modello mediante la funzione `semPaths` del pacchetto *semPlot*:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n  fit1b,\n  layout = \"spring\",    # Oppure prova \"circle\" o \"spring\"\n  sizeMan = 7, \n  sizeInt = 5,\n  style = \"ram\",\n  residuals = TRUE,\n  intAtSide = FALSE,\n  edge.label.cex = 0.9, # Riduce la dimensione delle etichette sui percorsi\n  label.cex = 0.9,      # Riduce la dimensione delle etichette dei nodi\n  whatLabels = \"est\",\n  nCharNodes = 0,\n  normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Analisi dei percorsi e regressione multipla\n\nLa regressione semplice √® limitata all‚Äôuso di una sola variabile esogena. Nella pratica, per√≤, un ricercatore pu√≤ voler studiare come un insieme di variabili esogene contribuiscano a predire una singola variabile di esito. Supponiamo dunque di avere due variabili esogene (ad es. `x1` e `x2`) e una variabile endogena (`y`). Questo caso √® noto come regressione multipla, esprimibile in LISREL con la seguente equazione:\n\n$$\ny_1 = \\alpha_1 + \\gamma_1 x_1 + \\gamma_2 x_2 + \\zeta_1.\n$$\n\nIn questo contesto, il diagramma di percorso mostra frecce orientate da `x1` e `x2` verso `y`, con i rispettivi coefficienti di regressione (i pesi parziali), mentre le frecce non orientate (o archi curvi) rappresentano le (co)varianze fra le variabili esogene e la varianza residua di `y`. \n\n::: {#fig-lisrel_mr}\n![](../../figures/lisrel_mr.png){width=\"80%\"}\n\nDiagramma di percorso per il modello di regressione multipla.\n:::\n\n### Numero di equazioni e termini\n\nIn un diagramma di percorso, il numero di equazioni corrisponde al numero di variabili endogene. Nel caso della regressione multipla con un‚Äôunica variabile endogena, esiste un‚Äôunica equazione:\n\n$$\ny_1 = \\alpha_1 + \\gamma_1 x_1 + \\gamma_2 x_2 + \\zeta_1.\n$$\n\nIl numero di termini in quest‚Äôequazione coincide con quello delle frecce orientate che puntano a $y_1$. Nell‚Äôesempio sopra, i termini sono tre: l‚Äôintercetta ($\\alpha_1$) e i due coefficienti di regressione ($\\gamma_1$ e $\\gamma_2$).\n\n### Stima in R\n\nPossiamo stimare il modello di regressione multipla in modo classico tramite `lm`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2a <- lm(y ~ 1 + x1 + x2, data = dat)\nfit2a <- summary(m2a) \nfit2a\n#> \n#> Call:\n#> lm(formula = y ~ 1 + x1 + x2, data = dat)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -77.30 -19.86  -2.48  19.11  75.62 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)   44.454     13.664    3.25   0.0016\n#> x1             0.199      0.188    1.06   0.2918\n#> x2             1.085      0.113    9.63  8.5e-16\n#> \n#> Residual standard error: 30.4 on 97 degrees of freedom\n#> Multiple R-squared:  0.643,\tAdjusted R-squared:  0.636 \n#> F-statistic: 87.3 on 2 and 97 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\ne ottenere gli stessi risultati con *lavaan* specificando il modello:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2b <- \"\n    y ~ 1 + x1 + x2\n    x1 ~~ x1\n    x2 ~~ x2\n    x1 ~~ x2\n\"\n\nfit2b <- sem(m2b, data = dat)\nparameterEstimates(fit2b)\n#>   lhs op rhs      est      se      z pvalue ci.lower ci.upper\n#> 1   y ~1       44.454  13.457  3.303  0.001   18.078   70.830\n#> 2   y  ~  x1    0.199   0.185  1.076  0.282   -0.164    0.562\n#> 3   y  ~  x2    1.085   0.111  9.775  0.000    0.868    1.303\n#> 4  x1 ~~  x1  429.432  60.731  7.071  0.000  310.402  548.462\n#> 5  x2 ~~  x2 1192.840 168.693  7.071  0.000  862.208 1523.472\n#> 6  x1 ~~  x2  446.927  84.379  5.297  0.000  281.546  612.307\n#> 7   y ~~   y  896.963 126.850  7.071  0.000  648.342 1145.584\n#> 8  x1 ~1       90.650   2.072 43.744  0.000   86.589   94.712\n#> 9  x2 ~1       88.026   3.454 25.487  0.000   81.257   94.795\n```\n:::\n\n\n\n\nPossiamo infine visualizzare il diagramma di percorso corrispondente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit2b,\n    layout = \"spring\", sizeMan = 7, sizeInt = 5, style = \"ram\",\n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 0.7,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n**In sintesi**, la regressione lineare ‚Äî sia bivariata che multipla ‚Äî pu√≤ essere vista come un caso speciale di *path analysis*, dove ciascuna equazione corrisponde a una variabile endogena e i coefficienti di regressione rappresentano i ‚Äúcammini‚Äù (o percorsi causali) che collegano le variabili esogene a quelle endogene. L‚Äôuso della notazione LISREL ne facilita l‚Äôintegrazione in modelli pi√π complessi, dove si considerano simultaneamente diverse relazioni tra variabili manifeste o latenti.\n\n\n## Effetti diretti e indiretti\n\nL‚Äôanalisi del percorso (o *path analysis*) mette in evidenza diverse tipologie di effetti tra le variabili di un modello, consentendoci di distinguere in modo netto tra:\n\n- **effetto diretto**, \n- **effetto indiretto**,\n- **effetto totale**.\n\n### Effetto diretto\n\nL‚Äôeffetto diretto √® l‚Äôinfluenza esercitata da una variabile $X$ su un‚Äôaltra variabile $Y$ senza la mediazione di altre variabili intermedie. In un diagramma di percorso, l‚Äôeffetto diretto √® rappresentato da una singola freccia diretta che collega $X$ a $Y$.\n\n### Effetto indiretto\n\nL‚Äôeffetto indiretto rappresenta l‚Äôinfluenza di una variabile $X$ su un‚Äôaltra variabile $Y$ quando tale influenza passa attraverso almeno una variabile intermedia (spesso chiamata *mediatore* o *variabile mediatrice*). In un diagramma di percorso, questo si traduce in un percorso composto da pi√π di una freccia (ad esempio $X \\rightarrow M \\rightarrow Y$).\n\n### Effetto totale\n\nL‚Äôeffetto totale di $X$ su $Y$ √® dato dalla somma dell‚Äôeffetto diretto e dell‚Äôeffetto indiretto. In formule, se $X$ esercita su $Y$ un effetto diretto $\\beta_{XY}$ e un effetto indiretto $\\beta_{X \\cdot M \\cdot Y}$, l‚Äôeffetto totale $\\beta_{\\text{tot}}$ √®:\n\n$$\n\\beta_{\\text{tot}} = \\beta_{XY} + \\beta_{X \\cdot M \\cdot Y}.\n$$\n\n### Esempio in un modello a catena\n\nNella @fig-path_03 si osserva un modello a catena in cui la variabile $y_1$ influenza la variabile $y_2$, che a sua volta influenza $y_3$:\n\n::: {#fig-path_03}\n![](../../figures/path_03.png){width=\"40%\"}\n\nDiagramma di percorso per un modello a catena.\n:::\n\n1. **Effetto diretto di $y_1$ su $y_2$**: √® rappresentato dalla freccia che va da $y_1$ a $y_2$. Questo coefficiente indica in che misura $y_1$ influenza $y_2$ *senza* passare attraverso alcun‚Äôaltra variabile.\n2. **Effetto diretto di $y_2$ su $y_3$**: √® la freccia che collega $y_2$ a $y_3$. Definisce quanto $y_2$ influenzi $y_3$ direttamente.\n3. **Effetto indiretto di $y_1$ su $y_3$**: poich√© non esiste una freccia diretta da $y_1$ a $y_3$, ogni possibile relazione tra queste due variabili avviene attraverso $y_2$. In altre parole, l‚Äôeffetto di $y_1$ su $y_3$ √® *mediato* da $y_2$.\n4. **Effetto totale di $y_1$ su $y_3$**: si calcola come somma degli effetti diretti e indiretti, ma in questo caso (se non esiste freccia $y_1 \\rightarrow y_3$) coincide unicamente con l‚Äôeffetto indiretto. Se esistesse anche una freccia che andasse direttamente da $y_1$ a $y_3$, avremmo un effetto totale costituito sia da una componente diretta sia da una indiretta.\n\nNel contesto mostrato in figura, $y_1$ funge da variabile esogena, mentre $y_2$ e $y_3$ sono variabili endogene. La natura ‚Äúesogena‚Äù di $y_1$ implica che essa non √® spiegata da alcun‚Äôaltra variabile del modello, mentre $y_2$ e $y_3$ dipendono causalmente da altre variabili.\n\n### Stima degli effetti in path analysis\n\nQuando si utilizzano strumenti di stima (ad esempio tramite il pacchetto *lavaan* in R o software equivalenti per modelli strutturali), gli effetti diretti e indiretti sono spesso riportati in tabelle separate:\n\n- **Effetti diretti** (direct effects),\n- **Effetti indiretti** (indirect effects),\n- **Effetti totali** (total effects).\n\nIn *lavaan*, ad esempio, possiamo specificare nella sintassi:\n\n```r\nmodel <- '\n  y2 ~ a * y1\n  y3 ~ b * y2\n  # definizione degli effetti indiretti e totali (opzionale, ma utile)\n  y3 := (a * b)   # effetto indiretto y1 -> y2 -> y3\n'\nfit <- sem(model, data = myData)\nparameterEstimates(fit)\n```\n\ndove si possono calcolare e testare statisticamente sia l‚Äôeffetto diretto sia quello indiretto (tramite il prodotto dei coefficienti lungo il percorso mediato).\n\n### Significato interpretativo\n\n- **Effetti diretti**: Se l‚Äôeffetto diretto di $X$ su $Y$ √® significativo, possiamo concludere che $X$ √® associato a variazioni in $Y$ *anche* al netto di ci√≤ che accade attraverso le altre variabili.\n- **Effetti indiretti**: Se l‚Äôeffetto indiretto √® significativo, vuol dire che una parte del cambiamento in $Y$ √® spiegata dal ruolo di una o pi√π variabili mediatrici. In termini di modelli di mediazione, ci√≤ corrisponde a un effetto di tipo ‚Äúmediato‚Äù.\n- **Effetti totali**: Un effetto totale significativo indica che, considerando tutte le possibili vie di influenza (dirette e indirette), la variabile $X$ influenza significativamente la variabile $Y$.\n\n**In sintesi**, l‚Äôanalisi di effetti diretti e indiretti √® cruciale in qualunque modello che contempli variabili mediatrici. Distinguere correttamente queste componenti ci permette di comprendere meglio la natura del legame tra le variabili, evidenziando i meccanismi attraverso cui gli effetti si propagano. Nei modelli a catena, come quello in @fig-path_03, √® possibile illustrare come un cambiamento iniziale in $y_1$ possa ripercuotersi su $y_3$ passando per $y_2$, fornendo una visione pi√π ricca e realistica del fenomeno studiato rispetto a un semplice modello bivariato.\n\nL‚Äôidentificazione di effetti diretti, indiretti e totali rappresenta una delle caratteristiche distintive e fondamentali dell‚Äôanalisi del percorso e, pi√π in generale, di qualsiasi modello strutturale, poich√© fornisce una comprensione approfondita di come le variabili si influenzano reciprocamente, tenendo conto anche dei passaggi intermedi.\n\n## Le regole di Wright\n\nUn obiettivo fondamentale dell‚Äôanalisi del percorso √® decomporre le correlazioni (o covarianze) in una somma di contributi riconducibili ai vari percorsi che collegano due variabili. Tali contributi dipendono dai cosiddetti *path coefficients*, ossia i coefficienti associati alle frecce unidirezionali (coefficiente di regressione) o bidirezionali (coefficiente di correlazione/covarianza) che compaiono nel diagramma di percorso.\n\n### Le ‚Äútracing rules‚Äù\n\nFu @wright1934method a definire una serie di regole, conosciute come *tracing rules*, che stabiliscono in che modo possiamo ‚Äútracciare‚Äù i percorsi all‚Äôinterno del diagramma per scomporre la correlazione (o covarianza) tra due variabili:\n\n1. **Senso di percorrenza delle frecce**: √à permesso seguire una freccia in avanti (nel verso della causalit√†) e poi una freccia a ritroso (contro la direzione della causalit√†), ma non √® consentito avanzare nel verso della freccia e poi tornare indietro sullo stesso ramo.\n2. **Assenza di cicli**: Un percorso composto non deve passare pi√π di una volta per la stessa variabile; in altre parole, non sono ammessi giri ciclici (loop).\n3. **Singola linea curva**: Un percorso non pu√≤ includere pi√π di una freccia bidirezionale (o linea curva che rappresenta correlazione/covarianza residua).\n\nIn concreto, un *percorso* valido √® una sequenza di variabili collegate da frecce unidirezionali e/o da una sola freccia bidirezionale. A ciascun percorso viene assegnato un valore pari al prodotto dei coefficienti presenti su ogni segmento di quel percorso. I coefficienti unidirezionali sono tipicamente coefficienti di regressione (spesso standardizzati, quindi *beta*), mentre le frecce bidirezionali rappresentano correlazioni o covarianze.\n\n## Scomposizione delle correlazioni/covarianze\n\n### Principio generale di Wright\n\n@wright1934method formul√≤ il principio fondamentale secondo cui:\n\n> Ogni correlazione tra due variabili in un sistema di relazioni pu√≤ essere analizzata suddividendola nei contributi provenienti da tutti i percorsi (diretti o indiretti, attraverso fattori o variabili comuni) che collegano le due variabili. Ogni contributo √® il prodotto dei coefficienti relativi ai segmenti di quel percorso. Se lungo il percorso sono presenti correlazioni residue (frecce bidirezionali), uno (e soltanto uno) di tali coefficienti pu√≤ essere una correlazione bidirezionale; tutti gli altri devono essere coefficienti di percorso unidirezionale.\n\nIn pratica, ci√≤ significa che:\n\n- Se due variabili $X$ e $Y$ sono collegate da pi√π di un percorso (diretto o indiretto), dobbiamo identificare ogni singolo percorso che parta da $X$ e arrivi a $Y$ (senza violare le tracing rules).\n- Per ciascun percorso si moltiplicano i coefficienti di regressione (per le frecce unidirezionali) e, se presente, **una sola** correlazione (per la freccia bidirezionale).\n- Si sommano poi tutti questi prodotti per ottenere la correlazione (o covarianza) complessiva tra $X$ e $Y$.\n\n::: {#exm-}\n\nConsideriamo il seguente diagramma di percorso:\n\n\n\n\n```{mermaid}\nflowchart LR\n    X((X)) --> |Œ≤_XY| Y((Y))\n    X --> |Œ≤_XZ| Z((Z))\n    Z --> |Œ≤_ZY| Y\n    \n    style X fill:#f9f9f9,stroke:#333,stroke-width:2px\n    style Y fill:#f9f9f9,stroke:#333,stroke-width:2px\n    style Z fill:#f9f9f9,stroke:#333,stroke-width:2px\n```\n\n\n\n\nSe esiste un singolo percorso diretto $X \\rightarrow Y$ con coefficiente di regressione $\\beta_{XY}$, e un percorso indiretto $X \\rightarrow Z \\rightarrow Y$ (con i coefficienti $\\beta_{XZ}$ e $\\beta_{ZY}$), la correlazione totale tra $X$ e $Y$ (in forma standardizzata) potr√† essere approssimata da:\n\n$$\nr_{XY} \\approx \\beta_{XY} + (\\beta_{XZ} \\cdot \\beta_{ZY}),\n$$\n\nsupponendo che non vi siano correlazioni residue o altri percorsi pi√π complessi.\n:::\n\n## Scomposizione della varianza\n\nLe stesse regole di tracciamento possono essere utilizzate per decomporre la varianza di una variabile endogena. In un modello di *path analysis*, la varianza di una variabile $Y$ pu√≤ essere suddivisa in:\n\n1. **Componente spiegata**: somma dei contributi di tutte le variabili che hanno un effetto su $Y$ (diretto o mediato).\n2. **Componente non spiegata**: associata all‚Äôerrore o a fattori non inclusi nel modello (rappresentati da una freccia bidirezionale con la variabile stessa).\n\nLa *componente spiegata* deriva dal totale dei prodotti dei coefficienti che, seguendo le tracing rules, ‚Äúcollegano‚Äù la variabile $Y$ a se stessa attraverso le variabili causali precedenti. La somma di questi contributi corrisponde, nella pratica, alla varianza spiegata (o R¬≤) nel caso di un‚Äôanalisi di regressione multipla, ma generalizzata a tutto il sistema di equazioni.\n\n## Relazioni tra variabili endogene ed esogene: le 8 regole dei coefficienti di percorso\n\nL‚Äôanalisi del percorso, e pi√π in generale i modelli a equazioni strutturali, fanno ampio uso di *regole* per determinare come calcolare e interpretare i coefficienti di un diagramma. Una sintesi di tali principi, spesso presentata come ‚Äú8 regole dei coefficienti di percorso‚Äù, comprende:\n\n1. **Relazioni non specificate tra variabili esogene**: Se due variabili esogene non sono collegate da frecce unidirezionali nel diagramma, la loro associazione √® rappresentata dalla loro correlazione (o covarianza) bivariata.\n2. **Percorso univoco**: Se due variabili sono collegate da una singola freccia (unidirezionale), il coefficiente di tale freccia √® un coefficiente di regressione.\n3. **Prodotto dei coefficienti**: La forza di un percorso composto da pi√π segmenti (per es. $X \\rightarrow M \\rightarrow Y$) √® calcolata come il prodotto dei coefficienti dei singoli segmenti ($\\beta_{XM} \\cdot \\beta_{MY}$).\n4. **Coefficienti parziali**: Quando due variabili hanno pi√π di un percorso che le collega, i singoli coefficienti di ogni segmento di un percorso vanno intesi come coefficienti ‚Äúparziali‚Äù (di regressione, se unidirezionali).\n5. **Errori sulle variabili endogene**: Gli errori (o varianze residuali) delle variabili endogene rappresentano la porzione di varianza non spiegata dalle variabili causali precedenti. In un path diagram, questi errori si disegnano come frecce bidirezionali che vanno dalla variabile endogena a se stessa.\n6. **Correlazioni non analizzate (residui)**: Se due variabili endogene presentano una correlazione residua, questa viene indicata da una freccia bidirezionale tra di esse, che esprime una correlazione (o covarianza) parziale non spiegata da altre relazioni nel modello.\n7. **Effetto totale**: L‚Äôeffetto totale di una variabile $X$ su un‚Äôaltra variabile $Y$ √® la somma dell‚Äôeffetto diretto ($X \\rightarrow Y$) e di tutti gli effetti indiretti ($X \\rightarrow \\ldots \\rightarrow Y$).\n8. **Equivalenza con la correlazione totale**: L‚Äôeffetto totale di $X$ su $Y$, includendo tutti i percorsi, coincide con la correlazione totale tra $X$ e $Y$ quando il modello √® perfettamente specificato e in forma standardizzata.\n\n**In sintesi**, le regole di Wright costituiscono la base logica per passare dai semplici diagrammi di percorso a un vero e proprio calcolo formale di correlazioni, varianze e covarianze all‚Äôinterno di un sistema di relazioni causali. Le *tracing rules* assicurano che ogni percorso sia conteggiato correttamente (senza loop, senza ripetizioni), e che la correlazione (o la varianza) possa essere scomposta in un insieme di contributi interpretabili. Questa scomposizione permette di capire esattamente **quanto** di un‚Äôassociazione o di una varianza √® imputabile a effetti diretti, indiretti o a correlazioni residue, fornendo cos√¨ una visione pi√π ricca e dettagliata dei processi causali sottostanti alle variabili d‚Äôinteresse.\n\n::: {#exm-}\nConsideriamo nuovamente il modello di regressione multipla con due variabili esogene e una sola variabile endogena che √® stato presentato sopra. \n\nLa la covarianza tra `y` e `x1` \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncov(dat$y, dat$x1) * 99 / 100\n#> [1] 570.6\n```\n:::\n\n\n\n\npu√≤ essere ricavata usando le regole di Wright nel modo seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n0.199 * 429.43 + 1.085 * 446.93\n#> [1] 570.4\n```\n:::\n\n\n\n\nLa quota di varianza non spiegata della variabile endogena √®:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(var(dat$y) * 99 / 100) - (\n    0.199^2 * 429.43 + (1.085)^2 * 1192.84 + 2 * (0.199 * 1.085 * 446.93)\n)\n#> [1] 897.9\n```\n:::\n\n\n\n:::\n\n\n## Oltre la Regressione Multipla\n\nL'analisi del percorso (*path analysis*) estende le potenzialit√† della regressione multipla, consentendo di specificare e testare relazioni pi√π complesse tra un insieme di variabili. Per illustrare come applicare questa tecnica, possiamo far riferimento allo studio di @barbeau2019path, che presenta sia un modello di mediazione sia un modello pi√π articolato.\n\n### L‚Äôanalisi di mediazione\n\nL‚Äôanalisi di mediazione studia in che modo una variabile indipendente ($X$) influisce su una variabile dipendente ($Y$) attraverso una o pi√π variabili intermedie, dette **mediatrici** ($M$). Questo approccio va oltre la semplice regressione multipla, poich√© non si limita a osservare se $X$ predice $Y$, ma esplora anche i meccanismi che mediano tale relazione.\n\nUn esempio rilevante √® tratto dalla **Self-Determination Theory** (SDT) di Deci e Ryan (2000). Tale teoria indaga come la soddisfazione e la frustrazione dei bisogni psicologici fondamentali influiscano sui sintomi bulimici in giovani donne adulte. In breve:\n\n- I bisogni di autonomia, competenza e relazionalit√† risultano fondamentali per il benessere psicologico.\n- La loro frustrazione pu√≤ favorire comportamenti disfunzionali, mentre la loro soddisfazione pu√≤ fungere da fattore protettivo (Vansteenkiste & Ryan, 2013).\n\n### Un modello concettuale di mediazione\n\nNello studio, @barbeau2019path ipotizzano un modello in cui la **frustrazione dei bisogni psicologici** predice (1) l‚Äôapprovazione degli ideali culturali di magrezza e (2) l‚Äôinflessibilit√† negli schemi corporei, contribuendo infine a incrementare i sintomi bulimici. Nello specifico:\n\n1. **Frustrazione dei bisogni (X)**  \n   - Favorisce l‚Äôapprovazione di ideali culturali di magrezza (M).  \n   - √à associata a maggiore inflessibilit√† negli schemi corporei (Y1).\n\n2. **Approvazione degli ideali (M)**  \n   - Predice l‚Äôinflessibilit√† negli schemi corporei (Y1).\n\n3. **Inflessibilit√† degli schemi corporei (Y1)**  \n   - Media gli effetti della frustrazione dei bisogni (X) sui sintomi bulimici (Y2).\n\nQuesto modello teorico postula che la frustrazione dei bisogni psicologici (X) diminuisca le risorse per resistere agli ideali culturali disfunzionali, incrementando cos√¨ il rischio di sintomi bulimici (Y2). Pertanto, l‚Äôinflessibilit√† negli schemi corporei e l‚Äôapprovazione di tali ideali diventano fattori chiave per comprendere in che modo l‚Äôeffetto di X possa manifestarsi in comportamenti disfunzionali (Pelletier & Dion, 2007).\n\n### Formalizzazione e stima del modello\n\nNel caso pi√π semplice di mediazione singola, il modello pu√≤ essere espresso da due equazioni di regressione:\n\n1. **Equazione per il mediatore ($M$):**\n   $$\n   M = a_0 + a \\cdot X + e_M,\n   $$\n   dove $a$ √® l‚Äôeffetto di $X$ su $M$, ed $e_M$ √® il termine di errore.\n\n2. **Equazione per la variabile dipendente ($Y$):**\n   $$\n   Y = b_0 + b \\cdot M + c' \\cdot X + e_Y,\n   $$\n   dove $b$ √® l‚Äôeffetto di $M$ su $Y$, e $c'$ √® l‚Äôeffetto diretto di $X$ su $Y$ non mediato da $M$.\n\nIn questo contesto, possiamo distinguere:\n\n- **Effetto diretto ($c'$)**: influenza di $X$ su $Y$ che non passa attraverso il mediatore $M$.  \n- **Effetto indiretto ($a \\cdot b$)**: componente dell‚Äôeffetto di $X$ su $Y$ che avviene attraverso $M$.  \n- **Effetto totale ($c' + a \\cdot b$)**: somma degli effetti diretto e indiretto, rappresenta l‚Äôinfluenza complessiva di $X$ su $Y$.\n\n### Il caso di studio @barbeau2019path\n\nLo studio di @barbeau2019path ha coinvolto 192 partecipanti e ha utilizzato i seguenti strumenti di misura:\n\n- **Frustrazione e soddisfazione dei bisogni:** *Basic Psychological Needs Satisfaction and Frustration Scale* (Chen et al., 2015).  \n- **Approvazione degli ideali di magrezza:** *Endorsement of Societal Beliefs Related to Thinness and Obesity* (Boyer, 1991).  \n- **Inflessibilit√† degli schemi corporei:** *Body Image-Acceptance and Action Questionnaire* (Sandoz et al., 2013).  \n- **Sintomi bulimici:** *Eating Disorders Inventory-2* (Garner, 1991).\n\nLa matrice di covarianza delle variabili √® caricata in R come segue:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nupper <- '\n  1 0.44 -0.41 0.55 0.63\n  1 -0.37 0.45 0.44\n  1 -0.71 -0.39\n  1 0.47\n  1\n'\ndat_cov <- lavaan::getCov(\n    upper,\n    lower = FALSE,\n    names = c(\"BFLX\", \"END\", \"MNS\", \"MNF\", \"BULS\")\n)\ndat_cov\n#>       BFLX   END   MNS   MNF  BULS\n#> BFLX  1.00  0.44 -0.41  0.55  0.63\n#> END   0.44  1.00 -0.37  0.45  0.44\n#> MNS  -0.41 -0.37  1.00 -0.71 -0.39\n#> MNF   0.55  0.45 -0.71  1.00  0.47\n#> BULS  0.63  0.44 -0.39  0.47  1.00\n```\n:::\n\n\n\n\nAbbiamo:\n\n- **BFLX** (*Body Inflexibility*) come variabile endogena.\n- **MNF** (*Mean Need Frustration*) come variabile esogena.\n- **END** (*Endorsement of Societal Beliefs*) come variabile mediatrice.\n\n#### Specifica del modello di mediazione\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- \"\n  # Effetto diretto\n  BFLX ~ c*MNF\n  \n  # Mediatore\n  BFLX ~ b*END\n  END  ~ a*MNF\n\n  # Effetto indiretto\n  ab := a*b\n\n  # Effetto totale\n  total := c + (a*b)\n\"\n```\n:::\n\n\n\n\nDopo l‚Äôadattamento del modello alla matrice di covarianza (con 192 osservazioni),\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- sem(\n    mod,\n    sample.cov = dat_cov,\n    sample.nobs = 192\n)\n```\n:::\n\n\n\n\nl‚Äôoutput di `lavaan` fornisce i coefficienti $a, b, c'$ e i relativi errori standard, nonch√© le misure di bont√† di adattamento. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(\n  fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE\n)\n#> lavaan 0.6-19 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         5\n#> \n#>   Number of observations                           192\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 0.000\n#>   Degrees of freedom                                 0\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               125.849\n#>   Degrees of freedom                                 3\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    1.000\n#>   Tucker-Lewis Index (TLI)                       1.000\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)               -480.945\n#>   Loglikelihood unrestricted model (H1)       -480.945\n#>                                                       \n#>   Akaike (AIC)                                 971.890\n#>   Bayesian (BIC)                               988.178\n#>   Sample-size adjusted Bayesian (SABIC)        972.339\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.000\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.000\n#>   P-value H_0: RMSEA <= 0.050                       NA\n#>   P-value H_0: RMSEA >= 0.080                       NA\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.000\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   BFLX ~                                                                \n#>     MNF        (c)    0.441    0.065    6.769    0.000    0.441    0.441\n#>     END        (b)    0.241    0.065    3.702    0.000    0.241    0.241\n#>   END ~                                                                 \n#>     MNF        (a)    0.450    0.064    6.982    0.000    0.450    0.450\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .BFLX              0.648    0.066    9.798    0.000    0.648    0.651\n#>    .END               0.793    0.081    9.798    0.000    0.793    0.797\n#> \n#> R-Square:\n#>                    Estimate\n#>     BFLX              0.349\n#>     END               0.203\n#> \n#> Defined Parameters:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     ab                0.109    0.033    3.271    0.001    0.109    0.109\n#>     total             0.550    0.060    9.125    0.000    0.550    0.550\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit,\n    layout = \"tree\", sizeMan = 7, sizeInt = 5, style = \"ram\",\n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 1.15,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nNello studio originale, @barbeau2019path stimano $a = 0.37$, $b = 0.29$, $c = 0.34$ (utilizzando Mplus). L‚Äôoutput di `lavaan` in R risulta molto simile (anche se non identico) a tali valori.\n\n- **Effetto diretto di MNF su BFLX:** $c' = 0.44$\n- **Effetto indiretto:** $a \\cdot b = 0.45 \\cdot 0.24 = 0.109$\n- **Effetto totale:** $c' + a \\cdot b = 0.44 + 0.109 = 0.55$\n\nI valori riportati nell'output di lavaan includono anche gli errori standard e i test per verificare se gli effetti siano significativamente diversi da zero.\n\nLe correlazioni tra le variabili possono essere calcolate combinando i coefficienti di percorso. Ad esempio:\n\n- Correlazione tra BFLX e MNF:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n.44 + .45 * .24\n#> [1] 0.548\n```\n:::\n\n\n\n\n- Correlazione tra BFLX e END:\n  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n.24 + .44 * .45\n#> [1] 0.438\n```\n:::\n\n\n\n\nLa varianza spiegata dalle variabili esogene per le due variabili endogene √® riportata nell'output di lavaan. Ad esempio, la varianza spiegata di END √® calcolata come:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n0.45^2\n#> [1] 0.2025\n```\n:::\n\n\n\n\n### Interpretazione dei risultati\n\n- **Effetto diretto ($c'$)**: quantifica l‚Äôinfluenza di MNF (frustrazione dei bisogni) su BFLX (inflessibilit√† corporea) che non passa attraverso END (approvazione degli ideali).  \n- **Effetto indiretto ($a \\cdot b$)**: misura quanto MNF influisce su BFLX mediato da END.  \n- **Effetto totale**: somma dei due effetti precedenti, rappresenta l‚Äôimpatto complessivo di MNF su BFLX.\n\nAttraverso la funzione `summary(...)` di `lavaan`, si possono ottenere:\n\n1. **Valori stimati e test di significativit√†** per ciascun coefficiente.  \n2. **Misure di adattamento** del modello (CFI, TLI, RMSEA, ecc.).  \n3. **Varianza spiegata (R¬≤)** per ciascuna variabile endogena.\n\n### Espandere il modello: una struttura pi√π complessa\n\nPer esaminare relazioni ancora pi√π ricche, @barbeau2019path presentano un modello [Fig. 4 nel loro articolo] che include:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- \"\n  BULS ~ MNF + BFLX\n  BFLX ~ END + MNF\n  END  ~ MNS + MNF\n\"\n```\n:::\n\n\n\n\ndove:\n\n- **BULS** (sintomi bulimici) √® predetto da MNF (frustrazione bisogni) e BFLX (inflessibilit√† corporea).\n- **BFLX** √® predetta da END (approvazione ideali) e MNF.\n- **END** √® predetta a sua volta sia da MNS (soddisfazione dei bisogni) sia da MNF.\n\nAdattando questo modello con `lavaan`, \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit2 <- sem(\n    mod,\n    sample.cov = dat_cov,\n    sample.nobs = 192\n)\n```\n:::\n\n\n\n\npossiamo osservare come, rispetto al caso di mediazione semplice, si aggiungano percorsi multipli e ulteriori relazioni tra le variabili. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(\n  fit2, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE\n)\n#> lavaan 0.6-19 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         9\n#> \n#>   Number of observations                           192\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 8.229\n#>   Degrees of freedom                                 3\n#>   P-value (Chi-square)                           0.042\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               239.501\n#>   Degrees of freedom                                 9\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.977\n#>   Tucker-Lewis Index (TLI)                       0.932\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)               -700.169\n#>   Loglikelihood unrestricted model (H1)       -696.054\n#>                                                       \n#>   Akaike (AIC)                                1418.338\n#>   Bayesian (BIC)                              1447.655\n#>   Sample-size adjusted Bayesian (SABIC)       1419.146\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.095\n#>   90 Percent confidence interval - lower         0.017\n#>   90 Percent confidence interval - upper         0.176\n#>   P-value H_0: RMSEA <= 0.050                    0.130\n#>   P-value H_0: RMSEA >= 0.080                    0.696\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   BULS ~                                                                \n#>     MNF               0.177    0.066    2.688    0.007    0.177    0.177\n#>     BFLX              0.533    0.066    8.085    0.000    0.533    0.533\n#>   BFLX ~                                                                \n#>     END               0.241    0.065    3.702    0.000    0.241    0.241\n#>     MNF               0.441    0.065    6.769    0.000    0.441    0.441\n#>   END ~                                                                 \n#>     MNS              -0.102    0.091   -1.116    0.264   -0.102   -0.102\n#>     MNF               0.378    0.091    4.140    0.000    0.378    0.378\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .BULS              0.578    0.059    9.798    0.000    0.578    0.581\n#>    .BFLX              0.648    0.066    9.798    0.000    0.648    0.651\n#>    .END               0.788    0.080    9.798    0.000    0.788    0.792\n#> \n#> R-Square:\n#>                    Estimate\n#>     BULS              0.419\n#>     BFLX              0.349\n#>     END               0.208\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit2,\n    layout = \"tree\", sizeMan = 7, sizeInt = 1, style = \"ram\",\n    residuals = TRUE, intAtSide = FALSE, edge.label.cex = 1.15,\n    whatLabels = \"est\", nCharNodes = 0, normalize = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_path_analysis_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesto consente di:\n\n1. **Separare gli effetti** di soddisfazione (MNS) e frustrazione (MNF) dei bisogni.  \n2. **Verificare ipotesi** pi√π articolate sulla genesi dei sintomi bulimici, con effetti diretti e indiretti che passano attraverso END e BFLX.  \n3. **Confrontare i risultati** (coefficenti di percorso, varianze spiegate) con quelli riportati da @barbeau2019path, per valutare la replicabilit√† e la robustezza del modello.\n\nAd esempio, la correlazione tra MNF e BULS pu√≤ essere calcolata come somma degli effetti diretti e indiretti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n-.71 * -.10 * .24 * .53 +\n.38 * .24 * .53 +\n.44 * .53 +\n.18\n#> [1] 0.4706\n```\n:::\n\n\n\n\nIl valore risultante corrisponde al valore osservato nel campione (0.47), confermando la coerenza del modello stimato.\n\nLe varianze spiegate riportate nel loro articolo sono:  \n\n- **END**: 0.209 (contro 0.208 stimate da `lavaan`)  \n- **BFLX**: 0.292 (contro 0.349 stimate da `lavaan`)  \n- **BULS**: 0.478 (contro 0.419 stimate da `lavaan`)\n\nLe piccole differenze sono attese, data la diversit√† di software (Mplus vs `lavaan`) e di possibili configurazioni di stima. Tuttavia, l‚Äôandamento generale e l‚Äôinterpretazione dei risultati rimangono concordi.\n\n1. **Il modello di mediazione** chiarisce come una variabile $X$ influisca su $Y$ attraverso uno o pi√π mediatori ($M$).  \n2. **Il passaggio a modelli pi√π complessi** consente di includere pi√π variabili e relazioni simultaneamente (ad es., frustrazione e soddisfazione dei bisogni psicologici, inflessibilit√† corporea, approvazione di ideali culturali, sintomi bulimici).  \n3. **La coerenza tra software diversi** (Mplus vs `lavaan`) √® elevata, bench√© possano emergere lievi differenze numeriche.  \n4. **La comprensione degli effetti diretti, indiretti e totali** supporta l‚Äôinterpretazione teorica e pratica dei risultati, fornendo spunti per la ricerca futura e per gli interventi clinici.\n\n**In sintesi**, l‚Äôanalisi del percorso (*path analysis*) offre una panoramica ben pi√π ricca delle relazioni tra variabili rispetto alla regressione multipla tradizionale. Grazie alla possibilit√† di specificare *modelli di mediazione* e di integrare diverse variabili esogene ed endogene in un‚Äôunica struttura, si possono testare ipotesi complesse e articolate sulla base di teorie solide (come la Self-Determination Theory).\n\n## Modellare le Medie nella Path Analysis\n\nLa *path analysis* (analisi dei percorsi) consente di descrivere e testare relazioni complesse tra variabili, ma non si limita a indagare le loro covarianze o correlazioni. Un aspetto spesso trascurato, infatti, √® la possibilit√† di *modellare* anche le **medie** delle variabili manifeste all‚Äôinterno della struttura di analisi. Includere le medie permette di ottenere una visione pi√π completa del fenomeno in studio, valutando non solo *come* le variabili si influenzano reciprocamente, ma anche *a quali livelli medi* tali variabili si stabilizzano.\n\n### Perch√© modellare le medie\n\nNella maggior parte delle analisi, si √® abituati a focalizzarsi principalmente sui rapporti di covarianza o correlazione tra le variabili (ovvero, le relazioni *relazionali* o di *struttura*). Tuttavia, anche i valori medi di tali variabili (la *struttura delle medie*) possono fornire informazioni preziose, specialmente se:\n\n- **si desidera confrontare** gruppi diversi su un set di variabili latenti o manifeste, tenendo conto di differenze sia nelle relazioni sia nei livelli medi;\n- **si sospetta la presenza di bias** sistematici nelle medie (ad esempio, variabili esogene non misurate che causano una tendenza a punteggi pi√π alti o pi√π bassi);\n- **si cerca un modello ‚Äúcompleto‚Äù** che spieghi simultaneamente varianze, covarianze e scostamenti nelle medie di alcune variabili chiave.\n\n### Passaggi chiave per la modellazione delle medie\n\n1. **Raccolta dei dati**  \n   - Oltre a una matrice di covarianza (o correlazione) che riassume le relazioni tra le variabili, √® necessario disporre anche delle medie *osservate* di ciascuna variabile.  \n   - Questi dati costituiscono l‚Äôinput fondamentale per specificare sia la struttura delle covarianze, sia quella delle medie nel modello.\n\n2. **Specifica del modello**  \n   - Il modello deve rappresentare contemporaneamente la *struttura di covarianza* (relazioni tra le variabili) e la *struttura delle medie* (livelli medi di ciascuna variabile).  \n   - In termini pratici, ci√≤ implica che si fornisce a `lavaan` (o altro software di SEM) la matrice di covarianza *e* il vettore delle medie, oltre al numero di osservazioni.\n\n3. **Integrazione delle medie nel modello**  \n   - Per le variabili **esogene** (non predette da altre variabili nel modello), le loro medie corrispondono ai valori osservati o alle intercette specificate nel modello.  \n   - Per le variabili **endogene** (predette da altre variabili), bisogna includere **le intercette** nelle relative equazioni strutturali. Tali intercette sono i termini costanti che indicano il valore atteso della variabile endogena quando tutte le variabili predittive valgono zero (o, pi√π spesso, i loro valori centrati).\n\n4. **Costante ‚Äú1‚Äù per il modello delle medie**  \n   - Nei software di SEM (come `lavaan`), si inserisce una variabile costante (spesso indicata semplicemente come ‚Äú1‚Äù) tra i predittori, in modo da stimare esplicitamente l‚Äôintercetta di ogni variabile coinvolta.  \n   - In `lavaan`, ci√≤ si realizza di solito in automatico specificando le variabili endogene e abilitando la stima delle intercette (`meanstructure = TRUE`).\n\n5. **Stima del modello**  \n   - Nel momento in cui si adatta il modello, vengono simultaneamente stimate (a) le relazioni tra le variabili e (b) i valori medi previsti dal modello per ogni variabile endogena.  \n   - Il software produce quindi *residui* delle medie, confrontando i valori osservati con quelli previsti. Se i residui sono elevati, potrebbe essere necessario rivedere la specificazione del modello.\n\n### Come si calcolano le medie previste\n\nPer una variabile endogena $\\displaystyle Y$, consideriamo la classica equazione di regressione:\n\n$$\nY = c_0 + \\sum_{i=1}^p b_i X_i + \\varepsilon,\n$$\n\ndove\n\n- $c_0$ √® l‚Äôintercetta (ovvero il valore medio previsto per $Y$ quando tutte le $X$ sono zero o ai loro valori di riferimento);\n- $b_i$ sono i coefficienti di percorso che collegano le variabili predittive $X_i$ a $Y$;\n- $X_i$ rappresentano le variabili esplicative;\n- $\\varepsilon$ √® il termine di errore, la cui media √® zero.\n\nLa **media prevista** di $Y$ ($\\mu_Y$) si ottiene come:\n\n$$\n\\mu_Y = c_0 + \\sum_{i=1}^p b_i \\mu_{X_i},\n$$\n\ndove $\\mu_{X_i}$ √® la media osservata di ciascun predittore $X_i$. Dato che $\\varepsilon$ ha media zero, non contribuisce alla media complessiva di $Y$.\n\n#### Esempio numerico\n\nSupponiamo di avere la seguente equazione:\n\n$$\nY = 2.5 + 0.6 \\, X_1 \\;-\\; 0.3 \\, X_2 + \\varepsilon,\n$$\n\ne che le medie osservate dei predittori siano:\n\n- $\\mu_{X_1} = 4$\n- $\\mu_{X_2} = 3$\n\nLa media prevista di $Y$ sar√†:\n\n$$\n\\mu_Y \n= 2.5 \\;+\\; (0.6 \\cdot 4) \\;+\\; (-0.3 \\cdot 3)\n= 2.5 \\;+\\; 2.4 \\;-\\; 0.9\n= 4.0.\n$$\n\nSe la media osservata di $Y$ fosse $\\bar{Y} = 4.2$, il *residuo di media* risulterebbe:\n\n$$\n\\bar{Y} - \\mu_Y\n= 4.2 - 4.0\n= 0.2.\n$$\n\nUn residuo di media di 0.2 significa che il modello sottostima la media osservata di $Y$ di 0.2 punti.\n\n### Perch√© i residui delle medie sono importanti\n\nIl confronto tra le medie previste e quelle osservate (attraverso i residui di media) offre un indicatore critico sull‚Äôadeguatezza del modello. Se i residui:\n\n- **sono piccoli e non sistematici**, il modello approssima bene le medie osservate.  \n- **sono ampi o mostrano uno schema ricorrente**, potrebbe esserci un errore di specificazione. Ci√≤ potrebbe richiedere di:\n  - aggiungere ulteriori predittori;  \n  - ridefinire la struttura del modello (ad esempio, aggiungere variabili latenti o interazioni);  \n  - riconsiderare la scala di misura (ad esempio, centrare o trasformare le variabili).\n\n**In sintesi**, integrare la **struttura delle medie** in un‚Äôanalisi dei percorsi amplia la prospettiva offerta dai soli rapporti di covarianza, consentendo di:\n\n1. **verificare l‚Äôadeguatezza del modello** non solo in termini di relazioni (covarianze) tra variabili, ma anche rispetto ai livelli medi osservati;  \n2. **ottenere stime pi√π complete e interpretabili**, specialmente in studi dove i valori medi rivestono un ruolo teorico importante (es. fenomeni clinici, differenze di gruppo, effetti di trattamento);  \n3. **diagnosticarne eventuali insufficienze**, intervenendo tempestivamente sulla specificazione del modello se i residui di media risultano elevati.\n\nIn definitiva, la capacit√† di modellare e valutare le medie permette di formulare una rappresentazione pi√π articolata e accurata del fenomeno in studio, massimizzando il potere esplicativo della path analysis.\n\n## Riflessioni Conclusive \n\nIl diagramma di un modello di *path analysis* non √® semplicemente uno strumento di calcolo, ma anche un mezzo privilegiato per comuicare efficacemente la complessit√† delle relazioni tra variabili. Attraverso una rappresentazione grafica chiara e sistematica ‚Äî basata spesso sul formalismo RAM (McArdle e McDonald) ‚Äî √® possibile tradurre in simboli visivi (frecce, nodi, annotazioni) le specifiche computazionali di un modello, rivelando a colpo d‚Äôocchio i percorsi diretti e indiretti, le covarianze e i nodi teoricamente rilevanti.\n\nGrazie a questa **componente visiva**:\n\n- le **frecce unidirezionali** indicano le relazioni di influenza (o percorsi causali) tra variabili, illuminando le direzioni d‚Äôeffetto che il ricercatore intende esplorare o testare;\n- le **frecce bidirezionali** sintetizzano covarianze o correlazioni, mostrando relazioni simmetriche o non direzionali tra variabili;  \n- i **nodi** rappresentano le variabili, che possono essere manifeste o latenti, rendendo esplicito il livello di astrazione su cui si fonda l‚Äôanalisi.  \n\nOgni etichetta o costante di scala chiarisce come i parametri vengano interpretati, permettendo a chiunque consulti il diagramma di riconoscere immediatamente le ipotesi fondamentali del modello. In questo modo, la path analysis agevola sia la comunicazione tra esperti sia la traduzione del modello in istruzioni per i software statistici (ad esempio, la sintassi di `lavaan` o Mplus).\n\nSotto il profilo analitico, la *path analysis* offre una visione dettagliata delle **relazioni dirette**, delle **relazioni indirette** (o effetti mediati) e delle **associazioni complessive** tra le variabili. Mediante la decomposizione di covarianze e correlazioni in percorsi elementari, si ottiene un quadro interpretativo che evidenzia:\n\n1. **effetti di influenza specifici** (coefficienti di percorso) e i loro livelli di significativit√†;  \n2. **processi di mediazione** o moderazione, svelando come alcune variabili possano veicolare o modulare gli effetti di altre;  \n3. **sovrapposizioni e interazioni complesse**, che possono emergere dall‚Äôanalisi combinata di percorsi multipli.\n\nIn definitiva, la path analysis si configura come uno strumento di ricerca potente ed elegante, in grado di coniugare rigore metodologico e chiarezza espositiva. La sua **natura visiva e strutturata** favorisce il pensiero teorico, consentendo ai ricercatori di esplorare ipotesi causali e di comunicare i risultati in modo intuitivo e accessibile. Questo equilibrio tra analisi statistica e interpretazione teorica permette di valorizzare le connessioni fra le variabili, offrendo una solida base per una comprensione approfondita e condivisa dei processi in esame.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] dagitty_0.3-4     ggdag_0.2.13      ggokabeito_0.1.0  see_0.11.0       \n#>  [5] MASS_7.3-65       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#>  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#> [13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12     \n#> [17] scales_1.3.0      markdown_1.13     knitr_1.50        lubridate_1.9.4  \n#> [21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#> [25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#> [29] tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.1      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.2.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   curl_6.2.1          broom_1.0.7        \n#>  [16] Formula_1.2-5       htmlwidgets_1.6.4   plyr_1.8.9         \n#>  [19] sandwich_3.1-1      emmeans_1.10.7      zoo_1.8-13         \n#>  [22] igraph_2.1.4        mime_0.13           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-3        R6_2.6.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] digest_0.6.37       OpenMx_2.21.13      fdrtool_1.2.18     \n#>  [34] colorspace_2.1-1    rprojroot_2.0.4     Hmisc_5.2-3        \n#>  [37] timechange_0.3.0    abind_1.4-8         compiler_4.4.2     \n#>  [40] withr_3.0.2         glasso_1.11         htmlTable_2.4.3    \n#>  [43] backports_1.5.0     carData_3.0-5       ggsignif_0.6.4     \n#>  [46] corpcor_1.6.10      gtools_3.9.5        tools_4.4.2        \n#>  [49] pbivnorm_0.6.0      foreign_0.8-88      zip_2.3.2          \n#>  [52] httpuv_1.6.15       nnet_7.3-20         glue_1.8.0         \n#>  [55] quadprog_1.5-8      nlme_3.1-167        promises_1.3.2     \n#>  [58] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [61] cluster_2.1.8.1     reshape2_1.4.4      generics_0.1.3     \n#>  [64] gtable_0.3.6        tzdb_0.5.0          data.table_1.17.0  \n#>  [67] hms_1.1.3           tidygraph_1.3.1     car_3.1-3          \n#>  [70] sem_3.1-16          pillar_1.10.1       rockchalk_1.8.157  \n#>  [73] later_1.4.1         splines_4.4.2       lattice_0.22-6     \n#>  [76] survival_3.8-3      kutils_1.73         tidyselect_1.2.1   \n#>  [79] miniUI_0.1.1.1      pbapply_1.7-2       reformulas_0.4.0   \n#>  [82] V8_6.0.2            stats4_4.4.2        xfun_0.51          \n#>  [85] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [88] pacman_0.5.1        boot_1.3-31         evaluate_1.0.3     \n#>  [91] codetools_0.2-20    mi_1.1              cli_3.6.4          \n#>  [94] RcppParallel_5.1.10 rpart_4.1.24        xtable_1.8-4       \n#>  [97] Rdpack_2.6.3        munsell_0.5.1       Rcpp_1.0.14        \n#> [100] coda_0.19-4.1       png_0.1-8           XML_3.99-0.18      \n#> [103] parallel_4.4.2      jpeg_0.1-10         lme4_1.1-36        \n#> [106] mvtnorm_1.3-3       openxlsx_4.2.8      rlang_1.1.5        \n#> [109] multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "01_path_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
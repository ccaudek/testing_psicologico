{
  "hash": "629faa32589a6a9b34e08cb9d747db24",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lo Sviluppo dell'Intelligenza\"\nformat: html\neditor: source\n---\n\n\n\n\n**Prerequisiti**\n\n**Concetti e Competenze Chiave**\n\n**Preparazione del Notebook**\n\n\n\n\n\n::: {.cell}\n\n```{.r .fold-show .cell-code}\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |> source()\n\nif(!require(\"pacman\")){install.packages(\"pacman\",repos = \"http://cran.us.r-project.org\")}\n\npacman::p_load(lavaan, tidyverse, here, reshape2)\n```\n:::\n\n\n\n\n## Introduzione\n\nQuesta discussione riproduce il tutorial presentato nel [Workshop on Latent Growth Modeling in Lavaan](https://github.com/njudd/LGC_Workshop/tree/main) tenuto al Donders Institute nel novembre 2024. Questo tutorial riprende in un unico studio i concetti che avevamo esaminato nei capitoli precedenti. Verranno utilizzati dei dati longitudinali relativi al WISC-V forniti dagli autori a 6, 7, 9 e 11 anni.\n\n## Dati\n\nIl WISC-V Test (Wechsler Intelligence Scale for Children) è un test del QI somministrato a bambini di età compresa tra 6 e 16 anni. Fornisce cinque punteggi indici principali, ovvero Indice di Comprensione Verbale, Indice Visuo-Spaziale, Indice di Ragionamento Fluido, Indice di Memoria di Lavoro e Indice di Velocità di Elaborazione. Nel workshop gli autori discutono su un sottoinsieme contenente: Indice di Comprensione Verbale, Indice di Velocità di Elaborazione e il totale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\nwisc <- rio::import(\n  here::here(\n    \"data\", \"wisc.csv\"\n  )\n)[,-1]\n\nhead(wisc)         #first 6 rows\n#>   ID Verbal_T6 Verbal_T7 Verbal_T9 Verbal_T11 Pspeed_T6 Pspeed_T7 Pspeed_T9\n#> 1  0      24.4      27.0      39.6       55.6     19.84      23.0      43.9\n#> 2  1      12.4      14.4      21.9       37.8      5.90      13.4      18.3\n#> 3  2      32.4      33.5      34.3       50.2     27.64      45.0      47.0\n#> 4  3      22.7      28.4      42.2       44.7     33.16      29.7      46.0\n#> 5  4      28.2      37.8      41.1       71.0     27.64      44.4      65.5\n#> 6  5      16.1      20.1      38.0       39.9      8.45      15.8      27.0\n#>   Pspeed_T11 Total_6 Total_7 Total_9 Total_11 age_T6 sex race mo_edu\n#> 1       44.2   22.13    25.0    41.8     49.9   5.83   1    1      4\n#> 2       40.4    9.17    13.9    20.1     39.1   5.92   2    2      6\n#> 3       77.7   30.03    39.3    40.6     63.9   6.33   1    1      2\n#> 4       61.7   27.93    29.0    44.1     53.2   6.33   2    1      2\n#> 5       64.2   27.93    41.1    53.3     67.6   6.17   1    1      3\n#> 6       39.1   12.25    17.9    32.5     39.5   5.67   1    1      2\n#>   mo_educat fa_edu fa_educat\n#> 1         0      4         0\n#> 2         0      5         0\n#> 3         2      3         1\n#> 4         2      2         2\n#> 5         1      3         1\n#> 6         2      2         2\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(wisc)          #number of rows and columns\n#> [1] 204  20\n```\n:::\n\n\n\n\nGli autori si concentrano sull'analisi dei dati del subtest verbale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\nwisc_verbal <- wisc[,c(\"ID\",\"Verbal_T6\",\"Verbal_T7\",\"Verbal_T9\",\"Verbal_T11\")]\nglimpse(wisc_verbal)\n#> Rows: 204\n#> Columns: 5\n#> $ ID         <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 21, 2…\n#> $ Verbal_T6  <dbl> 24.4, 12.4, 32.4, 22.7, 28.2, 16.1, 8.5, 14.1, 15.5, 20…\n#> $ Verbal_T7  <dbl> 27.0, 14.4, 33.5, 28.4, 37.8, 20.1, 16.5, 20.9, 23.4, 3…\n#> $ Verbal_T9  <dbl> 39.6, 21.9, 34.3, 42.2, 41.1, 38.0, 28.7, 21.5, 37.4, 3…\n#> $ Verbal_T11 <dbl> 55.6, 37.8, 50.2, 44.7, 71.0, 39.9, 40.8, 25.7, 45.5, 4…\n```\n:::\n\n\n\n\nI dati vanno trasformati nel formato long.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\nwisc_verbal_long <- wisc_verbal %>% \n  pivot_longer(!ID, names_to = \"wave\", values_to = \"verbal\")\n\nwisc_verbal_long |> head()\n#> # A tibble: 6 × 3\n#>      ID wave       verbal\n#>   <int> <chr>       <dbl>\n#> 1     0 Verbal_T6    24.4\n#> 2     0 Verbal_T7    27.0\n#> 3     0 Verbal_T9    39.6\n#> 4     0 Verbal_T11   55.6\n#> 5     1 Verbal_T6    12.4\n#> 6     1 Verbal_T7    14.4\n```\n:::\n\n\n\n\nUn grafico dei dati si ottiene nel modo seguente.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\nwisc_verbal_long$wave = factor(wisc_verbal_long$wave, levels=c(\"Verbal_T6\",\"Verbal_T7\",\"Verbal_T9\",\"Verbal_T11\"))\n\nggplot(wisc_verbal_long, aes(wave, verbal, group=ID, fill=ID, color=ID)) +\n  geom_point() + \n  geom_line() +\n  theme_classic(base_size = 15) + # adding a classic theme; https://ggplot2.tidyverse.org/reference/ggtheme.html\n  theme(legend.position = \"none\") + # getting rid of legend\n  labs(x = \"Wave\", y = \"Score on Verbal Subtest\")\n```\n\n::: {.cell-output-display}\n![](11_lgm_wais_files/figure-html/plotdata-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Modello lineare\n\nIl modello più semplice è quello di crescita lineare.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Create LGM\nlinear_growth_model <- '\n  i =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n  s =~ 0*Verbal_T6 + 1*Verbal_T7 + 2*Verbal_T9 + 3*Verbal_T11'\n\n```\n:::\n\n\n\n\nAdattiamo il modello ai dati ed esaminiamo i risultati.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Fit LGM\nfit_linear_growth_model <- growth(linear_growth_model, data=wisc_verbal,missing='fiml')\n# Output results\nsummary(fit_linear_growth_model, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 65 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         9\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               100.756\n#>   Degrees of freedom                                 5\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               585.906\n#>   Degrees of freedom                                 6\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.835\n#>   Tucker-Lewis Index (TLI)                       0.802\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.835\n#>   Robust Tucker-Lewis Index (TLI)                0.802\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2530.194\n#>   Loglikelihood unrestricted model (H1)      -2479.816\n#>                                                       \n#>   Akaike (AIC)                                5078.388\n#>   Bayesian (BIC)                              5108.251\n#>   Sample-size adjusted Bayesian (SABIC)       5079.736\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.306\n#>   90 Percent confidence interval - lower         0.256\n#>   90 Percent confidence interval - upper         0.360\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    1.000\n#>                                                       \n#>   Robust RMSEA                                   0.306\n#>   90 Percent confidence interval - lower         0.256\n#>   90 Percent confidence interval - upper         0.360\n#>   P-value H_0: Robust RMSEA <= 0.050             0.000\n#>   P-value H_0: Robust RMSEA >= 0.080             1.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.113\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i =~                                                                  \n#>     Verbal_T6         1.000                               4.354    0.775\n#>     Verbal_T7         1.000                               4.354    0.681\n#>     Verbal_T9         1.000                               4.354    0.583\n#>     Verbal_T11        1.000                               4.354    0.417\n#>   s =~                                                                  \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         1.000                               1.251    0.196\n#>     Verbal_T9         2.000                               2.502    0.335\n#>     Verbal_T11        3.000                               3.752    0.360\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i ~~                                                                  \n#>     s                 5.081    1.079    4.709    0.000    0.933    0.933\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     i                18.760    0.391   48.006    0.000    4.308    4.308\n#>     s                 7.291    0.192   38.007    0.000    5.829    5.829\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6        12.600    2.175    5.793    0.000   12.600    0.399\n#>    .Verbal_T7        10.213    1.463    6.982    0.000   10.213    0.250\n#>    .Verbal_T9        10.243    1.941    5.277    0.000   10.243    0.184\n#>    .Verbal_T11       45.410    5.781    7.855    0.000   45.410    0.417\n#>     i                18.961    3.154    6.012    0.000    1.000    1.000\n#>     s                 1.565    0.658    2.379    0.017    1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.601\n#>     Verbal_T7         0.750\n#>     Verbal_T9         0.816\n#>     Verbal_T11        0.583\n```\n:::\n\n\n\n\nIl modello non si adatta bene ai dati.\n\n## Crescita non lineare\n\nNell'analisi precedente, abbiamo modellato un modello di crescita lineare. Tuttavia, è anche possibile modellare una crescita non lineare in lavaan come una traiettoria quadratica. Per fare ciò, è necessario aggiungere un terzo parametro chiamato termine quadratico che avrà gli stessi loadings del coefficiente angolare, ma al quadrato.\n\nPer fare questo, è necessario specificare un'altra variabile latente nel modello chiamata termine quadratico. Al termine quadratico vengono assegnati loadings che sono i quadrati dei loadings del coefficiente angolare.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n\n# Create quadratic growth model\nquad_growth_model <- 'i =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n                      s =~ 0*Verbal_T6 + 1*Verbal_T7 + 2*Verbal_T9 + 3*Verbal_T11\n                      q =~ 0*Verbal_T6 + 1*Verbal_T7 + 4*Verbal_T9 + 9*Verbal_T11'\n# Fit model\nfit_quad_growth_model <- growth(quad_growth_model, data=wisc_verbal,missing='fiml')\n# Output results\nsummary(fit_quad_growth_model, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 99 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        13\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 6.176\n#>   Degrees of freedom                                 1\n#>   P-value (Chi-square)                           0.013\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               585.906\n#>   Degrees of freedom                                 6\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.991\n#>   Tucker-Lewis Index (TLI)                       0.946\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.991\n#>   Robust Tucker-Lewis Index (TLI)                0.946\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2482.904\n#>   Loglikelihood unrestricted model (H1)      -2479.816\n#>                                                       \n#>   Akaike (AIC)                                4991.808\n#>   Bayesian (BIC)                              5034.943\n#>   Sample-size adjusted Bayesian (SABIC)       4993.755\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.159\n#>   90 Percent confidence interval - lower         0.059\n#>   90 Percent confidence interval - upper         0.289\n#>   P-value H_0: RMSEA <= 0.050                    0.039\n#>   P-value H_0: RMSEA >= 0.080                    0.910\n#>                                                       \n#>   Robust RMSEA                                   0.159\n#>   90 Percent confidence interval - lower         0.059\n#>   90 Percent confidence interval - upper         0.289\n#>   P-value H_0: Robust RMSEA <= 0.050             0.039\n#>   P-value H_0: Robust RMSEA >= 0.080             0.910\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.023\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i =~                                                                  \n#>     Verbal_T6         1.000                               4.883    0.843\n#>     Verbal_T7         1.000                               4.883    0.800\n#>     Verbal_T9         1.000                               4.883    0.668\n#>     Verbal_T11        1.000                               4.883    0.459\n#>   s =~                                                                  \n#>     Verbal_T6         0.000                                  NA       NA\n#>     Verbal_T7         1.000                                  NA       NA\n#>     Verbal_T9         2.000                                  NA       NA\n#>     Verbal_T11        3.000                                  NA       NA\n#>   q =~                                                                  \n#>     Verbal_T6         0.000                                  NA       NA\n#>     Verbal_T7         1.000                                  NA       NA\n#>     Verbal_T9         4.000                                  NA       NA\n#>     Verbal_T11        9.000                                  NA       NA\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i ~~                                                                  \n#>     s                -0.564    6.937   -0.081    0.935   -0.064   -0.064\n#>     q                 2.014    1.811    1.112    0.266    0.738    0.738\n#>   s ~~                                                                  \n#>     q                 1.518    1.719    0.883    0.377    1.500    1.500\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     i                19.697    0.409   48.124    0.000    4.033    4.033\n#>     s                 4.051    0.354   11.439    0.000       NA       NA\n#>     q                 1.284    0.130    9.861    0.000       NA       NA\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6         9.730    6.209    1.567    0.117    9.730    0.290\n#>    .Verbal_T7        11.059    2.297    4.814    0.000   11.059    0.297\n#>    .Verbal_T9         9.542    2.677    3.564    0.000    9.542    0.179\n#>    .Verbal_T11       29.417   11.518    2.554    0.011   29.417    0.260\n#>     i                23.848    6.558    3.636    0.000    1.000    1.000\n#>     s                -3.277    7.053   -0.465    0.642       NA       NA\n#>     q                -0.312    0.656   -0.476    0.634       NA       NA\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.710\n#>     Verbal_T7         0.703\n#>     Verbal_T9         0.821\n#>     Verbal_T11        0.740\n```\n:::\n\n\n\n\nÈ anche possibile modellare una crescita non lineare in lavaan senza alcuna ipotesi sulla forma. Per farlo, si fissano i loadings della prima e dell'ultima misurazione, ma si stimano liberamente quelli intermedi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Create non-linear growth model\nbasis_growth_model <- 'i =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n                       s =~ 0*Verbal_T6 + Verbal_T7 + Verbal_T9 + 1*Verbal_T11'\n# Fit model\nfit_basis_growth_model <- growth(basis_growth_model, data=wisc_verbal,missing='fiml')\n# Output results\nsummary(fit_basis_growth_model, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 109 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        11\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 5.893\n#>   Degrees of freedom                                 3\n#>   P-value (Chi-square)                           0.117\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               585.906\n#>   Degrees of freedom                                 6\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.995\n#>   Tucker-Lewis Index (TLI)                       0.990\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.995\n#>   Robust Tucker-Lewis Index (TLI)                0.990\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2482.763\n#>   Loglikelihood unrestricted model (H1)      -2479.816\n#>                                                       \n#>   Akaike (AIC)                                4987.525\n#>   Bayesian (BIC)                              5024.024\n#>   Sample-size adjusted Bayesian (SABIC)       4989.173\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.069\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.151\n#>   P-value H_0: RMSEA <= 0.050                    0.275\n#>   P-value H_0: RMSEA >= 0.080                    0.491\n#>                                                       \n#>   Robust RMSEA                                   0.069\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.151\n#>   P-value H_0: Robust RMSEA <= 0.050             0.275\n#>   P-value H_0: Robust RMSEA >= 0.080             0.491\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.043\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i =~                                                                  \n#>     Verbal_T6         1.000                               4.610    0.825\n#>     Verbal_T7         1.000                               4.610    0.731\n#>     Verbal_T9         1.000                               4.610    0.620\n#>     Verbal_T11        1.000                               4.610    0.446\n#>   s =~                                                                  \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         0.237    0.012   20.223    0.000    1.300    0.206\n#>     Verbal_T9         0.536    0.012   43.295    0.000    2.937    0.395\n#>     Verbal_T11        1.000                               5.484    0.531\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i ~~                                                                  \n#>     s                15.072    3.133    4.811    0.000    0.596    0.596\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     i                19.634    0.391   50.221    0.000    4.259    4.259\n#>     s                24.180    0.565   42.773    0.000    4.409    4.409\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6         9.974    1.645    6.063    0.000    9.974    0.319\n#>    .Verbal_T7         9.704    1.307    7.422    0.000    9.704    0.244\n#>    .Verbal_T9         9.217    1.513    6.093    0.000    9.217    0.167\n#>    .Verbal_T11       25.340    4.317    5.870    0.000   25.340    0.237\n#>     i                21.255    2.898    7.335    0.000    1.000    1.000\n#>     s                30.076    6.788    4.430    0.000    1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.681\n#>     Verbal_T7         0.756\n#>     Verbal_T9         0.833\n#>     Verbal_T11        0.763\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Compare model fit\nanova(fit_linear_growth_model, fit_quad_growth_model)\n#> \n#> Chi-Squared Difference Test\n#> \n#>                         Df  AIC  BIC  Chisq Chisq diff RMSEA Df diff\n#> fit_quad_growth_model    1 4992 5035   6.18                         \n#> fit_linear_growth_model  5 5078 5108 100.76       94.6 0.333       4\n#>                         Pr(>Chisq)\n#> fit_quad_growth_model             \n#> fit_linear_growth_model     <2e-16\n```\n:::\n\n\n\n\nIl modello non lineare in lavaan senza alcuna ipotesi sulla forma e il modello quadratico non sono annidati. Pertanto un test del rapporto di verosimiglianza non è possibile. Tuttavia, gli indici di bontà di adattamento del modello senza ipotesi sulla forma sono migliori del modello quadratico, per cui sarà quello il modello prescelto.\n\n## Predizioni\n\nSi potrebbe essere interessati a ciò che predice i punteggi di base e/o il cambiamento. Per valutare questo, si possono aggiungere predittori nel modello di crescita. Un'ipotesi potrebbe essere che il livello di istruzione della madre predica lo sviluppo della comprensione verbale.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Specify model\nbasis_growth_model_cov <- ' \n  i =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n  s =~ 0*Verbal_T6 + Verbal_T7 + Verbal_T9 + 1*Verbal_T11 \n  s~mo_edu\n  i~mo_edu\n  '\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Fit model\nfit_basis_growth_model_cov <- growth(basis_growth_model_cov, data=wisc,missing='fiml')\n# Output results\nsummary(fit_basis_growth_model_cov, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 118 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        13\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 6.498\n#>   Degrees of freedom                                 5\n#>   P-value (Chi-square)                           0.261\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               650.266\n#>   Degrees of freedom                                10\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.998\n#>   Tucker-Lewis Index (TLI)                       0.995\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.998\n#>   Robust Tucker-Lewis Index (TLI)                0.995\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2450.885\n#>   Loglikelihood unrestricted model (H1)      -2447.636\n#>                                                       \n#>   Akaike (AIC)                                4927.770\n#>   Bayesian (BIC)                              4970.906\n#>   Sample-size adjusted Bayesian (SABIC)       4929.718\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.038\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.110\n#>   P-value H_0: RMSEA <= 0.050                    0.520\n#>   P-value H_0: RMSEA >= 0.080                    0.210\n#>                                                       \n#>   Robust RMSEA                                   0.038\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.110\n#>   P-value H_0: Robust RMSEA <= 0.050             0.520\n#>   P-value H_0: Robust RMSEA >= 0.080             0.210\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.038\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i =~                                                                  \n#>     Verbal_T6         1.000                               4.615    0.826\n#>     Verbal_T7         1.000                               4.615    0.732\n#>     Verbal_T9         1.000                               4.615    0.619\n#>     Verbal_T11        1.000                               4.615    0.447\n#>   s =~                                                                  \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         0.237    0.012   20.312    0.000    1.306    0.207\n#>     Verbal_T9         0.535    0.012   43.171    0.000    2.949    0.396\n#>     Verbal_T11        1.000                               5.508    0.534\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   s ~                                                                   \n#>     mo_edu           -1.724    0.414   -4.165    0.000   -0.313   -0.394\n#>   i ~                                                                   \n#>     mo_edu           -1.943    0.259   -7.503    0.000   -0.421   -0.531\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>  .i ~~                                                                  \n#>    .s                 9.676    2.721    3.556    0.000    0.489    0.489\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .i                26.302    0.958   27.446    0.000    5.700    5.700\n#>    .s                30.098    1.527   19.710    0.000    5.464    5.464\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6         9.923    1.622    6.117    0.000    9.923    0.318\n#>    .Verbal_T7         9.607    1.281    7.500    0.000    9.607    0.242\n#>    .Verbal_T9         9.443    1.501    6.291    0.000    9.443    0.170\n#>    .Verbal_T11       24.956    4.288    5.820    0.000   24.956    0.234\n#>    .i                15.298    2.309    6.624    0.000    0.718    0.718\n#>    .s                25.619    6.352    4.033    0.000    0.844    0.844\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.682\n#>     Verbal_T7         0.758\n#>     Verbal_T9         0.830\n#>     Verbal_T11        0.766\n#>     i                 0.282\n#>     s                 0.156\n```\n:::\n\n\n\n\nI risultati indicano come il livello di educazione della madre influenza sia il valore di base delle abilità verbali del bambino, sia il tasso di crescita. \n\nAggiungiamo ora la velocità di elaborazione a 11 anni come esito dei cambiamenti nella comprensione verbale. In altre parole, verifichiamo se le pendenze del cambiamento verbale predicono il livello di velocità di elaborazione a 11.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Specify model\nbasis_growth_model_covO <- ' \n  i =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n  s =~ 0*Verbal_T6 + Verbal_T7 + Verbal_T9 + 1*Verbal_T11 \n  Pspeed_T11~s\n  Pspeed_T11~1\n'\n\n# Fit model\nfit_basis_growth_model_covO <- growth(basis_growth_model_covO, data=wisc,missing='fiml')\n# Output results\nsummary(fit_basis_growth_model_covO, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 142 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        14\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                14.016\n#>   Degrees of freedom                                 6\n#>   P-value (Chi-square)                           0.029\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               685.769\n#>   Degrees of freedom                                10\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.988\n#>   Tucker-Lewis Index (TLI)                       0.980\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.988\n#>   Robust Tucker-Lewis Index (TLI)                0.980\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -3240.780\n#>   Loglikelihood unrestricted model (H1)      -3233.772\n#>                                                       \n#>   Akaike (AIC)                                6509.560\n#>   Bayesian (BIC)                              6556.014\n#>   Sample-size adjusted Bayesian (SABIC)       6511.657\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.081\n#>   90 Percent confidence interval - lower         0.024\n#>   90 Percent confidence interval - upper         0.137\n#>   P-value H_0: RMSEA <= 0.050                    0.151\n#>   P-value H_0: RMSEA >= 0.080                    0.566\n#>                                                       \n#>   Robust RMSEA                                   0.081\n#>   90 Percent confidence interval - lower         0.024\n#>   90 Percent confidence interval - upper         0.137\n#>   P-value H_0: Robust RMSEA <= 0.050             0.151\n#>   P-value H_0: Robust RMSEA >= 0.080             0.566\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.043\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i =~                                                                  \n#>     Verbal_T6         1.000                               4.476    0.804\n#>     Verbal_T7         1.000                               4.476    0.714\n#>     Verbal_T9         1.000                               4.476    0.598\n#>     Verbal_T11        1.000                               4.476    0.434\n#>   s =~                                                                  \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         0.237    0.012   19.886    0.000    1.220    0.195\n#>     Verbal_T9         0.534    0.013   42.125    0.000    2.752    0.367\n#>     Verbal_T11        1.000                               5.157    0.500\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   Pspeed_T11 ~                                                          \n#>     s                 1.683    0.219    7.690    0.000    8.680    0.697\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i ~~                                                                  \n#>     s                17.195    2.513    6.842    0.000    0.745    0.745\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Pspeed_T11       10.214    5.368    1.903    0.057   10.214    0.820\n#>     i                19.648    0.390   50.431    0.000    4.389    4.389\n#>     s                24.194    0.554   43.672    0.000    4.691    4.691\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6        10.997    1.451    7.578    0.000   10.997    0.354\n#>    .Verbal_T7         9.658    1.299    7.436    0.000    9.658    0.246\n#>    .Verbal_T9        10.154    1.529    6.640    0.000   10.154    0.181\n#>    .Verbal_T11       25.254    3.694    6.836    0.000   25.254    0.238\n#>    .Pspeed_T11       79.657   10.996    7.244    0.000   79.657    0.514\n#>     i                20.036    2.643    7.580    0.000    1.000    1.000\n#>     s                26.598    5.701    4.666    0.000    1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.646\n#>     Verbal_T7         0.754\n#>     Verbal_T9         0.819\n#>     Verbal_T11        0.762\n#>     Pspeed_T11        0.486\n```\n:::\n\n\n\n\nI dati mostrano come le pendenze del cambiamento verbale effettivamente predicono il livello di velocità di elaborazione a 11 anni.\n\n\nI predittori tempo-invarianti sono predittori delle differenze individuali nelle intercette e nelle pendenze. Sono spesso misurati al basale (ad esempio, reddito familiare) o sono caratteristiche specifiche della persona il cui valore è costante nel tempo (ad esempio, sesso biologico, paese di origine). Ad esempio, nelle analisi precedenti, il livello di istruzione della madre e la velocità di elaborazione a 6 anni sono predittori tempo-invarianti.\n\nI predittori tempo-varianti sono predittori dell'esito in ogni punto temporale. Nel nostro esempio, ad esempio, avremmo bisogno di misurazioni a T6, T7, T9 e T11.\n\nIn questo ultimo modello useremo la velocità di elaborazione come predittore tempo-variante della misurazione verbale in ogni punto temporale. Ci chiediamo le seguenti domande. Come sono l'intercetta e la pendenza delle misure verbali? La velocità di elaborazione predice le misure verbali allo stesso modo in tutti i punti temporali?\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Specify model\nbasis_growth_model_tvp <- ' \n  i =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n  s =~ 0*Verbal_T6 + Verbal_T7 + Verbal_T9 + 1*Verbal_T11 \n  Verbal_T6~Pspeed_T6\n  Verbal_T7~Pspeed_T7\n  Verbal_T9~Pspeed_T9\n  Verbal_T11~Pspeed_T11\n  '\n# Fit LGM\nfit_basis_growth_model_tvp <- growth(basis_growth_model_tvp, data=wisc,missing='fiml')\n# Output results\nsummary(fit_basis_growth_model_tvp, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 96 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        15\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                90.277\n#>   Degrees of freedom                                15\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               754.793\n#>   Degrees of freedom                                22\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.897\n#>   Tucker-Lewis Index (TLI)                       0.849\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.897\n#>   Robust Tucker-Lewis Index (TLI)                0.849\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2440.511\n#>   Loglikelihood unrestricted model (H1)      -2395.373\n#>                                                       \n#>   Akaike (AIC)                                4911.022\n#>   Bayesian (BIC)                              4960.794\n#>   Sample-size adjusted Bayesian (SABIC)       4913.269\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.157\n#>   90 Percent confidence interval - lower         0.127\n#>   90 Percent confidence interval - upper         0.189\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    1.000\n#>                                                       \n#>   Robust RMSEA                                   0.157\n#>   90 Percent confidence interval - lower         0.127\n#>   90 Percent confidence interval - upper         0.189\n#>   P-value H_0: Robust RMSEA <= 0.050             0.000\n#>   P-value H_0: Robust RMSEA >= 0.080             1.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.194\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i =~                                                                  \n#>     Verbal_T6         1.000                               3.628    0.710\n#>     Verbal_T7         1.000                               3.628    0.627\n#>     Verbal_T9         1.000                               3.628    0.535\n#>     Verbal_T11        1.000                               3.628    0.386\n#>   s =~                                                                  \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         0.297    0.071    4.209    0.000    1.337    0.231\n#>     Verbal_T9         0.703    0.108    6.531    0.000    3.161    0.466\n#>     Verbal_T11        1.000                               4.498    0.479\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   Verbal_T6 ~                                                           \n#>     Pspeed_T6         0.243    0.038    6.467    0.000    0.243    0.397\n#>   Verbal_T7 ~                                                           \n#>     Pspeed_T7         0.230    0.034    6.853    0.000    0.230    0.397\n#>   Verbal_T9 ~                                                           \n#>     Pspeed_T9         0.220    0.036    6.130    0.000    0.220    0.332\n#>   Verbal_T11 ~                                                          \n#>     Pspeed_T11        0.319    0.039    8.233    0.000    0.319    0.423\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i ~~                                                                  \n#>     s                 5.873    2.723    2.157    0.031    0.360    0.360\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     i                15.271    0.754   20.245    0.000    4.209    4.209\n#>     s                12.341    1.994    6.190    0.000    2.744    2.744\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6         8.814    1.705    5.170    0.000    8.814    0.338\n#>    .Verbal_T7         9.806    1.311    7.478    0.000    9.806    0.292\n#>    .Verbal_T9         9.583    1.978    4.846    0.000    9.583    0.208\n#>    .Verbal_T11       27.351    4.282    6.387    0.000   27.351    0.310\n#>     i                13.165    2.347    5.609    0.000    1.000    1.000\n#>     s                20.235    6.197    3.265    0.001    1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.662\n#>     Verbal_T7         0.708\n#>     Verbal_T9         0.792\n#>     Verbal_T11        0.690\n```\n:::\n\n\n\n\n## Interazione tra pendenza e intercetta\n\nOra che sappiamo come stimare la traiettoria di una variabile, siamo in grado di stimare la traiettoria di due variabili e vedere come interagiscono.\n\nNell'analisi successiva, creiamo due modelli di crescita non lineari, uno per la comprensione verbale e uno per la velocità di elaborazione. Correliamo i cambiamenti delle due metriche e ci chiediamo se loro pendenze sono correlate.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Specify model\nbasis_growth_model_cor_ver_pro <- ' \n  i_verbal =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n  s_verbal =~ 0*Verbal_T6 + Verbal_T7 + Verbal_T9 + 1*Verbal_T11 \n  i_processpeed =~ 1*Pspeed_T6 + 1*Pspeed_T7 + 1*Pspeed_T9 + 1*Pspeed_T11\n  s_processpeed =~ 0*Pspeed_T6 + Pspeed_T7 + Pspeed_T9 + 1*Pspeed_T11 \n  s_verbal ~~ s_processpeed\n'\n\n# Fit LGM\nfit_basis_growth_model_cor_ver_pro <- growth(basis_growth_model_cor_ver_pro, data=wisc,missing='fiml')\n# Output results\nsummary(fit_basis_growth_model_cor_ver_pro, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 211 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        26\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                29.305\n#>   Degrees of freedom                                18\n#>   P-value (Chi-square)                           0.045\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              1423.083\n#>   Degrees of freedom                                28\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.992\n#>   Tucker-Lewis Index (TLI)                       0.987\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.992\n#>   Robust Tucker-Lewis Index (TLI)                0.987\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -5124.285\n#>   Loglikelihood unrestricted model (H1)      -5109.632\n#>                                                       \n#>   Akaike (AIC)                               10300.570\n#>   Bayesian (BIC)                             10386.841\n#>   Sample-size adjusted Bayesian (SABIC)      10304.465\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.055\n#>   90 Percent confidence interval - lower         0.009\n#>   90 Percent confidence interval - upper         0.091\n#>   P-value H_0: RMSEA <= 0.050                    0.367\n#>   P-value H_0: RMSEA >= 0.080                    0.137\n#>                                                       \n#>   Robust RMSEA                                   0.055\n#>   90 Percent confidence interval - lower         0.009\n#>   90 Percent confidence interval - upper         0.091\n#>   P-value H_0: Robust RMSEA <= 0.050             0.367\n#>   P-value H_0: Robust RMSEA >= 0.080             0.137\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.048\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i_verbal =~                                                           \n#>     Verbal_T6         1.000                               4.637    0.832\n#>     Verbal_T7         1.000                               4.637    0.734\n#>     Verbal_T9         1.000                               4.637    0.617\n#>     Verbal_T11        1.000                               4.637    0.451\n#>   s_verbal =~                                                           \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         0.237    0.012   20.495    0.000    1.349    0.213\n#>     Verbal_T9         0.533    0.012   43.283    0.000    3.037    0.404\n#>     Verbal_T11        1.000                               5.694    0.554\n#>   i_processpeed =~                                                      \n#>     Pspeed_T6         1.000                               7.604    0.902\n#>     Pspeed_T7         1.000                               7.604    0.799\n#>     Pspeed_T9         1.000                               7.604    0.713\n#>     Pspeed_T11        1.000                               7.604    0.617\n#>   s_processpeed =~                                                      \n#>     Pspeed_T6         0.000                               0.000    0.000\n#>     Pspeed_T7         0.298    0.011   26.220    0.000    1.841    0.194\n#>     Pspeed_T9         0.648    0.012   53.375    0.000    4.005    0.376\n#>     Pspeed_T11        1.000                               6.183    0.502\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   s_verbal ~~                                                           \n#>     s_processpeed    16.813    4.806    3.499    0.000    0.478    0.478\n#>   i_verbal ~~                                                           \n#>     s_verbal         14.606    3.112    4.694    0.000    0.553    0.553\n#>     i_processpeed    26.537    3.572    7.430    0.000    0.753    0.753\n#>     s_processpeed     2.520    3.154    0.799    0.424    0.088    0.088\n#>   s_verbal ~~                                                           \n#>     i_processpeed    25.796    4.875    5.291    0.000    0.596    0.596\n#>   i_processpeed ~~                                                      \n#>     s_processpeed    14.974    5.451    2.747    0.006    0.319    0.319\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     i_verbal         19.642    0.390   50.360    0.000    4.236    4.236\n#>     s_verbal         24.200    0.561   43.138    0.000    4.250    4.250\n#>     i_processpeed    17.949    0.590   30.419    0.000    2.360    2.360\n#>     s_processpeed    32.986    0.615   53.609    0.000    5.335    5.335\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6         9.574    1.581    6.055    0.000    9.574    0.308\n#>    .Verbal_T7         9.698    1.269    7.643    0.000    9.698    0.243\n#>    .Verbal_T9        10.149    1.491    6.806    0.000   10.149    0.180\n#>    .Verbal_T11       22.419    4.039    5.551    0.000   22.419    0.212\n#>    .Pspeed_T6        13.286    2.911    4.565    0.000   13.286    0.187\n#>    .Pspeed_T7        20.338    2.534    8.026    0.000   20.338    0.225\n#>    .Pspeed_T9        20.430    2.945    6.937    0.000   20.430    0.180\n#>    .Pspeed_T11       25.840    5.200    4.969    0.000   25.840    0.170\n#>     i_verbal         21.502    2.893    7.432    0.000    1.000    1.000\n#>     s_verbal         32.425    6.990    4.639    0.000    1.000    1.000\n#>     i_processpeed    57.821    6.889    8.393    0.000    1.000    1.000\n#>     s_processpeed    38.226    8.968    4.263    0.000    1.000    1.000\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.692\n#>     Verbal_T7         0.757\n#>     Verbal_T9         0.820\n#>     Verbal_T11        0.788\n#>     Pspeed_T6         0.813\n#>     Pspeed_T7         0.775\n#>     Pspeed_T9         0.820\n#>     Pspeed_T11        0.830\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-show .cell-code}\n# Specify model\nbasis_growth_model_pred_ver_pro <- ' \n  i_verbal =~ 1*Verbal_T6 + 1*Verbal_T7 + 1*Verbal_T9 + 1*Verbal_T11\n  s_verbal =~ 0*Verbal_T6 + Verbal_T7 + Verbal_T9 + 1*Verbal_T11 \n  i_processpeed =~ 1*Pspeed_T6 + 1*Pspeed_T7 + 1*Pspeed_T9 + 1*Pspeed_T11\n  s_processpeed =~ 0*Pspeed_T6 + Pspeed_T7 + Pspeed_T9 + 1*Pspeed_T11 \n  s_verbal ~ i_processpeed\n  s_processpeed ~ i_verbal'\n\n# Fit LGM\nfit_basis_growth_model_pred_ver_pro <- growth(basis_growth_model_pred_ver_pro, data=wisc,missing='fiml')\n# Output results\nsummary(fit_basis_growth_model_pred_ver_pro, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 175 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        24\n#> \n#>   Number of observations                           204\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                38.158\n#>   Degrees of freedom                                20\n#>   P-value (Chi-square)                           0.008\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              1423.083\n#>   Degrees of freedom                                28\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.987\n#>   Tucker-Lewis Index (TLI)                       0.982\n#>                                                       \n#>   Robust Comparative Fit Index (CFI)             0.987\n#>   Robust Tucker-Lewis Index (TLI)                0.982\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -5128.711\n#>   Loglikelihood unrestricted model (H1)      -5109.632\n#>                                                       \n#>   Akaike (AIC)                               10305.422\n#>   Bayesian (BIC)                             10385.057\n#>   Sample-size adjusted Bayesian (SABIC)      10309.018\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.067\n#>   90 Percent confidence interval - lower         0.033\n#>   90 Percent confidence interval - upper         0.099\n#>   P-value H_0: RMSEA <= 0.050                    0.181\n#>   P-value H_0: RMSEA >= 0.080                    0.268\n#>                                                       \n#>   Robust RMSEA                                   0.067\n#>   90 Percent confidence interval - lower         0.033\n#>   90 Percent confidence interval - upper         0.099\n#>   P-value H_0: Robust RMSEA <= 0.050             0.181\n#>   P-value H_0: Robust RMSEA >= 0.080             0.268\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.055\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i_verbal =~                                                           \n#>     Verbal_T6         1.000                               4.809    0.856\n#>     Verbal_T7         1.000                               4.809    0.760\n#>     Verbal_T9         1.000                               4.809    0.647\n#>     Verbal_T11        1.000                               4.809    0.477\n#>   s_verbal =~                                                           \n#>     Verbal_T6         0.000                               0.000    0.000\n#>     Verbal_T7         0.238    0.011   21.065    0.000    1.421    0.225\n#>     Verbal_T9         0.534    0.012   43.708    0.000    3.189    0.429\n#>     Verbal_T11        1.000                               5.977    0.593\n#>   i_processpeed =~                                                      \n#>     Pspeed_T6         1.000                               7.861    0.929\n#>     Pspeed_T7         1.000                               7.861    0.831\n#>     Pspeed_T9         1.000                               7.861    0.756\n#>     Pspeed_T11        1.000                               7.861    0.662\n#>   s_processpeed =~                                                      \n#>     Pspeed_T6         0.000                               0.000    0.000\n#>     Pspeed_T7         0.299    0.011   26.953    0.000    2.078    0.220\n#>     Pspeed_T9         0.648    0.012   53.898    0.000    4.495    0.432\n#>     Pspeed_T11        1.000                               6.940    0.585\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   s_verbal ~                                                            \n#>     i_processpeed     0.408    0.071    5.782    0.000    0.537    0.537\n#>   s_processpeed ~                                                       \n#>     i_verbal          0.143    0.142    1.013    0.311    0.099    0.099\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   i_verbal ~~                                                           \n#>     i_processpeed    26.674    3.649    7.310    0.000    0.706    0.706\n#>  .s_verbal ~~                                                           \n#>    .s_processpeed    10.954    5.052    2.168    0.030    0.315    0.315\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     i_verbal         19.630    0.393   49.926    0.000    4.082    4.082\n#>    .s_verbal         16.877    1.368   12.333    0.000    2.823    2.823\n#>     i_processpeed    17.944    0.592   30.305    0.000    2.283    2.283\n#>    .s_processpeed    30.167    2.843   10.612    0.000    4.347    4.347\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Verbal_T6         8.445    1.407    6.000    0.000    8.445    0.267\n#>    .Verbal_T7         9.715    1.287    7.547    0.000    9.715    0.243\n#>    .Verbal_T9        10.375    1.493    6.951    0.000   10.375    0.188\n#>    .Verbal_T11       21.001    3.922    5.355    0.000   21.001    0.207\n#>    .Pspeed_T6         9.777    2.479    3.943    0.000    9.777    0.137\n#>    .Pspeed_T7        21.117    2.640    8.000    0.000   21.117    0.236\n#>    .Pspeed_T9        21.159    3.017    7.014    0.000   21.159    0.196\n#>    .Pspeed_T11       23.241    5.106    4.552    0.000   23.241    0.165\n#>     i_verbal         23.129    2.847    8.125    0.000    1.000    1.000\n#>    .s_verbal         25.426    5.629    4.517    0.000    0.712    0.712\n#>     i_processpeed    61.801    6.889    8.971    0.000    1.000    1.000\n#>    .s_processpeed    47.685    8.194    5.820    0.000    0.990    0.990\n#> \n#> R-Square:\n#>                    Estimate\n#>     Verbal_T6         0.733\n#>     Verbal_T7         0.757\n#>     Verbal_T9         0.812\n#>     Verbal_T11        0.793\n#>     Pspeed_T6         0.863\n#>     Pspeed_T7         0.764\n#>     Pspeed_T9         0.804\n#>     Pspeed_T11        0.835\n#>     s_verbal          0.288\n#>     s_processpeed     0.010\n```\n:::\n",
    "supporting": [
      "11_lgm_wais_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
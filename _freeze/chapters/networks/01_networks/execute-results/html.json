{
  "hash": "3d0d04972726fed27ebc4ecb6c52782e",
  "result": {
    "engine": "knitr",
    "markdown": "# Network psicologici {#sec-networks-intro}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- Definire e utilizzare le reti per modellare le interazioni tra variabili psicologiche.\n- Stimare reti utilizzando metodi come le correlazioni parziali regolarizzate.\n- Rappresentare graficamente le connessioni tra i nodi e interpretare i pesi degli archi.\n- Confrontare strutture di rete (ad esempio tra gruppi o contesti) mediante metodi statistici come il Network Comparison Test (NCT).\n- Valutare la stabilità dei pesi degli archi attraverso il bootstrapping.\n- Verificare l'accuratezza delle misure di centralità utilizzando il case dropping test.\n- Interpretare la stabilità delle misure di centralità in base alla correlazione residua con campioni ridotti.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Psychological Networks: A Modern Approach to Analysis of Learning and Complex Learning Processes* del testo di @saqr2024learning.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  rio, bootnet, networktools, NetworkToolbox, NetworkComparisonTest, qgraph, \n  mgm, matrixcalc\n)\n```\n:::\n\n\n\n:::\n\n## Introduzione\n\nQuesto capitolo costituisce un riassunto semplificato del capitolo *Psychological Networks: A Modern Approach to Analysis of Learning and Complex Learning Processes* del testo di @saqr2024learning.\n\n## La Network Analysis\n\nL'analisi delle reti è un potente strumento per i ricercatori, utile per mappare relazioni, individuare connessioni e identificare cluster o comunità tra elementi interagenti. Questa metodologia si è affermata come una delle più importanti per comprendere sistemi complessi. In psicologia, l’analisi delle reti non è più limitata allo studio delle interazioni sociali, ma viene sempre più utilizzata per esplorare processi astratti come quelli cognitivi, emotivi e comportamentali. In questo ambito, le **reti probabilistiche** svolgono un ruolo centrale, rappresentando i nodi come variabili psicologiche (ad esempio, punteggi di scale o indicatori di costrutti) e gli archi come associazioni probabilistiche tra di esse.\n\nUn esempio di spicco è il **Gaussian Graphical Model (GGM)**, in cui i nodi rappresentano costrutti psicologici come emozioni, comportamenti o tratti, mentre gli archi riflettono correlazioni parziali. La correlazione parziale rappresenta la relazione tra due variabili controllando l’effetto di tutte le altre variabili nella rete, secondo il principio del *ceteris paribus*. \n\nAd esempio, in una rete in cui i nodi rappresentano motivazione, successo accademico, coinvolgimento, autoregolazione e benessere, un arco tra benessere e successo accademico indica che il benessere è associato al successo accademico, indipendentemente dagli effetti delle altre variabili. L’assenza di un arco, invece, suggerisce che due nodi sono condizionalmente indipendenti, una volta considerati gli effetti delle altre variabili.\n\n### Vantaggi delle Reti Psicologiche\n\nL’analisi delle reti offre diversi strumenti per valutare la robustezza e la precisione delle stime:\n\n- **Accuratezza delle stime**: Tecniche come il *bootstrapping* permettono di valutare la stabilità dei pesi degli archi.\n- **Centralità**: Misure come la forza, vicinanza e intermediazione dei nodi permettono di identificare elementi centrali o influenti nella rete.\n- **Simulazioni**: Analisi basate su campioni simulati consentono di stimare la replicabilità dei risultati.\n\nConsideriamo, ad esempio, una rete che rappresenta le relazioni tra emozioni negative (ansia, tristezza, rabbia), pensieri disfunzionali e strategie di coping. Un arco tra ansia e pensieri disfunzionali potrebbe indicare che l’ansia è strettamente associata ai pensieri disfunzionali, controllando per l’effetto di tristezza, rabbia e coping. Questo tipo di analisi non solo chiarisce le interazioni tra variabili, ma suggerisce interventi mirati: ad esempio, rafforzare le strategie di coping per ridurre l’impatto delle emozioni negative sui pensieri disfunzionali.\n\nIn sintesi, la **Network Analysis** rappresenta un approccio innovativo e rigoroso per indagare i sistemi psicologici complessi, offrendo una visione dettagliata delle interazioni tra variabili e potenziali punti di intervento.\n\n## Tutorial con R\n\nQuesto capitolo presenta un tutorial passo-passo su come utilizzare le reti psicologiche applicandole a dati raccolti in indagini trasversali, così come discusso da @saqr2024learning. Il dataset utilizzato contiene le risposte di 6071 studenti a un questionario che indaga le caratteristiche psicologiche legate al loro benessere durante la pandemia di COVID-19, condotto in Finlandia e Austria. \n\nLe domande del questionario riguardano i bisogni psicologici fondamentali degli studenti (relazionalità, autonomia e competenza percepita), l’apprendimento autoregolato, le emozioni positive e la motivazione intrinseca verso l’apprendimento. Inoltre, il dataset include variabili demografiche come paese di residenza, genere ed età.\n\nNel tutorial, mostreremo come costruire e visualizzare una rete che rappresenti le relazioni tra le diverse caratteristiche psicologiche. Successivamente, interpreteremo e valuteremo queste relazioni e confronteremo le differenze nelle reti tra gruppi demografici. Questo approccio consente di esplorare in modo visivo e quantitativo i collegamenti tra i costrutti psicologici, identificando eventuali differenze tra le categorie demografiche.\n\n## Importazione e Preparazione dei Dati\n\nLa prima fase prevede l'importazione dei dati e la loro preparazione, eliminando risposte mancanti o incomplete per garantire un dataset coerente e utilizzabile nelle analisi successive.\n\nI dati vengono importati direttamente da una fonte online. Utilizziamo la funzione `import()` per caricare il file e `drop_na()` per rimuovere eventuali righe contenenti valori mancanti.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nURL <- (\"https://raw.githubusercontent.com/lamethods/data/main/11_universityCovid/data.sav\") \ndf <- import(URL) |>\n    drop_na()\n```\n:::\n\n\n\n\nPer rappresentare ciascun costrutto misurato dal questionario, combiniamo le colonne relative agli item dello stesso costrutto calcolando la media delle risposte. Questo approccio permette di ottenere una sintesi per ogni costrutto psicologico (ad esempio Competence, Autonomy, ecc.).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naggregated <- df |> rowwise() |> mutate(\n    Competence = rowMeans(cbind\n    (comp1.rec , comp2.rec, comp3.rec),\n    na.rm = T),\n    Autonomy = rowMeans(cbind\n    (auto1.rec , auto2.rec, auto3.rec),\n    na.rm = T),\n    Motivation = rowMeans(cbind\n    (lm1.rec , lm2.rec, lm3.rec),\n    na.rm = T),\n    Emotion = rowMeans(cbind\n    (pa1.rec , pa2.rec, pa3.rec),\n    na.rm = T),\n    Relatedness = rowMeans(cbind\n    (sr1.rec , sr2.rec, sr3.rec),\n    na.rm = T),\n    SRL = rowMeans(cbind\n    (gp1.rec , gp2.rec, gp3.rec),\n    na.rm = T)\n)\n```\n:::\n\n\n\n\nDopo aver calcolato i valori medi per ciascun costrutto, manteniamo solo le colonne appena generate. Questo rende il dataset più pulito e specifico per l'analisi.\n\nInoltre, creiamo dei sottoinsiemi di dati in base al genere (un dataset per i maschi e uno per le femmine) e al paese (un dataset per l'Austria e un altro per la Finlandia). Utilizzeremo questi dataset successivamente per confronti tra generi e paesi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncols <- c(\n    \"Relatedness\", \"Competence\", \"Autonomy\",\n    \"Emotion\", \"Motivation\", \"SRL\"\n)\ndplyr::filter(aggregated, country == 1) |>\n    dplyr::select(all_of(cols)) -> finlandData\ndplyr::filter(aggregated, country == 0) |>\n    dplyr::select(all_of(cols)) -> austriaData\ndplyr::filter(aggregated, gender == 1) |>\n    dplyr::select(all_of(cols)) -> femaleData\ndplyr::filter(aggregated, gender == 2) |>\n    dplyr::select(all_of(cols)) -> maleData\ndplyr::select(aggregated, all_of(cols)) -> allData\n```\n:::\n\n\n\n\nInfine, utilizziamo glimpse() per visualizzare una panoramica del dataset finale, verificando che i dati siano stati preparati correttamente.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallData |> glimpse()\n#> Rows: 7,160\n#> Columns: 6\n#> Rowwise: \n#> $ Relatedness <dbl> 3.00, 5.00, 4.67, 4.33, 5.00, 4.00, 4.67, 2.33, 3.00, …\n#> $ Competence  <dbl> 2.33, 3.00, 4.00, 3.33, 4.00, 2.67, 4.33, 3.67, 3.33, …\n#> $ Autonomy    <dbl> 2.33, 1.67, 2.67, 3.00, 3.00, 2.67, 3.33, 2.67, 3.00, …\n#> $ Emotion     <dbl> 2.00, 2.33, 4.00, 3.33, 4.00, 3.33, 4.67, 5.00, 3.67, …\n#> $ Motivation  <dbl> 1.33, 2.00, 3.00, 2.67, 3.00, 2.67, 4.33, 1.33, 2.00, …\n#> $ SRL         <dbl> 2.67, 4.33, 4.33, 2.67, 4.33, 5.00, 4.67, 2.67, 4.00, …\n```\n:::\n\n\n\n\n## Controllo delle Assunzioni\n\nPrima di procedere con l'analisi, è essenziale verificare alcune assunzioni per assicurarsi che il dataset e la rete stimata siano appropriati e robusti.\n\n### Matrice di Correlazione Definita Positiva\n\nLa matrice di correlazione deve essere definita positiva, il che implica che le variabili incluse non devono essere combinazioni lineari tra loro. In termini pratici, ogni variabile deve aggiungere informazioni uniche al modello. Per controllare questa proprietà, utilizziamo la funzione `is.positive.definite()` del pacchetto `matrixcalc`.\n\nSe la matrice di correlazione non fosse definita positiva, è possibile utilizzare metodi alternativi, come l'opzione cor_auto, per ottenere una matrice che soddisfi questa condizione. Nel nostro caso, la matrice risulta già definita positiva. Inoltre, specifichiamo l’argomento `use = \"pairwise.complete.obs\"` per includere tutte le osservazioni disponibili per ogni coppia di variabili.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorrelationMatrix <- cor(\n  x = allData, use = c(\"pairwise.complete.obs\")\n)\nis.positive.definite(correlationMatrix)\n#> [1] TRUE\n```\n:::\n\n\n\n\nSe la funzione restituisce TRUE, possiamo procedere con l'analisi; in caso contrario, sarà necessario intervenire per correggere il problema.\n\n### Assenza di ridondanza tra le variabili\n\nLa seconda verifica consiste nell’assicurarci che non ci siano variabili altamente correlate al punto da risultare ridondanti. Questo è fondamentale per garantire che ogni variabile rappresenti un costrutto unico e non una semplice sovrapposizione di altri costrutti già inclusi.\n\nUtilizziamo l'algoritmo **goldbricker**, che identifica pattern di correlazione fortemente simili tra coppie di variabili. I criteri utilizzati per individuare la ridondanza sono:\n\n- Correlazione alta: $r > 0.50$\n- Frazione significativa: almeno il 25% delle variabili altamente correlate.\n- p-value: 0.05 (significatività statistica).\n\nEseguiamo il controllo con il codice seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoldbricker(allData,\n    p = 0.05, method = \"hittner2003\",\n    threshold = 0.25, corMin = 0.5, \n    progressbar = FALSE\n)\n#> Suggested reductions: Less than 25 % of correlations are significantly different for the following pairs: \n#> [1] \"No suggested reductions\"\n```\n:::\n\n\n\n\nSe vengono identificate variabili ridondanti, sarà necessario rivedere il dataset, eliminando o modificando alcune variabili per ridurre la sovrapposizione.\n\n\n## Stima della Rete\n\nUna volta verificato che i dati soddisfano le assunzioni necessarie, possiamo procedere alla stima della rete. Questo processo consiste nel quantificare le associazioni tra le variabili per analizzare come i loro valori si influenzano reciprocamente. Nelle reti psicologiche, le associazioni più comuni sono le correlazioni, che permettono di individuare relazioni dirette o condizionate tra le variabili (ad esempio, se alti livelli di motivazione sono associati ad alti livelli di coinvolgimento). \n\nLe associazioni possono essere stimate attraverso diverse misure, tra cui covarianze, correlazioni semplici, correlazioni parziali e modelli basati su regressioni. In questo contesto, ci concentriamo sulla **stima delle correlazioni parziali regolarizzate**, una tecnica molto utilizzata nelle analisi di rete psicologica.\n\n### Correlazioni Parziali Regolarizzate\n\nLe correlazioni parziali regolarizzate offrono numerosi vantaggi e rappresentano uno standard nell’analisi delle reti psicologiche. Queste consentono di ottenere una struttura della rete interpretabile, evidenziando associazioni condizionate tra le variabili.\n\nVantaggi Principali:\n\n1. **Recupero della struttura reale**: Le correlazioni parziali regolarizzate aiutano a identificare le relazioni condizionate effettive, eliminando interferenze di altre variabili.\n2. **Sparsità**: Forniscono una rete più chiara e leggibile, mantenendo solo gli archi più rilevanti.\n\nLa **correlazione parziale** misura l’associazione tra due variabili controllando l’effetto di tutte le altre variabili nella rete (*ceteris paribus*). Ad esempio, possiamo stimare l’associazione tra motivazione e coinvolgimento, escludendo l’influenza di variabili come successo accademico, ansia o benessere. Questo approccio permette di concentrarsi su relazioni specifiche e significative.\n\n### Regolarizzazione\n\nLa regolarizzazione introduce una penalità per semplificare la complessità del modello di rete, contribuendo a eliminare associazioni spurie e a migliorare l’interpretabilità del risultato.\n\nVantaggi della Regolarizzazione:\n\n- **Riduzione degli archi spuri**: Elimina associazioni false o deboli causate da rumore statistico o sovrapposizione.\n- **Chiarezza**: Imposta a zero i pesi degli archi trascurabili, producendo una rete meno densa e più interpretabile.\n- **Affidabilità**: Riduce il rischio di errori di Tipo 1 (falsi positivi), mantenendo solo le associazioni più forti e significative.\n\nLa tecnica più comune per applicare la regolarizzazione è il **LASSO** (*Least Absolute Shrinkage and Selection Operator*), che penalizza la complessità della rete eliminando gli archi di importanza marginale. Questo approccio garantisce che la rete rappresenti fedelmente le relazioni chiave tra le variabili, riducendo il rumore e semplificando l’interpretazione.\n\nIn sintesi, la stima delle correlazioni parziali regolarizzate consente di costruire una rete psicologica robusta, chiara e focalizzata sulle relazioni essenziali tra variabili. Questo metodo combina l’efficacia delle correlazioni parziali con l’efficienza della regolarizzazione, fornendo una rappresentazione affidabile e interpretabile delle interazioni tra costrutti psicologici.\n\n## Procedura di Stima della Rete\n\nIl processo di stima utilizza la funzione `estimateNetwork()` del pacchetto **bootnet**, che richiede tre elementi fondamentali:\n\n1. Il dataset di input contenente le variabili da analizzare.\n2. Il metodo \"EBICglasso\" per la regolarizzazione della rete.\n3. Il calcolo automatico delle correlazioni tra variabili.\n\nLa funzione opera attraverso questi passaggi:\n\n1. Genera 100 modelli di rete differenti.\n2. Valuta ogni modello utilizzando l'Extended Bayesian Information Criterion (EBIC).\n3. Seleziona il modello ottimale che bilancia precisione e parsimonia.\n\nIl parametro gamma (γ) controlla il livello di parsimonia della rete:\n\n- γ = 0: produce una rete più densa con molte connessioni.\n- γ = 0.5 (valore consigliato): mantiene solo le connessioni più rilevanti.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallNetwork <- estimateNetwork(\n    allData,\n    default = \"EBICglasso\",\n    corMethod = \"cor_auto\",\n    tuning = 0.5\n)\n```\n:::\n\n\n\n\nQuesto codice produrrà una rete statistica ottimizzata che evidenzia le relazioni più importanti tra le variabili, eliminando le connessioni spurie o meno rilevanti.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione del risultato\nsummary(allNetwork)\n#> \n#> === Estimated network ===\n#> Number of nodes: 6 \n#> Number of non-zero edges: 15 / 15 \n#> Mean weight: 0.14 \n#> Network stored in object$graph \n#>  \n#> Default set used: EBICglasso \n#>  \n#> Use plot(object) to plot estimated network \n#> Use bootnet(object) to bootstrap edge weights and centrality indices \n#> \n#> Relevant references:\n#> \n#>  \tFriedman, J. H., Hastie, T., & Tibshirani, R. (2008). Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9 (3), 432-441.\n#> \tFoygel, R., & Drton, M. (2010). Extended Bayesian information criteria for Gaussian graphical models. \n#> \tFriedman, J. H., Hastie, T., & Tibshirani, R. (2014). glasso: Graphical lasso estimation of gaussian graphical models. Retrieved from https://CRAN.R-project.org/package=glasso\n#> \tEpskamp, S., Cramer, A., Waldorp, L., Schmittmann, V. D., & Borsboom, D. (2012). qgraph: Network visualizations of relationships in psychometric data. Journal of Statistical Software, 48 (1), 1-18.\n#> \tEpskamp, S., Borsboom, D., & Fried, E. I. (2016). Estimating psychological networks and their accuracy: a tutorial paper. arXiv preprint, arXiv:1604.08462.\n```\n:::\n\n\n\n\nIn sintesi, la funzione `estimateNetwork()` consente di costruire una rete psicologica affidabile e parsimoniosa, sfruttando il metodo delle correlazioni parziali regolarizzate con penalizzazione LASSO. Questo approccio garantisce un equilibrio ottimale tra complessità e accuratezza, rendendo la rete uno strumento efficace per analizzare le relazioni tra variabili.\n\n## Creazione del Grafico della Rete\n\nLa visualizzazione della rete è un passaggio fondamentale per interpretare le relazioni tra variabili. Con la funzione `plot()`, possiamo creare un grafico chiaro e informativo. Per impostazione predefinita, il grafico utilizza un tema inclusivo per daltonici e rappresenta le associazioni condizionate tra i nodi con le seguenti caratteristiche:\n\n- **Archi blu**: rappresentano correlazioni positive.  \n- **Archi rossi**: rappresentano correlazioni negative.  \n- **Spessore degli archi**: proporzionale alla magnitudine delle correlazioni parziali regolarizzate.\n\nAd esempio, il grafico può mostrare una forte associazione tra motivazione, autonomia e competenza, mentre le emozioni risultano strettamente legate alla competenza. Tutte le relazioni visualizzate nel grafico sono condizionate, ovvero tengono conto degli effetti di tutte le altre variabili nella rete, analogamente a quanto avviene in un'analisi di regressione.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallDataPlot <- plot(allNetwork)\nLX <- allDataPlot$layout\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nÈ possibile salvare il grafico in un oggetto R, come `allDataPlot`. Questo oggetto non solo memorizza il grafico, ma contiene anche informazioni utili, tra cui:\n\n- La **matrice di correlazione**.\n- I **parametri di configurazione del grafico**.\n- Il **layout della rete** (disposizione dei nodi), salvato in `allDataPlot$layout`. Questo layout può essere riutilizzato per mantenere una disposizione visiva coerente tra grafici di reti diverse, agevolando i confronti.\n\nPer migliorare la leggibilità e l’interpretazione, è utile personalizzare il grafico. Ecco alcuni esempi di opzioni disponibili:\n\n1. **Titolo**: Utilizzare l’argomento `title` per aggiungere un titolo descrittivo.\n2. **Dimensione dei nodi**: Regolare con l’opzione `vsize` per migliorare la visibilità.  \n3. **Pesi degli archi**: Impostare `edge.labels = TRUE` per visualizzare i valori numerici delle correlazioni sul grafico.  \n4. **Soglia di visibilità degli archi**:  \n   - `cut = 0.10`: evidenzia gli archi con correlazioni superiori a 0.10, mentre gli altri saranno rappresentati con colori più tenui.  \n   - `minimum = 0.05`: nasconde archi con valori inferiori a 0.05, riducendo il rumore visivo senza eliminarli dalla rete.  \n5. **Layout**: Specificare un layout, ad esempio `\"spring\"`, per posizionare automaticamente i nodi in modo intuitivo.\n\nEsempio di grafico personalizzato:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallDataPlot <- plot(\n    allNetwork,\n    title = \"Both countries combined\",\n    vsize = 9,\n    edge.labels = TRUE,\n    cut = 0.10,\n    minimum = 0.05,\n    layout = \"spring\"\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nPersonalizzare il grafico permette di:\n\n- Migliorare la leggibilità, evidenziando le connessioni più rilevanti.  \n- Ridurre il rumore visivo, concentrandosi su associazioni più robuste.  \n- Garantire coerenza visiva tra grafici di reti diverse, facilitando analisi comparative.  \n\nLa possibilità di salvare e riutilizzare il layout o altre configurazioni consente di ottimizzare la comunicazione visiva, rendendo i risultati più chiari e facilmente interpretabili.\n\n## Predicibilità dei Nodi\n\nLa **predicibilità** di un nodo rappresenta la proporzione di varianza che può essere spiegata dalle connessioni di quel nodo con gli altri nodi della rete. È una misura chiave per comprendere l’influenza reciproca delle variabili all’interno della rete e per identificare nodi centrali o meno integrati.\n\nLa predicibilità si basa su una regressione lineare in cui:\n\n1. Ogni nodo viene considerato come variabile dipendente.\n2. Gli altri nodi della rete agiscono come predittori.\n3. Si calcola il coefficiente di determinazione ($R^2$), che indica la percentuale di varianza spiegata.\n\nLa predicibilità viene calcolata per ciascun nodo. Valori di $R^2$ vicini a 0 indicano che il nodo è poco influenzato dalle sue connessioni, mentre valori vicini a 1 suggeriscono che il nodo è fortemente spiegato dalle sue relazioni.\n\n#### Interpretazione di $R^2$\n\n- $R^2 = 0$: Il nodo non è spiegato dalle sue connessioni. Questo potrebbe indicare che la variabile è marginale nella rete o mal misurata.\n- $R^2 > 0$: Indica una connessione significativa con altri nodi, proporzionata al valore di $R^2$.\n- $R^2$ molto alto (vicino a 1): Potrebbe suggerire una ridondanza del nodo rispetto ad altri oppure un modello sovrastimato.\n\n### Predicibilità e Controllabilità\n\nLa predicibilità è strettamente collegata al concetto di **controllabilità**, cioè la capacità di influenzare un nodo tramite le sue connessioni con altri nodi. Un nodo con alta predicibilità è particolarmente sensibile ai cambiamenti delle variabili ad esso connesse, rendendolo un potenziale target per interventi mirati in ambiti come la psicologia clinica o l’educazione.\n\n### Calcolo con il Pacchetto `mgm`\n\nPer stimare la predicibilità utilizziamo il pacchetto **mgm**, che permette di specificare il tipo di variabili incluse (es. gaussiane per variabili continue).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitAllData <- mgm(\n  as.matrix(allData), \n  type = rep('g', 6) # Variabili gaussiane\n)\n#> \n  |                                                                        \n  |                                                                  |   0%\n  |                                                                        \n  |-----------                                                       |  17%\n  |                                                                        \n  |----------------------                                            |  33%\n  |                                                                        \n  |---------------------------------                                 |  50%\n  |                                                                        \n  |--------------------------------------------                      |  67%\n  |                                                                        \n  |-------------------------------------------------------           |  83%\n  |                                                                        \n  |------------------------------------------------------------------| 100%\n#> Note that the sign of parameter estimates is stored separately; see ?mgm\n```\n:::\n\n\n\n\nSuccessivamente, possiamo calcolare la predicibilità per ciascun nodo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredictAll <- predict(fitAllData, na.omit(allData))\npredictAll$errors$R2\n#> [1] 0.139 0.518 0.442 0.315 0.458 0.126\n```\n:::\n\n\n\n\nPer valutare la qualità esplicativa complessiva della rete, calcoliamo la **predicibilità media**:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(predictAll$errors$R2)\n#> [1] 0.333\n```\n:::\n\n\n\n\nOltre a $R^2$, possiamo esaminare l’**Errore Quadratico Medio (RMSE)**, che misura la discrepanza tra i valori osservati e quelli previsti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(predictAll$errors$RMSE)\n#> [1] 0.811\n```\n:::\n\n\n\n\n### Interpretazione dei Risultati\n\nL'analisi della predicibilità evidenzia quanto ciascun nodo sia integrato nella rete e fornisce indicazioni utili sul ruolo di ogni variabile:\n\n1. **Nodi con Alta Predicibilità**: Variabili come competenza, motivazione e autonomia presentano valori di $R^2$ elevati. Questi nodi sono fortemente influenzati dalle loro connessioni, indicando che sono centrali nella rete e ben integrati nel modello.\n\n2. **Nodi con Bassa Predicibilità**: Variabili come apprendimento autoregolato (SRL) e relazionalità hanno $R^2$ più bassi. Questi nodi potrebbero essere meno influenti o scarsamente connessi, suggerendo la necessità di ulteriori verifiche, ad esempio:\n   - La variabile è meno centrale nel sistema studiato.\n   - Mancano connessioni significative con altri nodi.\n   - Possono esserci problemi nella misurazione o nella definizione della variabile.\n\nLa predicibilità può anche essere rappresentata graficamente, con il valore di $R^2$ visualizzato come grafici a torta all'interno dei nodi:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallDataPlot <- plot(\n    allNetwork,\n    title = \"Both countries combined\",\n    vsize = 9,\n    edge.labels = TRUE,\n    cut = 0.10,\n    minimum = 0.05,\n    pie = predictAll$errors$R2\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nL'analisi della predicibilità offre informazioni utili per:\n\n- **Identificare target di intervento**: Nodi con alta predicibilità (es. competenza e motivazione) sono particolarmente sensibili alle connessioni, rendendoli strategici per interventi mirati.\n- **Rivedere nodi marginali**: Nodi con bassa predicibilità (es. SRL e relazionalità) richiedono un'ulteriore esplorazione per comprendere meglio il loro ruolo nel sistema.\n\nLa combinazione di $R^2$, RMSE e la rappresentazione grafica permette di ottenere una visione completa della rete, aiutando a individuare punti di forza e aree da approfondire.\n\n## Inferenza sulla Rete: Misure di Centralità\n\nLe **misure di centralità** consentono di identificare i nodi più influenti e importanti all'interno di una rete psicologica. Queste misure forniscono informazioni sul ruolo di ciascun nodo nella rete, aiutando a individuare variabili chiave che potrebbero rappresentare bersagli strategici per interventi o analisi approfondite.\n\n### Principali Misure di Centralità\n\nTra le numerose misure disponibili, le seguenti sono le più comunemente utilizzate per le reti psicologiche grazie alla loro interpretazione chiara e al valore pratico:\n\n1. **Grado di centralità (Degree Centrality)**: Indica il numero di connessioni dirette di un nodo, ignorando il peso degli archi.\n2. **Forza di centralità (Strength Centrality)**: Somma i pesi assoluti di tutte le connessioni di un nodo, evidenziando l'intensità complessiva delle sue relazioni.\n3. **Influenza attesa (Expected Influence)**: Somma i pesi grezzi (positivi e negativi) delle connessioni di un nodo, fornendo un’indicazione dell’effetto complessivo delle sue relazioni.\n\nAd esempio, per un nodo con connessioni 0.3, -0.1 e 0.5:\n\n- **Degree Centrality**: 3 (numero di connessioni).  \n- **Strength Centrality**: $|0.3| + |-0.1| + |0.5| = 0.9$ (somma dei pesi assoluti).  \n- **Expected Influence**: $0.3 + (-0.1) + 0.5 = 0.7$ (somma dei pesi grezzi).  \n\nSe nella rete non sono presenti archi negativi, la **Strength Centrality** e l’**Expected Influence** coincidono.\n\nAltre misure, come **closeness**, **betweenness** ed **eigenvector centrality**, possono essere calcolate, ma spesso hanno un'interpretazione meno diretta nel contesto delle reti psicologiche e non sono generalmente raccomandate per un’analisi standard.\n\n### Calcolo e Visualizzazione delle Misure di Centralità\n\nPer stimare e visualizzare le misure di centralità, utilizziamo il pacchetto **bootnet**. La funzione `centralityPlot()` consente di creare un grafico con le misure selezionate, standardizzate come z-score per una migliore interpretazione visiva.\n\n#### Esempio di Visualizzazione\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncentralityPlot(\n    allNetwork,\n    include = c(\"ExpectedInfluence\", \"Strength\"),\n    scale = \"z-scores\"\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nSe si desiderano i valori numerici delle centralità, è possibile utilizzare la funzione `centralityTable()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncentralityTable(allNetwork)\n#>      graph type        node           measure  value\n#> 1  graph 1   NA Relatedness       Betweenness -0.617\n#> 2  graph 1   NA  Competence       Betweenness  0.772\n#> 3  graph 1   NA    Autonomy       Betweenness  1.697\n#> 4  graph 1   NA     Emotion       Betweenness -0.617\n#> 5  graph 1   NA  Motivation       Betweenness -0.617\n#> 6  graph 1   NA         SRL       Betweenness -0.617\n#> 7  graph 1   NA Relatedness         Closeness -1.144\n#> 8  graph 1   NA  Competence         Closeness  0.721\n#> 9  graph 1   NA    Autonomy         Closeness  1.206\n#> 10 graph 1   NA     Emotion         Closeness -0.202\n#> 11 graph 1   NA  Motivation         Closeness  0.578\n#> 12 graph 1   NA         SRL         Closeness -1.158\n#> 13 graph 1   NA Relatedness          Strength -1.074\n#> 14 graph 1   NA  Competence          Strength  1.224\n#> 15 graph 1   NA    Autonomy          Strength  0.634\n#> 16 graph 1   NA     Emotion          Strength -0.310\n#> 17 graph 1   NA  Motivation          Strength  0.695\n#> 18 graph 1   NA         SRL          Strength -1.170\n#> 19 graph 1   NA Relatedness ExpectedInfluence -1.003\n#> 20 graph 1   NA  Competence ExpectedInfluence  1.220\n#> 21 graph 1   NA    Autonomy ExpectedInfluence  0.649\n#> 22 graph 1   NA     Emotion ExpectedInfluence -0.371\n#> 23 graph 1   NA  Motivation ExpectedInfluence  0.708\n#> 24 graph 1   NA         SRL ExpectedInfluence -1.203\n```\n:::\n\n\n\n\n### Misure Avanzate con `NetworkToolbox`\n\nIl pacchetto **NetworkToolbox** offre un'ampia gamma di misure di centralità, tra cui:\n\n- **Degree Centrality**: Numero di connessioni dirette di un nodo.\n- **Strength Centrality**: Intensità complessiva delle connessioni.\n- **Closeness Centrality**: Misura della vicinanza di un nodo a tutti gli altri.\n- **Eigenvector Centrality**: Valuta l’importanza di un nodo considerando anche l’importanza dei suoi vicini.\n- **Leverage Centrality**: Peso relativo delle connessioni di un nodo rispetto ai suoi vicini.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDegree <- degree(allNetwork$graph)\nStrength <- strength(allNetwork$graph)\nBetweenness <- betweenness(allNetwork$graph)\nCloseness <- closeness(allNetwork$graph)\nEigenvector <- eigenvector(allNetwork$graph)\nLeverage <- leverage(allNetwork$graph)\n\ndata.frame(\n    Variable = names(Degree),\n    Degree,\n    Strength,\n    Betweenness,\n    Closeness,\n    Eigenvector,\n    Leverage\n)\n#>                Variable Degree Strength Betweenness Closeness Eigenvector\n#> Relatedness Relatedness      5     0.40           0      1.89       0.217\n#> Competence   Competence      5     1.07           6      3.27       0.553\n#> Autonomy       Autonomy      5     0.90          10      3.63       0.475\n#> Emotion         Emotion      5     0.62           0      2.58       0.363\n#> Motivation   Motivation      5     0.91           0      3.16       0.495\n#> SRL                 SRL      5     0.37           0      1.88       0.211\n#>             Leverage\n#> Relatedness   -3.429\n#> Competence     1.349\n#> Autonomy       1.066\n#> Emotion       -0.425\n#> Motivation     1.105\n#> SRL           -5.379\n```\n:::\n\n\n\n\nInterpretazione delle misure:\n\n1. **Grado e forza di centralità**: Indicazioni semplici e dirette del numero e della forza delle connessioni di un nodo.\n2. **Influenza attesa**: Misura più raffinata che considera il bilancio complessivo delle connessioni, includendo sia pesi positivi sia negativi.\n3. **Misure avanzate**: Strumenti utili in analisi specifiche, ma da usare con cautela in contesti psicologici standard, poiché la loro interpretazione può risultare meno intuitiva.\n\n### Implicazioni Pratiche\n\nLe misure di centralità sono strumenti cruciali per:\n\n- **Individuare target di intervento**: Nodi con elevata forza o influenza attesa possono rappresentare variabili chiave su cui focalizzarsi.\n- **Valutare l’integrazione dei nodi nella rete**: Nodi con basse misure di centralità possono essere marginali o meno influenti, suggerendo potenziali problemi nella definizione o nella misurazione della variabile.\n\nLe misure calcolate forniscono una visione approfondita della struttura della rete, guidando analisi teoriche e applicative in contesti come la psicologia clinica, l’educazione e la ricerca sui sistemi complessi.\n\n## Altre Opzioni per la Stima delle Reti\n\nCome accennato in precedenza, oltre alle reti basate su correlazioni parziali regolarizzate, esistono diverse altre opzioni di stima delle reti. Di seguito ne presentiamo alcune, ma per ulteriori dettagli si consiglia di consultare le pagine del manuale della funzione `estimateNetwork()`.\n\n### Rete di Associazione \n\nLa **rete di associazione** (*correlation network*) si basa sulle correlazioni semplici tra le variabili. Questo tipo di rete è utile principalmente per **esplorazioni preliminari dei dati**, ma non è generalmente raccomandata per analisi definitive, poiché tende a produrre reti molto dense con molteplici connessioni non significative.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallNetwork_cor <- estimateNetwork(allData,\n    default = \"cor\", verbose = FALSE\n)\n```\n:::\n\n\n\n\n### Metodo `ggmModSelect()`\n\nIl metodo `ggmModSelect()` è particolarmente indicato per dataset **di grandi dimensioni** con un **numero ridotto di nodi**. Funziona in questo modo:\n\n1. Parte da una rete regolarizzata come punto di riferimento iniziale.\n2. Stima tutte le possibili reti **non regolarizzate**.\n3. Seleziona il modello migliore in base al criterio EBIC (Extended Bayesian Information Criterion), scegliendo quello con il valore più basso.\n\nQuesto approccio combina i vantaggi della regolarizzazione con la flessibilità di reti non regolarizzate, risultando in un modello più accurato per dataset specifici.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallNetwork_mgm <- estimateNetwork(allData,\n    default = \"ggmModSelect\", verbose = FALSE\n)\n```\n:::\n\n\n\n\n### Rete di Importanza Relativa\n\nLa rete di **importanza relativa** (`relimp`; *Relative Importance Network*) stima una rete **direzionale** basata sull'importanza relativa dei predittori in un modello di regressione lineare. In questa rete:\n\n- Gli archi rappresentano la magnitudine dell'importanza relativa di ciascun predittore.\n- La direzione degli archi indica come ciascuna variabile influenza le altre, secondo i risultati della regressione.\n\nQuesta rete è utile per identificare relazioni causali teoriche o per evidenziare come alcune variabili predicono altre all'interno del dataset.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nallNetwork_relimp <- estimateNetwork(allData,\n    default = \"relimp\", verbose = FALSE\n)\n```\n:::\n\n\n\n\n### Confronto tra i Modelli\n\n- La **rete `ggmModSelect()`** produce risultati molto simili alla rete regolarizzata standard, con differenze minime nelle connessioni più deboli.\n- La **rete di associazione** è invece **molto densa**, poiché include tutte le correlazioni, senza applicare alcuna penalizzazione.\n- La **rete di importanza relativa** è direzionale e fornisce informazioni aggiuntive su come una variabile influenza le altre.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(\n    allNetwork_cor, title = \"Correlation\", vsize = 18, edge.labels = TRUE, \n    cut = 0.10, minimum = 0.05, layout = LX\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(\n    allNetwork, title = \"EBICglasso\", vsize = 18, edge.labels = TRUE,\n    cut = 0.10, minimum = 0.05, layout = LX\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(\n    allNetwork_mgm, title = \"ggmModSelect\", vsize = 18, edge.labels = TRUE,\n    cut = 0.10, minimum = 0.05, layout = LX\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(\n    allNetwork_relimp, title = \"Relative importance\", vsize = 18, \n    edge.labels = TRUE, cut = 0.10, minimum = 0.05, layout = LX\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Confronto tra Reti\n\nDopo aver illustrato i passaggi fondamentali per stimare una singola rete, procediamo ora al confronto tra diverse reti. Le reti psicologiche offrono metodi per confrontare le reti nel loro complesso, i pesi degli archi (edge weights) e le misure di centralità.\n\nNel nostro caso, disponendo di dati provenienti da due paesi (Finlandia e Austria), possiamo stimare due reti separate, una per ciascun paese, e confrontarle per osservare come differiscono.\n\nPer confrontare le reti, dobbiamo innanzitutto stimarle separatamente per ciascun paese. I passaggi di stima sono gli stessi descritti in precedenza. Per ciascun paese, iniziamo con i passi seguenti:\n\n- Controllo delle assunzioni per ciascun dataset (ad esempio, verifica che la matrice di correlazione sia positiva definita).\n- Verifica con l'algoritmo **goldbricker** per identificare nodi altamente simili che potrebbero necessitare di essere combinati o ridotti. In questo caso, i risultati mostrano che:\n\n- Le matrici di correlazione di entrambe le reti sono già positive definite.\n- Non ci sono nodi altamente simili che richiedono riduzioni.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n### Check the assumptions\n## Finland\n# check for positive definitiveness\ncorrelationMatrix <- cor(\n    x = finlandData, \n    use = c(\"pairwise.complete.obs\")\n)\n\nis.positive.definite(correlationMatrix)\n#> [1] TRUE\n# check for redundancy\ngoldbricker(finlandData,\n    p = 0.05, method = \"hittner2003\",\n    threshold = 0.25, corMin = 0.5, progressbar = FALSE\n)\n#> Suggested reductions: Less than 25 % of correlations are significantly different for the following pairs: \n#> [1] \"No suggested reductions\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Austria\n# check for positive definitiveness\ncorrelationMatrix <- cor(\n    x = austriaData, \n    use = c(\"pairwise.complete.obs\")\n)\n\nis.positive.definite(correlationMatrix)\n#> [1] TRUE\n# check for redundancy\ngoldbricker(austriaData,\n    p = 0.05, method = \"hittner2003\",\n    threshold = 0.25, corMin = 0.5, progressbar = FALSE\n)\n#> Suggested reductions: Less than 25 % of correlations are significantly different for the following pairs: \n#> [1] \"No suggested reductions\"\n```\n:::\n\n\n\n\nStima dei networks:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estimate the networks\nfinlandNetwork <- estimateNetwork(\n    finlandData,\n    default = \"EBICglasso\", corMethod = \"cor_auto\", tuning = 0.5\n)\n\naustriaNetwork <- estimateNetwork(\n    austriaData,\n    default = \"EBICglasso\", corMethod = \"cor_auto\", tuning = 0.5\n)\n```\n:::\n\n\n\n\nCalcoliamo la predicibilità per ciascun paese.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Compute the predictability\nfitFinland <- mgm(\n    as.matrix(finlandData), # data\n    c(\"g\", \"g\", \"g\", \"g\", \"g\", \"g\"),\n    # distribution for each var\n    verbatim = TRUE, # hide warnings and progress bar\n    signInfo = FALSE # hide message about signs\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredictFinland <- predict(fitFinland, na.omit(finlandData))\nmean(predictFinland$errors$R2)\n#> [1] 0.308\nmean(predictFinland$errors$RMSE)\n#> [1] 0.828\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitAustria <- mgm(\n    as.matrix(austriaData), # data\n    c(\"g\", \"g\", \"g\", \"g\", \"g\", \"g\"),\n    # distribution for each var\n    verbatim = TRUE, # hide warnings and progress bar\n    signInfo = FALSE # hide message about signs\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredictAustria <- predict(fitAustria, na.omit(austriaData))\nmean(predictAustria$errors$R2)\n#> [1] 0.344\nmean(predictAustria$errors$RMSE)\n#> [1] 0.804\n```\n:::\n\n\n\n\nDopo aver stimato le reti, possiamo visualizzarle per facilitare il confronto. Questo approccio consente di identificare rapidamente le differenze e le somiglianze tra le reti dei due paesi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nAverageLayout <- averageLayout(finlandNetwork, austriaNetwork)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(finlandNetwork, # input network\n    title = \"Finland\", # plot title\n    vsize = 19, # size of the nodes\n    edge.labels = TRUE, # label the edge weights\n    cut = 0.10, # saturate edges > .10\n    minimum = 0.05, # remove edges < .05\n    pie = predictFinland$errors$R2, # put R2 as pie\n    layout = LX\n) # set the layout\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-35-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(austriaNetwork, # input network\n    title = \"Austria\", # plot title\n    vsize = 19, # size of the nodes\n    edge.labels = TRUE, # label the edge weights\n    cut = 0.10, # saturate edges > .10\n    minimum = 0.05, # remove edges < .05\n    pie = predictAustria$errors$R2, # put R2 as pie\n    layout = LX\n) # set the layout\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-36-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nPossiamo rappresentare graficamente la differenza tra le due reti usando `qgraph()`. La funzione `qgraph()` richiede come input una rete stimata o una matrice. Per creare una rete di differenza, è necessario sottrarre le due matrici delle connessioni delle reti (ad esempio, `finlandNetwork$graph - austriaNetwork$graph`). \n\nIl seguente codice mostra come visualizzare la **rete di differenza** che evidenzia le variazioni nei pesi delle connessioni tra le due reti.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqgraph(finlandNetwork$graph - abs(austriaNetwork$graph),\n    title = \"Difference\", # plot title\n    theme = allDataPlot$Arguments$theme,\n    vsize = 19, # size of the nodes\n    edge.labels = TRUE, # label the edge weights\n    labels = allDataPlot$Arguments$labels, # node labels\n    cut = 0.10, # saturate edges > .10\n    layout = LX\n) # set the layout\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-37-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nIl confronto tra le reti evidenzia differenze tra i due paesi:\n\n- **Finlandia**:\n  - Connessione più forte tra **competenza** ed **emozione**.\n  - Connessione più forte tra **motivazione** e **relazionalità**.\n\n- **Austria**:\n  - Connessioni più forti tra:\n    - **Motivazione** e **competenza**.\n    - **Motivazione** ed **emozione**.\n    - **Competenza** e **autonomia**.\n    - **Autonomia** e **relazionalità**.\n\nQueste differenze suggeriscono che le relazioni psicologiche tra le variabili possono essere influenzate da fattori specifici di ciascun contesto culturale o sociale. La rete di differenza rappresenta un utile strumento visivo per evidenziare queste variazioni e guidare l’interpretazione.\n\nUn confronto visivo delle centralità può essere effettuato nello stesso modo descritto in precedenza. Per farlo, forniamo le reti che vogliamo confrontare come una lista e specifichiamo le misure di centralità da calcolare.\n\nI risultati mostrano che:\n\n- Nella rete dell'**Austria**, la variabile con il valore di centralità più alto è la **motivazione**, indicando che la motivazione è il fattore principale che guida la connettività nella rete.\n- Nella rete della **Finlandia**, la variabile più centrale è la **competenza**, che risulta essere il driver principale della connettività della rete.\n\nQuesto confronto mette in evidenza come le variabili centrali differiscano tra i due contesti, suggerendo che fattori culturali o ambientali possono influenzare il ruolo delle variabili psicologiche nella struttura della rete.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncentralityPlot(\n    list(\n        Finland = finlandNetwork,\n        Austria = austriaNetwork\n    ),\n    include = c(\"ExpectedInfluence\", \"Strength\")\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-38-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Confronto Statistico tra Reti \n\nPer confrontare in modo rigoroso le reti, è necessario utilizzare un test statistico che permetta di stabilire quali differenze nei pesi degli archi o nelle misure di centralità siano significative e non dovute al caso. Il **Network Comparison Test (NCT)** è uno strumento per effettuare un confronto dettagliato della struttura delle reti, dei pesi degli archi e delle centralità.\n\nL’NCT utilizza un approccio basato su permutazioni:\n\n1. Genera un grande numero di reti permutate a partire dalle reti originali, creando una distribuzione di riferimento.\n2. Confronta le reti originali con quelle permutate per determinare se le differenze osservate sono statisticamente significative.\n\nPer eseguire il test, dobbiamo:\n\n- Fornire le due reti da confrontare.\n- Specificare il numero di iterazioni (almeno 1000 è raccomandato per risultati affidabili).\n- Testare gli **archi** con `test.edges = TRUE` e `edges = 'all'` per verificare tutte le connessioni.\n- Testare le **centralità** con `test.centrality = TRUE` (poiché non vengono testate di default).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1337)\n\nCompared <- NCT(\n    finlandNetwork, # network 1\n    austriaNetwork, # network 2\n    verbose = FALSE, # hide warnings and progress bar\n    it = 1000, # number of iterations\n    abs = TRUE,\n    binary.data = FALSE, # set data distribution\n    test.edges = TRUE, # test edge differences\n    edges = 'all', # which edges to test\n    test.centrality = TRUE, # test centrality\n    progressbar = FALSE # progress bar\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCompared$glstrinv.sep # Separate global strength values of the individual networks\n#> [1] 2.15 2.17\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCompared$einv.pvals # Holm-Bonferroni adjusted p-values for each edge\n#>           Var1       Var2  p-value Test statistic E\n#> 7  Relatedness Competence 0.017982           0.0681\n#> 13 Relatedness   Autonomy 0.001998           0.0952\n#> 14  Competence   Autonomy 0.000999           0.1348\n#> 19 Relatedness    Emotion 0.165834           0.0414\n#> 20  Competence    Emotion 0.000999           0.1713\n#> 21    Autonomy    Emotion 0.009990           0.0767\n#> 25 Relatedness Motivation 0.000999           0.1371\n#> 26  Competence Motivation 0.000999           0.1605\n#> 27    Autonomy Motivation 0.003996           0.0876\n#> 28     Emotion Motivation 0.001998           0.1287\n#> 31 Relatedness        SRL 0.077922           0.0467\n#> 32  Competence        SRL 0.000999           0.1258\n#> 33    Autonomy        SRL 0.688312           0.0123\n#> 34     Emotion        SRL 0.073926           0.0530\n#> 35  Motivation        SRL 0.301698           0.0306\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCompared$diffcen.real # Difference in centralities\n#>             strength expectedInfluence\n#> Relatedness    0.105             0.105\n#> Competence     0.070             0.070\n#> Autonomy      -0.229            -0.229\n#> Emotion        0.127             0.214\n#> Motivation    -0.209            -0.209\n#> SRL            0.088             0.175\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nCompared$diffcen.pval # Holm-Bonferroni adjusted p-values for each centrality\n#>             strength expectedInfluence\n#> Relatedness 0.006993          0.006993\n#> Competence  0.127872          0.127872\n#> Autonomy    0.000999          0.000999\n#> Emotion     0.009990          0.000999\n#> Motivation  0.000999          0.000999\n#> SRL         0.132867          0.000999\n```\n:::\n\n\n\n\n### Interpretazione dei Risultati\n\n**Forza Globale delle Reti.** Finlandia: 2.15, Austria: 2.17. La differenza tra le due reti ($\\Delta = 0.024$) non è statisticamente significativa, indicando che le reti hanno una connettività complessiva simile.\n\n**Differenze nei Pesi degli Archi.** Gli archi **Competence-Autonomy**, **Competence-Emotion**, **Competence-Motivation**, **Relatedness-Competence** e **Relatedness-Motivation** mostrano differenze statisticamente significative ($p < 0.05$). Archi come **Relatedness-Emotion** e **Autonomy-SRL** non mostrano differenze significative.\n\n**Differenze nelle Centralità.** **Autonomy** e **Motivation** hanno differenze significative sia in **strength** che in **expected influence** ($p < 0.001$), suggerendo che il loro ruolo nella rete varia notevolmente tra i due paesi. **Relatedness** e **Emotion** mostrano differenze significative ($p < 0.01$). **Competence** e **SRL** non presentano differenze significative nelle centralità.\n\nIn conclusione, le reti di Finlandia e Austria hanno una forza globale simile, ma mostrano differenze significative in alcune connessioni chiave e centralità. **Competence**, **Autonomy**, e **Motivation** giocano ruoli diversi nei due contesti culturali.\n Le differenze nei pesi degli archi e nelle centralità suggeriscono influenze specifiche di fattori contestuali o culturali.\n\n## La Rete della Variabilità\n\nLa **rete della variabilità** fornisce un'indicazione di come i pesi degli archi (le connessioni tra nodi) variano tra le reti. In altre parole, questa rete riflette il **grado di variabilità** o le **differenze individuali** presenti nella popolazione analizzata.\n\n- **Archi con bassa variabilità:** Indicano che le connessioni sono simili tra le reti, ovvero stabili e consistenti.\n- **Archi con alta variabilità:** Indicano che le connessioni differiscono significativamente tra le reti, suggerendo la presenza di differenze individuali o contestuali.\n\nPer costruire la rete della variabilità, calcoliamo la deviazione standard dei pesi degli archi tra le due reti. Il processo include:\n\n1. La creazione di due matrici, una per ciascuna rete.\n2. Un ciclo che calcola la deviazione standard per ogni arco tra le due reti.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Construct a network where edges are standard deviations across edge weights of networks\nedgeMeanJoint <- matrix(0, 6, 6)\nedgeSDJoint <- matrix(0, 6, 6)\nfor (i in 1:6) {\n    for (j in 1:6) {\n        vector <- c(getWmat(finlandNetwork)[i, j], getWmat\n        (austriaNetwork)[i, j])\n        edgeMeanJoint[i, j] <- mean(vector)\n        edgeSDJoint[i, j] <- sd(vector)\n    }\n}\n```\n:::\n\n\n\n\nSuccessivamente, tracciamo le reti in cui i pesi degli archi rappresentano le deviazioni standard di tutti gli archi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqgraph(edgeSDJoint,\n    layout = LX, edge.labels = TRUE,\n    labels = allDataPlot$Arguments$labels, vsize = 9,\n    cut = 0.09, minimum = 0.01, theme = \"colorblind\"\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-45-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nAllo stesso modo in cui abbiamo confrontato i paesi, possiamo confrontare i generi. Come mostrato nel seguente blocco di codice, stimiamo la rete per il gruppo maschile, quella per il gruppo femminile e la rete di differenza. Le differenze risultano molto piccole o addirittura trascurabili.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmaleNetwork <- estimateNetwork(maleData, default = \"EBICglasso\")\nfemaleNetwork <- estimateNetwork(femaleData, default = \"EBICglasso\")\n\nplot(maleNetwork,\n    title = \"Male\", vsize = 9, edge.labels = TRUE,\n    cut = 0.10, minimum = 0.05, layout = LX\n)\n\nplot(femaleNetwork,\n    title = \"Female\", vsize = 9,\n    edge.labels = TRUE,\n    cut = 0.10, minimum = 0.05, layout = LX\n)\n\nqgraph(femaleNetwork$graph - maleNetwork$graph,\n    title =\n        \"Difference\", cut = 0.1,\n    labels = allDataPlot$Arguments$labels, vsize = 9,\n    minimum = 0.01,\n    edge.labels = TRUE, layout = LX, theme =\n        \"colorblind\"\n)\n```\n:::\n\n\n\n\nDi seguito eseguiamo il **Network Comparison Test (NCT)** e osserviamo che i valori $p$ relativi alle differenze tra tutti gli archi non sono statisticamente significativi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nComparedGender <- NCT(\nmaleNetwork, # network 1\nfemaleNetwork, # network 2\nverbose = FALSE, # hide warnings and progress bar\nit = 1000, # number of iterations\nabs = T, # test strength or expected influence?\nbinary.data = FALSE, # set data distribution\ntest.edges = TRUE, # test edge differences\nedges = 'all', # which edges to test\nprogressbar = FALSE) # progress bar\nComparedGender$einv.pvals # Holm-Bonferroni adjusted p-values for each edge\n```\n:::\n\n\n\n\n## Valutazione della Robustezza e Accuratezza\n\nIl metodo più comune per valutare la stabilità e l'accuratezza delle reti stimate è il **bootstrapping**. Questo procedimento prevede la creazione di un grande numero di reti bootstrappate (almeno 1000) a partire dai dati originali.\n\n**Passaggi del Bootstrapping:**\n\n1. Si generano un numero elevato di reti bootstrappate basate sui dati originali.\n2. Si calcolano i pesi degli archi per ciascuna di queste reti.\n3. Si utilizzano i pesi degli archi delle reti bootstrappate per costruire intervalli di confidenza che rappresentano l'accuratezza degli archi.\n\n**Interpretazione:**\n\n- Per ogni arco nella rete stimata, i pesi vengono confrontati con gli intervalli di confidenza generati dalle reti bootstrappate.\n- Un arco è considerato statisticamente significativo se i limiti superiore e inferiore dell’intervallo di confidenza non includono lo zero.\n- Al contrario, un arco è non significativo se uno dei limiti dell’intervallo di confidenza attraversa la linea dello zero.\n\nQuesto approccio consente di identificare quali archi sono robusti e quali potrebbero essere il risultato di variabilità casuale nei dati.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnCores <- parallel::detectCores() - 1\n# Non-parametric bootstrap for stability of edges and of edge differences\n\nallBoot <- bootnet(\n    allNetwork, # network input\n    default = \"EBICglasso\", # method\n    nCores = nCores, # number of cores for parallelization\n    computeCentrality = FALSE, # estimate centrality?\n    statistics = \"edge\" # what statistics do we want?\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(allBoot,\n    plot = \"area\", order = \"sample\", legend = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-49-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nCome mostrato nella Figura precedente, solo gli archi **autonomy-emotion** ed **emotion-SRL** attraversano la linea dello zero e, pertanto, non sono significativi. \n\nPossiamo inoltre tracciare il **grafico delle differenze tra gli archi**, che verifica se i pesi degli archi differiscono significativamente tra loro. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(allBoot,\n    plot = \"difference\", order = \"sample\",\n    onlyNonZero = FALSE, labels = TRUE\n)\n```\n:::\n\n\n\n\n**Interpretazione del Grafico delle Differenze tra gli Archi**\n\n- **Quadrati grigi:** Indicano che l'intervallo di confidenza al 95% ottenuto dal bootstrapping per la differenza tra due archi attraversa la linea dello zero, suggerendo che la differenza non è statisticamente significativa.\n- **Quadrati neri:** Indicano che l'intervallo di confidenza non attraversa lo zero, quindi la differenza tra i due archi è significativa.\n\nAd esempio:\n\n- Gli archi **autonomy-emotion** ed **emotion-SRL** presentano un quadrato grigio, indicando una differenza non significativa.\n- Gli archi **emotion-SRL** e **relatedness-SRL** presentano un quadrato nero, indicando che i due archi differiscono significativamente.\n\nL'accuratezza delle misure di centralità viene valutata tramite il **case dropping test**. In questo test, vengono eliminate diverse proporzioni di casi dai dati, e si calcola la correlazione tra la misura di centralità osservata e quella ottenuta dai dati ridotti. Se la correlazione diminuisce significativamente dopo l'eliminazione di un piccolo sottoinsieme di casi, la misura di centralità è considerata **non affidabile**.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1)\ncentBoot <- bootnet(\n    allNetwork, # network input\n    default = \"EBICglasso\", # method\n    type = \"case\", # method for testing centrality stability\n    nCores = nCores, # number of cores\n    computeCentrality = TRUE, # compute centrality\n    statistics = c(\"strength\", \"expectedInfluence\"),\n    nBoots = 19000, # number of bootstraps\n    caseMin = .05, # min cases to drop\n    caseMax = .95 # max cases to drop\n)\n```\n:::\n\n\n\n\nIl **coefficiente di stabilità della correlazione** è una metrica utilizzata per valutare la stabilità delle misure di centralità attraverso il **case dropping test**. Esso viene stimato come la massima proporzione di casi che può essere eliminata mantenendo una correlazione di almeno 0.7 con il campione originale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorStability(centBoot)\n#> === Correlation Stability Analysis === \n#> \n#> Sampling levels tested:\n#>    nPerson Drop%    n\n#> 1      358    95 1860\n#> 2     1074    85 1932\n#> 3     1790    75 1884\n#> 4     2506    65 1893\n#> 5     3222    55 1950\n#> 6     3938    45 1904\n#> 7     4654    35 1887\n#> 8     5370    25 1860\n#> 9     6086    15 1834\n#> 10    6802     5 1996\n#> \n#> Maximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:\n#> \n#> expectedInfluence: 0.95 (CS-coefficient is highest level tested)\n#>   - For more accuracy, run bootnet(..., caseMin = 0.85, caseMax = 1) \n#> \n#> strength: 0.95 (CS-coefficient is highest level tested)\n#>   - For more accuracy, run bootnet(..., caseMin = 0.85, caseMax = 1) \n#> \n#> Accuracy can also be increased by increasing both 'nBoots' and 'caseN'.\n```\n:::\n\n\n\n\nSe tracciamo i risultati, possiamo osservare che il **coefficiente di stabilità della correlazione** è pari a 0.95, un valore molto elevato che indica un'alta stabilità degli archi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(centBoot)\n```\n\n::: {.cell-output-display}\n![](01_networks_files/figure-html/unnamed-chunk-53-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Riflessioni Conclusive\n\nIl campo delle reti psicologiche è in continua evoluzione, con metodi sempre più raffinati e applicazioni in costante crescita. In questo capitolo abbiamo esplorato i passaggi fondamentali per analizzare una rete psicologica, visualizzarne i risultati e confrontare diverse reti, oltre a introdurre tecniche statistiche robuste come il bootstrapping per valutare l’accuratezza delle reti stimate.\n\nUn tema rilevante è il confronto tra le reti psicologiche e altri approcci analitici. Ad esempio, l’**Epistemic Network Analysis (ENA)** presenta alcune limitazioni rispetto all’analisi delle reti psicologiche:\n\n- Non offre strumenti per verificare se i pesi degli archi si discostano dal caso.\n- Non include metodi rigorosi per confrontare reti o valutare i pesi degli archi.\n- Non prevede misure di centralità o altre metriche tipiche delle reti.\n\nAllo stesso modo, il **process mining**, che genera reti di transizione, è limitato nella sua capacità di fornire test statistici per confermare la validità dei modelli o confrontarli con altri. L'**analisi delle reti sociali (SNA)**, pur essendo più affine alle reti psicologiche, si concentra prevalentemente su archi non direzionati e positivi, utilizzati per analizzare interazioni sociali o semantiche, risultando meno flessibile per studiare le dipendenze complesse tra variabili psicologiche.\n\nLe reti psicologiche si distinguono per la loro capacità di rappresentare in modo dettagliato le interazioni e le dipendenze tra variabili. Grazie a una vasta gamma di metodi di stima e tecniche di ottimizzazione, offrono una prospettiva unica e ricca di possibilità analitiche. La comunità scientifica che sostiene questo approccio è particolarmente dinamica, contribuendo con continue innovazioni.\n\nUn ulteriore punto di forza è la flessibilità: le reti psicologiche **non richiedono una teoria predefinita o assunzioni rigide** sulle variabili. Questo le rende strumenti estremamente versatili, adatti sia per esplorazioni teoriche sia per analisi applicate. Come sottolineato da Borsboom et al., le reti psicologiche costituiscono un \"ponte naturale tra l'analisi dei dati e la formulazione di teorie basate sui principi della scienza delle reti,\" aprendo la strada alla **generazione di ipotesi causali**.\n\nIn conclusione, le reti psicologiche rappresentano uno strumento potente e innovativo per l’analisi dei sistemi complessi. Offrono nuove modalità per esplorare le interazioni tra variabili psicologiche, superando molte delle limitazioni di altri approcci. La loro capacità di integrare analisi empiriche e teorie emergenti le rende un contributo fondamentale per il progresso della ricerca psicologica, favorendo la scoperta di nuovi schemi interpretativi e la formulazione di ipotesi teoriche di grande impatto.\n\n**Risorse Raccomandate**\n\n1. Epskamp, S., Borsboom, D., & Fried, E. I. (2018). Estimating psychological networks and their accuracy: A tutorial paper. *Behavior Research Methods, 50*(1), 195–212. https://doi.org/10.3758/s13428-017-0862-1  \n\n2. Epskamp, S., & Fried, E. I. (2018). A tutorial on regularized partial correlation networks. *Psychological Methods, 23*(4), 617–634. https://doi.org/10.1037/met0000167  \n\n3. Van Borkulo, C. D., Van Bork, R., Boschloo, L., Kossakowski, J. J., Tio, P., Schoevers, R. A., & Waldorp, L. J. (2022). Comparing network structures on three aspects: A permutation test. *Psychological Methods.* https://doi.org/10.1037/met0000427  \n\n4. Borsboom, D., Deserno, M. K., Rhemtulla, M., Epskamp, S., Fried, E. I., McNally, R. J., & Waldorp, L. J. (2021). Network analysis of multivariate data in psychological science. *Nature Reviews Methods Primers, 1*(1), 58. https://doi.org/10.1038/s43586-021-00055-w  \n\n5. Bringmann, L. F., Elmer, T., Epskamp, S., Krause, R. W., Schoch, D., Wichers, M., & Snippe, E. (2019). What do centrality measures measure in psychological networks? *Journal of Abnormal Psychology, 128*(8), 892–903. https://doi.org/10.1037/abn0000446  \n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] matrixcalc_1.0-6            mgm_1.2-14                 \n#>  [3] qgraph_1.9.8                NetworkComparisonTest_2.2.2\n#>  [5] NetworkToolbox_1.4.2        networktools_1.5.2         \n#>  [7] bootnet_1.6                 rio_1.2.3                  \n#>  [9] ggokabeito_0.1.0            see_0.10.0                 \n#> [11] MASS_7.3-65                 viridis_0.6.5              \n#> [13] viridisLite_0.4.2           ggpubr_0.6.0               \n#> [15] ggExtra_0.10.1              gridExtra_2.3              \n#> [17] patchwork_1.3.0             bayesplot_1.11.1           \n#> [19] semTools_0.5-6              semPlot_1.1.6              \n#> [21] lavaan_0.6-19               psych_2.4.12               \n#> [23] scales_1.3.0                markdown_1.13              \n#> [25] knitr_1.49                  lubridate_1.9.4            \n#> [27] forcats_1.0.0               stringr_1.5.1              \n#> [29] dplyr_1.1.4                 purrr_1.0.4                \n#> [31] readr_2.1.5                 tidyr_1.3.1                \n#> [33] tibble_3.2.1                ggplot2_3.5.1              \n#> [35] tidyverse_2.0.0             here_1.0.1                 \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2       later_1.4.1         R.oo_1.27.0        \n#>   [4] XML_3.99-0.18       rpart_4.1.24        lifecycle_1.0.4    \n#>   [7] Rdpack_2.6.2        rstatix_0.7.2       doParallel_1.0.17  \n#>  [10] rprojroot_2.0.4     lattice_0.22-6      survey_4.4-2       \n#>  [13] rockchalk_1.8.157   backports_1.5.0     magrittr_2.0.3     \n#>  [16] openxlsx_4.2.8      Hmisc_5.2-2         rmarkdown_2.29     \n#>  [19] plotrix_3.8-4       yaml_2.3.10         IsingFit_0.4       \n#>  [22] httpuv_1.6.15       zip_2.3.2           DBI_1.2.3          \n#>  [25] pbapply_1.7-2       minqa_1.2.8         RColorBrewer_1.1-3 \n#>  [28] multcomp_1.4-28     abind_1.4-8         quadprog_1.5-8     \n#>  [31] R.utils_2.13.0      nnet_7.3-20         TH.data_1.1-3      \n#>  [34] sandwich_3.1-1      relaimpo_2.2-7      gdata_3.0.1        \n#>  [37] ellipse_0.5.0       arm_1.14-4          codetools_0.2-20   \n#>  [40] tidyselect_1.2.1    shape_1.4.6.1       farver_2.1.2       \n#>  [43] IsingSampler_0.2.3  lme4_1.1-36         stats4_4.4.2       \n#>  [46] base64enc_0.1-3     eigenmodel_1.11     jsonlite_1.9.0     \n#>  [49] e1071_1.7-16        mitml_0.4-5         Formula_1.2-5      \n#>  [52] survival_3.8-3      iterators_1.0.14    emmeans_1.10.7     \n#>  [55] foreach_1.5.2       tools_4.4.2         snow_0.4-4         \n#>  [58] Rcpp_1.0.14         glue_1.8.0          mnormt_2.1.1       \n#>  [61] pan_1.9             xfun_0.51           withr_3.0.2        \n#>  [64] fastmap_1.2.0       mitools_2.4         boot_1.3-31        \n#>  [67] digest_0.6.37       mi_1.1              timechange_0.3.0   \n#>  [70] R6_2.6.1            mime_0.12           estimability_1.5.1 \n#>  [73] mice_3.17.0         colorspace_2.1-1    gtools_3.9.5       \n#>  [76] jpeg_0.1-10         weights_1.0.4       R.methodsS3_1.8.2  \n#>  [79] generics_0.1.3      data.table_1.17.0   corpcor_1.6.10     \n#>  [82] class_7.3-23        htmlwidgets_1.6.4   pkgconfig_2.0.3    \n#>  [85] sem_3.1-16          gtable_0.3.6        htmltools_0.5.8.1  \n#>  [88] carData_3.0-5       cocor_1.1-4         png_0.1-8          \n#>  [91] wordcloud_2.6       reformulas_0.4.0    rstudioapi_0.17.1  \n#>  [94] tzdb_0.4.0          reshape2_1.4.4      curl_6.2.1         \n#>  [97] coda_0.19-4.1       checkmate_2.3.2     nlme_3.1-167       \n#> [100] nloptr_2.1.1        proxy_0.4-27        zoo_1.8-13         \n#> [103] parallel_4.4.2      miniUI_0.1.1.1      foreign_0.8-88     \n#> [106] pillar_1.10.1       grid_4.4.2          vctrs_0.6.5        \n#> [109] promises_1.3.2      car_3.1-3           OpenMx_2.21.13     \n#> [112] jomo_2.7-6          xtable_1.8-4        cluster_2.1.8      \n#> [115] htmlTable_2.4.3     evaluate_1.0.3      pbivnorm_0.6.0     \n#> [118] mvtnorm_1.3-3       cli_3.6.4           kutils_1.73        \n#> [121] compiler_4.4.2      rlang_1.1.5         smacof_2.1-7       \n#> [124] ggsignif_0.6.4      labeling_0.4.3      fdrtool_1.2.18     \n#> [127] plyr_1.8.9          stringi_1.8.4       nnls_1.6           \n#> [130] munsell_0.5.1       lisrelToR_0.3       glmnet_4.1-8       \n#> [133] pacman_0.5.1        Matrix_1.7-2        hms_1.1.3          \n#> [136] glasso_1.11         shiny_1.10.0        haven_2.5.4        \n#> [139] rbibutils_2.3       igraph_2.1.4        broom_1.0.7        \n#> [142] RcppParallel_5.1.10 polynom_1.4-1\n```\n:::\n",
    "supporting": [
      "01_networks_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "147833238bf28d2d825d4cffbfde0b00",
  "result": {
    "engine": "knitr",
    "markdown": "# Exploratory structural equation modelling {#sec-sem-esem}\n\n::: callout-important\n## In questo capitolo imparerai a:\n\n- Comprensione delle differenze tra l'ESEM completo e il set-ESEM, con quest'ultimo come compromesso tra CFA e ESEM per gestire specifici blocchi indipendenti di variabili.\n- Giustificazione dell'uso del set-ESEM nei modelli strutturali come alternativa al CFA.\n- Identificazione degli effetti distorti e dei coefficienti di percorso attenuati nei modelli CFA a causa della multicollinearità, e come il set-ESEM riduce questo problema.\n- Uso dell'invarianza di misura nei modelli longitudinali per garantire la stabilità delle misurazioni nel tempo, applicabile in set-ESEM.\n- Benefici del set-ESEM, inclusi miglior fit del modello, validità discriminante più accurata e riduzione degli errori di tipo II nei modelli strutturali.\n- Implementazione pratica in R con lavaan.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Structural Equation Modeling* del testo di @petersen2024principles.\n- Leggere l'articolo: \n    - Marsh, H., & Alamer, A. (2024). When and how to use set‐exploratory structural equation modelling to test structural models: A tutorial using the R package lavaan. *British Journal of Mathematical and Statistical Psychology*, *77*, 459--476.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(semTools, tidyr, psych, lavaan, kableExtra, stringr)\n```\n:::\n\n\n\n:::\n\n## Introduzione\n\nL'*Exploratory Structural Equation Modeling* (ESEM) è una tecnica statistica innovativa che combina i punti di forza dell'analisi fattoriale esplorativa (EFA) e dell'analisi fattoriale confermativa (CFA). Introdotta da Asparouhov e Muthén nel 2009 e successivamente sviluppata da Marsh et al. (2009, 2014), l'ESEM consente di modellare strutture fattoriali complesse mantenendo una flessibilità analitica che supera i limiti tradizionali della CFA. Questa tecnica si rivela particolarmente vantaggiosa in presenza di item con fonti di varianza multiple, come sottolineato da Morin et al. (2013), grazie alla sua capacità di migliorare l'adattamento del modello, ridurre le correlazioni spurie tra fattori e rappresentare in modo realistico le saturazioni fattoriali incrociate.\n\nL'efficacia dell'ESEM è stata dimostrata in numerosi ambiti della psicologia, tra cui la psicologia clinica, educativa, industriale e della salute, dove spesso supera il CFA in termini di adattamento e interpretabilità del modello. Tuttavia, in contesti specifici, potrebbe essere necessario introdurre restrizioni al modello ESEM completamente libero. Questo ha portato all'evoluzione del set-ESEM (Marsh et al., 2020), una tecnica che integra in modo strategico elementi di ESEM e CFA in un quadro analitico unificato.\n\nIn questo capitolo, esploreremo i fondamenti e le applicazioni dell'*Exploratory Structural Equation Modeling* (ESEM), seguendo il tutorial proposto da @marsh2024and.\n\n## EFA, CFA, ESEM e Set-ESEM\n\nL'analisi fattoriale esplorativa (EFA) e l'analisi fattoriale confermativa (CFA) rappresentano i due approcci principali per indagare le strutture latenti nei dati. L'EFA, introdotta da Spearman (1904) e sviluppata ulteriormente da Thurstone (1935, 1947), era inizialmente conosciuta semplicemente come \"analisi fattoriale.\" Solo con l'introduzione della CFA si è stabilita una distinzione tra l'approccio esplorativo (EFA) e quello confermativo (CFA). La CFA è diventata uno strumento centrale nella psicometria grazie alla sua capacità di valutare l'adattamento del modello, gestire dati mancanti con metodi avanzati e confrontare modelli teorici alternativi. Tuttavia, uno dei suoi principali limiti è l'ipotesi rigida che ogni item carichi su un solo fattore, ignorando potenziali carichi incrociati.\n\nQuesto limite ha portato allo sviluppo dell'Exploratory Structural Equation Modeling (ESEM) da parte di Asparouhov e Muthén (2009). L'ESEM combina la flessibilità dell'EFA con la potenza analitica della SEM, consentendo carichi incrociati tra i fattori e offrendo un migliore adattamento ai dati psicometrici complessi. Questo approccio si è dimostrato superiore alla CFA in numerosi studi, migliorando l'adattamento del modello e sostenendo la validità discriminante tra i fattori. Una meta-analisi recente condotta da Gegenfurtner (2022) su 158 studi ha confermato che l'ESEM supera la CFA sia per bontà di adattamento sia per validità discriminante.\n\nL'ESEM è ormai uno strumento consolidato nella psicometria moderna, dimostrando la sua efficacia nel modellare strutture fattoriali complesse. Grazie alla sua capacità di rappresentare accuratamente le correlazioni e le regressioni tra fattori e di utilizzare tutte le informazioni disponibili a livello degli indicatori, si è affermato come un'alternativa valida e spesso preferibile alla CFA.\n\nTuttavia, l'ESEM, pur essendo più flessibile, può risultare meno parsimonioso rispetto alla CFA in alcune situazioni. Per questo motivo è stato sviluppato il set-ESEM (Marsh et al., 2020), un'evoluzione che bilancia la flessibilità dell'ESEM con una struttura più rigorosa, tipica della CFA. Il set-ESEM utilizza tecniche di rotazione come la geomin rotation o il target rotation per limitare i carichi incrociati non essenziali, rendendo il modello più parsimonioso e adatto a specifiche esigenze empiriche.\n\n::: {#fig-set-esem}\n![](../../figures/cfa_esem_set_esem.png){width=\"80%\"}\n\n**CFA, ESEM completo e set-ESEM.** Nota: le linee tratteggiate indicano i carichi incrociati non target. [Figura tratta da Marsh et al., 2024]\n:::\n\n## Situazioni in cui il Set-ESEM è Preferibile all'ESEM Completo\n\nIn alcune situazioni, l'ESEM completo potrebbe non essere l'approccio ottimale per un'analisi. Questo accade quando è necessario garantire che specifici insiemi di fattori e item siano distinti da altri insiemi non correlati. Per affrontare tali scenari, si può utilizzare il *set-ESEM*, un approccio introdotto da Marsh et al. (2020) che permette di creare sottoinsiemi di ESEM all'interno di un modello più ampio. Il set-ESEM bilancia la flessibilità dell'ESEM completo con la struttura più rigorosa della CFA, offrendo un compromesso ideale in termini di adattamento del modello, parsimonia e definizione chiara dei modelli di misurazione. Di seguito, descriviamo due situazioni reali in cui il set-ESEM può risultare preferibile, basandoci su dati empirici.\n\n### 1. Item relativi a costrutti teoricamente distinti\n\nLa prima situazione riguarda dataset che includono item derivati da costrutti concettualmente distinti o appartenenti a teorie differenti. Ad esempio, consideriamo un dataset che misura le tre necessità psicologiche di base—autonomia, competenza e relazionalità—utilizzando la scala *BPN-L2* (Alamer, 2022), insieme a due costrutti di perseveranza nello sforzo e coerenza dell’interesse, derivati dalla teoria del *grit* (Duckworth et al., 2007) e misurati con la scala *L2-grit* (Alamer, 2021b). Poiché le necessità psicologiche di base e il *grit* si fondano su teorie con obiettivi e funzioni differenti, stimare carichi incrociati tra i loro item risulterebbe inappropriato. Per esempio, i fattori delle necessità psicologiche sono influenzati dal contesto sociale, mentre il *grit* è considerato un tratto stabile della personalità.\n\nIn queste circostanze, il set-ESEM consente di suddividere il modello in due blocchi: uno dedicato ai tre fattori delle necessità psicologiche, con carichi incrociati tra loro ma non con gli item del *grit*, e un secondo blocco per i due fattori del *grit*, senza carichi incrociati con le necessità psicologiche. Questo approccio mantiene una maggiore parsimonia, preservando sia la coerenza teorica sia l’accuratezza empirica.\n\n### 2. Costrutti rilevanti misurati in più momenti temporali\n\nIl secondo scenario in cui il set-ESEM è consigliato riguarda analisi longitudinali, in cui i dati provengono da costrutti misurati in più momenti temporali. In questi casi, i carichi incrociati dovrebbero essere stimati solo tra item relativi allo stesso momento temporale. Ad esempio, consideriamo un dataset che misura passione armoniosa, passione ossessiva e autonomia in due momenti distinti. Questi costrutti sono correlati concettualmente, rendendo ragionevoli i carichi incrociati all'interno dello stesso momento. Tuttavia, permettere carichi incrociati tra item di momenti diversi sarebbe teoricamente inappropriato e tecnicamente problematico, introducendo effetti di confondimento.\n\nInoltre, nelle analisi longitudinali SEM è consuetudine correlare i residui degli stessi item nel tempo (Marsh & Hau, 1996). Utilizzando il set-ESEM, è possibile preservare la flessibilità analitica dell'ESEM mantenendo il rigore strutturale necessario per evitare interpretazioni distorte.\n\n::: {#fig-set-esem}\n![](../../figures/cfa_esem_set_esem.png){width=\"80%\"}\n\n**CFA, ESEM completo e set-ESEM.** Nota: le linee tratteggiate indicano i carichi incrociati non target. [Figura tratta da @marsh2024and]\n:::\n\n## Necessità Psicologiche di Base e Percezione del Sé\n\nPer illustrare il primo scenario descritto in precedenza, esaminiamo uno studio condotto su 269 studenti sauditi che imparano l’inglese come seconda lingua (*L2*) in un’università pubblica saudita [@marsh2024and]. I partecipanti, di età compresa tra 18 e 20 anni (M = 18.5), parlavano arabo come lingua madre e hanno completato un questionario online. Lo studio utilizza il set-ESEM per analizzare i dati, dimostrando come questo approccio possa superare sia l’ESEM completo che la CFA in termini di adattamento del modello e precisione nelle stime.\n\n### Struttura del Modello\n\nLo studio si basa su due blocchi teorici di costrutti: \n\n1. **Necessità Psicologiche di Base (BPN)**:  \n   Questo blocco include autonomia, competenza e relazionalità, tre fattori derivati dalla teoria delle necessità psicologiche di base (Ryan & Deci, 2017; Noels, 2023). Gli item valutano la percezione degli studenti sull’insegnante come promotore di questi tre fattori. \n\n2. **Percezione del Sé**:  \n   Questo blocco comprende senso di significato, senso di sicurezza e motivazione intrinseca, costrutti associati ai risultati positivi delle BPN. La letteratura suggerisce che quando gli studenti percepiscono l’insegnante come un promotore delle BPN, si osserva un aumento della motivazione intrinseca, del senso di significato e della sicurezza (Alamer, 2022; Alamer & Al Khateeb, 2023; Guay et al., 2015).  \n\n### Distinzione Concettuale\n\nAi partecipanti è stato chiesto di valutare sia la percezione dell’insegnante come promotore delle BPN, sia la loro percezione personale in termini di senso di significato, sicurezza e motivazione intrinseca. Questa distinzione concettuale giustifica l’assenza di carichi incrociati tra i due blocchi di item:  \n\n- Gli item relativi alle BPN si concentrano sull’insegnante e riflettono l’interazione sociale.  \n- Gli item relativi alla percezione di sé misurano costrutti soggettivi e individuali.  \n\nConsentire carichi incrociati tra questi due domini sarebbe teoricamente ingiustificato, data la loro natura distinta.\n\n### Variabile di Esito\n\nLo studio include anche l’intenzione di abbandonare il corso come variabile di esito. Questo costrutto rappresenta un indicatore pratico delle implicazioni educative delle percezioni relative all’insegnante e al sé.\n\n### Analisi dei Modelli\n\nI modelli alternativi analizzati nello studio—uno basato su CFA e l’altro su set-ESEM—sono illustrati nella @fig-set-esem-cfa. L’analisi dimostra che il set-ESEM bilancia efficacemente rigore teorico e flessibilità empirica, fornendo stime più affidabili delle relazioni tra variabili latenti e risultati migliori rispetto agli approcci tradizionali.\n\n::: {#fig-set-esem-cfa}\n![](../../figures/set_esem_cfa.png){width=\"90%\"}\n\nSet-ESEM (modello A) e CFA (modello B). Nota: le linee tratteggiate indicano i carichi incrociati non target. [Figura tratta da @marsh2024and]\n:::\n\n**Strumenti di Misura**\n\nPer valutare i costrutti oggetto di studio, sono state utilizzate diverse scale validate, ognuna composta da specifici item rappresentativi. \n\n1. **BPN-L2** *(Alamer, 2022)*:  \n   Questa scala misura le tre necessità psicologiche di base — autonomia, competenza e relazionalità — ciascuna con tre item. Esempi:  \n   - **Autonomia**: *\"Il mio insegnante ci permette di scegliere i compiti di apprendimento linguistico\"* (ω = .75).  \n   - **Competenza**: *\"Il mio insegnante ci dice che siamo capaci di imparare l'inglese\"* (ω = .75).  \n   - **Relazionalità**: *\"Il mio insegnante di inglese è amichevole e cordiale con noi\"* (ω = .91).  \n\n2. **Motivazione intrinseca** *(SDT-L2; Alamer, 2022)*:  \n   Questo costrutto è stato misurato tramite tre item, come:  \n   - *\"Imparo l'inglese perché mi piace\"* (ω = .91).  \n\n3. **Senso di sicurezza e senso di significato** *(Dörnyei & Ushioda, 2021; Dörnyei & Ryan, 2015)*:  \n   - **Sicurezza**: Tre item, ad esempio: *\"Credo nelle mie capacità di fare bene nel corso\"* (ω = .74).  \n   - **Significato**: Tre item, come: *\"So perché mi sono iscritto a questo corso\"* (ω = .91).  \n\n4. **Intenzione di abbandonare il corso** *(Lounsbury et al., 2004)*:  \n   Questo costrutto è stato misurato con cinque item, ad esempio:  \n   - *\"Non ho intenzione di continuare a studiare in questo settore\"* (ω = .90).  \nTutte le misure adottano una scala Likert a cinque punti, con risposte che vanno da 1 (*fortemente in disaccordo*) a 5 (*fortemente d'accordo*), per valutare l'accordo o il disaccordo dei partecipanti con ciascun item.\n\n**Dati**\n\nImportiamo i dati e esaminiamo le variabili.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nstudy1_dat <- rio::import(\n    here::here(\n        \"data\", \"marsh_alamer\", \"Study_1_data.csv\"\n    )\n)\n\nglimpse(study1_dat)\n#> Rows: 269\n#> Columns: 23\n#> $ Intent_to_withdraw1 <int> 2, 2, 4, 4, 5, 1, 4, 2, 1, 5, 2, 4, 5, 5, 3, 5…\n#> $ Intent_to_withdraw2 <int> 2, 3, 4, 5, 5, 1, 3, 4, 1, 5, 2, 5, 5, 5, 4, 5…\n#> $ Intent_to_withdraw3 <int> 1, 2, 1, 4, 5, 1, 3, 1, 1, 5, 2, 3, 4, 4, 3, 4…\n#> $ Intent_to_withdraw4 <int> 2, 2, 3, 5, 5, 1, 3, 2, 2, 4, 2, 4, 4, 4, 5, 4…\n#> $ Intent_to_withdraw5 <int> 3, 3, 4, 4, 4, 1, 4, 2, 1, 5, 2, 4, 4, 4, 4, 4…\n#> $ T_relatedness1      <int> 4, 4, 2, 2, 2, 5, 1, 4, 4, 4, 4, 4, 1, 1, 1, 1…\n#> $ T_relatedness2      <int> 3, 4, 2, 2, 1, 5, 1, 4, 4, 2, 4, 3, 1, 1, 1, 1…\n#> $ T_relatedness3      <int> 3, 5, 2, 2, 2, 5, 1, 4, 4, 4, 4, 4, 1, 1, 3, 1…\n#> $ T_competence1       <int> 4, 5, 2, 4, 3, 5, 5, 4, 2, 4, 3, 4, 2, 2, 3, 2…\n#> $ T_competence2       <int> 4, 4, 2, 3, 3, 5, 5, 5, 2, 4, 4, 4, 2, 2, 4, 2…\n#> $ T_competence3       <int> 4, 5, 1, 4, 3, 5, 4, 4, 2, 4, 3, 3, 2, 2, 4, 2…\n#> $ T_autonomy1         <int> 4, 5, 2, 2, 4, 5, 3, 4, 4, 4, 4, 4, 2, 2, 2, 2…\n#> $ T_autonomy2         <int> 3, 5, 2, 3, 3, 5, 1, 4, 4, 4, 4, 3, 3, 3, 2, 3…\n#> $ T_autonomy3         <int> 3, 5, 2, 2, 3, 5, 1, 4, 4, 3, 3, 3, 1, 1, 4, 1…\n#> $ S_meaning1          <int> 4, 5, 4, 1, 2, 5, 3, 4, 4, 3, 5, 2, 5, 5, 2, 5…\n#> $ S_meaning2          <int> 3, 5, 4, 2, 2, 5, 1, 4, 4, 4, 5, 2, 5, 5, 1, 5…\n#> $ S_meaning3          <int> 5, 4, 4, 2, 2, 5, 1, 4, 4, 4, 5, 2, 5, 5, 2, 5…\n#> $ S_confidence1       <int> 4, 5, 5, 4, 4, 5, 5, 4, 2, 5, 5, 3, 5, 5, 4, 5…\n#> $ S_confidence2       <int> 4, 5, 5, 4, 4, 5, 5, 4, 2, 5, 5, 4, 5, 5, 4, 5…\n#> $ S_confidence3       <int> 4, 5, 5, 5, 5, 5, 5, 4, 1, 5, 5, 3, 5, 5, 4, 5…\n#> $ S_Intrinsic1        <int> 4, 4, 2, 2, 2, 5, 3, 4, 2, 5, 3, 3, 2, 2, 1, 2…\n#> $ S_Intrinsic2        <int> 4, 5, 2, 3, 3, 5, 4, 4, 2, 5, 5, 4, 1, 1, 2, 1…\n#> $ S_Intrinsic3        <int> 4, 5, 1, 2, 3, 5, 4, 4, 2, 5, 4, 4, 1, 1, 2, 1…\n```\n:::\n\n\n\n\n**Codice lavaan per il modello ESEM**\n\nDefiniamo il modello ESEM.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nesem1 <- '\n\n  # the long format (more flexible) each factor is defined separately\n  efa(\"teacher\")*Teacher_autonomy =~ T_autonomy1 + T_autonomy2 + T_autonomy3 + T_competence1 + T_competence2 + T_competence3 + T_relatedness1 + T_relatedness2 + T_relatedness3\n  efa(\"teacher\")*Teacher_competence =~ T_autonomy1 + T_autonomy2 + T_autonomy3 + T_competence1 + T_competence2 + T_competence3 + T_relatedness1 + T_relatedness2 + T_relatedness3\n  efa(\"teacher\")*Teacher_relatedness =~ T_autonomy1 + T_autonomy2 + T_autonomy3 + T_competence1 + T_competence2 + T_competence3 + T_relatedness1 + T_relatedness2 + T_relatedness3\n\n  # the short format (less flexible) all factors defined in one instance (remove ”##” if you want to use this)\n  # efa(\"teacher\")*Teacher_autonomy +\n  # efa(\"teacher\")*Teacher_competence +\n  # efa(\"teacher\")*Teacher_relatedness =~ T_autonomy1 + T_autonomy2 + T_autonomy3 + T_competence1 + T_competence2 + T_competence3 + T_relatedness1 + T_relatedness2 + T_relatedness3\n\n  # defining the second ESEM block\n  efa(\"self\")*Self_Meaning =~ S_meaning1 + S_meaning2 + S_meaning3 + S_confidence1 + S_confidence2 + S_confidence3 + S_Intrinsic1 + S_Intrinsic2+S_Intrinsic3\n  efa(\"self\")*Self_Confidence =~ S_meaning1 + S_meaning2 + S_meaning3 + S_confidence1 + S_confidence2 + S_confidence3 + S_Intrinsic1 + S_Intrinsic2+S_Intrinsic3\n  efa(\"self\")*Intrinsic_Motivation =~ S_meaning1 + S_meaning2 + S_meaning3 + S_confidence1 + S_confidence2 + S_confidence3 + S_Intrinsic1 + S_Intrinsic2+S_Intrinsic3\n\n  # defining the outcome variable\n  Intent_to_Quit =~ Intent_to_withdraw1 + Intent_to_withdraw2 + Intent_to_withdraw3 + Intent_to_withdraw4 + Intent_to_withdraw5\n\n  # defining the structural part\n  Self_Meaning ~ Teacher_autonomy + Teacher_competence + Teacher_relatedness\n  Self_Confidence ~ Teacher_autonomy + Teacher_competence + Teacher_relatedness\n  Intrinsic_Motivation ~ Teacher_autonomy + Teacher_competence + Teacher_relatedness\n  Intent_to_Quit ~ Self_Meaning + Self_Confidence + Intrinsic_Motivation +\n                   Teacher_autonomy + Teacher_competence + Teacher_relatedness\n'\n```\n:::\n\n\n\n\nAdattiamo il modello ai dati.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nout1 <- sem(\n    model = esem1,\n    data = study1_dat,\n    estimator = \"MLR\", # verbose = TRUE, test = \"yuan.bentler\",\n    rotation = \"geomin\",\n    rotation.args = list(geomin.epsilon = 0.005)\n)\n```\n:::\n\n\n\n\nCreiamo il diagramma di percorso.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    out1,\n    what = \"col\", whatLabels = \"no\", style = \"mx\",\n    layout = \"tree\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 5, sizeMan2 = 4\n)\n```\n\n::: {.cell-output-display}\n![](13_esem_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo la soluzione fattoriale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(out1, standardized = TRUE, fit.measures = TRUE) \n#> lavaan 0.6-19 ended normally after 67 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                       103\n#>   Row rank of the constraints matrix                12\n#> \n#>   Rotation method                       GEOMIN OBLIQUE\n#>   Geomin epsilon                                 0.005\n#>   Rotation algorithm (rstarts)                GPA (30)\n#>   Standardized metric                             TRUE\n#>   Row weights                                     None\n#> \n#>   Number of observations                           269\n#> \n#> Model Test User Model:\n#>                                               Standard      Scaled\n#>   Test Statistic                               396.932     367.121\n#>   Degrees of freedom                               185         185\n#>   P-value (Chi-square)                           0.000       0.000\n#>   Scaling correction factor                                  1.081\n#>     Yuan-Bentler correction (Mplus variant)                       \n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              4271.294    3518.139\n#>   Degrees of freedom                               253         253\n#>   P-value                                        0.000       0.000\n#>   Scaling correction factor                                  1.214\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.947       0.944\n#>   Tucker-Lewis Index (TLI)                       0.928       0.924\n#>                                                                   \n#>   Robust Comparative Fit Index (CFI)                         0.950\n#>   Robust Tucker-Lewis Index (TLI)                            0.932\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -7894.627   -7894.627\n#>   Scaling correction factor                                  1.378\n#>       for the MLR correction                                      \n#>   Loglikelihood unrestricted model (H1)      -7696.161   -7696.161\n#>   Scaling correction factor                                  1.179\n#>       for the MLR correction                                      \n#>                                                                   \n#>   Akaike (AIC)                               15971.254   15971.254\n#>   Bayesian (BIC)                             16298.373   16298.373\n#>   Sample-size adjusted Bayesian (SABIC)      16009.844   16009.844\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.065       0.060\n#>   90 Percent confidence interval - lower         0.056       0.052\n#>   90 Percent confidence interval - upper         0.074       0.069\n#>   P-value H_0: RMSEA <= 0.050                    0.003       0.025\n#>   P-value H_0: RMSEA >= 0.080                    0.003       0.000\n#>                                                                   \n#>   Robust RMSEA                                               0.063\n#>   90 Percent confidence interval - lower                     0.053\n#>   90 Percent confidence interval - upper                     0.072\n#>   P-value H_0: Robust RMSEA <= 0.050                         0.013\n#>   P-value H_0: Robust RMSEA >= 0.080                         0.001\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.045       0.045\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Sandwich\n#>   Information bread                           Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                                  Estimate  Std.Err  z-value  P(>|z|)\n#>   Teacher_autonomy =~ teacher                                       \n#>     T_autonomy1                     0.787    0.128    6.159    0.000\n#>     T_autonomy2                     1.156    0.077   14.918    0.000\n#>     T_autonomy3                     0.971    0.104    9.323    0.000\n#>     T_competence1                  -0.058    0.072   -0.806    0.420\n#>     T_competence2                   0.288    0.164    1.753    0.080\n#>     T_competence3                   0.123    0.219    0.564    0.573\n#>     T_relatedness1                  0.423    0.149    2.845    0.004\n#>     T_relatedness2                 -0.011    0.029   -0.391    0.696\n#>     T_relatedness3                  0.332    0.246    1.348    0.178\n#>   Teacher_competence =~ teacher                                     \n#>     T_autonomy1                     0.261    0.119    2.184    0.029\n#>     T_autonomy2                    -0.035    0.039   -0.901    0.368\n#>     T_autonomy3                     0.087    0.085    1.022    0.307\n#>     T_competence1                   1.220    0.073   16.735    0.000\n#>     T_competence2                   0.943    0.147    6.433    0.000\n#>     T_competence3                   0.622    0.169    3.678    0.000\n#>     T_relatedness1                 -0.024    0.020   -1.247    0.212\n#>     T_relatedness2                  0.049    0.053    0.919    0.358\n#>     T_relatedness3                  0.061    0.151    0.404    0.686\n#>   Teacher_relatedness =~ teacher                                    \n#>     T_autonomy1                     0.042    0.061    0.684    0.494\n#>     T_autonomy2                    -0.048    0.066   -0.729    0.466\n#>     T_autonomy3                     0.078    0.104    0.752    0.452\n#>     T_competence1                   0.029    0.054    0.536    0.592\n#>     T_competence2                  -0.041    0.040   -1.043    0.297\n#>     T_competence3                   0.179    0.111    1.608    0.108\n#>     T_relatedness1                  0.832    0.156    5.346    0.000\n#>     T_relatedness2                  1.129    0.086   13.160    0.000\n#>     T_relatedness3                  0.316    0.198    1.593    0.111\n#>   Self_Meaning =~ self                                              \n#>     S_meaning1                      0.808    0.065   12.388    0.000\n#>     S_meaning2                      1.065    0.060   17.818    0.000\n#>     S_meaning3                      1.040    0.056   18.600    0.000\n#>     S_confidence1                  -0.028    0.040   -0.697    0.486\n#>     S_confidence2                   0.098    0.038    2.599    0.009\n#>     S_confidence3                  -0.016    0.017   -0.900    0.368\n#>     S_Intrinsic1                   -0.008    0.053   -0.157    0.875\n#>     S_Intrinsic2                   -0.002    0.044   -0.057    0.955\n#>     S_Intrinsic3                    0.009    0.037    0.231    0.818\n#>   Self_Confidence =~ self                                           \n#>     S_meaning1                      0.052    0.060    0.875    0.382\n#>     S_meaning2                     -0.027    0.027   -0.996    0.319\n#>     S_meaning3                     -0.002    0.026   -0.069    0.945\n#>     S_confidence1                   0.609    0.074    8.255    0.000\n#>     S_confidence2                   0.560    0.059    9.441    0.000\n#>     S_confidence3                   0.553    0.065    8.445    0.000\n#>     S_Intrinsic1                   -0.027    0.073   -0.374    0.708\n#>     S_Intrinsic2                    0.107    0.062    1.737    0.082\n#>     S_Intrinsic3                   -0.011    0.031   -0.354    0.723\n#>   Intrinsic_Motivation =~ self                                      \n#>     S_meaning1                      0.043    0.030    1.461    0.144\n#>     S_meaning2                     -0.011    0.016   -0.665    0.506\n#>     S_meaning3                     -0.014    0.016   -0.915    0.360\n#>     S_confidence1                  -0.026    0.029   -0.905    0.366\n#>     S_confidence2                  -0.004    0.010   -0.396    0.692\n#>     S_confidence3                   0.028    0.024    1.194    0.232\n#>     S_Intrinsic1                    0.449    0.047    9.469    0.000\n#>     S_Intrinsic2                    0.498    0.076    6.581    0.000\n#>     S_Intrinsic3                    0.634    0.078    8.120    0.000\n#>   Intent_to_Quit =~                                                 \n#>     Intnt_t_wthdr1                  1.000                           \n#>     Intnt_t_wthdr2                  0.946    0.033   28.953    0.000\n#>     Intnt_t_wthdr3                  1.017    0.031   32.987    0.000\n#>     Intnt_t_wthdr4                  0.683    0.074    9.170    0.000\n#>     Intnt_t_wthdr5                  0.665    0.053   12.648    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.787    0.612\n#>     1.156    0.922\n#>     0.971    0.774\n#>    -0.058   -0.046\n#>     0.288    0.227\n#>     0.123    0.102\n#>     0.423    0.324\n#>    -0.011   -0.009\n#>     0.332    0.250\n#>                   \n#>     0.261    0.203\n#>    -0.035   -0.028\n#>     0.087    0.069\n#>     1.220    0.972\n#>     0.943    0.744\n#>     0.622    0.516\n#>    -0.024   -0.019\n#>     0.049    0.039\n#>     0.061    0.046\n#>                   \n#>     0.042    0.033\n#>    -0.048   -0.038\n#>     0.078    0.062\n#>     0.029    0.023\n#>    -0.041   -0.033\n#>     0.179    0.149\n#>     0.832    0.636\n#>     1.129    0.900\n#>     0.316    0.238\n#>                   \n#>     0.890    0.738\n#>     1.173    0.919\n#>     1.146    0.927\n#>    -0.031   -0.031\n#>     0.107    0.140\n#>    -0.017   -0.023\n#>    -0.009   -0.008\n#>    -0.003   -0.002\n#>     0.009    0.007\n#>                   \n#>     0.055    0.045\n#>    -0.028   -0.022\n#>    -0.002   -0.002\n#>     0.637    0.639\n#>     0.586    0.763\n#>     0.578    0.766\n#>    -0.028   -0.024\n#>     0.112    0.093\n#>    -0.012   -0.009\n#>                   \n#>     0.070    0.058\n#>    -0.018   -0.014\n#>    -0.023   -0.019\n#>    -0.043   -0.043\n#>    -0.006   -0.008\n#>     0.046    0.061\n#>     0.725    0.619\n#>     0.805    0.669\n#>     1.025    0.815\n#>                   \n#>     1.170    0.955\n#>     1.107    0.911\n#>     1.190    0.875\n#>     0.799    0.637\n#>     0.778    0.648\n#> \n#> Regressions:\n#>                           Estimate  Std.Err  z-value  P(>|z|)   Std.lv\n#>   Self_Meaning ~                                                      \n#>     Teacher_autnmy          -0.040    0.139   -0.287    0.774   -0.036\n#>     Teacher_cmptnc           0.271    0.125    2.172    0.030    0.246\n#>     Teachr_rltdnss           0.287    0.120    2.387    0.017    0.260\n#>   Self_Confidence ~                                                   \n#>     Teacher_autnmy          -0.096    0.152   -0.630    0.529   -0.092\n#>     Teacher_cmptnc           0.299    0.146    2.048    0.041    0.286\n#>     Teachr_rltdnss          -0.306    0.159   -1.925    0.054   -0.293\n#>   Intrinsic_Motivation ~                                              \n#>     Teacher_autnmy           0.862    0.333    2.588    0.010    0.533\n#>     Teacher_cmptnc           0.217    0.198    1.096    0.273    0.134\n#>     Teachr_rltdnss           0.339    0.227    1.494    0.135    0.210\n#>   Intent_to_Quit ~                                                    \n#>     Self_Meaning            -0.123    0.078   -1.580    0.114   -0.115\n#>     Self_Confidenc           0.056    0.072    0.774    0.439    0.050\n#>     Intrinsc_Mtvtn           0.169    0.096    1.764    0.078    0.234\n#>     Teacher_autnmy          -0.790    0.211   -3.752    0.000   -0.676\n#>     Teacher_cmptnc           0.078    0.115    0.676    0.499    0.066\n#>     Teachr_rltdnss          -0.208    0.156   -1.337    0.181   -0.178\n#>   Std.all\n#>          \n#>    -0.036\n#>     0.246\n#>     0.260\n#>          \n#>    -0.092\n#>     0.286\n#>    -0.293\n#>          \n#>     0.533\n#>     0.134\n#>     0.210\n#>          \n#>    -0.115\n#>     0.050\n#>     0.234\n#>    -0.676\n#>     0.066\n#>    -0.178\n#> \n#> Covariances:\n#>                          Estimate  Std.Err  z-value  P(>|z|)   Std.lv\n#>   Teacher_autonomy ~~                                                \n#>     Teacher_cmptnc          0.652    0.067    9.730    0.000    0.652\n#>     Teachr_rltdnss          0.659    0.064   10.287    0.000    0.659\n#>   Teacher_competence ~~                                              \n#>     Teachr_rltdnss          0.545    0.084    6.495    0.000    0.545\n#>  .Self_Meaning ~~                                                    \n#>    .Self_Confidenc          0.195    0.083    2.346    0.019    0.195\n#>    .Intrinsc_Mtvtn          0.071    0.105    0.678    0.498    0.071\n#>  .Self_Confidence ~~                                                 \n#>    .Intrinsc_Mtvtn          0.281    0.116    2.431    0.015    0.281\n#>   Std.all\n#>          \n#>     0.652\n#>     0.659\n#>          \n#>     0.545\n#>          \n#>     0.195\n#>     0.071\n#>          \n#>     0.281\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .T_autonomy1       0.642    0.085    7.529    0.000    0.642    0.388\n#>    .T_autonomy2       0.356    0.093    3.822    0.000    0.356    0.226\n#>    .T_autonomy3       0.399    0.062    6.482    0.000    0.399    0.254\n#>    .T_competence1     0.138    0.115    1.209    0.227    0.138    0.088\n#>    .T_competence2     0.338    0.072    4.723    0.000    0.338    0.210\n#>    .T_competence3     0.766    0.106    7.238    0.000    0.766    0.528\n#>    .T_relatedness1    0.409    0.080    5.113    0.000    0.409    0.239\n#>    .T_relatedness2    0.254    0.161    1.579    0.114    0.254    0.161\n#>    .T_relatedness3    1.363    0.119   11.408    0.000    1.363    0.773\n#>    .S_meaning1        0.600    0.084    7.099    0.000    0.600    0.412\n#>    .S_meaning2        0.274    0.089    3.093    0.002    0.274    0.168\n#>    .S_meaning3        0.231    0.052    4.420    0.000    0.231    0.151\n#>    .S_confidence1     0.593    0.136    4.354    0.000    0.593    0.598\n#>    .S_confidence2     0.218    0.053    4.138    0.000    0.218    0.370\n#>    .S_confidence3     0.232    0.046    4.988    0.000    0.232    0.407\n#>    .S_Intrinsic1      0.855    0.105    8.179    0.000    0.855    0.622\n#>    .S_Intrinsic2      0.772    0.101    7.655    0.000    0.772    0.534\n#>    .S_Intrinsic3      0.528    0.098    5.370    0.000    0.528    0.334\n#>    .Intnt_t_wthdr1    0.133    0.031    4.277    0.000    0.133    0.088\n#>    .Intnt_t_wthdr2    0.253    0.038    6.622    0.000    0.253    0.171\n#>    .Intnt_t_wthdr3    0.432    0.057    7.549    0.000    0.432    0.234\n#>    .Intnt_t_wthdr4    0.936    0.137    6.820    0.000    0.936    0.595\n#>    .Intnt_t_wthdr5    0.836    0.104    8.004    0.000    0.836    0.580\n#>     Teacher_autnmy    1.000                               1.000    1.000\n#>     Teacher_cmptnc    1.000                               1.000    1.000\n#>     Teachr_rltdnss    1.000                               1.000    1.000\n#>    .Self_Meaning      1.000                               0.824    0.824\n#>    .Self_Confidenc    1.000                               0.914    0.914\n#>    .Intrinsc_Mtvtn    1.000                               0.383    0.383\n#>    .Intent_to_Quit    0.786    0.093    8.477    0.000    0.574    0.574\n```\n:::\n\n\n\n\n**Codice lavaan per il modello CFA**\n\nDefiniamo ora il modello CFA.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncfa1 <- ' ## Specify the measurement model\n\n  # \"teacher\" factors\n  Teacher_autonomy    =~    T_autonomy1 +    T_autonomy2 +    T_autonomy3\n  Teacher_competence  =~  T_competence1 +  T_competence2 +  T_competence3\n  Teacher_relatedness =~ T_relatedness1 + T_relatedness2 + T_relatedness3\n\n  # \"self\" factors\n  Self_Meaning         =~    S_meaning1 +    S_meaning2 +    S_meaning3\n  Self_Confidence      =~ S_confidence1 + S_confidence2 + S_confidence3\n  Intrinsic_Motivation =~  S_Intrinsic1 +  S_Intrinsic2 +  S_Intrinsic3\n\n  # defining the outcome variable\n  Intent_to_Quit =~ Intent_to_withdraw1 + Intent_to_withdraw2 + Intent_to_withdraw3 + Intent_to_withdraw4 + Intent_to_withdraw5\n\n  # specify the structural model\n  Self_Meaning ~ Teacher_autonomy + Teacher_competence + Teacher_relatedness\n  Self_Confidence ~ Teacher_autonomy + Teacher_competence + Teacher_relatedness\n  Intrinsic_Motivation ~ Teacher_autonomy + Teacher_competence + Teacher_relatedness\n  Intent_to_Quit ~ Self_Meaning + Self_Confidence + Intrinsic_Motivation +\n                   Teacher_autonomy + Teacher_competence + Teacher_relatedness\n\n  # residual covariances among mediating factors in Block 2 (\"self\")\n  # (not automatically estimated due to being predictors as well,\n  #  but ESEM rotation allows their covariances to be nonzero)\n  Self_Meaning    ~~ Self_Confidence + Intrinsic_Motivation\n  Self_Confidence ~~ Intrinsic_Motivation\n'\n```\n:::\n\n\n\n\nAdattiamo il modello.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit1 <- sem(\n    model = cfa1, data = study1_dat,\n    estimator = \"MLR\", std.lv = TRUE\n)\n```\n:::\n\n\n\n\nCreiamo il diagramma di percorso.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(\n    fit1,\n    what = \"col\", whatLabels = \"no\", style = \"mx\",\n    layout = \"tree\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 6, sizeMan2 = 4\n)\n```\n\n::: {.cell-output-display}\n![](13_esem_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo la soluzione fattoriale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit1, standardized = TRUE, fit.measures = TRUE) |> print()\n#> lavaan 0.6-19 ended normally after 53 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        67\n#> \n#>   Number of observations                           269\n#> \n#> Model Test User Model:\n#>                                               Standard      Scaled\n#>   Test Statistic                               459.107     419.040\n#>   Degrees of freedom                               209         209\n#>   P-value (Chi-square)                           0.000       0.000\n#>   Scaling correction factor                                  1.096\n#>     Yuan-Bentler correction (Mplus variant)                       \n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              4271.294    3518.139\n#>   Degrees of freedom                               253         253\n#>   P-value                                        0.000       0.000\n#>   Scaling correction factor                                  1.214\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.938       0.936\n#>   Tucker-Lewis Index (TLI)                       0.925       0.922\n#>                                                                   \n#>   Robust Comparative Fit Index (CFI)                         0.942\n#>   Robust Tucker-Lewis Index (TLI)                            0.930\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -7925.715   -7925.715\n#>   Scaling correction factor                                  1.439\n#>       for the MLR correction                                      \n#>   Loglikelihood unrestricted model (H1)      -7696.161   -7696.161\n#>   Scaling correction factor                                  1.179\n#>       for the MLR correction                                      \n#>                                                                   \n#>   Akaike (AIC)                               15985.429   15985.429\n#>   Bayesian (BIC)                             16226.275   16226.275\n#>   Sample-size adjusted Bayesian (SABIC)      16013.842   16013.842\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.067       0.061\n#>   90 Percent confidence interval - lower         0.058       0.053\n#>   90 Percent confidence interval - upper         0.075       0.069\n#>   P-value H_0: RMSEA <= 0.050                    0.001       0.013\n#>   P-value H_0: RMSEA >= 0.080                    0.004       0.000\n#>                                                                   \n#>   Robust RMSEA                                               0.064\n#>   90 Percent confidence interval - lower                     0.055\n#>   90 Percent confidence interval - upper                     0.073\n#>   P-value H_0: Robust RMSEA <= 0.050                         0.006\n#>   P-value H_0: Robust RMSEA >= 0.080                         0.001\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.053       0.053\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Sandwich\n#>   Information bread                           Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                           Estimate  Std.Err  z-value  P(>|z|)   Std.lv\n#>   Teacher_autonomy =~                                                 \n#>     T_autonomy1              1.016    0.059   17.270    0.000    1.016\n#>     T_autonomy2              1.066    0.050   21.119    0.000    1.066\n#>     T_autonomy3              1.093    0.046   23.977    0.000    1.093\n#>   Teacher_competence =~                                               \n#>     T_competence1            1.129    0.053   21.180    0.000    1.129\n#>     T_competence2            1.164    0.050   23.337    0.000    1.164\n#>     T_competence3            0.819    0.074   11.027    0.000    0.819\n#>   Teacher_relatedness =~                                              \n#>     T_relatedness1           1.191    0.048   24.632    0.000    1.191\n#>     T_relatedness2           1.053    0.052   20.124    0.000    1.053\n#>     T_relatedness3           0.628    0.089    7.015    0.000    0.628\n#>   Self_Meaning =~                                                     \n#>     S_meaning1               0.839    0.061   13.822    0.000    0.920\n#>     S_meaning2               1.061    0.060   17.603    0.000    1.163\n#>     S_meaning3               1.039    0.058   17.821    0.000    1.139\n#>   Self_Confidence =~                                                  \n#>     S_confidence1            0.582    0.071    8.139    0.000    0.617\n#>     S_confidence2            0.578    0.057   10.172    0.000    0.612\n#>     S_confidence3            0.538    0.066    8.172    0.000    0.570\n#>   Intrinsic_Motivation =~                                             \n#>     S_Intrinsic1             0.443    0.050    8.881    0.000    0.719\n#>     S_Intrinsic2             0.501    0.074    6.773    0.000    0.812\n#>     S_Intrinsic3             0.634    0.069    9.250    0.000    1.028\n#>   Intent_to_Quit =~                                                   \n#>     Intnt_t_wthdr1           0.893    0.050   17.918    0.000    1.171\n#>     Intnt_t_wthdr2           0.844    0.048   17.608    0.000    1.107\n#>     Intnt_t_wthdr3           0.907    0.053   17.267    0.000    1.189\n#>     Intnt_t_wthdr4           0.608    0.069    8.834    0.000    0.798\n#>     Intnt_t_wthdr5           0.593    0.055   10.801    0.000    0.778\n#>   Std.all\n#>          \n#>     0.790\n#>     0.850\n#>     0.871\n#>          \n#>     0.900\n#>     0.918\n#>     0.681\n#>          \n#>     0.911\n#>     0.840\n#>     0.473\n#>          \n#>     0.763\n#>     0.911\n#>     0.922\n#>          \n#>     0.619\n#>     0.798\n#>     0.756\n#>          \n#>     0.614\n#>     0.675\n#>     0.817\n#>          \n#>     0.956\n#>     0.910\n#>     0.875\n#>     0.636\n#>     0.648\n#> \n#> Regressions:\n#>                          Estimate  Std.Err  z-value  P(>|z|)   Std.lv\n#>   Self_Meaning ~                                                     \n#>     Teacher_autnmy         -0.170    0.192   -0.882    0.378   -0.155\n#>     Teacher_cmptnc          0.335    0.160    2.096    0.036    0.305\n#>     Teachr_rltdnss          0.308    0.157    1.963    0.050    0.281\n#>   Self_Confidence ~                                                  \n#>     Teacher_autnmy         -0.080    0.158   -0.511    0.610   -0.076\n#>     Teacher_cmptnc          0.437    0.134    3.251    0.001    0.412\n#>     Teachr_rltdnss         -0.403    0.160   -2.526    0.012   -0.380\n#>   Intrinsic_Motivation ~                                             \n#>     Teacher_autnmy          0.886    0.283    3.131    0.002    0.546\n#>     Teacher_cmptnc          0.128    0.192    0.666    0.505    0.079\n#>     Teachr_rltdnss          0.342    0.213    1.606    0.108    0.211\n#>   Intent_to_Quit ~                                                   \n#>     Self_Meaning           -0.151    0.087   -1.731    0.083   -0.126\n#>     Self_Confidenc          0.051    0.085    0.596    0.551    0.041\n#>     Intrinsc_Mtvtn          0.197    0.109    1.804    0.071    0.244\n#>     Teacher_autnmy         -0.899    0.267   -3.368    0.001   -0.686\n#>     Teacher_cmptnc          0.155    0.143    1.083    0.279    0.118\n#>     Teachr_rltdnss         -0.259    0.191   -1.356    0.175   -0.197\n#>   Std.all\n#>          \n#>    -0.155\n#>     0.305\n#>     0.281\n#>          \n#>    -0.076\n#>     0.412\n#>    -0.380\n#>          \n#>     0.546\n#>     0.079\n#>     0.211\n#>          \n#>    -0.126\n#>     0.041\n#>     0.244\n#>    -0.686\n#>     0.118\n#>    -0.197\n#> \n#> Covariances:\n#>                         Estimate  Std.Err  z-value  P(>|z|)   Std.lv\n#>  .Self_Meaning ~~                                                   \n#>    .Self_Confidenc         0.241    0.081    2.970    0.003    0.241\n#>    .Intrinsc_Mtvtn         0.093    0.106    0.876    0.381    0.093\n#>  .Self_Confidence ~~                                                \n#>    .Intrinsc_Mtvtn         0.334    0.119    2.801    0.005    0.334\n#>   Teacher_autonomy ~~                                               \n#>     Teacher_cmptnc         0.765    0.044   17.327    0.000    0.765\n#>     Teachr_rltdnss         0.798    0.042   18.935    0.000    0.798\n#>   Teacher_competence ~~                                             \n#>     Teachr_rltdnss         0.662    0.049   13.510    0.000    0.662\n#>   Std.all\n#>          \n#>     0.241\n#>     0.093\n#>          \n#>     0.334\n#>          \n#>     0.765\n#>     0.798\n#>          \n#>     0.662\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .T_autonomy1       0.623    0.086    7.243    0.000    0.623    0.376\n#>    .T_autonomy2       0.435    0.063    6.871    0.000    0.435    0.277\n#>    .T_autonomy3       0.380    0.062    6.153    0.000    0.380    0.241\n#>    .T_competence1     0.301    0.063    4.791    0.000    0.301    0.191\n#>    .T_competence2     0.254    0.058    4.380    0.000    0.254    0.158\n#>    .T_competence3     0.778    0.116    6.726    0.000    0.778    0.537\n#>    .T_relatedness1    0.291    0.077    3.752    0.000    0.291    0.170\n#>    .T_relatedness2    0.464    0.066    7.012    0.000    0.464    0.295\n#>    .T_relatedness3    1.369    0.121   11.283    0.000    1.369    0.777\n#>    .S_meaning1        0.608    0.088    6.906    0.000    0.608    0.418\n#>    .S_meaning2        0.278    0.089    3.115    0.002    0.278    0.171\n#>    .S_meaning3        0.230    0.052    4.434    0.000    0.230    0.151\n#>    .S_confidence1     0.612    0.139    4.413    0.000    0.612    0.616\n#>    .S_confidence2     0.214    0.055    3.893    0.000    0.214    0.363\n#>    .S_confidence3     0.244    0.049    4.982    0.000    0.244    0.429\n#>    .S_Intrinsic1      0.857    0.105    8.146    0.000    0.857    0.624\n#>    .S_Intrinsic2      0.786    0.108    7.292    0.000    0.786    0.544\n#>    .S_Intrinsic3      0.528    0.090    5.836    0.000    0.528    0.333\n#>    .Intnt_t_wthdr1    0.130    0.031    4.223    0.000    0.130    0.087\n#>    .Intnt_t_wthdr2    0.254    0.038    6.685    0.000    0.254    0.172\n#>    .Intnt_t_wthdr3    0.433    0.057    7.569    0.000    0.433    0.235\n#>    .Intnt_t_wthdr4    0.937    0.137    6.830    0.000    0.937    0.595\n#>    .Intnt_t_wthdr5    0.836    0.104    8.005    0.000    0.836    0.580\n#>     Teacher_autnmy    1.000                               1.000    1.000\n#>     Teacher_cmptnc    1.000                               1.000    1.000\n#>     Teachr_rltdnss    1.000                               1.000    1.000\n#>    .Self_Meaning      1.000                               0.832    0.832\n#>    .Self_Confidenc    1.000                               0.889    0.889\n#>    .Intrinsc_Mtvtn    1.000                               0.380    0.380\n#>    .Intent_to_Quit    1.000                               0.582    0.582\n```\n:::\n\n\n\n\n**Confronto tra modelli**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Extract model fit statistics from out1 and fit1\nfit_stats_out1 <- fitMeasures(out1, c(\"chisq\", \"df\", \"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\", \"cfi\", \"tli\"))\nfit_stats_fit1 <- fitMeasures(fit1, c(\"chisq\", \"df\", \"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\", \"cfi\", \"tli\"))\n\n# Create a tibble with the extracted fit statistics\nfit_table <- tibble(\n    Model = c(\"CFA-based model\", \"Set-ESEM-based model\"),\n    chisq = c(fit_stats_fit1[\"chisq\"], fit_stats_out1[\"chisq\"]),\n    df = c(fit_stats_fit1[\"df\"], fit_stats_out1[\"df\"]),\n    RMSEA = c(fit_stats_fit1[\"rmsea\"], fit_stats_out1[\"rmsea\"]),\n    `RMSEA 90% CI` = c(\n        sprintf(\"(%.3f, %.3f)\", fit_stats_fit1[\"rmsea.ci.lower\"], fit_stats_fit1[\"rmsea.ci.upper\"]),\n        sprintf(\"(%.3f, %.3f)\", fit_stats_out1[\"rmsea.ci.lower\"], fit_stats_out1[\"rmsea.ci.upper\"])\n    ),\n    CFI = c(fit_stats_fit1[\"cfi\"], fit_stats_out1[\"cfi\"]),\n    TLI = c(fit_stats_fit1[\"tli\"], fit_stats_out1[\"tli\"])\n)\n\n# Convert numeric columns to formatted strings with three decimal places\nfit_table <- fit_table %>%\n    mutate(\n        across(where(is.numeric), ~ sprintf(\"%.3f\", .)),\n        chisq = sprintf(\"%.3f\", as.numeric(chisq)), # Ensure chisq is formatted correctly\n        df = as.character(df) # Convert df to character for consistent formatting\n    )\n\n# Calculate column widths for alignment\ncol_widths <- fit_table %>%\n    summarise(across(everything(), ~ max(nchar(.), na.rm = TRUE)))\n\n# Create text-based table output\nheader <- paste(\n    str_pad(\"Model\", col_widths$Model, side = \"right\"),\n    str_pad(\"chisq\", col_widths$chisq, side = \"right\"),\n    str_pad(\"df\", col_widths$df, side = \"right\"),\n    str_pad(\"RMSEA\", col_widths$RMSEA, side = \"right\"),\n    str_pad(\"RMSEA 90% CI\", col_widths$`RMSEA 90% CI`, side = \"right\"),\n    str_pad(\"CFI\", col_widths$CFI, side = \"right\"),\n    str_pad(\"TLI\", col_widths$TLI, side = \"right\"),\n    sep = \" | \"\n)\nseparator <- strrep(\"-\", nchar(header))\n\n# Print header and separator\ncat(header, \"\\n\")\n#> Model                | chisq   | df      | RMSEA | RMSEA 90% CI   | CFI   | TLI\ncat(separator, \"\\n\")\n#> ---------------------------------------------------------------------------------\n\n# Print each row formatted with aligned columns\nfit_table %>%\n    mutate(\n        Model = str_pad(Model, col_widths$Model, side = \"right\"),\n        chisq = str_pad(chisq, col_widths$chisq, side = \"right\"),\n        df = str_pad(df, col_widths$df, side = \"right\"),\n        RMSEA = str_pad(RMSEA, col_widths$RMSEA, side = \"right\"),\n        `RMSEA 90% CI` = str_pad(`RMSEA 90% CI`, col_widths$`RMSEA 90% CI`, side = \"right\"),\n        CFI = str_pad(CFI, col_widths$CFI, side = \"right\"),\n        TLI = str_pad(TLI, col_widths$TLI, side = \"right\")\n    ) %>%\n    rowwise() %>%\n    mutate(row_text = paste(Model, chisq, df, RMSEA, `RMSEA 90% CI`, CFI, TLI, sep = \" | \")) %>%\n    pull(row_text) %>%\n    cat(sep = \"\\n\")\n#> CFA-based model      | 459.107 | 209.000 | 0.067 | (0.058, 0.075) | 0.938 | 0.925\n#> Set-ESEM-based model | 396.932 | 185.000 | 0.065 | (0.056, 0.074) | 0.947 | 0.928\n```\n:::\n\n\n\n\nPer stimare i modelli, @marsh2024and utilizzano la versione robusta della massima verosimiglianza (MLR), che garantisce stime robuste rispetto a deviazioni dalla normalità multivariata (Yuan & Bentler, 2000). Per valutare la qualità dei modelli, sono presi in considerazione diversi indicatori di adattamento: il chi-quadro robusto (χ²) con i relativi gradi di libertà e valore *p*, il Comparative Fit Index (CFI), il Tucker-Lewis Index (TLI), e il Root Mean Square Error of Approximation (RMSEA) con il suo intervallo di confidenza al 90%. Coerentemente con l'approccio MLR, i valori di CFI, TLI e RMSEA riportati nei due esempi sono calcolati nella loro versione robusta.\n\nI risultati presentati nella tabella precedente indicano che sia il modello strutturale basato su CFA sia quello basato su set-ESEM mostrano un buon adattamento ai dati. Tuttavia, @marsh2024and si concentrano principalmente sulle differenze nelle relazioni strutturali tra i due modelli, tralasciando un'analisi dettagliata delle specifiche del modello di misura.\n\n### Miglior adattamento del set-ESEM\n\nLa Tabella 2 dell'articolo di @marsh2024and riporta i coefficienti di percorso per entrambi i modelli. Sebbene entrambi mostrino un adattamento accettabile, il modello set-ESEM si distingue per un adattamento superiore. Questo è evidenziato da un incremento di +0.01 nei valori di TLI e CFI rispetto al modello CFA. Anche i criteri informativi confermano il vantaggio del set-ESEM:\n\n- **CFA**: AIC = 15985.43, BIC = 16226.27, BIC corretto = 16013.84.\n- **Set-ESEM**: AIC = 15971.25, BIC = 16298.37, BIC corretto = 16009.84.\n\nValori più bassi di AIC e BIC indicano un miglior adattamento complessivo per il modello set-ESEM.\n\n### Riduzione delle correlazioni sovrastimate\n\nUn noto limite del CFA è la tendenza a sovrastimare le correlazioni tra variabili latenti esogene, il che può aumentare il rischio di collinearità e compromettere l'accuratezza dei parametri stimati (Shao et al., 2022). Il set-ESEM riduce notevolmente questo problema. Ad esempio:\n\n- La correlazione tra *Autonomia_Insegnante* e *Relazionalità_Insegnante* nel modello CFA è di .80, mentre nel set-ESEM scende a .51 (Δr = .29).\n\nQuesta riduzione migliora la validità discriminante e garantisce stime più attendibili.\n\n### Sensibilità ai percorsi significativi\n\nIl set-ESEM dimostra una maggiore capacità di rilevare percorsi significativi rispetto al CFA. Due esempi illustrativi includono:\n\n- Il percorso *Competenza_Insegnante → Motivazione_Intrinseca* è non significativo nel CFA (β = .08, *p* = .51), ma diventa significativo nel set-ESEM (β = .19, *p* = .03).\n- Il percorso *Relazionalità_Insegnante → Intenzione_di_Ritiro* è non significativo nel CFA (β = −.20, *p* = .18), ma significativo nel set-ESEM (β = −.28, *p* = .01).\n\nQuesti risultati dimostrano come il set-ESEM possa rivelare relazioni importanti tra variabili latenti che il CFA potrebbe non individuare.\n\nIn conclusione, i risultati evidenziano che i modelli CFA e set-ESEM possono portare a interpretazioni diverse sulle relazioni tra variabili latenti. Tuttavia, il miglior adattamento del set-ESEM, unito alla riduzione delle correlazioni spurie e a una maggiore sensibilità ai percorsi significativi, suggerisce che i coefficienti stimati con questo approccio siano più affidabili. In contesti analitici complessi, il set-ESEM si dimostra un'opzione preferibile, garantendo un equilibrio ottimale tra flessibilità, parsimonia e validità delle stime.\n\n\n<!-- ## Studio 2: Utilizzo del set-ESEM per valutare modelli longitudinali -->\n\n<!-- Lo Studio 2 di @marsh2024and illustra un secondo scenario, in cui il ricercatore dispone di costrutti raccolti in momenti temporali differenti. In questo esempio, sono stati misurati tre costrutti in due tempi diversi. I primi due costrutti, autonomia e motivazione intrinseca, sono stati descritti nello Studio 1 e derivano dalla teoria dell’autodeterminazione (Ryan & Deci, 2017). Il terzo costrutto è l’autoefficacia, che riflette la convinzione degli studenti circa la propria capacità di ottenere risultati desiderati e prevenire quelli dannosi (Woodrow, 2006). La ricerca suggerisce che questi tre fattori (autonomia, motivazione intrinseca e autoefficacia) agiscono collettivamente come motivazioni parallele che favoriscono risultati positivi (Alamer et al., 2023; Noels, 2023; Ryan & Deci, 2017). -->\n\n<!-- Un modello che stima i costrutti al tempo 1 per prevedere i corrispondenti al tempo 2 (controllando la stabilità della misura nel tempo) e che valuta anche il loro effetto sulla variabile di esito può essere meglio analizzato con il set-ESEM piuttosto che con il full-ESEM (Marsh et al., 2020). Nei modelli longitudinali SEM, è spesso necessario correlare le unicità dello stesso item nel tempo (Marsh & Hau, 1996). Inoltre, il ricercatore può voler applicare l’invarianza di misura per garantire la stabilità della misura nel tempo, imponendo vincoli di uguaglianza longitudinale sui carichi fattoriali, possibile con il codice in formato long per il set-ESEM in lavaan. -->\n\n<!-- Ecco un esempio di vincoli di uguaglianza sui quattro item di self-confidence nei due tempi. Le etichette a*, b*, c* e d* indicano vincoli di uguaglianza sui carichi primari: lo stesso item ha la stessa etichetta nei due tempi. Parametri con la stessa etichetta sono stimati come uguali. Seguendo la prassi CFA per l’invarianza di misura, bisogna impostare la scala latente per un gruppo di riferimento o occasione (qui, il tempo 1), lasciando liberi i restanti. Il valore mancante, NA*, libera la varianza del fattore al tempo 2. In lavaan, per preservare i vincoli di uguaglianza tra blocchi in una soluzione ruotata, è necessario equare tutti i carichi, affinché il blocco del tempo 2 rispecchi quello del tempo 1. Sebbene vincoli di parziale invarianza siano più realistici, essi non sarebbero mantenuti in una soluzione ruotata. -->\n\n<!-- Ecco un esempio di sintassi per gli item di self-confidence: -->\n\n<!-- ```R -->\n<!-- efa(\"time1\")*SelfConfidenceT1 =~ a*SelfConf1T1 + b*SelfConf2T1 + -->\n<!-- c*SelfConf3T1 + d*SelfConf4T1 + e*Intr1T1 + f*Intr2T1 + g*Intr3T1 + -->\n<!-- h*Auton1T1 + i*Auton2T1 + j*Auton3T1 + k*Auton4T1 -->\n<!-- efa(\"time2\")*SelfConfidenceT2 =~ a*SelfConf1T2 + b*SelfConf2T2 + -->\n<!-- c*SelfConf3T2 + d*SelfConf4T2 + e*Intr1T2 + f*Intr2T2 + g*Intr3T2 + -->\n<!-- h*Auton1T2 + i*Auton2T2 + j*Auton3T2 + k*Auton4T2 -->\n<!-- ## liberazione della varianza del fattore al Tempo 2 -->\n<!-- SelfConfidenceT2 ~~ NA*SelfConfidenceT2 -->\n<!-- ``` -->\n\n<!-- L’utilizzo dell’invarianza di misura nel set-ESEM permette di ridurre la soluzione a un singolo blocco ESEM, più parsimonioso e spesso vantaggioso per l’analisi longitudinale. Tuttavia, per mantenere il focus sulle applicazioni standard del CFA e del set-ESEM, riportiamo solo gli indici di adattamento dei modelli con invarianza di misura senza discutere i coefficienti di percorso. Forniamo comunque la sintassi R nel repository OSF per consentire ai lettori di riprodurre i risultati completi. -->\n\n<!-- Per testare un modello longitudinale set-ESEM, @marsh2024and stimano solo i cross-loading tra i fattori nello stesso tempo. Ad esempio, gli item del tempo 1 per autonomia, motivazione intrinseca e autoefficacia hanno cross-loading sui fattori del tempo 1, ma non su quelli del tempo 2. Allo stesso modo, gli item del tempo 2 hanno cross-loading sui fattori del tempo 2, ma non su quelli del tempo 1. Si noti che le correlazioni tra le unicità dello stesso item nei due tempi sono stimate ma non visualizzate in figura per semplicità (solo un esempio di correlazione tra unicità è mostrato tra Aut1 e Aut1T2). -->\n\n<!-- **Misure** -->\n\n<!-- Per valutare l'autonomia, sono stati utilizzati quattro item della scala BPN-L2 già descritta in precedenza. Un esempio di item è stato presentato nello Studio 1. La motivazione intrinseca è stata misurata con tre item della scala SDT-L2 (Alamer, 2022). La self-confidence (fiducia in sé stessi) è stata valutata tramite quattro item adottati da Dörnyei e Ushioda (2021; vedi anche Dörnyei & Ryan, 2015), come descritto nello Studio 1. Le misurazioni si basano su una scala Likert a cinque punti, con risposte da 1 (fortemente in disaccordo) a 5 (fortemente d'accordo). -->\n\n<!-- Il livello di competenza linguistica è stato misurato tramite un test di collocamento in inglese come seconda lingua. Il test include item sulle quattro abilità principali: vocabolario, grammatica, lettura e scrittura. È stato sviluppato consultando il corso di lingua Unlock, ideato dall'Università di Cambridge (Ostrowska et al., 2021). Sebbene il formato del test possa variare, consiste principalmente in domande a scelta multipla e in esercizi di completamento. Un campione simulato è incluso nel repository OSF. Il punteggio totale del test va da 0 a 20, con una media di 14.2 e una deviazione standard di 4.7. -->\n\n<!-- ::: {#fig-esem-study2} -->\n<!-- ![](../../figures/esem_study2.png){width=\"90%\"} -->\n<!-- Un modello longitudinale basato su CFA (modello A) e un modello longitudinale set-ESEM (modello B).  Nota: le linee tratteggiate indicano i carichi incrociati non target. [Figura tratta da @marsh2024and] -->\n<!-- ::: -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- study2_dat <- rio::import( -->\n<!--     here::here( -->\n<!--         \"data\", \"marsh_alamer\", \"Study_2_data.csv\" -->\n<!--     ) -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- esem2_config <- ' -->\n\n<!--   # The measurement model -->\n<!--   # WITHOUT equality constraints on factor loadings -->\n\n<!--   # Time 1 Set-ESEM -->\n<!--   efa(\"time1\")*SelfConfidenceT1 =~ SelfConf1T1 + SelfConf2T1 + SelfConf3T1 + SelfConf4T1 + Intr1T1 + Intr2T1 + Intr3T1 + Auton1T1 + Auton2T1 + Auton3T1 + Auton4T1 -->\n<!--   efa(\"time1\")*IntrinsicT1 =~ SelfConf1T1 + SelfConf2T1 + SelfConf3T1 + SelfConf4T1 + Intr1T1 + Intr2T1 + Intr3T1 + Auton1T1 + Auton2T1 + Auton3T1 + Auton4T1 -->\n<!--   efa(\"time1\")*AutonomyT1 =~ SelfConf1T1 + SelfConf2T1 + SelfConf3T1 + SelfConf4T1 + Intr1T1 + Intr2T1 + Intr3T1 + Auton1T1 + Auton2T1 + Auton3T1 + Auton4T1 -->\n\n<!--   # Time 2 Set-ESEM -->\n<!--   efa(\"time2\")*SelfConfidenceT2 =~ SelfConf1T2 + SelfConf2T2 + SelfConf3T2 + SelfConf4T2 + Intr1T2 + Intr2T2 + Intr3T2 + Auton1T2 + Auton2T2 + Auton3T2 + Auton4T2 -->\n<!--   efa(\"time2\")*IntrinsicT2 =~ SelfConf1T2 + SelfConf2T2 + SelfConf3T2 + SelfConf4T2 + Intr1T2 + Intr2T2 + Intr3T2 + Auton1T2 + Auton2T2 + Auton3T2 + Auton4T2 -->\n<!--   efa(\"time2\")*AutonomyT2 =~ SelfConf1T2 + SelfConf2T2 + SelfConf3T2 + SelfConf4T2 + Intr1T2 + Intr2T2 + Intr3T2 + Auton1T2 + Auton2T2 + Auton3T2 + Auton4T2 -->\n\n<!--   # The structural model -->\n<!--   SelfConfidenceT2 ~ SelfConfidenceT1 -->\n<!--   IntrinsicT2 ~ IntrinsicT1 -->\n<!--   AutonomyT2 ~ AutonomyT1 -->\n<!--   L2_achievement ~ SelfConfidenceT1 + IntrinsicT1 + AutonomyT1 + SelfConfidenceT2 + IntrinsicT2 + AutonomyT2 -->\n\n<!--   # Residual correlations -->\n<!--   SelfConf1T2 ~~ SelfConf1T1 -->\n<!--   SelfConf2T2 ~~ SelfConf2T1 -->\n<!--   SelfConf3T2 ~~ SelfConf3T1 -->\n<!--   SelfConf4T2 ~~SelfConf4T1 -->\n\n<!--   Auton1T2 ~~ Auton1T1 -->\n<!--   Auton2T2 ~~ Auton2T1 -->\n<!--   Auton3T2 ~~ Auton3T1 -->\n<!--   Auton4T2 ~~ Auton4T1 -->\n\n<!--   Intr1T2 ~~ Intr1T1 -->\n<!--   Intr2T2 ~~ Intr2T1 -->\n<!--   Intr3T2 ~~ Intr3T1 -->\n<!-- ' -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- out2_config <- sem( -->\n<!--     model = esem2_config, -->\n<!--     data = study2_dat, -->\n<!--     estimator = \"MLR\", # verbose = TRUE, -->\n<!--     rotation = \"geomin\", -->\n<!--     rotation.args = list(geomin.epsilon = 0.005) -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- esem2_metric <- ' -->\n\n<!--   # The measurement model -->\n<!--   # WITH equality constraints on factor loadings -->\n\n<!--   # Time 1 Set-ESEM -->\n<!--   efa(\"time1\")*SelfConfidenceT1 =~ a*SelfConf1T1 + b*SelfConf2T1 + c*SelfConf3T1 + d*SelfConf4T1 + e*Intr1T1 + f*Intr2T1 + g*Intr3T1 + h*Auton1T1 + i*Auton2T1 + j*Auton3T1 + k*Auton4T1 -->\n<!--   efa(\"time1\")*IntrinsicT1 =~ aa*SelfConf1T1 + bb*SelfConf2T1 + cc*SelfConf3T1 + dd*SelfConf4T1 + ee*Intr1T1 + ff*Intr2T1 + gg*Intr3T1 + hh*Auton1T1 + ii*Auton2T1 + jj*Auton3T1 + kk*Auton4T1 -->\n<!--   efa(\"time1\")*AutonomyT1 =~ aaa*SelfConf1T1 + bbb*SelfConf2T1 + ccc*SelfConf3T1 + ddd*SelfConf4T1 + eee*Intr1T1 + fff*Intr2T1 + ggg*Intr3T1 + hhh*Auton1T1 + iii*Auton2T1 + jjj*Auton3T1 + kkk*Auton4T1 -->\n\n<!--   # Time 2 Set-ESEM -->\n<!--   efa(\"time2\")*SelfConfidenceT2 =~ a*SelfConf1T2 + b*SelfConf2T2 + c*SelfConf3T2 + d*SelfConf4T2 + e*Intr1T2 + f*Intr2T2 + g*Intr3T2 + h*Auton1T2 + i*Auton2T2 + j*Auton3T2 + k*Auton4T2 -->\n<!--   efa(\"time2\")*IntrinsicT2 =~ aa*SelfConf1T2 + bb*SelfConf2T2 + cc*SelfConf3T2 + dd*SelfConf4T2 + ee*Intr1T2 + ff*Intr2T2 + gg*Intr3T2 + hh*Auton1T2 + ii*Auton2T2 + jj*Auton3T2 + kk*Auton4T2 -->\n<!--   efa(\"time2\")*AutonomyT2 =~ aaa*SelfConf1T2 + bbb*SelfConf2T2 + ccc*SelfConf3T2 + ddd*SelfConf4T2 + eee*Intr1T2 + fff*Intr2T2 + ggg*Intr3T2 + hhh*Auton1T2 + iii*Auton2T2 + jjj*Auton3T2 + kkk*Auton4T2 -->\n\n<!--   # Free factors variances at Time 2 -->\n<!--   SelfConfidenceT2 ~~ NA*SelfConfidenceT2 -->\n<!--   IntrinsicT2 ~~ NA*IntrinsicT2 -->\n<!--   AutonomyT2 ~~ NA*AutonomyT2 -->\n\n<!--   # The structural model -->\n<!--   SelfConfidenceT2 ~ SelfConfidenceT1 -->\n<!--   IntrinsicT2 ~ IntrinsicT1 -->\n<!--   AutonomyT2 ~ AutonomyT1 -->\n<!--   L2_achievement ~ SelfConfidenceT1 + IntrinsicT1 + AutonomyT1 + SelfConfidenceT2 + IntrinsicT2 + AutonomyT2 -->\n\n<!--   # Residual correlations -->\n<!--   SelfConf1T2 ~~ SelfConf1T1 -->\n<!--   SelfConf2T2 ~~ SelfConf2T1 -->\n<!--   SelfConf3T2 ~~ SelfConf3T1 -->\n<!--   SelfConf4T2 ~~SelfConf4T1 -->\n\n<!--   Auton1T2 ~~ Auton1T1 -->\n<!--   Auton2T2 ~~ Auton2T1 -->\n<!--   Auton3T2 ~~ Auton3T1 -->\n<!--   Auton4T2 ~~ Auton4T1 -->\n\n<!--   Intr1T2 ~~ Intr1T1 -->\n<!--   Intr2T2 ~~ Intr2T1 -->\n<!--   Intr3T2 ~~ Intr3T1 -->\n\n<!-- ' -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- out2_metric <- sem( -->\n<!--     model = esem2_metric, data = study2_dat, -->\n<!--     estimator = \"MLR\", # verbose = TRUE, -->\n<!--     rotation = \"geomin\", rotation.args = list(geomin.epsilon = 0.005) -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- lavTestLRT(out2_config, out2_metric) -->\n<!-- ``` -->\n\n<!-- @marsh2024and considerano anche i corrispondenti modelli CFA, senza invarianza di misurazione e con invarianza di misurazione. -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- cfa2_config <- \" -->\n\n<!--   # The measurement model -->\n<!--   # WITHOUT equality constraints on factor loadings -->\n\n<!--   # Time 1 Set-ESEM -->\n<!--   SelfConfidenceT1 =~ SelfConf1T1 + SelfConf2T1 + SelfConf3T1 + SelfConf4T1 -->\n<!--   IntrinsicT1      =~     Intr1T1 +     Intr2T1 +     Intr3T1 -->\n<!--   AutonomyT1       =~    Auton1T1 +    Auton2T1 +    Auton3T1 +    Auton4T1 -->\n\n<!--   # Time 2 Set-ESEM -->\n<!--   SelfConfidenceT2 =~ SelfConf1T2 + SelfConf2T2 + SelfConf3T2 + SelfConf4T2 -->\n<!--   IntrinsicT2      =~     Intr1T2 +     Intr2T2 +     Intr3T2 -->\n<!--   AutonomyT2       =~    Auton1T2 +    Auton2T2 +    Auton3T2 +    Auton4T2 -->\n\n<!--   ## The structural model -->\n<!--   SelfConfidenceT2 ~ SelfConfidenceT1 -->\n<!--   IntrinsicT2 ~ IntrinsicT1 -->\n<!--   AutonomyT2 ~ AutonomyT1 -->\n<!--   L2_achievement ~ SelfConfidenceT1 + IntrinsicT1 + AutonomyT1 + SelfConfidenceT2 + IntrinsicT2 + AutonomyT2 -->\n\n<!--   # Residual correlations -->\n<!--   SelfConf1T2 ~~ SelfConf1T1 -->\n<!--   SelfConf2T2 ~~ SelfConf2T1 -->\n<!--   SelfConf3T2 ~~ SelfConf3T1 -->\n<!--   SelfConf4T2 ~~SelfConf4T1 -->\n\n<!--   Auton1T2 ~~ Auton1T1 -->\n<!--   Auton2T2 ~~ Auton2T1 -->\n<!--   Auton3T2 ~~ Auton3T1 -->\n<!--   Auton4T2 ~~ Auton4T1 -->\n\n<!--   Intr1T2 ~~ Intr1T1 -->\n<!--   Intr2T2 ~~ Intr2T1 -->\n<!--   Intr3T2 ~~ Intr3T1 -->\n\n<!--   # Residual correlations among Time-2 factors -->\n<!--   # (not automatically estimated due to being predictors as well, -->\n<!--   #  but ESEM rotation allows their covariances to be nonzero) -->\n<!--   SelfConfidenceT2 ~~ IntrinsicT2 + AutonomyT2 -->\n<!--   IntrinsicT2      ~~ AutonomyT2 -->\n\n<!-- \" -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- fit2_config <- sem( -->\n<!--     model = cfa2_config, -->\n<!--     data = study2_dat, -->\n<!--     estimator = \"MLR\", -->\n<!--     std.lv = TRUE -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- cfa2_metric <- \" -->\n\n<!--   # The measurement model -->\n<!--   # WITHOUT equality constraints on factor loadings -->\n\n<!--   # Time 1 Set-ESEM -->\n<!--   SelfConfidenceT1 =~ a*SelfConf1T1 + b*SelfConf2T1 + c*SelfConf3T1 + d*SelfConf4T1 -->\n<!--   IntrinsicT1      =~     e*Intr1T1 +     f*Intr2T1 +     g*Intr3T1 -->\n<!--   AutonomyT1       =~    h*Auton1T1 +    i*Auton2T1 +    j*Auton3T1 +    k*Auton4T1 -->\n\n<!--   # Time 2 Set-ESEM -->\n<!--   SelfConfidenceT2 =~ a*SelfConf1T2 + b*SelfConf2T2 + c*SelfConf3T2 + d*SelfConf4T2 -->\n<!--   IntrinsicT2      =~     e*Intr1T2 +     f*Intr2T2 +     g*Intr3T2 -->\n<!--   AutonomyT2       =~    h*Auton1T2 +    i*Auton2T2 +    j*Auton3T2 +    k*Auton4T2 -->\n\n<!--   # Free factors variances at Time 2 -->\n<!--   SelfConfidenceT2 ~~ NA*SelfConfidenceT2 -->\n<!--   IntrinsicT2 ~~ NA*IntrinsicT2 -->\n<!--   AutonomyT2 ~~ NA*AutonomyT2 -->\n\n<!--   # The structural model -->\n<!--   SelfConfidenceT2 ~ SelfConfidenceT1 -->\n<!--   IntrinsicT2 ~ IntrinsicT1 -->\n<!--   AutonomyT2 ~ AutonomyT1 -->\n<!--   L2_achievement ~ SelfConfidenceT1 + IntrinsicT1 + AutonomyT1 + SelfConfidenceT2 + IntrinsicT2 + AutonomyT2 -->\n\n<!--   # Residual correlations -->\n<!--   SelfConf1T2 ~~ SelfConf1T1 -->\n<!--   SelfConf2T2 ~~ SelfConf2T1 -->\n<!--   SelfConf3T2 ~~ SelfConf3T1 -->\n<!--   SelfConf4T2 ~~SelfConf4T1 -->\n\n<!--   Auton1T2 ~~ Auton1T1 -->\n<!--   Auton2T2 ~~ Auton2T1 -->\n<!--   Auton3T2 ~~ Auton3T1 -->\n<!--   Auton4T2 ~~ Auton4T1 -->\n\n<!--   Intr1T2 ~~ Intr1T1 -->\n<!--   Intr2T2 ~~ Intr2T1 -->\n<!--   Intr3T2 ~~ Intr3T1 -->\n\n<!--   # Residual correlations among Time-2 factors -->\n<!--   # (not automatically estimated due to being predictors as well, -->\n<!--   #  but ESEM rotation allows their covariances to be nonzero) -->\n<!--   SelfConfidenceT2 ~~ IntrinsicT2 + AutonomyT2 -->\n<!--   IntrinsicT2      ~~ AutonomyT2 -->\n\n<!-- \" -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- fit2_metric <- sem( -->\n<!--     model = cfa2_metric, -->\n<!--     data = study2_dat, -->\n<!--     estimator = \"MLR\", -->\n<!--     std.lv = TRUE -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- lavTestLRT(fit2_config, fit2_metric) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| vscode: {languageId: r} -->\n<!-- summary(fit2_metric, standardized = TRUE, fit.measures = TRUE) |> print() -->\n<!-- ``` -->\n\n<!-- **Risultati** -->\n\n<!-- **Stima dei modelli strutturali set-ESEM e CFA** -->\n\n<!-- @marsh2024and stimano i modelli strutturali basati su set-ESEM e CFA usando l'MLR. I risultati dei due modelli sono riportati nella Tabella 3 e indicano che entrambi offrono un buon adattamento ai dati. Si noti che questi risultati si riferiscono ai modelli con invarianza metrica, poiché essi hanno mostrato un adattamento simile ai modelli configurali. Tuttavia, il modello set-ESEM ha mostrato un adattamento migliore ai dati (ΔTLI/CFI = +.01). Gli indici AIC, BIC e BIC corretto per la dimensione del campione per il modello CFA sono rispettivamente 23,782.68, 24,034.45 e 23,834.55, mentre per il modello ESEM sono 23,764.25, 24,067.98 e 23,826.82. Valori più bassi di AIC e BIC corretto nel modello ESEM indicano un adattamento migliore di questo modello. -->\n\n<!-- Come mostrato nella Tabella 4, le correlazioni tra i fattori esogeni sono notevolmente più basse nel modello strutturale set-ESEM rispetto al modello CFA. Ad esempio, la correlazione tra Self_Confidence_T1 e Autonomy_T1 è 0.55 nel modello CFA, ma solo 0.29 nel modello set-ESEM (Δr = .26). Questi valori di correlazione più bassi influenzano la predizione degli effetti nel modello strutturale, come spiegato di seguito. In particolare, alcuni coefficienti di percorso differiscono in dimensione e valore di p tra i due modelli. -->\n\n<!-- **TABELLA 3: Indici di adattamento per i modelli longitudinali CFA e set-ESEM** -->\n<!-- \\*Significativo a p < .01. -->\n\n<!-- | Modello                           | χ²     | df  | RMSEA | Intervallo di confidenza RMSEA (90%) | CFI   | TLI   | -->\n<!-- |-----------------------------------|--------|-----|-------|--------------------------------------|-------|-------| -->\n<!-- | Modello basato su CFA             | 346.24\\* | 205 | .044  | (.036, .052)                        | .951  | .940  | -->\n<!-- | Modello CFA con invarianza metrica| 353.48\\* | 213 | .043  | (.035, .050)                        | .952  | .943  | -->\n<!-- | Modello basato su set-ESEM        | 283.98\\* | 173 | .042  | (.033, .050)                        | .962  | .945  | -->\n<!-- | Modello set-ESEM con invarianza   | 314.93\\* | 200 | .040  | (.031, .048)                        | .961  | .950  | -->\n\n<!-- **TABELLA 4: Coefficienti di percorso nei due modelli con invarianza metrica** -->\n\n<!-- | Variabile dipendente    | Predittore              | Risultati CFA       | Risultati set-ESEM    | -->\n<!-- |-------------------------|-------------------------|---------------------|------------------------| -->\n<!-- | Self_Confidence_T2      | Self_Confidence_T1      | .66 (p < .01)       | .66 (p < .01)          | -->\n<!-- | Intrinsic_T2            | Intrinsic_T1            | .61 (p < .01)       | .55 (p < .01)          | -->\n<!-- | Autonomy_T2             | Autonomy_T1             | .45 (p < .01)       | .42 (p < .01)          | -->\n<!-- | L2_achievement          | Self_Confidence_T1      | .30 (p < .01)       | .27 (p < .01)          | -->\n<!-- | L2_achievement          | Intrinsic_T1            | .10 (p = .07)       | .14 (p < .01)          | -->\n<!-- | L2_achievement          | Autonomy_T1             | .11 (p = .05)       | .16 (p < .01)          | -->\n<!-- | L2_achievement          | Self_Confidence_T2      | .39 (p < .01)       | .40 (p < .01)          | -->\n<!-- | L2_achievement          | Intrinsic_T2            | .08 (p = .09)       | .12 (p = .01)          | -->\n<!-- | L2_achievement          | Autonomy_T2             | .23 (p < .01)       | .26 (p < .01)          | -->\n\n<!-- Le correlazioni tra fattori mostrano differenze sostanziali nei due modelli, con valori inferiori per il set-ESEM. Ad esempio, nel modello CFA, la correlazione tra Self_Confidence_T1 e Autonomy_T1 è 0.55 (p < .01), mentre nel modello set-ESEM è 0.29 (p < .01). -->\n\n<!-- Alcuni coefficienti di percorso mostrano anche risultati differenti tra i modelli CFA e set-ESEM. Ad esempio, il modello CFA indica che la motivazione intrinseca al tempo 1 e al tempo 2 non è significativa come predittore del successo linguistico (e.g., Intrinsic_T1 → L2_achievement, β = .10, p = .07 e Intrinsic_T2 → L2_achievement, β = .08, p = .09), mentre nel modello set-ESEM questi effetti risultano significativi (Intrinsic_T1 → L2_achievement, β = .14, p < .01, e Intrinsic_T2 → L2_achievement, β = .12, p = .01). La significatività di questi coefficienti di percorso nel modello set-ESEM, ma non nel CFA, porta a conclusioni diverse sugli effetti predittivi delle variabili. -->\n\n\n## Riflessioni Conclusive\n\nIn questo tutorial, @marsh2024and presentano un'introduzione approfondita all'ESEM, con particolare attenzione al set-ESEM. Sebbene questa tecnica sia spesso utilizzata per i modelli di misurazione, gli autori ne esplorano l'applicazione nei modelli strutturali, evidenziando i vantaggi concettuali ed empirici rispetto al CFA e all'ESEM completamente rilassato. Il set-ESEM, grazie alla possibilità di specificare “mini-set” indipendenti di ESEM all'interno di un unico modello (Marsh et al., 2020), rappresenta un compromesso ottimale tra flessibilità e parsimonia. Questo approccio è particolarmente utile quando l'ESEM completo risulta tecnicamente impraticabile o teoricamente non giustificato. \n\nGli esempi discussi dagli autori dimostrano che il set-ESEM offre una rappresentazione più accurata dei dati rispetto al CFA. Sebbene entrambi i modelli possano mostrare un adattamento accettabile, le correlazioni tra fattori esogeni nel CFA tendono a essere sistematicamente sovrastimate, come evidenziato in entrambi gli studi presentati. Questo porta a un rischio maggiore di multicollinearità, che può influenzare negativamente la stima dei coefficienti di percorso (Mai et al., 2018; Morin, 2023). Ad esempio, nello Studio 1, alcune relazioni tra variabili latenti risultano significative nel set-ESEM, ma non nel CFA. In particolare:\n\n- Il percorso **Competenza_Insegnante → Motivazione_Intrinseca**, non significativo nel CFA (β = .08, *p* = .51), diventa significativo nel set-ESEM (β = .19, *p* = .03).\n- Il percorso **Relazionalità_Insegnante → Intenzione_di_Ritiro**, non significativo nel CFA (β = −.20, *p* = .18), risulta significativo nel set-ESEM (β = −.28, *p* = .01).\n\nQueste differenze sottolineano come il set-ESEM riesca a identificare relazioni importanti tra variabili che il CFA potrebbe non rilevare. Simili variazioni emergono nello Studio 2 (non trattato qui), dove le differenze tra i due approcci influenzano le conclusioni sulle relazioni longitudinali.\n\n@marsh2024and identificano i principali vantaggi del set-ESEM rispetto a CFA ed ESEM completo:\n\n- **Equilibrio tra parsimonia e adattamento**: Il set-ESEM è più parsimonioso dell’ESEM completo e si adatta spesso meglio del CFA.\n- **Separazione dei costrutti teorici**: Permette di includere costrutti teoricamente distinti in un unico modello, evitando carichi incrociati non giustificati.\n- **Rotazione target**: Consente un approccio confermativo, superando le limitazioni delle rotazioni meccaniche (es. geomin).\n- **Gestione di modelli strutturali complessi**: Rende possibile testare modelli strutturali che l’ESEM completo non può trattare.\n- **Migliore validità discriminante**: Le correlazioni tra fattori risultano più realistiche rispetto al CFA.\n- **Precisione dei coefficienti di percorso**: Riduce l'attenuazione degli effetti, migliorando l’accuratezza delle stime e diminuendo i tassi di errore di tipo II.\n\nNonostante i suoi vantaggi, il set-ESEM rimane meno parsimonioso rispetto al CFA. Pertanto, quando i modelli CFA e set-ESEM mostrano correlazioni tra fattori e indici di adattamento simili, il CFA dovrebbe essere preferito per la sua semplicità. Tuttavia, in presenza di cross-loading teoricamente giustificati, il set-ESEM rappresenta l’opzione migliore.\n\nIn sintesi, il set-ESEM offre una soluzione metodologica efficace per superare i limiti del CFA e dell’ESEM completo. Gli esempi empirici mostrano come l’adozione del set-ESEM possa migliorare l'adattamento del modello e la precisione delle stime, evitando problemi di collinearità comuni nel CFA. L'analisi dei dati con il CFA, senza considerare il set-ESEM, potrebbe portare a interpretazioni parziali o errate delle relazioni tra variabili, con implicazioni importanti per la teoria e la pratica (Shao et al., 2022; Tabachnick & Fidell, 2023).\n\nIn definitiva, @marsh2024and raccomandano l'uso del set-ESEM per analisi strutturali e di misurazione, specialmente quando l’ESEM completo è troppo flessibile o il CFA troppo restrittivo. La loro analisi evidenzia che, in situazioni in cui i coefficienti di percorso differiscono significativamente tra CFA e set-ESEM, quest'ultimo fornisce risultati più affidabili e interpretabili.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] kableExtra_1.4.0  ggokabeito_0.1.0  see_0.10.0        MASS_7.3-64      \n#>  [5] viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1   \n#>  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6   \n#> [13] semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12      scales_1.3.0     \n#> [17] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#> [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#> [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#> [29] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] rio_1.2.3           emmeans_1.10.7      zoo_1.8-12         \n#>  [22] igraph_2.1.4        mime_0.12           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-2        R6_2.5.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] numDeriv_2016.8-1.1 digest_0.6.37       OpenMx_2.21.13     \n#>  [34] fdrtool_1.2.18      colorspace_2.1-1    rprojroot_2.0.4    \n#>  [37] Hmisc_5.2-2         timechange_0.3.0    abind_1.4-8        \n#>  [40] compiler_4.4.2      withr_3.0.2         glasso_1.11        \n#>  [43] htmlTable_2.4.3     backports_1.5.0     carData_3.0-5      \n#>  [46] R.utils_2.12.3      ggsignif_0.6.4      corpcor_1.6.10     \n#>  [49] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [52] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [55] nnet_7.3-20         R.oo_1.27.0         glue_1.8.0         \n#>  [58] quadprog_1.5-8      nlme_3.1-167        promises_1.3.2     \n#>  [61] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [64] cluster_2.1.8       reshape2_1.4.4      generics_0.1.3     \n#>  [67] gtable_0.3.6        tzdb_0.4.0          R.methodsS3_1.8.2  \n#>  [70] data.table_1.16.4   hms_1.1.3           xml2_1.3.6         \n#>  [73] car_3.1-3           sem_3.1-16          pillar_1.10.1      \n#>  [76] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [79] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [82] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [85] reformulas_0.4.0    svglite_2.1.3       stats4_4.4.2       \n#>  [88] xfun_0.50           qgraph_1.9.8        arm_1.14-4         \n#>  [91] stringi_1.8.4       yaml_2.3.10         pacman_0.5.1       \n#>  [94] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#>  [97] mi_1.1              cli_3.6.3           RcppParallel_5.1.10\n#> [100] rpart_4.1.24        systemfonts_1.2.1   xtable_1.8-4       \n#> [103] Rdpack_2.6.2        munsell_0.5.1       Rcpp_1.0.14        \n#> [106] coda_0.19-4.1       png_0.1-8           XML_3.99-0.18      \n#> [109] parallel_4.4.2      jpeg_0.1-10         lme4_1.1-36        \n#> [112] mvtnorm_1.3-3       openxlsx_4.2.8      rlang_1.1.5        \n#> [115] multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "13_esem_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "0f54e2585b385b42a3c1f601f3899f35",
  "result": {
    "engine": "knitr",
    "markdown": "# Introduzione ai Modelli SEM {#sec-sem-intro}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- comprendere le basi dei Modelli di Equazioni Strutturali (SEM) e le loro componenti principali;\n- distinguere tra variabili osservate e latenti e il loro ruolo nei SEM;\n- interpretare la struttura di covarianza e la struttura delle medie nei modelli SEM; \n- utilizzare il software `lavaan` per specificare, stimare e valutare un modello SEM;\n- confrontare l'approccio SEM con tecniche tradizionali, come la regressione multipla e l'analisi fattoriale.  \n\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Structural Equation Modeling* del testo di @petersen2024principles.\n- Leggere il capitolo *Structural Equation Modeling with R for\nEducation Scientists* del testo di @saqr2024learning.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaanExtra, psych, tidyr, mvnormalTest, semPlot, DiagrammeRsvg, rsvg, effectsize)\n```\n:::\n\n\n\n:::\n\n\n## Introduzione\n\nLa ricerca in psicologia si basa sull'indagine di costrutti teorici che, essendo non direttamente osservabili, possono essere studiati solo in modo indiretto attraverso le risposte dei partecipanti a indicatori osservabili (ad esempio, le risposte a item di un questionario). I capitoli precedenti sull'analisi fattoriale hanno illustrato come valutare la struttura fattoriale di questi costrutti latenti, identificando quali item siano buoni indicatori per misurare tali costrutti. Questo processo è fondamentale per sviluppare strumenti validi e affidabili volti a quantificare i costrutti latenti che caratterizzano la ricerca psicologica. Tuttavia, una buona misurazione non rappresenta quasi mai il fine ultimo: i ricercatori desiderano solitamente esplorare le relazioni tra costrutti, confrontare differenze medie o rispondere a domande del tipo: *“La self-compassion è un fattore protettivo contro il burnout?”*.  \n\nQuando i ricercatori dispongono di sole variabili osservate come predittori e outcome, e desiderano esaminare gli effetti di uno o più predittori su un singolo outcome, possono utilizzare metodi di analisi familiari, come la regressione multipla. Tuttavia, se le domande di ricerca implicano costrutti latenti o richiedono di testare sistemi complessi di relazioni tra variabili, è necessario ricorrere a tecniche di analisi più flessibili in grado di modellare simultaneamente relazioni tra variabili osservate e latenti: questo è il campo dei Modelli di Equazioni Strutturali (SEM, *Structural Equation Modeling*).\n\nAlla base dei SEM si trova una combinazione di analisi fattoriale e analisi dei percorsi (*path analysis*). L'analisi dei percorsi può essere vista come un'estensione della regressione multipla, poiché consente di stimare e testare effetti diretti tra variabili. Tuttavia, a differenza della regressione multipla, che si concentra sugli effetti diretti di uno o più predittori su un unico outcome, l'analisi dei percorsi consente di analizzare sia effetti diretti sia indiretti tra interi insiemi di variabili predittive e di outcome in modo simultaneo. Questo approccio permette a una variabile di fungere contemporaneamente da predittore e da outcome: una variabile può essere prevista da una o più altre variabili, mentre a sua volta funge da predittore per altre variabili. In altre parole, l'analisi dei percorsi offre la possibilità di costruire modelli complessi, purché tutte le variabili siano osservate.\n\nL'inclusione di variabili latenti richiede però di andare oltre l'analisi dei percorsi tradizionale. Grazie al lavoro pionieristico di Jöreskog e Van Thillo, è stato possibile integrare variabili latenti nei modelli di percorsi, dando vita a quella che oggi conosciamo come SEM. Questo approccio è stato reso progressivamente più accessibile da software sempre più intuitivi, contribuendo alla diffusione dei SEM nella psicologia e nelle scienze sociali. \n\n### Struttura e Obiettivi dei SEM\n\nUn modello SEM tipico si compone di due parti principali:  \n\n1. **La parte di misurazione**, che collega i costrutti latenti a un insieme di variabili osservate o indicatori.  \n2. **La parte strutturale**, che modella le relazioni ipotizzate tra i costrutti latenti.  \n\nL'obiettivo principale dei SEM è testare ipotesi teoriche specifiche tramite modelli che rappresentano le previsioni di tali ipotesi, utilizzando costrutti misurati attraverso variabili osservabili appropriate. I SEM fungono così da ponte tra teoria e osservazione, consentendo di tradurre concetti astratti in entità misurabili e di analizzarne le relazioni in modo sistematico e coerente con la teoria.\n\n### Considerazioni Critiche sull'Uso dei SEM\n\nNonostante la loro potenza, i SEM richiedono un uso critico e consapevole. Ogni modello statistico è una semplificazione della realtà, come sottolineato dal celebre aforisma: *“Tutti i modelli sono sbagliati, ma alcuni sono utili”*. Questo implica che un buon adattamento ai dati non garantisce una rappresentazione accurata della realtà. Modelli intrinsecamente imprecisi possono adattarsi bene ai dati, portando a conclusioni errate. Pertanto, la scelta dei modelli non deve essere un semplice esercizio statistico, ma un processo orientato allo sviluppo e al raffinamento di teorie valide. La revisione critica dei modelli, basata su evidenze empiriche e solidi principi teorici, è essenziale per un progresso scientifico affidabile.\n\n## Modelli di Regressione e Introduzione ai SEM  \n\nIn questo capitolo, i Modelli di Equazioni Strutturali (SEM) vengono introdotti partendo dal caso più semplice: il modello di regressione multipla, reinterpretato e rappresentato all'interno di un framework SEM. L'obiettivo è fornire un ripasso rigoroso del modello di regressione lineare, evidenziando come possa essere formalizzato e implementato come un caso particolare di un modello SEM. Questa rappresentazione permette di estendere il concetto di regressione multipla a modelli più complessi che includono variabili latenti e relazioni strutturali.  \n\nUtilizzeremo dati empirici per illustrare l'approccio, focalizzandoci sulla *Self-Sompassion Scale* e sulle tre sottoscale del DASS-21: *ansia*, *stress* e *depressione*. Il campione analizzato comprende 526 studenti universitari iscritti a corsi di psicologia.  \n\nLe sottoscale del DASS-21 rappresentano variabili osservate che misurano concetti teorici distinti ma correlati. L'obiettivo è esplorare come il punteggio totale della Self-Compassion possa essere predetto dalle tre sottoscale del DASS-21 utilizzando un approccio di regressione multipla. Successivamente, questo modello sarà riformulato e stimato come un caso specifico di SEM.  \n\nL'implementazione in `R` mediante il pacchetto `lavaan` consentirà di confrontare i risultati della regressione tradizionale con quelli ottenuti dalla rappresentazione SEM, illustrando i vantaggi di quest'ultimo approccio, come la maggiore flessibilità e la possibilità di incorporare errori di misura nelle variabili osservate.  \n\n### Preliminari\n\nImportiamo i dati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- read.csv(\n    here::here(\"data\", \"dass_rosenberg_scs.csv\"),\n    header = TRUE\n)\ndat |>\n    head()\n#>   stress anxiety depression rosenberg self_kindness common_humanity\n#> 1      7       6          4        31            17              16\n#> 2      3       2          1        32            14              14\n#> 3      1       0          1        31            20              16\n#> 4     12      11         13        34            12               6\n#> 5     10       6         12        25            16              17\n#> 6      5       1          2        31            14              14\n#>   mindfulness self_judgment isolation over_identification scs_ts\n#> 1          16            11         8                  10     98\n#> 2          16            16        11                  13     82\n#> 3          16            13         6                   9    102\n#> 4           6            10         7                  15     70\n#> 5          13            17        16                  18     73\n#> 6          10            12         8                  11     85\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(dat)\n#> [1] 526  11\n```\n:::\n\n\n\n\nSelezioniamo le variabili di interesse:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_mr <- dat |>\n    dplyr::select(stress, anxiety, depression, scs_ts)\n\n```\n:::\n\n\n\n\nEsaminiamo i diagrammi di dispersione tra le varie misure per verificare che la relazione tra le variabili sia lineare.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npairs(d_mr)\n```\n\n::: {.cell-output-display}\n![](01_sem_intro_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nConvertiamo i dati in formato matriciale:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- d_mr$scs_ts |> as.matrix()\ndim(y)\n#> [1] 526   1\n```\n:::\n\n\n\n\n## Modello di Regressione Lineare Multipla\n\nIl modello generale di regressione lineare multipla (MLR) può essere espresso attraverso la seguente equazione:\n\n$$\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\cdots + \\beta_p x_{pi} + \\epsilon_i,\n$$\n\ndove: \n\n- $i = 1, \\ldots, N$ identifica l'$i$-esima osservazione,  \n- $\\beta_0$ è l'intercetta del modello,  \n- $\\beta_1, \\ldots, \\beta_p$ sono i coefficienti di regressione associati alle variabili indipendenti,  \n- $\\epsilon_i$ è il termine di errore per l'$i$-esima osservazione,  \n- Si assume che $\\epsilon_i$ sia indipendente dalle variabili esplicative $x_{1i}, \\ldots, x_{pi}$ e distribuito con media zero e varianza costante $\\sigma^2$.  \n\nIn questa formulazione, $y_i$ rappresenta il valore della variabile dipendente per l'$i$-esima osservazione, mentre i coefficienti $\\beta$ quantificano l'effetto delle variabili indipendenti $x_{1i}, \\ldots, x_{pi}$ su $y_i$. Il termine di errore $\\epsilon_i$ cattura la varianza non spiegata dal modello lineare. Questa struttura consente di modellare relazioni lineari tra una variabile dipendente e più variabili indipendenti, fornendo una base per effettuare inferenze sui parametri $\\beta$.\n\n### Forma Matriciale del Modello\n\nIl modello MLR può essere rappresentato in forma matriciale come:\n\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon},\n$$\n\ndove:  \n\n- $\\mathbf{y}$ è un vettore $N \\times 1$ contenente i valori osservati della variabile dipendente,  \n- $\\mathbf{X}$ è una matrice di progettazione $N \\times (p+1)$ che include le $p$ variabili indipendenti e una colonna di uni per l'intercetta,  \n- $\\boldsymbol{\\beta}$ è un vettore $(p+1) \\times 1$ dei coefficienti di regressione (inclusa l'intercetta),  \n- $\\boldsymbol{\\epsilon}$ è un vettore $N \\times 1$ che rappresenta i termini di errore.  \n\nLe componenti del modello sono definite come segue:\n\n$$\n\\mathbf{y} = \n\\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_N\n\\end{pmatrix}, \\quad\n\\boldsymbol{\\epsilon} = \n\\begin{pmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_N\n\\end{pmatrix}, \\quad\n\\mathbf{X} = \n\\begin{pmatrix}\n1 & x_{11} & \\cdots & x_{p1} \\\\\n1 & x_{12} & \\cdots & x_{p2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{1N} & \\cdots & x_{pN}\n\\end{pmatrix}.\n$$\n\nOgni riga della matrice $\\mathbf{X}$ rappresenta un'osservazione e include i valori delle variabili indipendenti per quella osservazione, oltre a un uno per l'intercetta.\n\n### Metodo dei Minimi Quadrati\n\nIl metodo dei minimi quadrati (*Least Squares Estimation*, LSE) mira a stimare i parametri $\\boldsymbol{\\beta}$ minimizzando la somma dei quadrati degli errori (SSE), definita come:\n\n$$\n\\text{SSE} = \\boldsymbol{\\epsilon}'\\boldsymbol{\\epsilon} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}).\n$$\n\nEspandendo questa espressione:\n\n$$\n\\text{SSE} = \\mathbf{y}'\\mathbf{y} - 2\\boldsymbol{\\beta}'\\mathbf{X}'\\mathbf{y} + \\boldsymbol{\\beta}'\\mathbf{X}'\\mathbf{X}\\boldsymbol{\\beta}.\n$$\n\nMinimizzando la SSE rispetto a $\\boldsymbol{\\beta}$ e ponendo la derivata prima pari a zero, si ottiene il sistema normale:\n\n$$\n\\mathbf{X}'\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}'\\mathbf{y}.\n$$\n\nSe la matrice $\\mathbf{X}'\\mathbf{X}$ è invertibile, la soluzione per i coefficienti stimati è:\n\n$$\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}.\n$$\n\nQuesta soluzione fornisce le stime dei coefficienti di regressione che minimizzano la discrepanza tra i valori osservati $\\mathbf{y}$ e quelli predetti $\\mathbf{X}\\hat{\\boldsymbol{\\beta}}$ dal modello. In tal modo, si ottengono le migliori stime lineari e non distorte dei parametri, sotto le ipotesi classiche di regressione.\n\n\n## Regressione Multipla in R\n\nApplichiamo il modello di regressione lineare multipla (MLR) ai dati disponibili, utilizzando sia la formulazione matriciale sia le funzioni predefinite di R. Come esempio, analizziamo le relazioni tra depressione, ansia, stress e una variabile dipendente (*scs_ts*) nei dati.\n\n### Preparazione dei Dati\n\nSelezioniamo le variabili di interesse dal dataset:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndass <- d_mr |>\n    dplyr::select(depression, anxiety, stress)\n```\n:::\n\n\n\n\nCreiamo la matrice di progettazione $\\mathbf{X}$, includendo una colonna di uni per l'intercetta:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nX <- model.matrix(~ depression + anxiety + stress, data = dass)\nhead(X)\n#>   (Intercept) depression anxiety stress\n#> 1           1          4       6      7\n#> 2           1          1       2      3\n#> 3           1          1       0      1\n#> 4           1         13      11     12\n#> 5           1         12       6     10\n#> 6           1          2       1      5\n```\n:::\n\n\n\n\n### Stima dei Coefficienti con la Formula Matriciale\n\nCalcoliamo i coefficienti $\\boldsymbol{\\beta}$ utilizzando la formula dei minimi quadrati:\n\n$$\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}.\n$$\n\nIn R, il calcolo viene effettuato come segue:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- d_mr$scs_ts\nbeta <- solve(t(X) %*% X) %*% t(X) %*% y\nbeta\n#>               [,1]\n#> (Intercept) 91.361\n#> depression  -1.484\n#> anxiety      1.049\n#> stress      -0.973\n```\n:::\n\n\n\n\n### Verifica dei Risultati con `lm()`\n\nConfrontiamo i risultati ottenuti con la funzione `lm()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm <- lm(scs_ts ~ depression + anxiety + stress, data = d_mr)\ncoef(fm) \n#> (Intercept)  depression     anxiety      stress \n#>      91.361      -1.484       1.049      -0.973\n```\n:::\n\n\n\n\nI coefficienti stimati con il metodo matriciale e quelli calcolati da `lm()` devono coincidere.\n\n### Valori Predetti e Residui\n\nCalcoliamo i valori predetti $\\hat{y}$ utilizzando i coefficienti stimati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nyhat <- X %*% beta\ncor(yhat, fm$fitted.values) \n#>      [,1]\n#> [1,]    1\n```\n:::\n\n\n\n\nCalcoliamo i residui $e = \\mathbf{y} - \\hat{\\mathbf{y}}$:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ne <- d_mr$scs_ts - yhat\ncor(e, fm$residuals) \n#>      [,1]\n#> [1,]    1\n```\n:::\n\n\n\n\n### Somma dei Quadrati dei Residui\n\nLa somma dei quadrati dei residui (RSS) è definita come:\n\n$$\n\\text{RSS} = \\mathbf{e}'\\mathbf{e}.\n$$\n\nIn R:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nRSS <- t(e) %*% e\nRSS \n#>        [,1]\n#> [1,] 128700\n```\n:::\n\n\n\n\n### Stima della Varianza dei Residui\n\nLa stima della varianza dei residui è data da:\n\n$$\n\\hat{\\sigma}^2 = \\frac{\\text{RSS}}{N - (p+1)},\n$$\n\ndove $N$ è il numero di osservazioni e $p+1$ è il numero di parametri stimati (inclusa l'intercetta):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar_e <- RSS / (length(y) - dim(X)[2])\nvar_e \n#>      [,1]\n#> [1,]  247\n```\n:::\n\n\n\n\n### Errore Standard della Regressione\n\nL'errore standard della regressione, $\\hat{\\sigma}$, è la radice quadrata della varianza dei residui:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsqrt(var_e)\n#>      [,1]\n#> [1,] 15.7\n```\n:::\n\n\n\n\nVerifichiamo questi risultati con il sommario del modello `lm()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = scs_ts ~ depression + anxiety + stress, data = d_mr)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -36.80 -12.00  -0.35  10.74  43.67 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)   91.361      1.623   56.29  < 2e-16\n#> depression    -1.484      0.238   -6.25  8.7e-10\n#> anxiety        1.049      0.210    4.99  8.2e-07\n#> stress        -0.973      0.255   -3.81  0.00015\n#> \n#> Residual standard error: 15.7 on 522 degrees of freedom\n#> Multiple R-squared:  0.247,\tAdjusted R-squared:  0.243 \n#> F-statistic: 57.1 on 3 and 522 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\n### Coefficiente di Determinazione $R^2$\n\nIl coefficiente di determinazione $R^2$ misura la proporzione della varianza spiegata dal modello rispetto alla varianza totale:\n\n$$\nR^2 = \\frac{\\sum (\\hat{y}_i - \\bar{y})^2}{\\sum (y_i - \\bar{y})^2}.\n$$\n\nIn R, calcoliamo $R^2$ come segue:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nR2 <- (sum((yhat - mean(y))^2)) / (sum((y - mean(y))^2)) \nR2 \n#> [1] 0.247\n```\n:::\n\n\n\n\nIn conclusione, questo esempio dimostra come implementare un modello di regressione multipla sia utilizzando la formulazione matriciale sia ricorrendo a funzioni predefinite di R. Il confronto tra i due approcci evidenzia la coerenza dei risultati e offre un'utile comprensione del funzionamento interno dei metodi di regressione.\n\n## Modello di Percorso\n\nPassiamo ora al cuore di questo capitolo: la rappresentazione del modello di regressione multipla come un caso speciale di Modello di Equazioni Strutturali (SEM). In precedenza, il modello di regressione è stato descritto nei termini di un modello statistico stimato mediante il **metodo della massima verosimiglianza** (ML). Questo metodo, sotto l'ipotesi di normalità multivariata, coincide con il **metodo dei minimi quadrati ordinari** (OLS). Tuttavia, nei modelli SEM, le relazioni tra le variabili possono essere più complesse rispetto a quelle di un modello di regressione multipla. Di conseguenza, non esistono formule analitiche esplicite per stimare i coefficienti del modello.\n\n### Stima nei Modelli SEM \n\nNei modelli di equazioni strutturali (SEM), la stima dei parametri non avviene attraverso l'applicazione diretta di formule analitiche (come abbiamo visto in precedenza), ma si basa su un processo di ottimizzazione numerica iterativa. È importante comprendere che, quando parliamo di massima verosimiglianza (ML) o minimi quadrati generalizzati (GLS), non ci riferiamo a soluzioni analitiche chiuse, ma a funzioni obiettivo che l'algoritmo cerca di ottimizzare.\n\nIl processo funziona così:\n\n1. Si parte da valori iniziali dei parametri (spesso basati su stime preliminari).\n2. L'algoritmo calcola la discrepanza tra la matrice di covarianza osservata (S) e quella predetta dal modello (Σ) con i parametri correnti.\n3. Basandosi su questa discrepanza, l'algoritmo aggiusta i parametri in una direzione che dovrebbe ridurre la differenza.\n4. Si ripetono i passi 2 e 3 finché la discrepanza non può essere ulteriormente ridotta in modo significativo.\n\nLa funzione di discrepanza (o funzione di costo) può essere basata su diversi criteri, come la verosimiglianza o la somma dei quadrati delle differenze, ma in tutti i casi l'obiettivo è trovare i valori dei parametri che la minimizzano attraverso successive approssimazioni. Non esiste una formula diretta per trovare questi valori - l'algoritmo \"esplora\" iterativamente lo spazio dei parametri cercando il punto di minimo della funzione di costo.\n\nQuesta natura iterativa del processo di stima ha importanti implicazioni pratiche:\n\n- L'algoritmo potrebbe non convergere a una soluzione.\n- Potrebbe convergere a un minimo locale invece che globale.\n- Il tempo di calcolo aumenta con la complessità del modello.\n- La scelta dei valori iniziali può influenzare il risultato finale.\n\nLa differenza fondamentale rispetto a metodi analitici diretti (come la regressione lineare semplice) è che non esiste una formula chiusa per calcolare i parametri ottimali, ma si procede per successive approssimazioni guidate dalla riduzione di una funzione di costo.\n\n### Rappresentazione di un Modello di Percorso con `lavaan`\n\nPer illustrare l'equivalenza tra un modello di regressione multipla e un SEM, riformuliamo il modello di regressione come un **modello di percorso** utilizzando la sintassi del pacchetto `lavaan` in R.\n\nDefiniamo il modello:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_mr <- \"\n  scs_ts ~ anxiety + depression + stress\n\"\n```\n:::\n\n\n\n\nIn questo caso:  \n\n- `scs_ts` rappresenta la variabile dipendente (ad esempio, una misura di self-compassion),  \n- `anxiety`, `depression`, e `stress` sono le variabili predittive.  \n\nAdattiamo il modello ai dati disponibili:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_mr <- lavaan::sem(mod_mr, d_mr)\n```\n:::\n\n\n\n\nIl comando `lavaan::sem()` specifica che vogliamo stimare il modello utilizzando l'approccio SEM.\n\nEsaminiamo i parametri stimati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameterEstimates(fit_mr) \n#>           lhs op        rhs     est     se     z pvalue ci.lower ci.upper\n#> 1      scs_ts  ~    anxiety   1.049  0.209  5.01      0    0.639    1.460\n#> 2      scs_ts  ~ depression  -1.484  0.237 -6.27      0   -1.948   -1.020\n#> 3      scs_ts  ~     stress  -0.973  0.254 -3.83      0   -1.472   -0.475\n#> 4      scs_ts ~~     scs_ts 244.677 15.087 16.22      0  215.106  274.247\n#> 5     anxiety ~~    anxiety  32.082  0.000    NA     NA   32.082   32.082\n#> 6     anxiety ~~ depression  24.546  0.000    NA     NA   24.546   24.546\n#> 7     anxiety ~~     stress  24.538  0.000    NA     NA   24.538   24.538\n#> 8  depression ~~ depression  31.418  0.000    NA     NA   31.418   31.418\n#> 9  depression ~~     stress  25.662  0.000    NA     NA   25.662   25.662\n#> 10     stress ~~     stress  29.714  0.000    NA     NA   29.714   29.714\n```\n:::\n\n\n\n\nI parametri stimati includono:  \n\n1. I **coefficienti di regressione** che rappresentano le relazioni tra la variabile dipendente e i predittori.  \n2. L'**errore standard** associato a ciascun parametro stimato.  \n3. Il **valore p** (che può essere ignorato in un'analisi bayesiana o interpretato con cautela).  \n\n### Confronto con il Modello di Regressione Multipla\n\nI parametri stimati da `lavaan` risultano praticamente identici a quelli ottenuti con il metodo della massima verosimiglianza per il modello di regressione multipla. Questo è coerente con il fatto che il modello di regressione multipla è un caso particolare di SEM in cui tutte le variabili sono osservate e non vi sono variabili latenti o relazioni complesse.\n\nIn conclusione, rappresentare un modello di regressione multipla come un modello di percorso SEM evidenzia l'equivalenza metodologica tra i due approcci nei casi più semplici. Tuttavia, l'approccio SEM offre maggiore flessibilità, permettendo di includere variabili latenti, relazioni indirette, e modelli più complessi, che non possono essere gestiti con il semplice framework della regressione multipla. Questa flessibilità rende SEM uno strumento indispensabile per analisi avanzate in psicologia e scienze sociali.\n\n## Modelli SEM e Scomposizione della Covarianza\n\n### Principio Fondamentale\n\nI modelli SEM mirano a spiegare le covarianze osservate nei dati attraverso una rete di relazioni causali dirette e indirette tra variabili. Questa rete è rappresentata da coefficienti di percorso che, opportunamente combinati, permettono di ricostruire la struttura di covarianza dei dati osservati.\n\n### Esempio Pratico\n\nPrendiamo come esempio la relazione tra self-compassion (misurata dal punteggio totale) e ansia (misurata dal DASS-21). La covarianza osservata tra queste due variabili può essere scomposta in diversi percorsi causali:\n\n1. **Effetto Diretto**: \n   - Il coefficiente che rappresenta l'influenza diretta dell'ansia sulla self-compassion\n\n2. **Effetti Indiretti**:\n   - Via depressione: l'ansia è correlata con la depressione, che a sua volta influenza la self-compassion\n   - Via stress: l'ansia è correlata con lo stress, che a sua volta influenza la self-compassion\n\n### Calcolo della Covarianza Predetta\n\nLa covarianza totale tra ansia e self-compassion viene calcolata combinando questi percorsi attraverso la seguente formula:\n\n```r\nCovarianza_Predetta = \n    (Effetto_Diretto × Varianza_Ansia) +\n    (Coefficiente_Depressione × Covarianza_Ansia_Depressione) +\n    (Coefficiente_Stress × Covarianza_Ansia_Stress)\n```\n\nNel nostro modello specifico:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Coefficienti di percorso\nbeta_anxiety_scs_ts <- 1.0493140    # Effetto diretto ansia → self-compassion\nbeta_depression_scs_ts <- -1.4841573 # Effetto diretto depressione → self-compassion\nbeta_stress_scs_ts <- -0.9733368    # Effetto diretto stress → self-compassion\n\n# Covarianze tra predittori\ncov_anxiety_depression <- 24.5464225\ncov_anxiety_stress <- 24.5381096\ncov_depression_stress <- 25.6615608\n\n# Varianze dei predittori\nvar_anxiety <- 32.0817418\nvar_depression <- 31.4182365\nvar_stress <- 29.7137880\n\n# Calcolo della covarianza predetta\npredicted_cov_anxiety_scs_ts <- \n    beta_anxiety_scs_ts * var_anxiety +\n    beta_depression_scs_ts * cov_anxiety_depression +\n    beta_stress_scs_ts * cov_anxiety_stress\n\npredicted_cov_anxiety_scs_ts\n#> [1] -26.7\n```\n:::\n\n\n\n\n### Verifica del Modello\n\nLa bontà del modello può essere verificata confrontando la covarianza predetta con quella osservata nei dati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Covarianza osservata nei dati\ncov(d_mr$anxiety, d_mr$scs_ts)\n#> [1] -26.7\n```\n:::\n\n\n\n\nQuesto procedimento di scomposizione viene applicato a tutti gli elementi della matrice di varianza/covarianza, permettendo di:\n\n1. Comprendere i meccanismi attraverso cui le variabili si influenzano reciprocamente\n2. Quantificare l'importanza relativa dei diversi percorsi causali\n3. Validare la struttura teorica del modello confrontando le covarianze predette con quelle osservate\n\nLa visualizzazione del modello attraverso il grafico `semPaths` aiuta a rappresentare questa rete di relazioni in modo intuitivo, mostrando i coefficienti di percorso stimati per ogni relazione.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPaths(fit_mr,\n    whatLabels = \"est\",\n    sizeMan = 10,\n    edge.label.cex = 1.15,\n    style = \"mx\",\n    nCharNodes = 0, nCharEdges = 0\n)\n```\n\n::: {.cell-output-display}\n![](01_sem_intro_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Errore di Specificazione\n\nConosciuto spiritosamente come *\"heartbreak of L.O.V.E.\"* (Left-Out Variable Error; @mauro1990understanding), l'**errore di specificazione** rappresenta una problematica fondamentale nei modelli di regressione, che deve essere sempre considerata attentamente durante l'interpretazione dei risultati. \n\nL'errore di specificazione si verifica quando una variabile viene esclusa dal modello di regressione, e tale variabile soddisfa entrambe le seguenti condizioni:  \n\n1. **È associata ad altre variabili incluse nel modello**.  \n2. **Ha un effetto diretto sulla variabile dipendente** ($y$).  \n\nQuando ciò accade, i coefficienti di regressione stimati per le variabili incluse nel modello risultano **distorti** in termini sia di intensità sia di segno. Questo fenomeno può portare a conclusioni errate sull'effetto delle variabili indipendenti sulla variabile dipendente.\n\n### Un Esempio con Dati Simulati\n\nConsideriamo un esempio in cui la prestazione (*performance*) è positivamente associata alla motivazione (*motivation*) e negativamente all'ansia (*anxiety*). Inoltre, supponiamo che ansia e motivazione siano positivamente correlate. Vogliamo osservare come il coefficiente della variabile \"motivazione\" cambi se \"ansia\" viene esclusa dal modello.\n\nCreiamo i dati simulati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 400\n\nanxiety <- rnorm(n, 10, 1.5)\nmotivation <- 4.0 * anxiety + rnorm(n, 0, 3.5)\ncor(anxiety, motivation)\n#> [1] 0.862\n```\n:::\n\n\n\n\nLa variabile *performance* è definita come una combinazione lineare di *motivation* e *anxiety*, con un effetto positivo ma piccolo della motivazione e un effetto negativo marcato dell'ansia:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nperformance <- 0.5 * motivation - 5.0 * anxiety + rnorm(n, 0, 3)\n```\n:::\n\n\n\n\nSalviamo i dati in un `data frame`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsim_dat2 <- tibble(performance, motivation, anxiety)\nsim_dat2 |> head() |> print()\n#> # A tibble: 6 × 3\n#>   performance motivation anxiety\n#>         <dbl>      <dbl>   <dbl>\n#> 1       -26.5       36.4    9.16\n#> 2       -33.0       34.5    9.65\n#> 3       -35.6       47.1   12.3 \n#> 4       -26.9       40.3   10.1 \n#> 5       -28.6       43.1   10.2 \n#> 6       -40.2       44.5   12.6\n```\n:::\n\n\n\n\n#### Modello corretto\n\nAdattiamo un modello di regressione che includa entrambi i predittori (*motivation* e *anxiety*):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm1 <- lm(performance ~ motivation + anxiety, sim_dat2)\ncoef(fm1) |> print()\n#> (Intercept)  motivation     anxiety \n#>       1.371       0.495      -5.105\n```\n:::\n\n\n\n\nLe stime dei coefficienti di regressione riflettono correttamente i parametri utilizzati per generare i dati.\n\n#### Modello con specificazione errata\n\nOra escludiamo il predittore *anxiety* e stimiamo il modello solo con *motivation*:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm2 <- lm(performance ~ motivation, sim_dat2)\nsummary(fm2) |> print()\n#> \n#> Call:\n#> lm(formula = performance ~ motivation, data = sim_dat2)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -13.501  -3.409   0.005   3.311  12.616 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept) -12.3972     1.4459   -8.57  2.2e-16\n#> motivation   -0.4372     0.0355  -12.31  < 2e-16\n#> \n#> Residual standard error: 4.87 on 398 degrees of freedom\n#> Multiple R-squared:  0.276,\tAdjusted R-squared:  0.274 \n#> F-statistic:  151 on 1 and 398 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\nIn questo caso, il segno del coefficiente di regressione per *motivation* è invertito rispetto al modello generatore dei dati. Questo è un tipico esempio di errore di specificazione.\n\n### Spiegazione Matematica\n\nSupponiamo che il vero modello sia:\n\n$$\ny = \\alpha + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon,\n$$\n\nstimato come:\n\n$$\ny = a + b_1 X_1 + b_2 X_2 + e.\n$$\n\nSe omettiamo erroneamente $X_2$, il modello diventa:\n\n$$\ny = a^\\prime + b_1^\\prime X_1 + e^\\prime,\n$$\n\ndove $b_1^\\prime$ è dato da:\n\n$$\nb_1^\\prime = \\frac{\\text{Cov}(X_1, y)}{\\text{Var}(X_1)}.\n$$\n\nSviluppando l'espressione:\n\n$$\nb_1^\\prime = b_1 + b_2 \\frac{\\text{Cov}(X_1, X_2)}{\\text{Var}(X_1)}.\n$$\n\nPertanto, il coefficiente $b_1^\\prime$ stimato nel modello con specificazione errata è distorto dalla presenza di $b_2$ e dalla correlazione $\\text{Cov}(X_1, X_2)$.\n\n### Verifica dell'Errore nei Dati Simulati\n\nCalcoliamo manualmente il coefficiente distorto $b_1^\\prime$ utilizzando i risultati del modello completo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm1$coef[2] + fm1$coef[3] * \n  cov(sim_dat2$motivation, sim_dat2$anxiety) / \n  var(sim_dat2$motivation)\n#> motivation \n#>     -0.437\n```\n:::\n\n\n\n\nIl valore calcolato coincide con quello stimato dal modello `performance ~ motivation`, confermando che il coefficiente è distorto.\n\nPossiamo trarre le seguenti conclusioni:  \n\n1. **Il coefficiente stimato $b_1^\\prime$ è distorto** se vengono omessi predittori rilevanti ($X_2$) correlati a quelli inclusi ($X_1$).  \n2. **La distorsione è sistematica e non si riduce all’aumentare della numerosità campionaria**, rendendo lo stimatore **inconsistente**.  \n3. **La causa dell’errore** è l’attribuzione degli effetti di $X_2$ al predittore incluso, $X_1$.  \n\nL'errore di specificazione può essere evitato solo se:  \n\n- Il predittore omesso ($X_2$) non ha un effetto sulla variabile dipendente ($\\beta_2 = 0$).  \n- Il predittore omesso è incorrelato con i predittori inclusi ($\\text{Cov}(X_1, X_2) = 0$).  \n\nUna corretta specificazione del modello è quindi essenziale per garantire risultati affidabili e interpretazioni corrette.\n\n## Errore di Specificazione e Modelli SEM\n\nQui abbiamo descritto l'errore di specificazione in riferimento al modello di regressione. Tuttavia, dato che i Modelli di Equazioni Strutturali (SEM) possono essere considerati un'estensione del modello di regressione, le stesse considerazioni si applicano anche ai SEM. \n\nAnche se i SEM permettono di rappresentare e testare relazioni più complesse tra variabili osservate e latenti, le loro conclusioni rimangono condizionate a un'importante assunzione: che il modello sia specificato correttamente. In altre parole, le inferenze tratte da un SEM presuppongono che non vi siano variabili rilevanti omesse o erroneamente incluse nel modello. Tuttavia, questa ipotesi è spesso irrealistica. Dato che non possiamo sapere con certezza se esistano altre variabili correlate con quelle del modello e che, in generale, tale eventualità è altamente probabile, è inevitabile che le relazioni descritte da un SEM siano **sempre influenzate, almeno in parte, dall'errore di specificazione**.\n\n### La Natura Condizionale delle Conclusioni nei SEM\n\nL'interpretazione dei risultati di un SEM è sempre **condizionale** all'assunzione che il modello rappresenti correttamente le relazioni tra le variabili. Questa condizionalità implica che:  \n\n- Le stime dei parametri e le inferenze derivate sono valide solo all'interno del contesto teorico e delle specifiche del modello scelto.  \n- La validità delle conclusioni è compromessa se il modello è distorto da errori di specificazione, come l'omissione di variabili rilevanti o la presenza di relazioni spurie tra le variabili incluse.\n\n### La Portata dell'Errore di Specificazione nei SEM\n\nL'errore di specificazione è intrinseco a tutti i modelli statistici, SEM inclusi. Questo deriva dal fatto che non possiamo conoscere tutte le variabili rilevanti né possiamo verificare in modo definitivo se il modello include tutte le relazioni pertinenti. Ne consegue che: \n\n1. **L'errore di specificazione è inevitabile**, ma non sempre rilevante. La sua gravità dipende da quanto le variabili omesse o erroneamente incluse distorcono le stime dei parametri del modello.  \n2. **Non è possibile quantificare con precisione la portata dell'errore di specificazione**, poiché non possiamo osservare direttamente le variabili omesse.  \n\n### Utilità del Modello e il Dilemma della Verità\n\nTornando al celebre aforisma di George Box: *“Tutti i modelli sono falsi, ma alcuni sono utili”*, l'obiettivo dell'analisi con i SEM non è stabilire se il modello sia \"vero\". Questa verifica è impossibile, dato che non possiamo mai essere certi di non aver omesso variabili rilevanti o di aver incluso solo relazioni valide. **Il problema non è evitare l'errore di specificazione, bensì valutarne l'impatto e considerare l'utilità del modello nonostante la sua inevitabile falsità.**\n\n### Cosa Significa \"Utilità\" in un SEM?\n\nUn modello è utile se:  \n\n- Consente di rispondere a specifiche domande di ricerca, anche in presenza di alcune semplificazioni.  \n- Fornisce una rappresentazione ragionevolmente coerente delle relazioni teoriche proposte, pur riconoscendo i limiti del contesto empirico.  \n- Offre predizioni interpretabili e comprensibili che possano guidare ulteriori ricerche, lo sviluppo teorico e decisioni pratiche.\n\nIn conclusione, riconoscere l'inevitabilità dell'errore di specificazione è essenziale per un utilizzo critico e consapevole dei SEM. Invece di mirare a modelli \"veri\" (un obiettivo irrealistico), il nostro scopo dovrebbe essere quello di costruire modelli **sufficientemente validi e utili** da consentire inferenze significative, pur accettandone le limitazioni. Questo approccio non elimina l'incertezza, ma permette di utilizzare i SEM come strumenti potenti per esplorare e chiarire le relazioni tra costrutti teorici complessi.\n\n### Soppressione\n\nLe conseguenze dell'errore di specificazione possono manifestarsi sotto forma di **soppressione** (*suppression*), un fenomeno che si verifica quando le relazioni tra i predittori e la variabile criterio (dipendente) assumono caratteristiche inaspettate o controintuitive nell'analisi di regressione multipla. La soppressione si verifica in due situazioni principali:\n\n1. Il valore assoluto del peso $\\beta$ di un predittore è maggiore della sua correlazione bivariata con la variabile criterio.  \n2. Il peso $\\beta$ e la correlazione bivariata hanno segni opposti.  \n\nLa soppressione può essere suddivisa in tre categorie principali:\n\n#### 1. Soppressione Negativa\n\nQuesto fenomeno si verifica quando un predittore ha una **correlazione bivariata positiva con il criterio**, ma riceve un **peso $\\beta$ negativo** nell'analisi di regressione multipla.  \nL'esempio precedente dell'errore di specificazione illustra proprio un caso di soppressione negativa: la variabile *motivazione* ha una correlazione bivariata positiva con la *prestazione*, ma, a causa della specificazione errata del modello (omissione della variabile *ansia*), il suo coefficiente $\\beta$ diventa negativo. Questo tipo di soppressione è comune nei casi in cui predittori correlati negativamente tra loro competono per spiegare la stessa varianza della variabile criterio.\n\n#### 2. Soppressione Classica\n\nNella soppressione classica, un predittore **non ha alcuna correlazione bivariata con il criterio**, ma riceve un **peso $\\beta$ diverso da zero** nell'analisi di regressione multipla. Questo accade quando il predittore in questione contribuisce a ridurre la varianza non spiegata associata agli altri predittori, aumentando così il potere predittivo complessivo del modello.  \nAd esempio, una variabile può essere utile per \"sopprimere\" la varianza irrilevante di un altro predittore, migliorando l'accuratezza delle stime.\n\n#### 3. Soppressione Reciproca\n\nLa soppressione reciproca si verifica quando due predittori sono **positivamente correlati con il criterio**, ma sono **negativamente correlati tra loro**. In questi casi, l'inclusione di entrambi i predittori nel modello di regressione può aumentare i pesi $\\beta$ di ciascuno, poiché ciascun predittore riduce la varianza non spiegata dell'altro, migliorando la spiegazione complessiva della varianza del criterio.\n\n### Implicazioni della Soppressione\n\nLa soppressione, come conseguenza dell'errore di specificazione o della struttura dei dati, ha implicazioni significative per l'interpretazione dei modelli di regressione e SEM:  \n\n- **Distorsione dei risultati:** La soppressione può portare a interpretazioni controintuitive, come l'apparente effetto negativo di un predittore che ha una relazione positiva con il criterio.  \n- **Dipendenza dal modello:** I pesi $\\beta$ nei modelli di regressione e SEM sono sempre condizionali alle variabili incluse nel modello. Aggiungere o rimuovere predittori può alterare significativamente i pesi stimati.  \n- **Importanza del controllo delle variabili:** La soppressione evidenzia l'importanza di includere tutti i predittori rilevanti nel modello per evitare distorsioni e garantire stime accurate.\n\nIn conclusione, la soppressione è un fenomeno complesso ma inevitabile in analisi multivariate. Comprendere i meccanismi alla base della soppressione, e come essa può emergere a seguito di errori di specificazione, è cruciale per interpretare correttamente i risultati delle analisi statistiche. \n\n### Regressione Stepwise\n\nNel contesto della regressione, è fondamentale comprendere che i predittori non dovrebbero essere selezionati basandosi esclusivamente sulle loro correlazioni bivariate con la variabile dipendente (criterio). Queste correlazioni, chiamate **associazioni di ordine zero**, non tengono conto dell'influenza reciproca tra i predittori e, di conseguenza, possono risultare fuorvianti quando si interpretano i coefficienti di regressione parziale.  \n\nLa **significatività statistica** delle correlazioni bivariate non è un criterio affidabile per la selezione dei predittori, poiché non considera gli effetti congiunti di altri predittori nel modello. Questo punto è particolarmente rilevante nei modelli con più predittori correlati, dove le relazioni tra le variabili sono complesse e non lineari.\n\n#### Criticità delle Procedure Stepwise\n\nLe procedure automatiche di selezione dei predittori, come la regressione **stepwise**, possono sembrare attraenti per la loro semplicità ed efficienza. Tuttavia, queste tecniche presentano gravi limitazioni:  \n- **Sensibilità alla struttura dei dati:** Piccole non-linearità o interazioni tra predittori possono alterare in modo significativo i coefficienti di regressione stimati.  \n- **Esposizione all'errore di specificazione:** La rimozione o l'aggiunta automatica di variabili può distorcere il modello, attribuendo erroneamente effetti ad altri predittori.  \n- **Non replicabilità dei risultati:** I modelli generati tramite procedure stepwise sono spesso specifici del campione di dati utilizzato, e i risultati tendono a non essere replicabili in altri campioni.\n\nPer queste ragioni, molte riviste scientifiche non accettano studi che utilizzano procedure stepwise. I risultati ottenuti con tali tecniche sono considerati inaffidabili e difficilmente generalizzabili.\n\n#### Selezione dei Predittori: Approccio Teorico vs. Statistico\n\nIn alternativa ai metodi automatici, i predittori dovrebbero essere scelti sulla base di **considerazioni teoriche** o di **risultati empirici consolidati**. Questo approccio ponderato aiuta a evitare distorsioni e garantisce che il modello rifletta le ipotesi di ricerca e il contesto teorico di riferimento.  \n\nUna volta selezionati, i predittori possono essere inseriti nell'equazione di regressione con due strategie principali:  \n1. **Inserimento simultaneo:** Tutti i predittori vengono inclusi contemporaneamente nel modello.  \n2. **Inserimento sequenziale:** I predittori vengono aggiunti gradualmente, seguendo un ordine prestabilito, in base a criteri teorici o statistici.  \n\n##### Regressione Gerarchica\n\nL'approccio teorico si traduce spesso nella **regressione gerarchica**, dove l'ordine di inserimento dei predittori è determinato da considerazioni razionali. Ad esempio, è comune includere prima le variabili demografiche e successivamente le variabili psicologiche di interesse. Questo approccio consente di: \n\n- Controllare gli effetti delle variabili demografiche.  \n- Valutare il contributo unico delle variabili psicologiche, misurato tramite l'incremento del coefficiente di determinazione ($\\Delta R^2$).  \n\n##### Regressione Stepwise\n\nL'approccio statistico, invece, è rappresentato dalla **regressione stepwise**, in cui il computer decide l'ordine di inserimento dei predittori in base ai valori di $p$:  \n- Nella **stepwise forward inclusion**, i predittori vengono aggiunti uno alla volta, scegliendo quello con il $p$ più piccolo a ogni passo. Una volta aggiunti, i predittori rimangono nel modello.  \n- Nella **stepwise backward elimination**, il modello parte con tutti i predittori e li elimina progressivamente in base ai loro valori di $p$, fino a ottenere il modello finale.  \n- Nella **stepwise bidirezionale**, predittori possono essere aggiunti o rimossi a ogni passo.  \n\nQueste varianti si interrompono quando l'aggiunta o la rimozione di ulteriori predittori non migliora significativamente $\\Delta R^2$. Tuttavia, come già sottolineato, tali procedure sono altamente problematiche e non raccomandate per la ricerca scientifica.\n\n### La Tentazione di Rimuovere Predittori \"Non Significativi\"\n\nUn errore comune è la rimozione dal modello di predittori che non risultano \"statisticamente significativi\". Questa pratica è controproducente per diverse ragioni: \n\n- **Potenza statistica insufficiente:** In campioni piccoli, i test di significatività possono non rilevare effetti reali. Eliminare variabili potenzialmente rilevanti a causa della mancanza di significatività statistica può compromettere il modello.  \n- **Specificazione errata del modello:** La rimozione di predittori senza una giustificazione teorica solida può introdurre errori di specificazione, distorcendo i coefficienti di regressione per le variabili rimanenti.  \n\nSe esiste una motivazione teorica convincente per includere un predittore, questo dovrebbe essere mantenuto nel modello, indipendentemente dalla sua significatività statistica. Le decisioni relative ai predittori dovrebbero essere guidate da un approccio scientifico, non da criteri meccanici come i valori di $p$.  \n\nIn conclusione, le procedure di selezione dei predittori, in particolare quelle automatiche come la regressione stepwise, presentano gravi rischi di distorsione e non replicabilità. Al contrario, un approccio basato su solide considerazioni teoriche e supportato da prove empiriche garantisce modelli più robusti e utili Infine, è essenziale superare l'ossessione per la significatività statistica e focalizzarsi sulla coerenza teorica e sull'utilità del modello.\n\n## Oltre la Regressione Multipla\n\nUna volta chiarita la relazione tra modello di regressione e modelli SEM, possiamo usare i modelli SEM per analizzare relazioni tra variabili che non possono essere descritte nei termini di un modello di regressione. Per fare un esempio, concludiamo il capitolo utilizzando il modello SEM per descrivere la relazione tra due costrutti: \n\nAnalizziamo un esempio in cui il modello di Equazioni Strutturali (SEM) viene impiegato per studiare la relazione tra autocompassione e disagio emotivo, utilizzando come indicatori le sotto-scale della DASS-21 (Depressione, Ansia, Stress) e della Self-Compassion Scale. In questo contesto, definiamo due variabili latenti: \"disagio emotivo\" e \"autocompassione\". La variabile latente \"disagio emotivo\" è composta dalle tre sotto-scale della DASS-21, mentre la variabile \"autocompassione\" è formata dalle sei sotto-scale della Self-Compassion Scale.\n\nIl modello strutturale esplora la relazione tra queste due variabili latenti. L'autocompassione è considerata una variabile esogena, ipotizzata come un fattore di protezione che riduce il disagio emotivo, che a sua volta è trattato come variabile endogena. L'ipotesi principale del modello è che esista una relazione di regressione negativa tra autocompassione e disagio emotivo, indicando che livelli più elevati di autocompassione sono associati a minori livelli di disagio emotivo.\n\nUn elemento chiave dei modelli SEM è la gestione dell'errore di misurazione. Le variabili latenti sono progettate per riflettere il nucleo vero dei costrutti teorici, in questo caso autocompassione e disagio emotivo, isolando gli effetti degli errori di misurazione che possono affliggere gli indicatori osservati. Questo approccio consente di esaminare la \"vera\" relazione tra i costrutti, eliminando le distorsioni introdotte dagli errori di misurazione nelle misure osservate.\n\nLa capacità del modello SEM di separare la variabilità attribuibile ai costrutti latenti da quella dovuta agli errori di misurazione aumenta l'accuratezza e l'affidabilità dell'analisi. Questo è particolarmente vantaggioso in campi come la psicologia, dove i costrutti teorici non sono direttamente osservabili e devono essere inferiti attraverso misure potenzialmente errate.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_sc <- \"\n  ED =~ anxiety + depression + stress\n  SC =~ self_kindness\t+ common_humanity\t+ mindfulness\t+ \n        self_judgment\t+ isolation\t+ over_identification\n  ED ~~ SC \n\"\n```\n:::\n\n\n\n\nAdattiamo il modello ai dati.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_sc <- lavaan::sem(mod_sc, dat, std.lv = TRUE)\n```\n:::\n\n\n\n\nEsaminiamo la soluzione ottenuta.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstandardizedSolution(fit_sc) \n#>                    lhs op                 rhs est.std    se      z pvalue\n#> 1                   ED =~             anxiety   0.847 0.014  58.51      0\n#> 2                   ED =~          depression   0.909 0.011  82.50      0\n#> 3                   ED =~              stress   0.929 0.010  91.94      0\n#> 4                   SC =~       self_kindness   0.757 0.022  33.98      0\n#> 5                   SC =~     common_humanity   0.621 0.030  20.70      0\n#> 6                   SC =~         mindfulness   0.689 0.026  26.23      0\n#> 7                   SC =~       self_judgment  -0.770 0.022 -35.80      0\n#> 8                   SC =~           isolation  -0.770 0.022 -35.82      0\n#> 9                   SC =~ over_identification  -0.767 0.022 -35.41      0\n#> 10                  ED ~~                  SC  -0.476 0.038 -12.38      0\n#> 11             anxiety ~~             anxiety   0.282 0.025  11.49      0\n#> 12          depression ~~          depression   0.173 0.020   8.63      0\n#> 13              stress ~~              stress   0.136 0.019   7.25      0\n#> 14       self_kindness ~~       self_kindness   0.427 0.034  12.65      0\n#> 15     common_humanity ~~     common_humanity   0.615 0.037  16.53      0\n#> 16         mindfulness ~~         mindfulness   0.525 0.036  14.52      0\n#> 17       self_judgment ~~       self_judgment   0.407 0.033  12.29      0\n#> 18           isolation ~~           isolation   0.407 0.033  12.28      0\n#> 19 over_identification ~~ over_identification   0.411 0.033  12.36      0\n#> 20                  ED ~~                  ED   1.000 0.000     NA     NA\n#> 21                  SC ~~                  SC   1.000 0.000     NA     NA\n#>    ci.lower ci.upper\n#> 1     0.819    0.876\n#> 2     0.888    0.931\n#> 3     0.910    0.949\n#> 4     0.713    0.801\n#> 5     0.562    0.679\n#> 6     0.637    0.740\n#> 7    -0.812   -0.728\n#> 8    -0.812   -0.728\n#> 9    -0.810   -0.725\n#> 10   -0.551   -0.400\n#> 11    0.234    0.330\n#> 12    0.134    0.212\n#> 13    0.099    0.173\n#> 14    0.361    0.493\n#> 15    0.542    0.688\n#> 16    0.454    0.596\n#> 17    0.342    0.472\n#> 18    0.342    0.472\n#> 19    0.346    0.476\n#> 20    1.000    1.000\n#> 21    1.000    1.000\n```\n:::\n\n\n\n\n1. **Saturazioni Fattoriali (Loadings) per le Variabili Latenti:**\n   - **ED:** Le variabili osservate \"anxiety\", \"depression\", e \"stress\" hanno elevate saturazioni fattoriali sulla variabile latente \"ED\". Questo suggerisce che ciascuna di queste misure è un buon indicatore della variabile latente \"ED\".\n   - **SC:** Le variabili \"self_kindness\", \"common_humanity\", \"mindfulness\", \"self_judgment\", \"isolation\", e \"over_identification\" hanno anch'esse significative saturazioni sulla variabile latente \"SC\". Si noti che \"self_judgment\", \"isolation\", e \"over_identification\" hanno saturazioni negative, indicando che queste variabili sono inversamente associate con \"SC\".\n\n2. **Correlazione tra Variabili Latenti:**\n   - La correlazione tra \"ED\" e \"SC\" mostra un coefficiente negativo (-0.476), il che indica una relazione inversa tra queste due variabili latenti. Questo significa che livelli più alti di \"SC\" sono associati a livelli più bassi di \"ED\".\n\n3. **Varianza delle Variabili Latenti:**\n   - La varianza di \"ED\" e \"SC\" indica quanto della variazione nelle variabili latenti è spiegata dai loro rispettivi indicatori. La varianza di \"ED\" (0.77) è relativamente alta, suggerendo che gli indicatori spiegano una buona parte della varianza in \"ED\". La varianza di \"SC\" è fissata a 1, un approccio comune per identificare il modello.\n\n4. **Varianze Residue degli Indicatori:**\n   - Le varianze residue (ad esempio, \"anxiety ~~ anxiety\") rappresentano la varianza non spiegata in ciascun indicatore dalle variabili latenti. Valori più bassi indicano che la variabile latente spiega una maggior parte della varianza dell'indicatore. Ad esempio, \"anxiety\" ha una varianza residua di 0.28, suggerendo che \"ED\" spiega una buona parte, ma non tutta, della varianza in \"anxiety\".\n\nGeneriamo una rappresentazione grafica del modello.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPaths(fit_sc,\n    whatLabels = \"std\",\n    sizeMan = 10,\n    edge.label.cex = 0.9,\n    style = \"mx\",\n    nCharNodes = 5, nCharEdges = 0, \n    fade=FALSE\n)\n```\n\n::: {.cell-output-display}\n![](01_sem_intro_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nI coefficienti stimati nel modello SEM appaiono coerenti e in linea con le aspettative, in particolare il coefficiente che descrive la correlazione tra il fattore dell'autocompassione e il disagio emotivo, che si attesta a -0.48. Questo valore negativo corrobora l'ipotesi secondo cui l'autocompassione svolge un ruolo di fattore protettivo contro il disagio emotivo. Tuttavia, prima di confermare definitivamente questa conclusione, è cruciale esaminare gli indici di bontà di adattamento del modello. Questi indici ci permetteranno di valutare quanto accuratamente il modello SEM si adatta ai dati osservati, fornendo un quadro più chiaro della validità delle nostre inferenze. In altre parole, sebbene il modello suggerisca una relazione negativa tra autocompassione e disagio emotivo, la conferma finale di questa associazione dipenderà dall'adeguatezza complessiva del modello rispetto ai dati. Questo argomento verrà affrontato nei prossimi capitoli.\n\n### Vantaggi del Modello SEM\n\nÈ evidente che avremmo potuto calcolare la correlazione tra disagio emotivo e autocompassione in modo più semplice, utilizzando semplicemente la **correlazione di Pearson** tra il punteggio totale del DASS-21 (disagio emotivo) e il punteggio totale della Self-Compassion Scale (SCS). Per calcolare il punteggio totale del DASS-21, sommiamo le sottoscale di stress, ansia e depressione:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- dat |> \n  mutate(ed = stress + anxiety + depression)\n```\n:::\n\n\n\n\nIl valore della correlazione così ottenuto è pari a 0.405:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor.test(dat$ed, dat$scs_ts)\n#> \n#> \tPearson's product-moment correlation\n#> \n#> data:  dat$ed and dat$scs_ts\n#> t = -10, df = 524, p-value <2e-16\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.474 -0.331\n#> sample estimates:\n#>    cor \n#> -0.405\n```\n:::\n\n\n\n\nTuttavia, questo valore differisce in maniera rilevante da quello calcolato mediante il modello SEM, dove la correlazione stimata è $r = -0.476$. Questa differenza evidenzia una distinzione fondamentale tra i due approcci:\n\n1. **Correlazione di Pearson:**  \n   La correlazione di Pearson si basa sui punteggi osservati delle variabili, che includono sia il **punteggio vero** (il costrutto sottostante) sia l’**errore di misurazione**. Di conseguenza, la correlazione calcolata può essere distorta dall’errore associato alla misurazione di ciascun costrutto.\n\n2. **Modello SEM:**  \n   Nei modelli SEM, la correlazione è stimata tra i **punteggi veri** dei costrutti, al netto dell’errore di misurazione. Questo approccio fornisce una stima più accurata e affidabile della relazione tra i costrutti teorici, eliminando la varianza attribuibile agli errori di misurazione.\n\nIl principale vantaggio dei modelli SEM è la loro capacità di descrivere le associazioni tra le variabili in modo meno influenzato dagli errori di misurazione rispetto alle semplici correlazioni. Questo permette di ottenere stime più vicine alle relazioni reali tra i costrutti, migliorando la validità delle conclusioni.  \n\nLa differenza tra i due valori di correlazione calcolati sottolinea l'importanza di utilizzare modelli SEM quando si vuole ottenere una rappresentazione più precisa delle relazioni tra costrutti latenti, in particolare in presenza di variabili soggette a errori di misurazione.\n\n## Impiego delle Medie nei Modelli SEM\n\nUn altro elemento importante da evidenziare nell'introduzione ai modelli SEM è il ruolo delle **medie**. Nei SEM, l'enfasi è tradizionalmente posta sull'analisi delle covarianze tra variabili. Tuttavia, a differenza dell'analisi fattoriale classica, i SEM permettono di includere anche le medie delle variabili osservate e latenti. Questo arricchisce l'analisi, fornendo informazioni importanti in contesti come i modelli longitudinali di analisi fattoriale confermativa (CFA), dove le ipotesi centrali possono riguardare cambiamenti o differenze nelle medie dei costrutti latenti nel tempo.\n\n### Struttura delle Medie nei Modelli SEM\n\nLa struttura delle medie nei SEM può essere descritta con la seguente equazione:\n\n$$ \nE(\\mathbf{y}) = \\boldsymbol{\\mu}_y = \\boldsymbol{\\tau} + \\mathbf{\\Lambda} \\boldsymbol{\\alpha}, \n$$\n\ndove:  \n\n- $\\mathbf{y}$ rappresenta i punteggi degli indicatori osservati,  \n- $E(\\mathbf{y})$ è il vettore delle medie attese degli indicatori,  \n- $\\boldsymbol{\\mu}_y$ è il vettore delle medie degli indicatori osservati (analogo a $\\mathbf{\\Sigma}$ nelle strutture di covarianza),  \n- $\\boldsymbol{\\tau}$ è il vettore delle **intercette** degli indicatori,  \n- $\\mathbf{\\Lambda}$ è la matrice dei **carichi fattoriali**, che definisce la relazione tra gli indicatori e i costrutti latenti,  \n- $\\boldsymbol{\\alpha}$ è il vettore delle **medie dei costrutti latenti**.\n\nIn un diagramma a percorsi, l'intercetta è rappresentata da un triangolo con il numero 1, che funge da costante di regressione. Questo simbolo indica l'origine della scala per la variabile e permette di stimare la media di una variabile quando viene regredita su questa costante.\n\n### Interpretazione e Collegamento tra Medie e Carichi Fattoriali\n\nNei modelli SEM, gli indicatori con carichi fattoriali più elevati ($\\mathbf{\\Lambda}$) esercitano un impatto maggiore sulla media stimata del costrutto ($\\boldsymbol{\\alpha}$). Questo collegamento evidenzia che i carichi fattoriali non solo influenzano la struttura di covarianza, ma giocano un ruolo chiave anche nella determinazione delle medie latenti.\n\n### Vincoli e Scalatura delle Medie\n\nCome per le strutture di covarianza, anche per le strutture delle medie è necessario imporre vincoli per definire la scala del modello. Spesso si utilizza lo **zero come riferimento** per le medie dei costrutti latenti. Questo vincolo serve a fissare un punto di partenza per le stime e a calcolare le differenze rispetto al riferimento, che possono assumere valori sia positivi sia negativi. \n\nAd esempio:  \n\n- Nei modelli CFA longitudinali, i vincoli sulle medie possono essere utilizzati per studiare cambiamenti temporali nei costrutti latenti.  \n- Nei modelli con gruppi multipli, i vincoli sulle medie permettono di confrontare le medie dei costrutti tra gruppi diversi.\n\n### Stima delle Intercette con `lavaan`\n\nPer stimare le intercette e includere la struttura delle medie in un modello SEM, è necessario disporre non solo della matrice di covarianza, ma anche delle **medie delle variabili osservate**. Il software `lavaan` semplifica questo processo attraverso l'opzione `meanstructure = TRUE`. Quando questa opzione è attivata, `lavaan` integra automaticamente una costante \"1\" in tutte le equazioni del modello, consentendo di stimare:  \n\n- Le **intercette** per le variabili osservate.  \n- Le **medie** dei costrutti latenti ($\\boldsymbol{\\alpha}$).  \n\nEsempio di codice in `lavaan` per includere le medie:\n\n```r\nmodel <- \"\n  y1 + y2 + y3 =~ latent1\n  y4 + y5 + y6 =~ latent2\n\"\nfit <- lavaan::sem(model, data = dat, meanstructure = TRUE)\nsummary(fit, standardize = TRUE)\n```\n\nIn questo contesto, `lavaan` stimerà sia le strutture di covarianza sia le medie e le intercette per le variabili osservate e latenti. L'inclusione delle medie è specificata dall'uso dell'argomento `meanstructure = TRUE`.\n\n### Importanza delle Medie nei Modelli SEM\n\nL'inclusione delle medie nei modelli SEM fornisce un livello aggiuntivo di informazione, permettendo di confrontare:  \n\n1. **Le medie stimate dai modelli SEM** con le **medie osservate** nei dati.  \n2. Le medie di costrutti latenti tra **diversi gruppi** o in **momenti temporali differenti**.  \n\nIn conclusione, l'integrazione delle medie nei modelli SEM rappresenta un importante arricchimento rispetto all'analisi delle sole covarianze. Questo approccio consente di ottenere una visione più completa delle relazioni tra variabili, al netto dell'errore di misurazione, e di esplorare le differenze nelle medie dei costrutti in contesti complessi come studi longitudinali o analisi multigruppo. Di conseguenza, l'analisi delle medie nei SEM non solo amplia la gamma di domande di ricerca a cui è possibile rispondere, ma migliora anche la validità delle conclusioni tratte dai dati.\n\n## Riflessioni Conclusive\n\nIn questo capitolo, abbiamo esplorato i Modelli di Equazioni Strutturali (SEM), evidenziando come questi modelli non si limitino a descrivere le correlazioni tra variabili osservabili, ma permettano anche di analizzare le relazioni tra variabili latenti. La forza dei SEM risiede nella loro capacità di integrare il modello di misurazione, che definisce le relazioni tra gli indicatori e le variabili latenti, con il modello strutturale, che esamina le interazioni tra le stesse variabili latenti.\n\nNei prossimi capitoli, approfondiremo vari aspetti della modellazione SEM. Esamineremo la bontà di adattamento del modello, un criterio fondamentale per verificare la fedeltà con cui il modello riflette la realtà osservata. Analizzeremo anche il confronto tra modelli alternativi, un passaggio cruciale per identificare il modello che migliora l'interpretazione dei dati.\n\nUn altro tema importante sarà l'analisi dell'applicabilità dei modelli a gruppi diversi, vitale per valutare la loro generalizzabilità e la pertinenza in contesti specifici. Inoltre, discuteremo le sfide metodologiche legate alla gestione di dati categoriali, all'implementazione di modelli SEM multilivello e alla gestione di dati mancanti. Questi approfondimenti ci permetteranno di comprendere meglio come i modelli SEM possono essere adattati e applicati efficacemente in diversi ambiti di ricerca.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] effectsize_1.0.0   rsvg_2.6.1         DiagrammeRsvg_0.1 \n#>  [4] mvnormalTest_1.0.0 lavaanExtra_0.2.1  ggokabeito_0.1.0  \n#>  [7] see_0.10.0         MASS_7.3-65        viridis_0.6.5     \n#> [10] viridisLite_0.4.2  ggpubr_0.6.0       ggExtra_0.10.1    \n#> [13] gridExtra_2.3      patchwork_1.3.0    bayesplot_1.11.1  \n#> [16] semTools_0.5-6     semPlot_1.1.6      lavaan_0.6-19     \n#> [19] psych_2.4.12       scales_1.3.0       markdown_1.13     \n#> [22] knitr_1.49         lubridate_1.9.4    forcats_1.0.0     \n#> [25] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.4       \n#> [28] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n#> [31] ggplot2_3.5.1      tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.0      datawizard_1.0.0   \n#>   [4] magrittr_2.0.3      TH.data_1.1-3       estimability_1.5.1 \n#>   [7] farver_2.1.2        nloptr_2.1.1        rmarkdown_2.29     \n#>  [10] vctrs_0.6.5         minqa_1.2.8         base64enc_0.1-3    \n#>  [13] rstatix_0.7.2       htmltools_0.5.8.1   curl_6.2.1         \n#>  [16] broom_1.0.7         Formula_1.2-5       htmlwidgets_1.6.4  \n#>  [19] plyr_1.8.9          sandwich_3.1-1      copula_1.1-5       \n#>  [22] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [25] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [28] Matrix_1.7-2        R6_2.6.1            fastmap_1.2.0      \n#>  [31] rbibutils_2.3       shiny_1.10.0        numDeriv_2016.8-1.1\n#>  [34] digest_0.6.37       OpenMx_2.21.13      fdrtool_1.2.18     \n#>  [37] colorspace_2.1-1    rprojroot_2.0.4     Hmisc_5.2-2        \n#>  [40] pspline_1.0-21      timechange_0.3.0    abind_1.4-8        \n#>  [43] compiler_4.4.2      gsl_2.1-8           withr_3.0.2        \n#>  [46] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [49] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [52] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [55] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [58] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [61] stabledist_0.7-2    nlme_3.1-167        promises_1.3.2     \n#>  [64] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [67] cluster_2.1.8       reshape2_1.4.4      generics_0.1.3     \n#>  [70] gtable_0.3.6        nortest_1.0-4       tzdb_0.4.0         \n#>  [73] data.table_1.17.0   hms_1.1.3           car_3.1-3          \n#>  [76] sem_3.1-16          pillar_1.10.1       rockchalk_1.8.157  \n#>  [79] later_1.4.1         splines_4.4.2       moments_0.14.1     \n#>  [82] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [85] tidyselect_1.2.1    ADGofTest_0.3       miniUI_0.1.1.1     \n#>  [88] pbapply_1.7-2       reformulas_0.4.0    V8_6.0.1           \n#>  [91] stats4_4.4.2        xfun_0.51           qgraph_1.9.8       \n#>  [94] arm_1.14-4          stringi_1.8.4       pacman_0.5.1       \n#>  [97] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#> [100] mi_1.1              cli_3.6.4           RcppParallel_5.1.10\n#> [103] rpart_4.1.24        parameters_0.24.1   xtable_1.8-4       \n#> [106] Rdpack_2.6.2        munsell_0.5.1       Rcpp_1.0.14        \n#> [109] coda_0.19-4.1       png_0.1-8           XML_3.99-0.18      \n#> [112] parallel_4.4.2      bayestestR_0.15.2   jpeg_0.1-10        \n#> [115] lme4_1.1-36         mvtnorm_1.3-3       insight_1.0.2      \n#> [118] pcaPP_2.0-5         openxlsx_4.2.8      rlang_1.1.5        \n#> [121] multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "01_sem_intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
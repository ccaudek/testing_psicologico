{
  "hash": "9cd54a67db8afbf44e071e70154a0ecf",
  "result": {
    "engine": "knitr",
    "markdown": "# Dati mancanti {#sec-sem-missing-data}\n\n::: callout-important\n\n## In questo capitolo imparerai a:\n\n- Identificare le diverse tipologie di dati mancanti (MCAR, MAR, MNAR) e comprenderne le implicazioni.\n- Applicare metodi di gestione come listwise deletion, pairwise deletion e imputazione dei dati.\n- Utilizzare il metodo Full Information Maximum Likelihood (FIML) per analisi robusta in contesti CFA e SEM.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Structural Equation Modeling* del testo di @petersen2024principles.\n- Leggere il capitolo *Structural Equation Modeling with R for\nEducation Scientists* del testo di @saqr2024learning.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, semTools, semPlot)\n```\n:::\n\n\n\n:::\n\n\n## Introduzione\n\nRaramente un ricercatore si trova nella situazione fortunata nella quale un'analisi statistica (di tipo CFA/SEM o altro) può essere condotta utilizzando un set di dati in cui tutte le variabili sono state osservate su tutte le unità statistiche: nella pratica ricerca i dati mancanti sono la norma piuttosto che l'eccezione.\n\n## Tipologie di dati mancanti\n\nCi sono molti motivi che possono stare alla base dei dati mancanti. Ad esempio, i dati possono mancare per disegno dello studio (\"mancanza pianificata\"), come ad esempio nei progetti di ricerca in cui i partecipanti al campione vengono selezionati casualmente per completare sottoinsiemi diversi della batteria di valutazione (una scelta di questo tipo viene motivata, ad esempio, a causa di considerazioni pratiche come i vincoli di tempo). In tali condizioni, si presume che i dati mancanti si distribuiscano in un modo completamente casuale rispetto a tutte le altre variabili nello studio. \n\nIn generale, i meccanismi che determinano la presenza di dati mancanti possono essere classificati in tre categorie:\n\n1. *valori mancanti completamente casuali* (*Missing Completely At Random*, MCAR). La probabilità di dati mancanti su una variabile non è collegata né al valore mancante sulla variabile, né al valore di ogni altra variabile presente nella matrice dati che si sta analizzando;\n2. *valori mancanti casuali* (*Missing At Random*, MAR). I valori mancanti sono indipendenti dal valore che viene a mancare, ma dipendono da altre variabili, cioè i dati sulla variabile sono mancanti per categorie di partecipanti che potrebbero essere identificati dai valori assunti dalle altre variabili presenti nello studio;\n3. *valori mancanti non ignorabili* (*Missing Not At Random*, MNAR). La mancanza di un dato può dipendere sia dal valore del dato stesso che dalle altre variabili. Per esempio, se si studia la salute mentale e le persone depresse riferiscono meno volentieri informazioni riguardanti il loro stato di salute, allora i dati non sono mancanti per caso.\n\n## La gestione dei dati mancanti\n\nIl passo successivo dopo la definizione dei meccanismi è quello della gestione dei dati mancanti. Sostanzialmente le scelte possibili sono due: l'eliminazione dei casi o la sostituzione dei dati mancanti. Un metodo semplice, indicato solo nel caso in cui l'ammontare dei dati mancanti è limitato e questi sono mancanti completamente a caso (MCAR), è quello di rimuovere i casi con dati mancanti (*case deletion*). \n\nCi sono due metodi per eliminare le osservazioni con valori mancanti: *listwise deletion* e *pairwise deletion*. Nel primo caso si elimina dal campione ogni osservazione che contiene dati mancanti. Le analisi avverranno quindi solo sui casi che hanno valori validi su tutte le variabili in esame. In questo modo si ottiene una maggiore semplicità di trattazione nell'analisi statistica, tuttavia non si utilizza tutta l'informazione osservata (si riduce la numerosità campionaria e, quindi, l'informazione). Il secondo metodo è la *pairwise deletio*n, che utilizza tutti i casi che hanno i dati validi su due variabili volta per volta. In questo modo si riesce a massimizzare la numerosità del campione da utilizzare, ma si tratta comunque di un metodo che presenta dei problemi, per esempio il fatto che con questo approccio i parametri del modello saranno basati su differenti insiemi di dati, con differenti numerosità campionarie e differenti errori standard.\n\nQuando i dati non sono MNAR è opportuno sostituirli con appropriate funzioni dei dati effettivamente osservati. Questa procedura è chiamata imputazione (*imputation*). Di seguito sono indicati alcuni metodi.\n\n1. *Mean Imputation*. Il dato mancante viene sostituito con la media della variabile. Questo metodo, utilizzato troppo spesso per la sua semplicità, riducendo la variabilità dei dati, ha effetti importanti su molte analisi dei dati e, in generale, dovrebbe essere evitato.\n2. *Regression Imputation*. Si tratta di un approccio basato sulle informazioni disponibili sulle altre variabili. Si stima una equazione di regressione lineare per ogni variabile utilizzando le altre variabili come predittori. Questo metodo offre il vantaggio di poter utilizzare i rapporti esistenti tra le variabili per effettuare le valutazioni dei dati mancanti; tuttavia esso è usato raramente, in quanto amplifica le correlazioni tra le variabili; quindi, se le analisi si basano su regressioni o modelli SEM, questo metodo è sconsigliato.\n3. *Multiple Imputation*. La tecnica di multiple imputation, applicabile in caso di MAR, prevede che un dato mancante su una variabile sia sostituito, sulla base dei dati esistenti sulle altre variabili, con un valore che però comprende anche una componente di errore ricavata dalla distribuzione dei residui della variabile. \n4. *Expectation-Maximization*. Un altro approccio moderno del trattamento dei dati mancanti è l'applicazione dell'algoritmo Expectation Maximization (EM). La tecnica è quella di stimare i parametri sulla base dei dati osservati, e di stimare poi i dati mancanti sulla base di questi parametri (fase E). Poi i parametri vengono nuovamente stimati sulla base della nuova matrice di dati (fase M), e così via. Questo processo viene iterato fino a quando i valori stimati convergono. Tuttavia, una limitazione fondamentale dell'utilizzo dell'algoritmo EM per calcolare le matrici di input per le analisi CFA/SEM è che gli errori standard risultanti delle stime dei parametri non sono consistenti. Pertanto, gli intervalli di confidenza e i test di significatività possono risultare compromessi. \n\n### Metodo Direct ML\n\nBenché i metodi precedenti vengano spesso usati,  nella pratica concreta è preferibile usare il metodo *Direct ML*, conosciuto anche come \"raw ML\" o \"full information ML\" (FIML), in quanto è generalmente considerano come il metodo migliore per gestire i dati mancanti nella maggior parte delle applicazioni CFA e SEM. Il metodo *full information ML* è esente dai problemi associati all'utilizzo dell'algoritmo EM e produce stime consistenti sotto l'ipotesi di normalità multivariata per dati mancanti MAR. \n\nIntuitivamente, l'approccio utilizza la relazione tra le variabili per dedurre quali siano i valori mancanti con maggiore probabilità. Ad esempio, se due variabili, $X$ e $Y$, sono correlate positivamente, allora se, per alcune osservazioni $i$, $X_i$ è il valore più alto nella variabile, è probabile che anche il valore mancante $Y_i$ sia un valore alto. FIML utilizza queste informazioni senza procedere all'imputazione dei valori mancanti, ma invece basandosi sulle stime più verosimili dei parametri della popolazione, ovvero massimizzando direttamente la verosimiglianza del modello specificato. Sotto l'assunzione di normalità multivariata, la funzione di verosimiglianza diventa\n\n$$\nL(\\mu, \\Sigma) = \\prod_i f(y_i \\mid \\mu_i, \\Sigma_i),\n$$\n\ndove $y_i$ sono i dati, $\\mu_i$ e $\\Sigma_i$ sono i parametri della popolazione se gli elementi mancanti in $y_i$ vengono rimossi. Si cercano i valori $\\mu$ e $\\Sigma$ che massimizzano la verosimiglianza.\n\nIn `lavaan` l'applicazione di tale metodo si ottiene specificando l'argomento `missing = \"ml\"`.\n\n### Un esempio concreto\n\nPer applicare il metodo *direct ML*, @brown2015confirmatory prende in esame i dati reali di un questionario (un singolo fattore, quattro item, una covarianza di errore) caratterizzato dalla presenza di dati mancanti. Importiamo i dati in R:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- rio::import(here::here(\"data\", \"brown_table_9_1.csv\"))\nhead(d)\n#>   subject s1 s2 s3 s4\n#> 1    5760  2  0  1 NA\n#> 2    5761  3  3  3 NA\n#> 3    5763  2  4  4 NA\n#> 4    5761  2  0  0 NA\n#> 5    5769  2  1  1 NA\n#> 6    5771  4  3  3 NA\n```\n:::\n\n\n\n\nAbbiamo 650 osservazioni:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(d)\n#> [1] 650   5\n```\n:::\n\n\n\n\nLe frequenze di dati mancanti vengono ottentute mediante la funzione `summary()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(d)\n#>     subject           s1             s2             s3             s4     \n#>  Min.   :5756   Min.   :0.00   Min.   :0.00   Min.   :0.00   Min.   :0.0  \n#>  1st Qu.:5934   1st Qu.:2.00   1st Qu.:2.00   1st Qu.:1.00   1st Qu.:2.0  \n#>  Median :6102   Median :3.00   Median :3.00   Median :2.00   Median :3.0  \n#>  Mean   :6104   Mean   :2.93   Mean   :2.56   Mean   :2.21   Mean   :2.4  \n#>  3rd Qu.:6275   3rd Qu.:4.00   3rd Qu.:4.00   3rd Qu.:4.00   3rd Qu.:3.0  \n#>  Max.   :6451   Max.   :4.00   Max.   :4.00   Max.   :4.00   Max.   :4.0  \n#>                 NA's   :25     NA's   :25     NA's   :25     NA's   :190\n```\n:::\n\n\n\n\nIl modello viene specificato come segue @brown2015confirmatory:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel <- '\n  esteem =~ s1 + s2 + s3 + s4\n  s2 ~~ s4\n'\n```\n:::\n\n\n\n\nAdattiamo il modello ai dati specificanto l'utilizzo del metodo *full information ML* per la gestione dei dati mancanti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- cfa(model, data = d, missing = \"fiml\")\n```\n:::\n\n\n\n\nÈ possibile identificare le configurazioni di risposte agli item che contengono dati mancanti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit@Data@Mp[[1]]$npatterns\n#> [1] 5\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npats <- fit@Data@Mp[[1]]$pat * 1L\ncolnames(pats) <- fit@Data@ov.names[[1]]\nprint(pats)\n#>      s1 s2 s3 s4\n#> [1,]  1  1  1  1\n#> [2,]  1  1  1  0\n#> [3,]  0  1  1  1\n#> [4,]  1  0  1  1\n#> [5,]  1  1  0  1\n```\n:::\n\n\n\n\nPossiamo esaminare la proporzione di dati disponibili per ciascun indicatore e per ciascuna coppia di indicatori: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoverage <- fit@Data@Mp[[1]]$coverage\ncolnames(coverage) <- rownames(coverage) <- fit@Data@ov.names[[1]]\nprint(coverage)\n#>       s1    s2    s3    s4\n#> s1 0.962 0.923 0.923 0.669\n#> s2 0.923 0.962 0.923 0.669\n#> s3 0.923 0.923 0.962 0.669\n#> s4 0.669 0.669 0.669 0.708\n```\n:::\n\n\n\n\nAd esempio, consideriamo l'item `s1`; se moltiplichiamo la copertura di questo elemento per la numerosità campionaria possiamo concludere che questa variabile contiene 25 osservazioni mancanti; e così via.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n650 * 0.9615385\n#> [1] 625\n```\n:::\n\n\n\n\nProcediamo poi come sempre per esaminare la soluzione ottenuta.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neffectsize::interpret(fit)\n#>     Name   Value Threshold Interpretation\n#> 1    GFI 0.99945      0.95   satisfactory\n#> 2   AGFI 0.99229      0.90   satisfactory\n#> 3    NFI 0.99919      0.90   satisfactory\n#> 4   NNFI 0.99898      0.90   satisfactory\n#> 5    CFI 0.99983      0.90   satisfactory\n#> 6  RMSEA 0.02024      0.05   satisfactory\n#> 7   SRMR 0.00485      0.08   satisfactory\n#> 8    RFI 0.99516      0.90   satisfactory\n#> 9   PNFI 0.16653      0.50           poor\n#> 10   IFI 0.99983      0.90   satisfactory\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstandardizedSolution(fit)\n#>       lhs op    rhs est.std    se     z pvalue ci.lower ci.upper\n#> 1  esteem =~     s1   0.737 0.020 37.09      0    0.698    0.776\n#> 2  esteem =~     s2   0.920 0.013 68.65      0    0.894    0.947\n#> 3  esteem =~     s3   0.880 0.013 66.43      0    0.854    0.906\n#> 4  esteem =~     s4   0.905 0.016 55.40      0    0.873    0.937\n#> 5      s2 ~~     s4  -0.886 0.216 -4.11      0   -1.309   -0.463\n#> 6      s1 ~~     s1   0.456 0.029 15.55      0    0.399    0.514\n#> 7      s2 ~~     s2   0.153 0.025  6.19      0    0.104    0.201\n#> 8      s3 ~~     s3   0.225 0.023  9.64      0    0.179    0.271\n#> 9      s4 ~~     s4   0.182 0.030  6.15      0    0.124    0.240\n#> 10 esteem ~~ esteem   1.000 0.000    NA     NA    1.000    1.000\n#> 11     s1 ~1          2.375 0.078 30.61      0    2.223    2.527\n#> 12     s2 ~1          1.881 0.066 28.59      0    1.752    2.010\n#> 13     s3 ~1          1.584 0.059 26.78      0    1.468    1.700\n#> 14     s4 ~1          1.850 0.071 26.05      0    1.710    1.989\n#> 15 esteem ~1          0.000 0.000    NA     NA    0.000    0.000\n```\n:::\n\n\n\n\n## Dati mancanti in R\n\nPer completezza, aggiungiamo qualche breve accenno alla gestione dei dati mancanti in R.\n\nIn R, i valori mancanti vengono indicati dal codice `NA`, che significa *not available* — non disponibile. \n\nSe una variabile contiene valori mancanti, `R` non è in grado di applicare ad essa alcune funzioni, come ad esempio la media. Per questa ragione, la gran parte delle funzioni di `R` prevedono modi specifici per trattare i valori mancanti.\n\nCi sono diversi tipi di dati \"mancanti\" in `R`;\n\n- `NA` - generico dato mancante;\n- `NaN` - il codice `NaN` (*Not a Number*) indica i valori numerici impossibili, quali ad esempio un valore 0/0;\n- `Inf` e `-Inf` - Infinity, si verifca, ad esempio, quando si divide un numero per 0.\n\nLa funzione `is.na()` ritorna un output che indica con TRUE le celle che contengono NA o NaN.\n\nSi noti che \n\n- se `is.na(x)` è TRUE, allora `!is.na(x)` è FALSE;\n- `all(!is.na(x))` ritorna TRUE se tutti i valori `x` sono NOT NA;\n- `any(is.na(x))` risponde alla domanda: c'è qualche valore NA (almeno uno) in `x`?;\n- `complete.cases(x)` ritorna TRUE se ciascun elemento di `x` è is NOT NA; ritorna FALSE se almeno un elemento di `x` è NA;\n\nLe funzioni `R` `is.nan()` e `is.infinite()` si applicano ai tipi di dati `NaN` e `Inf`.\n\nPer esempio, consideriamo il seguente data.frame:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- tibble(\n  w = c(1, 2, NA, 3, NA), \n  x = 1:5, \n  y = 1, \n  z = x ^ 2 + y,\n  q = c(3, NA, 5, 1, 4)\n)\nd\n#> # A tibble: 5 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     1     1     1     2     3\n#> 2     2     2     1     5    NA\n#> 3    NA     3     1    10     5\n#> 4     3     4     1    17     1\n#> 5    NA     5     1    26     4\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nis.na(d$w)\n#> [1] FALSE FALSE  TRUE FALSE  TRUE\nis.na(d$x)\n#> [1] FALSE FALSE FALSE FALSE FALSE\n```\n:::\n\n\n\n\nPer creare un nuovo Dataframe senza valori mancanti:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_clean <- d[complete.cases(d), ]\nd_clean\n#> # A tibble: 2 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     1     1     1     2     3\n#> 2     3     4     1    17     1\n```\n:::\n\n\n\n\nOppure, se vogliamo eliminare le righe con NA solo in una variabile:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd1 <- d[!is.na(d$q), ]\nd1\n#> # A tibble: 4 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     1     1     1     2     3\n#> 2    NA     3     1    10     5\n#> 3     3     4     1    17     1\n#> 4    NA     5     1    26     4\n```\n:::\n\n\n\n\nSe vogliamo esaminare le righe con i dati mancanti in qualunque colonna:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_na <- d[!complete.cases(d), ]\nd_na\n#> # A tibble: 3 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     2     2     1     5    NA\n#> 2    NA     3     1    10     5\n#> 3    NA     5     1    26     4\n```\n:::\n\n\n\n\n## Riflessioni Conclusive\n\nIn conclusione, questo capitolo ha fornito una panoramica completa sui dati mancanti, affrontando le loro tipologie, le possibili cause e le strategie di gestione più appropriate in base al contesto e al meccanismo sottostante. Abbiamo esplorato tecniche tradizionali come la listwise e pairwise deletion, metodi di imputazione semplici e avanzati, e approcci più robusti come l'algoritmo Expectation-Maximization e il Full Information Maximum Likelihood (FIML), evidenziandone vantaggi e limiti.\n\nIn particolare, è stato sottolineato come il metodo FIML rappresenti una soluzione ottimale per molte applicazioni in CFA e SEM, grazie alla sua capacità di sfruttare tutte le informazioni disponibili senza introdurre i bias tipici dell’imputazione. Esempi pratici e codice R hanno illustrato come implementare queste tecniche, rendendo il capitolo una risorsa preziosa sia per comprendere i fondamenti teorici sia per affrontare casi applicativi concreti. La gestione adeguata dei dati mancanti non solo migliora l’affidabilità delle analisi, ma contribuisce a una migliore interpretazione dei risultati, garantendo robustezza e validità nelle conclusioni di ricerca.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] ggokabeito_0.1.0  see_0.10.0        MASS_7.3-64       viridis_0.6.5    \n#>  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#>  [9] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n#> [13] lavaan_0.6-19     psych_2.4.12      scales_1.3.0      markdown_1.13    \n#> [17] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#> [25] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      datawizard_1.0.0   \n#>   [4] magrittr_2.0.3      TH.data_1.1-3       estimability_1.5.1 \n#>   [7] farver_2.1.2        nloptr_2.1.1        rmarkdown_2.29     \n#>  [10] vctrs_0.6.5         minqa_1.2.8         effectsize_1.0.0   \n#>  [13] base64enc_0.1-3     rstatix_0.7.2       htmltools_0.5.8.1  \n#>  [16] broom_1.0.7         Formula_1.2-5       htmlwidgets_1.6.4  \n#>  [19] plyr_1.8.9          sandwich_3.1-1      rio_1.2.3          \n#>  [22] emmeans_1.10.7      zoo_1.8-12          igraph_2.1.4       \n#>  [25] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [28] Matrix_1.7-2        R6_2.6.1            fastmap_1.2.0      \n#>  [31] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [34] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [37] rprojroot_2.0.4     Hmisc_5.2-2         timechange_0.3.0   \n#>  [40] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [43] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [46] carData_3.0-5       performance_0.13.0  R.utils_2.12.3     \n#>  [49] ggsignif_0.6.4      corpcor_1.6.10      gtools_3.9.5       \n#>  [52] tools_4.4.2         pbivnorm_0.6.0      foreign_0.8-88     \n#>  [55] zip_2.3.2           httpuv_1.6.15       nnet_7.3-20        \n#>  [58] R.oo_1.27.0         glue_1.8.0          quadprog_1.5-8     \n#>  [61] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [64] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8      \n#>  [67] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [70] tzdb_0.4.0          R.methodsS3_1.8.2   data.table_1.16.4  \n#>  [73] hms_1.1.3           car_3.1-3           sem_3.1-16         \n#>  [76] pillar_1.10.1       rockchalk_1.8.157   later_1.4.1        \n#>  [79] splines_4.4.2       lattice_0.22-6      survival_3.8-3     \n#>  [82] kutils_1.73         tidyselect_1.2.1    miniUI_0.1.1.1     \n#>  [85] pbapply_1.7-2       reformulas_0.4.0    stats4_4.4.2       \n#>  [88] xfun_0.50           qgraph_1.9.8        arm_1.14-4         \n#>  [91] stringi_1.8.4       pacman_0.5.1        boot_1.3-31        \n#>  [94] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [97] cli_3.6.4           RcppParallel_5.1.10 rpart_4.1.24       \n#> [100] parameters_0.24.1   xtable_1.8-4        Rdpack_2.6.2       \n#> [103] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [106] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [109] bayestestR_0.15.2   jpeg_0.1-10         lme4_1.1-36        \n#> [112] mvtnorm_1.3-3       insight_1.0.2       openxlsx_4.2.8     \n#> [115] rlang_1.1.5         multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
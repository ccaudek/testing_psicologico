{
  "hash": "e68740b03598ef865cf3fc31ad3e450d",
  "result": {
    "engine": "knitr",
    "markdown": "# Test del Modello e Indicizzazione {#sec-sem-gof}\n\n::: callout-important\n## In questo capitolo imparerai a:\n\n- calcolare e interpretare i principali indici di bontà di adattamento per i modelli SEM;\n- comprendere vantaggi e limiti dei tradizionali indici di bontà di adattamento.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Structural Equation Modeling* del testo di @petersen2024principles.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  lavaan, lavaanExtra, lavaanPlot, semTools, semPlot, mvnormalTest, lme4,\n  DiagrammeRsvg, tidyr, psych, rsvg, effectsize\n)\n```\n:::\n\n\n\n:::\n\n## Introduzione\n\nIn questo capitolo, ci concentriamo sulle due principali categorie di statistiche per valutare l’adattamento globale nei modelli SEM: le statistiche di test del modello e gli indici di adattamento approssimativo. Queste due categorie si riferiscono rispettivamente al test di adattamento del modello e alla misurazione continua della sua bontà.\n\n1. **Statistiche di Test del Modello:** Queste statistiche prevedono una decisione binaria, ossia stabilire se accettare o respingere le ipotesi nulle riguardanti il modello. La decisione si basa sui valori-p derivati dai test di significatività, con l’obiettivo di verificare se l’intero modello si adatti ai dati osservati.\n\n2. **Indici di Adattamento Approssimativo:** A differenza delle statistiche di test, gli indici di adattamento approssimativo forniscono una misura continua che esprime il grado di adattamento del modello ai dati. Questo approccio ricorda la stima dell’effetto quantitativo più che un test dicotomico, fornendo così una valutazione più dettagliata dell’adattamento e superando la semplice accettazione o rifiuto dell’ipotesi nulla.\n\nUn aspetto critico da considerare è che, benché entrambe le categorie di statistiche valutino la corrispondenza media o generale tra modello e dati, possono non rilevare un cattivo adattamento locale. Questo si riferisce a specifiche coppie di variabili osservate per cui il modello potrebbe non spiegare adeguatamente le associazioni osservate. È fondamentale riconoscere che un modello con adattamento locale inadeguato non dovrebbe essere accettato, indipendentemente dalla sua bontà di adattamento globale.\n\nLa valutazione completa di un modello SEM segue una sequenza metodica: specificazione del modello, stima dei parametri, verifica dell’adattamento e dei parametri, e, se necessario, modifica del modello. Questo processo iterativo prosegue finché si identifica un modello ritenuto accettabile.\n\nInoltre, questo capitolo esplora due metodi fondamentali per pianificare la dimensione del campione nei modelli SEM: l’analisi della potenza e la stima della precisione dei parametri (precisione nella pianificazione). Questi approcci sono essenziali per assicurare che lo studio sia adeguatamente dimensionato e che i parametri siano stimati con massima precisione. La valutazione degli indici di bontà dell’adattamento, ampiamente utilizzati nella letteratura, rappresenterà un elemento chiave in questo contesto, fornendo una panoramica completa degli strumenti disponibili per giudicare l’efficacia dei modelli SEM.\n\n## Valutazione della Bontà di Adattamento nel Modello SEM\n\nNel contesto dei modelli SEM (Structural Equation Modeling), la valutazione dell'adattamento del modello si basa sul confronto tra la matrice di varianze e covarianze stimata dal modello, $\\Sigma(\\hat{\\theta})$, e la matrice di covarianza campionaria, $S$. Il nostro obiettivo è verificare se la discrepanza tra queste due matrici indica possibili inadeguatezze nel modello proposto. Ecco alcuni aspetti rilevanti da considerare:\n\n- **Modelli Saturi vs Modelli Ristretti**: Un modello saturo include un numero di parametri in $\\theta$ pari al numero di elementi distinti nella matrice di covarianza. In contrasto, un modello ristretto ha meno parametri rispetto al numero degli elementi distinti nella matrice di covarianza. La differenza tra questi due numeri corrisponde ai gradi di libertà del modello. Per esempio, in un modello saturo, se il numero dei parametri in $\\theta$ e il numero degli elementi distinti nella matrice di covarianza sono entrambi 3, allora il modello ha zero gradi di libertà.\n\n- **Perfetto Adattamento dei Modelli Saturi**: In un modello saturo, $\\Sigma(\\hat{\\theta})$ coincide sempre con $S$, poiché il modello ha abbastanza parametri per adattarsi perfettamente ai dati del campione. Tuttavia, ciò non implica necessariamente che il modello rappresenti fedelmente la popolazione più ampia. Le stime dei parametri in un modello saturo possono fornire informazioni sui pattern di relazione tra le variabili nel campione specifico, ma è cruciale interpretarle con cautela.\n\n- **Stima e Identificabilità del Modello**: Generalmente, la stima dei parametri non si basa sul semplice risolvere un sistema di equazioni matematiche. Invece, si utilizza una funzione di adattamento o discrepanza tra $\\Sigma(\\theta)$ e $S$, cercando il valore ottimale di $\\hat{\\theta}$ attraverso tecniche di ottimizzazione numerica. Un modello SEM deve essere identificabile, il che significa che deve essere possibile stimare univocamente i parametri del modello. L'identificabilità implica che il numero di unità di informazione, come elementi nella matrice di covarianza, sia maggiore o uguale al numero di parametri da stimare.\n\n### Gradi di Libertà e Identificabilità del Modello\n\nI gradi di libertà (dof) in un modello SEM sono calcolati come:\n\n$$\ndof = \\# (\\text{unità di informazione}) - \\# (\\text{parametri da stimare})\n$$\n\nPer una matrice di covarianza di ordine $ p $, il numero di unità di informazione è $ \\frac{p (p+1)}{2} $. Per garantire l'identificabilità, è necessario soddisfare alcune condizioni:\n\n1. In tutti i modelli, l'unità di misura delle variabili latenti deve essere specificata.\n2. Il numero di unità di informazione deve essere uguale o superiore al numero di parametri da stimare.\n3. In modelli ad un fattore, è richiesto un minimo di tre indicatori per una soluzione \"appena identificata\".\n4. In modelli a più fattori, si raccomanda un minimo di tre indicatori per ogni variabile latente.\n\nUn modello è:\n\n- *Non identificato* se $dof < 0$.\n- *Appena identificato* o \"saturo\" se $dof = 0$.\n- *Sovra-identificato* se $dof > 0$.\n\nÈ importante notare che un'analisi fattoriale con solo due indicatori per un fattore non è possibile, poiché ci sono meno unità di informazione rispetto ai parametri da stimare. Un modello con tre indicatori e un fattore è \"appena identificato\", senza gradi di libertà per valutare la bontà dell'adattamento. Per modelli ad un solo fattore comune latente, è quindi necessario disporre di almeno **quattro indicatori**.\n\n## Funzione di Discrepanza e Valutazione della Bontà di Adattamento\n\nLa funzione di discrepanza tra $S$ (matrice di covarianza osservata) e $\\Sigma(\\theta)$ (matrice di covarianza stimata dal modello in base ai parametri $\\theta$) misura l'adeguatezza con cui il modello rappresenta i dati. Derivata dalla log-verosimiglianza per una distribuzione normale multivariata, la funzione confronta le strutture di covarianza teoriche e osservate.\n\nLa formula per la discrepanza ML (Massima Verosimiglianza) è:\n\n$$\nFML(S, \\Sigma(\\theta)) = \\log|\\Sigma(\\theta)| - \\log|S| + \\text{traccia}(S\\Sigma(\\theta)^{-1}) - p,\n$$\n\ndove $|S|$ e $|\\Sigma(\\theta)|$ indicano i determinanti di $S$ e $\\Sigma(\\theta)$ rispettivamente, e $p$ è la dimensione delle matrici. Vediamo ogni termine per comprenderne il significato.\n\n### Componenti della Formula di Discrepanza\n\n1. **Logaritmo del determinante della matrice stimata, $\\log|\\Sigma(\\theta)|$**:\n   - Il termine $\\log|\\Sigma(\\theta)|$ rappresenta una misura della \"dimensione\" o \"scala\" della matrice $\\Sigma(\\theta)$. Più precisamente, il determinante di una matrice di covarianza può essere visto come una misura del volume dello spazio descritto dalle variabili nel modello: maggiore è il determinante, più \"ampio\" è lo spazio che copre la distribuzione del modello. Il logaritmo del determinante di $\\Sigma(\\theta)$ contribuisce quindi a quantificare la scala complessiva del modello.\n\n2. **Logaritmo del determinante della matrice osservata, $\\log|S|$**:\n   - Similmente, $\\log|S|$ rappresenta la scala della matrice di covarianza osservata nei dati. Questo termine funge da riferimento per confrontare la scala dei dati con quella stimata dal modello. In altre parole, $|S|$ ci dice quale sarebbe la \"dimensione\" dei dati se fossero perfettamente rappresentati solo da $S$, la matrice di covarianza empirica.\n\n3. **Traccia del prodotto $S\\Sigma(\\theta)^{-1}$**:\n   - La traccia, ossia la somma degli elementi diagonali, del prodotto $S\\Sigma(\\theta)^{-1}$ rappresenta la relazione tra $S$ e l'inverso della matrice $\\Sigma(\\theta)$. Se $S$ e $\\Sigma(\\theta)$ fossero perfettamente identiche, questa traccia sarebbe pari a $p$, la dimensione delle matrici, perché il prodotto di una matrice con la propria inversa è la matrice identità, che ha una somma degli elementi diagonali pari alla dimensione. Un valore diverso da $p$ indica discrepanze tra le covarianze osservate e quelle stimate.\n\n4. **Termine di normalizzazione, $-p$**:\n   - Sottrarre $p$ serve a normalizzare la traccia in modo che, in assenza di discrepanze (ovvero quando $S = \\Sigma(\\theta)$), il valore complessivo della funzione di discrepanza sia zero. Questo termine fa sì che la discrepanza sia relativa a quanto $S$ differisca da $\\Sigma(\\theta)$ in una forma più bilanciata.\n\n### Interpretazione Complessiva\n\nLa funzione di discrepanza combina queste tre componenti per ottenere una misura della distanza o della differenza tra $S$ e $\\Sigma(\\theta)$. Essa confronta sia la \"dimensione\" complessiva (tramite i termini log-determinante) sia la \"forma\" (tramite la traccia) delle due matrici. In sintesi, la funzione di discrepanza $FML(S, \\Sigma(\\theta))$ ci indica quanto il modello con parametri $\\theta$ si discosta dai dati osservati e consente di capire se il modello è una buona rappresentazione delle relazioni di covarianza presenti nei dati.\n\nSe questa funzione di discrepanza risulta elevata, significa che le covarianze stimate dal modello non rispecchiano adeguatamente quelle osservate, indicando una possibile necessità di migliorare il modello o di rivedere i parametri $\\theta$.\n\n### Distribuzione e Test di Adattamento\n\nLa discrepanza calcolata, sotto l'ipotesi di buon adattamento, si distribuisce asintoticamente come una variabile chi-quadrato (χ²), che permette un test statistico. I gradi di libertà sono dati dalla differenza tra il numero di elementi indipendenti nella matrice di covarianza e il numero di parametri del modello. \n\n- Se il valore di discrepanza è minore del valore critico χ², l'ipotesi nulla di buon adattamento non viene rifiutata, suggerendo un buon modello.\n- Se invece è maggiore, l'ipotesi viene rifiutata, indicando una necessità di revisione del modello.\n\nQuesto test fornisce un’indicazione quantitativa della bontà di adattamento, utile per valutare se le strutture teoriche catturano adeguatamente le relazioni nei dati.\n\n## Test $\\chi^2$\n\nIl test del chi quadrato ($\\chi^2$) è utilizzato per determinare quanto bene un modello teorico si adatta ai dati osservati. La formula per calcolare la statistica $\\chi^2$ è:\n\n$$\n\\chi^2 = N \\times F_{\\text{min}},\n$$\n\ndove:\n- $N$ rappresenta la dimensione del campione.\n- $F_{\\text{min}}$ è il valore minimo della funzione di discrepanza.\n\nLa funzione di discrepanza, $F$, è una misura di quanto le covarianze (o le varianze) osservate nei dati differiscano da quelle previste dal modello. Durante il processo di stima dei parametri del modello, questa funzione viene minimizzata. Il valore di $F$ al suo minimo, $F_{\\text{min}}$, rappresenta la discrepanza minima tra i dati osservati e quelli previsti dal modello.\n\nNell'ambito dell'analisi strutturale di covarianza, il valore di $F_{\\text{min}}$ è tipicamente ottenuto attraverso la stima di massima verosimiglianza (Maximum Likelihood, ML). Tuttavia, ci sono due modi comuni per calcolare $\\chi^2$, che possono variare a seconda del software utilizzato:\n\n1. $\\chi^2 = (N - 1) \\times F_{\\text{min}}$\n2. $\\chi^2 = N \\times F_{\\text{min}}$\n\nLa scelta tra $N$ e $N-1$ dipende da come il software gestisce la normalizzazione e l'adattamento delle strutture di covarianza.\n\n### Interpretazione del Test del $\\chi^2$\n\n- **Ipotesi Nulla $ H_0 $**: Il modello si adatta bene ai dati. Ciò significa che non c'è una differenza significativa tra le covarianze osservate e quelle previste dal modello.\n- **Valore p**: Un valore p basso (ad esempio, minore di 0.05) suggerisce che dovremmo rifiutare l'ipotesi nulla, indicando che il modello non si adatta bene ai dati.\n\n### Limitazioni\n\nLa statistica $\\chi^2$ è influenzata dalla dimensione del campione: con campioni ampi, anche lievi discrepanze tra il modello e i dati possono portare a un valore di $\\chi^2$ elevato, risultando in un rifiuto ingiustificato di un modello valido. Inoltre, il test del $\\chi^2$ presenta alcune limitazioni importanti:\n\n- **Non fornisce indicazioni sulla direzione o sulla natura della discrepanza**: il test non specifica dove il modello si discosta dai dati o in che modo le discrepanze si manifestano.\n- **Efficacia ridotta in modelli complessi**: per modelli con molteplici parametri, o in condizioni in cui le ipotesi fondamentali (ad esempio, la normalità multivariata) non sono soddisfatte, il test del $\\chi^2$ potrebbe non essere affidabile.\n\nPer tali ragioni, è comune integrare il test del $\\chi^2$ con altri indici di adattamento, come l’indice di adattamento comparativo (CFI) e la radice dell'errore quadratico medio di approssimazione (RMSEA), per ottenere una valutazione più accurata e robusta dell’adattamento del modello ai dati.\n\nIl test del $\\chi^2$ resta dunque un utile strumento di valutazione, ma è fondamentale interpretarlo con cautela, tenendo conto delle dimensioni del campione e di altri fattori che possono influire sul risultato. Nonostante le sue limitazioni, la statistica $\\chi^2$ ha un ruolo importante in contesti specifici, come:\n\n- **Confronto tra modelli nidificati**: consente di valutare se aggiunte o modifiche migliorano significativamente l’adattamento del modello.\n- **Calcolo di altri indici di adattamento**: come l’indice di Tucker-Lewis (TLI).\n- **Rapporto tra $\\chi^2$ e gradi di libertà**: un rapporto basso è indicativo di un buon adattamento relativo del modello ai dati.\n\nIn conclusione, pur essendo utile, la statistica $\\chi^2$ va affiancata da altri strumenti di valutazione per una comprensione più completa e bilanciata della bontà di adattamento del modello.\n\n### Test di rapporto di verosimiglianza\n\nIl test del $\\chi^2$ può essere impiegato come un test di rapporto di verosimiglianza per confrontare due modelli nidificati. In questo contesto, \"nidificati\" significa che uno dei modelli (considerato il modello più semplice o ristretto) è un caso speciale dell'altro (il modello più complesso), con meno parametri liberi da stimare. Questo tipo di test è particolarmente utile per valutare se l'aggiunta di parametri supplementari (rendendo il modello più complesso) migliora significativamente l'adattamento del modello ai dati.\n\nIl processo di confronto tra i due modelli avviene nel seguente modo:\n\n1. Si stima il modello più semplice e si calcola il suo valore di $\\chi^2$.\n2. Si stima il modello più complesso e si calcola il suo valore di $\\chi^2$.\n3. Si confrontano i due valori di $\\chi^2$ per determinare se l'aggiunta di parametri aggiuntivi giustifica un miglioramento dell'adattamento del modello ai dati, dati i gradi di libertà aggiuntivi.\n\nSe il valore p associato al $\\chi^2$ del modello più complesso è significativamente più basso rispetto a quello del modello più semplice, questo suggerisce che l'aggiunta dei parametri fornisce un miglioramento significativo nell'adattamento del modello. Al contrario, se non vi è un miglioramento significativo, si può concludere che il modello più semplice è preferibile in termini di parsimonia e adattamento.\n\n## Chi Quadrato Normalizzato (NC)\n\nIl Chi Quadrato Normalizzato (NC) emerge come un tentativo di attenuare l'effetto della dimensione del campione sulla statistica del chi quadrato del modello ($\\chi^2$). Questa pratica, adottata da alcuni ricercatori, consiste nel dividere $\\chi^2$ per il numero dei gradi di libertà del modello (dfM), risultando nella formula $\\frac{\\chi_{ML}}{dfM}$. Nonostante l'intento di mitigare l'impatto della dimensione del campione (N), l'impiego di NC presenta limitazioni sostanziali:\n\n1. **Influenza di N sui Modelli Erronei**: La statistica $\\chi_{ML}$ è sensibile a N esclusivamente per i modelli non corretti. Questo implica che l'uso di NC per modelli veritieri potrebbe essere fuorviante.\n2. **Indipendenza di dfM da N**: I gradi di libertà del modello (dfM) non sono correlati con la dimensione del campione, rendendo la divisione di $\\chi_{ML}$ per dfM arbitraria e priva di fondamento statistico.\n3. **Mancanza di Linee Guida**: Non esistono criteri consolidati che definiscano i limiti \"accettabili\" per il valore di NC. Per esempio, non è chiaro se un valore massimo di NC debba essere inferiore a 2.0, 3.0, o altro.\n\nIn conclusione, data la mancanza di una solida giustificazione statistica o logica, @kline2023principles sconsiglia l'utilizzo del Chi Quadrato Normalizzato come strumento di valutazione della bontà di adattamento del modello.\n\n## Chi Quadrato Scalato e Errori Standard Robusti per Distribuzioni Non Normali\n\nNell'ambito dell'analisi di massima verosimiglianza (ML), sia l'approccio ML standard che quello robusto forniscono le stesse stime dei parametri. Tuttavia, il ML robusto differisce nell'introduzione di chi quadrati scalati ($\\chi^2$ scalati) e di errori standard robusti, i quali sono adattati per controbilanciare gli effetti della non normalità dei dati. \n\n### Chi Quadrato Scalato di Satorra-Bentler\n\nUn metodo sviluppato da Satorra e Bentler, che si basa sull'utilizzo di dati completi, calcola il chi quadrato scalato ($\\chi_{SB}$) applicando un fattore di correzione di scala, indicato con $c$, al valore del chi quadrato non scalato del modello ($\\chi_{ML}$). Questo fattore di scala $c$ è determinato dalla curtosi multivariata media osservata nei dati grezzi. La formula specifica per il calcolo di $\\chi_{SB}$ è:\n\n$$\n\\chi_{SB} = \\frac{\\chi_{ML}}{c}.\n$$\n\nQuesta formula evidenzia come il chi quadrato scalato di Satorra-Bentler modifica il chi quadrato tradizionale per tenere conto della curtosi nei dati, fornendo così una misura più affidabile della bontà di adattamento del modello in presenza di distribuzioni non normali.\n\nLe distribuzioni di $\\chi_{SB}$ tendono ad avvicinarsi alle distribuzioni chi quadrato centrali, ma con una caratteristica fondamentale: le loro medie sono asintoticamente corrette. Questo significa che, su larga scala, $\\chi_{SB}$ fornisce una stima media accurata della discrepanza tra i dati osservati e quelli previsti dal modello, correggendo per eventuali distorsioni causate dalla non normalità dei dati.\n\n### Chi Quadrato Scalato di Asparouhov e Muthén\n\nUn altro tipo di chi quadrato, sviluppato da Asparouhov e Muthén, non si basa sul $\\chi_{ML}$ standard. Invece, nei campioni di grandi dimensioni, il loro chi quadrato scalato corrisponde alla statistica T2* di Yuan e Bentler. Questa versione del chi quadrato è particolarmente adatta per gestire dati non normali o con valori mancanti. I gradi di libertà, sia per $\\chi_{SB}$ che per T2*, sono rappresentati da dfM, indicando la flessibilità del modello in termini di numero di parametri stimabili.\n\n### Altri Chi Quadrato Corretti\n\nAl di là di questi, esistono chi quadrati che sono corretti sia per la media che per la varianza. Questi chi quadrati utilizzano fattori di scala diversi e, in genere, seguono distribuzioni chi quadrato centrali con medie e varianze che sono corrette in modo asintotico. Sebbene questi metodi richiedano maggiori risorse computazionali rispetto ai metodi che correggono solo per la media, tendono ad essere più precisi, specialmente in campioni di grandi dimensioni. Questa precisione aggiuntiva è particolarmente utile quando si affrontano set di dati complessi o di ampie dimensioni, permettendo una stima più accurata della bontà di adattamento del modello.\n\n### Metodi Robusti con `lavaan`\n\nIl pacchetto `lavaan` offre diverse opzioni per implementare metodi robusti di stima basati sulla massima verosimiglianza (ML). Questi metodi sono particolarmente utili in presenza di deviazioni dalle assunzioni di normalità multivariata. Ecco le principali opzioni disponibili:\n\n1. **MLM**: Utilizzato per dati completi, calcola un chi-quadrato scalato secondo il metodo di Satorra-Bentler basato sulla media.\n2. **MLR**: Applicabile sia a dati completi che incompleti, genera un chi-quadrato corretto per la media basato sulla statistica T2* di Yuan-Bentler. È particolarmente indicato per analisi con dati mancanti.\n3. **MLMV**: Per dati completi, produce un chi-quadrato scalato corretto per la media e la varianza.\n4. **MLMVS**: Adatto a dati completi, utilizza una correzione per eteroschedasticità basata sul metodo di Satterthwaite, calcolando un chi-quadrato corretto per media e varianza.\n\n#### La Matrice di Informazione in `lavaan`\n\nUn concetto centrale per i metodi ML robusti è la **matrice di informazione**, utilizzata per stimare gli errori standard dei parametri. Questa matrice rappresenta la varianza e la covarianza dei parametri stimati ed è cruciale per testare ipotesi e costruire intervalli di credibilità o confidenza. In `lavaan`, la matrice di informazione può essere calcolata in due modi:\n\n1. **Matrice di Informazione Attesa**: È l'opzione predefinita per il calcolo degli errori standard. Questa matrice si basa sulle aspettative teoriche delle varianze e covarianze dei parametri stimati, derivate dal modello e dai dati. È generalmente utilizzata in condizioni di dati completi e normali.\n\n2. **Matrice di Informazione Osservata**: Viene impiegata quando sono presenti dati mancanti. In questo caso, le varianze e covarianze vengono calcolate utilizzando i dati effettivamente osservati. Questo approccio può fornire stime degli errori standard più affidabili in presenza di incompletezza nei dati.\n\nGli utenti possono scegliere esplicitamente quale matrice utilizzare, ad esempio forzando l'uso della matrice attesa anche con dati incompleti, in base alle esigenze specifiche della loro analisi.\n\n#### Considerazioni Etiche e Metodologiche\n\nÈ essenziale utilizzare questi strumenti in modo rigoroso e trasparente. Selezionare metodi o combinazioni di chi-quadrati scalati ed errori standard robusti solo per ottenere risultati che meglio supportano le proprie ipotesi compromette l'integrità della ricerca. Per questo motivo, i ricercatori dovrebbero:\n\n- Dichiarare chiaramente i metodi utilizzati, incluso il tipo di matrice di informazione scelta.\n- Segnalare eventuali variazioni nei risultati legate alla scelta del metodo.\n- Garantire che le analisi siano guidate da principi metodologici, non da convenienze interpretative.\n\nQueste buone pratiche sono fondamentali per mantenere l’affidabilità e la credibilità delle analisi svolte.\n\n## Indicizzazione dell'Adattamento del Modello\n\nL'indicizzazione dell'adattamento del modello si basa sull'uso di indici di adattamento approssimati, i quali si differenziano dai test di significatività tradizionali. Invece di fornire una decisione dicotomica, come il rifiuto o l'accettazione di un'ipotesi nulla, questi indici offrono una misura continua di quanto bene un modello si adatta ai dati osservati. Non essendoci una separazione netta tra i limiti dell'errore di campionamento, gli indici di adattamento forniscono una valutazione più sfumata e graduale della bontà di adattamento.\n\nQuesti indici possono essere classificati in due categorie principali:\n\n1. **Statistiche di Cattivo Adattamento**: In questa categoria, valori più elevati indicano un peggior adattamento del modello ai dati. Un esempio tipico di questa categoria è il chi quadrato del modello, dove valori più alti suggeriscono una maggiore discrepanza tra il modello e i dati.\n2. **Statistiche di Buon Adattamento**: Al contrario, per gli indici in questa categoria, valori più alti segnalano un migliore adattamento del modello ai dati. Molti di questi indici sono normalizzati in modo che il loro intervallo varii da 0 a 1.0, dove 1.0 rappresenta l'adattamento ottimale del modello.\n\nA differenza del test del chi quadrato, che si basa su un framework teorico ben definito, l'interpretazione e l'applicazione degli indici di adattamento approssimati non sono guidate da un unico insieme di principi teorici consolidati. Questa situazione fa sì che la valutazione dell'adattamento del modello si allinei maggiormente a ciò che Little (2013) ha descritto come \"scuola di modellazione\". Questo approccio contempla l'analisi di modelli statistici complessi in un contesto in cui le regole decisionali sono meno rigide e più soggette a interpretazione. \n\nLa natura flessibile di questo approccio rispecchia la varietà e la complessità dei modelli statistici, che devono essere personalizzati per rispondere a specifiche domande di ricerca. Questa flessibilità, tuttavia, porta con sé una certa ambiguità nelle regole di valutazione dei modelli statistici. Pur offrendo la possibilità di adattare l'analisi alle particolarità di ogni studio, questa mancanza di rigore teorico uniforme può talvolta non tradursi in pratiche ottimali di modellazione. \n\nLa questione filosofica relativa all'adattamento esatto dei modelli statistici solleva dubbi sull'idea di perfezione come standard per questi modelli. In effetti, è ampiamente riconosciuto che tutti i modelli statistici sono in qualche misura imperfetti; sono piuttosto strumenti di approssimazione che aiutano i ricercatori a organizzare e interpretare le loro osservazioni sui fenomeni di interesse. Un modello troppo semplificato, che non cattura la complessità del fenomeno, può essere inadeguato e quindi rifiutato. Allo stesso tempo, un modello eccessivamente complesso, che cerca di replicare fedelmente il fenomeno, può risultare di scarsa utilità scientifica a causa della sua complessità eccessiva.\n\nGeorge Box, nel suo influente lavoro del 1976, avanzò l'idea che nessun modello statistico potesse essere considerato perfettamente \"corretto\". Questa visione nasce dalla consapevolezza che tutti i modelli hanno una certa dose di imperfezione intrinseca. Box suggeriva che lo scopo principale di uno scienziato dovrebbe essere la ricerca di una \"descrizione economica\" dei fenomeni naturali, cercando cioè di formulare modelli che siano semplici, ma al contempo efficaci, nella rappresentazione della realtà. Egli criticava la tendenza a sovraelaborare o sovraparametrizzare i modelli, considerandola un segno di mediocrità nella pratica scientifica. Box enfatizzava l'importanza di concentrarsi sugli errori sostantivi, o \"tigri\", piuttosto che su piccole imperfezioni, o \"topi\", affermando:\n\n> \"Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\"\n\nCiò implica che l'obiettivo nella modellazione statistica non dovrebbe essere una perfezione irraggiungibile, ma piuttosto lo sviluppo di modelli che, pur nella loro semplicità, riescano a cogliere gli aspetti fondamentali dei fenomeni analizzati. Questo richiede un equilibrio tra la complessità necessaria per una descrizione accurata e la semplicità che rende un modello pratico e interpretabile.\n\n@hayduk2014shame, nel commentare l'affermazione di Box, si focalizza specificatamente sul contesto della modellizzazione SEM (Structural Equation Modeling). Egli identifica le \"tigri\", ovvero gli errori gravi nei modelli, come indicatori di una specificazione errata del modello. Hayduk sottolinea l'importanza critica di riconoscere e correggere gli errori significativi piuttosto che disperdere energie su dettagli minori. In sostanza, Hayduk rafforza l'idea che è essenziale distinguere tra errori minori e maggiori, questi ultimi potendo compromettere seriamente la validità e l'utilità di un modello statistico.\n\n## Tipologie di Indici di Adattamento Approssimati\n\nGli indici di adattamento approssimati possono essere classificati in diverse categorie, che riflettono diversi aspetti della bontà di adattamento di un modello statistico ai dati. Sebbene questa classificazione non sia esaustiva né le categorie siano mutualmente esclusive, i tipi principali di indici di adattamento sono i seguenti:\n\n1. **Indici di Adattamento Assoluto**: Questi indici, come il GFI (Goodness of Fit Index), misurano quanto bene un modello spiega i dati senza riferimento ad altri modelli. Indicano l'abilità del modello di riprodurre i dati osservati.\n\n2. **Indici di Adattamento Parsimonioso**: Questi indici confrontano i gradi di libertà del modello (dfM) con il numero massimo possibile di gradi di libertà disponibili nei dati. Un esempio è l'AGFI (Adjusted Goodness of Fit Index), che incorpora una penalità per la complessità del modello, benché non sia un indice di adattamento parsimonioso come definito in questa categoria.\n\n3. **Indici di Adattamento Incrementale (Relativo o Comparativo)**: Questi indici confrontano l'adattamento del modello del ricercatore con quello di un modello di base, tipicamente un modello di indipendenza che assume covarianze nulle tra le variabili osservate. È possibile scegliere un modello di base diverso, sebbene il calcolo manuale dell'indice possa essere necessario se il modello di base desiderato differisce da quello predefinito nel software.\n\n4. **Indici di Adattamento Non Centrale**: Stimano il grado in cui l'ipotesi di adattamento esatto è falsa, dati il modello e i dati. Questi indici approssimano parametri nelle distribuzioni chi quadrato non centrali, che descrivono anche le distribuzioni campionarie per gli indici di adattamento di questo tipo.\n\n5. **Indici di Adattamento Predittivo (o basati sulla Teoria dell'Informazione)**: Derivati dalla teoria dell'informazione, stimano l'adattamento del modello in campioni di replica ipotetici della stessa dimensione, estratti casualmente dalla stessa popolazione del campione originale. Sono utilizzati principalmente per confrontare modelli alternativi basati sulle stesse variabili e adattati agli stessi dati, ma dove i modelli non sono gerarchicamente correlati.\n\nNon tutti gli indici di adattamento approssimati hanno resistito alla prova del tempo. Ad esempio, gli indici di adattamento parsimonioso non hanno mai raggiunto una popolarità significativa tra i ricercatori applicati, restando relativamente oscuri. Altri indici, come il GFI e l'AGFI, sono stati criticati per la loro sensibilità alla dimensione del campione e al numero di indicatori nei modelli di analisi fattoriale.\n\nI software moderni per la Structural Equation Modeling (SEM) presentano una notevole varietà nel numero di indici di adattamento approssimati forniti nei loro output. Programmi come Amos e LISREL elencano un numero elevato di indici (oltre 12), mentre altri come lavaan e Mplus ne includono un numero più limitato (circa 4-5). Questa abbondanza di indici può portare al rischio di \"cherry-picking\", cioè la tendenza a selezionare e riportare solo quegli indici che mostrano risultati favorevoli al modello proposto dal ricercatore. Per mitigare questo rischio, è consigliabile limitarsi a un insieme essenziale di indici e prestare attenzione all'analisi dei residui.\n\n### Modello Baseline\n\nIl modello baseline, noto anche come modello nullo, è un modello in cui tutte le covarianze sono impostate a zero, mentre le varianze sono stimate liberamente. In questo modello, non si stimano i carichi fattoriali; ci si limita invece a stimare le medie e le varianze osservate, eliminando tutte le covarianze tra le variabili.\n\nÈ utile pensare al modello nullo o baseline come il peggior modello possibile, da confrontare poi con il modello saturato, che rappresenta invece la migliore approssimazione ai dati. Teoricamente, il modello baseline è fondamentale per comprendere come vengono calcolati altri indici di adattamento del modello, in quanto fornisce un punto di riferimento iniziale per la valutazione della bontà di adattamento in un contesto di Modelli di Equazioni Strutturali.\n\n### Set di Indici di Adattamento Consigliati\n\n@kline2023principles suggerisce un insieme essenziale di soli tre indici di adattamento approssimati, che sono ampiamente utilizzati nei software SEM e frequentemente presenti negli studi pubblicati. Questi indici sono stati selezionati per le seguenti ragioni:\n\n1. **Ampia Presenza nella Letteratura**: Sono ampiamente riportati in numerosi studi SEM, rendendoli familiari sia ai ricercatori che ai revisori.\n\n2. **Standardizzazione**: Le scale di questi indici non dipendono dalle variabili osservate o latenti, fornendo così una misura standardizzata di adattamento.\n\n3. **Validità Statistica Estesa**: Almeno uno di questi indici, l'RMSEA, possiede un solido fondamento statistico e un quadro interpretativo più ampio per la stima degli intervalli, i test delle ipotesi e la pianificazione della dimensione del campione.\n\nNonostante la loro utilità, è fondamentale usare questi indici con attenzione. I ricercatori dovrebbero evitare l'uso acritico di soglie o punti di taglio, sia fissi sia variabili, che si suppone differenzino tra modelli con un buon o cattivo adattamento. L'applicazione di queste soglie può essere problematica, poiché non sono valide universalmente per tutti i tipi di modelli e set di dati. L'uso improprio di tali soglie può portare a decisioni errate, in particolare se si trascura l'analisi dei residui.\n\nIl gruppo principale di tre indici di adattamento approssimati raccomandato comprende:\n\n1. **Root Mean Square Error of Approximation (RMSEA) di Steiger-Lind** (Steiger, 1990), accompagnato dal suo intervallo di confidenza al 90%. L'RMSEA valuta l'adattamento assoluto del modello, penalizzando la complessità del modello, ma non è un indice di adattamento parsimonioso. È un indice di cattivo adattamento dove il valore zero rappresenta l'adattamento ideale, senza un limite massimo teorico.\n\n2. **Comparative Fit Index (CFI) di Bentler** (Bentler, 1990). Il CFI è un indice di adattamento incrementale e valuta la bontà di adattamento relativa del modello rispetto a un modello di base. Si estende su una scala da 0 a 1.0, dove 1.0 indica l'adattamento ottimale, e non impone penalità per la complessità del modello.\n\n3. **Standardized Root Mean Square Residual (SRMR)** (Jöreskog & Sörbom; 1981). L'SRMR è un indice di adattamento assoluto che misura la discrepanza tra le correlazioni osservate e quelle previste dal modello. Un valore di zero indica un adattamento perfetto.\n\nSia l'RMSEA sia il CFI incorporano il chi quadrato del modello e i suoi gradi di libertà nelle loro formule. Questo implica che condividono le stesse assunzioni distributive della corrispondente statistica di test. Se tali assunzioni non sono valide, i valori degli indici e della statistica di test (incluso il valore p) potrebbero non essere accurati. Entrambi gli indici sono stati inizialmente definiti per dati continui con distribuzioni normali analizzati tramite ML standard. Tuttavia, in presenza di dati significativamente non normali, i valori di chiML, RMSEA e CFI possono risultare distorti. Alcuni software SEM implementano correzioni ad hoc per la non normalità.\n\n\n## Misure di adeguamento per il confronto\n\n### CFI\n\nGli indici di *adattamento comparativo* [detti anche *indici di adattamento incrementale*; ad es. @hu1998fit] valutano l'adattamento di una soluzione specificata dall'utente in relazione a un modello di base nidificato più ristretto. Tipicamente, il modello base è un modello \"nullo\" o \"di indipendenza\" in cui le covarianze tra tutti gli indicatori di input sono fissate a zero, ma nessun vincolo viene posto sulle varianze degli indicatori. Uno di questi indici, l'*indice di adattamento comparativo* (*comparative fit index*, CFI; Bentler, 1990). Il CFI si basa su un confronto relativo, situando il modello di interesse lungo un continuum che va dal modello peggiore (nullo) al modello perfetto (saturo).\n\nIl CFI valuta la **riduzione relativa del parametro di non-centralità** ($\\lambda$) tra il modello di interesse e il modello di riferimento (Bentler, 1990). Il parametro di non-centralità $\\lambda_m$ rappresenta il grado di errore di specificazione del modello $m$ ed è calcolato come:\n\n$$\n\\lambda_m = \\chi^2_m - \\text{df}_m,\n$$\n\ndove $\\chi^2_m$ è il valore chi-quadro stimato per il modello e $\\text{df}_m$ rappresenta i gradi di libertà. Più alto è $\\lambda_m$, maggiore è la discrepanza tra il modello e i dati osservati. Il valore del CFI si basa sul rapporto tra i parametri di non-centralità del modello di interesse ($\\lambda_m$) e del modello nullo ($\\lambda_b$):\n\n$$\nCFI(m, b) = 1 - \\frac{\\lambda_m}{\\lambda_b} = 1 - \\frac{\\chi^2_m - \\text{df}_m}{\\chi^2_b - \\text{df}_b}.\n$$\n\nIl valore del CFI varia generalmente tra 0 e 1 (anche se in casi particolari può superare 1 o essere negativo), dove un valore vicino a 1 indica un buon adattamento del modello rispetto al modello nullo.\n\n#### Modello nullo come baseline\nIl **modello nullo** è un modello in cui tutte le variabili osservate sono considerate non correlate. Il CFI misura quindi quanto il modello di interesse riesce a migliorare l'adattamento rispetto a questo modello di riferimento, in modo analogo al concetto di $R^2$ per la regressione lineare.\n\n#### Sensibilità ai dati e alle caratteristiche del modello\nIl comportamento del CFI è influenzato da tre fattori principali:\n\n1. **Dimensione del campione ($n$)**: Campioni più grandi aumentano il parametro di non-centralità del modello nullo ($\\lambda_b$), migliorando la capacità del CFI di distinguere tra modelli.\n2. **Numero di variabili osservate ($p$)**: Un numero elevato di variabili può complicare l'interpretazione del CFI, poiché aumenta i gradi di libertà del modello nullo, riducendo la non-centralità $\\lambda_b$.\n3. **Correlazione tra variabili ($R$)**: Maggiore è la correlazione tra le variabili, più il modello nullo differisce dai dati, e più il CFI può differenziare tra modelli.\n\n#### Regole empiriche\nValori del CFI superiori a 0.90 erano considerati accettabili in passato (Bentler & Bonett, 1980), mentre valori superiori a 0.95 sono oggi considerati indicativi di un buon adattamento (Hu & Bentler, 1999). Tuttavia, studi di simulazione più recenti, come quelli di Fan e Sivo nel 2005 e di Yuan nel 2005, hanno messo in dubbio l'universalità di un valore soglia specifico per il CFI, evidenziando che l'adeguatezza di tale valore può variare a seconda delle caratteristiche dei modelli e del grado di non normalità nei dati. Di conseguenza, è importante non applicare queste regole in modo meccanico, ma valutare il contesto specifico. Inoltre, Brosseau-Liard e Savalei (2014) hanno descritto delle versioni robuste del CFI adatte per dati non normali. Queste versioni del CFI sono calcolate e fornite dal software `lavaan` quando si utilizzano metodi di stima Maximum Likelihood (ML) robusti. Questo implica che, quando si lavora con dati che presentano deviazioni dalla normalità, queste versioni robuste del CFI possono offrire una misura più affidabile dell'adattamento del modello.\n\n#### Variabilità campionaria\nA livello di popolazione, un modello corretto dovrebbe avere un valore di CFI pari a 1. Tuttavia, la variabilità campionaria può influenzare il parametro di non-centralità $\\lambda_m$ e $\\lambda_b$, causando deviazioni rispetto alle aspettative teoriche. Questo fenomeno è particolarmente rilevante nei campioni piccoli o in presenza di modelli complessi.\n\n## Misure di adeguamento parsimonioso\n\n### TLI \n\nUn indice che rientra nella degli indici di adeguamento parsimonioso è l'*indice Tucker-Lewis* (*Tucker–Lewis index*, TLI, anche chiamato indice di adattamento non normato). Il TLI si pone il problema di penalizzare la complessità del modello, ovvero include una funzione di penalizzazione per l'addizione di parametri che non migliorano in maniera sostanziale l'adattamento del modello. Il TLI è calcolato con la seguente formula:\n\n$$\n\\begin{equation}\nTLI = \\frac{(\\chi^2_B / dof_B)–(\\chi^2_T / dof_T)}{(\\chi^2_B / dof_B) – 1},\n\\end{equation}\n$$\n\ndove $\\chi^2_T$ è il valore $\\chi^2$ del modello target, $dof_T$ sono i gradi di libertà del modello target, $\\chi^2_B$ è il valore $\\chi^2$ del modello baseline e $dof_B$ sono i gradi di libertà del modello base.\n\nL'Indice di Tucker-Lewis (TLI) può, in teoria, assumere valori inferiori a zero se il modello di base, ovvero un modello diverso da quello studiato dal ricercatore, mostra un ottimo adattamento ai dati. Tuttavia, questa eventualità è rara nella pratica. Al contrario, il TLI può superare il valore di 1.0 se il modello analizzato dal ricercatore si adatta in modo particolarmente stretto ai dati. Marsh e Balla (1994) hanno evidenziato che la dimensione del campione influenza poco i valori del TLI.\n\nSecondo quanto osservato da Kenny (2020), si possono trarre due conclusioni importanti:\n\n1. Il Comparative Fit Index (CFI) e il TLI sono entrambi influenzati dall'entità delle correlazioni tra le variabili misurate. Ciò significa che valori medi di correlazione più elevati risultano in valori più alti sia per il CFI che per il TLI, e il contrario è vero per correlazioni medie più basse.\n2. I valori del CFI e del TLI mostrano una forte correlazione tra loro. Di conseguenza, è consigliabile riportare solo uno dei due indici per evitare ripetizioni e per mantenere la chiarezza del report. La scelta tra CFI e TLI dovrebbe basarsi su criteri specifici relativi al contesto e agli obiettivi dello studio in questione.\n\n\n## Misure di Adeguamento Assoluto\n\n### Root Mean Square Error of Approximation (RMSEA)\n\nL'Errore Quadratico Medio di Approssimazione (RMSEA) misura quanto bene un modello statistico si adatta ai dati osservati, valutando l'adattamento in termini assoluti, piuttosto che confrontarlo con un modello di riferimento (come fanno indici quali CFI e TLI). \n\nIl calcolo del RMSEA si basa sul chi-quadrato ($\\chi^2$), che rappresenta la discrepanza tra la matrice di covarianza osservata e quella stimata dal modello. La discrepanza, indicata con $\\delta$, è definita come:\n\n$$\n\\delta = \\chi^2 - df,\n$$\n\ndove $df$ rappresenta i gradi di libertà del modello. Valori più alti di $\\delta$ indicano una maggiore discrepanza, ossia un peggior adattamento del modello ai dati.\n\nLa formula generale per il calcolo del RMSEA è:\n\n$$\n\\text{RMSEA} = \\sqrt{\\frac{\\max(0, \\delta)}{df \\cdot (n - 1)}},\n$$\n\ndove $n$ è il numero di osservazioni nel campione. Questo indice riflette l'errore di approssimazione del modello rispetto alla matrice di covarianza della popolazione, tenendo conto della parsimonia del modello (ossia del numero di gradi di libertà).\n\n### Distribuzione del Chi-Quadrato e Non Centralità\n\nAssumendo che:\n\n- i dati seguano una distribuzione normale multivariata;\n- il modello sia corretto;\n- il campione sia grande e casuale;\n\nil chi-quadrato del modello ($\\chi^2_{\\text{ML}}$) segue una distribuzione $\\chi^2$ con $df_M$ gradi di libertà. Tuttavia, se il modello non è corretto, il chi-quadrato segue una distribuzione non centrale $\\chi^2(df_M, \\lambda)$, dove $\\lambda$ rappresenta il parametro di non centralità, che indica il grado di discrepanza tra il modello e i dati.\n\nIl parametro di non centralità normalizzato è definito come:\n\n$$\n\\delta_{\\text{norm}} = \\max(0, \\chi^2_{\\text{ML}} - df_M).\n$$\n\nQuesto valore è utilizzato per stimare la discrepanza tra la matrice di covarianza osservata e quella della popolazione sotto il modello.\n\n### Formula Finale del RMSEA\n\nIl valore finale del RMSEA, indicato spesso con $\\epsilon$, è calcolato come:\n\n$$\n\\epsilon = \\sqrt{\\frac{\\delta_{\\text{norm}}}{df_M \\cdot (n - 1)}}.\n$$\n\nSebbene $\\epsilon$ possa essere una stima distorta a causa della restrizione $\\epsilon \\geq 0$, rappresenta una buona approssimazione dell'errore. \n\n### Soglie Interpretative\n\nBrowne e Cudeck (1993) suggerirono che:\n\n- $\\epsilon \\leq 0.05$ indica un buon adattamento del modello;\n- $0.05 < \\epsilon \\leq 0.08$ rappresenta un adattamento accettabile;\n- $\\epsilon > 0.10$ segnala un cattivo adattamento.\n\nTuttavia, queste soglie non sono universali, e si consiglia di valutare anche il limite superiore dell'intervallo di confidenza di $\\epsilon$ (indicato come $\\epsilon_U$) per un'interpretazione più accurata.\n\n### Considerazioni e Versioni Robuste\n\n1. **Interpretazione:** L'interpretazione di $\\epsilon$, $\\epsilon_L$ (limite inferiore) e $\\epsilon_U$ (limite superiore) è appropriata in campioni ampi e con modelli ben specificati. In campioni piccoli o con errori di specificazione significativi, è necessaria maggiore cautela.\n\n2. **Penalità per Modelli Complessi:** Studi di simulazione indicano che il RMSEA tende a penalizzare maggiormente i modelli con pochi gradi di libertà (ad esempio, modelli con poche variabili).\n\n3. **Versioni Robuste:** Versioni robuste del RMSEA, come quella basata sul chi-quadrato scalato di Satorra-Bentler, correggono gli effetti della non normalità e tendono a essere più accurate rispetto alla versione standard, che può sovrastimare l'indice in condizioni di non normalità.\n\n4. **Potenza Statistica:** Esistono metodi per calcolare la potenza statistica associata a ipotesi nulle basate sul RMSEA e per stimare la dimensione minima del campione necessaria a raggiungere determinati livelli di potenza.\n\nConcludendo, il RMSEA è uno strumento potente per valutare l'adattamento assoluto di un modello, ma il suo utilizzo richiede attenzione alle specifiche del modello, alla qualità dei dati e al contesto dell'analisi.\n\n### Root Mean Square Residual (RMRS)\n\nA differenza del chi quadrato del modello e dei gradi di libertà, che valutano la bontà di adattamento di un modello in base a criteri di adattamento globale, l'indice RMRS (Root Mean Square Residual) si concentra esclusivamente sui residui del modello, ovvero le discrepanze tra le correlazioni osservate e quelle previste dal modello.\n\nLa formula per calcolare l'RMRS è la seguente:\n\n$$ \nRMRS = \\sqrt{ \\frac{2 \\sum_i\\sum_j(r_{ij} - \\hat{r}_{ij})^2}{p(p+1)}}, \n$$\n\ndove:\n\n- $p$ rappresenta il numero di item (variabili) nel modello,\n- $r_{ij}$ è la correlazione osservata tra le variabili $i$ e $j$,\n- $\\hat{r}_{ij}$ è la correlazione prevista dal modello tra le variabili $i$ e $j$.\n\nUn valore di RMRS pari a 0 indica un adattamento perfetto del modello, mentre valori crescenti indicano un adattamento meno preciso. In generale, un valore di SRMR inferiore a 0.08 è considerato favorevole (Hu e Bentler, 1999).\n\nTuttavia, è importante notare che il SRMR è una misura media e può nascondere variazioni significative tra i residui di correlazione individuali. Ad esempio, se il SRMR è 0.03, potrebbe sembrare un buon adattamento. Ma se i residui di correlazione variano da -0.12 a 0.18, con alcuni residui superiori a 0.10, potrebbe indicare problemi di adattamento locali più gravi.\n\nPertanto, quando si riportano i risultati in un report, per ottenere una comprensione più completa dell'adattamento del modello è consigliabile descrivere i residui di correlazione o, meglio ancora, presentare l'intera matrice dei residui, anziché basarsi esclusivamente su un valore medio come il SRMR.\n\n\n### Interpretazione con `lavaan`\n\nL'interpretazione degli indici di bontà di adattamento trovati nella CFA o nella modellazione di equazioni strutturali può essere ottenuta usando le funzioni del pacchetto `effectsize`. \n\n## Adattamento Locale\n\nI modelli SEM possono teoricamente superare i test di adattamento globale ma fallire nei test di adattamento locale. Questi dettagli, relativi all'adattamento del modello, sono esaminati direttamente nei test di adattamento locale. L'analisi dei residui (sia standardizzati che di correlazione) è quindi cruciale per una valutazione completa del modello (Maydeu-Olivares e Shi, 2017). Le recenti norme di reportistica per il SEM richiedono agli autori di descrivere sia l'adattamento globale che quello locale (Appelbaum et al., 2018); Greiff e Heene, 2017; Vernon e Eysenck, 2007).\n\n### Residui di Covarianza, Residui Standardizzati, Residui Normalizzati\n\n1. **Residui di Covarianza**: Sono le differenze tra le covarianze osservate e quelle previste dal modello. Questi residui possono essere difficili da interpretare perché non sono standardizzati, ovvero la loro metrica dipende dalle scale delle variabili coinvolte. Pertanto, residui di covarianza per coppie di variabili diverse non sono direttamente confrontabili a meno che tutte le variabili non siano sulla stessa metrica.\n\n2. **Residui Standardizzati**: Sono versioni standardizzate dei residui di covarianza, interpretati come un test z in campioni grandi. Un residuo standardizzato significativamente diverso da zero indica una discrepanza tra modello e dati. Tuttavia, la significatività di questi residui può dipendere dalla dimensione del campione, con residui vicini allo zero che possono essere significativi in campioni grandi, mentre residui relativamente grandi potrebbero non essere significativi in campioni piccoli.\n\n3. **Residui Normalizzati**: Sono i rapporti tra i residui di covarianza e l'errore standard della covarianza campionaria. Sono generalmente più conservativi dei residui standardizzati in termini di test di significatività. In modelli complessi, quando non è possibile calcolare il denominatore di un residuo standardizzato, il residuo normalizzato fornisce un'alternativa più conservativa.\n\nNel software `lavaan` ci sono due opzioni principali per calcolare i residui di correlazione:\n\n- **Opzione `cor.bollen`**: Questa specifica indica al computer di convertire separatamente le matrici di covarianza del campione e quelle implicite dal modello in matrici di correlazione prima di calcolare i residui. Questo processo comporta la standardizzazione di ciascuna matrice in base alle varianze (deviazioni standard quadrate) presenti nella diagonale principale di ciascuna matrice. Le varianze nella matrice di covarianza del campione sono osservate direttamente, mentre le varianze per le variabili endogene nella matrice di covarianza implicata dal modello sono previste dal modello e possono differire dalle varianze osservate corrispondenti.\n- **Opzione `cor.bentler`**: Questa opzione standardizza sia la matrice di covarianza del campione che quella implicata dal modello basandosi sulle varianze presenti solo nella matrice di covarianza del campione. Poiché non tutti gli elementi della diagonale principale nella matrice di covarianza implicata dal modello sono varianze osservate, alcuni valori dei residui di correlazione del tipo Bentler potrebbero non essere pari a zero. Tuttavia, i valori dei residui fuori diagonale per entrambi i metodi sono generalmente simili.\n\nPer impostazione predefinita, `lavaan` utilizza il metodo `cor.bollen` per calcolare i residui di correlazione nelle sue analisi.\n\n## Esempio Empirico\n\nNel capitolo precedente abbiamo formulato un modello SEM nel quale abbiamo definito una variabile latente con le sei sottoscale della Self-Compassion Scale e una seconda variabile latente con le tre sottoscale della DASS-21. Abbiamo ipotizzato che il fattore dell'autocompassione eserciti un effetto (protettivo) nei confronti del disagio psicologico misurato dal fattore definito dalle sottoscale della DASS-21.\n\nImportiamo i dati in R.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_sc <- read.csv(\"../../data/dass_rosenberg_scs.csv\", header = TRUE)\n```\n:::\n\n\n\n\nDefiniamo il modello SEM.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_sc <- \"\n  F =~ anxiety + depression + stress\n  SC =~ self_kindness\t+ common_humanity\t+ mindfulness\t+ \n        self_judgment\t+ isolation\t+ over_identification\n  F ~ SC\n\"\n```\n:::\n\n\n\n\nAdattiamo il modello.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_sc <- lavaan::sem(mod_sc, d_sc)\n```\n:::\n\n\n\n\nCreiamo un diagramma di percorso.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPlot::semPaths(fit_sc,\n    what = \"col\", whatLabels = \"std\", style = \"mx\", \n    layout = \"tree2\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 8, sizeMan2 = 5\n)\n```\n\n::: {.cell-output-display}\n![](03_gof_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nI coefficienti stimati nel modello SEM appaiono coerenti e in linea con le aspettative, in particolare il coefficiente che descrive l'effetto \"causale\" del fattore dell'autocompassione sul disagio emotivo, che si attesta a -0.48. Questo valore negativo corrobora l'ipotesi secondo cui l'autocompassione svolge un ruolo di fattore protettivo contro il disagio emotivo. Tuttavia, prima di confermare definitivamente questa conclusione, è cruciale esaminare gli indici di bontà di adattamento del modello. Questi indici ci permetteranno di valutare quanto accuratamente il modello SEM si adatta ai dati osservati, fornendo un quadro più chiaro della validità delle nostre inferenze. In altre parole, sebbene il modello suggerisca una relazione negativa tra autocompassione e disagio emotivo, la conferma finale di questa associazione dipenderà dall'adeguatezza complessiva del modello rispetto ai dati.\n\nCalcoliamo gli indici di bontà di adattamento.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitMeasures(fit_sc) \n#>                  npar                  fmin                 chisq \n#>              1.90e+01              4.27e-01              4.49e+02 \n#>                    df                pvalue        baseline.chisq \n#>              2.60e+01              0.00e+00              3.13e+03 \n#>           baseline.df       baseline.pvalue                   cfi \n#>              3.60e+01              0.00e+00              8.63e-01 \n#>                   tli                  nnfi                   rfi \n#>              8.11e-01              8.11e-01              8.01e-01 \n#>                   nfi                  pnfi                   ifi \n#>              8.56e-01              6.19e-01              8.64e-01 \n#>                   rni                  logl     unrestricted.logl \n#>              8.63e-01             -1.23e+04             -1.21e+04 \n#>                   aic                   bic                ntotal \n#>              2.47e+04              2.47e+04              5.26e+02 \n#>                  bic2                 rmsea        rmsea.ci.lower \n#>              2.47e+04              1.76e-01              1.62e-01 \n#>        rmsea.ci.upper        rmsea.ci.level          rmsea.pvalue \n#>              1.90e-01              9.00e-01              0.00e+00 \n#>        rmsea.close.h0 rmsea.notclose.pvalue     rmsea.notclose.h0 \n#>              5.00e-02              1.00e+00              8.00e-02 \n#>                   rmr            rmr_nomean                  srmr \n#>              1.20e+00              1.20e+00              7.10e-02 \n#>          srmr_bentler   srmr_bentler_nomean                  crmr \n#>              7.10e-02              7.10e-02              7.90e-02 \n#>           crmr_nomean            srmr_mplus     srmr_mplus_nomean \n#>              7.90e-02              7.10e-02              7.10e-02 \n#>                 cn_05                 cn_01                   gfi \n#>              4.65e+01              5.45e+01              8.46e-01 \n#>                  agfi                  pgfi                   mfi \n#>              7.33e-01              4.89e-01              6.69e-01 \n#>                  ecvi \n#>              9.26e-01\n```\n:::\n\n\n\n\nL'analisi degli indici di bontà di adattamento rivela alcune preoccupazioni significative riguardo alla validità del nostro modello SEM. Il rapporto $\\chi^2 / df$ emerge come eccessivamente elevato, segnalando una possibile mancanza di adattamento:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n449.141 / 26\n#> [1] 17.3\n```\n:::\n\n\n\n\nAnalogamente, i valori di CFI e TLI sono inferiori al livello desiderato, suggerendo che il modello non rappresenta adeguatamente la struttura dei dati. In aggiunta, gli indici RMSEA e SRMR superano le soglie accettabili, indicando ulteriormente un'inadeguata aderenza del modello ai dati.\n\nDi fronte a questi risultati, è imprudente accettare la conclusione precedentemente formulata secondo cui l'autocompassione agisce come un fattore protettivo contro il disagio emotivo. Questa interpretazione, benché teoricamente fondata, non trova un solido supporto empirico nel contesto del modello attuale.\n\nIn questa situazione, un percorso costruttivo potrebbe essere quello di rivedere e potenzialmente modificare il modello. L'obiettivo sarebbe quello di esplorare alternative che potrebbero risultare in un migliore adattamento ai dati, mantenendo al contempo l'adeguatezza teorica. Ciò potrebbe includere la revisione delle assunzioni del modello, la riconsiderazione delle variabili incluse o la ristrutturazione delle relazioni ipotizzate tra di esse. Solo attraverso un modello che dimostra una bontà di adattamento adeguata possiamo affermare con maggiore sicurezza che i dati empirici sostengono l'ipotesi dell'effetto protettivo dell'autocompassione sul disagio emotivo.\n\n## Potere Statistico e Precisione\n\nNell'ambito dei modelli di Structural Equation Modeling (SEM), l'analisi della potenza statistica è fondamentale per garantire l'affidabilità e la validità dei risultati. Esistono due approcci principali per quest'analisi: la potenza a priori (prospettica) e la potenza retrospettiva (post hoc, osservata).\n\n1. **Potenza a priori (Prospettica):** Questa analisi viene effettuata prima della raccolta dei dati e mira a stimare la probabilità che uno studio identifichi un effetto significativo, se presente nella popolazione. È cruciale nella pianificazione della ricerca per determinare la dimensione del campione necessaria, aumentando così l'efficienza dello studio e prevenendo l'uso di campioni eccessivamente grandi o inadeguati. In SEM, la potenza a priori si stima specificando nel software le caratteristiche del modello di popolazione, ipotesi nulle e alternative, il livello di significatività statistica e la dimensione campionaria prevista.\n\n2. **Potenza Retrospettiva (Post Hoc, Osservata):** A differenza dell'analisi a priori, questa viene condotta dopo la raccolta dei dati. Le statistiche campionarie vengono trattate come parametri reali della popolazione, ma questa pratica presenta limitazioni significative. Le stime possono essere distorte, e una maggiore potenza osservata non implica necessariamente una forte evidenza a favore delle ipotesi nulle non rifiutate. Inoltre, essendo una misura post hoc, non aiuta nella progettazione proattiva della ricerca.\n\nPer l'analisi della potenza in SEM, sono stati sviluppati diversi metodi, tra cui:\n\n1. Il metodo Satorra–Saris stima la potenza del test del rapporto di verosimiglianza per un singolo parametro.\n2. Il metodo MacCallum–RMSEA si basa sulla RMSEA di popolazione e sulle distribuzioni chi-quadrato non centrali.\n3. Il metodo di simulazione Monte Carlo è un'alternativa moderna e flessibile che non presuppone né risultati continui né stima ML predefinita.\n\nCon l'avanzamento degli strumenti informatici, l'analisi della potenza statistica in SEM è diventata più accessibile:\n\n**Software SEM con Simulazione Monte Carlo:** Software come Mplus e LISREL includono capacità di simulazione Monte Carlo, permettendo di generare dati campionari basati su ipotesi del modello e di valutare la frequenza con cui i risultati significativi vengono ottenuti.\n\n**Metodo Kelley–Lai Precision:** Calcola la dimensione campionaria minima necessaria per stimare parametri come l'indice RMSEA entro un margine di errore specificato.\n\nNel contesto di `R`, le funzioni `semTools::findRMSEApower` e `semTools::findRMSEAsamplesize` del pacchetto `semTools` facilitano queste analisi:\n\n1. `semTools::findRMSEApower`: Determina la potenza di un test SEM data una dimensione specifica del campione, basandosi sull'RMSEA e altri parametri del test.\n   \n2. `semTools::findRMSEAsamplesize`: Calcola la dimensione del campione necessaria per raggiungere una specifica potenza statistica in un test SEM, considerando l'RMSEA e altri criteri come il livello di significatività e la potenza desiderata.\n\nQuesti strumenti sono importanti per ottimizzare la progettazione della ricerca SEM, garantendo campioni adeguati e potenza statistica sufficiente per rilevare gli effetti di interesse.\n\n## Riflessioni Conclusive\n\nNella letteratura SEM, sono state avanzate critiche significative all'uso di indici come RMSEA, CFI e TLI e ai loro valori di cutoff convenzionali [si veda, ad esempio, @barrett2007structural]. Nonostante queste critiche, tali indici continuano a essere ampiamente utilizzati nella ricerca SEM, in assenza di alternative più accettate e praticabili. Come sottolineato da @xia2019rmsea, l'attuale prassi considera valori più elevati di RMSEA e valori più bassi di CFI e TLI come indicativi di un peggior adattamento del modello. Questo ha portato molti ricercatori a modificare i loro modelli per ottimizzare tali indici, spesso spingendoli a concentrarsi esclusivamente su questi criteri.\n\nLa dipendenza eccessiva da RMSEA, CFI e TLI ha condotto a una situazione in cui gli indici di adattamento vengono utilizzati come *unico* criterio per accettare o rifiutare un modello ipotizzato. Ad esempio, se un modello raggiunge soglie considerate \"pubblicabili\" (ad es., RMSEA < .06), viene spesso accettato senza ulteriori miglioramenti. Tuttavia, questa pratica è problematica: affermazioni come \"poiché i valori di RMSEA, CFI e TLI indicano un buon adattamento, questo modello è stato scelto come modello finale\" sono insufficienti e riduttive.\n\nIl raggiungimento di soglie desiderate per questi indici dovrebbe rappresentare solo uno dei fattori da considerare nel processo di selezione del modello. È essenziale che i ricercatori:\n\n1. **Valutino altre opzioni di miglioramento del modello**: Analizzando se esistano modifiche che potrebbero migliorare l'adattamento senza compromettere la validità teorica o la parsimonia.\n   \n2. **Giustifichino le scelte adottate o scartate**: Spiegando chiaramente perché determinate opzioni di miglioramento non sono state applicate e quali sono le implicazioni di tali decisioni.\n\n3. **Considerino le conseguenze scientifiche e pratiche**: Valutando l'impatto delle scelte di modellazione sulle conclusioni scientifiche e, quando pertinente, sulle applicazioni cliniche.\n\nIn sintesi, affidarsi esclusivamente a soglie arbitrarie per RMSEA, CFI e TLI non è sufficiente per determinare la qualità di un modello. Un approccio più integrato e critico, che tenga conto di considerazioni teoriche, pratiche e metodologiche, è necessario per garantire che i modelli scelti siano solidi e utili per rispondere alle domande di ricerca.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] effectsize_1.0.0   rsvg_2.6.1         DiagrammeRsvg_0.1 \n#>  [4] lme4_1.1-36        Matrix_1.7-2       mvnormalTest_1.0.0\n#>  [7] lavaanPlot_0.8.1   lavaanExtra_0.2.1  ggokabeito_0.1.0  \n#> [10] see_0.10.0         MASS_7.3-64        viridis_0.6.5     \n#> [13] viridisLite_0.4.2  ggpubr_0.6.0       ggExtra_0.10.1    \n#> [16] gridExtra_2.3      patchwork_1.3.0    bayesplot_1.11.1  \n#> [19] semTools_0.5-6     semPlot_1.1.6      lavaan_0.6-19     \n#> [22] psych_2.4.12       scales_1.3.0       markdown_1.13     \n#> [25] knitr_1.49         lubridate_1.9.4    forcats_1.0.0     \n#> [28] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.4       \n#> [31] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n#> [34] ggplot2_3.5.1      tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2       later_1.4.1         datawizard_1.0.0   \n#>   [4] XML_3.99-0.18       rpart_4.1.24        lifecycle_1.0.4    \n#>   [7] Rdpack_2.6.2        rstatix_0.7.2       rprojroot_2.0.4    \n#>  [10] lattice_0.22-6      insight_1.0.2       rockchalk_1.8.157  \n#>  [13] backports_1.5.0     magrittr_2.0.3      openxlsx_4.2.8     \n#>  [16] Hmisc_5.2-2         rmarkdown_2.29      httpuv_1.6.15      \n#>  [19] qgraph_1.9.8        zip_2.3.2           pbapply_1.7-2      \n#>  [22] minqa_1.2.8         RColorBrewer_1.1-3  ADGofTest_0.3      \n#>  [25] multcomp_1.4-28     abind_1.4-8         quadprog_1.5-8     \n#>  [28] pspline_1.0-21      nnet_7.3-20         TH.data_1.1-3      \n#>  [31] sandwich_3.1-1      moments_0.14.1      nortest_1.0-4      \n#>  [34] arm_1.14-4          codetools_0.2-20    tidyselect_1.2.1   \n#>  [37] farver_2.1.2        stats4_4.4.2        base64enc_0.1-3    \n#>  [40] jsonlite_1.8.9      Formula_1.2-5       survival_3.8-3     \n#>  [43] emmeans_1.10.7      tools_4.4.2         Rcpp_1.0.14        \n#>  [46] glue_1.8.0          mnormt_2.1.1        xfun_0.50          \n#>  [49] withr_3.0.2         numDeriv_2016.8-1.1 fastmap_1.2.0      \n#>  [52] boot_1.3-31         digest_0.6.37       mi_1.1             \n#>  [55] timechange_0.3.0    R6_2.6.1            mime_0.12          \n#>  [58] estimability_1.5.1  colorspace_2.1-1    gtools_3.9.5       \n#>  [61] jpeg_0.1-10         copula_1.1-5        DiagrammeR_1.0.11  \n#>  [64] generics_0.1.3      data.table_1.16.4   corpcor_1.6.10     \n#>  [67] htmlwidgets_1.6.4   parameters_0.24.1   pkgconfig_2.0.3    \n#>  [70] sem_3.1-16          gtable_0.3.6        pcaPP_2.0-5        \n#>  [73] htmltools_0.5.8.1   carData_3.0-5       png_0.1-8          \n#>  [76] reformulas_0.4.0    rstudioapi_0.17.1   tzdb_0.4.0         \n#>  [79] reshape2_1.4.4      coda_0.19-4.1       visNetwork_2.1.2   \n#>  [82] checkmate_2.3.2     nlme_3.1-167        curl_6.2.0         \n#>  [85] nloptr_2.1.1        zoo_1.8-12          parallel_4.4.2     \n#>  [88] miniUI_0.1.1.1      foreign_0.8-88      pillar_1.10.1      \n#>  [91] grid_4.4.2          vctrs_0.6.5         promises_1.3.2     \n#>  [94] car_3.1-3           OpenMx_2.21.13      xtable_1.8-4       \n#>  [97] cluster_2.1.8       htmlTable_2.4.3     evaluate_1.0.3     \n#> [100] pbivnorm_0.6.0      mvtnorm_1.3-3       cli_3.6.4          \n#> [103] kutils_1.73         compiler_4.4.2      rlang_1.1.5        \n#> [106] ggsignif_0.6.4      fdrtool_1.2.18      plyr_1.8.9         \n#> [109] stringi_1.8.4       munsell_0.5.1       gsl_2.1-8          \n#> [112] lisrelToR_0.3       bayestestR_0.15.2   pacman_0.5.1       \n#> [115] V8_6.0.1            hms_1.1.3           stabledist_0.7-2   \n#> [118] glasso_1.11         shiny_1.10.0        rbibutils_2.3      \n#> [121] igraph_2.1.4        broom_1.0.7         RcppParallel_5.1.10\n```\n:::\n",
    "supporting": [
      "03_gof_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "e9853bffb1f84367907edf57546cfdf8",
  "result": {
    "engine": "knitr",
    "markdown": "# Modelli multilivello {#sec-raters-multilevel-models}\n\n::: callout-important\n## In questo capitolo apprenderai come:\n\n- implementare e confrontare i modelli di **complete pooling**, **no pooling** e **partial pooling**, comprendendone le differenze concettuali e applicative;\n- interpretare l'output della funzione `lmer()` e utilizzare le stime dei parametri per analisi e visualizzazioni dei risultati.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Reliability* del testo di @petersen2024principles.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(car, lme4, lavaan, semPlot, repr, kableExtra)\n```\n:::\n\n\n\n:::\n\n## Introduzione \n\nI modelli multilivello, anche denominati modelli gerarchici o a effetti misti, costituiscono un approccio statistico avanzato progettato per analizzare dati organizzati in strutture gerarchiche o nidificate. Tali modelli consentono di modellare simultaneamente variazioni a diversi livelli di aggregazione, come il livello individuale e quello di gruppo, migliorando la precisione dell'inferenza e la comprensione delle dinamiche sottostanti ai dati.\n\nIn psicologia, i modelli multilivello rivestono un ruolo fondamentale, poiché i dati spesso derivano da contesti complessi in cui fattori individuali e ambientali interagiscono. Per esempio, nell’analisi delle prestazioni cognitive o delle risposte emotive, questi modelli permettono di distinguere le variazioni attribuibili a caratteristiche individuali (ad es., abilità cognitiva, tratti di personalità) da quelle dovute a fattori ambientali (ad es., clima scolastico, dinamiche familiari).\n\nLe principali applicazioni dei modelli multilivello includono:\n\n- **Analisi di dati longitudinali**: Gestiscono la dipendenza seriale introdotta da misurazioni ripetute sugli stessi soggetti, migliorando l’accuratezza nell’estimare gli effetti temporali.\n- **Studio dell’impatto di fattori contestuali**: Permettono di quantificare l'influenza dell'ambiente su variabili psicologiche, fornendo stime che isolano gli effetti specifici dei contesti.\n- **Rappresentazione della variabilità intra- e inter-individuale**: Offrono una modellazione flessibile che cattura sia le differenze tra individui sia le fluttuazioni all'interno dello stesso individuo, riflettendo fedelmente la complessità dei processi psicologici.\n\n## Un Esempio Concreto: Analisi dei Dati di Deprivazione del Sonno\n\nQuesto capitolo illustra l'applicazione pratica dei modelli multilivello nell'analisi dei dati di uno studio sperimentale che ha investigato l'effetto della deprivazione del sonno sulle prestazioni psicomotorie. I dati analizzati provengono dalla ricerca di Belenky et al. (2003), che ha esaminato gli effetti cumulativi della restrizione del sonno.\n\n### Accesso ai Dati\n\nI dati utilizzati sono inclusi nel dataset `sleepstudy`, disponibile nel pacchetto `lme4` di R [@bates2014fitting]:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(sleepstudy)\n```\n:::\n\n\n\n\nIl dataset è costituito da 180 osservazioni e contiene tre variabili principali:\n\n- **`Reaction`**: Tempo medio di reazione (in millisecondi).\n- **`Days`**: Numero di giorni consecutivi di deprivazione del sonno.\n- **`Subject`**: Identificativo del partecipante.\n\n### Struttura del Dataset\n\nIl dataset presenta una tipica struttura multilivello: dati longitudinali con misurazioni ripetute del tempo medio di reazione (variabile dipendente) raccolte dai medesimi partecipanti nell’arco di dieci giorni. Tale configurazione è comune in psicologia sperimentale, dove è frequente analizzare variazioni intra-individuali e inter-individuali.\n\nI 18 partecipanti dello studio sono stati sottoposti a una restrizione del sonno di tre ore per notte. Ogni giorno, per dieci giorni consecutivi, hanno eseguito un \"test di vigilanza psicomotoria\" di dieci minuti. Durante il test, i partecipanti monitoravano uno schermo e premevano un pulsante il più rapidamente possibile alla comparsa di uno stimolo visivo. La variabile di interesse è il **tempo medio di reazione (RT)**, utilizzato come indicatore delle prestazioni psicomotorie.\n\n### Analisi Esplorativa\n\n#### Visualizzazione per un Singolo Partecipante\n\nPer iniziare, si può esaminare l’andamento del tempo medio di reazione per un singolo partecipante. Ad esempio, consideriamo il soggetto identificato con `308`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\njust_308 <- sleepstudy |>\n    filter(Subject == \"308\")\n\nggplot(just_308, aes(x = Days, y = Reaction)) +\n    geom_point(size = 2.5) +\n    scale_x_continuous(breaks = 0:9) +\n    labs(title = \"Andamento del tempo di reazione (Soggetto 308)\", \n         x = \"Giorni di deprivazione del sonno\", \n         y = \"Tempo medio di reazione (ms)\"\n    )\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n#### Visualizzazione per Tutti i Partecipanti\n\nPer un'analisi più completa, è utile rappresentare i dati di tutti i 18 partecipanti in un'unica visualizzazione, evidenziando le differenze individuali nelle prestazioni psicomotorie durante il periodo di studio:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleepstudy, aes(x = Days, y = Reaction)) +\n    geom_point(alpha = 0.6) +\n    scale_x_continuous(breaks = 0:9) +\n    facet_wrap(~Subject) +\n    labs(title = \"Andamento del tempo di reazione per tutti i partecipanti\", \n         x = \"Giorni di deprivazione del sonno\", \n         y = \"Tempo medio di reazione (ms)\"\n    )\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQueste visualizzazioni preliminari evidenziano sia le tendenze generali che le differenze individuali nel tempo di reazione in risposta alla deprivazione del sonno. Tali pattern saranno ulteriormente analizzati utilizzando modelli multilivello, che consentono di quantificare le variazioni intra-individuali e inter-individuali, isolando l’effetto cumulativo della deprivazione del sonno.\n\n### Descrizione del Disegno Sperimentale\n\n- **Fase di Adattamento e Baseline**: Lo studio è iniziato con tre giorni preliminari dedicati all'adattamento e all'addestramento (T1 e T2) seguiti dalla misurazione baseline (B). Durante questi giorni, i partecipanti hanno mantenuto un regime di sonno controllato, trascorrendo 8 ore a letto ogni notte (dalle 23:00 alle 07:00). Lo scopo di questa fase era garantire una condizione standardizzata e ridurre la variabilità individuale dovuta a precedenti abitudini di sonno.\n\n- **Condizioni di Restrizione e Prolungamento del Sonno**: A partire dal quarto giorno, i partecipanti sono stati assegnati a diverse condizioni sperimentali per un periodo di sette giorni consecutivi (E1-E7). La durata del tempo trascorso a letto (Time in Bed, TIB) è stata manipolata e variava da un minimo di 3 ore a un massimo di 9 ore, al fine di indurre stati progressivi di deprivazione o recupero del sonno.\n\nNella codifica temporale dello studio:\n- I giorni 0 e 1 rappresentano la fase di adattamento e addestramento.\n- Il giorno 2 corrisponde alla misurazione baseline, che riflette le prestazioni psicomotorie in condizioni di sonno ottimale.\n- I giorni 3-9 rappresentano il periodo sperimentale, durante il quale è stata applicata la manipolazione del sonno.\n\nPer l'analisi, è fondamentale considerare il giorno di baseline (2) come punto di riferimento per valutare gli effetti della manipolazione del sonno sulle prestazioni. I giorni di adattamento e addestramento (0 e 1) devono essere esclusi dall'analisi, poiché le variazioni osservate in questa fase sono attribuibili all'acclimatazione ai protocolli dello studio e non alle condizioni sperimentali di sonno. L'esclusione di questi giorni garantisce che le stime dell'effetto siano focalizzate esclusivamente sull'impatto della restrizione o del prolungamento del sonno.\n\n### Preparazione dei Dati\n\nLa preparazione dei dati è un passaggio essenziale per garantire che l'analisi rifletta accuratamente gli effetti della manipolazione sperimentale. I seguenti passaggi sono stati eseguiti:\n\n1. **Rimozione delle Osservazioni Iniziali**  \n   Le osservazioni relative ai giorni 0 e 1, corrispondenti alla fase di adattamento e addestramento, sono state escluse dal dataset. Questo assicura che l'analisi si concentri esclusivamente sul periodo di interesse, ovvero il baseline (giorno 2) e i successivi giorni di manipolazione del sonno.\n\n2. **Creazione di una Variabile Ricodificata**  \n   È stata generata una nuova variabile, `days_deprived`, per rappresentare il numero di giorni di privazione del sonno a partire dal giorno baseline (giorno 2). La ricodifica inizia con 0 per il giorno baseline, 1 per il primo giorno di privazione (giorno 3), e così via. Questa variabile facilita la lettura e l'interpretazione dei risultati nel contesto del protocollo sperimentale.\n\n3. **Salvataggio del Dataset Modificato**  \n   Il dataset modificato è stato denominato `sleep2` e ora include solo le osservazioni rilevanti per l'analisi, con una chiara distinzione tra il baseline e i giorni di privazione del sonno.\n\nEcco il codice per implementare questi passaggi:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Filtraggio e creazione della nuova variabile\nsleep2 <- sleepstudy |>\n    filter(Days >= 2L) |>  # Escludiamo i giorni 0 e 1\n    mutate(days_deprived = Days - 2L)  # Ricodifichiamo la variabile Days\n```\n:::\n\n\n\n\n4. **Verifica della Ricodifica**  \n   La correttezza della ricodifica è stata verificata calcolando il numero di osservazioni per ciascun valore di `days_deprived` e confrontandolo con i valori originali della variabile `Days`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsleep2 |>\n    count(days_deprived, Days)\n#>   days_deprived Days  n\n#> 1             0    2 18\n#> 2             1    3 18\n#> 3             2    4 18\n#> 4             3    5 18\n#> 5             4    6 18\n#> 6             5    7 18\n#> 7             6    8 18\n#> 8             7    9 18\n```\n:::\n\n\n\n\n5. **Visualizzazione dei Dati**  \n   Per esplorare le tendenze individuali nel tempo di reazione in funzione dei giorni di privazione del sonno, è stato creato un grafico a dispersione con le seguenti caratteristiche:\n   - L'asse x rappresenta i giorni di privazione del sonno, con 0 corrispondente al baseline.\n   - L'asse y rappresenta il tempo medio di reazione (`Reaction`).\n   - Ogni partecipante è visualizzato separatamente tramite il wrapping dei facet.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n    geom_point() +\n    scale_x_continuous(breaks = 0:7) +\n    facet_wrap(~Subject) +\n    labs(\n        y = \"Tempo medio di reazione (ms)\",\n        x = \"Giorni di privazione del sonno (0 = baseline)\",\n        title = \"Andamento del tempo di reazione durante la privazione del sonno\"\n    )\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesta preparazione consente un'analisi più mirata, isolando gli effetti della privazione del sonno e semplificando l'interpretazione delle dinamiche temporali.\n\n## Relazione tra Tempo di Reazione e Privazione del Sonno\n\nL'analisi dei dati relativi alla privazione del sonno rivela che, con una singola eccezione (il soggetto 335), il tempo medio di reazione tende ad aumentare progressivamente con ogni giorno di privazione aggiuntivo. Questo trend suggerisce che un modello di regressione lineare potrebbe essere utile per descrivere le prestazioni di ciascun partecipante.\n\nLa regressione lineare è definita dalla seguente equazione:\n\n$$ \nE(Y) = \\beta_0 + \\beta_1 X,\n$$\n\ndove:\n\n- $Y$ rappresenta la variabile dipendente (il tempo di reazione medio),\n- $\\beta_0$ è l'intercetta, ovvero il tempo di reazione stimato al giorno iniziale (baseline, senza privazione del sonno),\n- $\\beta_1$ è il coefficiente di pendenza, che rappresenta la variazione stimata nel tempo di reazione per ogni giorno di privazione aggiuntivo,\n- $X$ indica il numero di giorni di privazione del sonno.\n\nI parametri $\\beta_0$ e $\\beta_1$ vengono stimati dai dati, e la loro interpretazione fornisce informazioni chiave sulle dinamiche delle prestazioni psicomotorie.\n\n## Scelta del Modello di Regressione\n\nUn aspetto cruciale nell'analisi è decidere quale struttura modellistica adottare per descrivere i dati. Si devono considerare le seguenti opzioni:\n\n1. **Complete Pooling**  \n   Questo approccio utilizza un unico modello di regressione lineare per tutti i partecipanti, assumendo che la relazione tra privazione del sonno e tempo di reazione sia identica per tutti. In pratica, si stima una singola intercetta ($\\beta_0$) e una singola pendenza ($\\beta_1$) comuni a tutti i soggetti. Sebbene semplice, questo metodo ignora completamente le differenze individuali.\n\n2. **No Pooling**  \n   Qui, si stima un modello di regressione lineare separato per ciascun partecipante, consentendo a ogni soggetto di avere una propria intercetta e una propria pendenza. Questo approccio riconosce pienamente le variazioni individuali, ma potrebbe risultare eccessivamente complesso e sensibile al rumore nei dati, specialmente con pochi punti di osservazione per soggetto.\n\n3. **Partial Pooling**  \n   Questo approccio intermedio, spesso implementato attraverso modelli multilivello, bilancia i due estremi sopra descritti. Si assume una relazione media condivisa tra i soggetti (ad esempio, una pendenza media), ma si consente una variazione individuale attorno a questa media. Il partial pooling sfrutta le informazioni condivise tra i partecipanti, migliorando la robustezza delle stime, specialmente in presenza di pochi dati per soggetto.\n\n## Complete pooling\n\nL'approccio di \"complete pooling\" in analisi statistica implica l'utilizzo di un modello che calcola un'unica intercetta e una sola pendenza per l'intero dataset. Questo metodo si basa sull'ipotesi che tutti i soggetti nel dataset condividano le stesse caratteristiche di base riguardo alla relazione tra la variabile dipendente e indipendente.\n\nQuesto approccio non tiene conto delle possibili differenze individuali nelle intercette o nelle pendenze tra i diversi soggetti. Ad esempio, ignorara come ciascun soggetto reagisce in modo diverso alla privazione del sonno.\n\nDall'analisi preliminare dei dati, abbiamo notato che l'approccio di complete pooling potrebbe non essere adatto per il nostro studio. La visualizzazione dei dati suggerisce che ogni partecipante potrebbe avere una propria relazione unica tra il tempo di reazione e i giorni di privazione del sonno, indicando la necessità di valori individuali per le intercette e le pendenze.\n\n### Modello di Regressione Lineare in Complete Pooling\n\nIl modello generale lineare (GLM) per l'approccio di complete pooling è formulato come segue:\n\n$$\nY_{sd} = \\beta_0 + \\beta_1 X_{sd} + e_{sd},\n$$\n\ndove:\n\n- $Y_{sd}$ rappresenta il tempo di reazione medio del soggetto $s$ nel giorno $d$.\n- $X_{sd}$ è il numero di giorni di privazione del sonno (variabile `days_deprived`), che varia da 0 a 7.\n- $e_{sd}$ è il termine di errore, che rappresenta le fluttuazioni casuali non spiegate dal modello.\n\nPer adattare questo modello in R, si utilizza la funzione `lm()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncp_model <- lm(Reaction ~ days_deprived, sleep2)\nsummary(cp_model)\n#> \n#> Call:\n#> lm(formula = Reaction ~ days_deprived, data = sleep2)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -112.28  -26.73    2.14   27.73  140.45 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)     267.97       7.74   34.63  < 2e-16\n#> days_deprived    11.44       1.85    6.18  6.3e-09\n#> \n#> Residual standard error: 50.9 on 142 degrees of freedom\n#> Multiple R-squared:  0.212,\tAdjusted R-squared:  0.207 \n#> F-statistic: 38.2 on 1 and 142 DF,  p-value: 6.32e-09\n```\n:::\n\n\n\n\nIl modello di regressione che abbiamo considerato offre una stima del tempo di risposta medio per i soggetti allo studio al Giorno 0 (prima della privazione del sonno) e la variazione media del tempo di risposta per ogni giorno aggiuntivo di privazione. Secondo questo modello, il tempo di risposta medio iniziale è stimato essere di circa 268 millisecondi, con un incremento medio di circa 11 millisecondi per ogni giorno successivo di privazione del sonno.\n\nÈ importante notare, tuttavia, che questo modello potrebbe avere delle limitazioni nella sua applicabilità:\n\n- **Assunzione di Indipendenza**: Il modello assume che tutte le osservazioni siano indipendenti. Questa assunzione potrebbe non essere valida nel nostro studio, dato che le osservazioni provengono da misurazioni ripetute sugli stessi soggetti.\n- **Errori Standard dei Coefficienti**: La presunta indipendenza delle osservazioni implica che gli errori standard dei coefficienti di regressione potrebbero non essere completamente affidabili.\n\n### Visualizzazione\n\nPer visualizzare meglio questi risultati, possiamo aggiungere le previsioni del modello al grafico che abbiamo già creato. Utilizziamo la funzione `geom_abline()` di R per tracciare la linea di regressione stimata direttamente sul grafico esistente:\n\n- **Utilizzo di `geom_abline()`**: Questa funzione ci permette di aggiungere una linea di regressione al grafico, specificando l'intercetta e la pendenza.\n- **Coefficienti del Modello**: Utilizziamo `coef(cp_model)` per ottenere i coefficienti di regressione (intercetta e pendenza) dal nostro modello. Questa funzione restituisce un vettore con due elementi corrispondenti all'intercetta e alla pendenza, che possono essere poi utilizzati per definire la linea nel grafico.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n    geom_abline(\n        intercept = coef(cp_model)[1],\n        slope = coef(cp_model)[2],\n        color = \"blue\"\n    ) +\n    geom_point() +\n    scale_x_continuous(breaks = 0:7) +\n    facet_wrap(~Subject) +\n    labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nDall'analisi effettuata, emerge che il modello attuale non si adatta in modo ottimale ai dati raccolti. Questa situazione indica la necessità di esplorare un approccio diverso per modellare in modo più accurato le relazioni presenti nei dati.\n\n## Approccio di No Pooling \n\nIn alternativa al modello di \"complete pooling\", consideriamo l'approccio di \"no pooling\". Questo approccio si basa sull'idea di adattare modelli di regressione separati per ogni partecipante, trattando ogni individuo come un'entità distinta. \n\n### Caratteristiche del No Pooling\n\n- **Indipendenza delle Stime**: In questo approccio, ogni partecipante ha il proprio set di stime per l'intercetta e la pendenza. Le stime relative a un partecipante non sono influenzate dalle stime degli altri.\n- **Stime Individualizzate**: Si stima separatamente una coppia di intercetta/pendenza per ciascuno dei 18 partecipanti, riconoscendo la possibilità di variazioni significative nelle risposte individuali.\n\n### Implementazione del Modello di No Pooling\n\nEsistono due modi principali per implementare questo approccio:\n\n1. **Regressioni Separate per Ogni Partecipante**: Eseguire una serie di regressioni lineari individuali, una per ogni soggetto.\n2. **Modello di Regressione Unificato con Effetti Principali e Interazione**: Utilizzare un unico modello di regressione che includa sia gli effetti principali sia l'interazione tra le variabili `Subject` (soggetto) e `Day` (giorno). Questo metodo permette di includere tutte le stime in un unico modello.\n\nPer il secondo approccio, è necessario considerare le seguenti fasi:\n\n- **Creazione di Variabili Dummy per il Fattore `Subject`**: Poiché `Subject` ha 18 livelli, saranno necessarie 17 variabili dummy per rappresentare questi livelli. In R, questo può essere fatto automaticamente definendo `Subject` come un fattore.\n- **Includere `Subject` come Fattore nel Modello**: Aggiungere `Subject`, definito come un fattore, come predittore nel modello. L'inclusione dell'interazione tra `Subject` e `days_deprived` permette variazioni nelle intercette e nelle pendenze tra i soggetti.\n\nPrima di procedere, è importante assicurarsi che `Subject` sia definito correttamente come un fattore. Questo può essere verificato utilizzando la funzione `summary()` in R, che fornisce una sintesi delle caratteristiche della variabile, compreso se è trattata come un fattore.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsleep2 |> \n    summary()\n#>     Reaction        Days         Subject   days_deprived \n#>  Min.   :203   Min.   :2.00   308    : 8   Min.   :0.00  \n#>  1st Qu.:265   1st Qu.:3.75   309    : 8   1st Qu.:1.75  \n#>  Median :303   Median :5.50   310    : 8   Median :3.50  \n#>  Mean   :308   Mean   :5.50   330    : 8   Mean   :3.50  \n#>  3rd Qu.:348   3rd Qu.:7.25   331    : 8   3rd Qu.:5.25  \n#>  Max.   :466   Max.   :9.00   332    : 8   Max.   :7.00  \n#>                               (Other):96\n```\n:::\n\n\n\n\nLa funzione `pull()` viene utilizzata per estrarre una specifica colonna da un data frame. Con le seguenti istruzioni verifichiamo se la colonna `Subject` è codificata come `factor`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsleep2 |>\n    pull(Subject) |>\n    is.factor()\n#> [1] TRUE\n```\n:::\n\n\n\n\nAdattiamo il modello di regressione ai dati. Si noti che la sintassi seguente può essere semplificata utilizzando `Reaction ~ days_deprived * Subject`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnp_model <- lm(Reaction ~ days_deprived + Subject + days_deprived:Subject,\n    data = sleep2\n)\n\nsummary(np_model)\n#> \n#> Call:\n#> lm(formula = Reaction ~ days_deprived + Subject + days_deprived:Subject, \n#>     data = sleep2)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -106.52   -8.54    1.14    8.89  128.55 \n#> \n#> Coefficients:\n#>                          Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)               288.217     16.477   17.49  < 2e-16\n#> days_deprived              21.690      3.939    5.51  2.5e-07\n#> Subject309                -87.926     23.302   -3.77  0.00026\n#> Subject310                -62.286     23.302   -2.67  0.00869\n#> Subject330                -14.953     23.302   -0.64  0.52242\n#> Subject331                  9.966     23.302    0.43  0.66974\n#> Subject332                 27.816     23.302    1.19  0.23522\n#> Subject333                 -2.758     23.302   -0.12  0.90600\n#> Subject334                -50.205     23.302   -2.15  0.03342\n#> Subject335                -25.343     23.302   -1.09  0.27921\n#> Subject337                 24.614     23.302    1.06  0.29319\n#> Subject349                -59.218     23.302   -2.54  0.01246\n#> Subject350                -40.202     23.302   -1.73  0.08734\n#> Subject351                -24.247     23.302   -1.04  0.30042\n#> Subject352                 43.065     23.302    1.85  0.06732\n#> Subject369                -21.504     23.302   -0.92  0.35815\n#> Subject370                -53.307     23.302   -2.29  0.02411\n#> Subject371                -30.490     23.302   -1.31  0.19350\n#> Subject372                  2.477     23.302    0.11  0.91554\n#> days_deprived:Subject309  -17.333      5.570   -3.11  0.00238\n#> days_deprived:Subject310  -17.792      5.570   -3.19  0.00184\n#> days_deprived:Subject330  -13.685      5.570   -2.46  0.01561\n#> days_deprived:Subject331  -16.823      5.570   -3.02  0.00315\n#> days_deprived:Subject332  -19.295      5.570   -3.46  0.00076\n#> days_deprived:Subject333  -10.815      5.570   -1.94  0.05480\n#> days_deprived:Subject334   -3.575      5.570   -0.64  0.52242\n#> days_deprived:Subject335  -25.899      5.570   -4.65  9.5e-06\n#> days_deprived:Subject337    0.752      5.570    0.13  0.89289\n#> days_deprived:Subject349   -5.264      5.570   -0.95  0.34673\n#> days_deprived:Subject350    1.601      5.570    0.29  0.77438\n#> days_deprived:Subject351  -13.168      5.570   -2.36  0.01987\n#> days_deprived:Subject352  -14.402      5.570   -2.59  0.01106\n#> days_deprived:Subject369   -7.895      5.570   -1.42  0.15927\n#> days_deprived:Subject370   -1.049      5.570   -0.19  0.85091\n#> days_deprived:Subject371   -9.344      5.570   -1.68  0.09633\n#> days_deprived:Subject372  -10.604      5.570   -1.90  0.05961\n#> \n#> Residual standard error: 25.5 on 108 degrees of freedom\n#> Multiple R-squared:  0.849,\tAdjusted R-squared:   0.8 \n#> F-statistic: 17.4 on 35 and 108 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\nPer chiarire, il soggetto di riferimento è il 308; in R, la modalità predefinita è quella di ordinare i livelli del fattore in ordine alfabetico e di scegliere il primo come soggetto di riferimento. Questo significa che l'intercetta e la pendenza per il soggetto 308 sono rappresentate rispettivamente da `(Intercept)` e `days_deprived`, poiché tutte le altre 17 variabili dummy saranno nulle per il soggetto 308.\n\nTutti i coefficienti di regressione degli altri soggetti sono rappresentati come scostamenti da questo soggetto di riferimento. Se desideriamo calcolare l'intercetta e la pendenza per un dato soggetto, dobbiamo semplicemente sommare gli scostamenti corrispondenti. Pertanto, abbiamo:\n\nIntercetta per 308: 288.217\\\nPendenza per 308: 21.69\n\nIntercetta per 335: `(Intercept) + Subject335` = 288.217 + -25.343 = 262.874\\\nPendenza per 335: `days_deprived + days_deprived:Subject335` = 21.69 + -25.899 = -4.209\n\nE così via.\n\nNel modello \"no pooling\", non viene stimata un'intercetta e una pendenza complessive per l'intera popolazione; in questo caso, `(Intercept)` e `days_deprived` sono stime dell'intercetta e della pendenza per il soggetto 308, che è stato scelto (arbitrariamente) come soggetto di riferimento. Per ottenere stime per l'intera popolazione, è possibile procedere con una seconda fase dell'analisi statistica in cui calcoliamo le medie delle intercette e delle pendenze individuali. \n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ncoef(np_model) |> as.data.frame()\n#>                          coef(np_model)\n#> (Intercept)                     288.217\n#> days_deprived                    21.690\n#> Subject309                      -87.926\n#> Subject310                      -62.286\n#> Subject330                      -14.953\n#> Subject331                        9.966\n#> Subject332                       27.816\n#> Subject333                       -2.758\n#> Subject334                      -50.205\n#> Subject335                      -25.343\n#> Subject337                       24.614\n#> Subject349                      -59.218\n#> Subject350                      -40.202\n#> Subject351                      -24.247\n#> Subject352                       43.065\n#> Subject369                      -21.504\n#> Subject370                      -53.307\n#> Subject371                      -30.490\n#> Subject372                        2.477\n#> days_deprived:Subject309        -17.333\n#> days_deprived:Subject310        -17.792\n#> days_deprived:Subject330        -13.685\n#> days_deprived:Subject331        -16.823\n#> days_deprived:Subject332        -19.295\n#> days_deprived:Subject333        -10.815\n#> days_deprived:Subject334         -3.575\n#> days_deprived:Subject335        -25.899\n#> days_deprived:Subject337          0.752\n#> days_deprived:Subject349         -5.264\n#> days_deprived:Subject350          1.601\n#> days_deprived:Subject351        -13.168\n#> days_deprived:Subject352        -14.402\n#> days_deprived:Subject369         -7.895\n#> days_deprived:Subject370         -1.049\n#> days_deprived:Subject371         -9.344\n#> days_deprived:Subject372        -10.604\n```\n:::\n\n\n\n\nCalcoliamo le intercette individuali:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nall_intercepts <- c(\n    coef(np_model)[\"(Intercept)\"],\n    coef(np_model)[3:19] + coef(np_model)[\"(Intercept)\"]\n)\n```\n:::\n\n\n\n\nCalcliamo le pendenze individuali:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nall_slopes <- c(\n    coef(np_model)[\"days_deprived\"],\n    coef(np_model)[20:36] + coef(np_model)[\"days_deprived\"]\n)\n```\n:::\n\n\n\n\nCreiamo un DataFrame con le colonne Subject, intercept e slope:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nids <- sleep2 |>\n    pull(Subject) |>\n    levels() |>\n    factor()\nprint(ids)\n#>  [1] 308 309 310 330 331 332 333 334 335 337 349 350 351 352 369 370 371 372\n#> 18 Levels: 308 309 310 330 331 332 333 334 335 337 349 350 351 352 ... 372\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# make a tibble with the data extracted above\nnp_coef <- tibble(\n    Subject = ids,\n    intercept = all_intercepts,\n    slope = all_slopes\n)\n\nprint(np_coef)\n#> # A tibble: 18 × 3\n#>   Subject intercept slope\n#>   <fct>       <dbl> <dbl>\n#> 1 308          288. 21.7 \n#> 2 309          200.  4.36\n#> 3 310          226.  3.90\n#> 4 330          273.  8.01\n#> 5 331          298.  4.87\n#> 6 332          316.  2.40\n#> # ℹ 12 more rows\n```\n:::\n\n\n\n\nEsaminiamo l'adattamento di questo modello ai dati.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n    geom_abline(\n        data = np_coef,\n        mapping = aes(\n            intercept = intercept,\n            slope = slope\n        ),\n        color = \"blue\"\n    ) +\n    geom_point() +\n    scale_x_continuous(breaks = 0:7) +\n    facet_wrap(~Subject) +\n    labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesta situazione è notevolmente migliorata rispetto al modello di pooling completo. Se desideriamo testare l'ipotesi nulla secondo cui la pendenza della retta di regressione è uguale a zero, possiamo farlo eseguendo un test $t$ di Student sul campione di pendenze individuali.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nnp_coef |>\n    pull(slope) |>\n    t.test()\n#> \n#> \tOne Sample t-test\n#> \n#> data:  pull(np_coef, slope)\n#> t = 6, df = 17, p-value = 1e-05\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>   7.54 15.33\n#> sample estimates:\n#> mean of x \n#>      11.4\n```\n:::\n\n\n\n\nQuesto test suggerisce che la pendenza media di 11.435 è diversa da zero, t(17) = 6.20 p < .001.\n\n## Partial Pooling\n\nNell'analisi dei dati psicologici, la scelta del metodo di pooling rappresenta una decisione cruciale per bilanciare la variabilità individuale con la necessità di sfruttare le informazioni aggregate. Da un lato, l'approccio di *complete pooling* tratta tutti i dati come se appartenessero a un unico gruppo omogeneo, ignorando completamente le differenze tra individui. Dall'altro lato, l'approccio di *no pooling* analizza i dati di ciascun partecipante separatamente, senza beneficiare delle informazioni condivise tra i soggetti. Entrambi questi estremi presentano limiti significativi: il *complete pooling* può occultare variazioni individuali rilevanti, mentre il *no pooling* rischia di produrre stime instabili e meno robuste, soprattutto in presenza di pochi dati per soggetto.\n\n### Il Vantaggio del Partial Pooling\n\nIl *partial pooling*, implementato tramite modelli lineari a effetti misti, rappresenta un approccio intermedio che supera queste limitazioni. Questo metodo sfrutta le informazioni condivise tra i partecipanti per migliorare le stime a livello individuale, mantenendo al contempo la capacità di catturare variazioni specifiche. In pratica, il modello:\n\n- **Condivide informazioni tra soggetti**: Le stime individuali sono influenzate dalle tendenze generali osservate nel gruppo, evitando così di basarsi esclusivamente sui dati limitati di ciascun partecipante.\n- **Permette variazioni individuali**: Ogni soggetto può avere una propria intercetta e pendenza che si discostano dalla media di gruppo, riflettendo le differenze individuali.\n\nQuesto equilibrio consente di ottenere stime che sono sia robuste sia rappresentative, riducendo il rischio di sovradattamento (*overfitting*) e migliorando la generalizzabilità dei risultati.\n\n\n### Implementazione dei Modelli a Effetti Misti\n\n- **Trattare i Soggetti come Fattori Casuali**: Nel *partial pooling*, i soggetti vengono considerati come un fattore casuale anziché fisso. Ciò implica che i livelli del fattore (i soggetti nel nostro caso) sono visti come un campione casuale da una popolazione più ampia.\n- **Modello Lineare a Effetti Misti**: Questo tipo di modello statistico consente di includere i fattori casuali nell'analisi. In un modello misto, le stime per ogni soggetto sono \"informate\" o influenzate dalle informazioni aggregate degli altri soggetti.\n- **Shrinkage**: Il fenomeno dello *shrinkage* (restringimento) indica che le stime per ciascun soggetto vengono regolate o \"spostate\" verso le stime medie della popolazione, permettendo una valutazione più equilibrata e meno influenzata da variazioni estreme o casuali.\n\n### Articolazione e Applicazione del Modello Multilivello\n\nIl modello multilivello descritto cattura le relazioni tra variabili misurate a più livelli, integrando dinamicamente la variabilità individuale e di gruppo. La struttura a due livelli consente di modellare sia le differenze tra soggetti che le relazioni all'interno di ciascun soggetto.\n\n### Livello 1: Relazione Individuale\n\nAl livello individuale, il modello esprime una relazione lineare tra la variabile di risposta $Y_{sd}$ (tempo di reazione) e il predittore $X_{sd}$ (giorni di privazione del sonno):\n\n$$\nY_{sd} = \\beta_{0s} + \\beta_{1s} X_{sd} + e_{sd},\n$$\n\ndove:\n\n- $Y_{sd}$: Tempo di reazione del soggetto $s$ al giorno $d$,\n- $\\beta_{0s}$: Intercetta specifica del soggetto $s$,\n- $\\beta_{1s}$: Pendenza specifica del soggetto $s$,\n- $e_{sd} \\sim N(0, \\sigma^2)$: Errore residuo per il soggetto $s$ al giorno $d$, distribuito normalmente con varianza $\\sigma^2$.\n\nLe intercette ($\\beta_{0s}$) e le pendenze ($\\beta_{1s}$) variano tra i soggetti e sono determinate al Livello 2.\n\n\n### Livello 2: Variabilità Tra Soggetti\n\nAl livello superiore, il modello specifica come le intercette e le pendenze variano tra i soggetti:\n\n$$\n\\beta_{0s} = \\gamma_{0} + S_{0s},\n$$\n$$\n\\beta_{1s} = \\gamma_{1} + S_{1s},\n$$\n\ndove:\n\n- $\\gamma_0$: Intercetta media della popolazione,\n- $\\gamma_1$: Pendenza media della popolazione,\n- $S_{0s} \\sim N(0, \\tau_{00}^2)$: Effetto casuale sull'intercetta per il soggetto $s$,\n- $S_{1s} \\sim N(0, \\tau_{11}^2)$: Effetto casuale sulla pendenza per il soggetto $s$,\n- $\\langle S_{0s}, S_{1s} \\rangle$: Effetti casuali correlati con covarianza $\\rho \\tau_{00} \\tau_{11}$.\n\nLa matrice di varianza-covarianza degli effetti casuali è data da:\n\n$$\n\\Sigma = \n\\begin{pmatrix}\n\\tau_{00}^2 & \\rho \\tau_{00} \\tau_{11} \\\\\n\\rho \\tau_{00} \\tau_{11} & \\tau_{11}^2\n\\end{pmatrix},\n$$\n\ndove $\\tau_{00}^2$ e $\\tau_{11}^2$ rappresentano rispettivamente la varianza delle intercette e delle pendenze, e $\\rho$ descrive la correlazione tra questi effetti.\n\n### Modello Completo\n\nCombinando i due livelli, il modello multilivello può essere espresso come:\n\n$$\nY_{sd} = \\gamma_0 + S_{0s} + (\\gamma_1 + S_{1s}) X_{sd} + e_{sd},\n$$\n\ndove:\n\n- $\\gamma_0$ e $\\gamma_1$: Effetti fissi (intercetta e pendenza medie della popolazione),\n- $S_{0s}$ e $S_{1s}$: Effetti casuali che catturano variazioni individuali,\n- $e_{sd}$: Errore residuo specifico per ciascuna osservazione.\n\n### Interpretazione degli Effetti Fissi e Casuali\n\n- **Effetti Fissi ($\\gamma_0$, $\\gamma_1$)**: Rappresentano la tendenza generale della popolazione, fornendo stime medie valide per tutti i soggetti.\n- **Effetti Casuali ($S_{0s}$, $S_{1s}$)**: Catturano la variabilità tra i soggetti, modellando le deviazioni rispetto agli effetti fissi.\n\n### Importanza della Matrice di Varianza-Covarianza\n\nLa matrice di varianza-covarianza consente di:\n\n1. **Quantificare la variabilità tra i soggetti**: Le varianze $\\tau_{00}^2$ e $\\tau_{11}^2$ indicano l'eterogeneità delle intercette e delle pendenze rispettivamente.\n2. **Esaminare le relazioni tra intercette e pendenze**: La covarianza $\\rho \\tau_{00} \\tau_{11}$ fornisce informazioni sulle correlazioni tra i due parametri. Ad esempio, una correlazione positiva potrebbe indicare che soggetti con tempi di reazione iniziali più elevati (intercetta maggiore) tendono a mostrare aumenti più rapidi del tempo di reazione con la privazione del sonno.\n\n### Vantaggi del Modello Multilivello\n\n1. **Bilancia complete pooling e no pooling**: Integra tendenze generali con variazioni specifiche.\n2. **Stime robuste**: Migliora l'accuratezza delle stime per i soggetti individuali sfruttando le informazioni condivise tra tutti i soggetti.\n3. **Generalizzabilità**: Fornisce una base solida per inferenze valide sull'intera popolazione.\n\nIn conclusione, il modello multilivello offre un approccio flessibile e potente per analizzare dati gerarchici, come quelli longitudinali o nidificati. Permette di distinguere tra effetti generali e variazioni individuali, fornendo una rappresentazione dettagliata dei fenomeni psicologici e una base solida per interpretazioni e inferenze.\n\n## Stima dei Parametri del Modello\n\nPer stimare i parametri del modello in R, utilizzeremo la funzione `lmer()` del pacchetto **lme4** [@bates2014fitting]. Questa funzione consente di specificare sia gli effetti fissi (ad esempio, giorni di deprivazione del sonno) sia gli effetti casuali (ad esempio, variazioni tra soggetti), costruendo un modello che bilancia informazioni aggregate e individuali.\n\n### Sintassi Generale di `lmer()`\n\nLa sintassi base di `lmer()` è:\n\n$$\n\\text{lmer(formula, data, ...)},\n$$\n\ndove:\n\n- **`formula`** definisce la struttura del modello, specificando la relazione tra variabili dipendenti, effetti fissi e casuali.\n- **`data`** indica il dataset contenente le variabili.\n\nLa struttura generale della formula è:\n\n```r\nDV ~ fix1 + fix2 + ... + fixN + (ran1 + ran2 + ... + ranK | random_factor)\n```\n\ndove:\n\n- **`DV`**: variabile dipendente.\n- **`fix1, fix2, ..., fixN`**: effetti fissi (fattori indipendenti a livello globale).\n- **`ran1, ran2, ..., ranK`**: effetti casuali che variano tra i livelli del fattore casuale specificato da `random_factor`.\n\nLe **interazioni** tra i fattori possono essere definite utilizzando:\n\n- `A * B` (effetti principali + interazione),\n- `A:B` (solo interazione).\n\n### Effetti Casuali nella Formula\n\nGli effetti casuali sono specificati all'interno di parentesi, ad esempio:\n\n```r\n(1 + days_deprived | Subject)\n```\n\nQuesta sintassi indica che sia l'intercetta ($1$) sia il coefficiente associato a `days_deprived` variano tra i livelli del fattore casuale `Subject`. È anche possibile avere più termini di effetti casuali nella stessa formula, ad esempio, per fattori casuali incrociati.\n\nSul lato sinistro della barra `|` si elencano gli effetti che vogliamo far variare, mentre sul lato destro si specifica la variabile che identifica i livelli del fattore casuale (ad esempio, `Subject`).\n\n### Esempi di Modelli con `sleep2`\n\nConsideriamo diverse specifiche di modello per i dati `sleep2`, con le rispettive formule e strutture della matrice di varianza-covarianza ($\\mathbf{\\Sigma}$).\n\n#### Solo Intercette Casuali\n\n```r\nReaction ~ days_deprived + (1 | Subject)\n```\nIn questo modello, solo l'intercetta varia tra i soggetti ($\\tau_{00}^2$):\n\n$$\n\\mathbf{\\Sigma} =\n\\begin{pmatrix}\n\\tau_{00}^2 & 0 \\\\\n0 & 0\n\\end{pmatrix}\n$$\n\n#### Intercette e Pendenze Casuali\n```r\nReaction ~ days_deprived + (1 + days_deprived | Subject)\n```\nIn questo modello, sia l'intercetta ($\\tau_{00}^2$) sia la pendenza ($\\tau_{11}^2$) variano tra i soggetti, con una correlazione ($\\rho$) tra i due:\n\n$$\n\\mathbf{\\Sigma} =\n\\begin{pmatrix}\n\\tau_{00}^2 & \\rho \\tau_{00} \\tau_{11} \\\\\n\\rho \\tau_{00} \\tau_{11} & \\tau_{11}^2\n\\end{pmatrix}\n$$\n\n#### Pendenze Casuali Senza Correlazione\n```r\nReaction ~ days_deprived + (days_deprived || Subject)\n```\nQuesta sintassi alternativa esclude la covarianza tra intercette e pendenze, risultando in una matrice diagonale:\n\n$$\n\\mathbf{\\Sigma} =\n\\begin{pmatrix}\n\\tau_{00}^2 & 0 \\\\\n0 & \\tau_{11}^2\n\\end{pmatrix}\n$$\n\n#### Solo Pendenze Casuali\n```r\nReaction ~ days_deprived + (0 + days_deprived | Subject)\n```\nIn questo caso, solo le pendenze variano tra i soggetti ($\\tau_{11}^2$):\n\n$$\n\\mathbf{\\Sigma} =\n\\begin{pmatrix}\n0 & 0 \\\\\n0 & \\tau_{11}^2\n\\end{pmatrix}\n$$\n\n**Tabella Riassuntiva dei Modelli**\n\n| **Modello**                | **Formula**                                            | **Struttura di $\\mathbf{\\Sigma}$**                                                   |\n|----------------------------|-------------------------------------------------------|---------------------------------------------------------------------------------------|\n| **1. Solo intercette**      | `Reaction ~ days_deprived + (1 | Subject)`            | $\\begin{pmatrix} \\tau_{00}^2 & 0 \\\\ 0 & 0 \\end{pmatrix}$                           |\n| **2. Intercette e pendenze**| `Reaction ~ days_deprived + (1 + days_deprived | Subject)`| $\\begin{pmatrix} \\tau_{00}^2 & \\rho \\tau_{00} \\tau_{11} \\\\ \\rho \\tau_{00} \\tau_{11} & \\tau_{11}^2 \\end{pmatrix}$ |\n| **3. No covarianza**        | `Reaction ~ days_deprived + (days_deprived || Subject)`| $\\begin{pmatrix} \\tau_{00}^2 & 0 \\\\ 0 & \\tau_{11}^2 \\end{pmatrix}$                |\n| **4. Solo pendenze**        | `Reaction ~ days_deprived + (0 + days_deprived | Subject)`| $\\begin{pmatrix} 0 & 0 \\\\ 0 & \\tau_{11}^2 \\end{pmatrix}$                          |\n\n### Scelta del Modello\n\nLa scelta del modello dipende dalla complessità dei dati e dalle ipotesi sull’eterogeneità tra i soggetti:\n\n- **Modello 1**: È il più semplice, adatto quando si ritiene che le differenze tra soggetti influenzino solo l'intercetta.\n- **Modello 2**: Modello più flessibile, consente variazioni sia nelle intercette che nelle pendenze.\n- **Modello 3**: Variante di Modello 2, esclude la correlazione tra intercette e pendenze, utile per semplificare il modello.\n- **Modello 4**: Adatto quando si ritiene che la variabilità tra soggetti influenzi solo le pendenze.\n\nIn conclusione, la funzione `lmer()` offre una potente flessibilità per modellare dati multilivello, adattandosi a diverse ipotesi e configurazioni. La comprensione delle strutture della matrice di varianza-covarianza è fondamentale per interpretare correttamente i risultati e scegliere il modello più appropriato per il contesto analitico.\n\n### Applicazione\n\nPer i dati dell'esempio, il modello più appropriato è il **Modello 2**, che include intercette e pendenze casuali per ciascun soggetto. Procediamo quindi a stimarlo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_mod <- lmer(\n    Reaction ~ 1 + days_deprived + (1 + days_deprived | Subject), \n    data = sleep2\n)\n```\n:::\n\n\n\n\nPer verificare la stima del modello, utilizziamo la funzione `summary()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(pp_mod)\n#> Linear mixed model fit by REML ['lmerMod']\n#> Formula: Reaction ~ 1 + days_deprived + (1 + days_deprived | Subject)\n#>    Data: sleep2\n#> \n#> REML criterion at convergence: 1404\n#> \n#> Scaled residuals: \n#>    Min     1Q Median     3Q    Max \n#> -4.016 -0.354  0.007  0.468  5.073 \n#> \n#> Random effects:\n#>  Groups   Name          Variance Std.Dev. Corr\n#>  Subject  (Intercept)   958.4    30.96        \n#>           days_deprived  45.8     6.77    0.18\n#>  Residual               651.6    25.53        \n#> Number of obs: 144, groups:  Subject, 18\n#> \n#> Fixed effects:\n#>               Estimate Std. Error t value\n#> (Intercept)     267.97       8.27    32.4\n#> days_deprived    11.44       1.85     6.2\n#> \n#> Correlation of Fixed Effects:\n#>             (Intr)\n#> days_deprvd -0.062\n```\n:::\n\n\n\n\n### Predizioni del Modello\n\nPrima di interpretare i risultati, rappresentiamo graficamente i dati osservati e le previsioni del modello. La funzione `predict()` permette di calcolare le stime previste per ciascun livello del predittore, considerando gli effetti casuali e fissi. Di seguito, i passaggi per creare un dataset per le predizioni.\n\n#### Creazione di un Nuovo Dataset\n\nPer ottenere le previsioni, creiamo un nuovo dataset (`newdata`) con tutte le combinazioni dei livelli di `Subject` e `days_deprived`. Utilizziamo la funzione `crossing()` del pacchetto **dplyr**.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata <- crossing(\n    Subject = sleep2 |> \n        pull(Subject) |> \n        levels() |> \n        factor(),\n    days_deprived = 0:7\n)\n```\n:::\n\n\n\n\nEcco un'anteprima del dataset generato:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(newdata, 17)\n#> # A tibble: 17 × 2\n#>   Subject days_deprived\n#>   <fct>           <int>\n#> 1 308                 0\n#> 2 308                 1\n#> 3 308                 2\n#> 4 308                 3\n#> 5 308                 4\n#> 6 308                 5\n#> # ℹ 11 more rows\n```\n:::\n\n\n\n\n#### Dettagli del Codice\n\n- `Subject = sleep2 |> pull(Subject) |> levels() |> factor()`:\n  1. `pull(Subject)`: Estrae la colonna `Subject` dal dataset `sleep2`.\n  2. `levels()`: Recupera i livelli unici della variabile categorica `Subject`.\n  3. `factor()`: Converte i livelli in un fattore, garantendo la compatibilità con la funzione `crossing()`.\n\n- `days_deprived = 0:7`:\n  Genera una sequenza di valori da 0 a 7, rappresentando i giorni di privazione del sonno.\n\n- `crossing()`:\n  Combina tutte le possibili coppie di livelli di `Subject` e valori di `days_deprived`, creando un dataset completo per calcolare le predizioni.\n\n#### Calcolo delle Predizioni\n\nUtilizziamo la funzione `predict()` per stimare i valori di `Reaction` per ciascuna combinazione di soggetto e giorno:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata2 <- newdata |>\n    mutate(Reaction = predict(pp_mod, newdata))\n```\n:::\n\n\n\n\nVisualizziamo i primi valori del nuovo dataset:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(newdata2)\n#> # A tibble: 6 × 3\n#>   Subject days_deprived Reaction\n#>   <fct>           <int>    <dbl>\n#> 1 308                 0     292.\n#> 2 308                 1     313.\n#> 3 308                 2     333.\n#> 4 308                 3     353.\n#> 5 308                 4     373.\n#> 6 308                 5     393.\n```\n:::\n\n\n\n\n### Visualizzazione Grafica\n\nPer rappresentare graficamente le rette di regressione previste dal modello per ciascun soggetto, utilizziamo **ggplot2**:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n    geom_line(\n        data = newdata2,\n        aes(group = Subject),\n        color = \"blue\"\n    ) +\n    geom_point() +\n    scale_x_continuous(breaks = 0:7) +\n    facet_wrap(~Subject) +\n    labs(\n        y = \"Reaction Time (ms)\", \n        x = \"Days Deprived of Sleep (0 = baseline)\",\n        title = \"Reaction Time by Days of Sleep Deprivation\"\n    )\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n1. `geom_line()`: Disegna le rette di regressione previste per ciascun soggetto utilizzando i dati di `newdata2`. \n   - `aes(group = Subject)`: Specifica che ogni linea è associata a un soggetto distinto.\n   - `color = \"blue\"`: Imposta il colore delle linee.\n\n2. `geom_point()`: Aggiunge i punti corrispondenti ai dati osservati.\n\n3. `facet_wrap(~Subject)`: Crea un pannello separato per ciascun soggetto, facilitando il confronto tra dati osservati e predizioni.\n\n4. `labs()`: Personalizza le etichette degli assi e il titolo del grafico.\n\nIl grafico risultante mostra le predizioni del modello (linee blu) sovrapposte ai dati osservati (punti) per ciascun soggetto. Questo consente di valutare visivamente l'adeguatezza del modello nel catturare sia le tendenze generali sia le variazioni individuali.\n\n\n\n## Interpretare l'output di `lmer()` ed estrarre le stime\n\nLa chiamata a `lmer()` restituisce un oggetto della classe \"lmerMod\". \n\n### Effetti fissi\n\nLa sezione dell'output chiamata \"Effetti fissi:\" è simile a ciò che si vede nell'output per un modello lineare semplice adattato con `lm()`.\n\n```\nFixed effects:\n              Estimate Std. Error t value\n(Intercept)    267.967      8.266  32.418\ndays_deprived   11.435      1.845   6.197\n```\n\nL'output precedente indica che il tempo di reazione medio stimato per i partecipanti al Giorno 0 era di circa 268 millisecondi, con ogni giorno di privazione del sonno che aggiungeva mediamente ulteriori 11 millisecondi al tempo di risposta.\n\nSe dobbiamo ottenere gli effetti fissi dal modello, possiamo estrarli utilizzando la funzione `fixef()`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nfixef(pp_mod) |> \n    print()\n#>   (Intercept) days_deprived \n#>         268.0          11.4\n```\n:::\n\n\n\n\nGli errori standard ci forniscono stime della variabilità di questi parametri dovuta all'errore di campionamento. Possiamo utilizzarli per calcolare i valori $t$ o derivare gli intervalli di confidenza. Per estrarli, utilizziamo `vcov(pp_mod)`, che restituirà una matrice di varianza-covarianza (non quella associata agli effetti casuali), quindi estraiamo la diagonale utilizzando `diag()` e calcoliamo infine la radice quadrata utilizzando `sqrt()`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nvcov(pp_mod)\n#> 2 x 2 Matrix of class \"dpoMatrix\"\n#>               (Intercept) days_deprived\n#> (Intercept)         68.33         -0.95\n#> days_deprived       -0.95          3.41\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nvcov(pp_mod) |> \n    diag() |> \n    sqrt() |> \n    print()\n#>   (Intercept) days_deprived \n#>          8.27          1.85\n```\n:::\n\n\n\n\nSi noti che, nell'output di `lmer`, i valori $t$ non sono accompagnati dai valori $p$, come avviene di solito nei contesti di modellazione più semplici. Esistono molteplici approcci per ottenere i valori $p$ da modelli a effetti misti, ciascuno con vantaggi e svantaggi (si veda, ad esempio, Luke (2017) per un'analisi delle opzioni disponibili). I valori $t$ non vengono accompagnati dai gradi di libertà, poiché i gradi di libertà in un modello a effetti misti non sono ben definiti. Spesso i ricercatori trattano i valori $t$ come valori $z$ di Wald, ossia come osservazioni provenienti da una distribuzione normale standard. Poiché la distribuzione $t$ si avvicina alla distribuzione normale standard all'aumentare del numero di osservazioni, questa pratica \"t-as-z\" è legittima se il numero di osservazioni campionarie è sufficientemente grande.\n\nPer calcolare i valori $z$ di Wald, basta dividere la stima dell'effetto fisso per il suo errore standard:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ntvals <- fixef(pp_mod) / sqrt(diag(vcov(pp_mod)))\n\ntvals |> \n    print()\n#>   (Intercept) days_deprived \n#>          32.4           6.2\n```\n:::\n\n\n\n\nI valori-$p$ si ottengono nel modo seguente:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nprint(2 * (1 - pnorm(abs(tvals))))\n#>   (Intercept) days_deprived \n#>      0.00e+00      5.75e-10\n```\n:::\n\n\n\n\nQuesto fornisce una forte evidenza contro l'ipotesi nulla $H_0: \\gamma_1 = 0$. Sembra che la privazione del sonno aumenti effettivamente il tempo di risposta.\n\nÈ possibile ottenere gli intervalli di confidenza per le stime utilizzando la funzione `confint()` (questa tecnica utilizza il bootstrap parametrico). \n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nconfint(pp_mod) |> \n    print()\n#>                 2.5 %  97.5 %\n#> .sig01         19.098  46.337\n#> .sig02         -0.405   0.806\n#> .sig03          4.008  10.249\n#> .sigma         22.467  29.349\n#> (Intercept)   251.344 284.590\n#> days_deprived   7.725  15.146\n```\n:::\n\n\n\n\n### Effetti random\n\n```\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n```\n\nLa parte relativa agli effetti casuali dell'output di `summary()` ci fornisce una tabella con informazioni sulle diverse componenti della varianza: la matrice di varianza-covarianza (o matrici, se ci sono più fattori casuali) e la varianza residua.\n\nCominciamo con la riga `Residual`. Questo ci indica che la varianza residua, $\\sigma^2$, è stata stimata a circa 651.6. Il valore nella colonna successiva, 25.526, è la deviazione standard, $\\sigma$, che è la radice quadrata della varianza.\n\nEstraiamo la deviazione standard dei residui utilizzando la funzione `sigma()`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsigma(pp_mod) # residual\n#> [1] 25.5\n```\n:::\n\n\n\n\nLe due righe sopra la riga Residual ci forniscono informazioni sulla matrice di varianza-covarianza per il fattore casuale \"Subject\".\n\n```\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n```\n\nI valori nella colonna \"Variance\" ci forniscono la diagonale principale della matrice, mentre i valori nella colonna \"Std.Dev.\" rappresentano semplicemente le radici quadrate di questi valori. La colonna \"Corr\" indica la correlazione tra l'intercetta e la pendenza.\n\nPossiamo estrarre questi valori dall'oggetto adattato `pp_mod` utilizzando la funzione `VarCorr()`. Questa funzione restituisce una lista nominata, con un elemento per ciascun fattore casuale. Nel nostro caso, \"Subject\" è l'unico fattore casuale, quindi la lista avrà lunghezza 1.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# variance-covariance matrix for random factor Subject\nVarCorr(pp_mod)[[\"Subject\"]] |> \n    print() # oppure: VarCorr(pp_mod)[[1]]\n#>               (Intercept) days_deprived\n#> (Intercept)         958.4          37.2\n#> days_deprived        37.2          45.8\n#> attr(,\"stddev\")\n#>   (Intercept) days_deprived \n#>         30.96          6.77 \n#> attr(,\"correlation\")\n#>               (Intercept) days_deprived\n#> (Intercept)         1.000         0.178\n#> days_deprived       0.178         1.000\n```\n:::\n\n\n\n\nLe prime righe rappresentano la matrice di varianza-covarianza. Le varianze sono riportate sulla diagonale principale. `correlation` indica la correlazione tra la stima della pendenza e la stima dell'intercetta.\n\nPossiamo estrarre gli effetti casuali stimati (BLUPS) utilizzando la funzione `ranef()`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nranef(pp_mod)[[\"Subject\"]] |> \n    print()\n#>     (Intercept) days_deprived\n#> 308      24.499         8.602\n#> 309     -59.372        -8.128\n#> 310     -39.476        -7.429\n#> 330       1.350        -2.385\n#> 331      18.458        -3.748\n#> 332      30.527        -4.894\n#> 333      13.368         0.289\n#> 334     -18.158         3.844\n#> 335     -16.974       -12.070\n#> 337      44.585        10.176\n#> 349     -26.684         2.195\n#> 350      -5.966         8.176\n#> 351      -5.571        -2.372\n#> 352      46.635        -0.562\n#> 369       0.962         1.739\n#> 370     -18.522         5.632\n#> 371      -7.343         0.273\n#> 372      17.683         0.662\n```\n:::\n\n\n\n\nPossiamo ottenere i valori stimati dal modello utilizzando `fitted()` e i residui utilizzando `residuals()`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nmutate(sleep2,\n    fit = fitted(pp_mod),\n    resid = residuals(pp_mod)\n) |>\n    group_by(Subject) %>%\n    slice(c(1, 10)) %>%\n    print(n = +Inf)\n#> # A tibble: 18 × 6\n#> # Groups:   Subject [18]\n#>    Reaction  Days Subject days_deprived   fit  resid\n#>       <dbl> <dbl> <fct>           <dbl> <dbl>  <dbl>\n#>  1     251.     2 308                 0  292. -41.7 \n#>  2     203.     2 309                 0  209.  -5.62\n#>  3     234.     2 310                 0  228.   5.83\n#>  4     284.     2 330                 0  269.  14.5 \n#>  5     302.     2 331                 0  286.  15.4 \n#>  6     273.     2 332                 0  298. -25.5 \n#>  7     277.     2 333                 0  281.  -4.57\n#>  8     243.     2 334                 0  250.  -6.44\n#>  9     254.     2 335                 0  251.   3.50\n#> 10     292.     2 337                 0  313. -20.9 \n#> 11     239.     2 349                 0  241.  -2.36\n#> 12     256.     2 350                 0  262.  -5.80\n#> 13     270.     2 351                 0  262.   7.50\n#> 14     327.     2 352                 0  315.  12.3 \n#> 15     257.     2 369                 0  269. -11.7 \n#> 16     239.     2 370                 0  249. -10.5 \n#> 17     278.     2 371                 0  261.  17.3 \n#> 18     298.     2 372                 0  286.  11.9\n```\n:::\n\n\n\n\nInfine, possiamo ottenere previsioni per nuovi dati utilizzando `predict()`, come abbiamo fatto in precedenza. \n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n## create the table with new predictor values\nndat <- crossing(\n    Subject = sleep2 %>% pull(Subject) %>% levels() %>% factor(),\n    days_deprived = 8:10\n) %>%\n    mutate(Reaction = predict(pp_mod, newdata = .))\n\nndat |> \n    head()\n#> # A tibble: 6 × 3\n#>   Subject days_deprived Reaction\n#>   <fct>           <int>    <dbl>\n#> 1 308                 8     453.\n#> 2 308                 9     473.\n#> 3 308                10     493.\n#> 4 309                 8     235.\n#> 5 309                 9     238.\n#> 6 309                10     242.\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n    geom_line(\n        data = bind_rows(newdata2, ndat),\n        color = \"blue\"\n    ) +\n    geom_point() +\n    scale_x_continuous(breaks = 0:10) +\n    facet_wrap(~Subject) +\n    labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n```\n\n::: {.cell-output-display}\n![](01_multilevel_files/figure-html/unnamed-chunk-38-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Riflessioni Conclusive\n\nQuesto capitolo ha presentato una panoramica sui modelli statistici multilivello, con un focus sull'effetto della deprivazione del sonno sulle prestazioni psicomotorie utilizzando il dataset `sleepstudy`. In tale contesto, sono stati introdotti e discussi concetti fondamentali come il \"complete pooling\", il \"no pooling\" e il \"partial pooling\", esplorandone le implicazioni nella modellazione dei dati con misure ripetute.\n\nL'analisi ha posto l'accento sull'applicazione pratica dei modelli multilivello, con una particolare attenzione alla distinzione tra variabili fisse e casuali e alla loro rilevanza per la struttura del modello. Un aspetto centrale della trattazione è stata la matrice di varianza-covarianza, essenziale per comprendere le relazioni interne ai modelli multilivello.\n\nQuesti modelli rivestono un ruolo cruciale nel campo dell’assessment psicologico e della psicometria, poiché permettono di analizzare dati complessi tenendo conto delle variazioni individuali e di gruppo. Offrono strumenti flessibili per esaminare come fattori contestuali e individuali influenzino il comportamento e le prestazioni psicologiche, un elemento chiave per una valutazione psicologica accurata.\n\nInfine, il capitolo prepara il terreno per il successivo approfondimento sui modelli multilivello nell’ambito del calcolo dell’affidabilità tra giudici, argomento che sarà sviluppato nel capitolo seguente. Inoltre, viene tracciato un collegamento con i modelli di crescita latente, i quali saranno trattati nei capitoli successivi come naturale prosecuzione o alternativa ai modelli multilivello. Questo sottolinea la continuità e la rilevanza di tali approcci nell'ambito della ricerca psicologica e psicometrica.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] kableExtra_1.4.0  repr_1.1.7        lme4_1.1-36       Matrix_1.7-2     \n#>  [5] car_3.1-3         carData_3.0-5     ggokabeito_0.1.0  see_0.10.0       \n#>  [9] MASS_7.3-65       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#> [13] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#> [17] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12     \n#> [21] scales_1.3.0      markdown_1.13     knitr_1.49        lubridate_1.9.4  \n#> [25] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#> [29] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#> [33] tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.0      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [22] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] R6_2.6.1            fastmap_1.2.0       rbibutils_2.3      \n#>  [28] shiny_1.10.0        digest_0.6.37       OpenMx_2.21.13     \n#>  [31] fdrtool_1.2.18      colorspace_2.1-1    rprojroot_2.0.4    \n#>  [34] Hmisc_5.2-2         labeling_0.4.3      timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] ggsignif_0.6.4      corpcor_1.6.10      gtools_3.9.5       \n#>  [46] tools_4.4.2         pbivnorm_0.6.0      foreign_0.8-88     \n#>  [49] zip_2.3.2           httpuv_1.6.15       nnet_7.3-20        \n#>  [52] glue_1.8.0          quadprog_1.5-8      nlme_3.1-167       \n#>  [55] promises_1.3.2      lisrelToR_0.3       grid_4.4.2         \n#>  [58] checkmate_2.3.2     cluster_2.1.8       reshape2_1.4.4     \n#>  [61] generics_0.1.3      gtable_0.3.6        tzdb_0.4.0         \n#>  [64] data.table_1.17.0   hms_1.1.3           utf8_1.2.4         \n#>  [67] xml2_1.3.7          sem_3.1-16          pillar_1.10.1      \n#>  [70] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [73] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [76] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [79] reformulas_0.4.0    svglite_2.1.3       stats4_4.4.2       \n#>  [82] xfun_0.51           qgraph_1.9.8        arm_1.14-4         \n#>  [85] stringi_1.8.4       yaml_2.3.10         pacman_0.5.1       \n#>  [88] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#>  [91] mi_1.1              cli_3.6.4           RcppParallel_5.1.10\n#>  [94] rpart_4.1.24        systemfonts_1.2.1   xtable_1.8-4       \n#>  [97] Rdpack_2.6.2        munsell_0.5.1       Rcpp_1.0.14        \n#> [100] coda_0.19-4.1       png_0.1-8           XML_3.99-0.18      \n#> [103] parallel_4.4.2      jpeg_0.1-10         mvtnorm_1.3-3      \n#> [106] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-28    \n#> [109] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "01_multilevel_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
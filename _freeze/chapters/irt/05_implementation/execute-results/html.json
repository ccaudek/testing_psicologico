{
  "hash": "d7a97bd1888aa2805b92d0c13464b9cb",
  "result": {
    "engine": "knitr",
    "markdown": "# Implementazione {#sec-irt-implementation}\n\n::: callout-important  \n## In questo capitolo apprenderai come:\n\n- comprendere il ruolo del modello di Rasch nella valutazione dei test psicometrici;\n- applicare metodi grafici e statistici per valutare l’adattamento degli item e delle persone;  \n- interpretare curve caratteristiche e curve di informazione per analizzare le prestazioni di un test;  \n- stimare e interpretare parametri delle persone e degli item;  \n- calcolare l’affidabilità condizionale e l’errore standard di misurazione;  \n- utilizzare strumenti per verificare la validità e l’affidabilità complessiva di un test.  \n:::  \n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo 8, *Item Response Theory*, del testo *Principles of psychological assessment* di @petersen2024principles. \n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(eRm, mirt, grid, TAM, ggmirt, psychotools)\n```\n:::\n\n\n\n:::\n\n\n## Introduzione\n\nIn questo capitolo esamineremo il tutorial di @debelak2022introduction.\n\n## Un esempio pratico\n\nIl set di dati `data.fims.Aus.Jpn.scored` contiene le risposte valutate per un sottoinsieme di item da parte di studenti australiani e giapponesi nello studio \"First International Mathematics Study\" (FIMS, Husén, 1967).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(data.fims.Aus.Jpn.scored, package = \"TAM\")\nfims <- data.fims.Aus.Jpn.scored\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(fims)\n#> Rows: 6,371\n#> Columns: 16\n#> $ SEX     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#> $ M1PTI1  <dbl> 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1…\n#> $ M1PTI2  <dbl> 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1…\n#> $ M1PTI3  <dbl> 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1…\n#> $ M1PTI6  <dbl> 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0…\n#> $ M1PTI7  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ M1PTI11 <dbl> 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1…\n#> $ M1PTI12 <dbl> 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ M1PTI14 <dbl> 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1…\n#> $ M1PTI17 <dbl> 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0…\n#> $ M1PTI18 <dbl> 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n#> $ M1PTI19 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ M1PTI21 <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n#> $ M1PTI22 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ M1PTI23 <dbl> 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1…\n#> $ country <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n```\n:::\n\n\n\n\nOltre alle risposte sui 14 item di matematica, il data set contiene anche informazioni sul genere del partecipate e sul paese d'origine.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfims$SEX <- as.factor(fims$SEX)\nlevels(fims$SEX) <- c(\"male\", \"female\")\nfims$country <- as.factor(fims$country)\nlevels(fims$country) <- c(\"Australia\", \"Japan\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fims[, c(\"SEX\", \"country\")])\n#>      SEX            country    \n#>  male  :3319   Australia:4320  \n#>  female:3052   Japan    :2051\n```\n:::\n\n\n\n\nEsaminiamo le risposte dei primi 400 partecipanti. Con le seguenti istruzioni, per facilitare la manipolazione dei dati, cambiamo il nome delle colonne.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresponses <- fims[1:400, 2:15]\ncolnames(responses) <- gsub(\"M1PTI\", \"I\", colnames(responses))\nglimpse(responses)\n#> Rows: 400\n#> Columns: 14\n#> $ I1  <dbl> 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,…\n#> $ I2  <dbl> 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,…\n#> $ I3  <dbl> 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,…\n#> $ I6  <dbl> 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,…\n#> $ I7  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ I11 <dbl> 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,…\n#> $ I12 <dbl> 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ I14 <dbl> 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,…\n#> $ I17 <dbl> 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,…\n#> $ I18 <dbl> 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,…\n#> $ I19 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ I21 <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#> $ I22 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n#> $ I23 <dbl> 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,…\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngender <- as.factor(fims$SEX[1:400])\nlevels(gender) <- c(\"male\", \"female\")\n```\n:::\n\n\n\n\n## Modello di Rasch\n\nUn'analisi IRT può essere paragonata a un'analisi fattoriale. Dopo avere adattato il modello di Rasch ai dati usando `mirt()`, possiamo usare la funzione `summary()` per ottenere quella che viene definita \"soluzione fattoriale\", che include i carichi fattoriali (F1) e le comunalità (h2). Le comunalità, essendo carichi fattoriali al quadrato, sono interpretate come la varianza spiegata in un item dal tratto latente. Nel caso presente, tutti gli item hanno una relazione sostanziale (saturazioni $\\approx$ .50) con il tratto latente, indicando che il tratto latente è un buon indicatore della varianza osservata in quegli item. Questo suggerisce che il tratto latente è in grado di spiegare una porzione almento moderata della varianza nei punteggi degli item.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmirt_rm <- mirt(responses, 1, itemtype = \"Rasch\", verbose = FALSE)\nsummary(mirt_rm)\n#>     F1    h2\n#> I1     0.238\n#> I2     0.238\n#> I3     0.238\n#> I6     0.238\n#> I7     0.238\n#> I11    0.238\n#> I12    0.238\n#> I14    0.238\n#> I17    0.238\n#> I18    0.238\n#> I19    0.238\n#> I21    0.238\n#> I22    0.238\n#> I23    0.238\n#> \n#> SS loadings:  0 \n#> Proportion Var:  0 \n#> \n#> Factor correlations: \n#> \n#>    F1\n#> F1  1\n```\n:::\n\n\n\n\nNell'IRT, tuttavia, siamo generalmente più interessati ai parametri di discriminazione e difficoltà. Questi parametri possono essere estratti dall’oggetto creato da **mirt()** nel seguente modo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparams_rm <- coef(mirt_rm, IRTpars = TRUE, simplify = TRUE)\nround(params_rm$items, 2) # g = c = guessing parameter\n#>     a     b g u\n#> I1  1 -1.10 0 1\n#> I2  1 -1.25 0 1\n#> I3  1 -2.04 0 1\n#> I6  1 -0.05 0 1\n#> I7  1  2.53 0 1\n#> I11 1 -1.25 0 1\n#> I12 1  0.81 0 1\n#> I14 1 -0.50 0 1\n#> I17 1  1.33 0 1\n#> I18 1 -0.40 0 1\n#> I19 1  2.06 0 1\n#> I21 1  1.75 0 1\n#> I22 1  2.41 0 1\n#> I23 1 -1.93 0 1\n```\n:::\n\n\n\n\n- **$a$ (Discriminazione)**: Il parametro $a$ (discriminazione) rappresenta la pendenza delle curve caratteristiche degli item (ICC - Item Characteristic Curves). Una pendenza elevata (valore alto di $a$) indica che l'item è molto efficace nel distinguere tra individui con livelli diversi del tratto latente (ad esempio, abilità). Questo significa che piccole variazioni nel tratto latente portano a grandi cambiamenti nella probabilità di rispondere correttamente all'item. Una pendenza bassa (valore basso di $a$) suggerisce che l’item non è altrettanto efficace nel discriminare tra livelli diversi del tratto latente. In questo caso, anche ampie variazioni nel tratto latente comportano solo piccoli cambiamenti nella probabilità di risposta corretta. Nel modello di Rasch si assume che tutti gli item abbiano la stessa pendenza (o potere discriminante), e quindi tutti i valori di \n$a$ sono fissati allo stesso valore (ovvero 1).\n- **$b$ (Difficoltà)**: Rappresenta il livello di abilità a cui un rispondente ha il 50% di probabilità di rispondere correttamente all'item. Un valore positivo indica un item più difficile (richiede un livello di abilità superiore per rispondere correttamente), mentre un valore negativo indica un item più facile. Ad esempio, I7 ha un valore di difficoltà di 2.53, il che significa che è relativamente difficile, mentre I3, con un valore di -2.04, è relativamente facile.\n- **$g$ (Probabilità di Indovinare)**: In questo modello, la probabilità di indovinare è impostata a zero per tutti gli item, il che è coerente con il modello di Rasch, dove non si considera la possibilità di indovinare correttamente un item per caso.\n\nAdattiamo ora ai dati il modello di Rasch con la funzione `eRm::RM()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrm_sum0 <- eRm::RM(responses)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(rm_sum0)\n#> \n#> Results of RM estimation: \n#> \n#> Call:  eRm::RM(X = responses) \n#> \n#> Conditional log-likelihood: -1887 \n#> Number of iterations: 23 \n#> Number of parameters: 13 \n#> \n#> Item (Category) Difficulty Parameters (eta): with 0.95 CI:\n#>     Estimate Std. Error lower CI upper CI\n#> I2    -1.420      0.121   -1.658   -1.183\n#> I3    -2.210      0.145   -2.494   -1.926\n#> I6    -0.215      0.108   -0.426   -0.004\n#> I7     2.364      0.170    2.031    2.697\n#> I11   -1.420      0.121   -1.658   -1.183\n#> I12    0.642      0.113    0.422    0.863\n#> I14   -0.663      0.110   -0.879   -0.448\n#> I17    1.152      0.122    0.913    1.391\n#> I18   -0.565      0.109   -0.778   -0.351\n#> I19    1.889      0.146    1.602    2.175\n#> I21    1.578      0.134    1.315    1.841\n#> I22    2.244      0.163    1.925    2.564\n#> I23   -2.103      0.141   -2.379   -1.827\n#> \n#> Item Easiness Parameters (beta) with 0.95 CI:\n#>          Estimate Std. Error lower CI upper CI\n#> beta I1     1.273      0.118    1.041    1.504\n#> beta I2     1.420      0.121    1.183    1.658\n#> beta I3     2.210      0.145    1.926    2.494\n#> beta I6     0.215      0.108    0.004    0.426\n#> beta I7    -2.364      0.170   -2.697   -2.031\n#> beta I11    1.420      0.121    1.183    1.658\n#> beta I12   -0.642      0.113   -0.863   -0.422\n#> beta I14    0.663      0.110    0.448    0.879\n#> beta I17   -1.152      0.122   -1.391   -0.913\n#> beta I18    0.565      0.109    0.351    0.778\n#> beta I19   -1.889      0.146   -2.175   -1.602\n#> beta I21   -1.578      0.134   -1.841   -1.315\n#> beta I22   -2.244      0.163   -2.564   -1.925\n#> beta I23    2.103      0.141    1.827    2.379\n```\n:::\n\n\n\n\nLa funzione `RM()` impone un vincolo sulle stime dei parametri di difficoltà degli item. Questo vincolo è che la media di questi parametri (beta) sia zero. Questo approccio è noto come \"parametrizzazione ancorata\" o \"centrata\". Il vantaggio di questa parametrizzazione è che posiziona la scala di difficoltà degli item in un punto di riferimento fisso, facilitando il confronto tra diversi set di item o tra diverse applicazioni dello stesso test.\n\nVerifichiamo.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoef(rm_sum0) \n#>  beta I1  beta I2  beta I3  beta I6  beta I7 beta I11 beta I12 beta I14 \n#>    1.273    1.420    2.210    0.215   -2.364    1.420   -0.642    0.663 \n#> beta I17 beta I18 beta I19 beta I21 beta I22 beta I23 \n#>   -1.152    0.565   -1.889   -1.578   -2.244    2.103\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum(rm_sum0$betapar)\n#> [1] 8.88e-16\n```\n:::\n\n\n\n\nNella parametrizzazione utilizzata da `mirt()`, i parametri di difficoltà vengono invece stimati senza un vincolo sulla loro media. Questo può portare a stime dei parametri di difficoltà che differiscono da quelle ottenute tramite `RM()`. Questa libertà nella stima dei parametri permette una flessibilità maggiore, specialmente in modelli IRT complessi o multidimensionali, ma può rendere più complesso il confronto diretto tra set di item o test differenti.\n\nDalla soluzione prodotta da `eRm::RM()` possiamo estrarre le stime sia nei termini della facilità che della difficoltà degli item.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntab <- data.frame(\n    item_score = colSums(responses),\n    easiness = coef(rm_sum0),\n    difficulty = -coef(rm_sum0)\n)\ntab[order(tab$item_score), ]\n#>     item_score easiness difficulty\n#> I7          40   -2.364      2.364\n#> I22         44   -2.244      2.244\n#> I19         58   -1.889      1.889\n#> I21         73   -1.578      1.578\n#> I17         98   -1.152      1.152\n#> I12        134   -0.642      0.642\n#> I6         204    0.215     -0.215\n#> I18        233    0.565     -0.565\n#> I14        241    0.663     -0.663\n#> I1         287    1.273     -1.273\n#> I2         297    1.420     -1.420\n#> I11        297    1.420     -1.420\n#> I23        336    2.103     -2.103\n#> I3         341    2.210     -2.210\n```\n:::\n\n\n\n\nIn alterativa, possiamo usare il pacchetto `TAM`. Come nel caso di `mirt`, anche in questo caso viene usata una procedura di stima di massima verosimiglianza marginale. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntam_rm <- tam.mml(responses)\n#> ....................................................\n#> Processing Data      2025-02-24 07:51:53.814537 \n#>     * Response Data: 400 Persons and  14 Items \n#>     * Numerical integration with 21 nodes\n#>     * Created Design Matrices   ( 2025-02-24 07:51:53.815701 )\n#>     * Calculated Sufficient Statistics   ( 2025-02-24 07:51:53.816944 )\n#> ....................................................\n#> Iteration 1     2025-02-24 07:51:53.818038\n#> E Step\n#> M Step Intercepts   |----\n#>   Deviance = 5667.9246\n#>   Maximum item intercept parameter change: 0.315\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.123\n#> ....................................................\n#> Iteration 2     2025-02-24 07:51:53.819197\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5633.0417 | Absolute change: 34.9 | Relative change: 0.00619\n#>   Maximum item intercept parameter change: 0.00328\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.00796\n#> ....................................................\n#> Iteration 3     2025-02-24 07:51:53.819523\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5633.0057 | Absolute change: 0.036 | Relative change: 6.39e-06\n#>   Maximum item intercept parameter change: 0.0022\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.00584\n#> ....................................................\n#> Iteration 4     2025-02-24 07:51:53.819821\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9887 | Absolute change: 0.017 | Relative change: 3.02e-06\n#>   Maximum item intercept parameter change: 0.00151\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.00406\n#> ....................................................\n#> Iteration 5     2025-02-24 07:51:53.820123\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9805 | Absolute change: 0.0081 | Relative change: 1.44e-06\n#>   Maximum item intercept parameter change: 0.00104\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.00281\n#> ....................................................\n#> Iteration 6     2025-02-24 07:51:53.820413\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9767 | Absolute change: 0.0039 | Relative change: 6.8e-07\n#>   Maximum item intercept parameter change: 0.00071\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.00194\n#> ....................................................\n#> Iteration 7     2025-02-24 07:51:53.820725\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9749 | Absolute change: 0.0018 | Relative change: 3.2e-07\n#>   Maximum item intercept parameter change: 0.000486\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.00134\n#> ....................................................\n#> Iteration 8     2025-02-24 07:51:53.821029\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.974 | Absolute change: 9e-04 | Relative change: 1.5e-07\n#>   Maximum item intercept parameter change: 0.000333\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.000925\n#> ....................................................\n#> Iteration 9     2025-02-24 07:51:53.821312\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9736 | Absolute change: 4e-04 | Relative change: 7e-08\n#>   Maximum item intercept parameter change: 0.000228\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.000637\n#> ....................................................\n#> Iteration 10     2025-02-24 07:51:53.821597\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9734 | Absolute change: 2e-04 | Relative change: 3e-08\n#>   Maximum item intercept parameter change: 0.000156\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.000439\n#> ....................................................\n#> Iteration 11     2025-02-24 07:51:53.821889\n#> E Step\n#> M Step Intercepts   |--\n#>   Deviance = 5632.9733 | Absolute change: 1e-04 | Relative change: 2e-08\n#>   Maximum item intercept parameter change: 0.000107\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.000302\n#> ....................................................\n#> Iteration 12     2025-02-24 07:51:53.822159\n#> E Step\n#> M Step Intercepts   |-\n#>   Deviance = 5632.9733 | Absolute change: 0 | Relative change: 1e-08\n#>   Maximum item intercept parameter change: 7.3e-05\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.000208\n#> ....................................................\n#> Iteration 13     2025-02-24 07:51:53.822413\n#> E Step\n#> M Step Intercepts   |-\n#>   Deviance = 5632.9732 | Absolute change: 0 | Relative change: 0\n#>   Maximum item intercept parameter change: 5e-05\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 0.000143\n#> ....................................................\n#> Iteration 14     2025-02-24 07:51:53.822689\n#> E Step\n#> M Step Intercepts   |-\n#>   Deviance = 5632.9732 | Absolute change: 0 | Relative change: 0\n#>   Maximum item intercept parameter change: 3.4e-05\n#>   Maximum item slope parameter change: 0\n#>   Maximum regression parameter change: 0\n#>   Maximum variance parameter change: 9.8e-05\n#> ....................................................\n#> Item Parameters\n#>    xsi.index xsi.label    est\n#> 1          1        I1 -1.103\n#> 2          2        I2 -1.250\n#> 3          3        I3 -2.042\n#> 4          4        I6 -0.048\n#> 5          5        I7  2.531\n#> 6          6       I11 -1.250\n#> 7          7       I12  0.813\n#> 8          8       I14 -0.495\n#> 9          9       I17  1.326\n#> 10        10       I18 -0.397\n#> 11        11       I19  2.064\n#> 12        12       I21  1.754\n#> 13        13       I22  2.414\n#> 14        14       I23 -1.935\n#> ...................................\n#> Regression Coefficients\n#>      [,1]\n#> [1,]    0\n#> \n#> Variance:\n#>        [,1]\n#> [1,] 0.9037\n#> \n#> \n#> EAP Reliability:\n#> [1] 0.656\n#> \n#> -----------------------------\n#> Start:  2025-02-24 07:51:53.813656\n#> End:  2025-02-24 07:51:53.825199 \n#> Time difference of 0.0115 secs\n```\n:::\n\n\n\n\nPossiamo ispezionare le stime dei parametri con\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntam_rm$item\n#>     item   N     M xsi.item AXsi_.Cat1 B.Cat1.Dim1\n#> I1    I1 400 0.718   -1.103     -1.103           1\n#> I2    I2 400 0.743   -1.250     -1.250           1\n#> I3    I3 400 0.853   -2.042     -2.042           1\n#> I6    I6 400 0.510   -0.048     -0.048           1\n#> I7    I7 400 0.100    2.531      2.531           1\n#> I11  I11 400 0.743   -1.250     -1.250           1\n#> I12  I12 400 0.335    0.813      0.813           1\n#> I14  I14 400 0.603   -0.495     -0.495           1\n#> I17  I17 400 0.245    1.326      1.326           1\n#> I18  I18 400 0.583   -0.397     -0.397           1\n#> I19  I19 400 0.145    2.064      2.064           1\n#> I21  I21 400 0.182    1.755      1.755           1\n#> I22  I22 400 0.110    2.415      2.415           1\n#> I23  I23 400 0.840   -1.935     -1.935           1\n```\n:::\n\n\n\n\nLe colonne di questo output possono essere interpretate come segue:\n\n- `item` indica il nome dell'item.\n- `N` indica il numero di candidati che hanno risposto a ciascun item. In questo caso, tutti i 400 candidati hanno risposto a ogni item.\n- `M` è la media delle risposte a ciascun item. Nel caso di un item con una media alta ciò significa che a tale item è stata fornita uba risposta corretta da una alta percentuale di candidati.\n- `xsi.item` per il modello di Rasch è il parametro di difficoltà dell'item. Gli item con valori alti tendono ad essere più difficili. \n- `AXsi.Cat1` ripete la difficoltà dell'item per il modello di Rasch, ma permetterebbe l'inclusione di una matrice di design A, che non abbiamo usato qui. Per i modelli politomici, l'output includerà parametri dell'item per più di una categoria.\n- `B.Cat1.Dim1` è il parametro di discriminazione o pendenza dell'item. Per il modello di Rasch, la pendenza è 1 per ogni item.\n\nPossiamo mostrare solo la difficoltà e l'errore standard con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntam_rm$xsi\n#>        xsi se.xsi\n#> I1  -1.103  0.120\n#> I2  -1.250  0.123\n#> I3  -2.042  0.149\n#> I6  -0.048  0.109\n#> I7   2.531  0.174\n#> I11 -1.250  0.123\n#> I12  0.813  0.115\n#> I14 -0.495  0.111\n#> I17  1.326  0.125\n#> I18 -0.397  0.111\n#> I19  2.064  0.150\n#> I21  1.755  0.138\n#> I22  2.415  0.168\n#> I23 -1.935  0.145\n```\n:::\n\n\n\n\nLa parametrizzazione classica IRT si ottiene con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntam_rm$item_irt\n#>    item alpha   beta\n#> 1    I1     1 -1.103\n#> 2    I2     1 -1.250\n#> 3    I3     1 -2.042\n#> 4    I6     1 -0.048\n#> 5    I7     1  2.531\n#> 6   I11     1 -1.250\n#> 7   I12     1  0.813\n#> 8   I14     1 -0.495\n#> 9   I17     1  1.326\n#> 10  I18     1 -0.397\n#> 11  I19     1  2.064\n#> 12  I21     1  1.755\n#> 13  I22     1  2.415\n#> 14  I23     1 -1.935\n```\n:::\n\n\n\n\n## Valutazione del Test\n\nIl primo approccio per valutare i test consiste nell’utilizzo di metodi grafici. Tra questi, il primo strumento che esaminiamo è la **mappa persona-item**, utile per verificare se il campione di partecipanti copre l’intera gamma di difficoltà degli item e se, viceversa, gli item coprono l’intero spettro delle abilità del campione. \n\nIl secondo metodo riguarda il confronto tra le **Curve Caratteristiche degli Item (ICC)** teoriche ed empiriche, che consente di identificare eventuali item con scarsa aderenza al modello.\n\nInfine, il terzo approccio è il **test grafico** per il Funzionamento Differenziale degli Item (DIF), che offre un metodo visivo per rilevare discrepanze nel comportamento degli item tra gruppi di rispondenti.\n\n### Mappa Persona-Item\n\nLa **Mappa Persona-Item** (nota anche come Wright Map o *person-item map*) è uno strumento grafico utile per valutare quanto efficacemente gli item coprono l’intervallo delle abilità latenti nel campione studiato. Questo strumento consente di rispondere alla domanda: *Quanto bene gli item riflettono la gamma delle abilità latenti presenti nel campione?*\n\nLa costruzione della mappa avviene in due fasi:\n\n1. **Distribuzione delle abilità latenti**: Si rappresenta graficamente la distribuzione delle abilità latenti ($\\theta$) del campione di persone.\n2. **Difficoltà degli item**: Si sovrappone la difficoltà di ciascun item sulla stessa scala di $\\theta$ utilizzata per le abilità.\n\nL’allineamento di queste due rappresentazioni permette di valutare visivamente la corrispondenza tra le abilità del campione e le difficoltà degli item. Idealmente, le difficoltà degli item dovrebbero coprire l’intera gamma delle abilità delle persone, e viceversa. Questa corrispondenza è essenziale per garantire una stima precisa dei parametri degli item e delle abilità dei rispondenti.\n\nLa mappa persona-item fornisce quindi una panoramica intuitiva e immediata dell’adeguatezza del test rispetto al campione studiato, evidenziando eventuali gap nella copertura delle abilità o difficoltà non equilibrate.\n\nPer generare una mappa persona-item, è possibile utilizzare la funzione:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nitempersonMap(mirt_rm)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesta funzione consente di visualizzare facilmente le distribuzioni e di valutare il bilanciamento tra le abilità delle persone e le difficoltà degli item.\n\nLa parte superiore della mappa persona-item mostra un istogramma delle stime dei parametri di abilità, mentre la parte inferiore mostra le stime delle difficoltà per ciascun item del test. Per ogni item, la stima della difficoltà è indicata dalla posizione del punto sulla linea tratteggiata corrispondente a quell'item. Ad esempio, la difficoltà stimata per l'item 1 corrisponde alla posizione del punto sulla linea tratteggiata più in alto. La mappa persona-item offre un controllo visivo di coerenza per le stime del nostro modello IRT (Teoria della Risposta all'Item). Le stime delle abilità sono più accurate quando cadono nel mezzo della distribuzione dei parametri degli item e viceversa. Pertanto, idealmente, l'istogramma delle abilità e le stime delle difficoltà dovrebbero essere centrate sullo stesso punto e mostrare un'ampia sovrapposizione. Nel nostro test, sembra essere questo il caso.\n\nIn alternativa, possiamo usare la funzione `plotPImap()` di `eRm`.\n\n### ICC Empiriche\n\nLe Curve Caratteristiche degli Item (ICC) descrivono la relazione teorica tra l'abilità dei partecipanti al test e la probabilità di una risposta corretta che ci aspettiamo sotto il modello di Rasch per una data difficoltà. La ICC attesa per un item può essere tracciata dopo che la sua difficoltà è stata stimata.  Oltre alle probabilità attese di una risposta corretta illustrate dall'ICC, possiamo anche tracciare le frequenze relative empiriche di una risposta corretta. Queste frequenze relative empiriche sono indicate nella figura come punti e vengono chiamate ICC empiriche. \n\nUsando `eRm` possimo generare le ECC empiriche nel modo seguente.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplotICC(\n    rm_sum0, \n    item.subset = \"all\",\n    empICC = list(\"raw\"), \n    empCI = list()\n)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-20-2.png){fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-20-3.png){fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-20-4.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nLe ICC empiriche sono rappresentate dai singoli punti, mentre la ICC attesa sotto il modello di Rasch è indicata dalla linea liscia. Dalle figure precedenti, per gli item 12 e 14 notiamo che in generale la forma dell'ICC empirica è molto ben allineata con l'ICC attesa, ma per l'item 12 l'ICC empirica mostra valori sopra zero anche per le abilità più basse a sinistra della dimensione latente. Questo potrebbe indicare una tendenza al tentativo di indovinare (guessing). Per l'item 19, l'ICC empirica appare più ripida dell'ICC attesa sotto il modello di Rasch. Mostra un salto molto più pronunciato tra la prima metà approssimativa dei punti e i punti rimanenti. Per l'item 21, al contrario, l'ICC empirica è molto più piatta rispetto a quella attesa. Confronteremo la nostra impressione visiva con le statistiche di adattamento degli item per questi item di seguito.\n\nÈ possibile visualizzare le ICC attese di tutti gli item del test in un unico grafico utilizzando la funzione `plotjointICC()`. Questo grafico ci permette di esaminare come la difficoltà influenzi la probabilità che un candidato risponda correttamente a un item. Ricordiamo che la difficoltà di un item è definita come il livello di abilità in cui una persona ha una probabilità del 50% di rispondere correttamente all’item. Abbiamo aggiunto una linea tratteggiata orizzontale alla probabilità di 0.5 usando il comando `segments`. Il punto in cui un'ICC interseca questa linea rappresenta la sua difficoltà. Questo ci permette di leggere facilmente le difficoltà relative degli item dal grafico. Spostandosi da sinistra a destra, il primo ICC intersecato dalla linea orizzontale corrisponde all’item meno difficile (in questo caso l’item 3, seguito da vicino dall’item 23, come indicato nell’ordine degli item nella legenda), e l’ultimo ICC intersecato dalla linea orizzontale è per l’item più difficile (in questo caso l’item 7).\n\nDa notare che le ICC attese nella figura sono parallele per definizione. Il modello di Rasch assume che le ICC siano parallele, quindi produrrà sempre ICC teoriche o attese parallele, anche quando gli item hanno in realtà pendenze o tassi di guessing diversi, come abbiamo visto in precedenza per le ICC empiriche.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neRm::plotjointICC(rm_sum0, cex = 0.7)\nsegments(-2.5, 0.5, 4, 0.5, lty = 2)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nIn alternativa, possiamo generare le ICC usando il pacchetto `mirt`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmirt_rm <- mirt(responses, 1, \"Rasch\")\n#> \nIteration: 1, Log-Lik: -2816.924, Max-Change: 0.03346\nIteration: 2, Log-Lik: -2816.650, Max-Change: 0.02041\nIteration: 3, Log-Lik: -2816.562, Max-Change: 0.01357\nIteration: 4, Log-Lik: -2816.520, Max-Change: 0.01027\nIteration: 5, Log-Lik: -2816.501, Max-Change: 0.00584\nIteration: 6, Log-Lik: -2816.493, Max-Change: 0.00395\nIteration: 7, Log-Lik: -2816.490, Max-Change: 0.00307\nIteration: 8, Log-Lik: -2816.488, Max-Change: 0.00174\nIteration: 9, Log-Lik: -2816.487, Max-Change: 0.00118\nIteration: 10, Log-Lik: -2816.487, Max-Change: 0.00094\nIteration: 11, Log-Lik: -2816.487, Max-Change: 0.00054\nIteration: 12, Log-Lik: -2816.487, Max-Change: 0.00036\nIteration: 13, Log-Lik: -2816.487, Max-Change: 0.00028\nIteration: 14, Log-Lik: -2816.487, Max-Change: 0.00016\nIteration: 15, Log-Lik: -2816.487, Max-Change: 0.00011\nIteration: 16, Log-Lik: -2816.487, Max-Change: 0.00008\nplot(mirt_rm, type = \"trace\")\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nLe curve caratteristiche degli item offrono un quadro dettagliato e visuale di come ciascun item del test si comporta attraverso diversi livelli dell'abilità latente. Per esempio:\n\n1. **Visualizzazione della Difficoltà e della Discriminazione:**\n   - Supponiamo di avere un item che mostra una curva con una ripida salita in un punto specifico della scala di abilità. Questo indica che l'item ha una difficoltà concentrata attorno a quel punto e che discrimina efficacemente tra rispondenti con abilità appena al di sotto e al di sopra di quel livello. \n   - Al contrario, una curva più graduale suggerisce che l'item è meno discriminante, con una variazione più ampia nella probabilità di risposta corretta a seconda del livello di abilità.\n\n2. **Identificazione di Lacune nella Valutazione:**\n   - Visualizzando le curve di più item, possiamo identificare se ci sono lacune nella copertura dell'abilità latente. Ad esempio, se tutti gli item hanno curve che si concentrano su livelli di abilità bassi, potrebbe esserci una mancanza di item difficili per misurare l'abilità ad alti livelli.\n   - Inoltre, se le curve degli item si sovrappongono eccessivamente, potrebbe indicare ridondanza tra gli item, suggerendo che alcuni di essi non aggiungono informazioni uniche alla valutazione.\n\n3. **Confronto tra Diversi Tipi di Item:**\n   - Per esempio, gli item progettati per misurare concetti di base potrebbero avere curve che mostrano alta probabilità di risposta corretta anche a livelli di abilità bassi.\n   - Al contrario, item progettati per essere più impegnativi potrebbero mostrare probabilità elevate di risposta corretta solo a livelli di abilità più alti.\n\n### Test Grafico\n\nIl test grafico del modello, basato sui principi di Rasch (1960), è un metodo intuitivo per valutare l'invarianza degli item in un test, confrontando i parametri degli item stimati per due gruppi di persone. Affinché il modello di Rasch sia considerato valido, è necessario che le stime dei parametri degli item per i diversi gruppi concordino, fino a una trasformazione lineare. In termini pratici, ciò si traduce nel fatto che, quando visualizzate in un grafico, le stime dei parametri degli item dei due gruppi dovrebbero allinearsi lungo una linea retta.\n\nPer complementare questa analisi, possiamo ricorrere al test del rapporto di verosimiglianza di Andersen (1973), un approccio ben consolidato per verificare l'adeguatezza del modello di Rasch nel rappresentare il comportamento dei partecipanti ai test. Il test di Andersen valuta se le stime dei parametri degli item rimangono consistenti tra diversi gruppi di partecipanti. Se i parametri degli item stimati individualmente per ciascun gruppo differiscono significativamente, ciò indica che il modello di Rasch potrebbe non essere un'adeguata rappresentazione del comportamento osservato nei test.\n\nA differenza del test grafico, il test del rapporto di verosimiglianza confronta il massimo della verosimiglianza condizionata sotto il modello di Rasch con il massimo della verosimiglianza condizionata quando i parametri degli item possono variare tra i gruppi. Questa metodologia offre un'indicazione di quanto efficacemente ciascun modello rappresenti il comportamento dei partecipanti.\n\nIl test del rapporto di verosimiglianza utilizza la statistica di test $T = −2 \\cdot log(LR)$, che ha una distribuzione campionaria approssimativamente $\\chi^2$ per campioni grandi. Valori del rapporto di verosimiglianza inferiori a 1, o valori elevati di T, suggeriscono una violazione del modello di Rasch.\n\nIl test di Andersen è implementato nel pacchetto `eRm` in `R`, offrendo uno strumento utile per l'analisi. Tuttavia, è importante notare che un risultato non significativo in questo test non può essere interpretato automaticamente come supporto per il modello di Rasch, specialmente se il modello più generale non descrive adeguatamente i dati. Inoltre, la capacità di rilevare differenze tra i gruppi specificati dipende dall'effettiva diversità dei parametri del modello tra questi gruppi. Sono stati messi a punto approcci più flessibili per rilevare le differenze nei parametri.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrt_mean_split <- LRtest(rm_sum0, splitcr = \"mean\")\nlrt_mean_split\n#> \n#> Andersen LR-test: \n#> LR-value: 79.7 \n#> Chi-square df: 13 \n#> p-value:  0\n```\n:::\n\n\n\n\nL'output di questo test mostra una violazione significativa del modello di Rasch al livello $\\alpha$ = 0.05. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplotGOF(\n    lrt_mean_split,\n    tlab = \"item\", pos = 1,\n    main = \"Difficulty by Score (with Item Names)\",\n    conf = list(gamma = 0.95, col = 1)\n)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nOra possiamo tracciare le stime delle difficoltà di ciascun gruppo utilizzando la funzione `plotGOF()` per creare il test grafico. La funzione `plotGOF()` prende il risultato di `LRtest()` e traccia le stime dei parametri degli item per i due gruppi. Per facilitare la valutazione visiva, `plotGOF()` può opzionalmente etichettare gli item e aggiungere ellissi di confidenza. \n\nPer creare il grafico per il test grafico basato sulla divisione media, possiamo procedere in questo modo: ogni piccolo cerchio nella Figura mostra le stime delle difficoltà per un singolo item. La coordinata x di un cerchio indica la sua stima di difficoltà per i partecipanti al test con punteggi sotto la media e la sua coordinata y indica la stima di difficoltà per i partecipanti al test con punteggi sopra la media. La linea y = x è fornita come riferimento, poiché i punti che cadono su questa linea avrebbero la stessa stima in entrambi i gruppi. La distanza tra qualsiasi punto e la linea di riferimento y = x indica quanto le stime differiscono tra i due gruppi. Indica anche la direzione di questa differenza. Gli item sotto la linea sono più difficili per i partecipanti al test con punteggi sotto la media, mentre gli item sopra la linea sono più difficili per i partecipanti al test con punteggi sopra la media.\n\nGli assi orizzontali e verticali mostrano intervalli di confidenza per le stime per ciascun gruppo di partecipanti al test. La larghezza di ciascun intervallo di confidenza è determinata dall'elemento gamma della lista fornita a `conf`. L'impostazione predefinita `gamma = .95` produce intervalli di confidenza al 95% per ciascun asse dell'ellisse. Quando un'ellisse di confidenza non incrocia la linea di riferimento, l'item rispettivo è diagnosticato come mostrante un significativo DIF.\n\nLa figura indica che gli item 2, 6, 21 e 22 differiscono significativamente tra le persone con punteggi sopra e sotto la media, poiché le loro ellissi di confidenza non incrociano la linea di riferimento. Gli item 21 e 22 sono più difficili per le persone con punteggi pari o superiori alla media, mentre gli item 2 e 6 sono più difficili per le persone con punteggi sotto la media. Tali violazioni del modello possono verificarsi quando le ICC osservate differiscono dalle ICC attese sotto il modello di Rasch per i partecipanti al test con abilità basse e alte. Questo può accadere, ad esempio, se è presente il tentativo di indovinare (guessing), o se la pendenza è più ripida o meno ripida di quanto previsto dal modello di Rasch.\n\nPossiamo anche fornire all'argomento `splitcr` una variabile che divide i partecipanti al test in gruppi. Ad esempio, possiamo testare se i parametri degli item differiscono in base al genere passando un vettore contenente le appartenenze di gruppo come argomento splitcr. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrt_gender <- LRtest(rm_sum0, splitcr = gender)\nlrt_gender\n#> \n#> Andersen LR-test: \n#> LR-value: 33 \n#> Chi-square df: 13 \n#> p-value:  0.002\n```\n:::\n\n\n\n\nCome nel test precedente, anche il Test del Rapporto di Verosimiglianza (LRT) per il genere indica una violazione significativa del modello di Rasch al livello α = 0.05.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplotGOF(\n    lrt_gender,\n    tlab = \"item\", pos = 1,\n    main = \"Difficulty by Score (with Item Names)\",\n    conf = list(gamma = 0.95, col = 1)\n)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nLa figura indica che gli item 2, 7 e 21 differiscono tra partecipanti al test femminili e maschili. Gli item 2 e 7 sono più difficili per i partecipanti femminili, mentre l'item 21 è più difficile per i partecipanti maschili.\n\n### Test di Wald\n\nLe impostazioni del test del rapporto di verosimiglianza di Andersen (1973) e del test di Wald sono molto simili. Entrambi i test si basano sull'idea che il modello di Rasch sia un modello ragionevole per i dati dei test solo se i parametri degli item stimati non variano sistematicamente tra gruppi di persone. In entrambi i test, consideriamo le stime dei parametri degli item per ciascun gruppo di persone. A differenza del test del rapporto di verosimiglianza, tuttavia, il test di Wald confronta direttamente le stime dei parametri degli item dei gruppi. In sostanza, il test di Wald calcola la differenza tra la stima del primo gruppo della difficoltà dell'item i, β̂(1)i, e quella del secondo gruppo, β̂(2)i. Questa differenza viene divisa per il suo errore standard per tenere conto del fatto che tutte le stime sono soggette a rumore. Questo porta alla statistica di test per l'item i:\n\n$$ \nT_i = \\frac{\\hat{\\beta}^{(1)}_i - \\hat{\\beta}^{(2)}_i}{\\sqrt{se(\\hat{\\beta}^{(1)}_i)^2 + se(\\hat{\\beta}^{(2)}_i)^2}}, \n$$\n\ndove $ se(\\hat{\\beta}^{(1)}_i) $ e $ se(\\hat{\\beta}^{(2)}_i) $ indicano rispettivamente gli errori standard di $ \\hat{\\beta}^{(1)}_i $ e $ \\hat{\\beta}^{(2)}_i $.\n\nPer campioni di grandi dimensioni, $ T_i $ approssimativamente segue una distribuzione normale standard sotto l'ipotesi nulla che il vero parametro dell'item sia lo stesso per entrambi i gruppi. Valori estremi di $ T_i $ sono improbabili sotto la distribuzione normale. Quindi, un valore estremo di $ T_i $, con un piccolo valore p, indica che l'item i viola il modello di Rasch.\n\nEseguiamo il test con `R`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nWaldtest(rm_sum0, splitcr = \"mean\")\n#> \n#> Wald test on item level (z-values):\n#> \n#>          z-statistic p-value\n#> beta I1       -0.514   0.607\n#> beta I2       -3.328   0.001\n#> beta I3       -0.838   0.402\n#> beta I6       -2.555   0.011\n#> beta I7        0.210   0.834\n#> beta I11      -1.773   0.076\n#> beta I12       1.562   0.118\n#> beta I14       1.821   0.069\n#> beta I17       1.550   0.121\n#> beta I18       0.333   0.739\n#> beta I19      -1.827   0.068\n#> beta I21       5.768   0.000\n#> beta I22       4.106   0.000\n#> beta I23      -1.560   0.119\n```\n:::\n\n\n\n\nQuesti test indicano nuovamente che gli item 2, 6, 21 e 22 differiscono significativamente tra i partecipanti al test con punteggi sopra e sotto la media.\n\nPossiamo anche eseguire il test per la differenza tra maschi e femmine:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nWaldtest(rm_sum0, splitcr = gender)\n#> \n#> Wald test on item level (z-values):\n#> \n#>          z-statistic p-value\n#> beta I1       -1.727   0.084\n#> beta I2        2.543   0.011\n#> beta I3       -1.020   0.308\n#> beta I6        0.067   0.946\n#> beta I7        3.089   0.002\n#> beta I11      -1.978   0.048\n#> beta I12      -0.861   0.389\n#> beta I14      -0.673   0.501\n#> beta I17       0.815   0.415\n#> beta I18      -0.493   0.622\n#> beta I19       0.583   0.560\n#> beta I21      -2.305   0.021\n#> beta I22      -0.030   0.976\n#> beta I23      -1.019   0.308\n```\n:::\n\n\n\n\nI risultati qui concordano in gran parte anche con la figura precedente. In linea con il test grafico, il test di Wald indica che gli item 2, 7 e 21 differiscono tra i gruppi.\n\n### Ancoraggio\n\nL'ancoraggio è una procedura cruciale quando si confrontano le stime dei parametri degli item tra diversi gruppi, un passo fondamentale in test come il Wald e in metodi grafici. Tale processo necessita di particolare attenzione perché implica la restrizione di alcuni parametri degli item per allineare le scale latenti tra i gruppi. Ad esempio, fissare il parametro del primo item a zero in entrambi i gruppi crea un punto di riferimento comune, ma anche limitazioni.\n\nLa scelta degli item di ancoraggio è delicata: fissare un parametro in entrambi i gruppi significa non poter più valutare la differenza per quell'item specifico. La selezione dovrebbe essere guidata da un'attenta analisi dei dati e da considerazioni teoriche. Approcci guidati dai dati sono stati proposti per identificare item invarianti o escludere quelli con DIF, processo noto come purificazione. Tuttavia, occorre cautela: anche metodi ben progettati possono portare a conclusioni errate se gli item di ancoraggio scelti sono inappropriati.\n\nIn pratica, spesso si adotta una restrizione in cui la somma dei parametri degli item è zero per tutti i gruppi. Questo approccio, adottato da pacchetti software come eRm e difR in R, si basa sull'assunzione che eventuali DIF si annullino su tutti gli item. Ma se questa assunzione non è valida, o se l'ancoraggio include item con DIF, potremmo incorrere in errori interpretativi.\n\nIn sintesi, l'ancoraggio è una strategia potente ma che richiede un'attenta considerazione e un'analisi critica. È fondamentale non solo selezionare gli item di ancoraggio adeguati ma anche interpretare i risultati con una comprensione chiara delle ipotesi e delle potenziali limitazioni del metodo scelto.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresp <- as.matrix(responses)\nanchortest(\n    resp ~ gender,\n    class = \"constant\",\n    select = \"MPT\"\n)\n#> Anchor items:\n#> respI23, respI3, respI22, respI18\n#> \n#> Final DIF tests:\n#> \n#> \t Simultaneous Tests for General Linear Hypotheses\n#> \n#> Linear Hypotheses:\n#>              Estimate Std. Error z value Pr(>|z|)\n#> respI1 == 0    0.2422     0.2900    0.84   0.4037\n#> respI2 == 0   -0.8110     0.2923   -2.77   0.0055\n#> respI3 == 0    0.1253     0.2667    0.47   0.6384\n#> respI6 == 0   -0.1964     0.2709   -0.72   0.4685\n#> respI7 == 0   -1.7745     0.5717   -3.10   0.0019\n#> respI11 == 0   0.3185     0.2971    1.07   0.2837\n#> respI12 == 0   0.0195     0.2821    0.07   0.9449\n#> respI14 == 0  -0.0289     0.2734   -0.11   0.9160\n#> respI17 == 0  -0.3926     0.3080   -1.27   0.2025\n#> respI18 == 0  -0.0705     0.2203   -0.32   0.7492\n#> respI19 == 0  -0.3641     0.3621   -1.01   0.3147\n#> respI21 == 0   0.4477     0.3216    1.39   0.1639\n#> respI22 == 0  -0.1710     0.3019   -0.57   0.5711\n#> (Univariate p values reported)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanchortest(\n    resp ~ gender,\n    class = \"forward\",\n    select = \"MTT\"\n)\n#> Anchor items:\n#> respI23, respI12, respI18, respI14, respI6, respI1, respI11,\n#> respI19, respI17\n#> \n#> Final DIF tests:\n#> \n#> \t Simultaneous Tests for General Linear Hypotheses\n#> \n#> Linear Hypotheses:\n#>              Estimate Std. Error z value Pr(>|z|)\n#> respI1 == 0    0.2818     0.2362    1.19   0.2328\n#> respI2 == 0   -0.7714     0.2660   -2.90   0.0037\n#> respI3 == 0    0.1649     0.3229    0.51   0.6097\n#> respI6 == 0   -0.1568     0.2157   -0.73   0.4671\n#> respI7 == 0   -1.7349     0.5574   -3.11   0.0019\n#> respI11 == 0   0.3580     0.2432    1.47   0.1410\n#> respI12 == 0   0.0591     0.2262    0.26   0.7940\n#> respI14 == 0   0.0107     0.2188    0.05   0.9610\n#> respI17 == 0  -0.3530     0.2514   -1.40   0.1603\n#> respI18 == 0  -0.0309     0.2175   -0.14   0.8871\n#> respI19 == 0  -0.3245     0.3030   -1.07   0.2841\n#> respI21 == 0   0.4872     0.2952    1.65   0.0989\n#> respI22 == 0  -0.1314     0.3717   -0.35   0.7237\n#> (Univariate p values reported)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanchortest(\n    resp ~ gender,\n    select = \"Gini\"\n)\n#> Anchor items:\n#> respI23\n#> \n#> Final DIF tests:\n#> \n#> \t Simultaneous Tests for General Linear Hypotheses\n#> \n#> Linear Hypotheses:\n#>              Estimate Std. Error z value Pr(>|z|)\n#> respI1 == 0   0.12610    0.38737    0.33   0.7448\n#> respI2 == 0  -0.92706    0.38904   -2.38   0.0172\n#> respI3 == 0   0.00921    0.42718    0.02   0.9828\n#> respI6 == 0  -0.31249    0.37656   -0.83   0.4066\n#> respI7 == 0  -1.89057    0.63210   -2.99   0.0028\n#> respI11 == 0  0.20238    0.39228    0.52   0.6059\n#> respI12 == 0 -0.09661    0.38679   -0.25   0.8028\n#> respI14 == 0 -0.14496    0.37695   -0.38   0.7006\n#> respI17 == 0 -0.50866    0.40738   -1.25   0.2118\n#> respI18 == 0 -0.18656    0.37641   -0.50   0.6202\n#> respI19 == 0 -0.48019    0.45080   -1.07   0.2868\n#> respI21 == 0  0.33158    0.41809    0.79   0.4277\n#> respI22 == 0 -0.28708    0.47621   -0.60   0.5466\n#> (Univariate p values reported)\n```\n:::\n\n\n\n\nGli output di `R` della funzione `anchortest()` elencano gli item di ancoraggio selezionati dai rispettivi approcci di selezione dell'ancoraggio, oltre ai risultati del test di Wald basati su questi item di ancoraggio. Tutti e tre gli approcci portano a risultati in cui solo gli item 2 e 7 mostrano DIF per genere, mentre il test grafico e il test di Wald in eRm hanno identificato anche l'item 21 e l'item 11 (al limite) come aventi DIF.\n\nRiesaminando il test grafico nella figura precedente, notiamo che gli item 2 e 7 mostrano DIF nella stessa direzione (sopra la diagonale), mentre gli item 21 e 11 sono orientati nella direzione opposta (sotto la diagonale) e in misura minore.\n\nConsiderando questi risultati nel loro insieme, si può concludere che potrebbe essere presente un DIF non bilanciato e che la diagonale usata nella Figura 6.4 non è ideale per valutare gli item. Per illustrare ciò, tracciamo manualmente una linea di riferimento alternativa attraverso la posizione dell'item 23, che è stato selezionato come item di ancoraggio (primario) dai tre approcci presentati in psychotools, utilizzando il comando `abline`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n plotGOF(\n    lrt_gender,\n    tlab = \"item\", pos = 1,\n    main = \"Difficulty by Gender (with Item Names)\",\n    conf = list(gamma = 0.95, col = 1)\n)\nabline(-0.3, 1, lty=2)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-32-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nCome si può vedere nella figura risultante, basandoci sulla linea di riferimento alternativa, non troviamo più DIF negli item 11 e 21, ma gli item 2 e 7 mostrano ancora più chiaramente un DIF.\n\nPer questo set di dati, la stessa conclusione viene raggiunta in `eRm` quando si utilizza la funzione `stepwiseIt()`, che esegue diversi test di Wald e ad ogni passo esclude l'item singolo con la statistica di test più grande.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nstepwiseIt(rm_sum0, criterion = list(\"Waldtest\", gender))\n#> Eliminated item - Step 1: I7\n#> Eliminated item - Step 2: I2\n#> \n#> Results for stepwise item elimination:\n#> Number of steps: 2 \n#> Criterion: Waldtest\n#> \n#>            z-statistic p-value\n#> Step 1: I7        3.09   0.002\n#> Step 2: I2        3.06   0.002\n```\n:::\n\n\n\n\nUtilizzando questo metodo, dopo l'esclusione degli item 7 e 2, che presentavano il DIF più marcato, non si rilevano più differenze significative nei test degli item rimanenti. Per visualizzare meglio questo processo, immaginiamo la figura precedente: inizialmente, la linea di riferimento corrisponde alla diagonale solida. Tuttavia, dopo aver eliminato l'item 7, questa linea si sposta verso quella tratteggiata nel secondo passaggio e, rimuovendo poi l'item 2, si allinea o si avvicina molto alla linea tratteggiata nel terzo passaggio. Di conseguenza, gli item restanti non mostrano più un DIF significativo.\n\nIn sintesi, mentre i test grafici e di Wald basati sulla restrizione della somma zero possono risultare ingannevoli in presenza di un DIF non bilanciato, l'impiego di metodi di ancoraggio avanzati e l'approccio di eliminazione graduale degli item possono offrire una visione più accurata e dettagliata della situazione.\n\n### Rimozione di item \n\nSe questa analisi facesse parte della costruzione di un test reale, gli item che mostrano DIF (o altre anomalie nelle analisi successive) dovrebbero essere attentamente esaminati da esperti di contenuto per decidere se modificarli o rimuoverli dal test. Nella discussione seguente, tuttavia, non rimuoveremo gli item perché desideriamo mantenere il set di dati completo. Tuttavia, se si desiderasse rimuovere alcuni item (ovvero colonne) dal set di dati, ciò potrebbe essere fatto con i seguenti comandi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresponses_removeDIFitems <- \n  responses[, -which(colnames(responses) %in% c(\"I2\", \"I7\"))]\ncolnames(responses_removeDIFitems)\n#>  [1] \"I1\"  \"I3\"  \"I6\"  \"I11\" \"I12\" \"I14\" \"I17\" \"I18\" \"I19\" \"I21\" \"I22\" \"I23\"\n```\n:::\n\n\n\n\nDopo aver rimosso degli item, l'intero processo dovrebbe ricominciare da capo, rifacendo il modello di Rasch e indagando sugli item rimanenti. \n\n### Test di Martin-Löf \n\nNella sezione precedente, abbiamo visto che il test del rapporto di verosimiglianza di Andersen (1973) verifica l'ipotesi che i parametri degli item siano invarianti per vari gruppi di persone. Una ipotesi correlata riguarda l'invarianza dei parametri delle persone per diversi gruppi di item.\n\nQui, la domanda fondamentale è se diversi gruppi di item misurino tratti latenti differenti. Ciò rappresenterebbe una violazione del modello di Rasch, il quale implica un singolo tratto latente alla base di tutti gli item. Se questo tipo di violazione del modello viene rilevato, un modello IRT multidimensionale potrebbe essere più appropriato. \n\nUn metodo comune per valutare la dimensionalità in generale è l'analisi fattoriale esplorativa. Qui invece descriveremo il test di Martin-Löf che affronta l'ipotesi alternativa secondo cui gruppi di item misurano tratti latenti differenti ed è disponibile nel pacchetto `eRm`. Come il test del rapporto di verosimiglianza di Andersen, questo test si basa sul confronto di due verosimiglianze condizionate. La prima verosimiglianza condizionata Lu(r,β) è quella del modello di Rasch. La seconda verosimiglianza condizionata Lu(r1, r2, β) è nuovamente quella di un modello più generale che ora permette diversi parametri di persona per specifici gruppi di item. I gruppi di item devono essere definiti prima dell'analisi, il che può essere fatto in base alle loro difficoltà (cioè, testiamo item facili contro difficili) o in base a diverse dimensioni latenti che si sospetta siano misurate dai gruppi di item (cioè, il gruppo di item 1 è sospettato di misurare una dimensione latente diversa rispetto al gruppo di item 2). Se la seconda verosimiglianza è maggiore, ciò indica una violazione del modello di Rasch (analogamente al test del rapporto di verosimiglianza di Andersen).\n\nIl test di Martin-Löf è spesso descritto come un test per la unidimensionalità. Certi tipi di multidimensionalità possono anche manifestarsi come DIF. Per questa ragione, i test che mirano a rilevare il DIF, possono anche essere sensibili a certe violazioni della unidimensionalità.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmloef_median <- MLoef(rm_sum0, splitcr = \"median\")\nmloef_median\n#> \n#> Martin-Loef-Test (split criterion: median)\n#> LR-value: 67.083 \n#> Chi-square df: 48 \n#> p-value: 0.036\n```\n:::\n\n\n\n\nOtteniamo un valore p inferiore a 0.05. Ciò indica che le stime dei parametri delle persone ottenute dagli item facili e difficili differiscono in modo significativo, ovvero, una violazione del modello di Rasch.\n\n## Item e Person Fit\n\n### Tests e Statistiche di Bontà di Adattamento\n\nIn questa sezione esaminiamo una varietà di metodi per valutare l'adattamento dei dati di risposta agli item e al modello di Rasch. Alcuni di questi metodi sono test statistici formali, mentre altri sono statistiche descrittive per le quali sono stati suggeriti nella letteratura dei limiti critici empirici. Vedremo anche che esistono approcci per valutare l'adattamento a livello dell'intero test psicologico, così come approcci focalizzati sulla valutazione dell'adattamento di singoli item o individui.\n\n### Test di Bontà di Adattamento χ2 e G2\n\nNella valutazione del modello di Rasch, esaminiamo due classi principali di test di bontà di adattamento: il test χ2 e il test G2, entrambi noti nell'analisi delle tabelle di contingenza. A differenza dei test del rapporto di verosimiglianza o dei test di Martin-Löf, il test χ2 non confronta l'adattamento relativo di due modelli. Piuttosto, esso valuta quanto accuratamente i modelli di risposta previsti dal modello di Rasch corrispondano ai modelli di risposta osservati. Questo avviene attraverso il confronto tra il numero di partecipanti che mostrano ciascun modello di risposta osservato e il numero previsto dal modello di Rasch.\n\nIl principio dei test di bontà di adattamento χ2 per il modello di Rasch è basato sull'analisi di tutti i possibili modelli di risposta (combinazioni di 0 e 1 per risposte errate e corrette). Definiamo Ou come il numero osservato di partecipanti con il modello di risposta u e Eu come il numero previsto sotto il modello di Rasch. La statistica del test χ2 è data da:\n\n$$ T = \\sum_{u} \\frac{(O_u - E_u)^2}{E_u} $$\n\nIn questa formula, le differenze tra osservazioni e previsioni sono elevate al quadrato e poi ponderate inversamente rispetto alla frequenza attesa. In campioni di grandi dimensioni, T segue approssimativamente una distribuzione χ2, se il modello di Rasch è appropriato. Valori alti di T indicano una cattiva adattazione del modello.\n\nTuttavia, il test χ2 richiede che ogni modello di risposta abbia una frequenza attesa sufficientemente alta, una condizione spesso non soddisfatta in test con molti item. In questi casi, il test χ2 non segue una distribuzione χ2 sotto l'ipotesi nulla, rendendolo poco pratico. Una soluzione potrebbe essere quella di raggruppare i modelli di risposta per aumentare le frequenze attese.\n\nParallelamente, la statistica del rapporto di verosimiglianza G2, anch'essa derivante dall'analisi dei dati categoriali, è calcolata come:\n\n$$ G^2 = 2 \\sum_{u} O_u \\log \\left( \\frac{O_u}{E_u} \\right) $$\n\nG2 confronta le frequenze osservate con quelle attese, anziché le verosimiglianze di due modelli. Se le frequenze attese sono vicine a quelle osservate, il rapporto $\\frac{O_u}{E_u}$ si avvicina a 1, rendendo il logaritmo naturale $\\log\\left(\\frac{O_u}{E_u}\\right)$ vicino a 0 e la statistica G2 tende a 0, indicando un buon adattamento. Anche G2 segue una distribuzione χ2 se il modello di Rasch è appropriato. Tuttavia, proprio come per il test χ2, G2 è praticabile solo con grandi frequenze attese, limitandone l'uso effettivo. Nonostante ciò, G2 è importante da comprendere poiché molte altre statistiche di test si basano su di esso.\n\n### Statistica M2\n\nLa statistica M2, sviluppata da Maydeu-Olivares e Joe (2006), affronta il problema dei modelli di risposta rari che possono complicare i test χ2. Invece di confrontare le frequenze di interi modelli di risposta, la statistica M2 utilizza le informazioni provenienti dagli item individuali e dalle coppie di item. Specificatamente, confronta:\n1. Le frequenze attese e osservate delle risposte corrette agli item individuali.\n2. Le frequenze attese e osservate delle risposte corrette a entrambi gli item in una coppia di item.\n\nPer esempio, con due item, confronterebbe le frequenze osservate e attese per una risposta corretta al primo item, al secondo item e ad entrambi gli item insieme. Questo approccio è simile all'analisi delle tabelle di frequenza per le coppie di item. La statistica M2, come il test di bontà di adattamento χ2, implica un cattivo adattamento tra i dati e il modello di Rasch se produce un valore elevato o, equivalentemente, un valore p piccolo. Senza violazione del modello, la statistica M2 segue approssimativamente una distribuzione χ2 con gradi di libertà calcolati come $ k - d $, dove $ k $ è il numero di frequenze confrontate e $ d $ è il numero di parametri liberi del modello.\n\n### Errore Quadratico Medio di Approssimazione (RMSEA)\n\nIl RMSEA deriva dalla statistica M2. Utilizza i gradi di libertà (nuovamente $ k - d $) e la dimensione del campione $ P $ per calcolare il valore RMSEA. La formula per il RMSEA è:\n\n$$ \\text{RMSEA} = \\sqrt{\\frac{M2 - df}{P \\cdot df}} $$\n\nValori di RMSEA vicini a 0 generalmente indicano un buon adattamento del modello ai dati. Sebbene non esistano linee guida universalmente accettate per interpretare il RMSEA, un valore intorno a 0,05 è spesso considerato indicativo di un buon adattamento del modello.\n\n### Residuo Quadratico Medio Standardizzato (SRMSR)\n\nSRMSR è un'altra statistica di adattamento complessivo che confronta le correlazioni o le covarianze osservate tra tutte le coppie di item con quelle previste sotto il modello di Rasch (o un altro modello della teoria della risposta agli item). Valori vicini a 0 suggeriscono un buon adattamento del modello. Maydeu-Olivares (2013) raccomanda l'uso di un valore di soglia di 0.05 per SRMSR, simile al RMSEA.\n\nNel complesso, queste statistiche (M2, RMSEA e SRMSR) sono utili per valutare l'adattamento di un modello, come il modello di Rasch, a un dato insieme di dati di risposta agli item. Forniscono diverse prospettive attraverso le quali la congruenza tra i dati e il modello teorico può essere valutata, ognuna con il suo focus unico e metodo di calcolo.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_rasch <- mirt(responses, 1, itemtype = \"Rasch\", verbose = FALSE)\nfit_rasch\n#> \n#> Call:\n#> mirt(data = responses, model = 1, itemtype = \"Rasch\", verbose = FALSE)\n#> \n#> Full-information item factor analysis with 1 factor(s).\n#> Converged within 1e-04 tolerance after 16 EM iterations.\n#> mirt version: 1.44.0 \n#> M-step optimizer: nlminb \n#> EM acceleration: Ramsay \n#> Number of rectangular quadrature: 61\n#> Latent density type: Gaussian \n#> \n#> Log-likelihood = -2816\n#> Estimated parameters: 15 \n#> AIC = 5663\n#> BIC = 5723; SABIC = 5675\n#> G2 (16368) = 1319, p = 1\n#> RMSEA = 0, CFI = NaN, TLI = NaN\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM2(fit_rasch)\n#>        M2 df p  RMSEA RMSEA_5 RMSEA_95  SRMSR   TLI   CFI\n#> stats 278 90 0 0.0723  0.0626   0.0819 0.0941 0.749 0.752\n```\n:::\n\n\n\n\nLa statistica M2 è alta e significativa, indicando che ci sono differenze preoccupanti tra il modello e i dati. Questo è ulteriormente supportato da un RMSEA troppo alto e da un CFA e TLI lontani da 1.\n\nRicordiamo il significato degli indici RMSEA, CFA e TLI.\n\n**RMSEA (Root Mean Square Error of Approximation)**: \n   - Il RMSEA è una misura di adattamento che valuta quanto bene un modello si adatta ai dati a livello di popolazione. \n   - Un valore basso di RMSEA indica un buon adattamento, suggerendo che il modello approssima bene la realtà.\n   - Generalmente, un RMSEA inferiore a 0.05 o 0.06 è considerato indicativo di un ottimo adattamento del modello.\n\n**CFA (Comparative Fit Index)**: \n   - Il CFA è un indice relativo di bontà di adattamento che confronta il modello specificato con un modello nullo o di base. \n   - Valori più vicini a 1 indicano un adattamento migliore. Un CFA superiore a 0.90 o 0.95 è spesso considerato indicativo di un buon adattamento.\n\n**TLI (Tucker-Lewis Index)**: \n   - Simile al CFA, il TLI è un altro indice relativo di adattamento che tiene conto della complessità del modello.\n   - Anche per il TLI, valori più vicini a 1 indicano un adattamento migliore. Valori superiori a 0.90 o 0.95 sono generalmente considerati buoni.\n\n## Valutare l'Adattamento degli Item\n\nTuttavia, nell'IRT, ci interessiamo maggiormente agli indici di adattamento degli item e delle persone. L'IRT ci consente di valutare quanto bene ogni item si adatti al modello e se i pattern di risposta individuali sono allineati con il modello.\n\nIniziamo con l'addattamento agli item. Sono stati proposti diversi indici per valutare l'adattamento degli item e possiamo utilizzare la funzione `itemfit()` per ottenere una varietà di questi indici. Di default, riceviamo l'S_X2 di Orlando e Thissen (2000) con i corrispondenti gradi di libertà (dfs), RMSEA e valori p. Questo test dovrebbe risultare non significativo per indicare un buon adattamento dell'item. Come vediamo qui sotto, diversi item mostra un cattivo adattamento. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nitemfit(fit_rasch)\n#>    item  S_X2 df.S_X2 RMSEA.S_X2 p.S_X2\n#> 1    I1  4.15       7      0.000  0.762\n#> 2    I2 19.33       7      0.066  0.007\n#> 3    I3  5.53       7      0.000  0.596\n#> 4    I6 14.09       8      0.044  0.080\n#> 5    I7  8.98       7      0.027  0.254\n#> 6   I11 23.36       7      0.077  0.001\n#> 7   I12 17.67       7      0.062  0.014\n#> 8   I14  9.79       7      0.032  0.201\n#> 9   I17 35.13       7      0.100  0.000\n#> 10  I18  3.70       7      0.000  0.814\n#> 11  I19 20.93       7      0.071  0.004\n#> 12  I21 86.54       7      0.169  0.000\n#> 13  I22 73.46       7      0.154  0.000\n#> 14  I23  7.61       7      0.015  0.368\n```\n:::\n\n\n\n\n### Statistiche di Infit e Outfit\n\nNella sezione precedente abbiamo discusso i test χ2 e M2, basati sul confronto tra le frequenze osservate e quelle attese secondo il modello di Rasch. Le statistiche di adattamento presentate di seguito si basano su un approccio simile, utilizzando i residui di Rasch. Questi sono le differenze tra le risposte osservate (vale a dire, le risposte 0 o 1 per gli item dicotomici) e i loro valori attesi (cioè, le probabilità predette di una risposta corretta secondo il modello di Rasch). Tipicamente, questi valori attesi vengono calcolati in base alle stime dei parametri degli item e delle persone.\n\nGeneralmente, quando c'è un buon adattamento tra i dati e il modello, si può prevedere che i residui siano piccoli. Pertanto, è naturale che i residui di Rasch possano essere utilizzati per valutare l'adattamento del modello di Rasch. Vedremo che nell'analisi di Rasch non solo i casi in cui i residui sono più grandi del previsto possono essere motivo di preoccupazione, ma anche quelli in cui i residui sono più piccoli del previsto.\n\nUn approccio comune per verificare l'adattamento di singoli item usando i residui di Rasch consiste nel calcolare le statistiche di infit e outfit. Descriveremo i passaggi per calcolare queste statistiche prima di affrontarne l'interpretazione. Ci concentreremo sul caso in cui queste statistiche vengono calcolate per singoli item. \n\n#### Outfit\n\nLa funzione principale della statistica di outfit è quella di quantificare in che misura le risposte dei partecipanti si allontanano dalle previsioni del modello. Questo indice si calcola attraverso diversi passaggi, che mirano a stabilire la misura in cui le risposte individuali si discostano dalle aspettative teoriche.\n\n**1. Definizione dei Residui di Rasch:** \n   Inizialmente, per ogni partecipante e per ciascun item del test, si calcola il residuo di Rasch. Un residuo è essenzialmente la differenza tra la risposta osservata di un individuo a un determinato item e la risposta prevista da quel partecipante per lo stesso item. La risposta prevista è calcolata sulla base della probabilità, fornita dal modello di Rasch, che il partecipante risponda correttamente all'item. Ad esempio, se il modello prevede che un partecipante abbia il 40% di probabilità di rispondere correttamente a un item e il partecipante risponde effettivamente correttamente, il residuo corrispondente sarà $ 1 - 0.40 = 0.60 $.\n\n**2. Standardizzazione dei Residui di Rasch:**\n   Successivamente, questi residui vengono standardizzati. La standardizzazione implica l'adeguamento dei residui in modo che abbiano una media di zero e una varianza di uno. Ciò permette di confrontare i residui in maniera uniforme, indipendentemente dalle caratteristiche specifiche degli item o dei partecipanti.\n\n**3. Calcolo dello Z-Score:**\n   Per ciascun residuo, si calcola lo z-score standardizzato, $ Z_{si} $, utilizzando la formula:\n\n   $$\n   Z_{si} = \\frac{X_{si} - E(X_{si})}{\\sqrt{Var(X_{si})}},\n   $$\n\n   dove $ Z_{si} $ rappresenta lo z-score del residuo per il partecipante $ s $ all'item $ i $, $ X_{si} $ è la risposta osservata, $ E(X_{si}) $ è la risposta attesa (basata sulla probabilità di una risposta corretta secondo il modello di Rasch), e $ Var(X_{si}) $ è la varianza della risposta attesa.\n\n**4. Calcolo della Statistica di Outfit:**\n   Per calcolare la statistica di outfit mean square (MSQ) per un specifico item, si seguono questi passaggi:\n   - Si elevano al quadrato gli z-score standardizzati di ogni partecipante per l'item in questione.\n   - Si sommano tutti questi valori quadrati.\n   - Si divide la somma ottenuta per il numero totale dei partecipanti.\n\n   La formula risultante per la statistica di outfit MSQ per l'item $ i $ è la seguente:\n\n   $$\n   \\text{Outfit MSQ}_i = \\frac{\\sum_{p=1}^{P} Z_{pi}^2}{P}.\n   $$\n\nQuesta procedura fornisce una misura dell'adattamento delle risposte degli individui all'item specifico, rispetto alle previsioni del modello di Rasch. Un valore di MSQ significativamente alto o basso può indicare potenziali discrepanze tra le risposte osservate e quelle previste, suggerendo la necessità di ulteriori analisi o revisioni del modello o degli item del test.\n\nSecondo Wright e Masters (1990), questa statistica ha un valore atteso di 1 sotto il modello di Rasch. Valori superiori a 1 indicano residui di Rasch più grandi del previsto secondo il modello di Rasch, e quindi una possibile violazione del modello. Tali item vengono anche detti mostrare un underfit. Valori inferiori a 1 indicano che i residui sono inferiori al previsto. Ciò è considerato indicare un overfit delle risposte al modello di Rasch. In questo contesto, overfit significa che la deviazione tra i valori attesi e i dati empirici è minore del previsto. \n\nPossiamo inoltre ottenere una statistica di mean square pesata e standardizzata per ciascun item, tipicamente denotata da ti. Siano $\\sqrt[3]{\\text{MSQ}_i}$ e sd(MSQ_i) il cubo radice e la deviazione standard attesa di Outfit MSQ_i, rispettivamente. Allora la statistica standardizzata ti è\n\n$$ \n\\text{Outfit ti} = \\left( \\sqrt[3]{\\text{MSQ}_i} - 1 \\right) \\left( \\frac{3}{\\text{sd(MSQ}_i)} \\right) + \\left( \\frac{\\text{sd(MSQ}_i)}{3} \\right).\n$$\n\nQuesta statistica standardizzata ti è spesso presentata nei risultati del software in aggiunta alla statistica MSQ. \n\nItem che mostrano underfit e overfit possono anche essere identificati approssimativamente usando le loro ICC empiriche, come abbiamo già visto in precedenza. Gli item che mostrano underfit hanno ICC empiriche più piatte di quelle previste sotto il modello di Rasch. Gli item che mostrano overfit hanno ICC empiriche più ripide del previsto. \n\n#### Infit\n\nL'indice di infit è un altro indice critico nel modello di Rasch. A differenza dell'outfit, che è più influenzato da risposte casuali o outlier, l'infit è più sensibile alle risposte che sono incoerenti con il pattern generale del modello. L'infit è calcolato come una media ponderata dei residui standardizzati, dove i pesi sono inversamente proporzionali alla varianza degli item. Questo rende l'infit particolarmente utile per identificare problemi di adattamento del modello legati alla consistenza interna delle risposte.\n\nLa statistica di infit MSQ, come quella di outfit, serve a valutare l'adattamento delle risposte individuali rispetto alle aspettative teoriche del modello. Tuttavia, la statistica di infit differisce dall'outfit per il modo in cui tratta i residui.\n\n**1. Ponderazione dei Residui di Rasch:**\n   Nella statistica di infit, i residui di Rasch delle risposte individuali vengono ponderati in base alla loro varianza attesa sotto il modello di Rasch. Ciò significa che i residui con varianze minori (che tendono a verificarsi quando c'è una grande distanza tra le abilità dei rispondenti e la difficoltà degli item) hanno un impatto relativamente minore sulla statistica di infit rispetto a quelli con varianze maggiori. \n\n**2. Riduzione dell'Impatto degli Outlier:**\n   Questo approccio di ponderazione rende la statistica di infit meno sensibile agli outlier rispetto all'outfit. In altre parole, mentre la statistica di outfit è influenzata in maniera più uniforme da tutte le deviazioni dalle aspettative del modello, l'infit dà maggiore peso alle deviazioni che sono meno estreme o più prevedibili data la struttura del modello.\n\n**3. Formula per la Statistica di Infit MSQ:**\n   La formula per calcolare l'Infit MSQ per un dato item $ i $ è la seguente:\n\n   $$\n   \\text{Infit MSQ}_i = \\frac{\\sum_{p=1}^{P} W_{pi} Z_{pi}^2}{\\sum_{p=1}^{P} W_{pi}},\n   $$\n\n   dove:\n   - $ Z_{pi} $ rappresenta il residuo di Rasch standardizzato per il rispondente $ p $ all'item $ i $.\n   - $ W_{pi} $ è la varianza attesa del residuo $ Z_{pi} $ sotto il modello di Rasch.\n   - $ P $ è il numero totale dei rispondenti.\n\n**4. Standardizzazione della Statistica Infit:**\n   Come per l'outfit, è anche possibile calcolare una versione standardizzata dell'Infit MSQ per ogni item. Questa versione standardizzata, nota come statistica Infit t, consente di confrontare più facilmente l'adattamento degli item in diverse situazioni o in diversi test, normalizzando i valori su una scala comune.\n\nIn sintesi, la statistica di infit MSQ offre un modo ponderato per valutare l'adattamento delle risposte ai singoli item in un test basato sul modello di Rasch, tenendo conto della varianza attesa delle risposte. Questo la rende particolarmente utile per identificare i casi in cui le risposte si discostano dalle previsioni del modello in modi meno estremi o più in linea con la struttura del modello stesso.\n\n#### Soglie\n\nPer entrambi i valori MSQ e t delle statistiche di infit e outfit, sono stati proposti vari valori di soglia. Bond e Fox (2007) e Engelhard (2013) menzionano valori di soglia di -2 e 2 per le statistiche t, mentre Paek e Cole (2020) suggeriscono -3 e 3. Analogamente, Bond e Fox (2007) danno 0.75 e 1.3 come valori di soglia per le statistiche MSQ, mentre DeMars (2010) menziona 0.6 e 1.5 come possibili alternative. Desjardins e Bulut (2018), d'altra parte, si oppongono all'uso di valori di soglia specifici per queste statistiche.\n\nPossiamo calcolare le statistiche infit e oputfit degli item usando il pacchetto `eRm`:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nrm_sum0 <- RM(responses)\neRm::itemfit(person.parameter(rm_sum0))\n#> \n#> Itemfit Statistics: \n#>     Chisq  df p-value Outfit MSQ Infit MSQ Outfit t Infit t Discrim\n#> I1    325 397   0.996      0.818     0.904   -1.750  -1.666   0.418\n#> I2    274 397   1.000      0.688     0.809   -2.928  -3.271   0.520\n#> I3    289 397   1.000      0.727     0.869   -1.574  -1.505   0.371\n#> I6    334 397   0.991      0.838     0.860   -2.317  -3.257   0.505\n#> I7    273 397   1.000      0.686     0.838   -1.328  -1.423   0.279\n#> I11   333 397   0.992      0.836     0.816   -1.432  -3.143   0.473\n#> I12   459 397   0.018      1.152     0.972    1.538  -0.538   0.321\n#> I14   396 397   0.508      0.994     1.023   -0.043   0.492   0.320\n#> I17   524 397   0.000      1.317     0.936    2.290  -1.031   0.280\n#> I18   433 397   0.104      1.088     1.019    1.121   0.424   0.314\n#> I19   227 397   1.000      0.569     0.750   -2.579  -2.999   0.453\n#> I21   906 397   0.000      2.276     1.246    5.846   2.986  -0.108\n#> I22   728 397   0.000      1.829     0.985    2.918  -0.105   0.059\n#> I23   276 397   1.000      0.693     0.852   -1.918  -1.812   0.412\n```\n:::\n\n\n\n\nIn alternativa, è possibile usare la funzione `mirt` del pacchetto `mirt`:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nmirt_rm <- mirt(responses, 1, \"Rasch\")\n#> \nIteration: 1, Log-Lik: -2816.924, Max-Change: 0.03346\nIteration: 2, Log-Lik: -2816.650, Max-Change: 0.02041\nIteration: 3, Log-Lik: -2816.562, Max-Change: 0.01357\nIteration: 4, Log-Lik: -2816.520, Max-Change: 0.01027\nIteration: 5, Log-Lik: -2816.501, Max-Change: 0.00584\nIteration: 6, Log-Lik: -2816.493, Max-Change: 0.00395\nIteration: 7, Log-Lik: -2816.490, Max-Change: 0.00307\nIteration: 8, Log-Lik: -2816.488, Max-Change: 0.00174\nIteration: 9, Log-Lik: -2816.487, Max-Change: 0.00118\nIteration: 10, Log-Lik: -2816.487, Max-Change: 0.00094\nIteration: 11, Log-Lik: -2816.487, Max-Change: 0.00054\nIteration: 12, Log-Lik: -2816.487, Max-Change: 0.00036\nIteration: 13, Log-Lik: -2816.487, Max-Change: 0.00028\nIteration: 14, Log-Lik: -2816.487, Max-Change: 0.00016\nIteration: 15, Log-Lik: -2816.487, Max-Change: 0.00011\nIteration: 16, Log-Lik: -2816.487, Max-Change: 0.00008\nmirt::itemfit(mirt_rm, fit_stats = \"infit\", method = \"ML\")\n#>    item outfit z.outfit infit z.infit\n#> 1    I1  0.814   -1.683 0.904  -1.665\n#> 2    I2  0.685   -2.793 0.809  -3.271\n#> 3    I3  0.724   -1.510 0.870  -1.493\n#> 4    I6  0.834   -2.272 0.860  -3.258\n#> 5    I7  0.682   -1.357 0.831  -1.504\n#> 6   I11  0.832   -1.381 0.816  -3.143\n#> 7   I12  1.148    1.484 0.971  -0.554\n#> 8   I14  0.990   -0.086 1.023   0.494\n#> 9   I17  1.315    2.276 0.935  -1.040\n#> 10  I18  1.083    1.011 1.019   0.426\n#> 11  I19  0.569   -2.585 0.748  -3.014\n#> 12  I21  2.279    5.852 1.244   2.960\n#> 13  I22  1.823    2.911 0.978  -0.165\n#> 14  I23  0.690   -1.831 0.853  -1.804\n```\n:::\n\n\n\n\nLa tabella risultante inizia con le statistiche del test di adattamento χ2 approssimativo, i suoi gradi di libertà e i valori di p risultanti. Se il modello di Rasch è valido, la statistica di test risultante può essere approssimativamente descritta da una distribuzione χ2, il che porta ai valori di p presentati.\n\nLe colonne seguenti presentano le statistiche MSQ e t di infit e outfit. Per le statistiche MSQ di infit e outfit, valori vicini a 1 indicano un buon adattamento del modello, mentre per le statistiche t di infit e outfit, valori vicini a 0 indicano un buon adattamento. Valori più alti indicano che le risposte sono più casuali di quanto previsto dal modello di Rasch, segnalando un sottoadattamento (underfit); valori più bassi indicano che le risposte sono meno casuali del previsto, segnalando un sovradattamento (overfit).\n\nSeguendo una delle linee guida proposte, esamineremo ulteriormente quegli item i cui valori t di infit o outfit sono inferiori a -2 o superiori a 2 (ma esistono linee guida alternative). Troviamo che per gli item 2, 6, 11 e 19, almeno un valore t è inferiore a -2, indicando un sovradattamento. Per l'item 19 ciò è supportato dal fatto che la ICC empirica ha una pendenza più ripida rispetto alla ICC attesa.\n\nPer gli item 17, 21 e 22, invece, almeno un valore t per le statistiche di infit e outfit è superiore a 2, indicando un sottoadattamento. Questo è nuovamente in linea con l'esame delle ICC, dove abbiamo riscontrato che la ICC empirica per l'item 21 ha una pendenza inferiore rispetto alla ICC attesa.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nitemfitPlot(mirt_rm)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-41-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n### Valutare l'Adattamento delle Persone\n\nPossiamo generare le stesse misure di adattamento per ogni persona per valutare quanto bene i pattern di risposta di ciascuno si allineano con il modello. Ragioniamo in questo modo: se una persona con un alto valore di $\\theta$ (cioè alta abilità latente) non risponde correttamente a un item facile, questa persona non si adatta bene al modello. Al contrario, se una persona con bassa abilità risponde correttamente a una domanda molto difficile, anche questo non è conforme al modello. Nella pratica, è probabile che ci saranno alcune persone che non si adattano bene al modello. Tuttavia, finché il numero di rispondenti non conformi è basso, la situazione è accettabile. Di solito, ci concentriamo nuovamente sulle statistiche di infit e outfit. Se meno del 5% dei rispondenti presenta valori di infit e outfit superiori o inferiori a 1.96 e -1.96, possiamo considerare il modello adeguato.\n\nStimiamo gli indici infit e outfit delle persone usando `eRm`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neRm::personfit(person.parameter(rm_sum0)) \n#> \n#> Personfit Statistics: \n#>      Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t\n#> 1    13.19 13   0.433      0.942     1.080     0.07    0.35\n#> 2     7.00 13   0.902      0.500     0.744    -0.44   -0.85\n#> 3     7.56 13   0.871      0.540     0.799    -0.37   -0.62\n#> 4    13.65 13   0.399      0.975     1.112     0.14    0.44\n#> 5     4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 6    22.05 13   0.055      1.575     1.304     0.96    1.01\n#> 7    22.82 13   0.044      1.630     1.623     1.02    1.83\n#> 8    12.94 13   0.453      0.924     0.746     0.00   -0.66\n#> 9    71.92 13   0.000      5.137     1.376     2.32    1.11\n#> 10   22.51 13   0.048      1.608     1.065     1.12    0.30\n#> 11    8.24 13   0.827      0.589     0.786    -0.83   -0.52\n#> 12   17.93 13   0.160      1.280     0.916     0.67   -0.10\n#> 13    5.63 13   0.959      0.402     0.667    -0.33   -1.01\n#> 14   18.08 13   0.154      1.291     0.950     0.62   -0.07\n#> 15    9.43 13   0.740      0.673     0.890    -0.50   -0.24\n#> 16   49.15 13   0.000      3.511     1.562     1.53    1.20\n#> 17   16.14 13   0.242      1.153     1.094     0.46    0.37\n#> 18    7.40 13   0.880      0.529     0.785    -0.39   -0.68\n#> 19    4.70 13   0.981      0.336     0.424    -1.70   -1.96\n#> 20    4.70 13   0.981      0.336     0.424    -1.70   -1.96\n#> 21   45.74 13   0.000      3.267     1.221     1.99    0.79\n#> 22    5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 23    6.69 13   0.917      0.478     0.812    -0.21   -0.49\n#> 24    9.04 13   0.770      0.646     0.957    -0.19   -0.05\n#> 25   11.94 13   0.533      0.853     1.032    -0.01    0.21\n#> 26    8.35 13   0.820      0.596     0.851    -0.49   -0.42\n#> 27   28.14 13   0.009      2.010     1.853     1.40    2.35\n#> 28    7.92 13   0.849      0.566     0.731    -0.84   -0.66\n#> 29   65.84 13   0.000      4.703     1.677     1.83    1.38\n#> 30    8.30 13   0.824      0.593     0.752    -0.70   -0.71\n#> 31    6.58 13   0.922      0.470     0.660    -0.78   -1.18\n#> 32   11.04 13   0.607      0.789     1.055    -0.12    0.28\n#> 33   10.08 13   0.687      0.720     0.908    -0.39   -0.18\n#> 34   13.55 13   0.406      0.968     1.375     0.25    1.23\n#> 35   23.62 13   0.035      1.687     1.170     1.23    0.60\n#> 36   10.89 13   0.620      0.778     0.863    -0.33   -0.28\n#> 37    6.06 13   0.944      0.433     0.585    -1.15   -1.38\n#> 38   28.19 13   0.009      2.014     1.700     1.77    1.73\n#> 39   13.75 13   0.392      0.982     1.271     0.36    0.85\n#> 40   34.16 13   0.001      2.440     1.211     1.50    0.76\n#> 41   71.92 13   0.000      5.137     1.376     2.32    1.11\n#> 42   10.85 13   0.624      0.775     0.840    -0.31   -0.32\n#> 43    4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 44    6.98 13   0.903      0.499     0.661    -1.04   -0.90\n#> 45   68.33 13   0.000      4.881     1.024     2.24    0.18\n#> 46   15.79 13   0.260      1.128     1.141     0.41    0.55\n#> 47   21.71 13   0.060      1.551     1.756     0.86    1.83\n#> 48   13.78 13   0.390      0.984     1.094     0.25    0.37\n#> 49   15.99 13   0.250      1.142     1.334     0.60    0.81\n#> 50   10.99 13   0.612      0.785     1.008    -0.24    0.13\n#> 51   12.66 13   0.475      0.904     1.053    -0.04    0.27\n#> 52    4.17 13   0.989      0.298     0.804     0.40    0.00\n#> 53    7.53 13   0.873      0.538     0.972    -0.17    0.04\n#> 54    5.03 13   0.975      0.359     0.491    -1.08   -1.99\n#> 55   11.32 13   0.584      0.809     1.061    -0.08    0.30\n#> 56   42.85 13   0.000      3.061     1.148     1.39    0.46\n#> 57   30.25 13   0.004      2.161     1.909     1.95    2.13\n#> 58   17.43 13   0.180      1.245     1.137     0.57    0.47\n#> 59    5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 60    4.09 13   0.990      0.292     0.390    -1.43   -2.02\n#> 61   16.04 13   0.247      1.145     1.125     0.43    0.44\n#> 62   18.20 13   0.150      1.300     1.095     0.65    0.37\n#> 63   19.94 13   0.097      1.425     1.438     0.90    1.15\n#> 64   37.69 13   0.000      2.692     2.222     1.74    2.65\n#> 65   24.53 13   0.027      1.752     1.618     1.21    1.51\n#> 66   12.17 13   0.513      0.870     0.973     0.09    0.04\n#> 67   19.62 13   0.105      1.402     1.199     0.84    0.68\n#> 68   12.57 13   0.482      0.898     0.877    -0.05   -0.24\n#> 69   18.67 13   0.134      1.334     1.365     0.74    1.10\n#> 70    7.60 13   0.868      0.543     0.755    -0.60   -0.78\n#> 71    9.72 13   0.716      0.695     0.926    -0.50   -0.08\n#> 72    5.03 13   0.975      0.359     0.491    -1.08   -1.99\n#> 73    7.08 13   0.898      0.506     0.637    -1.02   -0.98\n#> 74    7.60 13   0.868      0.543     0.755    -0.60   -0.78\n#> 75    4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 76    5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 77    9.06 13   0.768      0.647     0.829    -0.38   -0.50\n#> 78    8.27 13   0.826      0.591     0.796    -0.58   -0.46\n#> 79   11.04 13   0.607      0.789     1.055    -0.12    0.28\n#> 80    5.83 13   0.952      0.416     0.549    -1.31   -1.31\n#> 81   10.48 13   0.654      0.749     0.917    -0.24   -0.10\n#> 82   10.89 13   0.620      0.778     1.038    -0.04    0.22\n#> 83   10.09 13   0.687      0.721     0.868    -0.30   -0.24\n#> 84    6.77 13   0.914      0.483     0.619    -1.09   -1.05\n#> 85    4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 86    6.47 13   0.927      0.462     0.649    -0.80   -1.22\n#> 87    8.13 13   0.835      0.581     0.875    -0.36   -0.24\n#> 88   12.39 13   0.496      0.885     0.903    -0.06   -0.14\n#> 89    5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 90    5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 91    5.36 13   0.966      0.383     0.507    -1.32   -1.73\n#> 92    4.09 13   0.990      0.292     0.390    -1.43   -2.02\n#> 93    6.58 13   0.922      0.470     0.660    -0.78   -1.18\n#> 94   12.09 13   0.520      0.864     0.995    -0.08    0.09\n#> 95    5.63 13   0.959      0.402     0.667    -0.33   -1.01\n#> 96   24.69 13   0.025      1.764     1.076     1.33    0.34\n#> 97   15.12 13   0.300      1.080     1.025     0.32    0.19\n#> 98    9.84 13   0.707      0.703     0.918    -0.43   -0.15\n#> 99   10.89 13   0.620      0.778     0.863    -0.33   -0.28\n#> 100   7.27 13   0.888      0.519     0.764    -0.41   -0.76\n#> 101   8.27 13   0.826      0.591     0.796    -0.58   -0.46\n#> 102  13.28 13   0.427      0.948     0.998     0.06    0.11\n#> 103  20.67 13   0.080      1.476     1.181     0.98    0.58\n#> 104  24.87 13   0.024      1.777     1.370     1.40    1.00\n#> 105   6.58 13   0.922      0.470     0.660    -0.78   -1.18\n#> 106   5.03 13   0.975      0.359     0.491    -1.08   -1.99\n#> 107   5.16 13   0.972      0.368     0.485    -1.37   -1.84\n#> 108  22.38 13   0.050      1.599     1.205     1.16    0.64\n#> 109   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 110   4.70 13   0.981      0.336     0.424    -1.70   -1.96\n#> 111   5.03 13   0.975      0.359     0.491    -1.08   -1.99\n#> 112   6.94 13   0.905      0.496     0.675    -0.81   -0.85\n#> 113   5.36 13   0.966      0.383     0.507    -1.32   -1.73\n#> 114   9.88 13   0.703      0.706     0.844    -0.51   -0.34\n#> 115  18.18 13   0.151      1.298     1.534     0.63    1.62\n#> 116   4.35 13   0.987      0.310     0.634    -0.11   -0.77\n#> 117  10.40 13   0.661      0.743     1.095    -0.05    0.41\n#> 118  26.27 13   0.016      1.876     1.226     1.46    0.75\n#> 119   5.83 13   0.952      0.416     0.549    -1.31   -1.31\n#> 120  40.54 13   0.000      2.896     1.718     1.51    1.87\n#> 121   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 122  28.23 13   0.008      2.016     1.666     1.41    1.93\n#> 123   5.64 13   0.958      0.403     0.735    -0.38   -0.69\n#> 124   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 125  38.77 13   0.000      2.769     1.219     1.46    0.72\n#> 126  45.62 13   0.000      3.258     1.202     1.98    0.73\n#> 127 102.53 13   0.000      7.324     1.711     2.35    1.44\n#> 128  40.52 13   0.000      2.895     1.439     1.51    1.26\n#> 129   7.30 13   0.886      0.521     0.779    -0.40   -0.70\n#> 130  26.98 13   0.013      1.927     1.304     1.52    0.95\n#> 131   8.84 13   0.785      0.632     0.892    -0.42   -0.27\n#> 132   9.43 13   0.740      0.673     0.890    -0.50   -0.24\n#> 133  27.41 13   0.011      1.957     1.442     1.35    1.38\n#> 134  19.83 13   0.099      1.417     1.647     0.72    1.92\n#> 135  25.52 13   0.020      1.823     1.546     1.22    1.64\n#> 136  11.12 13   0.601      0.794     1.081    -0.15    0.33\n#> 137  17.81 13   0.165      1.272     1.014     0.67    0.16\n#> 138  16.06 13   0.246      1.147     1.220     0.45    0.67\n#> 139   5.74 13   0.955      0.410     0.644    -0.70   -1.01\n#> 140   5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 141   7.08 13   0.898      0.506     0.637    -1.02   -0.98\n#> 142  11.50 13   0.569      0.822     1.160     0.06    0.61\n#> 143  10.95 13   0.615      0.782     0.932    -0.18   -0.06\n#> 144   6.06 13   0.944      0.433     0.585    -1.15   -1.38\n#> 145   4.92 13   0.977      0.351     0.633    -0.47   -1.06\n#> 146   5.28 13   0.968      0.377     0.630    -0.37   -1.16\n#> 147  24.05 13   0.031      1.718     1.470     1.37    1.26\n#> 148  15.12 13   0.300      1.080     1.025     0.32    0.19\n#> 149   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 150   5.16 13   0.972      0.368     0.485    -1.37   -1.84\n#> 151  11.64 13   0.558      0.831     0.940    -0.20   -0.05\n#> 152   8.67 13   0.797      0.619     0.812    -0.44   -0.56\n#> 153   6.26 13   0.936      0.447     0.628    -0.83   -1.32\n#> 154  15.00 13   0.307      1.071     1.263     0.31    0.77\n#> 155  17.01 13   0.199      1.215     1.418     0.55    1.23\n#> 156   7.27 13   0.888      0.519     0.764    -0.41   -0.76\n#> 157  12.37 13   0.498      0.883     1.136    -0.04    0.50\n#> 158   8.92 13   0.779      0.637     0.938    -0.21   -0.11\n#> 159   9.20 13   0.758      0.657     0.810    -0.59   -0.41\n#> 160   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 161  27.20 13   0.012      1.943     1.221     1.16    0.79\n#> 162   5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 163  58.61 13   0.000      4.186     1.621     2.44    1.86\n#> 164  10.70 13   0.636      0.764     0.896    -0.16   -0.26\n#> 165  41.12 13   0.000      2.937     1.378     1.53    1.12\n#> 166   5.16 13   0.972      0.368     0.485    -1.37   -1.84\n#> 167  58.08 13   0.000      4.149     1.313     1.56    0.62\n#> 168  17.86 13   0.163      1.276     1.502     0.60    1.54\n#> 169 146.26 13   0.000     10.447     1.338     2.27    0.65\n#> 170  21.25 13   0.068      1.518     1.420     1.00    1.24\n#> 171  26.86 13   0.013      1.919     1.962     1.31    2.59\n#> 172   4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 173   9.22 13   0.756      0.659     1.019     0.02    0.17\n#> 174   7.86 13   0.853      0.561     0.817    -0.10   -0.47\n#> 175  11.45 13   0.573      0.818     0.834    -0.21   -0.34\n#> 176   7.47 13   0.877      0.533     0.799    -0.13   -0.53\n#> 177   4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 178  10.70 13   0.636      0.764     0.896    -0.16   -0.26\n#> 179  20.35 13   0.087      1.453     1.320     0.91    0.99\n#> 180 123.64 13   0.000      8.832     2.158     3.23    2.72\n#> 181   8.28 13   0.825      0.592     1.068     0.61    0.35\n#> 182   8.86 13   0.784      0.633     0.808    -0.41   -0.58\n#> 183  48.85 13   0.000      3.489     1.539     2.10    1.65\n#> 184   4.09 13   0.990      0.292     0.390    -1.43   -2.02\n#> 185  10.98 13   0.613      0.784     1.153     0.01    0.59\n#> 186   4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 187   6.77 13   0.914      0.483     0.619    -1.09   -1.05\n#> 188  46.01 13   0.000      3.287     1.243     2.00    0.86\n#> 189  36.36 13   0.001      2.597     1.751     1.60    2.16\n#> 190  20.04 13   0.094      1.432     1.448     0.88    1.30\n#> 191   5.16 13   0.972      0.368     0.485    -1.37   -1.84\n#> 192  58.33 13   0.000      4.167     1.599     2.43    1.80\n#> 193   7.14 13   0.895      0.510     0.663    -0.92   -1.06\n#> 194   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 195  11.73 13   0.550      0.838     0.857    -0.16   -0.27\n#> 196  13.87 13   0.383      0.991     0.924     0.14   -0.10\n#> 197   9.06 13   0.768      0.647     0.829    -0.38   -0.50\n#> 198   4.28 13   0.988      0.306     0.544    -0.56   -1.41\n#> 199   5.74 13   0.955      0.410     0.644    -0.70   -1.01\n#> 200  10.58 13   0.646      0.755     0.746    -0.35   -0.61\n#> 201  17.32 13   0.185      1.237     1.268     0.60    0.78\n#> 202   6.26 13   0.936      0.447     0.628    -0.83   -1.32\n#> 203   9.81 13   0.710      0.700     0.767    -0.43   -0.66\n#> 204   6.26 13   0.936      0.447     0.628    -0.83   -1.32\n#> 205  10.48 13   0.654      0.749     0.917    -0.24   -0.10\n#> 206   9.17 13   0.760      0.655     1.086    -0.01    0.35\n#> 207  16.66 13   0.215      1.190     1.409     0.52    1.13\n#> 208  11.76 13   0.548      0.840     0.980    -0.07    0.07\n#> 209   5.83 13   0.952      0.416     0.549    -1.31   -1.31\n#> 210  14.94 13   0.311      1.067     1.217     0.35    0.68\n#> 211   5.35 13   0.967      0.382     0.570    -0.68   -1.62\n#> 212   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 213   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 214   5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 215   5.64 13   0.958      0.403     0.735    -0.38   -0.69\n#> 216   6.77 13   0.914      0.483     0.619    -1.09   -1.05\n#> 217   5.78 13   0.954      0.413     0.860    -0.01   -0.18\n#> 218  12.70 13   0.471      0.907     0.921    -0.01   -0.09\n#> 219   5.92 13   0.949      0.423     0.747    -0.34   -0.65\n#> 220   4.70 13   0.981      0.336     0.424    -1.70   -1.96\n#> 221  27.07 13   0.012      1.934     1.200     1.15    0.73\n#> 222   7.44 13   0.878      0.532     0.713    -0.86   -0.86\n#> 223   5.63 13   0.959      0.402     0.667    -0.33   -1.01\n#> 224   4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 225   9.13 13   0.763      0.652     0.859    -0.44   -0.27\n#> 226  14.02 13   0.372      1.001     1.074     0.17    0.32\n#> 227  10.95 13   0.615      0.782     0.932    -0.18   -0.06\n#> 228  13.78 13   0.390      0.984     1.094     0.25    0.37\n#> 229   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 230   8.26 13   0.826      0.590     0.741    -0.77   -0.63\n#> 231   6.77 13   0.914      0.483     0.619    -1.09   -1.05\n#> 232  10.66 13   0.639      0.762     0.843    -0.37   -0.34\n#> 233  62.46 13   0.000      4.461     2.648     3.13    3.89\n#> 234   8.74 13   0.793      0.624     0.755    -0.50   -0.59\n#> 235   7.86 13   0.853      0.561     0.817    -0.10   -0.47\n#> 236   7.92 13   0.849      0.566     0.731    -0.84   -0.66\n#> 237   7.92 13   0.849      0.566     0.731    -0.84   -0.66\n#> 238   4.37 13   0.987      0.312     0.865     0.40    0.07\n#> 239  18.15 13   0.152      1.296     1.223     0.92    0.53\n#> 240  33.12 13   0.002      2.366     1.889     1.72    2.43\n#> 241   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 242   8.79 13   0.788      0.628     0.782    -0.71   -0.54\n#> 243   7.44 13   0.878      0.532     0.713    -0.86   -0.86\n#> 244   8.23 13   0.828      0.588     0.749    -0.78   -0.60\n#> 245   5.63 13   0.959      0.402     0.667    -0.33   -1.01\n#> 246   4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 247  22.64 13   0.046      1.617     0.967     1.00   -0.01\n#> 248  16.01 13   0.249      1.144     1.334     0.44    0.96\n#> 249   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 250  18.84 13   0.128      1.346     1.182     0.65    0.62\n#> 251   4.35 13   0.987      0.310     0.634    -0.11   -0.77\n#> 252   9.20 13   0.758      0.657     0.810    -0.59   -0.41\n#> 253   6.47 13   0.927      0.462     0.649    -0.80   -1.22\n#> 254   9.30 13   0.750      0.664     0.822    -0.62   -0.41\n#> 255   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 256  18.16 13   0.152      1.297     1.362     0.70    0.99\n#> 257  12.84 13   0.460      0.917     1.162     0.07    0.53\n#> 258   5.36 13   0.966      0.383     0.507    -1.32   -1.73\n#> 259   6.91 13   0.907      0.494     0.910     0.11   -0.05\n#> 260   7.50 13   0.875      0.536     0.710    -0.98   -0.78\n#> 261   6.98 13   0.903      0.499     0.661    -1.04   -0.90\n#> 262   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 263   7.78 13   0.857      0.556     1.094     0.58    0.37\n#> 264   8.74 13   0.793      0.624     0.755    -0.50   -0.59\n#> 265   9.30 13   0.750      0.664     1.038    -0.21    0.23\n#> 266   8.48 13   0.811      0.606     0.901    -0.26   -0.24\n#> 267   4.22 13   0.989      0.301     0.456    -0.98   -1.79\n#> 268  20.66 13   0.080      1.476     1.214     0.84    0.76\n#> 269   6.47 13   0.927      0.462     0.649    -0.80   -1.22\n#> 270   8.37 13   0.819      0.598     0.829    -0.27   -0.51\n#> 271  23.03 13   0.041      1.645     1.150     0.95    0.52\n#> 272   8.67 13   0.798      0.619     0.756    -0.51   -0.58\n#> 273   7.85 13   0.853      0.561     0.740    -0.78   -0.76\n#> 274  19.06 13   0.121      1.362     1.210     0.66    0.70\n#> 275   8.23 13   0.828      0.588     0.749    -0.78   -0.60\n#> 276  14.98 13   0.309      1.070     1.236     0.31    0.78\n#> 277  12.38 13   0.497      0.884     1.034    -0.08    0.21\n#> 278   4.92 13   0.977      0.351     0.633    -0.47   -1.06\n#> 279   5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 280  11.27 13   0.589      0.805     1.035     0.00    0.22\n#> 281  30.64 13   0.004      2.189     1.642     1.39    1.61\n#> 282  16.13 13   0.242      1.152     1.025     0.45    0.19\n#> 283  10.80 13   0.628      0.771     1.136    -0.01    0.54\n#> 284   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 285  17.34 13   0.184      1.238     1.623     0.57    1.67\n#> 286   5.89 13   0.950      0.421     0.769    -0.35   -0.58\n#> 287  32.26 13   0.002      2.304     1.363     1.77    0.99\n#> 288  23.82 13   0.033      1.701     1.277     1.00    0.82\n#> 289   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 290   9.69 13   0.719      0.692     0.728    -0.50   -0.67\n#> 291  11.57 13   0.563      0.826     0.991    -0.21    0.09\n#> 292  15.01 13   0.307      1.072     1.001     0.32    0.13\n#> 293  12.04 13   0.524      0.860     0.736    -0.14   -0.69\n#> 294   8.46 13   0.812      0.605     0.790    -0.47   -0.64\n#> 296   5.74 13   0.955      0.410     0.644    -0.70   -1.01\n#> 297  15.67 13   0.267      1.119     1.279     0.41    0.83\n#> 298   7.78 13   0.857      0.556     1.094     0.58    0.37\n#> 299  15.52 13   0.276      1.109     1.298     0.38    0.85\n#> 300  32.03 13   0.002      2.288     1.795     2.03    1.84\n#> 301   5.03 13   0.975      0.359     0.491    -1.08   -1.99\n#> 302   5.36 13   0.966      0.383     0.507    -1.32   -1.73\n#> 303  10.58 13   0.646      0.755     0.746    -0.35   -0.61\n#> 304  12.08 13   0.521      0.863     0.975    -0.08    0.03\n#> 305  14.77 13   0.322      1.055     0.934     0.27   -0.07\n#> 306  18.87 13   0.127      1.348     1.290     0.78    0.83\n#> 308  14.15 13   0.363      1.011     1.091     0.28    0.37\n#> 309   5.74 13   0.955      0.410     0.644    -0.70   -1.01\n#> 310  18.16 13   0.152      1.297     1.087     0.72    0.36\n#> 311   5.35 13   0.967      0.382     0.570    -0.68   -1.62\n#> 312  16.04 13   0.247      1.145     1.125     0.43    0.44\n#> 313  23.03 13   0.041      1.645     1.150     0.95    0.52\n#> 314   6.94 13   0.905      0.496     0.675    -0.81   -0.85\n#> 315  11.31 13   0.584      0.808     1.024    -0.23    0.19\n#> 316   7.47 13   0.876      0.534     0.633    -0.99   -1.06\n#> 317  24.89 13   0.024      1.778     1.098     1.34    0.40\n#> 318  18.18 13   0.151      1.298     0.811     0.70   -0.41\n#> 319   6.02 13   0.945      0.430     0.903     0.01   -0.08\n#> 320  13.67 13   0.398      0.976     1.072     0.11    0.32\n#> 321   7.50 13   0.875      0.536     0.710    -0.98   -0.78\n#> 322   8.74 13   0.793      0.624     0.755    -0.50   -0.59\n#> 323  13.75 13   0.392      0.982     1.201     0.18    0.63\n#> 324  28.43 13   0.008      2.031     1.448     1.03    1.04\n#> 325   6.90 13   0.907      0.493     0.768    -0.53   -0.58\n#> 326  15.66 13   0.268      1.119     1.228     0.39    0.69\n#> 327   8.74 13   0.793      0.624     0.755    -0.50   -0.59\n#> 328   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 329   9.69 13   0.719      0.692     0.728    -0.50   -0.67\n#> 330   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 331   4.09 13   0.990      0.292     0.390    -1.43   -2.02\n#> 332   7.44 13   0.878      0.532     0.713    -0.86   -0.86\n#> 333   5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 334   8.05 13   0.840      0.575     0.762    -0.74   -0.68\n#> 335  31.38 13   0.003      2.242     1.672     1.97    1.61\n#> 336   4.70 13   0.981      0.336     0.424    -1.70   -1.96\n#> 337  10.03 13   0.691      0.717     0.928    -0.13   -0.08\n#> 338  11.78 13   0.546      0.841     1.183     0.09    0.68\n#> 339  11.27 13   0.589      0.805     1.035     0.00    0.22\n#> 340  30.47 13   0.004      2.176     1.461     1.65    1.20\n#> 341   4.09 13   0.990      0.292     0.390    -1.43   -2.02\n#> 342  17.01 13   0.199      1.215     1.125     0.54    0.45\n#> 343   5.12 13   0.972      0.366     0.513    -1.18   -1.46\n#> 344  12.13 13   0.517      0.866     0.920    -0.10   -0.09\n#> 345  12.26 13   0.507      0.876     0.905     0.10   -0.15\n#> 346  12.94 13   0.453      0.924     0.746     0.00   -0.66\n#> 347  21.89 13   0.057      1.564     1.668     0.81    1.67\n#> 348  13.52 13   0.409      0.965     0.934     0.10   -0.05\n#> 349   5.74 13   0.955      0.410     0.644    -0.70   -1.01\n#> 350  12.70 13   0.471      0.907     0.921    -0.01   -0.09\n#> 351  23.70 13   0.034      1.693     1.714     1.14    1.69\n#> 352   7.47 13   0.876      0.534     0.633    -0.99   -1.06\n#> 353  26.39 13   0.015      1.885     1.588     1.60    1.51\n#> 354  15.31 13   0.288      1.094     1.203     0.35    0.69\n#> 355   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 356   7.14 13   0.895      0.510     0.663    -0.92   -1.06\n#> 357  13.63 13   0.401      0.973     1.200     0.11    0.64\n#> 358   5.44 13   0.964      0.389     0.501    -1.49   -1.60\n#> 359  18.07 13   0.155      1.291     1.289     0.62    0.97\n#> 360  11.94 13   0.533      0.853     1.032    -0.01    0.21\n#> 361   8.30 13   0.824      0.593     0.752    -0.70   -0.71\n#> 362  21.69 13   0.060      1.549     1.504     1.09    1.28\n#> 363   8.67 13   0.797      0.619     0.812    -0.44   -0.56\n#> 364   8.35 13   0.820      0.596     0.851    -0.49   -0.42\n#> 365  17.60 13   0.173      1.257     1.041     0.65    0.23\n#> 366  20.61 13   0.081      1.472     1.003     0.97    0.13\n#> 367   8.28 13   0.825      0.592     1.068     0.61    0.35\n#> 368   4.57 13   0.984      0.326     0.848     0.42    0.06\n#> 369  63.80 13   0.000      4.557     1.160     1.79    0.49\n#> 370  38.91 13   0.000      2.779     1.507     1.46    1.42\n#> 371  20.97 13   0.073      1.498     1.488     0.91    1.25\n#> 372  31.49 13   0.003      2.249     1.150     1.62    0.57\n#> 373   5.16 13   0.972      0.368     0.485    -1.37   -1.84\n#> 374   7.47 13   0.877      0.533     0.799    -0.13   -0.53\n#> 375  26.27 13   0.016      1.876     1.226     1.46    0.75\n#> 376   7.27 13   0.888      0.519     0.764    -0.41   -0.76\n#> 377   8.75 13   0.792      0.625     0.921    -0.23   -0.17\n#> 378   6.39 13   0.931      0.456     0.873     0.07   -0.14\n#> 379  19.96 13   0.096      1.426     1.151     0.79    0.58\n#> 380  11.67 13   0.555      0.833     1.198     0.21    0.66\n#> 381   9.06 13   0.769      0.647     0.959    -0.19   -0.04\n#> 382   6.74 13   0.915      0.481     0.635    -1.01   -1.17\n#> 383   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 384  46.62 13   0.000      3.330     1.814     1.70    2.07\n#> 385  27.07 13   0.012      1.934     1.200     1.15    0.73\n#> 386   9.88 13   0.703      0.706     0.844    -0.51   -0.34\n#> 387   9.51 13   0.733      0.679     0.828    -0.53   -0.36\n#> 388  20.99 13   0.073      1.499     1.349     1.05    1.00\n#> 389   8.21 13   0.829      0.587     0.737    -0.59   -0.64\n#> 390   5.67 13   0.957      0.405     0.521    -1.43   -1.51\n#> 391   7.40 13   0.880      0.529     0.785    -0.39   -0.68\n#> 392   4.02 13   0.991      0.287     0.354    -1.81   -2.20\n#> 393   9.02 13   0.771      0.645     0.802    -0.67   -0.47\n#> 394   8.23 13   0.828      0.588     0.749    -0.78   -0.60\n#> 395  19.67 13   0.104      1.405     1.465     0.90    1.25\n#> 396   8.66 13   0.798      0.619     0.865    -0.24   -0.38\n#> 397   5.36 13   0.966      0.383     0.507    -1.32   -1.73\n#> 398   4.70 13   0.981      0.336     0.424    -1.70   -1.96\n#> 399  14.35 13   0.350      1.025     1.217     0.26    0.77\n#> 400   5.28 13   0.968      0.377     0.630    -0.37   -1.16\n```\n:::\n\n\n\n\nCome per le statistiche di infit e outfit per i singoli item, individui con valori di t superiori a 2 mostrano un comportamento di risposta più casuale rispetto a quanto previsto dal modello di Rasch. Questo può indicare, ad esempio, comportamenti di risposta basati su supposizioni o scarsa attenzione. I modelli di risposta che portano a valori di t inferiori a -2 indicano un comportamento di risposta più deterministico rispetto a quello atteso. In questo esempio, le persone identificate con il numero 5 e 43 mostrano questo comportamento.\n\nOtteniamo le stime infit e outfit per le persone con `mirt`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(personfit(mirt_rm))\n#>   outfit z.outfit infit z.infit     Zh\n#> 1  0.931   0.0419 1.090   0.372 -0.142\n#> 2  0.510  -0.6496 0.728  -0.898  0.889\n#> 3  0.548  -0.5660 0.782  -0.682  0.751\n#> 4  0.996   0.1686 1.111   0.430 -0.232\n#> 5  0.289  -1.8874 0.352  -2.239  1.654\n#> 6  1.465   0.8848 1.315   1.010 -1.002\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npersonfit(mirt_rm) %>%\n    summarize(\n        infit.outside = prop.table(table(z.infit > 1.96 | z.infit < -1.96)),\n        outfit.outside = prop.table(table(z.outfit > 1.96 | z.outfit < -1.96))\n    ) # lower row = non-fitting people\n#>   infit.outside outfit.outside\n#> 1        0.9175           0.98\n#> 2        0.0825           0.02\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npersonfitPlot(mirt_rm)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-45-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nIn conclusione, nel caso dei dati in esame, meno del 5% dei rispondenti mostra valori di outfit che eccedono la soglia di 1.96 o che sono inferiori a -1.96. Invece, l'8% dei rispondenti mostra valori di infit che eccedono la soglia di 1.96 o che sono inferiori a -1.96. Questi risultati suggeriscono che il modello di Rasch non è del tutto coerente con i dati esaminati.\n\n## Curva di Informazione dell'Item \n\nUn altro modo per valutare la qualità di ciascun item è tramite la creazione delle cosiddette curve di informazione degli item. L'informazione è un concetto statistico che si riferisce alla capacità di un item di stimare con precisione i punteggi su theta. L'informazione a livello di item chiarisce quanto bene ogni item contribuisca alla precisione nella stima dei punteggi, con livelli più elevati di informazione che portano a stime dei punteggi più accurate.\n\nPer esempio:\n\n- Un item con un'elevata informazione sarà molto utile per discriminare tra rispondenti con diversi livelli di abilità latente attorno a un certo punto della scala di theta. Questo significa che l'item fornisce dati affidabili e significativi sulla capacità o conoscenza che si sta misurando.\n- Al contrario, un item con bassa informazione non aggiunge molto alla precisione della stima del punteggio. Questo potrebbe accadere se l'item è troppo facile o troppo difficile per la maggior parte dei rispondenti, o se non è strettamente correlato al tratto latente che si sta cercando di misurare.\n\nLa posizione delle Curve Caratteristiche degli Item (ICC) determina le regioni sul tratto latente dove ciascun item fornisce il massimo di informazione. Questo viene illustrato tramite il grafico dell'informazione dell'item.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplotINFO(rm_sum0, type = \"item\", legpos = FALSE)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-46-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQui vediamo che alcuni item forniscono maggiori informazioni sui livelli più bassi di $\\theta$, altri a livelli medi di  $\\theta$ e altri ancora ai livelli alti di  $\\theta$.\n\n### Informazione del Test\n\nIl concetto di “informazione” può essere applicato anche all’intera scala del test. La **Test Information Curve (TIC)** è una rappresentazione grafica che mostra quanta **informazione** un test fornisce a diversi livelli di abilità latente ($\\theta$). L'informazione è una misura della precisione con cui il test stima l'abilità di un individuo\n\nIn questo caso, osserviamo che la scala è molto efficace nel stimare i punteggi di theta tra -2 e 3, ma presenta una minore precisione nella stima dei punteggi di theta agli estremi. In altre parole, il test fornisce stime accurate per una vasta gamma di abilità medie e leggermente superiori alla media, ma diventa meno affidabile per valutare abilità molto basse o molto elevate.\n\nQuesta osservazione ha importanti implicazioni pratiche:\n\n- **Valutazione Ottimale per la Maggior Parte dei Rispondenti:** La scala è particolarmente adatta per valutare rispondenti il cui livello di abilità si trova all’interno dell’intervallo in cui il test è più informativo (-2 a 4).\n- **Limiti nella Valutazione degli Estremi:** Per rispondenti con abilità molto al di sotto di -2 o molto al di sopra di 4, il test potrebbe non fornire stime di abilità così precise. Questo significa che per questi individui, il test potrebbe non essere in grado di discriminare efficacemente tra diversi livelli di abilità.\n  \nLe curve di informazione del test aiutano a identificare dove il test è più efficace e dove potrebbe aver bisogno di miglioramenti o aggiustamenti, come l’aggiunta di item più difficili o più facili per estendere la sua precisione ai livelli estremi di abilità. Questa analisi consente di ottimizzare il test per una valutazione più accurata su tutta la gamma di abilità latente che si intende misurare.\n\nIl grafico dell'informazione del test può essere generato utilizzando `eRm::plotINFO`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neRm::plotINFO(rm_sum0, type = \"test\")\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-47-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nOppure possiamo usare l'output di **mirt**:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(mirt_rm, type = \"info\")\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-48-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Errore Standard di Misurazione del Test\n\nIl **Test Standard Error of Measurement (SEM)** è una misura della precisione con cui un test stima il livello di abilità latente ($\\theta$) per una persona. In altre parole, rappresenta l’incertezza associata alla stima di $\\theta$. Il grafico prodotto da `plot(raschModel, type = \"SE\")` mostra come il SEM varia in funzione del livello di abilità latente ($\\theta$).\n\n- Il SEM è una stima dell'errore standard nella misurazione di $\\theta$.\n- È inversamente proporzionale alla quantità di informazione fornita dal test a un dato livello di $\\theta$:\n     \n$$\nSEM(\\theta) = \\frac{1}{\\sqrt{\\text{Informazione}(\\theta)}}\n$$\n\n- Il SEM è espresso nella stessa scala di $\\theta$.\n- Un valore più basso del SEM implica una stima più precisa di $\\theta$.\n- Il SEM non è costante: varia in base al livello di $\\theta$, riflettendo il fatto che il test è più informativo per alcune abilità rispetto ad altre.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(mirt_rm, type = \"SE\")\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-49-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nNel modello Rasch, il SEM dipende dalla distribuzione dei parametri di difficoltà ($b$) degli item:\n\n- Il SEM minimo si verifica intorno ai valori di $\\theta$ che corrispondono ai parametri di difficoltà ($b$) degli item.\n- Un SEM alto si verifica a valori di $\\theta$ lontani dal range dei parametri di difficoltà ($b$), poiché il test non discrimina bene a quei livelli di abilità.\n\nIn conclusione, il grafico del SEM ci aiuta a identificare i punti di forza e di debolezza del test in termini di precisione della stima di $\\theta$. Il SEM ci permette di capire in quali range di $\\theta$ il test fornisce stime più affidabili.\n\nLa funzione `testInfoPlot()` fornisce il grafico del SEM insieme alla curva di informazione del test:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntestInfoPlot(mirt_rm, adj_factor = 2)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-50-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nL'informazione del test è maggiore attorno allo zero e, di conseguenza, gli errori standard aumentano allontanandosi dallo zero.\n\n## Stima dei Parametri delle Persone\n\nLa stima dei parametri delle persone ottenuta con il metodo di massima verosimiglianza si ottiene nel modo seguente:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ntheta <- eRm::person.parameter(rm_sum0)\ntheta\n#> \n#> Person Parameters:\n#> \n#>  Raw Score Estimate Std.Error\n#>          1  -3.3992     1.085\n#>          2  -2.5218     0.832\n#>          3  -1.9160     0.737\n#>          4  -1.4093     0.692\n#>          5  -0.9452     0.673\n#>          6  -0.4965     0.668\n#>          7  -0.0474     0.673\n#>          8   0.4118     0.683\n#>          9   0.8878     0.698\n#>         10   1.3892     0.720\n#>         11   1.9351     0.762\n#>         12   2.5766     0.851\n#>         13   3.4832     1.097\n#>         14   4.4549        NA\n```\n:::\n\n\n\n\nDa notare che questa tabella non mostra una stima per ogni persona. La stima dell'abilità di una persona dipende unicamente dal numero di item a cui ha risposto correttamente. Questo significa che dobbiamo calcolare una stima dell'abilità per ogni possibile punteggio totale (indicato come \"punteggi grezzi\" nella tabella) e possiamo assegnare tale stima a ciascuna persona che ottiene quel punteggio. Ad esempio, stimiamo che l'abilità di una persona che risponde correttamente a dieci item sia circa 1.39. \n\nVediamo che le stime dell'abilità aumentano con il punteggio grezzo. Questo ha senso, poiché un candidato ha maggiori probabilità di rispondere correttamente a un item se la sua abilità supera la difficoltà di quell'item. Più item vengono risposti correttamente, più è probabile che l'abilità del candidato sia elevata. Inoltre, vediamo che l'errore standard aumenta con la distanza da zero, come era prevedibile dalla mappa persona-item o dalle curve di informazione degli item e del test, dove abbiamo visto che la maggior parte degli item si trova intorno allo zero.\n\nLa mancanza di un errore standard per i candidati che rispondono correttamente a tutti i 14 item potrebbe lasciarci perplessi. La ragione di tale mancanza è che non esiste una stima di massima verosimiglianza per questo punteggio perfetto. Per gestire questo, la funzione `person.parameter()` utilizza un metodo chiamato *interpolazione spline* per produrre una stima dell'abilità, ma la procedura non fornisce stime dell'errore. Lo stesso sarebbe vero per i candidati che risolvono correttamente 0 item, ma in questo campione non si è verificato un punteggio di zero.\n\nPossiamo ottenere informazioni sulle stime dell'abilità dei singoli candidati utilizzando la funzione `summary()`, cioè,\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsummary(theta)\n#> \n#> Estimation of Ability Parameters\n#> \n#> Collapsed log-likelihood: -76.3 \n#> Number of iterations: 10 \n#> Number of parameters: 13 \n#> \n#> ML estimated ability parameters (without spline interpolated values): \n#>           Estimate Std. Err.   2.5 %  97.5 %\n#> theta 1    -0.4965     0.668 -1.8067  0.8137\n#> theta 2    -1.4093     0.692 -2.7663 -0.0522\n#> theta 3    -1.4093     0.692 -2.7663 -0.0522\n#> theta 4    -0.4965     0.668 -1.8067  0.8137\n#> theta 5     0.4118     0.683 -0.9270  1.7506\n#> theta 6    -0.9452     0.673 -2.2645  0.3741\n#> theta 7    -0.9452     0.673 -2.2645  0.3741\n#> theta 8    -0.0474     0.673 -1.3664  1.2716\n#> theta 9    -1.9160     0.737 -3.3596 -0.4724\n#> theta 10   -0.4965     0.668 -1.8067  0.8137\n#> theta 11   -0.0474     0.673 -1.3664  1.2716\n#> theta 12    0.4118     0.683 -0.9270  1.7506\n#> theta 13   -1.9160     0.737 -3.3596 -0.4724\n#> theta 14   -0.9452     0.673 -2.2645  0.3741\n#> theta 15   -0.4965     0.668 -1.8067  0.8137\n#> theta 16   -2.5218     0.832 -4.1521 -0.8915\n#> theta 17   -0.0474     0.673 -1.3664  1.2716\n#> theta 18   -1.4093     0.692 -2.7663 -0.0522\n#> theta 19   -0.0474     0.673 -1.3664  1.2716\n#> theta 20   -0.0474     0.673 -1.3664  1.2716\n#> theta 21   -1.4093     0.692 -2.7663 -0.0522\n#> theta 22   -0.0474     0.673 -1.3664  1.2716\n#> theta 23   -1.9160     0.737 -3.3596 -0.4724\n#> theta 24   -1.4093     0.692 -2.7663 -0.0522\n#> theta 25   -0.9452     0.673 -2.2645  0.3741\n#> theta 26   -0.9452     0.673 -2.2645  0.3741\n#> theta 27   -0.9452     0.673 -2.2645  0.3741\n#> theta 28    0.4118     0.683 -0.9270  1.7506\n#> theta 29   -2.5218     0.832 -4.1521 -0.8915\n#> theta 30   -0.4965     0.668 -1.8067  0.8137\n#> theta 31   -0.9452     0.673 -2.2645  0.3741\n#> theta 32   -0.9452     0.673 -2.2645  0.3741\n#> theta 33   -0.4965     0.668 -1.8067  0.8137\n#> theta 34   -1.4093     0.692 -2.7663 -0.0522\n#> theta 35   -0.4965     0.668 -1.8067  0.8137\n#> theta 36   -0.0474     0.673 -1.3664  1.2716\n#> theta 37   -0.4965     0.668 -1.8067  0.8137\n#> theta 38   -0.0474     0.673 -1.3664  1.2716\n#> theta 39   -1.9160     0.737 -3.3596 -0.4724\n#> theta 40   -1.4093     0.692 -2.7663 -0.0522\n#> theta 41   -1.9160     0.737 -3.3596 -0.4724\n#> theta 42    0.4118     0.683 -0.9270  1.7506\n#> theta 43    0.4118     0.683 -0.9270  1.7506\n#> theta 44    0.4118     0.683 -0.9270  1.7506\n#> theta 45   -1.9160     0.737 -3.3596 -0.4724\n#> theta 46   -0.9452     0.673 -2.2645  0.3741\n#> theta 47    1.3892     0.720 -0.0226  2.8010\n#> theta 48    1.3892     0.720 -0.0226  2.8010\n#> theta 49   -2.5218     0.832 -4.1521 -0.8915\n#> theta 50   -0.4965     0.668 -1.8067  0.8137\n#> theta 51   -0.0474     0.673 -1.3664  1.2716\n#> theta 52   -3.3992     1.085 -5.5254 -1.2730\n#> theta 53    1.9351     0.762  0.4415  3.4287\n#> theta 54   -0.9452     0.673 -2.2645  0.3741\n#> theta 55   -0.9452     0.673 -2.2645  0.3741\n#> theta 56   -2.5218     0.832 -4.1521 -0.8915\n#> theta 57   -0.0474     0.673 -1.3664  1.2716\n#> theta 58    0.8878     0.698 -0.4796  2.2552\n#> theta 59   -0.0474     0.673 -1.3664  1.2716\n#> theta 60    0.8878     0.698 -0.4796  2.2552\n#> theta 61    0.8878     0.698 -0.4796  2.2552\n#> theta 62    0.8878     0.698 -0.4796  2.2552\n#> theta 63    0.4118     0.683 -0.9270  1.7506\n#> theta 64    1.3892     0.720 -0.0226  2.8010\n#> theta 65    0.8878     0.698 -0.4796  2.2552\n#> theta 66    1.3892     0.720 -0.0226  2.8010\n#> theta 67   -0.4965     0.668 -1.8067  0.8137\n#> theta 68   -0.0474     0.673 -1.3664  1.2716\n#> theta 69   -0.4965     0.668 -1.8067  0.8137\n#> theta 70   -0.9452     0.673 -2.2645  0.3741\n#> theta 71    0.4118     0.683 -0.9270  1.7506\n#> theta 72   -0.9452     0.673 -2.2645  0.3741\n#> theta 73    0.4118     0.683 -0.9270  1.7506\n#> theta 74   -0.9452     0.673 -2.2645  0.3741\n#> theta 75    1.3892     0.720 -0.0226  2.8010\n#> theta 76   -0.0474     0.673 -1.3664  1.2716\n#> theta 77   -0.9452     0.673 -2.2645  0.3741\n#> theta 78    0.8878     0.698 -0.4796  2.2552\n#> theta 79   -0.9452     0.673 -2.2645  0.3741\n#> theta 80    0.4118     0.683 -0.9270  1.7506\n#> theta 81    0.8878     0.698 -0.4796  2.2552\n#> theta 82    1.3892     0.720 -0.0226  2.8010\n#> theta 83    0.8878     0.698 -0.4796  2.2552\n#> theta 84    0.4118     0.683 -0.9270  1.7506\n#> theta 85    0.4118     0.683 -0.9270  1.7506\n#> theta 86   -0.9452     0.673 -2.2645  0.3741\n#> theta 87    1.3892     0.720 -0.0226  2.8010\n#> theta 88    0.4118     0.683 -0.9270  1.7506\n#> theta 89   -0.0474     0.673 -1.3664  1.2716\n#> theta 90    0.8878     0.698 -0.4796  2.2552\n#> theta 91   -0.4965     0.668 -1.8067  0.8137\n#> theta 92    0.8878     0.698 -0.4796  2.2552\n#> theta 93   -0.9452     0.673 -2.2645  0.3741\n#> theta 94   -0.4965     0.668 -1.8067  0.8137\n#> theta 95   -1.9160     0.737 -3.3596 -0.4724\n#> theta 96   -0.4965     0.668 -1.8067  0.8137\n#> theta 97   -0.4965     0.668 -1.8067  0.8137\n#> theta 98   -0.4965     0.668 -1.8067  0.8137\n#> theta 99   -0.0474     0.673 -1.3664  1.2716\n#> theta 100  -1.4093     0.692 -2.7663 -0.0522\n#> theta 101   0.8878     0.698 -0.4796  2.2552\n#> theta 102  -0.0474     0.673 -1.3664  1.2716\n#> theta 103   0.4118     0.683 -0.9270  1.7506\n#> theta 104   0.4118     0.683 -0.9270  1.7506\n#> theta 105  -0.9452     0.673 -2.2645  0.3741\n#> theta 106  -0.9452     0.673 -2.2645  0.3741\n#> theta 107  -0.4965     0.668 -1.8067  0.8137\n#> theta 108   0.4118     0.683 -0.9270  1.7506\n#> theta 109   0.4118     0.683 -0.9270  1.7506\n#> theta 110  -0.0474     0.673 -1.3664  1.2716\n#> theta 111  -0.9452     0.673 -2.2645  0.3741\n#> theta 112   0.8878     0.698 -0.4796  2.2552\n#> theta 113  -0.4965     0.668 -1.8067  0.8137\n#> theta 114  -0.0474     0.673 -1.3664  1.2716\n#> theta 115  -0.9452     0.673 -2.2645  0.3741\n#> theta 116  -2.5218     0.832 -4.1521 -0.8915\n#> theta 117  -1.4093     0.692 -2.7663 -0.0522\n#> theta 118  -0.4965     0.668 -1.8067  0.8137\n#> theta 119   0.4118     0.683 -0.9270  1.7506\n#> theta 120  -1.9160     0.737 -3.3596 -0.4724\n#> theta 121  -0.0474     0.673 -1.3664  1.2716\n#> theta 122  -0.9452     0.673 -2.2645  0.3741\n#> theta 123   1.9351     0.762  0.4415  3.4287\n#> theta 124  -0.0474     0.673 -1.3664  1.2716\n#> theta 125  -1.9160     0.737 -3.3596 -0.4724\n#> theta 126  -1.4093     0.692 -2.7663 -0.0522\n#> theta 127  -2.5218     0.832 -4.1521 -0.8915\n#> theta 128  -1.9160     0.737 -3.3596 -0.4724\n#> theta 129  -1.4093     0.692 -2.7663 -0.0522\n#> theta 130  -0.4965     0.668 -1.8067  0.8137\n#> theta 131  -0.9452     0.673 -2.2645  0.3741\n#> theta 132  -0.4965     0.668 -1.8067  0.8137\n#> theta 133  -0.9452     0.673 -2.2645  0.3741\n#> theta 134  -1.4093     0.692 -2.7663 -0.0522\n#> theta 135  -0.9452     0.673 -2.2645  0.3741\n#> theta 136   0.8878     0.698 -0.4796  2.2552\n#> theta 137  -0.0474     0.673 -1.3664  1.2716\n#> theta 138   0.4118     0.683 -0.9270  1.7506\n#> theta 139   1.3892     0.720 -0.0226  2.8010\n#> theta 140   0.8878     0.698 -0.4796  2.2552\n#> theta 141   0.4118     0.683 -0.9270  1.7506\n#> theta 142  -1.4093     0.692 -2.7663 -0.0522\n#> theta 143   0.8878     0.698 -0.4796  2.2552\n#> theta 144  -0.4965     0.668 -1.8067  0.8137\n#> theta 145   1.9351     0.762  0.4415  3.4287\n#> theta 146  -1.9160     0.737 -3.3596 -0.4724\n#> theta 147  -0.0474     0.673 -1.3664  1.2716\n#> theta 148  -0.4965     0.668 -1.8067  0.8137\n#> theta 149  -0.0474     0.673 -1.3664  1.2716\n#> theta 150  -0.4965     0.668 -1.8067  0.8137\n#> theta 151  -0.0474     0.673 -1.3664  1.2716\n#> theta 152  -0.9452     0.673 -2.2645  0.3741\n#> theta 153  -0.9452     0.673 -2.2645  0.3741\n#> theta 154   0.4118     0.683 -0.9270  1.7506\n#> theta 155  -0.4965     0.668 -1.8067  0.8137\n#> theta 156  -1.4093     0.692 -2.7663 -0.0522\n#> theta 157  -0.4965     0.668 -1.8067  0.8137\n#> theta 158  -1.4093     0.692 -2.7663 -0.0522\n#> theta 159   0.4118     0.683 -0.9270  1.7506\n#> theta 160  -0.0474     0.673 -1.3664  1.2716\n#> theta 161  -1.4093     0.692 -2.7663 -0.0522\n#> theta 162   0.8878     0.698 -0.4796  2.2552\n#> theta 163  -1.4093     0.692 -2.7663 -0.0522\n#> theta 164  -0.9452     0.673 -2.2645  0.3741\n#> theta 165  -1.9160     0.737 -3.3596 -0.4724\n#> theta 166  -0.4965     0.668 -1.8067  0.8137\n#> theta 167  -3.3992     1.085 -5.5254 -1.2730\n#> theta 168  -0.9452     0.673 -2.2645  0.3741\n#> theta 169  -3.3992     1.085 -5.5254 -1.2730\n#> theta 170  -0.4965     0.668 -1.8067  0.8137\n#> theta 171  -0.9452     0.673 -2.2645  0.3741\n#> theta 172   1.3892     0.720 -0.0226  2.8010\n#> theta 173  -1.9160     0.737 -3.3596 -0.4724\n#> theta 174  -1.9160     0.737 -3.3596 -0.4724\n#> theta 175   0.4118     0.683 -0.9270  1.7506\n#> theta 176  -1.9160     0.737 -3.3596 -0.4724\n#> theta 177   1.3892     0.720 -0.0226  2.8010\n#> theta 178  -0.9452     0.673 -2.2645  0.3741\n#> theta 179  -0.4965     0.668 -1.8067  0.8137\n#> theta 180  -1.9160     0.737 -3.3596 -0.4724\n#> theta 181  -3.3992     1.085 -5.5254 -1.2730\n#> theta 182  -0.9452     0.673 -2.2645  0.3741\n#> theta 183  -1.4093     0.692 -2.7663 -0.0522\n#> theta 184   0.8878     0.698 -0.4796  2.2552\n#> theta 185  -1.4093     0.692 -2.7663 -0.0522\n#> theta 186   1.3892     0.720 -0.0226  2.8010\n#> theta 187   0.4118     0.683 -0.9270  1.7506\n#> theta 188  -1.4093     0.692 -2.7663 -0.0522\n#> theta 189  -1.4093     0.692 -2.7663 -0.0522\n#> theta 190  -0.4965     0.668 -1.8067  0.8137\n#> theta 191  -0.4965     0.668 -1.8067  0.8137\n#> theta 192  -1.4093     0.692 -2.7663 -0.0522\n#> theta 193  -0.4965     0.668 -1.8067  0.8137\n#> theta 194  -0.0474     0.673 -1.3664  1.2716\n#> theta 195   0.4118     0.683 -0.9270  1.7506\n#> theta 196  -0.0474     0.673 -1.3664  1.2716\n#> theta 197  -0.9452     0.673 -2.2645  0.3741\n#> theta 198   1.9351     0.762  0.4415  3.4287\n#> theta 199   1.3892     0.720 -0.0226  2.8010\n#> theta 200   0.4118     0.683 -0.9270  1.7506\n#> theta 201   0.4118     0.683 -0.9270  1.7506\n#> theta 202  -0.9452     0.673 -2.2645  0.3741\n#> theta 203  -0.4965     0.668 -1.8067  0.8137\n#> theta 204  -0.9452     0.673 -2.2645  0.3741\n#> theta 205   0.8878     0.698 -0.4796  2.2552\n#> theta 206   1.9351     0.762  0.4415  3.4287\n#> theta 207   1.9351     0.762  0.4415  3.4287\n#> theta 208   0.8878     0.698 -0.4796  2.2552\n#> theta 209   0.4118     0.683 -0.9270  1.7506\n#> theta 210   1.3892     0.720 -0.0226  2.8010\n#> theta 211  -1.4093     0.692 -2.7663 -0.0522\n#> theta 212  -0.0474     0.673 -1.3664  1.2716\n#> theta 213  -0.0474     0.673 -1.3664  1.2716\n#> theta 214   0.8878     0.698 -0.4796  2.2552\n#> theta 215   1.9351     0.762  0.4415  3.4287\n#> theta 216   0.4118     0.683 -0.9270  1.7506\n#> theta 217   2.5766     0.851  0.9081  4.2451\n#> theta 218   0.4118     0.683 -0.9270  1.7506\n#> theta 219   1.9351     0.762  0.4415  3.4287\n#> theta 220  -0.0474     0.673 -1.3664  1.2716\n#> theta 221  -1.4093     0.692 -2.7663 -0.0522\n#> theta 222  -0.4965     0.668 -1.8067  0.8137\n#> theta 223  -1.9160     0.737 -3.3596 -0.4724\n#> theta 224   1.3892     0.720 -0.0226  2.8010\n#> theta 225   0.8878     0.698 -0.4796  2.2552\n#> theta 226  -0.0474     0.673 -1.3664  1.2716\n#> theta 227   0.8878     0.698 -0.4796  2.2552\n#> theta 228   1.3892     0.720 -0.0226  2.8010\n#> theta 229  -0.0474     0.673 -1.3664  1.2716\n#> theta 230   0.4118     0.683 -0.9270  1.7506\n#> theta 231   0.4118     0.683 -0.9270  1.7506\n#> theta 232  -0.0474     0.673 -1.3664  1.2716\n#> theta 233  -0.9452     0.673 -2.2645  0.3741\n#> theta 234   0.8878     0.698 -0.4796  2.2552\n#> theta 235  -1.9160     0.737 -3.3596 -0.4724\n#> theta 236   0.4118     0.683 -0.9270  1.7506\n#> theta 237   0.4118     0.683 -0.9270  1.7506\n#> theta 238   3.4832     1.097  1.3336  5.6329\n#> theta 239  -3.3992     1.085 -5.5254 -1.2730\n#> theta 240  -0.9452     0.673 -2.2645  0.3741\n#> theta 241   0.4118     0.683 -0.9270  1.7506\n#> theta 242  -0.0474     0.673 -1.3664  1.2716\n#> theta 243  -0.4965     0.668 -1.8067  0.8137\n#> theta 244   0.4118     0.683 -0.9270  1.7506\n#> theta 245  -1.9160     0.737 -3.3596 -0.4724\n#> theta 246   1.3892     0.720 -0.0226  2.8010\n#> theta 247  -0.9452     0.673 -2.2645  0.3741\n#> theta 248  -0.0474     0.673 -1.3664  1.2716\n#> theta 249   0.4118     0.683 -0.9270  1.7506\n#> theta 250  -1.9160     0.737 -3.3596 -0.4724\n#> theta 251  -2.5218     0.832 -4.1521 -0.8915\n#> theta 252   0.4118     0.683 -0.9270  1.7506\n#> theta 253  -0.9452     0.673 -2.2645  0.3741\n#> theta 254  -0.0474     0.673 -1.3664  1.2716\n#> theta 255  -0.0474     0.673 -1.3664  1.2716\n#> theta 256   0.4118     0.683 -0.9270  1.7506\n#> theta 257   0.8878     0.698 -0.4796  2.2552\n#> theta 258  -0.4965     0.668 -1.8067  0.8137\n#> theta 259  -2.5218     0.832 -4.1521 -0.8915\n#> theta 260  -0.0474     0.673 -1.3664  1.2716\n#> theta 261   0.4118     0.683 -0.9270  1.7506\n#> theta 262   0.4118     0.683 -0.9270  1.7506\n#> theta 263   3.4832     1.097  1.3336  5.6329\n#> theta 264   0.8878     0.698 -0.4796  2.2552\n#> theta 265   1.3892     0.720 -0.0226  2.8010\n#> theta 266  -1.4093     0.692 -2.7663 -0.0522\n#> theta 267   1.3892     0.720 -0.0226  2.8010\n#> theta 268  -0.9452     0.673 -2.2645  0.3741\n#> theta 269  -0.9452     0.673 -2.2645  0.3741\n#> theta 270  -1.4093     0.692 -2.7663 -0.0522\n#> theta 271   1.3892     0.720 -0.0226  2.8010\n#> theta 272   0.8878     0.698 -0.4796  2.2552\n#> theta 273  -0.4965     0.668 -1.8067  0.8137\n#> theta 274  -1.9160     0.737 -3.3596 -0.4724\n#> theta 275   0.4118     0.683 -0.9270  1.7506\n#> theta 276  -0.4965     0.668 -1.8067  0.8137\n#> theta 277  -0.0474     0.673 -1.3664  1.2716\n#> theta 278   1.9351     0.762  0.4415  3.4287\n#> theta 279   0.8878     0.698 -0.4796  2.2552\n#> theta 280   1.3892     0.720 -0.0226  2.8010\n#> theta 281   1.3892     0.720 -0.0226  2.8010\n#> theta 282   0.4118     0.683 -0.9270  1.7506\n#> theta 283  -1.4093     0.692 -2.7663 -0.0522\n#> theta 284  -0.0474     0.673 -1.3664  1.2716\n#> theta 285  -1.9160     0.737 -3.3596 -0.4724\n#> theta 286   1.9351     0.762  0.4415  3.4287\n#> theta 287   0.8878     0.698 -0.4796  2.2552\n#> theta 288   1.3892     0.720 -0.0226  2.8010\n#> theta 289   0.4118     0.683 -0.9270  1.7506\n#> theta 290   0.4118     0.683 -0.9270  1.7506\n#> theta 291  -0.0474     0.673 -1.3664  1.2716\n#> theta 292   0.8878     0.698 -0.4796  2.2552\n#> theta 293  -0.0474     0.673 -1.3664  1.2716\n#> theta 294  -0.9452     0.673 -2.2645  0.3741\n#> theta 296   1.3892     0.720 -0.0226  2.8010\n#> theta 297   1.3892     0.720 -0.0226  2.8010\n#> theta 298   3.4832     1.097  1.3336  5.6329\n#> theta 299   0.8878     0.698 -0.4796  2.2552\n#> theta 300   0.4118     0.683 -0.9270  1.7506\n#> theta 301  -0.9452     0.673 -2.2645  0.3741\n#> theta 302  -0.4965     0.668 -1.8067  0.8137\n#> theta 303   0.4118     0.683 -0.9270  1.7506\n#> theta 304  -0.4965     0.668 -1.8067  0.8137\n#> theta 305  -0.0474     0.673 -1.3664  1.2716\n#> theta 306   0.4118     0.683 -0.9270  1.7506\n#> theta 308   1.3892     0.720 -0.0226  2.8010\n#> theta 309   1.3892     0.720 -0.0226  2.8010\n#> theta 310  -0.0474     0.673 -1.3664  1.2716\n#> theta 311  -1.4093     0.692 -2.7663 -0.0522\n#> theta 312   0.8878     0.698 -0.4796  2.2552\n#> theta 313   1.3892     0.720 -0.0226  2.8010\n#> theta 314   0.8878     0.698 -0.4796  2.2552\n#> theta 315   0.4118     0.683 -0.9270  1.7506\n#> theta 316  -0.0474     0.673 -1.3664  1.2716\n#> theta 317  -0.4965     0.668 -1.8067  0.8137\n#> theta 318   0.4118     0.683 -0.9270  1.7506\n#> theta 319   2.5766     0.851  0.9081  4.2451\n#> theta 320  -0.0474     0.673 -1.3664  1.2716\n#> theta 321  -0.0474     0.673 -1.3664  1.2716\n#> theta 322   0.8878     0.698 -0.4796  2.2552\n#> theta 323   0.8878     0.698 -0.4796  2.2552\n#> theta 324   2.5766     0.851  0.9081  4.2451\n#> theta 325   1.3892     0.720 -0.0226  2.8010\n#> theta 326   0.4118     0.683 -0.9270  1.7506\n#> theta 327   0.8878     0.698 -0.4796  2.2552\n#> theta 328   0.4118     0.683 -0.9270  1.7506\n#> theta 329   0.4118     0.683 -0.9270  1.7506\n#> theta 330  -0.0474     0.673 -1.3664  1.2716\n#> theta 331   0.8878     0.698 -0.4796  2.2552\n#> theta 332  -0.4965     0.668 -1.8067  0.8137\n#> theta 333   0.8878     0.698 -0.4796  2.2552\n#> theta 334  -0.4965     0.668 -1.8067  0.8137\n#> theta 335   0.4118     0.683 -0.9270  1.7506\n#> theta 336  -0.0474     0.673 -1.3664  1.2716\n#> theta 337   1.3892     0.720 -0.0226  2.8010\n#> theta 338  -1.4093     0.692 -2.7663 -0.0522\n#> theta 339   1.3892     0.720 -0.0226  2.8010\n#> theta 340   0.8878     0.698 -0.4796  2.2552\n#> theta 341   0.8878     0.698 -0.4796  2.2552\n#> theta 342   1.9351     0.762  0.4415  3.4287\n#> theta 343   0.8878     0.698 -0.4796  2.2552\n#> theta 344   0.4118     0.683 -0.9270  1.7506\n#> theta 345   1.3892     0.720 -0.0226  2.8010\n#> theta 346  -0.0474     0.673 -1.3664  1.2716\n#> theta 347   1.9351     0.762  0.4415  3.4287\n#> theta 348   0.4118     0.683 -0.9270  1.7506\n#> theta 349   1.3892     0.720 -0.0226  2.8010\n#> theta 350   0.4118     0.683 -0.9270  1.7506\n#> theta 351   0.8878     0.698 -0.4796  2.2552\n#> theta 352  -0.0474     0.673 -1.3664  1.2716\n#> theta 353  -0.0474     0.673 -1.3664  1.2716\n#> theta 354  -0.4965     0.668 -1.8067  0.8137\n#> theta 355   0.4118     0.683 -0.9270  1.7506\n#> theta 356  -0.4965     0.668 -1.8067  0.8137\n#> theta 357  -0.0474     0.673 -1.3664  1.2716\n#> theta 358  -0.0474     0.673 -1.3664  1.2716\n#> theta 359  -0.9452     0.673 -2.2645  0.3741\n#> theta 360  -0.9452     0.673 -2.2645  0.3741\n#> theta 361  -0.4965     0.668 -1.8067  0.8137\n#> theta 362   0.4118     0.683 -0.9270  1.7506\n#> theta 363  -0.9452     0.673 -2.2645  0.3741\n#> theta 364  -0.9452     0.673 -2.2645  0.3741\n#> theta 365  -0.0474     0.673 -1.3664  1.2716\n#> theta 366   0.4118     0.683 -0.9270  1.7506\n#> theta 367  -3.3992     1.085 -5.5254 -1.2730\n#> theta 368  -3.3992     1.085 -5.5254 -1.2730\n#> theta 369  -2.5218     0.832 -4.1521 -0.8915\n#> theta 370  -1.9160     0.737 -3.3596 -0.4724\n#> theta 371   0.8878     0.698 -0.4796  2.2552\n#> theta 372  -0.9452     0.673 -2.2645  0.3741\n#> theta 373  -0.4965     0.668 -1.8067  0.8137\n#> theta 374  -1.9160     0.737 -3.3596 -0.4724\n#> theta 375  -0.4965     0.668 -1.8067  0.8137\n#> theta 376  -1.4093     0.692 -2.7663 -0.0522\n#> theta 377  -1.4093     0.692 -2.7663 -0.0522\n#> theta 378  -2.5218     0.832 -4.1521 -0.8915\n#> theta 379  -0.9452     0.673 -2.2645  0.3741\n#> theta 380  -1.9160     0.737 -3.3596 -0.4724\n#> theta 381  -1.4093     0.692 -2.7663 -0.0522\n#> theta 382  -0.4965     0.668 -1.8067  0.8137\n#> theta 383  -0.0474     0.673 -1.3664  1.2716\n#> theta 384  -1.9160     0.737 -3.3596 -0.4724\n#> theta 385  -1.4093     0.692 -2.7663 -0.0522\n#> theta 386  -0.0474     0.673 -1.3664  1.2716\n#> theta 387   0.4118     0.683 -0.9270  1.7506\n#> theta 388  -0.0474     0.673 -1.3664  1.2716\n#> theta 389   0.8878     0.698 -0.4796  2.2552\n#> theta 390  -0.0474     0.673 -1.3664  1.2716\n#> theta 391  -1.4093     0.692 -2.7663 -0.0522\n#> theta 392   0.4118     0.683 -0.9270  1.7506\n#> theta 393  -0.0474     0.673 -1.3664  1.2716\n#> theta 394   0.4118     0.683 -0.9270  1.7506\n#> theta 395  -0.0474     0.673 -1.3664  1.2716\n#> theta 396  -1.4093     0.692 -2.7663 -0.0522\n#> theta 397  -0.4965     0.668 -1.8067  0.8137\n#> theta 398  -0.0474     0.673 -1.3664  1.2716\n#> theta 399  -0.9452     0.673 -2.2645  0.3741\n#> theta 400  -1.9160     0.737 -3.3596 -0.4724\n```\n:::\n\n\n\n\nL'output – che qui abbiamo di nuovo troncato per risparmiare spazio – contiene stime ed errori standard, insieme ai limiti inferiori (2.5%) e superiori (97.5%) degli intervalli di confidenza al 95%, per tutti i candidati che hanno risposto correttamente fino a 13 item. I candidati che hanno risposto correttamente a tutti i 14 item (o a nessun item) sono omessi da questo output. Possiamo anche notare che alcuni candidati, ad esempio il secondo e il terzo, ricevono esattamente la stessa stima di abilità ed errore standard. Questo è dovuto al fatto che hanno lavorato sullo stesso set di item e hanno ottenuto lo stesso punteggio totale. In alternativa, possiamo utilizzare il comando `coef(theta)` per ottenere solo la stima dell'abilità per ciascun candidato.\n\nPossiamo anche stimare l'abilità dei candidati utilizzando la funzione `mirt::fscores()`. Per i modelli unidimensionali, gli argomenti più importanti di `fscores()` sono `object` e `method`. L'argomento `object` accetta il risultato della funzione `mirt()`. L'argomento `method` indica quale metodo utilizzare per stimare i parametri della persona. Per impostazione predefinita, `method=\"EAP\"`, il che indica che il parametro della persona dovrebbe essere stimato utilizzando il metodo *expected a posteriori* (EAP). Possiamo calcolare le stime EAP per il modello di Rasch e stampare le sue prime sei voci inserendo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta_eap <- fscores(mirt_rm)\nhead(theta_eap)\n#>          F1\n#> [1,] -0.218\n#> [2,] -0.828\n#> [3,] -0.828\n#> [4,] -0.218\n#> [5,]  0.391\n#> [6,] -0.521\n```\n:::\n\n\n\n\nPer impostazione predefinita mirt mostra solo le stime puntuali, ma è possibile aggiungere gli errori standard tramite l'opzione `full.scores.SE = TRUE` alla funzione `fscores()`. Gli errori standard dovrebbero essere esaminati prima di interpretare o riportare le stime dei parametri della persona.\n\nLa funzione `fscores()` fornisce anche stimatori di massima verosimiglianza (ML), massimo a posteriori (MAP) e likelihood ponderata (WLE). Ora confrontiamo i quattro tipi di stime dei parametri della persona fornite da `mirt`. Gli stimatori ML, MAP e WLE possono essere calcolati inserendo\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta_ml <- fscores(mirt_rm, method = \"ML\", max_theta = 30)\ntheta_map <- fscores(mirt_rm, method = \"MAP\")\ntheta_wle <- fscores(mirt_rm, method = \"WLE\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nests <- cbind(theta_eap, theta_ml, theta_map, theta_wle)\ncolnames(ests) <- c(\"EAP\", \"ML\", \"MAP\", \"WLE\")\npairs(ests, xlim = c(-3, 3), ylim = c(-3, 3))\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-55-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n## Affidabilità Condizionale\n\nIl concetto di affidabilità varia tra la CTT e la IRT. Nell'IRT, possiamo calcolare l'affidabilità condizionale, ossia l'affidabilità della scala a diversi livelli di theta. \n\n- Nella **CTT**, l'affidabilità è solitamente considerata come una proprietà fissa del test, indipendentemente dal livello di abilità dei rispondenti. Si misura spesso attraverso il coefficiente alfa di Cronbach o metodi simili.\n- Nell'**IRT**, invece, l'affidabilità è vista come una proprietà variabile che dipende dal livello di theta del rispondente. A diversi livelli di theta, la precisione con cui il test misura l'abilità può variare significativamente.\n  \nL'affidabilità condizionale fornisce una misura più specifica e dettagliata di quanto affidabilmente un test misura l'abilità a diversi livelli di $\\theta$. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconRelPlot(mirt_rm)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-56-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(mirt_rm, type = \"rxx\")\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-57-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nNel caso presente, \n\n- a livelli medi di $\\theta$: Il test mostra una buona affidabilità, indicando che è in grado di distinguere con precisione tra rispondenti con abilità medie.\n- agli estremi di $\\theta$: Il test mostra un'affidabilità più bassa, suggerendo che non è altrettanto efficace nel distinguere tra livelli di abilità molto alti o molto bassi.\n\nIn sostanza, l'affidabilità condizionale nell'IRT ci fornisce una comprensione più dettagliata di dove il test funziona bene e dove potrebbe richiedere miglioramenti per valutare con precisione l'abilità su tutta la gamma di theta.\n\nÈ comunque possibile calcolare un singolo valore di attendibilità:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmarginal_rxx(mirt_rm)\n#> [1] 0.698\n```\n:::\n\n\n\n\n\\\nIl valore riportato ($r_{xx} = 0.698$) indica che circa il 70% della varianza osservata nei punteggi stimati è attribuibile al punteggio vero ($\\theta$), mentre il restante 30% è dovuto all'errore di misura. Questo valore suggerisce che il test stima l'abilità latente $\\theta$ con una precisione accettabile.\n\n## Curva Caratteristica del Test\n\nUna proprietà aggiuntiva di un modello IRT è che il punteggio complessivo delle risposte corrette (la somma dei punteggi per le risposte corrette) risulta essere una stima efficace del tratto latente sottostante. Un grafico della cosiddetta curva caratteristica della scala (*scale characteristic curve*) permette di valutare visivamente questo aspetto tracciando la relazione tra theta e il punteggio di risposte corrette.\n\n- Questo tipo di grafico mostra come il punteggio totale delle risposte corrette si correla con il livello di abilità latente (theta) stimato dal modello IRT.\n- Ad esempio, se la curva mostra che punteggi più alti di risposte corrette corrispondono sistematicamente a livelli più alti di theta e viceversa, ciò indica che il punteggio totale è un buon indicatore del tratto latente.\n- Al contrario, se la curva non mostra una relazione chiara o lineare tra punteggio totale e theta, ciò potrebbe suggerire che il punteggio totale non cattura completamente la complessità o le sfumature del tratto latente.\n\nIn sintesi, la curva caratteristica della scala fornisce una rappresentazione visiva di come il punteggio totale di risposte corrette rifletta l'abilità latente misurata dal test, offrendo una visione utile per valutare l'efficacia del punteggio totale come indicatore del tratto latente in questione.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscaleCharPlot(mirt_rm)\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-59-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(mirt_rm, type = \"score\")\n```\n\n::: {.cell-output-display}\n![](05_implementation_files/figure-html/unnamed-chunk-60-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesta curva di solito assume la forma di una S, poiché la relazione è più forte nel range medio di theta e meno precisa agli estremi (come già visto nella curva di informazione del test). \n\nPossiamo ovviamente testare anche questo con una semplice correlazione. Per prima cosa, estraiamo il punteggio latente IRT utilizzando la funzione `fscores()`. Quindi lo correliamo con il punteggio di risposte corrette.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nscore <- fscores(mirt_rm)\nsumscore <- rowSums(responses)\ncor.test(score, sumscore)\n#> \n#> \tPearson's product-moment correlation\n#> \n#> data:  score and sumscore\n#> t = 1097, df = 398, p-value <2e-16\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  1 1\n#> sample estimates:\n#> cor \n#>   1\n```\n:::\n\n\n\n\nNel caso presente, la correlazione è quasi perfetta.\n\n## Riflessioni Conclusive\n\nTradizionalmente, il punteggio totale ottenuto in un test psicologico è stato considerato come la misura più efficace dell'abilità o della predisposizione di una persona rispetto a un certo tratto di personalità. Tuttavia, la dipendenza del punteggio totale dalla difficoltà degli item presenta limitazioni significative. Ad esempio, due persone possono ottenere lo stesso punteggio totale rispondendo in modo diverso a item di varia difficoltà, il che non riflette accuratamente le loro abilità reali.\n\nNella Teoria Classica dei Test (CTT), l'enfasi è posta sul punteggio totale, ma questa prospettiva ignora le variazioni nella difficoltà degli item e assume che gli errori di misurazione si annullino reciprocamente attraverso la procedura di sommazione. Tuttavia, la CTT è limitata dalla sua assunzione di varianze di errore uniformi per tutti i rispondenti, dall'aspettativa di errori di misurazione nulli e dalla focalizzazione esclusiva sui punteggi totali, senza considerare l'adattamento di item e persone.\n\nAl contrario, la Teoria della Risposta all'Item (IRT) cambia il focus dai punteggi totali alle risposte a ciascun item, sfruttando le caratteristiche degli item. L'IRT descrive come attributi come abilità, atteggiamento o personalità, insieme alle caratteristiche degli item, influenzino la probabilità di fornire una risposta. Il Modello di Rasch, una forma semplice di IRT per risposte binarie, stabilisce una relazione diretta tra la probabilità di una risposta corretta e il livello di abilità del rispondente.\n\nLa stima dell'abilità in IRT non dipende dagli specifici item somministrati, permettendo di confrontare i risultati tra gruppi diversi con lo stesso set di item. Inoltre, la qualità degli item è valutata indipendentemente dal campione di rispondenti, rendendo le proprietà degli item costanti tra diversi gruppi con varie abilità.\n\nL'IRT supera i limiti della CTT stimando congiuntamente le proprietà degli item e il livello di abilità dei rispondenti. Le caratteristiche degli item diventano indipendenti dal campione di individui utilizzato per costruire il test, permettendo la creazione di insiemi di item equivalenti per misurare abilità latenti. Questo approccio offre maggiore precisione e affidabilità nelle misurazioni, assicurando la comparabilità tra diversi gruppi di individui. In conclusione, l'IRT rappresenta un metodo statistico avanzato e versatile per una valutazione più accurata e affidabile di tratti e abilità in contesti psicometrici.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] grid      stats4    stats     graphics  grDevices utils     datasets \n#> [8] methods   base     \n#> \n#> other attached packages:\n#>  [1] psychotools_0.7-4 ggmirt_0.1.0      TAM_4.2-21        CDM_8.2-6        \n#>  [5] mvtnorm_1.3-3     mirt_1.44.0       lattice_0.22-6    eRm_1.0-6        \n#>  [9] ggokabeito_0.1.0  see_0.10.0        MASS_7.3-64       viridis_0.6.5    \n#> [13] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#> [17] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n#> [21] lavaan_0.6-19     psych_2.4.12      scales_1.3.0      markdown_1.13    \n#> [25] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [29] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#> [33] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2        later_1.4.1          R.oo_1.27.0         \n#>   [4] XML_3.99-0.18        rpart_4.1.24         lifecycle_1.0.4     \n#>   [7] Rdpack_2.6.2         rstatix_0.7.2        rprojroot_2.0.4     \n#>  [10] globals_0.16.3       rockchalk_1.8.157    backports_1.5.0     \n#>  [13] magrittr_2.0.3       openxlsx_4.2.8       Hmisc_5.2-2         \n#>  [16] rmarkdown_2.29       yaml_2.3.10          httpuv_1.6.15       \n#>  [19] qgraph_1.9.8         zip_2.3.2            sessioninfo_1.2.3   \n#>  [22] cowplot_1.1.3        pbapply_1.7-2        minqa_1.2.8         \n#>  [25] multcomp_1.4-28      abind_1.4-8          audio_0.1-11        \n#>  [28] quadprog_1.5-8       R.utils_2.12.3       nnet_7.3-20         \n#>  [31] TH.data_1.1-3        sandwich_3.1-1       listenv_0.9.1       \n#>  [34] testthat_3.2.3       RPushbullet_0.3.4    vegan_2.6-10        \n#>  [37] arm_1.14-4           parallelly_1.42.0    permute_0.9-7       \n#>  [40] codetools_0.2-20     tidyselect_1.2.1     farver_2.1.2        \n#>  [43] lme4_1.1-36          base64enc_0.1-3      jsonlite_1.8.9      \n#>  [46] polycor_0.8-1        progressr_0.15.1     Formula_1.2-5       \n#>  [49] survival_3.8-3       emmeans_1.10.7       tools_4.4.2         \n#>  [52] snow_0.4-4           Rcpp_1.0.14          glue_1.8.0          \n#>  [55] mnormt_2.1.1         admisc_0.37          xfun_0.50           \n#>  [58] mgcv_1.9-1           withr_3.0.2          beepr_2.0           \n#>  [61] fastmap_1.2.0        boot_1.3-31          digest_0.6.37       \n#>  [64] mi_1.1               timechange_0.3.0     R6_2.6.1            \n#>  [67] mime_0.12            estimability_1.5.1   colorspace_2.1-1    \n#>  [70] gtools_3.9.5         jpeg_0.1-10          R.methodsS3_1.8.2   \n#>  [73] generics_0.1.3       data.table_1.16.4    corpcor_1.6.10      \n#>  [76] SimDesign_2.18       htmlwidgets_1.6.4    pkgconfig_2.0.3     \n#>  [79] sem_3.1-16           gtable_0.3.6         brio_1.1.5          \n#>  [82] htmltools_0.5.8.1    carData_3.0-5        png_0.1-8           \n#>  [85] reformulas_0.4.0     rstudioapi_0.17.1    tzdb_0.4.0          \n#>  [88] reshape2_1.4.4       coda_0.19-4.1        checkmate_2.3.2     \n#>  [91] nlme_3.1-167         curl_6.2.0           nloptr_2.1.1        \n#>  [94] zoo_1.8-12           parallel_4.4.2       miniUI_0.1.1.1      \n#>  [97] foreign_0.8-88       pillar_1.10.1        vctrs_0.6.5         \n#> [100] promises_1.3.2       car_3.1-3            OpenMx_2.21.13      \n#> [103] xtable_1.8-4         Deriv_4.1.6          cluster_2.1.8       \n#> [106] dcurver_0.9.2        GPArotation_2024.3-1 htmlTable_2.4.3     \n#> [109] evaluate_1.0.3       pbivnorm_0.6.0       cli_3.6.4           \n#> [112] kutils_1.73          compiler_4.4.2       rlang_1.1.5         \n#> [115] future.apply_1.11.3  ggsignif_0.6.4       labeling_0.4.3      \n#> [118] fdrtool_1.2.18       plyr_1.8.9           stringi_1.8.4       \n#> [121] munsell_0.5.1        lisrelToR_0.3        pacman_0.5.1        \n#> [124] Matrix_1.7-2         hms_1.1.3            glasso_1.11         \n#> [127] future_1.34.0        shiny_1.10.0         rbibutils_2.3       \n#> [130] igraph_2.1.4         broom_1.0.7          RcppParallel_5.1.10\n```\n:::\n",
    "supporting": [
      "05_implementation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
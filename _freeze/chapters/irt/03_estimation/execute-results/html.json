{
  "hash": "cc5a21c5b2deec1d1e9a314308ccddfd",
  "result": {
    "engine": "knitr",
    "markdown": "# Stima {#sec-irt-estimation}\n\n\n::: callout-important\n## In questo capitolo apprenderai come:\n\n-  \n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo 8, *Item Response Theory*, del testo *Principles of psychological assessment* di @petersen2024principles. \n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |>\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    grid, latex2exp, mirt, TAM, ggmirt, cmdstanr, posterior,\n    rstan, tidyr, psych, rsvg, effectsize\n)\n```\n:::\n\n\n\n\n### Introduzione\n\nPer utilizzare il modello di Rasch nella ricerca pratica, è essenziale comprendere come stimare i suoi parametri a partire dai dati osservati. In questa sezione verranno illustrati diversi metodi di stima, ognuno dei quali consente di calcolare sia i parametri degli item che quelli delle persone, differenziandosi però per l'approccio utilizzato.\n\nAlcuni metodi, come la **massima verosimiglianza congiunta** e l'**inferenza bayesiana**, stimano simultaneamente i parametri degli item e delle persone. Altri, come la **massima verosimiglianza condizionale** e la **massima verosimiglianza marginale**, separano il processo di stima: i parametri degli item vengono stimati per primi, seguiti dalla stima dei parametri delle persone in una fase successiva. Questa distinzione tra approcci permette di scegliere la metodologia più adatta al contesto e alle caratteristiche dei dati analizzati.\n\n## La Funzione di Verosimiglianza\n\nLa stima dei parametri nel modello di Rasch si basa sulla **funzione di verosimiglianza**, che rappresenta la probabilità di osservare i dati disponibili dato un insieme di parametri sconosciuti. Nel contesto del modello, $U_{pi}$ denota la risposta (corretta o errata) fornita dalla persona $p$ all’item $i$, dove una risposta corretta è codificata come 1 e una errata come 0. La probabilità condizionale che una persona con abilità $\\theta_p$ risponda specificamente $u_{pi}$ all’item $i$, la cui difficoltà è $\\beta_i$, è definita dalla formula:\n\n$$\n\\text{Pr}(U_{pi} = u_{pi} | \\theta_p, \\beta_i) = \\frac{\\exp\\{u_{pi} \\cdot (\\theta_p - \\beta_i)\\}}{1 + \\exp(\\theta_p - \\beta_i)}.\n$$\n\nQuesta equazione calcola la probabilità della risposta osservata, basandosi sulla differenza tra l'abilità della persona ($\\theta_p$) e la difficoltà dell’item ($\\beta_i$). Se l'abilità $\\theta_p$ supera la difficoltà $\\beta_i$, la probabilità di una risposta corretta ($u_{pi} = 1$) è elevata; al contrario, se $\\theta_p$ è inferiore a $\\beta_i$, tale probabilità sarà ridotta.\n\n### Verosimiglianza Complessiva per una Persona\n\nLa **verosimiglianza complessiva** per una persona $p$ rispetto a tutte le sue risposte agli item del test ($i = 1, \\dots, I$) si ottiene moltiplicando le probabilità condizionali di ciascuna risposta. La funzione di verosimiglianza totale è quindi espressa come:\n\n$$\nL_{up}(\\theta_p, \\beta) = \\prod_{i=1}^{I} \\frac{\\exp\\{u_{pi} \\cdot (\\theta_p - \\beta_i)\\}}{1 + \\exp(\\theta_p - \\beta_i)}.\n$$\n\nRiorganizzando per maggiore chiarezza, questa può essere riscritta come:\n\n$$\nL_{up}(\\theta_p, \\beta) = \\frac{\\exp(r_p \\cdot \\theta_p - \\sum_{i=1}^{I} u_{pi} \\cdot \\beta_i)}{\\prod_{i=1}^{I} [1 + \\exp(\\theta_p - \\beta_i)]}, \\tag{1}\n$$\n\ndove:\n\n- $r_p = \\sum_{i=1}^{I} u_{pi}$ rappresenta il **punteggio grezzo** della persona $p$, ovvero il numero totale di risposte corrette.\n\nQuesta formulazione sintetizza come la funzione di verosimiglianza dipenda non solo dal parametro di abilità $\\theta_p$ della persona, ma anche dai parametri di difficoltà $\\beta_i$ degli item. La funzione è essenziale per stimare questi parametri e per interpretare la relazione tra abilità e difficoltà nel contesto del test.\n\n## Stima dei Parametri nel Modello di Rasch\n\nL’@eq-rasch-likelihood rappresenta la base comune per tutti i metodi di stima dei parametri nel modello di Rasch. Tuttavia, il metodo scelto per stimare i parametri influenzerà il modo in cui l'abilità delle persone ($\\theta_p$) e la difficoltà degli item ($\\beta_i$) vengono calcolate e interpretate:\n\n- **Stima simultanea**: Alcuni metodi, come la massima verosimiglianza congiunta e l'inferenza bayesiana, stimano simultaneamente $\\theta_p$ e $\\beta_i$.\n- **Stima separata**: Altri metodi, come la massima verosimiglianza condizionale e la massima verosimiglianza marginale, stimano $\\beta_i$ in un primo passaggio, per poi derivare $\\theta_p$.\n\nOgni approccio introduce assunzioni specifiche che influenzano le proprietà delle stime e la loro applicabilità in diversi contesti.\n\n### Stima della Massima Verosimiglianza Congiunta\n\nLa **stima della massima verosimiglianza congiunta (JML)** mira a determinare simultaneamente i parametri delle persone ($\\theta_p$) e degli item ($\\beta_i$) che massimizzano la probabilità complessiva dei dati osservati, come descritto nella funzione di verosimiglianza del modello di Rasch. Questo approccio identifica il set di parametri più probabili che potrebbero aver generato il dataset analizzato.\n\n**Punti di forza**:\n\n- Metodo diretto e intuitivo, che utilizza tutta l'informazione disponibile nei dati osservati.\n\n**Limitazioni**:\n\n- **Stime inconsistenti**: Nonostante la semplicità del metodo, JML non garantisce stime consistenti dei parametri degli item, anche con campioni di grandi dimensioni. Questo limita la sua affidabilità, specialmente in contesti che richiedono alta precisione e robustezza nelle stime.\n- **Bias intrinseco**: Le stime delle abilità ($\\theta_p$) e delle difficoltà ($\\beta_i$) possono essere influenzate l'una dall'altra, causando errori sistematici.\n\n**Implementazione in R**:\n\n- JML è implementato nel pacchetto **TAM**, attraverso la funzione `tam.jml()`. Sebbene disponibile, il suo utilizzo è sconsigliato in analisi avanzate o quando la consistenza delle stime è critica.\n\n### Stima della Massima Verosimiglianza Condizionale\n\nLa **stima della massima verosimiglianza condizionale (CML)** affronta le limitazioni della JML separando la stima dei parametri degli item da quella delle persone. Questo approccio procede in due fasi:\n\n1. **Stima dei parametri degli item**:\n\n   - La CML utilizza le **statistiche sufficienti** delle persone (ad esempio, i punteggi grezzi $r_p = \\sum u_{pi}$) per isolare i parametri degli item. In questa fase, le abilità delle persone ($\\theta_p$) non sono direttamente considerate, evitando il bias congiunto.\n   \n2. **Stima dei parametri delle persone**:\n\n   - Una volta stimati i parametri degli item ($\\beta_i$), si procede alla stima delle abilità ($\\theta_p$) basandosi sui dati individuali e sulle difficoltà stimate.\n\n**Vantaggi**:\n\n- Fornisce stime consistenti dei parametri degli item.\n- Evita il problema del bias associato alla stima simultanea di JML.\n\n**Limitazioni**:\n\n- L'accuratezza dei parametri delle persone dipende dalla precisione delle stime degli item nella prima fase.\n\n**Implementazione in R**:\n\n- La CML è implementata nel pacchetto **eRm** tramite la funzione `RM()`, che consente di stimare i parametri degli item in modo robusto e separato.\n\n### Stima della Massima Verosimiglianza Marginale\n\nLa **stima della massima verosimiglianza marginale (MML)** rappresenta un approccio avanzato che considera le abilità delle persone come una variabile casuale seguendo una distribuzione ipotizzata, tipicamente normale. Questo metodo differisce dalla CML trattando i parametri delle abilità ($\\theta_p$) come effetti casuali anziché fissi, e li integra nella funzione di verosimiglianza complessiva.\n\n**Come funziona**:\n\n1. **Distribuzione marginale delle abilità**:\n\n   - La MML assume che le abilità ($\\theta_p$) siano distribuite nella popolazione secondo una distribuzione nota (ad esempio, una normale standard). Invece di stimare direttamente $\\theta_p$, il metodo stima i parametri degli item ($\\beta_i$) tenendo conto di questa distribuzione.\n\n2. **Scoring individuale**:\n\n   - Dopo aver stimato i parametri degli item, si calcolano i punteggi individuali ($\\theta_p$) basandosi sulle risposte e sui parametri stimati.\n\n**Vantaggi**:\n\n- Produce stime più precise e realistiche dei parametri degli item rispetto alla JML.\n- È particolarmente utile quando le abilità nella popolazione seguono una distribuzione continua e ipotizzabile.\n\n**Limitazioni**:\n\n- La validità delle stime dipende dalla correttezza dell'assunzione sulla distribuzione delle abilità ($\\theta_p$).\n\n**Implementazione in R**:\n\n- La MML è supportata dai pacchetti **mirt** e **TAM**. Ad esempio:\n  - Funzioni come `mirt()` in **mirt** permettono stime flessibili con distribuzioni marginali specificabili.\n  - Anche **ltm** (sebbene non più attivamente sviluppato) offre strumenti per la stima marginale.\n\n\n### Confronto tra i Metodi\n\n| **Metodo**                  | **Caratteristiche principali**                                                                                        | **Pro**                                                              | **Contro**                                                   |\n|-----------------------------|-----------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------|--------------------------------------------------------------|\n| **JML (Massima Verosimiglianza Congiunta)** | Stima simultanea di $\\theta_p$ e $\\beta_i$.                                                              | Intuitivo e diretto.                                                 | Stime inconsistenti; bias congiunto.                        |\n| **CML (Massima Verosimiglianza Condizionale)** | Stima separata in due fasi: prima $\\beta_i$, poi $\\theta_p$.                                              | Stime consistenti per $\\beta_i$; evita il bias.                  | Dipende dall'accuratezza delle stime iniziali degli item.    |\n| **MML (Massima Verosimiglianza Marginale)** | Integra una distribuzione marginale per $\\theta_p$; tratta $\\theta_p$ come effetti casuali.               | Stime realistiche e robuste; considera la distribuzione della popolazione. | Dipende dall'assunzione sulla distribuzione delle abilità.  |\n\nIn conclusione, ogni metodo presenta vantaggi e svantaggi che lo rendono più o meno adatto a specifici contesti di analisi. La **JML** è utile per analisi preliminari o semplici, ma è limitata dalla mancanza di consistenza. La **CML** e la **MML** offrono stime più robuste e realistiche, con la MML che si distingue per la sua flessibilità nell'incorporare distribuzioni di popolazione. \n\n::: {#exr-}\n\nConsideriamo ora la procedura di stima del livello di abilità $\\theta$ di un individuo nel modello di Rasch attraverso l'uso della massima verosimiglianza marginale. La procedura per stimare la posizione di un individuo, dato un particolare pattern di risposte, può essere formulata con i seguenti passaggi.\n\n1. Consideriamo un determinato pattern di risposta. Per esempio, il pattern \"11000\" indica che un particolare individuo ha fornito due risposte corrette seguite da tre errate a cinque item, con un totale di $X = 2$ risposte corrette.\n\n2. Calcoliamo le probabilità per ogni risposta. Utilizziamo l'@eq-rasch-model per calcolare la probabilità di ciascuna risposta nel pattern, in base a un dato livello di abilità $\\theta$.\n\n3. Determiniamo la probabilità del pattern di risposta. Questo passaggio si basa sull'assunzione di indipendenza condizionale (ovvero, per un dato $\\theta$, le risposte sono indipendenti l'una dall'altra). Questa assunzione ci permette di applicare la regola di moltiplicazione per eventi indipendenti alle probabilità degli item per ottenere la probabilità complessiva del pattern di risposta per un dato $\\theta$.\n\n4. Ripetiamo i calcoli per diversi valori di $\\theta$. Ripetiamo i passaggi 1 e 2 per una serie di valori di $\\theta$. Nel nostro esempio, il range di $\\theta$ va da $-3$ a $3$.\n\n5. Determiniamo il valore di $\\theta$ con la massima verosimiglianza. L'ultimo passaggio consiste nel determinare quale valore di $\\theta$ tra quelli calcolati nel passaggio 3 abbia la più alta verosimiglianza di produrre il pattern \"11000\". Per fare questo scegliamo il valore $\\theta$ per cui la verosimiglianza è massima.\n\nDi seguito, esaminiamo uno script in `R` che implementa questa procedura.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definiamo il pattern di risposta\nresponse_pattern <- c(1, 1, 0, 0, 0)\n\n# Range di valori di theta da esplorare\ntheta_values <- seq(-3, 3, by = 0.01)\n\n# Funzione per calcolare la probabilità di un singolo pattern di risposta\ncalculate_probability <- function(theta, pattern) {\n    correct_probs <- exp(theta) / (1 + exp(theta))\n    item_probs <- ifelse(pattern == 1, correct_probs, 1 - correct_probs)\n    prod(item_probs)\n}\n# Per semplicità, assumiamo che il parametro di difficoltà (beta) sia zero per tutti gli item.\n\n# Calcoliamo le probabilità per ogni valore di theta. Usiamo sapply per applicare \n# la funzione calculate_probability a ciascun valore di theta nel range specificato.\nprobabilities <- sapply(theta_values, calculate_probability, pattern = response_pattern)\n\n# Identifichiamo il valore di theta con la massima verosimiglianza\nbest_theta <- theta_values[which.max(probabilities)]\n\nprint(paste(\"Valore di theta calcolato con la massima verosimiglianza:\", best_theta))\n#> [1] \"Valore di theta calcolato con la massima verosimiglianza: -0.41\"\n```\n:::\n\n\n\n\nQuesto script calcola la probabilità di ottenere il pattern di risposta \"11000\" per cinque item per un dato intervallo di valori di $\\theta$ e identifica il valore di $\\theta$ che massimizza questa probabilità. Si noti che il modello di Rasch prevede che tutti gli item abbiano la stessa discriminazione, quindi non è necessario specificare un parametro di discriminazione per ogni item. Abbiamo assunto inoltre che la difficoltà di tutti gli item sia uguale a zero.\n\nLa verosimiglianza di un pattern di risposta di un singolo rispondente a diversi item può essere rappresentata simbolicamente nel modo seguente. Se consideriamo $x$ come il pattern di risposta di un rispondente (ad esempio, $x = 11000$ indica che il rispondente ha risposto correttamente ai primi due item e ha dato risposte sbagliate agli ultimi tre), la verosimiglianza del vettore di risposta $x_i$ della persona $i$ è espressa come:\n\n$$\n\\begin{equation}\nL(x_i) = \\prod_{j=1}^{L} p_{ij},\n\\end{equation}\n$$\n\ndove $p_{ij} = p(x_{ij} = 1 \\mid \\theta_i, \\alpha_j, \\delta_j)$ rappresenta la probabilità che la persona $i$, con un livello di abilità $\\theta_i$, risponda correttamente all'item $j$. In questa formula, $\\alpha_j$ è il parametro di discriminazione dell'item $j$ e $\\delta_j$ è il suo parametro di difficoltà. Il parametro $\\alpha_j$ indica quanto bene l'item $j$ è in grado di discriminare tra rispondenti di diversi livelli di abilità, mentre $\\delta_j$ rappresenta il livello di abilità per cui la probabilità di una risposta corretta è del 50%. Il prodotto è calcolato su tutti gli $L$ item a cui il rispondente ha risposto, e il simbolo $\\prod$ rappresenta il prodotto di tutte queste probabilità individuali.\n\nIl calcolo diretto della verosimiglianza può diventare problematico all'aumentare del numero di item, poiché il prodotto di molteplici probabilità può risultare in valori molto piccoli, difficili da gestire con precisione in calcoli numerici. Pertanto, è spesso più pratico lavorare con la trasformazione logaritmica naturale della verosimiglianza, ovvero $\\log_e(L(x_i))$ o $\\ln(L(x_i))$. Questa trasformazione converte il prodotto in una somma, come segue:\n\n$$\n\\begin{equation}\n\\ln L(x_i) = \\sum_{j=1}^{L} \\ln(p_{ij}).\n\\end{equation}\n$$\n\nL'uso del logaritmo naturale trasforma quindi la verosimiglianza in una somma di logaritmi, semplificando il calcolo e riducendo i problemi di rappresentazione numerica nei calcoli complessi.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione del pattern di risposta\nresponse_pattern <- c(1, 1, 0, 0, 0)\n\n# Range di valori di theta da esplorare\ntheta_values <- seq(-3, 3, by = 0.1)\n\n# Calcolo della log-verosimiglianza per ogni valore di theta\nlog_likelihoods <- numeric(length(theta_values))\nfor (i in seq_along(theta_values)) {\n    theta <- theta_values[i]\n    log_item_probs <- numeric(length(response_pattern))\n\n    # Calcolo delle probabilità logaritmiche individuali per ogni item nel pattern\n    for (j in seq_along(response_pattern)) {\n        prob_correct <- exp(theta) / (1 + exp(theta))\n        prob <- ifelse(response_pattern[j] == 1, prob_correct, 1 - prob_correct)\n        log_item_probs[j] <- log(prob)\n    }\n\n    # Calcolo della log-verosimiglianza\n    log_likelihoods[i] <- sum(log_item_probs)\n}\n\n# Creazione di un dataframe per il plotting\nplot_data <- data.frame(theta = theta_values, log_likelihood = log_likelihoods)\n\n# Rappresentazione grafica della log-verosimiglianza\nggplot(plot_data, aes(x = theta, y = log_likelihood)) +\n    geom_line() +\n    labs(\n        x = expression(theta), y = \"Log-likelihood\",\n        title = \"Log-likelihood Function for Response Pattern 11000\"\n    ) \n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n:::\n\n## Errore Standard della Stima e Informazione dell'Item\n\nNel modello di Rasch, l'**Errore Standard della Stima (EES)** è un indicatore chiave che quantifica l'incertezza associata alla stima del livello di abilità di un individuo ($\\theta$). L'EES è fondamentale perché fornisce una misura della precisione con cui la stima di $\\theta$ riflette l'abilità reale del rispondente. Un EES più basso indica una stima più precisa, mentre un EES più alto segnala una maggiore incertezza.\n\n### Calcolo dell'EES\n\nL'EES è determinato dall'**informazione totale dell'item** a un dato livello di abilità $\\theta$, indicata con $I(\\theta)$. L'EES è definito come l'inverso della radice quadrata di $I(\\theta)$:\n\n$$\n\\text{EES}(\\theta) = \\frac{1}{\\sqrt{I(\\theta)}},\n$$\n\ndove $I(\\theta)$ rappresenta l'informazione totale accumulata dagli item del test a quel livello di abilità.\n\n\n### Informazione dell'Item\n\nL'**informazione dell'item** misura il contributo di ciascun item alla precisione della stima di $\\theta$. Per un dato livello di abilità, l'informazione fornita da un singolo item dipende dalla probabilità che il rispondente dia una risposta corretta ($p_{ij}$) e dalla probabilità di una risposta errata ($1 - p_{ij}$). La formula per calcolare l'informazione totale degli item è:\n\n$$\nI(\\theta) = \\sum_{j=1}^{L} p_{ij}(1 - p_{ij}),\n$$\n\ndove:\n\n- $L$ è il numero totale di item del test.\n- $p_{ij}$ è la probabilità che una persona con abilità $\\theta$ risponda correttamente all'item $j$.\n\nL'informazione fornita da un singolo item raggiunge il suo massimo quando la difficoltà dell'item ($\\delta_j$) è uguale al livello di abilità del rispondente ($\\theta$). In questa condizione, l'item discrimina al meglio tra rispondenti con livelli di abilità leggermente superiori o inferiori a $\\delta_j$.\n\n\n### Relazione tra Informazione e Precisione\n\n- **Massima informazione, minima incertezza**: Quando $I(\\theta)$ è alta, l'EES ($\\text{EES}(\\theta)$) è basso, indicando una stima precisa.\n- **Bassa informazione, alta incertezza**: Quando $I(\\theta)$ è bassa, l'EES è alto, segnalando una maggiore incertezza nella stima di $\\theta$.\n\nQuesta relazione evidenzia l'importanza di progettare test con item che siano informativi per il range di abilità di interesse.\n\n\n### Curva di Informazione dell'Item\n\nL'**informazione dell'item** varia a seconda del livello di abilità del rispondente. Per visualizzare questa relazione, si traccia la **curva di informazione dell'item**, che rappresenta l'informazione fornita da un singolo item in funzione di $\\theta$. Alcune caratteristiche della curva:\n\n- Ha una forma a campana.\n- Raggiunge il picco quando $\\theta = \\delta_j$, ossia quando l'abilità del rispondente corrisponde alla difficoltà dell'item.\n- Larghezza e altezza della curva dipendono dalla discriminazione dell'item (nel modello Rasch, fissata a 1).\n\nLa somma delle curve di informazione dei singoli item produce la **curva di informazione totale del test**, che mostra la precisione complessiva del test a diversi livelli di abilità.\n\n### Applicazioni pratiche\n\n- **Progettazione del test**: La conoscenza dell'informazione degli item aiuta a creare test che siano più informativi per specifici livelli di abilità, riducendo l'EES per i range di interesse.\n- **Interpretazione dei risultati**: L'EES permette di stimare intervalli di confidenza per $\\theta$, fornendo una misura della precisione della stima:\n\n  $$\n  \\text{Intervallo di confidenza per } \\theta = \\theta \\pm 1.96 \\cdot \\text{EES}(\\theta).\n  $$\n\nL'analisi dell'informazione dell'item e del test è quindi essenziale per garantire che le misurazioni ottenute siano affidabili e utili per l'interpretazione e il confronto delle abilità.\n\n::: {#exr-}\n\nUtilizzando il modello di Rasch, possiamo calcolare le probabilità di risposta corretta per diversi valori di abilità e, di conseguenza, la *Funzione Informativa dell'Item* (*Item Information Function*, IIF):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione di un range di abilità\ntheta <- seq(-4, 4, by = 0.1)\n\n# Definizione di un parametro di difficoltà dell'item\nbeta <- 0\n\n# Calcolo delle probabilità di risposta corretta per ciascun valore di abilità usando la funzione logistica\nprob_correct <- exp(theta - beta) / (1 + exp(theta - beta))\n\n# Calcolo dell'informazione dell'item\nitem_info <- prob_correct * (1 - prob_correct)\n\n# Creazione della prima grafica (ICC)\nplot(theta, prob_correct,\n    type = \"l\", col = \"blue\", lwd = 2,\n    xlab = \"Abilita' theta\", ylab = \"Probabilita' di Risposta Corretta\",\n    main = \"Curva Caratteristica dell'Item (ICC) e Informazione dell'Item\"\n)\n\n# Aggiunta di un secondo asse y per l'informazione\npar(new = TRUE)\nplot(theta, item_info,\n    type = \"l\", col = \"red\", lwd = 2,\n    xlab = \"\", ylab = \"\", axes = FALSE, ann = FALSE\n)\n\n# Aggiungere l'asse y di destra per l'informazione\naxis(side = 4, at = pretty(range(item_info)))\nmtext(\"Informazione\", side = 4, line = 3)\n\n# Aggiunta della legenda\nlegend(\"topright\",\n    legend = c(\"ICC\", \"Informazione\"),\n    col = c(\"blue\", \"red\"), lty = 1, cex = 0.8\n)\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nQuesta rappresentazione grafica in R mostra come l'informazione vari in funzione del livello di abilità. In generale, l'informazione è massima quando l'abilità dell'esaminando è vicina alla difficoltà dell'item e diminuisce man mano che ci si allontana da questo punto.\n\nIl concetto di informazione in IRT è fondamentale sia per la costruzione del test sia per la sua interpretazione. Indica quanto efficacemente ciascun item misura l'abilità a vari livelli e aiuta a determinare quali item sono più informativi per la stima dell'abilità degli esaminandi. Inoltre, fornisce indicazioni sulla precisione con cui l'abilità degli esaminandi può essere stimata a vari punti lungo la scala di abilità.\n:::\n\n::: {#exr-}\n\nPer dimostrare come calcolare la TIF in $\\mathsf{R}$, possiamo estendere l'esempio precedente includendo più item e sommando le loro informazioni:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione di parametri di difficoltà per diversi item\nbeta_items <- c(-1, 0, 1) # Esempio di tre item con difficoltà diverse\n\n# Calcolo dell'informazione per ogni item e somma per ottenere la TIF\ntest_info <- rep(0, length(theta))\nfor (beta in beta_items) {\n    prob_correct <- exp(theta - beta) / (1 + exp(theta - beta))\n    item_info <- prob_correct * (1 - prob_correct)\n    test_info <- test_info + item_info\n}\n\n# Creazione del grafico della TIF\nplot(theta, test_info,\n    type = \"l\", col = \"blue\", lwd = 2,\n    xlab = \"Abilità theta\", ylab = \"Informazione del Test\",\n    main = \"Funzione di Informazione del Test (TIF)\"\n)\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nIn questo esempio, calcoliamo e sommiamo le informazioni di tre item con diverse difficoltà per visualizzare la TIF di un test ipotetico. La TIF mostra in modo chiaro come il test nel suo insieme stima l'abilità degli esaminandi a vari livelli, fornendo così indicazioni preziose sulla costruzione e sull'utilizzo ottimale del test in diversi contesti.\n:::\n\n## Stima dell'Abilità\n\nNel contesto dell'IRT, la stima dell'abilità di un esaminando ($\\theta$) viene effettuata utilizzando metodi iterativi, come la massima verosimiglianza, che sfruttano i dati del test e i parametri degli item. Questo processo consente di stimare il livello di abilità in modo personalizzato, tenendo conto del pattern di risposte specifico di ciascun esaminando.\n\n### Procedura di Stima dell'Abilità\n\n1. **Punto di partenza**:\n   - La stima inizia con un'ipotesi iniziale o un valore a priori per l'abilità dell'esaminando. Questo valore può essere scelto in base a considerazioni teoriche (ad esempio, $\\theta = 0$, corrispondente alla media presunta dell'abilità) o determinato da informazioni preliminari.\n\n2. **Utilizzo dei parametri degli item**:\n   - I parametri noti degli item (ad esempio, difficoltà \\(\\beta_i\\) e discriminazione \\(a_i\\)) vengono utilizzati per calcolare la probabilità che l'esaminando risponda correttamente a ciascun item in base al livello di abilità iniziale ipotizzato. Questa probabilità è calcolata attraverso la funzione di risposta dell'item (IRF).\n\n3. **Iterazione per aggiustare la stima**:\n   - Il livello di abilità viene aggiornato iterativamente. L'obiettivo di ogni iterazione è migliorare la corrispondenza tra le probabilità previste di risposta corretta (basate sul livello di abilità stimato) e il pattern effettivo di risposte fornite dall'esaminando.\n   - Questo processo continua fino a quando le modifiche alla stima di $\\theta$ diventano trascurabili, indicando che è stato raggiunto un punto di convergenza. Il risultato finale è una stima stabile e affidabile dell'abilità.\n\n4. **Stima personalizzata**:\n   - Il processo viene ripetuto per ciascun esaminando, assicurando che ogni stima di $\\theta$ sia basata esclusivamente sulle sue risposte.\n\n### Metodi alternativi di stima\n\n- **Stima simultanea**:\n   - In alternativa alla stima iterativa individuale, esistono approcci che stimano simultaneamente i livelli di abilità di tutti gli esaminandi. Questi metodi sono particolarmente utili in presenza di un ampio campione, ottimizzando il processo di calcolo.\n\n- **Stima Bayesiana**:\n   - La stima bayesiana combina i dati del test con una distribuzione a priori sull'abilità ($\\theta$) per ottenere una stima posteriore. Questo approccio è particolarmente utile quando il numero di item è limitato o le risposte sono incomplete.\n\n\n### Importanza della Stima dell'Abilità\n\nLa stima dell'abilità in IRT è fondamentale per due motivi principali:\n\n1. **Valutazione personalizzata**:\n   - Permette di misurare l'abilità di ciascun esaminando in maniera individualizzata, considerando le interazioni specifiche tra il rispondente e gli item. Questa personalizzazione rende la stima più accurata rispetto ai punteggi grezzi, che non tengono conto delle caratteristiche degli item.\n\n2. **Analisi mirate**:\n   - Poiché la stima dell'abilità è direttamente legata ai parametri degli item, consente di condurre analisi dettagliate sull'efficacia del test (ad esempio, quali item sono più informativi per specifici livelli di abilità) e sulle caratteristiche dei rispondenti.\n\nIn conclusione, la stima dell'abilità in IRT è un processo iterativo che utilizza i parametri degli item e il pattern di risposte individuali per fornire stime accurate e personalizzate del livello di abilità di ciascun esaminando. Grazie alla sua precisione, questa metodologia rappresenta una componente essenziale dell'IRT, sia per la valutazione degli esaminandi sia per l'ottimizzazione dei test.\n\n## Stima Bayesiana\n\nLa stima bayesiana sta diventando un metodo sempre più popolare per stimare i parametri del modello di Rasch. Come la stima della massima verosimiglianza congiunta, la stima bayesiana stima simultaneamente sia i parametri delle persone che quelli degli item. Tuttavia, mentre la stima della massima verosimiglianza congiunta trova i valori di $\\theta$ e $\\beta$ massimizzando la verosimiglianza congiunta, la stima bayesiana utilizza la regola di Bayes per trovare la densità a posteriori, $f(\\theta,\\beta \\mid u)$. \n\nNel modello di Rasch, la regola di Bayes afferma che:\n\n$$ \nf(\\theta,\\beta \\mid u) = \\frac{\\text{Pr}(u \\mid \\theta,\\beta)f(\\theta,\\beta)}{\\text{Pr}(u)}. \n$$\n\nIl primo termine nel numeratore, $\\text{Pr}(u \\mid \\theta, \\beta)$, è la verosimiglianza congiunta. Il secondo è la distribuzione a priori congiunta per $\\theta$ e $\\beta$. Il denominatore è la probabilità media dei dati osservati rispetto alla distribuzione a priori congiunta.\n\nA differenza della stima della massima verosimiglianza, che si concentra sulla massimizzazione della verosimiglianza, la stima bayesiana integra le informazioni a priori con i dati osservati. La regola di Bayes combina la verosimiglianza dei dati osservati (la probabilità di osservare i dati dati i parametri) con la distribuzione a priori (le nostre credenze sui parametri prima di osservare i dati) per produrre una distribuzione a posteriori (le nostre credenze aggiornate sui parametri dopo aver osservato i dati). La densità a posteriori $f(\\theta,\\beta \\mid u)$ ci fornisce una stima completa dei parametri, considerando sia i dati osservati sia le informazioni a priori.\n\nIn pratica, la stima bayesiana fornisce un approccio flessibile e informativo alla stima dei parametri nel modello di Rasch, consentendo l'integrazione di conoscenze pregresse e osservazioni attuali.\n\n### Implementazione\n\nEsaminiamo un'applicazione della stima Bayesiana usando il linguaggio probabilistico Stan. Il modello di Rasch è implementato nel file `rasch_model.stan` utilizzando le distribuzioni a priori specificate da @debelak2022introduction. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_file <- \"../../code/rasch_model.stan\"\nmod <- cmdstan_model(stan_file)\nmod$print()\n#> data {\n#>   int<lower=1> num_person;\n#>   int<lower=1> num_item;\n#>   array[num_person, num_item] int<lower=0, upper=1> U;\n#> }\n#> parameters {\n#>   vector[num_person] theta;\n#>   vector[num_item] beta;\n#>   real mu_beta;\n#>   real<lower=0> sigma2_theta;\n#>   real<lower=0> sigma2_beta;\n#> }\n#> transformed parameters {\n#>   array[num_person, num_item] real<lower=0, upper=1> prob_solve;\n#>   for (p in 1:num_person) \n#>     for (i in 1:num_item) \n#>       prob_solve[p, i] = inv_logit(theta[p] - beta[i]);\n#> }\n#> model {\n#>   for (p in 1:num_person) \n#>     for (i in 1:num_item) \n#>       U[p, i] ~ bernoulli(prob_solve[p, i]);\n#>   theta ~ normal(0, sqrt(sigma2_theta));\n#>   beta ~ normal(mu_beta, sqrt(sigma2_beta));\n#>   sigma2_theta ~ inv_chi_square(0.5);\n#>   sigma2_beta ~ inv_chi_square(0.5);\n#> }\n```\n:::\n\n\n\n\nNella presente implementazione bayesiana del modello di Rasch, le sezioni \"transformed parameters\" e \"model\" hanno un ruolo centrale nel definire come i dati vengono processati e come il modello viene applicato. Vediamo dettagliatamente ciascuna sezione:\n\n#### Sezione Transformed Parameters\n\nNella sezione `transformed parameters`, viene definita la trasformazione dei parametri di base (i parametri `theta` per le abilità delle persone e `beta` per la difficoltà degli item) in una probabilità di risposta corretta per ogni coppia persona-item. Qui viene usata la funzione logistica inversa per convertire la differenza tra l'abilità della persona e la difficoltà dell'item in una probabilità:\n\n```stan\ntransformed parameters {\n  array[num_person, num_item] real<lower=0, upper=1> prob_solve;\n  for (p in 1:num_person) \n    for (i in 1:num_item) \n      prob_solve[p, i] = inv_logit(theta[p] - beta[i]);\n}\n```\n\nQuesta trasformazione serve a mappare la differenza tra l'abilità della persona (`theta[p]`) e la difficoltà dell'item (`beta[i]`) in un intervallo di probabilità tra 0 e 1. La funzione `inv_logit` è comunemente usata per questo scopo, essendo la funzione logistica inversa.\n\n#### Sezione Model\n\nNella sezione `model`, vengono definite le distribuzioni di probabilità per i dati osservati e i parametri del modello, che sono essenziali per la stima bayesiana. Questa parte del codice descrive come i dati sono generati, supponendo il modello di Rasch:\n\n```stan\nmodel {\n  for (p in 1:num_person) \n    for (i in 1:num_item) \n      U[p, i] ~ bernoulli(prob_solve[p, i]);\n  theta ~ normal(0, sqrt(sigma2_theta));\n  beta ~ normal(mu_beta, sqrt(sigma2_beta));\n  sigma2_theta ~ inv_chi_square(0.5);\n  sigma2_beta ~ inv_chi_square(0.5);\n}\n```\n\n- `U[p, i] ~ bernoulli(prob_solve[p, i])`: ogni risposta `U[p, i]`, che indica se la persona `p` ha risposto correttamente all'item `i`, segue una distribuzione di Bernoulli dove la probabilità di successo è data da `prob_solve[p, i]`. Questa è la vera verosimiglianza del modello, che collega i dati osservati alle probabilità calcolate tramite il modello logistico.\n- `theta ~ normal(0, sqrt(sigma2_theta))` e `beta ~ normal(mu_beta, sqrt(sigma2_beta))`: le distribuzioni a priori per i parametri `theta` e `beta` sono normali. Questo significa che, in assenza di dati, si assume che queste variabili si distribuiscano normalmente con una media di 0 per `theta` e `mu_beta` per `beta`, e una deviazione standard derivata dai parametri di varianza `sigma2_theta` e `sigma2_beta`.\n- `sigma2_theta ~ inv_chi_square(0.5)` e `sigma2_beta ~ inv_chi_square(0.5)`: le varianze `sigma2_theta` e `sigma2_beta` hanno distribuzioni a priori che seguono una distribuzione chi quadrato inversa con parametro di forma 0.5. Questa è una scelta comune per imporre una distribuzione non informativa (vaga) sui parametri di scala.\n\nIn conclusione, la sezione `transformed parameters` calcola le probabilità di risposta corretta basate sui parametri di abilità e difficoltà, mentre la sezione `model` specifica come questi parametri e le risposte osservate interagiscono secondo il modello di Rasch, definendo così la struttura della verosimiglianza e delle priorità nel contesto bayesiano.\n\nCompiliamo il modello usando CmdStan:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod$compile()\n```\n:::\n\n\n\n\nDefiniamo i dati nel formato appropriato per Stan:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(data.fims.Aus.Jpn.scored, package = \"TAM\")\npeople <- 1:400\nresponses <- data.fims.Aus.Jpn.scored[people, 2:15]\nresponses <- as.matrix(sapply(responses, as.integer))\ncolnames(responses) <- gsub(\"M1PTI\", \"I\", colnames(responses))\n\nstan_data <- list(\n    num_person = nrow(responses),\n    num_item = ncol(responses),\n    U = responses\n)\n```\n:::\n\n\n\n\nEseguiamo il campionamento MCMC per ottenere la distribuzione a posteriori dei parametri.\n\n\n\n\n::: {.cell layout-align=\"center\" tags='hide-output'}\n\n```{.r .cell-code}\nfit <- mod$sample(\n    data = stan_data,\n    chains = 4, # Number of MCMC chains\n    parallel_chains = 2, # Number of chains to run in parallel \n    iter_warmup = 2000, # Number of warmup iterations per chain\n    iter_sampling = 2000, # Number of sampling iterations per chain\n    seed = 1234 # Set a seed for reproducibility\n)\n#> Running MCMC with 4 chains, at most 2 in parallel...\n#> \n#> Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup)\n#> Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup)\n#> Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \n#> Chain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \n#> Chain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \n#> Chain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \n#> Chain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \n#> Chain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \n#> Chain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \n#> Chain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \n#> Chain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \n#> Chain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \n#> Chain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \n#> Chain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \n#> Chain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \n#> Chain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \n#> Chain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \n#> Chain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \n#> Chain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \n#> Chain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \n#> Chain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \n#> Chain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \n#> Chain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \n#> Chain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \n#> Chain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \n#> Chain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \n#> Chain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \n#> Chain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \n#> Chain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \n#> Chain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \n#> Chain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \n#> Chain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \n#> Chain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 1 finished in 14.5 seconds.\n#> Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup)\n#> Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 2 finished in 14.7 seconds.\n#> Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \n#> Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \n#> Chain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \n#> Chain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \n#> Chain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \n#> Chain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \n#> Chain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \n#> Chain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \n#> Chain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \n#> Chain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \n#> Chain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \n#> Chain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \n#> Chain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \n#> Chain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \n#> Chain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \n#> Chain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \n#> Chain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \n#> Chain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \n#> Chain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \n#> Chain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \n#> Chain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \n#> Chain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \n#> Chain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \n#> Chain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \n#> Chain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \n#> Chain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \n#> Chain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \n#> Chain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \n#> Chain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \n#> Chain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \n#> Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \n#> Chain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \n#> Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 3 finished in 14.5 seconds.\n#> Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 4 finished in 14.8 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 14.6 seconds.\n#> Total execution time: 29.8 seconds.\n```\n:::\n\n\n\n\nEsaminiamo le tracce per due parametri.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_draws <- fit$draws() # extract the posterior draws\nmcmc_trace(fit_draws, pars = c(\"beta[1]\"))\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_trace(fit_draws, pars = c(\"theta[1]\"))\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nFocalizziamoci sulla stima dei parametri degli item.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameters <- c(\n    \"beta[1]\", \"beta[2]\", \"beta[3]\", \"beta[4]\", \"beta[5]\",\n    \"beta[6]\", \"beta[7]\", \"beta[8]\", \"beta[9]\",\"beta[10]\",\n    \"beta[11]\", \"beta[12]\", \"beta[13]\", \"beta[14]\"\n)\n```\n:::\n\n\n\n\nEsaminiamo la statistica rhat.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrhats <- rhat(fit_draws, pars = parameters)\nmcmc_rhat(rhats)\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo l'effect ratio:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neff_ratio <- neff_ratio(fit, pars = parameters)\neff_ratio \n#>  beta[1]  beta[2]  beta[3]  beta[4]  beta[5]  beta[6]  beta[7]  beta[8] \n#>     1.13     1.19     1.16     1.10     1.36     1.16     1.18     1.08 \n#>  beta[9] beta[10] beta[11] beta[12] beta[13] beta[14] \n#>     1.30     1.21     1.26     1.23     1.39     1.31\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_neff(eff_ratio)\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo l'autocorrelazione.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_acf(fit_draws, pars = parameters)\n```\n\n::: {.cell-output-display}\n![](03_estimation_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nOtteniamo le statistiche riassuntive delle distribuzioni a posteriori dei parametri degli item.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit$summary(\n    variables = parameters,\n    posterior::default_summary_measures(),\n    extra_quantiles = ~ posterior::quantile2(., probs = c(.0275, .975))\n)\n#> # A tibble: 14 × 9\n#>   variable    mean  median    sd   mad     q5    q95  q2.75  q97.5\n#>   <chr>      <dbl>   <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n#> 1 beta[1]  -1.10   -1.10   0.129 0.126 -1.31  -0.892 -1.35  -0.849\n#> 2 beta[2]  -1.24   -1.24   0.130 0.130 -1.46  -1.03  -1.50  -0.997\n#> 3 beta[3]  -2.03   -2.02   0.158 0.156 -2.30  -1.77  -2.34  -1.73 \n#> 4 beta[4]  -0.0478 -0.0489 0.120 0.121 -0.241  0.149 -0.274  0.191\n#> 5 beta[5]   2.51    2.51   0.183 0.185  2.22   2.82   2.18   2.88 \n#> 6 beta[6]  -1.24   -1.24   0.132 0.131 -1.46  -1.03  -1.50  -0.989\n#> # ℹ 8 more rows\n```\n:::\n\n\n\n\nI risultati ottenuti replicano quelli riportati da @debelak2022introduction.\n\n## Grandezza del Campione\n\nLa stima dei parametri degli item basata su un campione osservato di risposte è spesso definita come la *calibrazione degli item*. Generalmente, un campione di calibrazione più ampio consente una stima più accurata dei parametri degli item, sebbene altri fattori influenzino anch'essi l'accuratezza della stima. Ad esempio, la difficoltà di un item può essere stimata con maggiore precisione se l'item non è né troppo facile né troppo difficile per il campione di partecipanti al test. Pertanto, i fattori che influenzano l'accuratezza della stima includono l'allineamento e la forma delle distribuzioni dei parametri degli item e delle persone, il numero di item e la tecnica di stima utilizzata.\n\nDiverse pubblicazioni hanno affrontato la questione della dimensione del campione tipicamente necessaria per lavorare con il modello di Rasch e come questa sia influenzata da questi e altri fattori. Ad esempio, De Ayala (2009) fornisce la linea guida generale che un campione di calibrazione dovrebbe contenere almeno diverse centinaia di rispondenti e cita, tra le altre referenze, un articolo precedente di Wright (1977) che afferma che un campione di calibrazione di 500 sarebbe più che adeguato. De Ayala (2009) suggerisce anche che 250 o più rispondenti sono necessari per adattare un modello di Partial Credit. Poiché il modello di Partial Credit è una generalizzazione del modello di Rasch con più parametri degli item, ciò implica che la dimensione del campione suggerita di 250 dovrebbe essere sufficiente anche per adattare un modello di Rasch. Studi più recenti hanno indagato l'applicazione del modello di Rasch con dimensioni del campione di soli 100 rispondenti (ad esempio, Steinfeld & Robitzsch, 2021; Suárez-Falcón & Glas, 2003). Tali linee guida non devono essere interpretate come regole fisse, ma solo come indicazioni generali in quanto una dimensione del campione adeguata dipende dalle condizioni e dagli obiettivi dell'analisi.\n\nUn metodo più elaborato per determinare la dimensione del campione necessaria è l'analisi della potenza statistica. Qui, l'accuratezza della stima desiderata o il rischio di falsi positivi e falsi negativi devono essere formalizzati prima dell'analisi. La dimensione del campione necessaria viene quindi determinata in base a queste considerazioni. \n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats4    grid      stats     graphics  grDevices utils     datasets \n#> [8] methods   base     \n#> \n#> other attached packages:\n#>  [1] effectsize_1.0.0    rsvg_2.6.1          rstan_2.32.6       \n#>  [4] StanHeaders_2.32.10 posterior_1.6.1     cmdstanr_0.8.1     \n#>  [7] ggmirt_0.1.0        TAM_4.2-21          CDM_8.2-6          \n#> [10] mvtnorm_1.3-3       mirt_1.44.0         lattice_0.22-6     \n#> [13] latex2exp_0.9.6     ggokabeito_0.1.0    see_0.10.0         \n#> [16] MASS_7.3-65         viridis_0.6.5       viridisLite_0.4.2  \n#> [19] ggpubr_0.6.0        ggExtra_0.10.1      gridExtra_2.3      \n#> [22] patchwork_1.3.0     bayesplot_1.11.1    semTools_0.5-6     \n#> [25] semPlot_1.1.6       lavaan_0.6-19       psych_2.4.12       \n#> [28] scales_1.3.0        markdown_1.13       knitr_1.49         \n#> [31] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n#> [34] dplyr_1.1.4         purrr_1.0.4         readr_2.1.5        \n#> [37] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n#> [40] tidyverse_2.0.0     here_1.0.1         \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2        later_1.4.1          R.oo_1.27.0         \n#>   [4] datawizard_1.0.0     XML_3.99-0.18        rpart_4.1.24        \n#>   [7] lifecycle_1.0.4      Rdpack_2.6.2         rstatix_0.7.2       \n#>  [10] rprojroot_2.0.4      processx_3.8.6       globals_0.16.3      \n#>  [13] insight_1.0.2        rockchalk_1.8.157    backports_1.5.0     \n#>  [16] magrittr_2.0.3       openxlsx_4.2.8       Hmisc_5.2-2         \n#>  [19] rmarkdown_2.29       yaml_2.3.10          httpuv_1.6.15       \n#>  [22] qgraph_1.9.8         zip_2.3.2            pkgbuild_1.4.6      \n#>  [25] sessioninfo_1.2.3    pbapply_1.7-2        minqa_1.2.8         \n#>  [28] multcomp_1.4-28      abind_1.4-8          audio_0.1-11        \n#>  [31] quadprog_1.5-8       R.utils_2.13.0       tensorA_0.36.2.1    \n#>  [34] nnet_7.3-20          TH.data_1.1-3        sandwich_3.1-1      \n#>  [37] inline_0.3.21        listenv_0.9.1        testthat_3.2.3      \n#>  [40] RPushbullet_0.3.4    vegan_2.6-10         arm_1.14-4          \n#>  [43] parallelly_1.42.0    permute_0.9-7        codetools_0.2-20    \n#>  [46] tidyselect_1.2.1     farver_2.1.2         lme4_1.1-36         \n#>  [49] matrixStats_1.5.0    base64enc_0.1-3      jsonlite_1.9.0      \n#>  [52] polycor_0.8-1        progressr_0.15.1     Formula_1.2-5       \n#>  [55] survival_3.8-3       emmeans_1.10.7       tools_4.4.2         \n#>  [58] snow_0.4-4           Rcpp_1.0.14          glue_1.8.0          \n#>  [61] mnormt_2.1.1         admisc_0.37          xfun_0.51           \n#>  [64] mgcv_1.9-1           distributional_0.5.0 loo_2.8.0           \n#>  [67] withr_3.0.2          beepr_2.0            fastmap_1.2.0       \n#>  [70] boot_1.3-31          digest_0.6.37        mi_1.1              \n#>  [73] timechange_0.3.0     R6_2.6.1             mime_0.12           \n#>  [76] estimability_1.5.1   colorspace_2.1-1     gtools_3.9.5        \n#>  [79] jpeg_0.1-10          R.methodsS3_1.8.2    utf8_1.2.4          \n#>  [82] generics_0.1.3       data.table_1.17.0    corpcor_1.6.10      \n#>  [85] SimDesign_2.18       htmlwidgets_1.6.4    parameters_0.24.1   \n#>  [88] pkgconfig_2.0.3      sem_3.1-16           gtable_0.3.6        \n#>  [91] brio_1.1.5           htmltools_0.5.8.1    carData_3.0-5       \n#>  [94] png_0.1-8            reformulas_0.4.0     rstudioapi_0.17.1   \n#>  [97] tzdb_0.4.0           reshape2_1.4.4       coda_0.19-4.1       \n#> [100] checkmate_2.3.2      nlme_3.1-167         curl_6.2.1          \n#> [103] nloptr_2.1.1         zoo_1.8-13           parallel_4.4.2      \n#> [106] miniUI_0.1.1.1       foreign_0.8-88       pillar_1.10.1       \n#> [109] vctrs_0.6.5          promises_1.3.2       car_3.1-3           \n#> [112] OpenMx_2.21.13       xtable_1.8-4         Deriv_4.1.6         \n#> [115] cluster_2.1.8        dcurver_0.9.2        GPArotation_2024.3-1\n#> [118] htmlTable_2.4.3      evaluate_1.0.3       pbivnorm_0.6.0      \n#> [121] cli_3.6.4            kutils_1.73          compiler_4.4.2      \n#> [124] rlang_1.1.5          future.apply_1.11.3  ggsignif_0.6.4      \n#> [127] labeling_0.4.3       fdrtool_1.2.18       ps_1.9.0            \n#> [130] plyr_1.8.9           stringi_1.8.4        QuickJSR_1.6.0      \n#> [133] munsell_0.5.1        lisrelToR_0.3        bayestestR_0.15.2   \n#> [136] V8_6.0.1             pacman_0.5.1         Matrix_1.7-2        \n#> [139] hms_1.1.3            glasso_1.11          future_1.34.0       \n#> [142] shiny_1.10.0         rbibutils_2.3        igraph_2.1.4        \n#> [145] broom_1.0.7          RcppParallel_5.1.10\n```\n:::\n",
    "supporting": [
      "03_estimation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
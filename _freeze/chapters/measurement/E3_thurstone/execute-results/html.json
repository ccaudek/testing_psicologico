{
  "hash": "c5ef620745d61052259d79bdf18baa31",
  "result": {
    "engine": "knitr",
    "markdown": "# ✏ Esercizi\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"../../code/_common.R\")\nlibrary(\"rio\")\nlibrary(\"psych\")\n```\n:::\n\n\n\n\n\n## Introduzione allo Scaling di Thurstone\n\nLo scaling di Thurstone, sviluppato da Louis Leon Thurstone nel 1931, è un approccio statistico che mira a modellare dati di ranking soggettivo. I dati di ranking soggettivo si producono quando le persone ordinano un insieme di elementi o stimoli secondo un criterio particolare. Questo tipo di dati è particolarmente utile quando è più semplice per i partecipanti esprimere una preferenza relativa piuttosto che stime quantitative precise.\n\n### Il Modello Thurstoniano \n\nIl modello Thurstoniano rappresenta un approccio statistico per analizzare e interpretare le preferenze o i ranking individuali rispetto a vari oggetti o stimoli. Questo modello si basa sull'idea che esista una scala latente, ovvero una dimensione non direttamente osservabile, attorno alla quale si distribuiscono i ranking individuali. In altre parole, ogni individuo assegna un punteggio ad ogni oggetto basandosi su criteri personali, ma queste valutazioni individuali sono influenzate da una percezione collettiva o aggregata che può essere descritta su una scala continua latente.\n\nIl principale obiettivo del modello Thurstoniano è di trasformare queste medie di ranking latenti aggregati, che esistono su una scala continua, in un ranking discreto che possiamo interpretare più facilmente. Per farlo, il modello si avvale di alcune ipotesi chiave:\n\n1. **Distribuzione Gaussiana**: Si assume che il ranking latente per ciascun oggetto possa essere descritto da una distribuzione gaussiana. \n\n2. **Media Differenziata, Varianza Costante**: Il modello presuppone che le distribuzioni gaussiane dei ranking per ciascun oggetto differiscano tra loro solo per la media, mantenendo costante la varianza (scaling di Thurstone caso V). Questo implica che, sebbene gli oggetti possano avere livelli di preferenza medi diversi (alcuni potrebbero essere generalmente preferiti ad altri), la variabilità delle valutazioni (quanto le opinioni dei rispondenti differiscono tra loro) è la stessa per tutti gli oggetti.\n\nPer posizionare gli oggetti sulla scala di Thurstone, si procede nel seguente modo:\n\n- Si calcola la proporzione di rispondenti che preferiscono un oggetto rispetto a ciascuno degli altri.\n- Si determinano i corrispondenti percentile (z-scores) della distribuzione cumulativa normale, che ci dicono quante deviazioni standard un valore è distante dalla media.\n- Si calcola la media di questi z-scores per ciascun oggetto.\n\nDi seguito propongo un esempio più lineare e coerente dello scaling di Thurstone per tre oggetti (A, B e C), assieme a una spiegazione puntuale dei vari passaggi. \n\n## Esempio\n\nImmaginiamo di avere tre oggetti – A, B e C – per cui abbiamo raccolto preferenze pairwise (cioè a coppie). Ipotizziamo di aver rilevato le seguenti percentuali di preferenza:\n\n- **A** è preferito a **B** dal 70% dei rispondenti.\n- **A** è preferito a **C** dall’80% dei rispondenti.\n- **B** è preferito a **C** dal 60% dei rispondenti.\n\nQuindi, se chiediamo ad un gruppo di persone di scegliere tra A e B, il 70% sceglie A, mentre se chiediamo di scegliere tra A e C, l’80% sceglie A; tra B e C, il 60% sceglie B.\n\n### Creazione del data frame delle preferenze\n\nIn R, possiamo creare un piccolo data frame (chiamato `preferences`) che contiene queste informazioni. Ciascuna riga riporta:\n\n1. La prima colonna (`obj1`): l’oggetto preferito dalla proporzione `p`.\n2. La seconda colonna (`obj2`): l’altro oggetto del confronto.\n3. La terza colonna (`p`): la proporzione di rispondenti che preferisce `obj1` rispetto a `obj2`.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definiamo le preferenze pairwise\npreferences <- data.frame(\n  obj1 = c(\"A\", \"A\", \"B\"),\n  obj2 = c(\"B\", \"C\", \"C\"),\n  p    = c(0.70, 0.80, 0.60)\n)\npreferences\n#>   obj1 obj2   p\n#> 1    A    B 0.7\n#> 2    A    C 0.8\n#> 3    B    C 0.6\n```\n:::\n\n\n\n\n\n- Prima riga: “A vs. B, p=0.70” significa che il 70% preferisce A rispetto a B.\n- Seconda riga: “A vs. C, p=0.80” significa che l’80% preferisce A rispetto a C.\n- Terza riga: “B vs. C, p=0.60” significa che il 60% preferisce B rispetto a C.\n\n### Conversione delle percentuali in z-score (qnorm)\n\nIl modello di Thurstone (caso V) prevede che queste proporzioni siano interpretabili come aree cumulative di una distribuzione normale standard. Se ad esempio il 70% preferisce A a B, questo 0.70 è la probabilità cumulata (fino a uno z-score positivo). Per convertire una proporzione in uno z-score, utilizziamo la funzione `qnorm()`. \n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Aggiungiamo al data frame la colonna z, che contiene la trasformazione delle \n# proporzioni in z-score\npreferences <- preferences %>%\n  mutate(z = qnorm(p))\n\npreferences\n#>   obj1 obj2   p     z\n#> 1    A    B 0.7 0.524\n#> 2    A    C 0.8 0.842\n#> 3    B    C 0.6 0.253\n```\n:::\n\n\n\n\n\n### Creazione di una matrice delle preferenze (z-score matrix)\n\nOra vogliamo creare una **matrice** (che chiameremo `z_matrix`) contenente gli z-score di tutte le coppie (A-B, A-C, B-C, e anche B-A, C-A, C-B, che saranno i corrispettivi negativi). In altre parole:\n\n- Nelle celle della matrice in cui la riga è `obj1` e la colonna è `obj2`, mettiamo lo z-score positivo (es. 0.52 se il 70% preferisce A a B).\n- Nella cella opposta (dove la riga è `obj2` e la colonna è `obj1`), mettiamo lo z-score negativo (es. -0.52, perché se 70% preferisce A a B, allora il 30% preferisce B a A).\n\nCosì otteniamo un quadro simmetrico del grado di preferenza fra tutti gli oggetti.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Ricaviamo l’elenco degli oggetti presenti\nobjects <- unique(c(preferences$obj1, preferences$obj2))\n\n# Creiamo una matrice quadrata vuota in cui inserire gli z-score\nz_matrix <- matrix(0, \n                   nrow = length(objects), \n                   ncol = length(objects),\n                   dimnames = list(objects, objects))\n\n# Compiliamo la matrice: \n# per ogni riga del data frame `preferences`,\n# inseriamo lo z-score positivo nella posizione [obj1, obj2] e\n# quello negativo nella posizione [obj2, obj1].\nfor (i in 1:nrow(preferences)) {\n  riga    <- preferences$obj1[i]\n  colonna <- preferences$obj2[i]\n  valore  <- preferences$z[i]\n  \n  z_matrix[riga, colonna] <- valore\n  z_matrix[colonna, riga] <- -valore\n}\n\nz_matrix\n#>        A      B     C\n#> A  0.000  0.524 0.842\n#> B -0.524  0.000 0.253\n#> C -0.842 -0.253 0.000\n```\n:::\n\n\n\n\n\n- La diagonale è 0 (ovviamente un oggetto confrontato con sé stesso non dà informazioni).\n- L’elemento `[A, B]` è $+0.524$ (z-score corrispondente a 70%), \n  mentre l’elemento `[B, A]` è $-0.524$.\n\n### Calcolo dei punteggi latenti medi \n\nSecondo il modello di Thurstone, uno dei modi più semplici per posizionare ogni oggetto sulla scala latente è calcolare, per ogni riga, la **media** degli z-score rispetto agli altri oggetti. L’idea è che questa media costituisca una stima della “posizione” dell’oggetto sulla scala latente di preferenza.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcoliamo la media degli z-score per ogni riga (oggetto)\nlatent_scores <- rowMeans(z_matrix)\nlatent_scores\n#>       A       B       C \n#>  0.4553 -0.0904 -0.3650\n```\n:::\n\n\n\n\n\nPer esempio: \n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nc(0.000,  0.524, 0.842) |> mean()\n#> [1] 0.455\n```\n:::\n\n\n\n\n\nSe `latent_scores[\"A\"]` è più alto degli altri, significa che A si colloca in media “più a destra” (o più in alto) sulla scala latente rispetto a B e C (cioè, è mediamente più preferito).\n\n### Creazione del ranking finale\n\nInfine, ordiniamo gli oggetti in base a questi punteggi latenti. Il risultato è un data frame con:\n\n1. Il nome dell’oggetto.\n2. Il suo punteggio latente medio.\n3. L’ordine di ranking (da più alto a più basso).\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nranking <- data.frame(\n  Oggetto          = names(latent_scores),\n  Punteggio_Latente = latent_scores\n) %>%\n  arrange(desc(Punteggio_Latente)) %>%\n  mutate(Ranking = row_number())\n\nranking\n#>   Oggetto Punteggio_Latente Ranking\n#> A       A            0.4553       1\n#> B       B           -0.0904       2\n#> C       C           -0.3650       3\n```\n:::\n\n\n\n\n\n### Interpretazione\n\n- **Oggetti con punteggi latenti più alti**: sono quelli preferiti più spesso dagli intervistati.  \n- **Oggetti con punteggi latenti più bassi**: sono quelli meno preferiti.\n\nSe ad esempio `A` ha un punteggio latente di 0.5, `B` di 0.1 e `C` di -0.6, allora l’ordine di preferenza sarà A > B > C.\n\nIn conclusione, questa è la logica di base dello **Scaling di Thurstone (caso V)**, che assume varianza costante degli errori di giudizio e distribuzioni normali per i punteggi latenti. Nella pratica, se si hanno molti oggetti (non solo 3), si procede alla raccolta di tutte le percentuali pairwise e poi si utilizza un procedimento analogo (eventualmente affinandolo con tecniche di stima più complesse).\n\n## Scaling Fechneriano\n\nUn altro esempio di scaling psicologico riguarda lo scaling fechneriano. Faccio qui riferimento ad uno studio condotto un po' di tempo fa nell'ambito delle Vision Sciences. \n\nNello studio di @domini2009intrinsic, abbiamo utilizzato il modello *Intrinsic Constraints* per correlare la **profondità visiva percepita** di un oggetto tridimensionale con i principi teorici dello **scaling sensoriale Fechneriano**. Quest’ultimo, basato sulle teorie psicofisiche di Fechner, prevede la costruzione di una scala psicofisica per attributi sensoriali mediante l’**integrazione cumulativa di incrementi psicometrici**, in particolare delle *Just Noticeable Differences* (JNDs). L’obiettivo della ricerca era progettare stimoli visivi caratterizzati da diversi indizi di profondità (stereopsi, parallasse di movimento, ecc.) in modo da indurre una **percezione soggettiva equivalente della profondità 3D**. Secondo questa logica, oggetti definiti da cue visivi distinti dovrebbero risultare percettivamente equiparabili in termini di profondità qualora fossero associati a un **numero identico di JNDs**. In altre parole, l’uniformità percettiva emerge quando gli stimoli, pur differendo negli indizi di profondità, raggiungono la stessa soglia di discriminabilità psicofisica.\n\n\n## Studio sulle preferenze riguardanti le caratteristiche dell'occupazione ideale\n\nI dati utilizzati in questo studio sono stati raccolti nell'ambito di una ricerca sulla motivazione lavorativa condotta da Ilke Inceoglu. Nel corso di questa indagine, 1079 partecipanti sono stati invitati a classificare nove aspetti lavorativi in base all'importanza che desideravano che fossero presenti nella loro occupazione ideale:\n\n1. Ambiente di Supporto (Supporto)\n2. Lavoro Stimolante (Sfida)\n3. Progressione di Carriera (Carriera)\n4. Lavoro Etico (Etica)\n5. Controllo sul Lavoro, Impatto Personale (Autonomia)\n6. Sviluppo (Sviluppo)\n7. Interazione Sociale (Interazione)\n8. Ambiente Competitivo (Competizione)\n9. Ambiente Piacevole e Sicuro (Sicurezza)\n\nL'obiettivo è identificare la struttura latente delle preferenze attraverso il modello di scaling di Thurstone (Caso V), tecnica psicometrica classica per l'analisi delle preferenze comparative.\n\nUn punteggio di 1 attribuito a qualsiasi aspetto lavorativo indica che tale aspetto era il più importante per quel partecipante, mentre un punteggio di 9 indica che era il meno importante.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nJobFeatures <- rio::import(\"../../data/JobFeatures.txt\")\nglimpse(JobFeatures)\n#> Rows: 1,079\n#> Columns: 9\n#> $ Support     <int> 8, 7, 5, 7, 1, 6, 5, 1, 1, 7, 6, 8, 5, 9, 8, 1, 6, 7, …\n#> $ Challenge   <int> 3, 5, 8, 6, 4, 1, 4, 9, 3, 4, 2, 1, 4, 8, 6, 7, 4, 4, …\n#> $ Career      <int> 4, 1, 1, 8, 8, 3, 7, 2, 7, 6, 3, 4, 6, 1, 3, 5, 8, 3, …\n#> $ Ethics      <int> 5, 6, 9, 9, 3, 7, 2, 8, 4, 1, 9, 3, 7, 5, 9, 6, 7, 5, …\n#> $ Autonomy    <int> 2, 2, 6, 3, 9, 8, 3, 7, 9, 8, 4, 6, 3, 7, 5, 2, 3, 8, …\n#> $ Development <int> 6, 8, 2, 4, 2, 5, 6, 5, 2, 5, 1, 2, 2, 6, 1, 3, 1, 2, …\n#> $ Interaction <int> 1, 3, 3, 2, 6, 2, 1, 4, 6, 9, 5, 5, 1, 4, 2, 8, 2, 6, …\n#> $ Competition <int> 7, 9, 4, 5, 7, 4, 9, 6, 8, 3, 7, 7, 9, 2, 7, 9, 9, 1, …\n#> $ Safety      <int> 9, 4, 7, 1, 5, 9, 8, 3, 5, 2, 8, 9, 8, 3, 4, 4, 5, 9, …\n```\n:::\n\n\n\n\n\nConsideriamo i dati del primo rispondente:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nJobFeatures[1, ]\n#>   Support Challenge Career Ethics Autonomy Development Interaction\n#> 1       8         3      4      5        2           6           1\n#>   Competition Safety\n#> 1           7      9\n```\n:::\n\n\n\n\n\nQuesto rispondente ha risposto assegnando la caratteristica più importante dell'impego a \"Interaction\", seguita da \"Autonomy\". L'ultima preferenza è \"Safety\".\n\nEseguiamo lo scaling di Thurstone usando la funzione `thurstone` del pacchetto psych:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscaling <- psych::thurstone(JobFeatures, ranks = TRUE)\n```\n:::\n\n\n\n\n\nGli attributi dell'oggetto `scaling` prodotto da `thurstone()` possono essere elencati nel modo seguente.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nattributes(scaling)\n#> $names\n#> [1] \"scale\"    \"GF\"       \"choice\"   \"residual\" \"Call\"    \n#> \n#> $class\n#> [1] \"psych\"     \"thurstone\"\n```\n:::\n\n\n\n\n\nI risultati dello scaling si ottengono nel modo seguente. Sono elencati nell'ordine fornito sopra, ovvero Support,\tChallenge,\tCareer,\tEthics,\tAutonomy,\tDevelopment,\tInteraction,\tCompetition\te Safety.\n\nUna media alta indica che i partecipanti attribuiscono un alto valore a questo aspetto lavorativo rispetto agli altri. Tuttavia, poiché le preferenze sono sempre relative, è impossibile identificare in maniera univoca tutte le medie. Pertanto, una delle medie deve essere fissata a un valore arbitrario. È consuetudine fissare la media dell'aspetto meno preferito a 0. Quindi, tutte le altre medie sono positive.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscaling$scale |> print()\n#> [1] 0.97 0.93 0.91 0.92 0.60 1.04 0.63 0.00 0.23\n```\n:::\n\n\n\n\n\nLa media più bassa (0.0) corrisponde all'8° aspetto, Competizione, mentre la media più alta (1.04) corrisponde al 6° aspetto, Sviluppo. Ciò significa che l'ambiente competitivo era il meno desiderato, mentre le opportunità di sviluppo personale erano le più desiderate dalle persone nel loro lavoro ideale. Gli altri aspetti sono stati valutati come aventi un'importanza relativa intermedia a queste due, con Sicurezza che ha una media bassa (0.23) - appena superiore a 0 per la Competizione, mentre Supporto, Sfida, Carriera ed Etica hanno medie simili (intorno a 0.9). Autonomia e Interazione hanno medie moderate simili intorno a 0.6.\n\nL'istruzione seguente produce una matrice 9x9 contenente le proporzioni dei partecipanti nel campione che hanno preferito l'aspetto nella colonna rispetto all'aspetto nella riga. Nella matrice risultante, le righe e le colonne seguono l'ordine delle variabili nel file originale.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscaling$choice |> \n  round(2)\n#>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n#>  [1,] 0.50 0.47 0.47 0.47 0.36 0.51 0.36 0.20 0.23\n#>  [2,] 0.53 0.50 0.47 0.49 0.38 0.53 0.36 0.17 0.28\n#>  [3,] 0.53 0.53 0.50 0.50 0.38 0.52 0.39 0.19 0.26\n#>  [4,] 0.53 0.51 0.50 0.50 0.36 0.52 0.38 0.19 0.26\n#>  [5,] 0.64 0.62 0.62 0.64 0.50 0.67 0.51 0.29 0.34\n#>  [6,] 0.49 0.47 0.48 0.48 0.33 0.50 0.29 0.15 0.20\n#>  [7,] 0.64 0.64 0.61 0.62 0.49 0.71 0.50 0.22 0.30\n#>  [8,] 0.80 0.83 0.81 0.81 0.71 0.85 0.78 0.50 0.61\n#>  [9,] 0.77 0.72 0.74 0.74 0.66 0.80 0.70 0.39 0.50\n```\n:::\n\n\n\n\n\nIl valore maggiore è\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmax(scaling$choice)\n#> [1] 0.853\n```\n:::\n\n\n\n\n\nQuesto valore, 0.8526, rappresenta la proporzione di partecipanti che hanno preferito l'8° aspetto, Competizione, al 6° aspetto, Sviluppo, ed è il valore più grande nella matrice precedente: questa coppia di caratteristiche ha la preferenza più decisa per un aspetto rispetto all'altro.\n\nLa preferenza più decisa in termini di proporzioni di persone che scelgono un aspetto rispetto all'altro deve avere la maggiore distanza/differenza sulla scala delle preferenze soggettive (il 6° aspetto, Sviluppo, deve avere una preferenza percepita media molto più alta dell'8° aspetto, Competizione). Questo risultato è effettivamente in linea con i risultati per le medie di utilità, dove la media dello Sviluppo è la più alta con un valore di 1.04 e la Competizione è la più bassa con un valore di 0.\n\nConsideriamo i residui del modello:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscaling$residual |> \n  round(2)\n#>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]\n#>  [1,]  0.00  0.01  0.00  0.01 -0.01  0.02  0.01 -0.04  0.01\n#>  [2,] -0.01  0.00  0.02  0.00 -0.01  0.01  0.02  0.01 -0.04\n#>  [3,]  0.00 -0.02  0.00  0.01  0.00  0.03  0.00  0.00 -0.01\n#>  [4,] -0.01  0.00 -0.01  0.00  0.01  0.03  0.01 -0.01 -0.01\n#>  [5,]  0.01  0.01  0.00 -0.01  0.00 -0.01  0.01 -0.01  0.02\n#>  [6,] -0.02 -0.01 -0.03 -0.03  0.01  0.00  0.05  0.00  0.02\n#>  [7,] -0.01 -0.02  0.00 -0.01 -0.01 -0.05  0.00  0.04  0.04\n#>  [8,]  0.04 -0.01  0.00  0.01  0.01  0.00 -0.04  0.00 -0.02\n#>  [9,] -0.01  0.04  0.01  0.01 -0.02 -0.02 -0.04  0.02  0.00\n```\n:::\n\n\n\n\n\nL'istruzione precedente produce una matrice 9x9 contenente le differenze tra le proporzioni osservate (la matrice delle scelte) e le proporzioni attese (proporzioni che preferiscono l'aspetto nella riga rispetto all'aspetto nella colonna, che sarebbe atteso in base alle distribuzioni normali standard delle preferenze soggettive intorno alle medie scalate come sopra). Gli scarti tra i valori attesi e quelli osservati sono il modo più diretto di misurare se un modello (in questo caso, il modello proposto da Thurstone) \"si adatta\" ai dati osservati. Gli scarti piccoli (vicini allo zero) indicano che ci sono piccole discrepanze tra le scelte osservate e le scelte previste dal modello; il che significa che il modello che abbiamo adottato è piuttosto buono. \n\nInfine, esaminiamo un indice di bontà di adattamento:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscaling$GF\n#> [1] 0.999\n```\n:::\n\n\n\n\n\nIl valore GF (Goodness of Fit) viene calcolato come 1 meno la somma dei residui al quadrato divisi per i valori osservati al quadrato. Quando i residui sono quasi zero, i loro rapporti al quadrato rispetto alle proporzioni osservate dovrebbero anch'essi avvicinarsi a zero. Di conseguenza, l'indice di bontà di adattamento di un modello ben adattato dovrebbe essere vicino a 1.\n\nNella nostra analisi, tutti i residui sono notevolmente piccoli, indicando una stretta corrispondenza tra le scelte osservate (proporzioni di preferenze per una caratteristica rispetto a un'altra). Questo allineamento preciso si riflette nell'indice GF, che è quasi 1, suggerendo che il modello di Thurstone cattura adeguatamente le proprietà dei dati relativi alle caratteristiche dell'occupazione ideale.\n\n## Considerazioni conclusive\n\nQuesta metodologia, introdotta da Louis Leon Thurstone negli anni '20, rappresenta una delle forme più semplici e intuitive di scaling, dove per \"scaling\" si intende il processo di costruzione di un ordinamento di valori lungo un continuum psicologico. Lo scaling thurstoniano si basa sulla premessa che sia possibile ordinare stimoli o concetti secondo il grado in cui incarnano una certa proprietà psicologica, creando così una scala di misura che riflette le percezioni, le attitudini o i giudizi degli individui.\n\nUno degli aspetti centrali dello scaling di Thurstone, in particolare il caso V della sua legge del giudizio comparativo, è l'assunzione che le distribuzioni di ranking degli stimoli abbiano varianze uguali. Questa ipotesi, pur facilitando la modellizzazione matematica e l'interpretazione dei dati, è stata oggetto di critiche poiché difficilmente riscontrabile nella pratica. Le varianze possono differire significativamente tra gli stimoli a seconda della coerenza dei giudizi degli individui e della natura degli stimoli stessi. Questa limitazione ha stimolato lo sviluppo e l'adozione di metodi alternativi più flessibili per affrontare la complessità dello scaling psicologico.\n\nUn'ulteriore criticità metodologica, spesso poco discussa, riguarda la falsificazione della coerenza interna del modello. Ad esempio, nello scaling di Mokken si assume la monotonicità, ovvero che la probabilità di una risposta positiva a un item aumenti monotonamente con l'aumentare del livello del tratto psicologico misurato. Tale assunzione può essere esplicitamente verificata sui dati empirici, e quando viene violata indica un problema di validità interna della scala. Lo scaling di Thurstone, tuttavia, non prevede procedure sistematiche o strumenti consolidati per testare esplicitamente e falsificare la validità interna del modello. In altre parole, se gli individui forniscono risposte non coerenti con l'assunzione di uguale varianza o di un unico continuum psicologico comune, il modello thurstoniano stesso non offre criteri chiari per identificare e gestire tali violazioni. Questa assenza di procedure di falsificazione interna rappresenta uno dei limiti più significativi del modello di Thurstone.\n\nNel panorama contemporaneo, l'approccio più diffuso e metodologicamente avanzato per lo scaling psicologico deriva dalla Teoria della Risposta all'Item (IRT). L'IRT supera alcune delle limitazioni intrinseche allo scaling thurstoniano offrendo un quadro teorico e metodologico che considera la probabilità di una certa risposta a un item in funzione delle caratteristiche dell'item stesso e del livello dell'attributo psicologico del rispondente. Questo approccio permette di gestire in modo più efficace la varianza tra gli stimoli, di testare esplicitamente assunzioni chiave (come la monotonicità e l'indipendenza locale) e di fornire stime più accurate delle proprietà psicometriche degli item e delle caratteristiche degli individui.\n\nIn conclusione, mentre lo scaling thurstoniano ha rappresentato un passo fondamentale nello sviluppo degli strumenti di misurazione in psicologia, l'evoluzione metodologica e teorica ha portato a preferire approcci basati sull'IRT. Questo non diminuisce il valore storico e didattico dello scaling di Thurstone, che continua a essere un esempio introduttivo prezioso per comprendere i concetti fondamentali dello scaling psicologico. Tuttavia, è nell'ambito della IRT che attualmente si trovano le soluzioni più robuste e sofisticate per affrontare le sfide della misurazione psicologica, guidando la ricerca e l'applicazione pratica nel campo della psicometria contemporanea.\n\n## Sesssion Info\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] rio_1.2.3         ggokabeito_0.1.0  see_0.10.0        MASS_7.3-65      \n#>  [5] viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1   \n#>  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6   \n#> [13] semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12      scales_1.3.0     \n#> [17] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#> [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#> [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#> [29] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.0      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [22] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-2        R6_2.6.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-2         timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] carData_3.0-5       R.utils_2.13.0      ggsignif_0.6.4     \n#>  [46] corpcor_1.6.10      gtools_3.9.5        tools_4.4.2        \n#>  [49] pbivnorm_0.6.0      foreign_0.8-88      zip_2.3.2          \n#>  [52] httpuv_1.6.15       nnet_7.3-20         R.oo_1.27.0        \n#>  [55] glue_1.8.0          quadprog_1.5-8      nlme_3.1-167       \n#>  [58] promises_1.3.2      lisrelToR_0.3       grid_4.4.2         \n#>  [61] checkmate_2.3.2     cluster_2.1.8       reshape2_1.4.4     \n#>  [64] generics_0.1.3      gtable_0.3.6        tzdb_0.4.0         \n#>  [67] R.methodsS3_1.8.2   data.table_1.17.0   hms_1.1.3          \n#>  [70] car_3.1-3           sem_3.1-16          pillar_1.10.1      \n#>  [73] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [76] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [79] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [82] reformulas_0.4.0    stats4_4.4.2        xfun_0.51          \n#>  [85] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [88] pacman_0.5.1        boot_1.3-31         evaluate_1.0.3     \n#>  [91] codetools_0.2-20    mi_1.1              cli_3.6.4          \n#>  [94] RcppParallel_5.1.10 rpart_4.1.24        xtable_1.8-4       \n#>  [97] Rdpack_2.6.2        munsell_0.5.1       Rcpp_1.0.14        \n#> [100] coda_0.19-4.1       png_0.1-8           XML_3.99-0.18      \n#> [103] parallel_4.4.2      jpeg_0.1-10         lme4_1.1-36        \n#> [106] mvtnorm_1.3-3       openxlsx_4.2.8      rlang_1.1.5        \n#> [109] multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
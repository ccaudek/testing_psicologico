{
  "hash": "01267b5177da0bb672e9c6a95a886911",
  "result": {
    "engine": "knitr",
    "markdown": "# ✏️ Esercizi\n\n## Ottimizzazione dello scoring dei dati di questionari ordinali\n\nNell'Esercizio precedente, abbiamo calcolato i punteggi del **Strength and Difficulties Questionnaire (SDQ)** utilizzando il cosiddetto approccio della **\"scalatura Likert\"**. In questo metodo, alle categorie di risposta \"Non vero\", \"Parzialmente vero\" e \"Assolutamente vero\" sono stati assegnati interi consecutivi, rispettivamente 0-1-2. Sebbene questo assegnamento rifletta apparentemente un grado crescente di accordo nelle opzioni di risposta, la scelta degli interi è stata arbitraria: non vi era un motivo particolare per assegnare 0-1-2 anziché, ad esempio, 1-2-3. Questo tipo di assegnazione arbitraria dei punteggi agli item è comunemente chiamato **\"misurazione per decreto\"** (*measurement by fiat*). \n\nIn questo secondo esercizio, cercheremo di individuare punteggi \"ottimali\" per le risposte ordinali al SDQ. Per \"ottimali\" intendiamo che i punteggi assegnati non siano semplicemente arbitrari, ma rappresentino la \"migliore\" scelta possibile in base a un determinato criterio statistico.\n\nEsistono diversi modi per \"ottimizzare\" i punteggi degli item. In questo caso, ci concentreremo sulla massimizzazione del rapporto tra la varianza del punteggio totale e la somma delle varianze dei punteggi degli item. In psicometria, soddisfare questo criterio significa massimizzare la somma delle correlazioni tra gli item e, di conseguenza, migliorare la **consistenza interna** del test, misurata, ad esempio, dall'**alfa di Cronbach**.\n\nQuesto approccio consente di definire punteggi più informativi, che riflettono meglio la coerenza tra le risposte degli item e il punteggio totale del test, migliorando la qualità psicometrica della scala.\n\nPer fare un esempio, useremo di nuovo gli item della scala  **Sintomi Emotivi**. Utilizzeremo il pacchetto **`aspect`**, che semplifica l'ottimizzazione della scalatura grazie a una gamma di opzioni utili e a funzioni grafiche integrate. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"../../code/_common.R\")\nlibrary(\"aspect\")\n```\n:::\n\n\n\n\nImportiamo i dati del *Strengths and Difficulties Questionnaire* (SDQ).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nload(\"../../data/data_sdq/SDQ.RData\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(SDQ)\n#> Rows: 228\n#> Columns: 51\n#> $ Gender   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#> $ consid   <dbl> 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, …\n#> $ restles  <dbl> 2, 0, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, …\n#> $ somatic  <dbl> 2, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, …\n#> $ shares   <dbl> 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, …\n#> $ tantrum  <dbl> 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, …\n#> $ loner    <dbl> 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, …\n#> $ obeys    <dbl> 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, …\n#> $ worries  <dbl> 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, …\n#> $ caring   <dbl> 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, …\n#> $ fidgety  <dbl> 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, …\n#> $ friend   <dbl> 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, …\n#> $ fights   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ unhappy  <dbl> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, …\n#> $ popular  <dbl> 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, …\n#> $ distrac  <dbl> 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, …\n#> $ clingy   <dbl> 1, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 0, 2, …\n#> $ kind     <dbl> 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, …\n#> $ lies     <dbl> 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, …\n#> $ bullied  <dbl> 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, …\n#> $ helpout  <dbl> 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, …\n#> $ reflect  <dbl> 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, …\n#> $ steals   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, …\n#> $ oldbest  <dbl> 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, …\n#> $ afraid   <dbl> 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, …\n#> $ attends  <dbl> 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, …\n#> $ consid2  <dbl> 1, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 1, NA, 2, 2, NA, 1, 2,…\n#> $ restles2 <dbl> 0, 1, 2, 1, NA, 0, 1, 1, 0, 0, NA, 2, NA, 0, 1, NA, 1, 1,…\n#> $ somatic2 <dbl> 0, 1, 1, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 1, NA, 0, 1,…\n#> $ shares2  <dbl> 1, 2, 2, 1, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ tantrum2 <dbl> 0, 1, 2, 0, NA, 0, 2, 0, 0, 0, NA, 2, NA, 0, 1, NA, 1, 0,…\n#> $ loner2   <dbl> 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 1, 0, NA, 0, 0,…\n#> $ obeys2   <dbl> 2, 1, 2, 1, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 1, NA, 1, 2,…\n#> $ worries2 <dbl> 0, 0, 1, 0, NA, NA, 1, 0, 0, 0, NA, 1, NA, 1, 2, NA, 0, 0…\n#> $ caring2  <dbl> 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ fidgety2 <dbl> 0, 1, 0, 0, NA, 0, 1, 0, 0, 0, NA, 2, NA, 0, 0, NA, 1, 0,…\n#> $ friend2  <dbl> 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 1, 2, NA, 2, 2,…\n#> $ fights2  <dbl> 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0,…\n#> $ unhappy2 <dbl> 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 0, 0, NA, 0, 0,…\n#> $ popular2 <dbl> 2, 1, 1, 2, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ distrac2 <dbl> 0, 0, 0, 2, NA, 0, 2, 1, 0, 0, NA, 1, NA, 0, 1, NA, 1, 0,…\n#> $ clingy2  <dbl> 1, 1, 1, 0, NA, 1, 1, 1, 0, 0, NA, 1, NA, 0, 0, NA, 2, 0,…\n#> $ kind2    <dbl> 2, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ lies2    <dbl> 1, 0, 0, 0, NA, 0, 1, 0, 1, 0, NA, 1, NA, 0, 0, NA, 1, 0,…\n#> $ bullied2 <dbl> 0, 0, 0, 0, NA, 0, 2, 0, 0, 0, NA, 0, NA, 0, 0, NA, 0, 0,…\n#> $ helpout2 <dbl> 1, 1, 1, 2, NA, 2, 2, 1, 2, 1, NA, 2, NA, 2, 1, NA, 0, 2,…\n#> $ reflect2 <dbl> 1, 1, 2, 1, NA, 2, 1, 2, 1, 2, NA, 1, NA, 2, 1, NA, 1, 2,…\n#> $ steals2  <dbl> 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0,…\n#> $ oldbest2 <dbl> 0, 0, 1, 0, NA, 1, 0, 1, 1, 0, NA, 1, NA, 0, 0, NA, 0, 0,…\n#> $ afraid2  <dbl> 0, 1, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0,…\n#> $ attends2 <dbl> 1, 1, 2, 0, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 2, NA, 1, 1,…\n```\n:::\n\n\n\n\nPer analizzare solo gli item che misurano i Sintomi Emotivi, è conveniente creare un nuovo data frame.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nitems_emotion <- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nsdq_emo <- SDQ[, items_emotion]\nsdq_emo |>\n    head()\n#> # A tibble: 6 × 5\n#>   somatic worries unhappy clingy afraid\n#>     <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n#> 1       2       1       0      1      0\n#> 2       2       0       0      1      0\n#> 3       0       0       0      0      1\n#> 4       0       0       0      1      1\n#> 5       2       1       0      1      0\n#> 6       1       0       0      1      0\n```\n:::\n\n\n\n\nAffrontiamo il problema dei dati mancanti come discusso in precedenza.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdq_emo <- sdq_emo %>%\n    mutate_at(\n      vars(somatic:afraid), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)\n      ) |> \n  round()\n```\n:::\n\n\n\n\nEsaminiamo le modalità di ciascun item:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemotional_symptoms <- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nresult <- lapply(emotional_symptoms, function(x) sort(unique(sdq_emo[[x]])))\nresult |> \n  print()\n#> [[1]]\n#> [1] 0 1 2\n#> \n#> [[2]]\n#> [1] 0 1 2\n#> \n#> [[3]]\n#> [1] 0 1 2\n#> \n#> [[4]]\n#> [1] 0 1 2\n#> \n#> [[5]]\n#> [1] 0 1 2\n```\n:::\n\n\n\n\nTrasformiamo il data frame in una matrice.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- sdq_emo |> \n  as.matrix()\n```\n:::\n\n\n\n\nImplementiamo lo scaling ottimale con la funzione `corAspect()`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nopt <- corAspect(M, aspect = \"aspectSum\", level = \"ordinal\")\n```\n:::\n\n\n\n\nParametri principali della funzione:\n\n1. **`data`**  \n   Questo argomento rappresenta il data frame che contiene i dati da analizzare. Nel nostro caso, si tratta degli item relativi alla scala che stiamo studiando (ad esempio, quelli che misurano i **Sintomi Emotivi**).\n\n2. **`aspect`**  \n   Questo parametro specifica il criterio da ottimizzare. Per impostazione predefinita, `aspect=\"aspectSum\"` massimizza la somma delle correlazioni tra gli item. Questo criterio è utile per migliorare la consistenza interna della scala, ad esempio incrementando l'alfa di Cronbach. Nel nostro caso, utilizziamo questa impostazione predefinita.\n\n3. **`level`**  \n   Questo argomento definisce il livello di misura delle variabili analizzate:  \n   - **`nominal`** (impostazione predefinita): suppone che le variabili rappresentino categorie nominali. In questo caso, non vi sono restrizioni sui punteggi risultanti.  \n   - **`ordinal`**: richiede che l’ordine dei punteggi venga preservato.  \n   - **`numerical`**: oltre a preservare l’ordine, richiede che le distanze tra i punteggi siano uguali.  \nNel caso delle categorie di risposta del **SDQ** (\"non vero\", \"parzialmente vero\", \"assolutamente vero\"), queste riflettono chiaramente un ordine crescente di accordo. Vogliamo preservare questo ordine durante l'ottimizzazione, quindi impostiamo `level=\"ordinal\"`.\n\nEsaminiamo il risultato ottenuto.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nattributes(opt) \n#> $names\n#>  [1] \"loss\"      \"catscores\" \"cormat\"    \"eigencor\"  \"indmat\"    \"scoremat\" \n#>  [7] \"data\"      \"burtmat\"   \"niter\"     \"call\"     \n#> \n#> $class\n#> [1] \"aspect\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(opt)\n#> \n#> Correlation matrix of the scaled data:\n#>         somatic worries unhappy clingy afraid\n#> somatic   1.000   0.339   0.369  0.254  0.313\n#> worries   0.339   1.000   0.468  0.397  0.378\n#> unhappy   0.369   0.468   1.000  0.367  0.454\n#> clingy    0.254   0.397   0.367  1.000  0.378\n#> afraid    0.313   0.378   0.454  0.378  1.000\n#> \n#> \n#> Eigenvalues of the correlation matrix:\n#> [1] 2.497 0.757 0.634 0.610 0.502\n#> \n#> Category scores:\n#> somatic:\n#>     score\n#> 0 -0.901\n#> 1  0.586\n#> 2  1.972\n#> \n#> worries:\n#>     score\n#> 0 -0.854\n#> 1  0.445\n#> 2  2.096\n#> \n#> unhappy:\n#>     score\n#> 0 -0.601\n#> 1  1.393\n#> 2  2.659\n#> \n#> clingy:\n#>     score\n#> 0 -1.199\n#> 1  0.237\n#> 2  1.617\n#> \n#> afraid:\n#>     score\n#> 0 -0.769\n#> 1  1.009\n#> 2  1.951\n```\n:::\n\n\n\n\n1. **Punteggi ottimali per ogni item:**  \n   La funzione calcola i punteggi \"ottimali\" per ogni item, ovvero valori che massimizzano la somma delle correlazioni tra gli item. Questo migliora la coerenza interna della scala.  \n\n2. **Preservazione dell'ordine delle risposte:**  \n   Utilizzando `level=\"ordinal\"`, i punteggi ottimizzati mantengono l'ordine crescente delle categorie di risposta, come ad esempio:\n   \n   - \"non vero\" < \"parzialmente vero\" < \"assolutamente vero\". \n   \n   Ciò assicura che la struttura ordinata delle risposte venga rispettata.\n\n3. **Correlazioni e punteggi trasformati:**  \n   L'output include:  \n   \n   - La **matrice di correlazione** dei punteggi trasformati, ovvero le correlazioni tra gli item dopo la scalatura ottimale.  \n   - Le correlazioni possono essere confrontate con quelle calcolate sulle variabili originali utilizzando la funzione `cor(items)`.  \n\n4. **Autovalori della matrice di correlazione:**  \n   L'output mostra anche gli **autovalori** della matrice di correlazione, che rappresentano le varianze delle componenti principali (da un'Analisi delle Componenti Principali, PCA).  \n   \n   - Gli autovalori sono utili per determinare il numero di dimensioni misurate dal set di item.  \n   - Ad esempio, se il primo autovalore è notevolmente più grande degli altri, e ciò suggerisce che gli item misurano una sola dimensione, come ci si aspettava.\n\n5. **Punteggi delle categorie:**  \n   La funzione mostra i **punteggi assegnati a ciascuna categoria di risposta** dopo la scalatura ottimale. Ad esempio, per l’item *somatic*, i risultati potrebbero indicare: \n   \n   - \"non vero\" → -0.886  \n   - \"parzialmente vero\" → 0.584  \n   - \"assolutamente vero\" → 2.045  \n\n   Questi punteggi sono scelti in modo da:\n   \n   - Avere una media pari a 0 nel campione analizzato.  \n   - Massimizzare le correlazioni tra gli item, migliorando la coerenza interna della scala.\n\n6. **Grafici delle trasformazioni:**  \n   Il pacchetto **`aspect`** offre grafici utili che mostrano visivamente l’assegnazione dei punteggi alle categorie. Questi grafici aiutano a interpretare il risultato della scalatura ottimale in modo intuitivo.\n\nQuesto approccio offre un metodo rigoroso per ottimizzare la misurazione degli item, migliorando la qualità psicometrica della scala e assicurando che l'interpretazione delle risposte rifletta al meglio la coerenza interna del test.\n\nI punteggi ottenuti si ottengono nel modo seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nopt$scoremat\n#>     somatic worries unhappy clingy afraid\n#> 1     1.972   0.445  -0.601  0.237 -0.769\n#> 2     1.972  -0.854  -0.601  0.237 -0.769\n#> 3    -0.901  -0.854  -0.601 -1.199  1.009\n#> 4    -0.901  -0.854  -0.601  0.237  1.009\n#> 5     1.972   0.445  -0.601  0.237 -0.769\n#> 6     0.586  -0.854  -0.601  0.237 -0.769\n#> 7    -0.901   0.445   1.393  1.617 -0.769\n#> 8    -0.901  -0.854  -0.601 -1.199 -0.769\n#> 9     0.586  -0.854  -0.601 -1.199 -0.769\n#> 10   -0.901  -0.854  -0.601 -1.199  1.009\n#> 11   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 12    1.972   2.096   1.393  0.237  1.951\n#> 13   -0.901  -0.854  -0.601 -1.199  1.951\n#> 14   -0.901   0.445  -0.601  1.617 -0.769\n#> 15    0.586   2.096   1.393  1.617  1.009\n#> 16    1.972  -0.854  -0.601  0.237  1.009\n#> 17    0.586   0.445  -0.601  1.617  1.009\n#> 18    0.586   0.445  -0.601 -1.199 -0.769\n#> 19    0.586   2.096   2.659  1.617  1.009\n#> 20    0.586   0.445   1.393  1.617  1.009\n#> 21    0.586  -0.854  -0.601 -1.199 -0.769\n#> 22    1.972   0.445  -0.601 -1.199  1.009\n#> 23    1.972   2.096   2.659  0.237  1.951\n#> 24   -0.901   0.445   1.393  0.237  1.009\n#> 25    0.586   2.096  -0.601 -1.199  1.951\n#> 26    1.972   2.096   2.659  1.617  1.009\n#> 27   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 28    0.586  -0.854  -0.601  1.617 -0.769\n#> 29    0.586  -0.854   1.393  0.237 -0.769\n#> 30   -0.901  -0.854  -0.601  0.237 -0.769\n#> 31   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 32   -0.901   0.445  -0.601  0.237 -0.769\n#> 33    0.586   0.445   1.393  1.617  1.009\n#> 34    0.586   0.445  -0.601  0.237 -0.769\n#> 35    1.972   2.096   1.393  1.617  1.951\n#> 36    0.586   0.445   1.393 -1.199  1.009\n#> 37   -0.901   0.445   1.393  0.237  1.009\n#> 38   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 39    0.586   2.096   1.393  1.617  1.009\n#> 40    0.586  -0.854  -0.601 -1.199 -0.769\n#> 41    0.586   0.445  -0.601 -1.199  1.009\n#> 42    0.586  -0.854   1.393  1.617  1.951\n#> 43    0.586   0.445  -0.601  0.237  1.009\n#> 44    1.972   0.445  -0.601  0.237  1.009\n#> 45   -0.901   0.445   1.393  0.237  1.009\n#> 46    0.586  -0.854  -0.601 -1.199 -0.769\n#> 47   -0.901   0.445   1.393  0.237  1.009\n#> 48    0.586  -0.854  -0.601 -1.199 -0.769\n#> 49   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 50   -0.901   0.445   1.393  1.617  1.009\n#> 51   -0.901  -0.854  -0.601  0.237 -0.769\n#> 52    0.586   0.445  -0.601 -1.199 -0.769\n#> 53    1.972  -0.854  -0.601 -1.199 -0.769\n#> 54   -0.901   0.445   1.393  0.237  1.009\n#> 55   -0.901   0.445  -0.601  1.617  1.009\n#> 56    0.586   0.445  -0.601  0.237  1.009\n#> 57    0.586   0.445   2.659  0.237  1.009\n#> 58   -0.901  -0.854  -0.601  0.237 -0.769\n#> 59    1.972   2.096   2.659  0.237  1.009\n#> 60   -0.901  -0.854  -0.601  0.237  1.951\n#> 61   -0.901   0.445  -0.601  0.237 -0.769\n#> 62   -0.901  -0.854  -0.601  0.237  1.009\n#> 63    0.586   0.445   1.393  0.237 -0.769\n#> 64   -0.901  -0.854  -0.601  0.237 -0.769\n#> 65   -0.901  -0.854  -0.601  0.237 -0.769\n#> 66   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 67   -0.901   0.445  -0.601  0.237 -0.769\n#> 68    0.586  -0.854  -0.601  0.237 -0.769\n#> 69    1.972   0.445   1.393  1.617  1.009\n#> 70   -0.901   0.445   1.393  1.617  1.009\n#> 71   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 72   -0.901   0.445  -0.601  0.237 -0.769\n#> 73    1.972   0.445   1.393  1.617  1.951\n#> 74   -0.901  -0.854  -0.601 -1.199  1.009\n#> 75   -0.901  -0.854  -0.601  0.237 -0.769\n#> 76    1.972   0.445  -0.601  1.617  1.951\n#> 77    0.586  -0.854  -0.601  0.237  1.951\n#> 78   -0.901  -0.854  -0.601  0.237 -0.769\n#> 79    0.586   2.096   1.393  1.617  1.951\n#> 80   -0.901   0.445  -0.601  0.237  1.009\n#> 81    0.586   2.096  -0.601  1.617 -0.769\n#> 82   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 83    0.586   0.445   1.393  0.237  1.009\n#> 84    0.586   0.445  -0.601  0.237  1.009\n#> 85   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 86    0.586  -0.854  -0.601 -1.199 -0.769\n#> 87    0.586  -0.854  -0.601 -1.199 -0.769\n#> 88   -0.901   2.096   1.393  0.237  1.009\n#> 89   -0.901   0.445  -0.601  0.237  1.009\n#> 90    0.586   2.096  -0.601  0.237  1.951\n#> 91    0.586  -0.854  -0.601 -1.199 -0.769\n#> 92    0.586  -0.854  -0.601  0.237  1.009\n#> 93   -0.901   0.445  -0.601  0.237 -0.769\n#> 94    0.586   2.096   1.393  0.237  1.009\n#> 95   -0.901   2.096   1.393  1.617  1.009\n#> 96   -0.901  -0.854  -0.601 -1.199 -0.769\n#> 97   -0.901  -0.854  -0.601  0.237  1.009\n#> 98   -0.901   0.445  -0.601  1.617  1.009\n#> 99    0.586   2.096  -0.601  0.237  1.009\n#> 100  -0.901   0.445  -0.601  0.237  1.009\n#> 101   0.586  -0.854  -0.601  0.237  1.009\n#> 102  -0.901  -0.854  -0.601  0.237 -0.769\n#> 103  -0.901  -0.854  -0.601  0.237 -0.769\n#> 104   1.972   0.445   1.393  1.617  1.009\n#> 105  -0.901  -0.854   1.393  0.237 -0.769\n#> 106   0.586   0.445  -0.601  0.237 -0.769\n#> 107   0.586   2.096  -0.601  1.617 -0.769\n#> 108   0.586  -0.854   1.393  0.237  1.951\n#> 109   0.586   2.096   1.393  0.237 -0.769\n#> 110  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 111  -0.901   0.445  -0.601  1.617  1.009\n#> 112  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 113   0.586   0.445   1.393  0.237 -0.769\n#> 114  -0.901  -0.854  -0.601  0.237 -0.769\n#> 115  -0.901  -0.854  -0.601  0.237 -0.769\n#> 116  -0.901   0.445  -0.601 -1.199 -0.769\n#> 117  -0.901   0.445  -0.601 -1.199 -0.769\n#> 118  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 119   0.586  -0.854  -0.601  0.237 -0.769\n#> 120   0.586   2.096   1.393  1.617  1.009\n#> 121  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 122   0.586   0.445  -0.601  0.237 -0.769\n#> 123   0.586   0.445   2.659  1.617  1.951\n#> 124   0.586  -0.854  -0.601  0.237  1.951\n#> 125   1.972   0.445   1.393  0.237  1.009\n#> 126  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 127  -0.901  -0.854  -0.601  0.237  1.009\n#> 128   1.972   0.445  -0.601  0.237 -0.769\n#> 129   1.972   0.445   1.393  0.237  1.951\n#> 130  -0.901   0.445  -0.601 -1.199 -0.769\n#> 131  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 132  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 133   0.586  -0.854  -0.601 -1.199 -0.769\n#> 134  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 135   0.586   2.096  -0.601  0.237 -0.769\n#> 136   0.586   0.445  -0.601  0.237 -0.769\n#> 137  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 138   1.972   2.096   2.659  1.617  1.951\n#> 139   0.586   0.445   1.393  0.237  1.009\n#> 140  -0.901   0.445  -0.601  0.237 -0.769\n#> 141  -0.901   0.445  -0.601 -1.199 -0.769\n#> 142   1.972   2.096   2.659 -1.199 -0.769\n#> 143   0.586  -0.854  -0.601 -1.199 -0.769\n#> 144  -0.901   0.445  -0.601  0.237 -0.769\n#> 145  -0.901  -0.854   1.393 -1.199 -0.769\n#> 146  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 147  -0.901   0.445  -0.601 -1.199 -0.769\n#> 148   1.972  -0.854  -0.601  1.617 -0.769\n#> 149  -0.901  -0.854   2.659  0.237  1.009\n#> 150   0.586  -0.854   1.393  0.237  1.009\n#> 151   0.586  -0.854   1.393 -1.199 -0.769\n#> 152   0.586   0.445  -0.601  1.617 -0.769\n#> 153   1.972   0.445   1.393  1.617  1.009\n#> 154   0.586   2.096   1.393 -1.199  1.009\n#> 155   1.972   2.096   1.393  0.237 -0.769\n#> 156  -0.901  -0.854  -0.601  0.237 -0.769\n#> 157  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 158   0.586   0.445   1.393  0.237  1.009\n#> 159  -0.901   0.445   1.393  0.237 -0.769\n#> 160   0.586  -0.854  -0.601 -1.199 -0.769\n#> 161   0.586  -0.854  -0.601  0.237  1.009\n#> 162  -0.901  -0.854  -0.601  1.617  1.009\n#> 163  -0.901   2.096  -0.601  1.617  1.951\n#> 164  -0.901   0.445  -0.601  0.237  1.951\n#> 165  -0.901  -0.854  -0.601  1.617 -0.769\n#> 166  -0.901  -0.854   1.393  1.617 -0.769\n#> 167  -0.901  -0.854  -0.601  0.237 -0.769\n#> 168  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 169   0.586  -0.854  -0.601  0.237  1.009\n#> 170   0.586   0.445  -0.601  0.237 -0.769\n#> 171  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 172   0.586  -0.854   1.393  0.237 -0.769\n#> 173  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 174  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 175  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 176   0.586  -0.854  -0.601  0.237 -0.769\n#> 177  -0.901  -0.854  -0.601  1.617 -0.769\n#> 178  -0.901   0.445  -0.601  0.237 -0.769\n#> 179  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 180  -0.901   0.445  -0.601 -1.199 -0.769\n#> 181   0.586   0.445   1.393  0.237  1.009\n#> 182   0.586  -0.854   1.393  0.237 -0.769\n#> 183  -0.901   0.445  -0.601  1.617 -0.769\n#> 184  -0.901  -0.854  -0.601  0.237 -0.769\n#> 185   1.972   0.445  -0.601  0.237 -0.769\n#> 186   0.586   0.445  -0.601  0.237 -0.769\n#> 187  -0.901  -0.854  -0.601  0.237 -0.769\n#> 188   0.586   2.096   1.393  0.237  1.009\n#> 189   1.972  -0.854  -0.601 -1.199 -0.769\n#> 190   0.586   0.445   1.393  0.237 -0.769\n#> 191  -0.901   0.445  -0.601  0.237 -0.769\n#> 192   0.586   0.445   1.393  1.617 -0.769\n#> 193  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 194  -0.901   0.445  -0.601  0.237 -0.769\n#> 195   0.586   2.096  -0.601  1.617 -0.769\n#> 196   0.586   0.445   1.393  0.237  1.009\n#> 197  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 198   0.586  -0.854  -0.601  0.237 -0.769\n#> 199   0.586  -0.854  -0.601  0.237 -0.769\n#> 200   0.586  -0.854  -0.601  0.237  1.009\n#> 201   0.586   0.445  -0.601  0.237  1.009\n#> 202  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 203  -0.901   2.096  -0.601 -1.199 -0.769\n#> 204   0.586   0.445   1.393 -1.199  1.009\n#> 205   0.586  -0.854  -0.601  0.237 -0.769\n#> 206   0.586  -0.854  -0.601  0.237 -0.769\n#> 207  -0.901  -0.854  -0.601  0.237 -0.769\n#> 208   0.586  -0.854  -0.601  1.617 -0.769\n#> 209  -0.901   0.445  -0.601  0.237 -0.769\n#> 210  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 211  -0.901   0.445  -0.601 -1.199 -0.769\n#> 212  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 213  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 214   0.586   2.096   1.393  1.617  1.951\n#> 215  -0.901   0.445  -0.601 -1.199 -0.769\n#> 216  -0.901  -0.854  -0.601  0.237 -0.769\n#> 217  -0.901  -0.854  -0.601  0.237  1.009\n#> 218   0.586  -0.854  -0.601 -1.199 -0.769\n#> 219  -0.901  -0.854  -0.601  1.617 -0.769\n#> 220   0.586  -0.854  -0.601 -1.199  1.009\n#> 221   0.586  -0.854   1.393  0.237  1.009\n#> 222  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 223  -0.901  -0.854  -0.601 -1.199 -0.769\n#> 224  -0.901   0.445  -0.601 -1.199 -0.769\n#> 225   0.586  -0.854  -0.601 -1.199  1.009\n#> 226  -0.901   0.445  -0.601  0.237 -0.769\n#> 227  -0.901   0.445  -0.601 -1.199 -0.769\n#> 228   1.972   0.445   1.393  0.237  1.009\n```\n:::\n\n\n\n\nEsaminiamo la relazione tra lo scoring basato sul metodo Likert con lo scoring ottimale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 1], sdq_emo$somatic)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 4], sdq_emo$clingy)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 3], sdq_emo$unhappy)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 2], sdq_emo$worries)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 5], sdq_emo$afraid)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nGuardando ai grafici ottenuti, si può notare che 1) i punteggi per le categorie successive aumentano quasi linearmente; 2) le categorie sono approssimativamente equidistanti. Concludiamo che per la valutazione degli item ordinali nella scala dei Sintomi Emotivi del SDQ, la scala Likert è appropriata, e l'ottimizzazione della scala rispetto alla semplice scala Likert di base produce cambiamenti minimi. Per altri dati, comunque, la situazione potrebbe essere molto diversa.\n\nIn conclusione, l'ottimizzazione dello scoring dei dati di questionari ordinali offre un metodo rigoroso per ottimizzare la misurazione degli item, migliorando la qualità psicometrica della scala e assicurando che l'interpretazione delle risposte rifletta al meglio la coerenza interna del test.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] aspect_1.0-6      ggokabeito_0.1.0  see_0.10.0        MASS_7.3-65      \n#>  [5] viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1   \n#>  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6   \n#> [13] semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12      scales_1.3.0     \n#> [17] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#> [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#> [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#> [29] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.0      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [22] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-2        R6_2.6.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-2         timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [46] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [49] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [52] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [55] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [58] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8      \n#>  [61] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [64] tzdb_0.4.0          data.table_1.17.0   hms_1.1.3          \n#>  [67] car_3.1-3           sem_3.1-16          pillar_1.10.1      \n#>  [70] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [73] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [76] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [79] reformulas_0.4.0    stats4_4.4.2        xfun_0.51          \n#>  [82] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [85] yaml_2.3.10         pacman_0.5.1        boot_1.3-31        \n#>  [88] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [91] cli_3.6.4           RcppParallel_5.1.10 rpart_4.1.24       \n#>  [94] xtable_1.8-4        Rdpack_2.6.2        munsell_0.5.1      \n#>  [97] Rcpp_1.0.14         coda_0.19-4.1       png_0.1-8          \n#> [100] XML_3.99-0.18       parallel_4.4.2      jpeg_0.1-10        \n#> [103] lme4_1.1-36         mvtnorm_1.3-3       openxlsx_4.2.8     \n#> [106] rlang_1.1.5         multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "E2_optimal_scoring_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "7b02b19c592694f942e6b9d5d0a1fbf9",
  "result": {
    "engine": "knitr",
    "markdown": "# ✏️ Esercizi\n\n## Ottimizzazione dello scoring per questionari a dati ordinali  \n\nNel precedente esercizio, i punteggi del *Questionario sulle Difficoltà e Risorse (SDQ)* sono stati calcolati mediante **scalatura Likert tradizionale**, assegnando in modo sequenziale i valori 0, 1 e 2 alle categorie \"Non vero\", \"Parzialmente vero\" e \"Assolutamente vero\". Sebbene questa assegnazione rifletta intuitivamente una progressione nell’accordo con le affermazioni, la scelta degli interi specifici (0-1-2 anziché 1-2-3 o altri) è puramente arbitraria, un metodo noto in letteratura come **\"misurazione per decreto\"** (*measurement by fiat*).  \n\nIn questo secondo esercizio, proponiamo un approccio alternativo volto a determinare punteggi **ottimali** per le risposte ordinali dell’SDQ, dove \"ottimalità\" è definita in base a criteri statistici rigorosi. L’obiettivo è superare l’arbitrarietà della scalatura tradizionale, identificando valori che massimizzino la coerenza psicometrica della scala.  \n\n## Obiettivo di ottimizzazione \n\nTrovare i punteggi $s_j$ (pesi numerici) assegnati alle categorie ordinali degli item che massimizzino la funzione:  \n\n$$\n\\mathcal{R} = \\frac{\\text{Var}(T)}{\\sum_{i=1}^k \\text{Var}(X_i)} ,\n$$\n\ndove: \n\n- $T = \\sum_{i=1}^k X_i$ è il punteggio totale del test ($k =$ numero di item),  \n- $\\text{Var}(T)$ è la varianza del punteggio totale,  \n- $\\text{Var}(X_i)$ è la varianza del punteggio dell'$i$-esimo item.  \n\n**Relazione con l'affidabilità**:  \nIl rapporto $\\mathcal{R}$ è legato all’**alfa di Cronbach** ($\\alpha$) dalla relazione:  \n$$\n\\alpha = \\frac{k}{k-1} \\left( 1 - \\frac{\\sum_{i=1}^k \\text{Var}(X_i)}{\\text{Var}(T)} \\right) = \\frac{k}{k-1} \\left( 1 - \\frac{1}{\\mathcal{R}} \\right) .\n$$  \nMassimizzare $\\mathcal{R}$ equivale quindi a massimizzare $\\alpha$, garantendo che gli item siano **coerenti** nel misurare il costrutto latente.  \n\n**Interpretazione**:  \n\n- Un $\\mathcal{R}$ elevato implica che la varianza totale $\\text{Var}(T)$ è spiegata principalmente dalle **covarianze tra gli item** (segnale condiviso), anziché dalla varianza individuale (rumore).  \n- Ciò ottimizza la **validità di costrutto** e la **sensibilità discriminante** del test.\n\n\n## Implementazione con il pacchetto `aspect`\n\nPer illustrare il metodo, focalizziamoci sulla sottoscala **Sintomi Emotivi** dell’SDQ. Utilizzeremo il pacchetto R **`aspect`**, progettato per ottimizzare le scalature attraverso algoritmi flessibili e strumenti visuali integrati. Questo strumento permette di: \n\n1. Assegnare punteggi non lineari alle categorie ordinali, adattandosi alla struttura latente dei dati.  \n2. Visualizzare graficamente l’impatto delle diverse scalature sull’affidabilità del test.  \n3. Confrontare soluzioni alternative in modo efficiente.  \n\nL’approccio ottimizzato non solo migliora la qualità metriche della scala, ma fornisce anche informazioni sulla risonanza psicologica degli item, rendendo i punteggi totali più rappresentativi del costrutto misurato.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"../../code/_common.R\")\nlibrary(\"aspect\")\n```\n:::\n\n\n\n\nImportiamo i dati del *Strengths and Difficulties Questionnaire* (SDQ).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nload(\"../../data/data_sdq/SDQ.RData\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(SDQ)\n#> Rows: 228\n#> Columns: 51\n#> $ Gender   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#> $ consid   <dbl> 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, …\n#> $ restles  <dbl> 2, 0, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, …\n#> $ somatic  <dbl> 2, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, …\n#> $ shares   <dbl> 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, …\n#> $ tantrum  <dbl> 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, …\n#> $ loner    <dbl> 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, …\n#> $ obeys    <dbl> 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, …\n#> $ worries  <dbl> 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, …\n#> $ caring   <dbl> 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, …\n#> $ fidgety  <dbl> 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, …\n#> $ friend   <dbl> 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, …\n#> $ fights   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ unhappy  <dbl> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, …\n#> $ popular  <dbl> 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, …\n#> $ distrac  <dbl> 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, …\n#> $ clingy   <dbl> 1, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 0, 2, …\n#> $ kind     <dbl> 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, …\n#> $ lies     <dbl> 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, …\n#> $ bullied  <dbl> 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, …\n#> $ helpout  <dbl> 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, …\n#> $ reflect  <dbl> 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, …\n#> $ steals   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, …\n#> $ oldbest  <dbl> 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, …\n#> $ afraid   <dbl> 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, …\n#> $ attends  <dbl> 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, …\n#> $ consid2  <dbl> 1, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 1, NA, 2, 2, NA, 1, 2,…\n#> $ restles2 <dbl> 0, 1, 2, 1, NA, 0, 1, 1, 0, 0, NA, 2, NA, 0, 1, NA, 1, 1,…\n#> $ somatic2 <dbl> 0, 1, 1, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 1, NA, 0, 1,…\n#> $ shares2  <dbl> 1, 2, 2, 1, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ tantrum2 <dbl> 0, 1, 2, 0, NA, 0, 2, 0, 0, 0, NA, 2, NA, 0, 1, NA, 1, 0,…\n#> $ loner2   <dbl> 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 1, 0, NA, 0, 0,…\n#> $ obeys2   <dbl> 2, 1, 2, 1, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 1, NA, 1, 2,…\n#> $ worries2 <dbl> 0, 0, 1, 0, NA, NA, 1, 0, 0, 0, NA, 1, NA, 1, 2, NA, 0, 0…\n#> $ caring2  <dbl> 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ fidgety2 <dbl> 0, 1, 0, 0, NA, 0, 1, 0, 0, 0, NA, 2, NA, 0, 0, NA, 1, 0,…\n#> $ friend2  <dbl> 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 1, 2, NA, 2, 2,…\n#> $ fights2  <dbl> 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0,…\n#> $ unhappy2 <dbl> 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 0, 0, NA, 0, 0,…\n#> $ popular2 <dbl> 2, 1, 1, 2, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ distrac2 <dbl> 0, 0, 0, 2, NA, 0, 2, 1, 0, 0, NA, 1, NA, 0, 1, NA, 1, 0,…\n#> $ clingy2  <dbl> 1, 1, 1, 0, NA, 1, 1, 1, 0, 0, NA, 1, NA, 0, 0, NA, 2, 0,…\n#> $ kind2    <dbl> 2, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2,…\n#> $ lies2    <dbl> 1, 0, 0, 0, NA, 0, 1, 0, 1, 0, NA, 1, NA, 0, 0, NA, 1, 0,…\n#> $ bullied2 <dbl> 0, 0, 0, 0, NA, 0, 2, 0, 0, 0, NA, 0, NA, 0, 0, NA, 0, 0,…\n#> $ helpout2 <dbl> 1, 1, 1, 2, NA, 2, 2, 1, 2, 1, NA, 2, NA, 2, 1, NA, 0, 2,…\n#> $ reflect2 <dbl> 1, 1, 2, 1, NA, 2, 1, 2, 1, 2, NA, 1, NA, 2, 1, NA, 1, 2,…\n#> $ steals2  <dbl> 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0,…\n#> $ oldbest2 <dbl> 0, 0, 1, 0, NA, 1, 0, 1, 1, 0, NA, 1, NA, 0, 0, NA, 0, 0,…\n#> $ afraid2  <dbl> 0, 1, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0,…\n#> $ attends2 <dbl> 1, 1, 2, 0, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 2, NA, 1, 1,…\n```\n:::\n\n\n\n\nPer analizzare solo gli item che misurano i Sintomi Emotivi, è conveniente creare un nuovo data frame.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nitems_emotion <- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nsdq_emo <- SDQ[, items_emotion]\nsdq_emo |>\n    head()\n#> # A tibble: 6 × 5\n#>   somatic worries unhappy clingy afraid\n#>     <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n#> 1       2       1       0      1      0\n#> 2       2       0       0      1      0\n#> 3       0       0       0      0      1\n#> 4       0       0       0      1      1\n#> 5       2       1       0      1      0\n#> 6       1       0       0      1      0\n```\n:::\n\n\n\n\nAffrontiamo il problema dei dati mancanti come discusso in precedenza.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdq_emo <- sdq_emo %>%\n    mutate_at(\n      vars(somatic:afraid), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)\n      ) |> \n  round()\n```\n:::\n\n\n\n\nEsaminiamo le modalità di ciascun item:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemotional_symptoms <- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nresult <- lapply(emotional_symptoms, function(x) sort(unique(sdq_emo[[x]])))\nresult |> \n  print()\n#> [[1]]\n#> [1] 0 1 2\n#> \n#> [[2]]\n#> [1] 0 1 2\n#> \n#> [[3]]\n#> [1] 0 1 2\n#> \n#> [[4]]\n#> [1] 0 1 2\n#> \n#> [[5]]\n#> [1] 0 1 2\n```\n:::\n\n\n\n\nTrasformiamo il data frame in una matrice.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- sdq_emo |> \n  as.matrix()\n```\n:::\n\n\n\n\nImplementiamo lo scaling ottimale con la funzione `corAspect()`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nopt <- corAspect(M, aspect = \"aspectSum\", level = \"ordinal\")\n```\n:::\n\n\n\n\nParametri principali della funzione:\n\n1. **`data`**  \n   Questo argomento rappresenta il data frame che contiene i dati da analizzare. Nel nostro caso, si tratta degli item relativi alla scala che stiamo studiando (ad esempio, quelli che misurano i **Sintomi Emotivi**).\n\n2. **`aspect`**  \n   Questo parametro specifica il criterio da ottimizzare. Per impostazione predefinita, `aspect=\"aspectSum\"` massimizza la somma delle correlazioni tra gli item. Questo criterio è utile per migliorare la consistenza interna della scala, ad esempio incrementando l'alfa di Cronbach. Nel nostro caso, utilizziamo questa impostazione predefinita.\n\n3. **`level`**  \n   Questo argomento definisce il livello di misura delle variabili analizzate:  \n   - **`nominal`** (impostazione predefinita): suppone che le variabili rappresentino categorie nominali. In questo caso, non vi sono restrizioni sui punteggi risultanti.  \n   - **`ordinal`**: richiede che l’ordine dei punteggi venga preservato.  \n   - **`numerical`**: oltre a preservare l’ordine, richiede che le distanze tra i punteggi siano uguali.  \nNel caso delle categorie di risposta del **SDQ** (\"non vero\", \"parzialmente vero\", \"assolutamente vero\"), queste riflettono chiaramente un ordine crescente di accordo. Vogliamo preservare questo ordine durante l'ottimizzazione, quindi impostiamo `level=\"ordinal\"`.\n\nEsaminiamo il risultato ottenuto.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nattributes(opt) \n#> $names\n#>  [1] \"loss\"      \"catscores\" \"cormat\"    \"eigencor\"  \"indmat\"    \"scoremat\" \n#>  [7] \"data\"      \"burtmat\"   \"niter\"     \"call\"     \n#> \n#> $class\n#> [1] \"aspect\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(opt)\n#> \n#> Correlation matrix of the scaled data:\n#>         somatic worries unhappy clingy afraid\n#> somatic  1.0000  0.3386  0.3691 0.2538 0.3134\n#> worries  0.3386  1.0000  0.4679 0.3966 0.3784\n#> unhappy  0.3691  0.4679  1.0000 0.3673 0.4539\n#> clingy   0.2538  0.3966  0.3673 1.0000 0.3778\n#> afraid   0.3134  0.3784  0.4539 0.3778 1.0000\n#> \n#> \n#> Eigenvalues of the correlation matrix:\n#> [1] 2.4968 0.7569 0.6343 0.6097 0.5024\n#> \n#> Category scores:\n#> somatic:\n#>      score\n#> 0 -0.9014\n#> 1  0.5862\n#> 2  1.9721\n#> \n#> worries:\n#>      score\n#> 0 -0.8540\n#> 1  0.4455\n#> 2  2.0964\n#> \n#> unhappy:\n#>      score\n#> 0 -0.6009\n#> 1  1.3931\n#> 2  2.6586\n#> \n#> clingy:\n#>     score\n#> 0 -1.199\n#> 1  0.237\n#> 2  1.617\n#> \n#> afraid:\n#>      score\n#> 0 -0.7686\n#> 1  1.0086\n#> 2  1.9509\n```\n:::\n\n\n\n\n1. **Punteggi ottimali per ogni item:**  \n   La funzione calcola i punteggi \"ottimali\" per ogni item, ovvero valori che massimizzano la somma delle correlazioni tra gli item. Questo migliora la coerenza interna della scala.  \n\n2. **Preservazione dell'ordine delle risposte:**  \n   Utilizzando `level=\"ordinal\"`, i punteggi ottimizzati mantengono l'ordine crescente delle categorie di risposta, come ad esempio:\n   \n   - \"non vero\" < \"parzialmente vero\" < \"assolutamente vero\". \n   \n   Ciò assicura che la struttura ordinata delle risposte venga rispettata.\n\n3. **Correlazioni e punteggi trasformati:**  \n   L'output include:  \n   \n   - La **matrice di correlazione** dei punteggi trasformati, ovvero le correlazioni tra gli item dopo la scalatura ottimale.  \n   - Le correlazioni possono essere confrontate con quelle calcolate sulle variabili originali utilizzando la funzione `cor(items)`.  \n\n4. **Autovalori della matrice di correlazione:**  \n   L'output mostra anche gli **autovalori** della matrice di correlazione, che rappresentano le varianze delle componenti principali (da un'Analisi delle Componenti Principali, PCA).  \n   \n   - Gli autovalori sono utili per determinare il numero di dimensioni misurate dal set di item.  \n   - Ad esempio, se il primo autovalore è notevolmente più grande degli altri, e ciò suggerisce che gli item misurano una sola dimensione, come ci si aspettava.\n\n5. **Punteggi delle categorie:**  \n   La funzione mostra i **punteggi assegnati a ciascuna categoria di risposta** dopo la scalatura ottimale. Ad esempio, per l’item *somatic*, i risultati potrebbero indicare: \n   \n   - \"non vero\" → -0.886  \n   - \"parzialmente vero\" → 0.584  \n   - \"assolutamente vero\" → 2.045  \n\n   Questi punteggi sono scelti in modo da:\n   \n   - Avere una media pari a 0 nel campione analizzato.  \n   - Massimizzare le correlazioni tra gli item, migliorando la coerenza interna della scala.\n\n6. **Grafici delle trasformazioni:**  \n   Il pacchetto **`aspect`** offre grafici utili che mostrano visivamente l’assegnazione dei punteggi alle categorie. Questi grafici aiutano a interpretare il risultato della scalatura ottimale in modo intuitivo.\n\nQuesto approccio offre un metodo rigoroso per ottimizzare la misurazione degli item, migliorando la qualità psicometrica della scala e assicurando che l'interpretazione delle risposte rifletta al meglio la coerenza interna del test.\n\nI punteggi ottenuti si ottengono nel modo seguente:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nopt$scoremat |> head()\n#>   somatic worries unhappy clingy  afraid\n#> 1  1.9721  0.4455 -0.6009  0.237 -0.7686\n#> 2  1.9721 -0.8540 -0.6009  0.237 -0.7686\n#> 3 -0.9014 -0.8540 -0.6009 -1.199  1.0086\n#> 4 -0.9014 -0.8540 -0.6009  0.237  1.0086\n#> 5  1.9721  0.4455 -0.6009  0.237 -0.7686\n#> 6  0.5862 -0.8540 -0.6009  0.237 -0.7686\n```\n:::\n\n\n\n\nEsaminiamo la relazione tra lo scoring basato sul metodo Likert con lo scoring ottimale.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 1], sdq_emo$somatic)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 4], sdq_emo$clingy)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 3], sdq_emo$unhappy)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 2], sdq_emo$worries)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(opt$scoremat[, 5], sdq_emo$afraid)\n```\n\n::: {.cell-output-display}\n![](E2_optimal_scoring_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nGuardando ai grafici ottenuti, si può notare che 1) i punteggi per le categorie successive aumentano quasi linearmente; 2) le categorie sono approssimativamente equidistanti. Concludiamo che per la valutazione degli item ordinali nella scala dei Sintomi Emotivi del SDQ, la scala Likert è appropriata, e l'ottimizzazione della scala rispetto alla semplice scala Likert di base produce cambiamenti minimi. Per altri dati, comunque, la situazione potrebbe essere molto diversa.\n\nIn conclusione, l'ottimizzazione dello scoring dei dati di questionari ordinali offre un metodo rigoroso per ottimizzare la misurazione degli item, migliorando la qualità psicometrica della scala e assicurando che l'interpretazione delle risposte rifletta al meglio la coerenza interna del test.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] aspect_1.0-6      ggokabeito_0.1.0  see_0.11.0        MASS_7.3-65      \n#>  [5] viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1   \n#>  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6   \n#> [13] semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12      scales_1.3.0     \n#> [17] markdown_1.13     knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#> [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#> [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#> [29] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.1      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.2.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [22] mime_0.13           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-3        R6_2.6.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-3         timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [46] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [49] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [52] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [55] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [58] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8.1    \n#>  [61] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [64] tzdb_0.5.0          data.table_1.17.0   hms_1.1.3          \n#>  [67] car_3.1-3           sem_3.1-16          pillar_1.10.1      \n#>  [70] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [73] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [76] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [79] reformulas_0.4.0    stats4_4.4.2        xfun_0.51          \n#>  [82] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [85] yaml_2.3.10         pacman_0.5.1        boot_1.3-31        \n#>  [88] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [91] cli_3.6.4           RcppParallel_5.1.10 rpart_4.1.24       \n#>  [94] xtable_1.8-4        Rdpack_2.6.3        munsell_0.5.1      \n#>  [97] Rcpp_1.0.14         coda_0.19-4.1       png_0.1-8          \n#> [100] XML_3.99-0.18       parallel_4.4.2      jpeg_0.1-10        \n#> [103] lme4_1.1-36         mvtnorm_1.3-3       openxlsx_4.2.8     \n#> [106] rlang_1.1.5         multcomp_1.4-28     mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "E2_optimal_scoring_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "2a1b4b9b342035e98d730adcf7c7dc5f",
  "result": {
    "engine": "knitr",
    "markdown": "# Il modello unifattoriale {#sec-fa-unifactor-model}\n\n**Prerequisiti**\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n\n**Concetti e Competenze Chiave**\n\n- Correlazione parziale\n- Teoria dei due fattori\n- Annullamento della tetrade\n\n**Preparazione del Notebook**\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |> source()\n\n# Carica pacchetti aggiuntivi\npacman::p_load(lavaan, corrplot, tidyr, kableExtra, lavaanPlot, lavaanExtra)\n```\n:::\n\n\n\n\n\n## Introduzione\n\nL’analisi fattoriale è una tecnica statistica che permette di spiegare le correlazioni tra variabili osservate attraverso la loro dipendenza da uno o più fattori latenti. In questo modello, le $p$ variabili osservate (ad esempio, item di un questionario o indicatori comportamentali) sono considerate **condizionalmente indipendenti, dato l’insieme di $m$ fattori comuni non osservabili**. L’obiettivo principale è interpretare tali fattori come costrutti teorici latenti sottostanti alle risposte osservate.\n\n::: {.callout-note title=\"Nota sulla indipendenza condizionale\" collapse=\"true\"}\nIn un modello fattoriale, si dice che le variabili osservate $y_1, y_2, \\dots, y_p$ sono *condizionalmente indipendenti* dato il fattore latente $\\xi$ quando, una volta noto il valore di $\\xi$, la conoscenza di una qualunque delle variabili osservate non fornisce informazioni aggiuntive sulle altre. Formalmente, per ogni coppia $i \\neq j$ si ha:\n\n$$\nP(y_i, y_j \\mid \\xi) = P(y_i \\mid \\xi) \\cdot P(y_j \\mid \\xi).\n$$\n\nQuesta proprietà implica che tutte le covarianze tra le variabili osservate sono spiegate esclusivamente dal fattore comune. In assenza di tale fattore, le variabili osservate risulterebbero tra loro incorrelate. L’indipendenza condizionale è una delle assunzioni centrali del modello fattoriale, e giustifica la possibilità di interpretare la covarianza tra item come effetto della loro dipendenza condivisa da un unico costrutto latente. Un esempio numerico è fornito nella @sec-fa-cor-parz.\n:::\n\nAd esempio, si può utilizzare l’analisi fattoriale per spiegare le correlazioni tra le prestazioni di un gruppo di individui in diversi compiti cognitivi attraverso un singolo fattore latente come l’intelligenza generale. In questo modo, l’analisi fattoriale consente di identificare i costrutti a cui gli item si riferiscono e di quantificare quanto ciascun item contribuisca a rappresentarli.\n\nIl modello può prevedere uno (modello unifattoriale, $m = 1$) o più fattori latenti (modello multifattoriale, $m > 1$). In questo capitolo ci concentreremo sul modello unifattoriale, che assume l’esistenza di un unico fattore comune che influenza tutte le variabili osservate.\n\nNel contesto dell’analisi fattoriale, le variabili latenti rappresentano **costrutti teorici non direttamente osservabili**, come abilità cognitive o tratti psicologici. Queste variabili riflettono le comunanze sottostanti a un insieme di indicatori osservabili, chiamati variabili manifeste. Le prime sono rappresentate nei diagrammi di percorso come cerchi, mentre le seconde come quadrati.\n\nIl legame tra fattore latente e variabili manifeste è descritto tramite i **carichi fattoriali** ($\\lambda$), che quantificano l’intensità dell’influenza esercitata dal fattore latente su ciascuna variabile osservata. Il valore di $\\lambda$ indica la proporzione di varianza della variabile osservata che è spiegata dal fattore comune: più alto è il carico, maggiore è la rappresentatività dell’item rispetto al costrutto latente.\n\nDal punto di vista matematico, ciascuna misura osservabile $y$ è modellata come una combinazione lineare del fattore latente $\\xi$, ponderato dal carico $\\lambda$, più un termine di errore specifico $\\delta$, che rappresenta la componente di varianza non spiegata dal fattore comune.\n\nUn esempio intuitivo può chiarire il significato di questa decomposizione: immaginate di usare una bilancia imprecisa per misurare il peso corporeo. Ogni misurazione ($y$) rifletterà in parte il peso reale della persona ($\\xi$), ma anche un errore casuale ($\\delta$) dovuto all’inaffidabilità dello strumento.\n\nQuando si dispone di più variabili osservabili $y$ che fanno riferimento a un medesimo costrutto latente $\\xi$, diventa possibile stimare con maggiore precisione sia il punteggio latente sia la componente di errore. Questo consente di ottenere una rappresentazione più affidabile del costrutto teorico di interesse e di migliorare l’interpretazione psicometrica dei dati.\n\n## Modello monofattoriale\n\nNel caso di un solo fattore comune e $p$ variabili manifeste $y_i$, il modello assume la forma:\n\n$$\n\\begin{equation}\ny_i = \\mu_i + \\lambda_{i} \\xi + 1 \\cdot \\delta_i \\qquad i = 1, \\dots, p,\n\\end{equation}\n$$ {#eq-mod-unifattoriale}\n\ndove:\n\n- $\\mu_i$ è la media della variabile osservata $y_i$,\n- $\\xi$ è il fattore latente comune a tutte le variabili osservate,\n- $\\lambda_i$ è la saturazione fattoriale, ovvero il peso del fattore comune $\\xi$ sulla variabile $y_i$,\n- $\\delta_i$ è il fattore specifico (o errore unico) associato a $y_i$, indipendente da $\\xi$.\n\nSi assume che:\n\n- il fattore comune $\\xi$ abbia media zero e varianza unitaria,\n- i fattori specifici $\\delta_i$ abbiano media zero, varianza $\\psi_i$, e siano indipendenti tra loro e dal fattore comune.\n\nIn questo modello, ciascuna variabile osservata $y_i$ è influenzata da una componente condivisa ($\\xi$) e da una componente specifica ($\\delta_i$), che rappresenta la parte di varianza unica della variabile non spiegata dal fattore comune.\n\nIl modello di analisi fattoriale può ricordare formalmente il modello di regressione lineare, ma esistono alcune differenze fondamentali. Innanzitutto, sia il fattore comune $\\xi$ sia i fattori specifici $\\delta_i$ sono variabili latenti, cioè non osservabili direttamente. Di conseguenza, tutti i termini presenti nel lato destro dell’equazione sono incogniti. Inoltre, i due modelli perseguono obiettivi differenti: la regressione lineare mira a identificare variabili indipendenti osservabili che spiegano la varianza di una variabile dipendente, mentre l’analisi fattoriale cerca di individuare una o più variabili latenti che rendano conto della covarianza tra un insieme di variabili osservate.\n\nPer semplicità, si assume spesso che le variabili osservate siano centrate, cioè che la loro media sia pari a zero ($\\mu_i = 0$). Questo equivale a considerare ogni $y_i$ come uno scarto rispetto alla propria media. Il modello unifattoriale può quindi essere riscritto nella forma:\n\n$$\n\\begin{equation}\ny_i - \\mu_i = \\lambda_i \\xi + 1 \\cdot \\delta_i,\n\\end{equation}\n$$ {#eq-mod-monofattoriale}\n\ndove:\n\n- $\\lambda_i$ è la saturazione (o carico) fattoriale della variabile $y_i$ sul fattore comune $\\xi$,\n- $\\delta_i$ rappresenta la componente specifica della variabile $y_i$, ovvero la parte di varianza non condivisa con le altre variabili.\n\nSi assume che:\n\n- il fattore comune $\\xi$ abbia media zero e varianza unitaria ($\\mathbb{E}[\\xi] = 0$, $\\mathrm{Var}(\\xi) = 1$),\n- ciascun fattore specifico $\\delta_i$ abbia media zero, varianza $\\psi_i$ e sia incorrelato con $\\xi$ e con gli altri $\\delta_j$ (per $j \\ne i$).\n\nSotto queste assunzioni, l’interdipendenza tra le variabili osservate è interamente spiegata dalla loro dipendenza dal fattore comune. I fattori specifici, invece, rendono conto della varianza residua non condivisa.\n\nQuesta formulazione permette di derivare espressioni analitiche per quantità fondamentali come:\n\n- la covarianza tra una variabile osservata $y_i$ e il fattore comune $\\xi$,\n- la varianza della variabile osservata $y_i$,\n- la covarianza tra due variabili osservate $y_i$ e $y_k$.\n\nL’obiettivo di questo capitolo è analizzare nel dettaglio tali quantità e mostrare come esse riflettano la struttura latente imposta dal modello unifattoriale.\n\n## Correlazione parziale\n\nPrima di introdurre formalmente il modello statistico dell’analisi fattoriale, è utile chiarire il concetto di **correlazione parziale**, centrale per comprendere la logica della separazione tra fattori comuni e specifici.\n\nL’analisi fattoriale è spesso fatta risalire agli studi di Charles Spearman. Nel 1904, Spearman pubblicò un articolo intitolato *\"General Intelligence, Objectively Determined and Measured\"*, nel quale propose la Teoria dei Due Fattori. In quel lavoro, mostrò che era possibile identificare un fattore latente a partire da una matrice di correlazioni osservate, utilizzando la tecnica dell’**annullamento della tetrade** (*tetrad differences*). Questa tecnica si basa sul principio della correlazione parziale e mira a verificare se, una volta controllati gli effetti di variabili latenti (i fattori $\\xi_j$), le correlazioni tra le variabili osservate $Y_i$ risultino nulle.\n\nPer illustrare il concetto, consideriamo un esempio con tre variabili: $Y_1$, $Y_2$ e una variabile comune $F$. La correlazione semplice $r_{12}$ tra $Y_1$ e $Y_2$ può riflettere l’influenza condivisa di $F$ su entrambe. La *correlazione parziale* tra $Y_1$ e $Y_2$ al netto di $F$ misura invece la relazione diretta tra $Y_1$ e $Y_2$ una volta rimosso l’effetto lineare di $F$ da entrambe le variabili.\n\nPer farlo, si calcolano i residui delle regressioni di $Y_1$ e $Y_2$ su $F$, ovvero le componenti ortogonali a $F$. Ad esempio, nel caso di $Y_1$:\n\n$$\nY_1 = b_{01} + b_{11}F + E_1,\n$$  {#eq-mod-reg-mult-fa}\n\ndove $E_1$ è la parte di $Y_1$ linearmente indipendente da $F$. Ripetendo l’operazione per $Y_2$ si ottiene un residuo $E_2$, anch’esso ortogonale a $F$. La correlazione di Pearson tra $E_1$ ed $E_2$ rappresenta la correlazione parziale tra $Y_1$ e $Y_2$ dato $F$.\n\nLa stessa quantità può essere calcolata direttamente a partire dalle correlazioni semplici tra le tre variabili, tramite la formula:\n\n$$\n\\begin{equation}\nr_{1,2 \\mid F} = \\frac{r_{12} - r_{1F}r_{2F}}{\\sqrt{(1-r_{1F}^2)(1-r_{2F}^2)}}.\n\\end{equation}\n$$  {#eq-corr-parz}\n\nQuesta formula mostra che la correlazione parziale è ottenuta sottraendo al valore osservato di $r_{12}$ il prodotto delle correlazioni tra $Y_1$ e $F$ e tra $Y_2$ e $F$, e normalizzando per la varianza residua non spiegata da $F$.\n\n### Esempio numerico {#sec-fa-cor-parz}\n\nSupponiamo di avere una variabile $f$ generata da una distribuzione normale:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1000\nf <- rnorm(n, 24, 12)\n```\n:::\n\n\n\n\n\nCostruiamo due variabili, $y_1$ e $y_2$, come combinazioni lineari di $f$ più un errore casuale:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny1 <- 10 + 7 * f + rnorm(n, 0, 50)\ny2 <- 3  + 2 * f + rnorm(n, 0, 50)\n```\n:::\n\n\n\n\n\nLe tre variabili sono correlate; in particolare $y_1$ e $y_2$ hanno una correlazione semplice $r_{12} = 0.380$:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nY <- cbind(y1, y2, f)\ncor(Y) |>\n    round(3)\n#>       y1    y2     f\n#> y1 1.000 0.380 0.867\n#> y2 0.380 1.000 0.423\n#> f  0.867 0.423 1.000\n```\n:::\n\n\n\n\n\nPer calcolare la correlazione parziale tra $y_1$ e $y_2$ al netto di $f$, eseguiamo due modelli di regressione lineare:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm1 <- lm(y1 ~ f)\nfm2 <- lm(y2 ~ f)\n```\n:::\n\n\n\n\n\nOgni osservazione viene così scomposta in due componenti: i valori adattati $\\hat{y}_i$ (dipendenti da $f$) e i residui $e_i$ (indipendenti da $f$):\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncbind(y1, y1.hat=fm1$fit, e=fm1$res, sum=fm1$fit+fm1$res) |>\n    head() |>\n    round(3)\n#>       y1 y1.hat        e    sum\n#> 1  81.13  130.5  -49.375  81.13\n#> 2 106.67  159.7  -53.037 106.67\n#> 3 308.03  317.8   -9.813 308.03\n#> 4 177.31  186.3   -8.971 177.31\n#> 5  61.39  191.5 -130.089  61.39\n#> 6 374.09  331.7   42.426 374.09\n```\n:::\n\n\n\n\n\nLa correlazione parziale tra $y_1$ e $y_2$ è quindi calcolabile come la correlazione tra i residui:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor(fm1$res, fm2$res)\n#> [1] 0.02829\n```\n:::\n\n\n\n\n\nNel nostro esempio, la correlazione parziale tra $y_1$ e $y_2$ al netto di $f$ è $r_{12|f} = 0.028$, praticamente nulla. Questo indica che la correlazione osservata tra $y_1$ e $y_2$ ($r = 0.380$) era dovuta esclusivamente all’influenza condivisa di $f$ su entrambe.\n\nIn altre parole, una volta eliminato l’effetto di $f$, non rimane alcuna associazione lineare diretta tra $y_1$ e $y_2$. Le due variabili sono quindi **condizionalmente indipendenti** dato $f$: le componenti di $y_1$ e $y_2$ non spiegate da $f$ risultano tra loro incorrelate.\n\nInfine, possiamo verificare che il valore ottenuto con la formula della correlazione parziale coincide con quello calcolato sui residui:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nR <- cor(Y)\n\n(R[1, 2] - R[1, 3] * R[2, 3]) / \n  sqrt((1 - R[1, 3]^2) * (1- R[2, 3]^2)) |>\n  round(3)\n#> [1] 0.02828\n```\n:::\n\n\n\n\n\nIl risultato conferma la coerenza tra il calcolo algebrico e il metodo dei residui. Questo esempio evidenzia come la correlazione parziale sia uno strumento fondamentale per isolare le relazioni dirette tra variabili, rimuovendo l’influenza di fattori comuni non osservabili.\n\n## Principio base dell'analisi fattoriale\n\nOggi, l'inferenza statistica in ambito fattoriale si basa prevalentemente su metodi di stima per massima verosimiglianza, ottenuti attraverso procedure iterative. Tuttavia, nelle fasi iniziali dello sviluppo dell’analisi fattoriale, l’estrazione dei fattori si fondava su proprietà invarianti che il modello fattoriale impone alla matrice di covarianza (o di correlazione) delle variabili osservate. Tra queste proprietà, la più nota è quella dell’*annullamento della tetrade*, caratteristica distintiva dei modelli a un solo fattore.\n\nUna *tetrade* è una combinazione lineare di quattro correlazioni tra variabili osservate. Se le correlazioni tra le variabili possono essere spiegate da un singolo fattore latente comune, allora è possibile costruire combinazioni di correlazioni la cui differenza si annulla. In altri termini, il modello a un fattore impone vincoli strutturali tali da rendere nulle alcune espressioni algebriche (le tetradi), che dipendono unicamente dalla matrice di correlazione.\n\nL’analisi fattoriale può dunque essere formulata come un problema di ricerca di un insieme ristretto di variabili latenti ($m < p$), tali che, una volta controllato il loro effetto, tutte le correlazioni parziali tra le variabili osservate $y_i$ risultino nulle. Se l’annullamento delle correlazioni parziali è confermato, lo psicologo può concludere che esistono $m$ fattori latenti capaci di spiegare la struttura di covarianza del sistema osservato.\n\nPer chiarire il principio, consideriamo la seguente matrice di correlazione, costruita in modo da riflettere un modello con un unico fattore latente $\\xi$:\n\n|       | $\\xi$   | $y_1$ | $y_2$ | $y_3$ | $y_4$ | $y_5$ |\n|-------|---------|-------|-------|-------|-------|-------|\n| $\\xi$ | **1.00** |       |       |       |       |       |\n| $y_1$ | **0.90** | 1.00  |       |       |       |       |\n| $y_2$ | **0.80** | 0.72  | 1.00  |       |       |       |\n| $y_3$ | **0.70** | 0.63  | 0.56  | 1.00  |       |       |\n| $y_4$ | **0.60** | 0.54  | 0.48  | 0.42  | 1.00  |       |\n| $y_5$ | **0.50** | 0.45  | 0.40  | 0.35  | 0.30  | 1.00  |\n\nIn questa matrice, ogni variabile $y_i$ ha una correlazione positiva con $\\xi$, e le correlazioni tra le $y_i$ sono coerenti con un modello in cui $\\xi$ agisce come unica fonte comune di covarianza. Per esempio, la correlazione parziale tra $y_3$ e $y_5$ al netto di $\\xi$ risulta:\n\n$$\n\\begin{align}\n  r_{35 \\mid \\xi} &= \\frac{r_{35} - r_{3\\xi}r_{5\\xi}}{\\sqrt{(1-r_{3\\xi}^2)(1-r_{5\\xi}^2)}} \\notag \\\\[12pt]\n  &= \\frac{0.35 - 0.7 \\times 0.5}{\\sqrt{(1 - 0.7^2)(1 - 0.5^2)}} = 0. \\notag\n\\end{align}\n$$\n\nLo stesso vale per qualunque altra coppia di variabili: tutte le correlazioni parziali condizionate a $\\xi$ sono nulle, cioè $r_{ij \\mid \\xi} = 0$ per ogni $i \\ne j$.\n\nIn questa matrice, ci sono $p(p-1)/2 = 5(5-1)/2 = 10$ correlazioni tra le variabili osservate, tutte spiegate dal singolo fattore $\\xi$. Questo non sorprende, poiché la matrice è stata costruita appositamente per rispettare questa proprietà.\n\nTuttavia, immaginiamo ora di trovarci in una situazione reale, in cui osserviamo soltanto le variabili $y_1, \\dots, y_5$, ma non abbiamo accesso diretto a $\\xi$. Possiamo allora porci la seguente domanda: esiste una variabile latente $\\xi$ tale che, se ne controllassimo l’effetto, tutte le correlazioni parziali tra le variabili osservate risulterebbero nulle?\n\nSe una tale variabile esiste, e riesce a spiegare completamente le interdipendenze osservate tra le $y_i$, essa assume lo status di **fattore**.\n\n::: {#def-}\nUn **fattore** è una variabile latente non osservabile che, una volta controllata, rende significativamente nulle tutte le correlazioni parziali tra le variabili manifeste.\n:::\n\n## Vincoli sulle correlazioni\n\nCome possiamo determinare se esiste una variabile latente $\\xi$ in grado di spiegare tutte le correlazioni osservate tra le variabili manifeste, rendendo nulle le loro correlazioni parziali? Possiamo partire dalla formula della correlazione parziale, già introdotta in precedenza (vedi @eq-corr-parz), e riscriverla per esprimere la correlazione parziale tra due variabili osservate $y_i$ e $y_j$ condizionata a $\\xi$:\n\n$$\n\\begin{align}\nr_{ij \\mid \\xi} = \\frac{r_{ij} - r_{i\\xi} \\, r_{j\\xi}}{\\sqrt{(1 - r_{i\\xi}^2)(1 - r_{j\\xi}^2)}}.\n\\end{align}\n$$\n\nAffinché la correlazione parziale $r_{ij \\mid \\xi}$ sia uguale a zero — cioè affinché $y_i$ e $y_j$ risultino condizionalmente indipendenti dato $\\xi$ — il numeratore della frazione deve annullarsi. Questa condizione si traduce nella seguente equazione:\n\n$$\nr_{ij} = r_{i\\xi} \\cdot r_{j\\xi}.\n$$ {#eq-fa-num-cor-parz}\n\nIn altri termini, la correlazione tra ogni coppia di variabili osservate deve essere pari al prodotto delle correlazioni tra ciascuna variabile e il fattore comune $\\xi$. Questa relazione vincola la struttura della matrice di correlazione osservata e costituisce una delle implicazioni fondamentali del modello fattoriale unifattoriale.\n\nIl principio è il seguente: **se un unico fattore latente $\\xi$ è in grado di spiegare tutte le correlazioni tra le variabili osservate $y_i$, allora ciascuna correlazione $r_{ij}$ deve poter essere scritta come il prodotto $r_{i\\xi} \\cdot r_{j\\xi}$.**\n\nQuesta condizione è il cuore del modello fattoriale a un fattore: tutte le interdipendenze tra le variabili manifeste sono attribuibili alla loro relazione con una variabile latente comune. Se la struttura delle correlazioni osservate viola questa condizione, il modello a un fattore non è compatibile con i dati, e sarà necessario considerare un modello con due o più fattori.\n\nDal punto di vista pratico, questo principio può essere utilizzato per valutare se una matrice di correlazione è compatibile con un modello fattoriale semplice. Ad esempio, per ogni terna di variabili si possono calcolare differenze di tetradi, cioè differenze tra prodotti incrociati di correlazioni. Se tali differenze risultano sistematicamente prossime a zero, ciò suggerisce che la struttura osservata potrebbe essere spiegata da un unico fattore comune.\n\nNei prossimi paragrafi analizzeremo in dettaglio la procedura per stimare formalmente le relazioni tra fattori e variabili manifeste.\n\n## Teoria dei Due Fattori\n\nPer illustrare in modo concreto il principio dell’annullamento della tetrade, consideriamo un esempio tratto dallo studio originale di @ch1904general. In uno dei suoi primi lavori, Spearman raccolse una serie di misurazioni delle capacità intellettive su un campione di studenti, includendo sia prestazioni scolastiche sia abilità percettive.\n\nLe sei variabili considerate furono:\n\n- Classics: rendimento nello studio dei classici;\n- French: rendimento in lingua francese;\n- English: rendimento in letteratura inglese;\n- Math: rendimento in matematica;\n- Pitch: abilità nella discriminazione dell’altezza dei suoni;\n- Music: competenza musicale.\n\nPer semplicità, nella discussione seguente considereremo solo tre materie scolastiche (studi classici, $c$, letteratura inglese, $e$, e matematica, $m$) e la discriminazione dell’altezza dei suoni, $p$. Nel suo studio, Spearman riportò le seguenti correlazioni:\n\n$$\n\\begin{array}{ccccc}\n  \\hline\n    & y_c & y_e & y_m & y_p \\\\\n  \\hline\n  y_c & 1.00 & 0.78 & 0.70 & 0.66 \\\\\n  y_e &      & 1.00 & 0.64 & 0.54 \\\\\n  y_m &      &      & 1.00 & 0.45 \\\\\n  y_p &      &      &      & 1.00 \\\\\n  \\hline\n\\end{array}\n$$\n\nSecondo la **Teoria dei Due Fattori**, proposta da Spearman, ogni prestazione intellettiva può essere scomposta in due componenti:\n\n- un **fattore generale** (*g*), comune a tutti i compiti cognitivi;\n- un **fattore specifico** (*s*), unico per ciascun compito.\n\nIl fattore $g$ rappresenta la componente stabile e condivisa dell’intelligenza, mentre ciascun fattore $s$ spiega la varianza residua specifica della singola prova. La domanda centrale è: esiste un’unica variabile latente in grado di spiegare le covarianze osservate tra le variabili manifeste?\n\nPer rispondere, Spearman utilizzò il metodo dell’**annullamento della tetrade**, che si basa sulle implicazioni della correlazione parziale. Abbiamo visto in precedenza che, se una variabile latente $\\xi$ è in grado di rendere nulle le correlazioni parziali tra le variabili osservate, allora:\n\n$$\nr_{ij} = r_{i\\xi} \\cdot r_{j\\xi}.\n$$\n\nNel contesto dei dati di Spearman, ciò significa ad esempio che la correlazione osservata tra “studi classici” ($c$) e “letteratura inglese” ($e$) deve essere uguale al prodotto delle loro correlazioni con il fattore comune $\\xi$: $r_{ec} = \\lambda_e \\cdot \\lambda_c$. Lo stesso vale per tutte le altre coppie di variabili.\n\nLe correlazioni tra le variabili manifeste e il fattore latente sono chiamate **saturazioni fattoriali** e vengono denotate con $\\lambda$. Il vincolo fondamentale del modello fattoriale è che ogni correlazione osservata può essere scomposta come prodotto di due saturazioni.\n\n## Annullamento della tetrade\n\nIl metodo dell’**annullamento della tetrade** si basa sull’assunto centrale del modello fattoriale unifattoriale: se un singolo fattore comune spiega tutte le covarianze tra le variabili osservate, allora la correlazione tra ciascuna coppia di variabili può essere espressa come il prodotto delle loro **saturazioni fattoriali**:\n\n$$\nr_{ij} = \\lambda_i \\cdot \\lambda_j.\n$$\n\nQuesta relazione consente di tradurre le correlazioni osservate in un sistema di equazioni non lineari, in cui le incognite sono le saturazioni fattoriali $\\lambda_i$.\n\nAd esempio, se consideriamo tre variabili — ad esempio *Classics* ($c$), *Math* ($m$) e *English* ($e$) — e assumiamo che siano tutte influenzate dallo stesso fattore latente $\\xi$, possiamo scrivere:\n\n$$\n\\begin{align}\nr_{cm} &= \\lambda_c \\cdot \\lambda_m, \\notag \\\\\nr_{em} &= \\lambda_e \\cdot \\lambda_m, \\\\\nr_{ce} &= \\lambda_c \\cdot \\lambda_e. \\notag\n\\end{align}\n$$\n\nRisolvendo questo sistema di equazioni, otteniamo un'espressione per ciascuna saturazione in funzione delle sole correlazioni osservate. Ad esempio, isolando $\\lambda_m$:\n\n$$\n\\lambda_m = \\sqrt{ \\frac{r_{cm} \\cdot r_{em}}{r_{ce}} }.\n$$  {#eq-tetrade}\n\nQuesta equazione mostra come si possa stimare il contributo di una variabile al fattore latente partendo esclusivamente dalle correlazioni empiriche tra le variabili osservate.\n\n### Esempio con i Dati di Spearman\n\nUtilizzando i dati riportati da Spearman nel 1904, e in particolare le variabili *Classics*, *Math* ed *English*, abbiamo:\n\n$$\nr_{cm} = 0.70, \\quad r_{em} = 0.64, \\quad r_{ce} = 0.78.\n$$\n\nSostituendo nella formula:\n\n$$\n\\hat{\\lambda}_{\\text{Math}} = \\sqrt{ \\frac{0.70 \\cdot 0.64}{0.78} } = \\sqrt{0.5733} \\approx 0.76.\n$$\n\nQuesto risultato rappresenta la **saturazione stimata** della variabile *Math* nel fattore comune latente $\\xi$.\n\nIl principio dell’annullamento della tetrade fornisce quindi un ponte diretto tra le correlazioni osservate e la struttura latente sottostante, assumendo che un singolo fattore sia responsabile delle covarianze tra le variabili.\n\n\n## Verifica del modello\n\nRipetendo il procedimento per diverse terne di variabili osservate, è possibile ottenere **stime multiple** per la stessa saturazione fattoriale. Nel caso dei dati di Spearman, ad esempio, la saturazione $\\lambda_m$ relativa alla variabile *Math* può essere stimata in almeno tre modi diversi, utilizzando combinazioni alternative di variabili:\n\n$$\n\\begin{align}\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{0.70 \\cdot 0.64}{0.78} } = 0.76, \\notag \\\\\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{0.78 \\cdot 0.45}{0.66} } = 0.69, \\notag \\\\\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{0.64 \\cdot 0.45}{0.54} } = 0.73. \\notag\n\\end{align}\n$$\n\nQuesta molteplicità di stime evidenzia un aspetto fondamentale del modello fattoriale unifattoriale: **se il modello è corretto**, ossia se un unico fattore comune spiega le correlazioni tra tutte le variabili, allora **tutte le stime ottenute devono essere coerenti tra loro**, entro un margine di errore accettabile. Se, al contrario, le stime risultano incoerenti o divergenti, ciò suggerisce che il modello a un solo fattore non è compatibile con i dati.\n\nIn altri termini, il modello di Spearman è **verificabile empiricamente**: è possibile confrontare le previsioni del modello (in termini di relazioni tra saturazioni e correlazioni osservate) con i dati raccolti. Sebbene Spearman non abbia formalizzato un test statistico per valutare la bontà del modello, ha introdotto un principio centrale nell’analisi fattoriale moderna: **non tutte le matrici di correlazione giustificano l’ipotesi dell’esistenza di un unico fattore latente**.\n\n## Metodo del centroide\n\nUna volta accettata l’ipotesi che le stime multiple siano sufficientemente simili, ci si può chiedere come ottenere un’unica stima sintetica per ciascuna saturazione.\n\nUn primo approccio consiste semplicemente nel calcolare la **media aritmetica** delle stime ottenute:\n\n$$\n\\bar{\\lambda}_m = \\frac{0.76 + 0.69 + 0.73}{3} \\approx 0.73.\n$$\n\nUn’alternativa più robusta è rappresentata dal **metodo del centroide**, che consiste nel calcolare una media pesata dei prodotti numeratori e dei denominatori coinvolti nelle diverse stime:\n\n$$\n\\hat{\\lambda}_m = \\sqrt{\n\\frac{0.70 \\cdot 0.64 + 0.78 \\cdot 0.45 + 0.64 \\cdot 0.45}{0.78 + 0.66 + 0.54}\n} = \\sqrt{ \\frac{1.031}{1.98} } \\approx 0.73.\n$$\n\nIn questo caso, entrambi i metodi producono un risultato identico. Applicando lo stesso procedimento alle altre variabili, otteniamo:\n\n$$\n\\hat{\\lambda}_c = 0.97, \\quad \\hat{\\lambda}_e = 0.84, \\quad \\hat{\\lambda}_p = 0.65,\n$$\n\ne quindi il vettore delle saturazioni fattoriali stimate è:\n\n$$\n\\boldsymbol{\\hat{\\Lambda}}' =\n(\\hat{\\lambda}_c, \\hat{\\lambda}_e, \\hat{\\lambda}_m, \\hat{\\lambda}_p) = (0.97, 0.84, 0.73, 0.65).\n$$\n\n**In sintesi**, l’esempio tratto dai dati di Spearman mostra come, a partire da una semplice matrice di correlazione tra variabili osservate, sia possibile **ricostruire una struttura latente** assumendo l’esistenza di un unico fattore comune. Il metodo dell’annullamento della tetrade fornisce sia un criterio per verificare la coerenza del modello, sia una procedura per stimare le saturazioni fattoriali.\n\nSebbene oggi l’analisi fattoriale si avvalga di metodi più avanzati, come la stima per massima verosimiglianza o i modelli bayesiani, il principio introdotto da Spearman conserva tutta la sua rilevanza: **la covarianza tra variabili osservate può essere interpretata come riflesso di costrutti latenti condivisi**. È proprio questo passaggio — dal livello osservabile al livello teorico — che rende l’analisi fattoriale uno strumento fondamentale per la psicometria e le scienze psicologiche.\n\n## Introduzione a `lavaan`\n\nAttualmente, l'analisi fattoriale viene svolta mediante software. Il pacchetto R più ampiamente utilizzato per condurre l'analisi fattoriale è `lavaan`. \n\n### Sintassi del modello\n\nAl cuore del pacchetto `lavaan` si trova la \"sintassi del modello\". La sintassi del modello è una descrizione del modello da stimare. In questa sezione, spieghiamo brevemente gli elementi della sintassi del modello `lavaan`. \n\nNell'ambiente R, una formula di regressione ha la seguente forma:\n\n```\ny ~ x1 + x2 + x3 + x4\n```\n\nIn questa formula, la tilde (\"~\") è l'operatore di regressione. Sul lato sinistro dell'operatore, abbiamo la variabile dipendente (y), e sul lato destro abbiamo le variabili indipendenti, separate dall'operatore \"+\" . In `lavaan`, un modello tipico è semplicemente un insieme (o sistema) di formule di regressione, in cui alcune variabili (che iniziano con una 'f' qui sotto) possono essere latenti. Ad esempio:\n\n```\ny ~ f1 + f2 + x1 + x2\nf1 ~ f2 + f3\nf2 ~ f3 + x1 + x2\n```\n\nSe abbiamo variabili latenti in una qualsiasi delle formule di regressione, dobbiamo \"definirle\" elencando i loro indicatori (manifesti o latenti). Lo facciamo utilizzando l'operatore speciale \"=~\", che può essere letto come \"è misurato da\". Ad esempio, per definire le tre variabili latenti f1, f2 e f3, possiamo usare la sintassi seguente:\n\n```\nf1 =~ y1 + y2 + y3\nf2 =~ y4 + y5 + y6\nf3 =~ y7 + y8 + y9 + y10\n```\n\nInoltre, le varianze e le covarianze sono specificate utilizzando un operatore \"doppia tilde\", ad esempio:\n\n```\ny1 ~~ y1 # varianza\ny1 ~~ y2 # covarianza\nf1 ~~ f2 # covarianza\n```\n\nE infine, le intercette per le variabili osservate e latenti sono semplici formule di regressione con solo una intercetta (esplicitamente indicato dal numero \"1\") come unico predittore:\n\n```\ny1 ~ 1\nf1 ~ 1\n```\n\nUtilizzando questi quattro tipi di formule, è possibile descrivere una vasta gamma di modelli di variabili latenti. L'attuale insieme di tipi di formula è riassunto nella tabella sottostante.\n\n| tipo di formula | operatore |  mnemonic |\n| --------------- | --------- | --------- |\n| definizione variabile latente | =~ | è misurato da |\n| regressione | ~ | viene regredito su |\n| (co)varianza (residuale) | ~~  |è correlato con |\n| intercetta | ~ 1 | intercetta |\n\nUna sintassi completa del modello lavaan è semplicemente una combinazione di questi tipi di formule, racchiusi tra virgolette singole. Ad esempio:\n\n```\nmy_model <- ' \n  # regressions\n  y1 + y2 ~ f1 + f2 + x1 + x2\n  f1 ~ f2 + f3\n  f2 ~ f3 + x1 + x2\n\n  # latent variable definitions \n  f1 =~ y1 + y2 + y3 \n  f2 =~ y4 + y5 + y6 \n  f3 =~ y7 + y8 + y9\n  \n  # variances and covariances \n  y1 ~~ y1 \n  y1 ~~ y2 \n  f1 ~~ f2\n\n  # intercepts \n  y1 ~ 1 \n  f1 ~ 1\n'\n```\n\nPer adattare il modello ai dati usiamo la seguente sintassi.\n\n```\nfit <- cfa(model = my_model, data = my_data)\n```\n\n## Un esempio concreto\n\nAnalizziamo nuovamente i dati di Spearman che abbiamo esaminato in precedenza usando `lavaan`. La matrice completa dei dati di Spearman è messa a disposizione da @kan2019extending. \n\nSpecifichiamo il nome delle variabili manifeste\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvarnames <- c(\n  \"Classics\", \"French\", \"English\", \"Math\", \"Pitch\", \"Music\"\n)\n```\n:::\n\n\n\n\n\ne il loro numero\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nny <- length(varnames)\n```\n:::\n\n\n\n\n\nCreiamo la matrice di correlazione:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspearman_cor_mat <- matrix(\n  c(\n    1.00,  .83,  .78,  .70,  .66,  .63,\n     .83, 1.00,  .67,  .67,  .65,  .57,\n     .78,  .67, 1.00,  .64,  .54,  .51,\n     .70,  .67,  .64, 1.00,  .45,  .51,\n     .66,  .65,  .54,  .45, 1.00,  .40,\n     .63,  .57,  .51,  .51,  .40, 1.00\n  ),\n  ny, ny,\n  byrow = TRUE,\n  dimnames = list(varnames, varnames)\n)\nspearman_cor_mat\n#>          Classics French English Math Pitch Music\n#> Classics     1.00   0.83    0.78 0.70  0.66  0.63\n#> French       0.83   1.00    0.67 0.67  0.65  0.57\n#> English      0.78   0.67    1.00 0.64  0.54  0.51\n#> Math         0.70   0.67    0.64 1.00  0.45  0.51\n#> Pitch        0.66   0.65    0.54 0.45  1.00  0.40\n#> Music        0.63   0.57    0.51 0.51  0.40  1.00\n```\n:::\n\n\n\n\n\nSpecifichiamo l'ampiezza campionaria:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- 33\n```\n:::\n\n\n\n\n\nDefiniamo il modello unifattoriale in `lavaan`. L'operatore `=~` si può leggere dicendo che la variabile latente a sinistra dell'operatore viene identificata dalle variabili manifeste elencate a destra dell'operatore e separate dal segno `+`. Per il caso presente, il modello dei due fattori di Spearman può essere specificato come segue.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspearman_mod <- \"\n  g =~ Classics + French + English + Math + Pitch + Music\n\"\n```\n:::\n\n\n\n\n\nAdattiamo il modello ai dati con la funzione `cfa()`:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit1 <- lavaan::cfa(\n  spearman_mod,\n  sample.cov = spearman_cor_mat,\n  sample.nobs = n,\n  std.lv = TRUE\n)\n```\n:::\n\n\n\n\n\nLa funzione `cfa()` del pacchetto `lavaan` serve per stimare un **modello di analisi fattoriale confermativa (CFA)**, cioè un modello che verifica se un insieme di variabili osservate può essere spiegato da una o più **variabili latenti** (cioè non direttamente osservabili).\n\nVediamo passo passo cosa significano gli argomenti specificati:\n\n🔹 `spearman_mod`: è il **modello CFA specificato dall’utente**. Di solito è scritto come stringa e indica quali variabili osservate sono collegate a quali fattori latenti. Per esempio, `g =~ Classics + French + English + Math + Pitch + Music` significa che tutte le variabili (`Classics`, `French`, ...) sono indicatori del **fattore latente g**.\n\n🔹 `sample.cov = spearman_cor_mat`: qui non stiamo fornendo direttamente i dati grezzi, ma una **matrice di correlazioni** tra le variabili osservate.  Questo approccio è comune quando si lavora con dati standardizzati o quando si vuole fare una CFA direttamente sulla matrice di correlazione.\n\n🔹 `sample.nobs = n`: è il **numero di osservazioni** (cioè i soggetti) usato per costruire la matrice di correlazioni. Serve a `lavaan` per calcolare **gli errori standard** e **gli indici di bontà di adattamento** del modello.\n\n🔹 `std.all = TRUE`: questa opzione chiede a lavaan di standardizzare le variabili latenti nel modello. Ciò significa che:\n\n- le variabili latenti (in questo caso il fattore g) vengono fissate con varianza = 1;\n- questo approccio fornisce una scala alle variabili latenti, che altrimenti non avrebbero una metrica naturale;\n- i coefficienti stimati (saturazioni fattoriali) saranno espressi in una scala più facilmente interpretabile;\n- rappresenta una convenzione standard nell'analisi fattoriale confermativa.\n\nQuesto è utile perché:\n\n- semplifica l'interpretazione dei risultati;\n- consente di confrontare più facilmente l'importanza relativa delle variabili osservate nel definire il fattore;\n- fornisce una scala di riferimento coerente per il fattore latente.\n\n### Esaminare i risultati del modello con `summary()`\n\nUna volta adattato il modello CFA, possiamo esaminarne i risultati principali usando la funzione `summary()`. Ad esempio:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nout <- summary(\n  fit1, \n  fit.measures = TRUE, \n  standardized = TRUE\n)\nout\n#> lavaan 0.6-19 ended normally after 23 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        12\n#> \n#>   Number of observations                            33\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 2.913\n#>   Degrees of freedom                                 9\n#>   P-value (Chi-square)                           0.968\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               133.625\n#>   Degrees of freedom                                15\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    1.000\n#>   Tucker-Lewis Index (TLI)                       1.086\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)               -212.547\n#>   Loglikelihood unrestricted model (H1)       -211.091\n#>                                                       \n#>   Akaike (AIC)                                 449.094\n#>   Bayesian (BIC)                               467.052\n#>   Sample-size adjusted Bayesian (SABIC)        429.622\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.000\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.000\n#>   P-value H_0: RMSEA <= 0.050                    0.976\n#>   P-value H_0: RMSEA >= 0.080                    0.016\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.025\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   g =~                                                                  \n#>     Classics          0.942    0.129    7.314    0.000    0.942    0.956\n#>     French            0.857    0.137    6.239    0.000    0.857    0.871\n#>     English           0.795    0.143    5.545    0.000    0.795    0.807\n#>     Math              0.732    0.149    4.923    0.000    0.732    0.743\n#>     Pitch             0.678    0.153    4.438    0.000    0.678    0.689\n#>     Music             0.643    0.155    4.142    0.000    0.643    0.653\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Classics          0.083    0.051    1.629    0.103    0.083    0.086\n#>    .French            0.234    0.072    3.244    0.001    0.234    0.242\n#>    .English           0.338    0.094    3.610    0.000    0.338    0.349\n#>    .Math              0.434    0.115    3.773    0.000    0.434    0.447\n#>    .Pitch             0.510    0.132    3.855    0.000    0.510    0.526\n#>    .Music             0.556    0.143    3.893    0.000    0.556    0.573\n#>     g                 1.000                               1.000    1.000\n```\n:::\n\n\n\n\n\nVediamo nel dettaglio cosa fanno i singoli argomenti:\n\n📌 `summary(fit1, ...)`: Questa funzione fornisce un **riassunto dettagliato** del modello stimato (in questo caso, `fit1`). L’output include:\n\n- informazioni generali sul modello (tipo di stimatore, ottimizzatore, numero di osservazioni, ecc.),\n- le **stime dei parametri** (es. carichi fattoriali, varianze residue, covarianze),\n- e, se richiesto, anche **gli indici di bontà dell’adattamento** e le **stime standardizzate**.\n\n📏 `fit.measures = TRUE`: Questa opzione richiede a `lavaan` di includere nella stampa una **sezione con gli indici di bontà di adattamento del modello**, tra cui:\n\n- **Chi-quadrato** del modello e p-value associato,\n- **CFI** (Comparative Fit Index),\n- **TLI** (Tucker-Lewis Index),\n- **RMSEA** (Root Mean Square Error of Approximation),\n- **SRMR** (Standardized Root Mean Residual),  \n- e altri.\n\nQuesti indici aiutano a valutare **quanto bene il modello riproduce le relazioni osservate nei dati**. Sono particolarmente utili per confrontare modelli alternativi e per verificare se il modello è coerente con la struttura teorica ipotizzata.\n\n\n🔁 `standardized = TRUE`: Questo argomento dice a `lavaan` di **aggiungere le stime standardizzate dei parametri**. Verranno incluse due colonne in più nell’output:\n\n🔹 `Std.lv` (standardizzato rispetto alla variabile latente)\n\n- Ogni carico fattoriale è standardizzato **considerando che la variabile latente ha varianza 1**, ma **senza standardizzare le variabili osservate**.\n- Questa colonna mostra **quanto una variabile osservata cambia in media per un aumento di 1 deviazione standard nel fattore latente**, mantenendo le osservate nella loro scala originale.\n- Se hai usato `std.lv = TRUE` nella stima (come nel nostro esempio), allora `Estimate` e `Std.lv` saranno **identici**, perché la varianza della latente è già fissata a 1.\n\n🔹 `Std.all` (completamente standardizzato)\n\n- Questa colonna mostra i **carichi completamente standardizzati**, cioè **sia la variabile latente che le variabili osservate sono standardizzate (varianza = 1)**.\n- I valori possono essere letti come **correlazioni** tra ogni indicatore osservato e il fattore latente.\n- È la forma più comunemente riportata negli articoli scientifici, perché:\n  - facilita il confronto tra variabili;\n  - semplifica l’interpretazione (tutti i parametri sono su una scala comparabile);\n  - consente di capire **quali indicatori sono più rappresentativi del costrutto**.\n\nℹ️ Nota sulla sezione **Varianze**\n\n- Le righe con un **punto davanti al nome** (es. `.x1`) indicano **variabili osservate**: il valore rappresenta la **varianza residua**, cioè la parte non spiegata dal fattore.\n- Le **variabili latenti** (es. `g`, `F1`, ecc.) non hanno il punto iniziale: il valore indicato rappresenta la loro **varianza totale**.\n\n📋 Come semplificare l’output\n\nPer estrarre solo la tabella delle stime:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoef(fit1)  # solo le stime grezze (non standardizzate)\n#>        g=~Classics          g=~French         g=~English            g=~Math \n#>              0.942              0.857              0.795              0.732 \n#>           g=~Pitch           g=~Music Classics~~Classics     French~~French \n#>              0.678              0.643              0.083              0.234 \n#>   English~~English         Math~~Math       Pitch~~Pitch       Music~~Music \n#>              0.338              0.434              0.510              0.556\n```\n:::\n\n\n\n\n\nOppure, per una tabella completa:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameterEstimates(fit1, standardized = TRUE)\n#>         lhs op      rhs   est    se     z pvalue ci.lower ci.upper std.lv\n#> 1         g =~ Classics 0.942 0.129 7.314  0.000    0.689    1.194  0.942\n#> 2         g =~   French 0.857 0.137 6.239  0.000    0.588    1.127  0.857\n#> 3         g =~  English 0.795 0.143 5.545  0.000    0.514    1.076  0.795\n#> 4         g =~     Math 0.732 0.149 4.923  0.000    0.441    1.024  0.732\n#> 5         g =~    Pitch 0.678 0.153 4.438  0.000    0.379    0.978  0.678\n#> 6         g =~    Music 0.643 0.155 4.142  0.000    0.339    0.948  0.643\n#> 7  Classics ~~ Classics 0.083 0.051 1.629  0.103   -0.017    0.183  0.083\n#> 8    French ~~   French 0.234 0.072 3.244  0.001    0.093    0.376  0.234\n#> 9   English ~~  English 0.338 0.094 3.610  0.000    0.154    0.522  0.338\n#> 10     Math ~~     Math 0.434 0.115 3.773  0.000    0.208    0.659  0.434\n#> 11    Pitch ~~    Pitch 0.510 0.132 3.855  0.000    0.251    0.769  0.510\n#> 12    Music ~~    Music 0.556 0.143 3.893  0.000    0.276    0.836  0.556\n#> 13        g ~~        g 1.000 0.000    NA     NA    1.000    1.000  1.000\n#>    std.all\n#> 1    0.956\n#> 2    0.871\n#> 3    0.807\n#> 4    0.743\n#> 5    0.689\n#> 6    0.653\n#> 7    0.086\n#> 8    0.242\n#> 9    0.349\n#> 10   0.447\n#> 11   0.526\n#> 12   0.573\n#> 13   1.000\n```\n:::\n\n\n\n\n\nPuoi anche **filtrare e formattare** l’output per visualizzare solo le saturazioni fattoriali:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameterEstimates(fit1, standardized = TRUE) |>\n  dplyr::filter(op == \"=~\") |>\n  dplyr::select(\n    \"Fattore latente\" = lhs,\n    Indicatore = rhs,\n    B = est,\n    SE = se,\n    Z = z,\n    \"p-value\" = pvalue,\n    Beta = std.all\n  )\n#>   Fattore.latente Indicatore     B    SE     Z p.value  Beta\n#> 1               g   Classics 0.942 0.129 7.314       0 0.956\n#> 2               g     French 0.857 0.137 6.239       0 0.871\n#> 3               g    English 0.795 0.143 5.545       0 0.807\n#> 4               g       Math 0.732 0.149 4.923       0 0.743\n#> 5               g      Pitch 0.678 0.153 4.438       0 0.689\n#> 6               g      Music 0.643 0.155 4.142       0 0.653\n```\n:::\n\n\n\n\n\n\n#### Analisi dei residui\n\nPer valutare quanto il modello riesce a riprodurre le correlazioni osservate, possiamo esaminare la **matrice delle correlazioni residue**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresiduals(fit1, type = \"cor\")$cov\n#>          Clsscs French Englsh   Math  Pitch  Music\n#> Classics  0.000                                   \n#> French   -0.003  0.000                            \n#> English   0.008 -0.033  0.000                     \n#> Math     -0.011  0.023  0.040  0.000              \n#> Pitch     0.001  0.050 -0.016 -0.062  0.000       \n#> Music     0.005  0.001 -0.017  0.024 -0.050  0.000\n```\n:::\n\n\n\n\n\nPossiamo visualizzare graficamente i residui, ad esempio con un **Q-Q plot**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres1 <- residuals(fit1, type = \"cor\")$cov\nres1[upper.tri(res1, diag = TRUE)] <- NA  # Consideriamo solo i residui non ridondanti\nv1 <- as.vector(res1)\nv2 <- v1[!is.na(v1)]\n\ntibble(v2) %>%\n  ggplot(aes(sample = v2)) + \n  stat_qq() + \n  stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](02_analisi_fattoriale_1_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nQuesto grafico serve a verificare se le **correlazioni residue** seguono una distribuzione normale: deviazioni dalla linea indicano **coppie di variabili mal rappresentate** dal modello fattoriale.\n\n\n## Diagrammi di percorso\n\nIl pacchetto `semPlot` consente di disegnare diagrammi di percorso per vari modelli SEM. La funzione `semPaths` prende in input un oggetto creato da `lavaan` e disegna il diagramma, con diverse opzioni disponibili. Il diagramma prodotto controlla le dimensioni dei caratteri/etichette, la visualizzazione dei residui e il colore dei percorsi/coefficienti. Sono disponibili queste e molte altre opzioni di controllo. \n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPaths(\n    fit1,\n    \"std\",\n    posCol = c(\"black\"),\n    edge.label.cex = 1.2,\n    whatLabels = \"std\", \n    edge.width = 0.3, # Imposta lo spessore delle linee \n    fade = FALSE # Disabilita il fading\n)\n```\n\n::: {.cell-output-display}\n![](02_analisi_fattoriale_1_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nIl calcolo delle saturazioni fattoriali con il metodo del centroide aveva prodotto il seguente risultato: \n\n- classici (Cls): 0.97\n- inglese (Eng): 0.84\n- matematica (Mth): 0.73\n- pitch discrimination (Ptc): 0.65\n\nSi noti la somiglianza con i valori ottenuti mediante il metodo di massima verosimiglianza riportati nella figura.\n\n\n## Analisi Fattoriale Esplorativa (EFA) in `lavaan`\n\nL'**analisi fattoriale esplorativa (EFA)** è una tecnica utilizzata per esplorare la struttura latente di un insieme di variabili osservate, **senza imporre vincoli a priori** su quali variabili siano associate a quali fattori. Anche in presenza di un solo fattore, EFA e CFA **non coincidono**, poiché nel CFA i legami tra fattori e indicatori sono **specificati dall’utente**, mentre nell’EFA sono **liberamente stimati dal modello**.\n\nIn `lavaan`, possiamo specificare un modello EFA utilizzando la sintassi `efa(\"nome\")*` nel modello.\n\nSpecificazione del modello EFA:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefa_model <- '\n  efa(\"efa\")*g =~ Classics + French + English + Math + Pitch + Music\n'\n```\n:::\n\n\n\n\n\nIn questo esempio:\n\n- `g` è un **fattore esplorativo** (non confermativo);\n- le saturazioni fattoriali saranno stimate **senza vincoli** a priori.\n\n\nAdattamento del modello ai dati:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit2 <- lavaan::cfa(\n  efa_model,\n  sample.cov = spearman_cor_mat,\n  sample.nobs = n,\n  std.lv = TRUE\n)\n```\n:::\n\n\n\n\n\nNota: anche se usiamo la funzione `cfa()`, il modello è trattato come EFA perché abbiamo specificato `efa()` nella sintassi del modello.\n\nEsame della soluzione ottenuta:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit2, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 3 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        12\n#> \n#>   Rotation method                       GEOMIN OBLIQUE\n#>   Geomin epsilon                                 0.001\n#>   Rotation algorithm (rstarts)                GPA (30)\n#>   Standardized metric                             TRUE\n#>   Row weights                                     None\n#> \n#>   Number of observations                            33\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 2.913\n#>   Degrees of freedom                                 9\n#>   P-value (Chi-square)                           0.968\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   g =~ efa                                                              \n#>     Classics          0.942    0.129    7.314    0.000    0.942    0.956\n#>     French            0.857    0.137    6.239    0.000    0.857    0.871\n#>     English           0.795    0.143    5.545    0.000    0.795    0.807\n#>     Math              0.732    0.149    4.923    0.000    0.732    0.743\n#>     Pitch             0.678    0.153    4.438    0.000    0.678    0.689\n#>     Music             0.643    0.155    4.142    0.000    0.643    0.653\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .Classics          0.083    0.051    1.629    0.103    0.083    0.086\n#>    .French            0.234    0.072    3.244    0.001    0.234    0.242\n#>    .English           0.338    0.094    3.610    0.000    0.338    0.349\n#>    .Math              0.434    0.115    3.773    0.000    0.434    0.447\n#>    .Pitch             0.510    0.132    3.855    0.000    0.510    0.526\n#>    .Music             0.556    0.143    3.893    0.000    0.556    0.573\n#>     g                 1.000                               1.000    1.000\n```\n:::\n\n\n\n\n\nL’output riporterà:\n\n- le **saturazioni fattoriali esplorative**;\n- le **varianze residue**;\n- le **stime standardizzate**, tra cui `Std.all`, interpretabili come **correlazioni tra fattore e variabili osservate**.\n\nVisualizzazione del modello (diagramma di percorso):\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemPaths(\n  fit2,\n  \"std\",\n  posCol = c(\"black\"),\n  edge.label.cex = 1.2,\n  whatLabels = \"std\",\n  edge.width = 0.3,\n  fade = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](02_analisi_fattoriale_1_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nQuesto comando crea un diagramma in cui:\n\n- le **variabili osservate** sono collegate al **fattore esplorativo**;\n- le etichette sui bordi mostrano i **carichi standardizzati** (`Std.all`).\n\n💡 Osservazione importante\n\nSe confronti la soluzione ottenuta con il modello CFA specificato come:\n\n```r\ncfa_model <- '\n  g =~ Classics + French + English + Math + Pitch + Music\n'\n```\n\npotresti ottenere **valori simili**, **ma la differenza concettuale rimane**:\n\n- nella CFA, i legami tra fattore e indicatori sono **vincolati** (nessun cross-loading);\n- nell’EFA (via `efa()`), i carichi sono **liberamente stimati**: è il modello a decidere \"quanto\" ogni variabile è legata al fattore.\n\n\n## Riflessioni Conclusive\n\nIn questo capitolo, abbiamo introdotto il metodo dell’annullamento della tetrade, che permette di stimare le saturazioni in un modello monofattoriale. Abbiamo anche illustrato come questo metodo sia, in effetti, un’applicazione del concetto di correlazione parziale.\n\nUn aspetto fondamentale nella costruzione dei test psicologici riguarda la determinazione del numero di fattori o tratti sottostanti al set di indicatori in esame. La teoria classica dei test presuppone che un test sia monofattoriale, cioè che gli indicatori riflettano un unico tratto latente. La mancata monodimensionalità introduce difficoltà nell’applicare i principi della teoria classica ai punteggi di un test che non soddisfa tale proprietà.\n\nL’analisi della dimensionalità di un insieme di indicatori rappresenta, quindi, una fase cruciale nel processo di costruzione di un test. Solitamente, questa valutazione viene effettuata attraverso l’analisi fattoriale. In questo capitolo, abbiamo descritto le proprietà di base del modello unifattoriale, gettando le fondamenta per una comprensione più approfondita della dimensionalità e dell'influenza di un singolo tratto latente sugli indicatori.\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] lavaanExtra_0.2.1 lavaanPlot_0.8.1  kableExtra_1.4.0  corrplot_0.95    \n#>  [5] ggokabeito_0.1.0  see_0.11.0        MASS_7.3-65       viridis_0.6.5    \n#>  [9] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#> [13] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n#> [17] lavaan_0.6-19     psych_2.5.3       scales_1.3.0      markdown_2.0     \n#> [21] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [25] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#> [29] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] RColorBrewer_1.1-3  rstudioapi_0.17.1   jsonlite_1.9.1     \n#>   [4] magrittr_2.0.3      TH.data_1.1-3       estimability_1.5.1 \n#>   [7] farver_2.1.2        nloptr_2.2.1        rmarkdown_2.29     \n#>  [10] vctrs_0.6.5         minqa_1.2.8         base64enc_0.1-3    \n#>  [13] rstatix_0.7.2       htmltools_0.5.8.1   broom_1.0.7        \n#>  [16] Formula_1.2-5       htmlwidgets_1.6.4   plyr_1.8.9         \n#>  [19] sandwich_3.1-1      emmeans_1.11.0      zoo_1.8-13         \n#>  [22] igraph_2.1.4        mime_0.13           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-3        R6_2.6.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] numDeriv_2016.8-1.1 digest_0.6.37       OpenMx_2.21.13     \n#>  [34] fdrtool_1.2.18      colorspace_2.1-1    rprojroot_2.0.4    \n#>  [37] Hmisc_5.2-3         labeling_0.4.3      timechange_0.3.0   \n#>  [40] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [43] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [46] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [49] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [52] foreign_0.8-89      zip_2.3.2           httpuv_1.6.15      \n#>  [55] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [58] DiagrammeR_1.0.11   nlme_3.1-167        promises_1.3.2     \n#>  [61] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [64] cluster_2.1.8.1     reshape2_1.4.4      generics_0.1.3     \n#>  [67] gtable_0.3.6        tzdb_0.5.0          data.table_1.17.0  \n#>  [70] hms_1.1.3           xml2_1.3.8          car_3.1-3          \n#>  [73] sem_3.1-16          pillar_1.10.1       rockchalk_1.8.157  \n#>  [76] later_1.4.1         splines_4.4.2       lattice_0.22-6     \n#>  [79] survival_3.8-3      kutils_1.73         tidyselect_1.2.1   \n#>  [82] miniUI_0.1.1.1      pbapply_1.7-2       reformulas_0.4.0   \n#>  [85] svglite_2.1.3       stats4_4.4.2        xfun_0.51          \n#>  [88] qgraph_1.9.8        arm_1.14-4          visNetwork_2.1.2   \n#>  [91] stringi_1.8.4       pacman_0.5.1        boot_1.3-31        \n#>  [94] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [97] cli_3.6.4           RcppParallel_5.1.10 rpart_4.1.24       \n#> [100] systemfonts_1.2.1   xtable_1.8-4        Rdpack_2.6.3       \n#> [103] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [106] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [109] jpeg_0.1-11         lme4_1.1-36         mvtnorm_1.3-3      \n#> [112] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-28    \n#> [115] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "02_analisi_fattoriale_1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
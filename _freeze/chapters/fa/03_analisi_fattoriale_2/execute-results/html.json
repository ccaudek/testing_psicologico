{
  "hash": "96aa3f9dda6a3b95f59ee2173b2411fa",
  "result": {
    "engine": "knitr",
    "markdown": "# Il modello statistico dell'analisi fattoriale {#sec-fa-statistical-model-fa}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- Comprendere il modello statistico monofattoriale.\n- Eseguire l'analisi statistica per il modello monofattoriale con `lavaan`.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, semPlot, tidyr, ggdag, dagitty)\n```\n:::\n\n\n\n:::\n\n## Modello monofattoriale\n\nL’analisi fattoriale esplorativa (AFE) parte da una matrice di\ndimensioni $p \\times p$ (dove $p$ è il numero di variabili\nosservate) che contiene i coefficienti di correlazione (o, in alternativa,\ndi covarianza) fra tali variabili. L’obiettivo dell’AFE è ottenere una\nmatrice di dimensioni $p \\times k$ (dove $k$ è il numero di fattori\ncomuni) i cui elementi – chiamati *saturazioni fattoriali* – descrivono\nla relazione tra ciascun fattore comune e ogni variabile osservata.\n\nNel caso più semplice, quello *monofattoriale*, si ipotizza\nl’esistenza di un unico fattore latente, $\\xi$. In presenza di $p$\nvariabili manifeste $Y_i$, il modello matematico di un solo fattore\ncomune si può esprimere nel modo seguente:\n\n$$\nY_i = \\mu_i + \\lambda_{i} \\,\\xi + \\delta_i ,\n\\quad\\text{per}\\quad \ni=1, \\dots, p,\n$$ {#eq-fa-model-1f}\n\ndove:\n\n- $\\xi$ è il fattore comune (o *fattore latente*), condiviso da tutte\n  le variabili $Y_i$;\n- $\\delta_i$ è il *fattore specifico* (o *fattore unico*) associato\n  alla $i$-esima variabile osservata, cioè una componente di varianza\n  che non è condivisa con le altre variabili;\n- $\\lambda_i$ è la *saturazione fattoriale* (o *peso*) della\n  $i$-esima variabile, ossia il coefficiente che quantifica il peso\n  esercitato dal fattore comune $\\xi$ su $Y_i$.\n\nPer semplificare l’analisi, si assume spesso che $\\mu_i = 0$,\nconsiderando le $Y_i$ già centrate (cioè prive della loro media).\nQuesta convenzione rende possibile riscrivere il modello come:\n\n$$\nY_i = \\lambda_i \\,\\xi + \\delta_i.\n$$ {#eq-fa-model-1f-noint}\n\nIn aggiunta a questa ipotesi di centratura, si stabilisce che:\n\n1. il fattore comune $\\xi$ abbia media nulla,\n   $\\mathbb{E}(\\xi) = 0$, e varianza unitaria,\n   $\\mathbb{V}(\\xi) = 1$;\n2. i fattori specifici $\\delta_i$ abbiano media nulla,\n   $\\mathbb{E}(\\delta_i)=0$, e varianza $\\psi_i$,\n   cioè $\\mathbb{V}(\\delta_i) = \\psi_i$;\n3. i fattori specifici siano tra loro incorrelati:\n   $\\mathbb{E}(\\delta_i \\,\\delta_k) = 0$ per $i \\neq k$;\n4. i fattori specifici siano incorrelati con il fattore comune:\n   $\\mathbb{E}(\\delta_i\\,\\xi) = 0$ per ogni $i$.\n\nDate queste ipotesi, l’interdipendenza (cioè le correlazioni) fra le\nvariabili osservate $Y_i$ e $Y_k$ è interamente spiegata dal singolo\nfattore comune $\\xi$. I termini $\\delta_i$ riguardano solo la\nvarianza *non condivisa* di ciascuna variabile.\n\nSulla base di queste assunzioni, è possibile:\n\n- calcolare la *covarianza* tra $Y_i$ e il fattore comune $\\xi$;\n- determinare la *varianza* di ciascuna variabile $Y_i$;\n- ottenere la *covarianza* tra due variabili manifeste $Y_i$ e\n  $Y_k$.\n\nTali derivazioni consentono di comprendere a fondo come il fattore\nlatente $\\xi$ contribuisca a spiegare le relazioni fra le variabili\nosservate e quanta parte della varianza di ciascuna variabile sia invece\nimputabile a fattori specifici (non condivisi). Questo concetto è alla\nbase di tutte le procedure di stima e di interpretazione nell’analisi\nfattoriale esplorativa con un solo fattore.\n\n## Covarianza tra un indicatore e il fattore comune\n\nNel modello monofattoriale, vogliamo determinare la covarianza teorica\ntra una variabile manifesta $Y_i$ e il fattore comune $\\xi$. La\ndefinizione di covarianza è:\n\n$$\n\\mathrm{Cov}(Y_i, \\xi) \n= \\mathbb{E}(Y_i \\, \\xi) \n  - \\mathbb{E}(Y_i)\\,\\mathbb{E}(\\xi).\n$$\n\nPoiché per semplicità assumiamo $\\mathbb{E}(\\xi) = 0$, la formula si\nriduce a:\n\n$$\n\\mathrm{Cov}(Y_i, \\xi) \n= \\mathbb{E}(Y_i \\,\\xi).\n$$\n\nUsando il modello monofattoriale $Y_i = \\lambda_i \\xi + \\delta_i$, si\nottiene:\n\n$$\n\\mathrm{Cov}(Y_i, \\xi) \n= \\mathbb{E}\\bigl((\\lambda_i \\,\\xi + \\delta_i)\\xi\\bigr)\n= \\mathbb{E}(\\lambda_i\\,\\xi^2 + \\delta_i\\,\\xi).\n$$\n\nIl termine $\\lambda_i$ è una costante (la *saturazione fattoriale*),\nperciò si può portare fuori dall’aspettazione:\n\n$$\n= \\lambda_i \\,\\mathbb{E}(\\xi^2) + \\mathbb{E}(\\delta_i \\,\\xi).\n$$\n\nA questo punto, valgono due ipotesi fondamentali:\n\n1. $\\mathbb{E}(\\xi^2) = \\mathbb{V}(\\xi) = 1$, cioè il fattore comune ha\n   varianza unitaria.\n2. $\\mathrm{Cov}(\\delta_i,\\xi) = \\mathbb{E}(\\delta_i \\,\\xi) = 0$, poiché\n   il fattore specifico $\\delta_i$ è incorrelato con il fattore comune\n   $\\xi$.\n\nApplicando queste ipotesi si ha:\n\n$$\n\\mathrm{Cov}(Y_i, \\xi) \n= \\lambda_i \\cdot 1 + 0 \n= \\lambda_i.\n$$\n\n**In sintesi**: in un modello a singolo fattore, la *saturazione*\n$\\lambda_i$ coincide con la covarianza tra la variabile manifesta\n$Y_i$ e il fattore comune $\\xi$. Inoltre, se ogni variabile $Y_i$\nè stata *standardizzata*, ossia ha varianza pari a 1, allora\n$\\lambda_i = \\mathrm{Corr}(Y_i,\\xi)$. In tal caso, $\\lambda_i$\nesprime direttamente la *correlazione* tra la variabile $Y_i$ e il\nfattore comune $\\xi$.\n\n\n## Espressione fattoriale della varianza\n\nSotto l’ipotesi che $\\mathbb{E}(Y_i) = 0$, la varianza di $Y_i$ è:\n\n$$\n\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) - [\\mathbb{E}(Y_i)]^2 \n                = \\mathbb{E}(Y_i^2).\n$$\n\nUsando di nuovo il modello monofattoriale $Y_i = \\lambda_i \\xi + \\delta_i$:\n\n$$\n\\mathbb{V}(Y_i) \n= \\mathbb{E}\\bigl((\\lambda_i \\,\\xi + \\delta_i)^2\\bigr).\n$$\n\nSviluppando il quadrato:\n\n$$\n= \\mathbb{E}\\bigl(\\lambda_i^2 \\,\\xi^2 \n                  + 2\\,\\lambda_i\\,\\xi\\,\\delta_i\n                  + \\delta_i^2\\bigr).\n$$\n\nDistinguiamo i tre termini all’interno dell’aspettazione:\n\n1. $\\mathbb{E}(\\lambda_i^2 \\,\\xi^2) = \\lambda_i^2 \\,\\mathbb{E}(\\xi^2)$\n   poiché $\\lambda_i^2$ è costante e\n   $\\mathbb{E}(\\xi^2) = \\mathbb{V}(\\xi) = 1$. Pertanto questo termine\n   diventa $\\lambda_i^2$.\n2. $\\mathbb{E}(2\\,\\lambda_i\\,\\xi\\,\\delta_i) = 2\\,\\lambda_i\\,\\mathbb{E}(\\xi\\,\\delta_i)$.\n   Ma $\\mathrm{Cov}(\\xi, \\delta_i) = 0$, dunque\n   $\\mathbb{E}(\\xi\\,\\delta_i) = 0$. Di conseguenza questo termine è\n   nullo.\n3. $\\mathbb{E}(\\delta_i^2) = \\mathbb{V}(\\delta_i) = \\psi_i$, dato che\n   il fattore specifico $\\delta_i$ ha varianza $\\psi_i$.\n\nMettendo insieme questi risultati, otteniamo:\n\n$$\n\\mathbb{V}(Y_i) \n= \\lambda_i^2 + \\psi_i.\n$$\n\n- $\\lambda_i^2$ è detta *comunalità* della variabile $Y_i$ e indica\n  la parte di varianza spiegata dal fattore comune $\\xi$.\n- $\\psi_i$ rappresenta la parte di varianza non spiegata dal fattore\n  comune, detta *unicità* di $Y_i$.\n\nNel caso in cui le $Y_i$ siano state *standardizzate* (quindi abbiano\n$\\mathbb{V}(Y_i) = 1$), si ottiene:\n\n$$\n1 = \\lambda_i^2 + \\psi_i,\n$$\n\nda cui\n\n$$\n\\psi_i = 1 - \\lambda_i^2.\n$$\n\nIn questo scenario, la comunalità $\\lambda_i^2$ indica esattamente la\npercentuale di varianza di $Y_i$ spiegata dal fattore comune, mentre\n$\\psi_i$ indica la percentuale rimanente, legata a fattori specifici\no ad altri errori di misura.\n\n\n**In sintesi**, la varianza di una variabile osservata $Y_i$ può\nessere scomposta in:\n\n- $\\lambda_i^2$, la parte *comune* che la variabile condivide con\n  tutte le altre (ossia la porzione di varianza attribuibile al fattore\n  comune $\\xi$, chiamata *comunalità*);\n- $\\psi_i$, la parte *specifica* o *residua*, non spiegata dal fattore\n  comune (chiamata *unicità*).\n\nNei modelli fattoriali, l’obiettivo principale è proprio stimare\ncorrettamente $\\lambda_i$ e $\\psi_i$ per capire in che misura un\nfattore latente unico ($\\xi$) spiega le relazioni tra le diverse\nvariabili manifeste $Y_1, Y_2, \\dots, Y_p$.\n\n::: {#exm-}\nRiprendiamo l’analisi della matrice di correlazioni di Spearman. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nSpearman <- matrix(c(\n  1.0, .78, .70, .66,\n  .78, 1.0, .64, .54,\n  .70, .64, 1.0, .45,\n  .66, .54, .45, 1.0\n),\nbyrow = TRUE, ncol = 4\n)\nrownames(Spearman) <- c(\"C\", \"E\", \"M\", \"P\")\ncolnames(Spearman) <- c(\"C\", \"E\", \"M\", \"P\")\nSpearman |>\n  print()\n#>      C    E    M    P\n#> C 1.00 0.78 0.70 0.66\n#> E 0.78 1.00 0.64 0.54\n#> M 0.70 0.64 1.00 0.45\n#> P 0.66 0.54 0.45 1.00\n```\n:::\n\n\n\n\nQuando eseguiamo una *analisi fattoriale* con la funzione `factanal()`, nello\nstesso output compare la quantità denominata `SS loadings`. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm <- factanal(covmat = Spearman, factors = 1)\nfm\n#> \n#> Call:\n#> factanal(factors = 1, covmat = Spearman)\n#> \n#> Uniquenesses:\n#>     C     E     M     P \n#> 0.086 0.329 0.460 0.539 \n#> \n#> Loadings:\n#>   Factor1\n#> C 0.956  \n#> E 0.819  \n#> M 0.735  \n#> P 0.679  \n#> \n#>                Factor1\n#> SS loadings      2.587\n#> Proportion Var   0.647\n#> \n#> The degrees of freedom for the model is 2 and the fit was 0.023\n```\n:::\n\n\n\n\nQuesta quantità indica quanta parte della *varianza totale* delle quattro\nvariabili manifeste è spiegata dal fattore comune.\n\nRicordiamo che, per *varianza totale* in statistica multivariata, si\nintende la somma delle varianze delle variabili osservate (cioè la\n*traccia* della matrice di covarianza). Se le variabili sono\nstandardizzate, ciascuna contribuisce con 1 alla varianza complessiva,\nquindi, con quattro variabili, la varianza totale risulta 4.\n\nLa *quota* della varianza totale spiegata dal modello fattoriale a un\nfattore è data dalla somma delle comunalità di ogni variabile, ossia\ndalle saturazioni fattoriali (loadings) *al quadrato*, sommate tra loro.\nNell’esempio, il valore ottenuto è 2.587; perciò la proporzione di\nvarianza spiegata è\n\n$$\n\\frac{2.587}{4} \\approx 0.647,\n$$\n\nche `factanal()` riporta come `Proportion Var`. \n\nLa parte di varianza di ciascuna variabile *non* spiegata dal fattore\ncomune prende il nome di *unicità* (in inglese *uniqueness*). Nel\nrisultato di `factanal()`, l’unicità di ogni variabile si ottiene con\n`fm$uniqueness`. La *comunalità* (ovvero la quota di varianza spiegata\ndal fattore comune) si ricava da `1 - fm$uniqueness`, oppure calcolando\ndirettamente il quadrato di ogni saturazione fattoriale. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nL <- c(fm$load[1], fm$load[2], fm$load[3], fm$load[4])\nprint(L)\n#> [1] 0.9563 0.8194 0.7350 0.6790\n```\n:::\n\n\n\n\nEseguendo il prodotto interno `t(L) %*% L`, infatti, si ottiene la somma dei quadrati delle saturazioni (le cosiddette *squared loadings*), che fornisce la\ncomunalità totale spiegata dal fattore per l’insieme delle variabili.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt(L) %*% L \n#>       [,1]\n#> [1,] 2.587\n```\n:::\n\n\n\n:::\n\n## Covarianza tra due variabili manifeste\n\nConsideriamo due variabili manifeste $Y_i$ e $Y_k$ con media nulla,\nossia $\\mathbb{E}(Y_i) = \\mathbb{E}(Y_k) = 0$. In questa ipotesi, la\nloro covarianza è data da:\n\n$$\n\\mathrm{Cov}(Y_i, Y_k) \n= \\mathbb{E}(Y_i \\, Y_k) \n  - \\mathbb{E}(Y_i)\\,\\mathbb{E}(Y_k) \n= \\mathbb{E}(Y_i \\, Y_k).\n$$\n\nNel *modello monofattoriale*, ogni variabile si esprime come\n$Y_i = \\lambda_i \\,\\xi + \\delta_i$, dove $\\xi$ è il fattore comune e\n$\\delta_i$ è il fattore specifico. Sostituendo queste espressioni\nnella formula della covarianza, otteniamo:\n\n$$\n\\mathrm{Cov}(Y_i, Y_k) \n= \\mathbb{E}\\bigl((\\lambda_i \\,\\xi + \\delta_i)\n                  (\\lambda_k \\,\\xi + \\delta_k)\\bigr).\n$$\n\nEspandendo il prodotto dentro l’aspettazione:\n\n$$\n= \\mathbb{E}\\bigl(\\lambda_i\\,\\lambda_k \\,\\xi^2 \n                + \\lambda_i\\,\\xi\\,\\delta_k \n                + \\lambda_k\\,\\delta_i\\,\\xi \n                + \\delta_i\\,\\delta_k\\bigr).\n$$\n\nA questo punto, si applicano le ipotesi del modello:\n\n1. $\\mathbb{E}(\\xi^2) = \\mathbb{V}(\\xi) = 1$.\n2. $\\mathrm{Cov}(\\xi, \\delta_i) = 0$, dunque\n   $\\mathbb{E}(\\xi \\,\\delta_i) = 0$.\n3. $\\mathrm{Cov}(\\delta_i, \\delta_k) = 0$, cioè\n   $\\mathbb{E}(\\delta_i \\,\\delta_k) = 0$.\n\nApplicandole ai termini sopra, abbiamo:\n\n$$\n\\mathrm{Cov}(Y_i, Y_k)\n= \\lambda_i\\,\\lambda_k\\,\\underbrace{\\mathbb{E}(\\xi^2)}_{=1}\n  + \\lambda_i \\,\\underbrace{\\mathbb{E}(\\xi\\,\\delta_k)}_{=0}\n  + \\lambda_k \\,\\underbrace{\\mathbb{E}(\\delta_i\\,\\xi)}_{=0}\n  + \\underbrace{\\mathbb{E}(\\delta_i\\,\\delta_k)}_{=0}\n= \\lambda_i \\,\\lambda_k.\n$$\n\n**In sintesi**, in un modello a singolo fattore, la covarianza tra due\nvariabili manifeste $Y_i$ e $Y_k$ è interamente spiegata dal\nfattore comune $\\xi$ e risulta pari al prodotto delle rispettive\nsaturazioni fattoriali $\\lambda_i$ e $\\lambda_k$.\n\n## Correlazioni osservate e correlazioni riprodotte dal modello\n\nNel modello monofattoriale, l’ipotesi di base è che il *fattore comune*\nspieghi *tutta* la covarianza tra le variabili osservate. In altre\nparole, ci aspettiamo che, una volta noto il valore del fattore comune\n$\\xi$, ogni variabile $Y_i$ sia incorrelata con le altre\n$(Y_k)$. Formalmente, ciò si traduce nell’uguaglianza:\n\n$$\n\\mathrm{Cov}(Y_i, Y_k \\,\\mid\\, \\xi) = 0\n\\quad\\text{per}\\quad \ni \\neq k.\n$$\n\nSe questa condizione risulta soddisfatta, il modello monofattoriale\nriproduce correttamente le *correlazioni* osservate fra le variabili.\nCon il termine $\\boldsymbol{\\Sigma}$ si indica la *matrice di\ncorrelazioni riprodotte* dal modello, che in forma matriciale si esprime\ncome:\n\n$$\n\\boldsymbol{\\Sigma} \n= \\boldsymbol{\\Lambda}\\,\\boldsymbol{\\Lambda}^{\\prime} \n  + \\boldsymbol{\\Psi},\n$$\n\ndove $\\boldsymbol{\\Lambda}$ è la matrice delle *saturazioni\nfattoriali* (loadings) e $\\boldsymbol{\\Psi}$ è la matrice delle\n*unicità* (cioè le varianze specifiche non spiegate dal fattore\ncomune). \n\nIl modello monofattoriale si considera *adeguato* se la differenza tra\nla matrice di correlazioni empiricamente osservate e la matrice\n$\\boldsymbol{\\Sigma}$ prodotta dal modello risulta trascurabile.\nQuando tale differenza (chiamata spesso *misura di scostamento* o\n*misfit*) è prossima allo zero, possiamo concludere che il fattore\ncomune riesce a spiegare in modo soddisfacente i rapporti di\ncorrelazione tra le variabili del nostro insieme di dati.\n\n::: {#exm-}\nPer i dati di Spearman, le correlazioni riprodotte dal modello ad un fattore sono\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround(L %*% t(L) + diag(fm$uniq), 3)\n#>       [,1]  [,2]  [,3]  [,4]\n#> [1,] 1.000 0.784 0.703 0.649\n#> [2,] 0.784 1.000 0.602 0.556\n#> [3,] 0.703 0.602 1.000 0.499\n#> [4,] 0.649 0.556 0.499 1.000\n```\n:::\n\n\n\n\nLa matrice delle differenze tra le correlazioni campionarie e quelle\nriprodotte è\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround(Spearman - (L %*% t(L) + diag(fm$uniq)), 3) \n#>        C      E      M      P\n#> C  0.000 -0.004 -0.003  0.011\n#> E -0.004  0.000  0.038 -0.016\n#> M -0.003  0.038  0.000 -0.049\n#> P  0.011 -0.016 -0.049  0.000\n```\n:::\n\n\n\n\nLo scarto maggiore tra le correlazioni campionarie e quelle riprodotte è\nuguale a 0.049. Si può dunque concludere che il modello monofattoriale\nspiega in maniera ragionevole i dati di Spearman.\n:::\n\n## Bontà di adattamento del modello ai dati\n\nUn aspetto fondamentale nell’analisi fattoriale è valutare se la\n*matrice di correlazioni* (o *covarianze*) prevista dal modello\nrispecchia adeguatamente i dati empirici. A tal scopo, si conduce un\ntest statistico che confronta la matrice di correlazioni/covarianze\n*osservata* con quella *predetta* dal modello fattoriale.\n\n### L’ipotesi nulla del test\n\nL’ipotesi nulla ($H_0$) afferma che le differenze tra le correlazioni\nosservate e quelle riprodotte dal modello siano dovute soltanto agli\nerrori di campionamento. In altre parole, il modello è considerato\n“corretto” a livello di popolazione, ossia\n$\\boldsymbol{\\Sigma}(\\theta) = \\boldsymbol{\\Sigma}$, dove:\n\n- $\\boldsymbol{\\Sigma}$ è la matrice di correlazioni (o covarianze)\n  nella *popolazione*;\n- $\\boldsymbol{\\Sigma}(\\theta)$ è la matrice di correlazioni (o\n  covarianze) riprodotta dal modello in base ai parametri $\\theta$.\n\n### La statistica $\\chi^2$\n\nLa statistica usata per il test, indicata come $v$ (o più\ncomunemente $\\chi^2$), è funzione della differenza tra\n$\\boldsymbol{S}$ (la matrice osservata) e\n$\\boldsymbol{S}(\\theta)$ (la matrice riprodotta dal modello):\n\n$$\nv = f\\bigl[\\boldsymbol{S}(\\theta) - \\boldsymbol{S}\\bigr].\n$$ {#eq-chisq-gof}\n\nQuando l’ipotesi nulla è vera (cioè la *discrepanza* tra le due matrici\nè solo casuale), $v$ si distribuisce approssimativamente come una\n$\\chi^2$ con $\\nu$ gradi di libertà, dove\n\n$$\n\\nu = \\frac{p(p+1)}{2} \\;-\\; q.\n$$ {#eq-chisq-gof-nu}\n\n- $p$ è il numero di variabili manifeste;\n- $q$ è il numero di parametri stimati dal modello (ad esempio,\n  $\\lambda$ e $\\psi$ nel modello monofattoriale).\n\nIl valore di $v$ è *tanto maggiore quanto più le correlazioni/covarianze\npreviste dal modello differiscono da quelle effettivamente osservate*.\nSe $v=0$, i parametri del modello ricostruiscono *esattamente* la\nmatrice di correlazioni della popolazione.\n\n### Interpretazione del test\n\nIl test $\\chi^2$ di adattamento del modello fattoriale segue la logica\ninversa rispetto ai test più comuni (dove un risultato significativo\nindica evidenza per l’ipotesi alternativa):\n\n- se il test *non* è significativo (es., $p\\geq 0{,}05$), non si può\n  escludere che la discrepanza tra matrice osservata e matrice stimata\n  sia dovuta al caso: in tal caso, il modello è considerato adeguato;\n- al contrario, un risultato *significativo* (es., $p < 0{,}05$)\n  indica che la differenza non si spiega solo con l’errore di\n  campionamento e che il modello presenta *carenze di adattamento* ai\n  dati.\n\n### Assunzioni e limiti\n\n1. **Normalità multivariata**: il test $\\chi^2$ richiede che le\n   variabili siano distribuite (almeno approssimativamente) come un\n   campione casuale tratto da una distribuzione normale multivariata.\n   Nella pratica, non sempre questa condizione è soddisfatta.\n2. **Dimensioni campionarie**: la statistica $\\chi^2$ è *sensibile* al\n   numero di osservazioni. Con campioni di grandi dimensioni, anche\n   piccole discrepanze tra il modello e i dati tendono a produrre\n   risultati statisticamente significativi, suggerendo un *falso* cattivo\n   adattamento.\n\nPer questi motivi, la bontà di adattamento del modello non si giudica\nsolo in base alla significatività del test $\\chi^2$. Un criterio\nalternativo è ad esempio valutare il **rapporto $\\chi^2/\\nu$**, dove\n$\\nu$ sono i gradi di libertà del test. Valori di\n$\\chi^2/\\nu \\leq 3$ (o talvolta $\\leq 4$) sono spesso considerati\nindicativi di un adattamento accettabile. Inoltre, in letteratura\nesistono molti altri indici (*fit indices*) che completano la valutazione\ndella bontà di adattamento del modello fattoriale.\n\n## L’errore standard della misurazione nel modello fattoriale\n\nIn questa sezione, mostriamo come il *concetto di errore standard di misurazione*, tipico della CTT, possa essere reinterpretato tramite il *modello fattoriale*.\n\n### Collegamento tra CTT e analisi fattoriale\n\nSecondo la CTT, il punteggio osservato $X$ di un test si scompone in\ndue parti:\n\n$$\nX = T + E,\n$$\n\ndove:\n\n- $T$ è il *valore vero* del soggetto,\n- $E$ è l’*errore di misurazione*, considerato una variabile casuale\n  con media zero, indipendente da $T$.\n\nSe consideriamo un modello fattoriale *monofattoriale* con $p$ item\n(variabili osservate), la relazione che descrive ciascun item $j$ per\nil soggetto $i$ è:\n\n$$\nY_{ji} = \\lambda_j \\,\\xi_i + \\delta_{ji},\n$$\n\ndove:\n\n- $Y_{ji}$ è il punteggio osservato nell’item $j$,\n- $\\xi_i$ è il fattore comune (latente) per il soggetto $i$,\n- $\\lambda_j$ è il *carico fattoriale* dell’item $j$ sul fattore\n  $\\xi$,\n- $\\delta_{ji}$ è l’errore unico (o fattore specifico) relativo\n  all’item $j$.\n\nIl **punteggio totale** $X_i$ del soggetto $i$ si ottiene sommando i\npunteggi dei singoli item:\n\n$$\nX_i \n= \\sum_{j=1}^p Y_{ji}\n= \\sum_{j=1}^p (\\lambda_j \\,\\xi_i + \\delta_{ji})\n= \\biggl(\\sum_{j=1}^p \\lambda_j\\biggr)\\,\\xi_i \n  + \\sum_{j=1}^p \\delta_{ji}.\n$$\n\nNotiamo che questa formula rispecchia la struttura della CTT [@mcdonald2013test]:\n\n$$\nX_i = T_i + E_i,\n$$\n\ndove il *valore vero* $T_i$ è\n$\\bigl(\\sum_{j=1}^p \\lambda_j\\bigr)\\,\\xi_i$ (la parte del punteggio\ndovuta al fattore comune) e l’*errore* $E_i$ è\n$\\sum_{j=1}^p \\delta_{ji}$ (la somma degli errori unici).\n\n### Decomposizione della varianza\n\nNella CTT, la varianza del punteggio osservato $\\sigma^2_{X_i}$ si\nscompone nella varianza del valore vero ($\\sigma^2_{T_i}$) e nella\nvarianza dell’errore ($\\sigma^2_{E_i}$):\n\n$$\n\\sigma^2_{X_i} \n= \\sigma^2_{T_i} + \\sigma^2_{E_i}.\n$$\n\nAll’interno del modello fattoriale, la *varianza del valore vero*\n($\\sigma^2_{T_i}$) corrisponde alla varianza del termine\n$\\bigl(\\sum_{j=1}^p \\lambda_j\\bigr)\\,\\xi_i$. Poiché $\\xi_i$ ha\nvarianza unitaria ($\\mathbb{V}(\\xi_i)=1$), si ha:\n\n$$\n\\sigma^2_{T_i}\n= \\mathbb{V}\\Biggl[\\biggl(\\sum_{j=1}^p \\lambda_j\\biggr)\\,\\xi_i\\Biggr]\n= \\biggl(\\sum_{j=1}^p \\lambda_j\\biggr)^2 \\,\\mathbb{V}(\\xi_i)\n= \\biggl(\\sum_{j=1}^p \\lambda_j\\biggr)^2.\n$$\n\nLa *varianza dell’errore* ($\\sigma^2_{E_i}$), invece, è la varianza\ndella somma degli errori unici $\\sum_{j=1}^p \\delta_{ji}$. Nel\nmodello fattoriale, si assume che gli errori $\\delta_{ji}$ siano\nincorrelati tra loro, per cui:\n\n$$\n\\sigma^2_{E_i}\n= \\mathbb{V}\\Biggl(\\sum_{j=1}^p \\delta_{ji}\\Biggr)\n= \\sum_{j=1}^p \\mathbb{V}(\\delta_{ji})\n= \\sum_{j=1}^p \\Psi_j,\n$$\n\ndove $\\Psi_j$ è la varianza (unicità) associata all’errore dell’item\n$j$. \n\n### Errore standard di misurazione\n\nNella CTT, *l’errore standard di misurazione* di un test quantifica, in\nmedia, quanto il punteggio osservato può differire dal valore vero\n$T_i$. Nel modello fattoriale, **l’errore standard di misurazione del\npunteggio totale** è la radice quadrata della somma delle varianze degli\nerrori unici:\n\n$$\n\\sigma_E \n= \\sqrt{\\sigma^2_{E_i}}\n= \\sqrt{\\sum_{j=1}^p \\Psi_j}.\n$$\n\nQuesto fornisce una visione fattoriale dell’errore di misurazione: la\nprecisione di un test (intesa come minore ampiezza dell’errore) aumenta\nal diminuire della somma delle unicità dei singoli item.\n\n**In sintesi**, il modello fattoriale arricchisce il tradizionale concetto di errore standard di misurazione della CTT, mostrando che l’errore\n(*specifico* o *unico*) di ciascun item influisce cumulativamente sulla\nprecisione del punteggio totale. In altre parole, **gli item che\npresentano carichi fattoriali elevati** contribuiscono a ridurre\nl’errore complessivo di misurazione, mentre **le loro corrispettive\nunicità** (varianze specifiche non spiegate dal fattore comune)\naumentano l’incertezza del punteggio totale. Questo legame tra CTT e\nanalisi fattoriale offre *un’ottica ulteriore* per comprendere e\nquantificare la precisione dei test psicometrici.\n\n\n## Un esempio concreto\n\nVediamo ora come applicare i concetti del modello monofattoriale e\ndell’errore standard di misurazione a un caso reale. Utilizzeremo i dati\nraccolti per la validazione italiana del *Cognitive Style Questionnaire\n– Short Form* (CSQ-SF, Meins et al. 2012). Questo questionario, volto a\nmisurare la vulnerabilità all’ansia e alla depressione, comprende cinque\nsottoscale: *Internality* (`I`), *Globality* (`G`), *Stability* (`S`),\n*Negative consequences* (`N`) e *Self-worth* (`W`). Sebbene la\nsottoscala di *Internality* risulti problematica, la includiamo\nnell’analisi per illustrare la procedura completa.\n\n\n### Lettura e ispezione preliminare dei dati\n\nIn $\\textsf{R}$, carichiamo il dataset e ne verifichiamo la dimensione\n($n$, numero di partecipanti). Per una prima esplorazione, calcoliamo\nle statistiche descrittive (`psych::describe(...)`) e visualizziamo la\nmatrice di correlazione con `psych::pairs.panels(...)`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncsq <- rio::import(here::here(\"data\", \"csq540.csv\"))\nn <- nrow(csq)                 # Numero di partecipanti\npsych::describe(csq, type = 2) # Statistiche descrittive\n#>   vars   n  mean    sd median trimmed   mad min max range  skew kurtosis\n#> I    1 540 47.76  5.78     48   47.87  4.45  21  64    43 -0.31     1.07\n#> G    2 540 45.00 11.94     42   44.55 11.86  16  78    62  0.34    -0.70\n#> S    3 540 44.60 12.18     42   44.24 13.34  16  77    61  0.27    -0.77\n#> N    4 540 22.01  6.92     21   21.86  7.41   8  39    31  0.21    -0.74\n#> W    5 540 44.05 13.10     43   43.66 13.34  16  79    63  0.31    -0.53\n#>     se\n#> I 0.25\n#> G 0.51\n#> S 0.52\n#> N 0.30\n#> W 0.56\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npsych::pairs.panels(csq)       # Matrice di correlazione\n```\n\n::: {.cell-output-display}\n![](03_analisi_fattoriale_2_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nNe emerge che la sottoscala *Internality* (`I`) presenta alcune criticità\n— aspetto già segnalato in letteratura.\n\n### Specifica e stima di un modello unifattoriale\n\nPer analizzare i dati secondo un modello fattoriale a un solo fattore,\nusiamo la sintassi del pacchetto `lavaan`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_csq <- \"\n  F =~ NA*I + G + S + N + W\n  F ~~ 1*F\n\"\nfit <- lavaan:::cfa(mod_csq, data = csq)\n```\n:::\n\n\n\n\n- Nella prima riga, `F =~ NA*I + G + S + N + W` indichiamo che il fattore\n  `F` è definito dai cinque item/sottoscale (`I, G, S, N, W`), con\n  parametro `NA` per lasciare libera la stima della prima saturazione.\n- Nella seconda riga, `F ~~ 1*F` impone varianza unitaria per il fattore\n  `F`.\n\nOtteniamo il resoconto completo con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit, standardized = TRUE, fit.measures = TRUE)\n#> lavaan 0.6-19 ended normally after 26 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        10\n#> \n#>   Number of observations                           540\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                46.716\n#>   Degrees of freedom                                 5\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              2361.816\n#>   Degrees of freedom                                10\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.982\n#>   Tucker-Lewis Index (TLI)                       0.965\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -8741.781\n#>   Loglikelihood unrestricted model (H1)      -8718.423\n#>                                                       \n#>   Akaike (AIC)                               17503.562\n#>   Bayesian (BIC)                             17546.478\n#>   Sample-size adjusted Bayesian (SABIC)      17514.734\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.124\n#>   90 Percent confidence interval - lower         0.093\n#>   90 Percent confidence interval - upper         0.158\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    0.989\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.033\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   F =~                                                                  \n#>     I                 0.725    0.253    2.867    0.004    0.725    0.126\n#>     G               -11.322    0.384  -29.481    0.000  -11.322   -0.949\n#>     S               -11.342    0.398  -28.513    0.000  -11.342   -0.932\n#>     N                -6.163    0.233  -26.398    0.000   -6.163   -0.891\n#>     W               -11.598    0.444  -26.137    0.000  -11.598   -0.886\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     F                 1.000                               1.000    1.000\n#>    .I                32.840    2.000   16.420    0.000   32.840    0.984\n#>    .G                14.038    1.473    9.532    0.000   14.038    0.099\n#>    .S                19.508    1.718   11.353    0.000   19.508    0.132\n#>    .N                 9.847    0.725   13.573    0.000    9.847    0.206\n#>    .W                36.892    2.685   13.737    0.000   36.892    0.215\n```\n:::\n\n\n\n\ne le stime dei parametri con:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameterEstimates(fit)\n#>    lhs op rhs     est    se       z pvalue ci.lower ci.upper\n#> 1    F =~   I   0.725 0.253   2.867  0.004    0.229    1.220\n#> 2    F =~   G -11.322 0.384 -29.481  0.000  -12.075  -10.569\n#> 3    F =~   S -11.342 0.398 -28.513  0.000  -12.122  -10.563\n#> 4    F =~   N  -6.163 0.233 -26.398  0.000   -6.621   -5.705\n#> 5    F =~   W -11.598 0.444 -26.137  0.000  -12.467  -10.728\n#> 6    F ~~   F   1.000 0.000      NA     NA    1.000    1.000\n#> 7    I ~~   I  32.840 2.000  16.420  0.000   28.920   36.759\n#> 8    G ~~   G  14.038 1.473   9.532  0.000   11.151   16.924\n#> 9    S ~~   S  19.508 1.718  11.353  0.000   16.140   22.876\n#> 10   N ~~   N   9.847 0.725  13.573  0.000    8.425   11.269\n#> 11   W ~~   W  36.892 2.685  13.737  0.000   31.628   42.155\n```\n:::\n\n\n\n\nIn particolare, ci soffermiamo sulle *unicità* (varianze specifiche di\nciascuna sottoscala), accessibili da:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npsi <- parameterEstimates(fit)$est[7:11]\npsi\n#> [1] 32.840 14.038 19.508  9.847 36.892\n```\n:::\n\n\n\n\n\n### Stima dell’errore standard di misurazione tramite il modello fattoriale\n\nNel modello fattoriale monofattoriale, *l’errore standard di\nmisurazione* di un punteggio totale è la radice quadrata della somma\ndelle varianze specifiche (unicità). Con le stime ottenute da lavaan,\nbasta sommare i valori $\\psi_j$ e prenderne la radice quadrata:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsqrt(sum(psi))\n#> [1] 10.64\n```\n:::\n\n\n\n\nQuesto valore rappresenta l’errore standard complessivo del *punteggio\ntotale* calcolato sui cinque item (sottoscale).\n\n\n### Confronto con la formula della CTT\n\nRicordiamo la *formula classica* per l’errore standard di misurazione\nnella **Classical Test Theory (CTT)**:\n\n$$\n\\sigma_E = \\sigma_X \\sqrt{1 - \\rho_{XX'}},\n$$\n\ndove $\\sigma_X$ è la *deviazione standard del punteggio totale* e\n$\\rho_{XX'}$ è l’*attendibilità* (affidabilità) del test.\n\n1. Calcoliamo il **punteggio totale** come somma delle sottoscale:\n\n\n\n\n   ::: {.cell layout-align=\"center\"}\n   \n   ```{.r .cell-code}\n   tot_score <- rowSums(csq)\n   ```\n   :::\n\n\n\n\n2. Otteniamo la **deviazione standard** di `tot_score`:\n\n\n\n\n   ::: {.cell layout-align=\"center\"}\n   \n   ```{.r .cell-code}\n   sigma <- sd(tot_score)\n   sigma\n   #> [1] 41.26\n   ```\n   :::\n\n\n\n\n3. Stimiamo l’**attendibilità** $\\rho_{XX'}$ (qui indicata da\n   $\\Omega$) con la funzione `semTools::reliability()` applicata\n   all’oggetto `fit` prodotto da `lavaan`:\n\n\n\n\n   ::: {.cell layout-align=\"center\"}\n   \n   ```{.r .cell-code}\n   rel <- semTools::reliability(fit)\n   rel\n   #>             F\n   #> alpha  0.8507\n   #> omega  0.9330\n   #> omega2 0.9330\n   #> omega3 0.9273\n   #> avevar 0.7917\n   ```\n   :::\n\n\n\n\n   Il valore di $\\Omega$ è tipicamente riportato nella seconda riga di\n   `rel`.\n\n4. Applichiamo la formula:\n\n\n\n\n   ::: {.cell layout-align=\"center\"}\n   \n   ```{.r .cell-code}\n   sigma * sqrt(1 - rel[2])\n   #> [1] 10.68\n   ```\n   :::\n\n\n\n\nIl valore ottenuto risulta molto simile all’errore standard di\nmisurazione calcolato con la formula di derivazione fattoriale\n$\\sqrt{\\sum_{j=1}^p \\Psi_j}$, a conferma della coerenza tra il\nmodello fattoriale e la CTT.\n\n\n### Correlazioni riprodotte dal modello\n\nPer ispezionare *come* il modello unifattoriale “ricostruisce” le\ncorrelazioni tra le variabili, possiamo estrarre:\n\n- La **matrice di correlazione riprodotta**:\n\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  cor_mat <- lavInspect(fit, \"cor.ov\")\n  cor_mat\n  #>        I      G      S      N      W\n  #> I  1.000                            \n  #> G -0.119  1.000                     \n  #> S -0.117  0.885  1.000              \n  #> N -0.112  0.846  0.830  1.000       \n  #> W -0.111  0.841  0.825  0.789  1.000\n  ```\n  :::\n\n\n\n\n- Le **saturazioni fattoriali standardizzate** (loadings):\n\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  l <- inspect(fit, what=\"std\")$lambda\n  l\n  #>        F\n  #> I  0.126\n  #> G -0.949\n  #> S -0.932\n  #> N -0.891\n  #> W -0.886\n  ```\n  :::\n\n\n\n\nNel modello monofattoriale, la **correlazione predetta** tra due\nvariabili manifeste (ad esempio `I` e `G`) è data dal *prodotto* delle\nloro saturazioni. Se `l[1]` è la saturazione di `I` e `l[2]` quella di\n`G`, allora:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nl[1] * l[2]\n#> [1] -0.1192\n```\n:::\n\n\n\n\nrestituisce la correlazione stimata per queste due sottoscale. Per\nvisualizzare la *matrice completa* delle correlazioni riprodotte dal\nmodello, calcoliamo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nl %*% t(l) |> round(3)\n#>        I      G      S      N      W\n#> I  0.016 -0.119 -0.117 -0.112 -0.111\n#> G -0.119  0.901  0.885  0.846  0.841\n#> S -0.117  0.885  0.868  0.830  0.825\n#> N -0.112  0.846  0.830  0.794  0.789\n#> W -0.111  0.841  0.825  0.789  0.785\n```\n:::\n\n\n\n\n\n### Varianza riprodotta di una variabile\n\nPrendiamo a esempio la variabile $`W`$ e confrontiamo:\n\n- La **varianza osservata**:  \n\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  var(csq$W)\n  #> [1] 171.7\n  ```\n  :::\n\n\n\n  \n- La **varianza riprodotta** dal modello: somma della varianza spiegata\n  dal fattore e della varianza residua. Poiché il caricamento fattoriale\n  standardizzato per `W` (ad esempio `-11.598` nel caso di non\n  standardizzazione, o un valore $\\lambda_W$ in quello standardizzato)\n  misura l’effetto di `F` su `W`, la parte spiegata è $\\lambda_W^2$.\n  Sommando poi la specificità (residuo), ricostruiamo la varianza\n  totale. Se prendiamo la proporzione di varianza residua rispetto a\n  quella osservata:\n\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  1 - (l^2 / var(csq$W))\n  #>       F\n  #> I 1.000\n  #> G 0.995\n  #> S 0.995\n  #> N 0.995\n  #> W 0.995\n  ```\n  :::\n\n\n\n\n  otteniamo un valore simile all’unicità stimata per `W`.\n\nProcedendo nello stesso modo per le altre sottoscale (`G`, `I`, ecc.)\npossiamo verificare la corrispondenza fra la varianza empirica e la\nvarianza spiegata dal modello unifattoriale.\n\n**In sintesi**, questo esempio illustra come, in un modello unifattoriale, sia possibile\ncollegare:\n\n1. **errori standard di misurazione** (CTT) e **somme di unicità** degli\n   item (analisi fattoriale);\n2. **correlazioni osservate** e **correlazioni riprodotte** dal modello\n   mediante il prodotto dei carichi fattoriali;\n3. **varianza osservata** e **varianza ricostruita** come somma di\n   varianza comune (fattore) e varianza residua (unicità).\n\nLa coerenza dei risultati fra CTT e analisi fattoriale ribadisce la loro\nstretta complementarità nello studio dell’affidabilità e della struttura\nlatente di un test psicometrico.\n\n\n## Correlazione tra variabili manifeste e fattore comune\n\nNel *modello unifattoriale*, la *saturazione fattoriale* $\\lambda_i$\ndella variabile manifesta $Y_i$ corrisponde teoricamente alla\n*correlazione* tra $Y_i$ e il *fattore comune* $\\xi$. Tuttavia,\nperché ciò risulti evidente in un’applicazione reale, è necessario poter\ndisporre di una *stima* dei punteggi fattoriali per ciascun\npartecipante, cioè i valori (stimati) del fattore comune $\\xi_i$. In\n$\\textsf{R}$, con `lavaan` possiamo ricavare i **punteggi fattoriali**\nusando la funzione `lavPredict(fit)`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(lavPredict(fit)) |> print()\n#>            F\n#> [1,]  0.2694\n#> [2,] -0.9111\n#> [3,]  0.1871\n#> [4,] -0.3316\n#> [5,]  0.8307\n#> [6,]  1.1535\ndim(lavPredict(fit))\n#> [1] 540   1\n```\n:::\n\n\n\n\n- `head(lavPredict(fit))` mostra le prime righe dei punteggi fattoriali\n  stimati per i soggetti.\n- `dim(lavPredict(fit))` conferma che abbiamo un punteggio per ognuno\n  dei 540 soggetti nel dataset.\n\nPer verificare in concreto la relazione tra $\\lambda_i$ e la\ncorrelazione di $Y_i$ con il fattore comune, calcoliamo la\n*correlazione* tra i valori osservati su ciascuna sottoscala del CSQ e\nle stime dei punteggi fattoriali (ossia $\\hat{\\xi}$):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nc(\n  cor(csq$I, lavPredict(fit)),\n  cor(csq$G, lavPredict(fit)),\n  cor(csq$S, lavPredict(fit)),\n  cor(csq$N, lavPredict(fit)),\n  cor(csq$W, lavPredict(fit))\n) |> \n  round(3)\n#> [1]  0.128 -0.970 -0.952 -0.910 -0.905\n```\n:::\n\n\n\n\nI risultati ottenuti sono molto *simili* (ma non necessariamente\nidentici) alle saturazioni fattoriali riportate in:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninspect(fit, what=\"std\")$lambda\n#>        F\n#> I  0.126\n#> G -0.949\n#> S -0.932\n#> N -0.891\n#> W -0.886\n```\n:::\n\n\n\n\nLa piccola differenza riscontrata è dovuta al fatto che i punteggi\nfattoriali $\\hat{\\xi}_i$ sono *stime* e non i valori reali del fattore\nlatente, quindi non coincidono esattamente con $\\xi_i$. Ciò nonostante,\nse il modello è ben specificato e i dati si adattano in modo\nsoddisfacente, le correlazioni tra punteggi osservati e fattore stimato\nrisulteranno prossime alle saturazioni fattoriali teoriche.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] dagitty_0.3-4     ggdag_0.2.13      ggokabeito_0.1.0  see_0.11.0       \n#>  [5] MASS_7.3-65       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#>  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#> [13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12     \n#> [17] scales_1.3.0      markdown_1.13     knitr_1.50        lubridate_1.9.4  \n#> [21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#> [25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#> [29] tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.1      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.2.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   curl_6.2.1          broom_1.0.7        \n#>  [16] Formula_1.2-5       htmlwidgets_1.6.4   plyr_1.8.9         \n#>  [19] sandwich_3.1-1      rio_1.2.3           emmeans_1.10.7     \n#>  [22] zoo_1.8-13          igraph_2.1.4        mime_0.13          \n#>  [25] lifecycle_1.0.4     pkgconfig_2.0.3     Matrix_1.7-3       \n#>  [28] R6_2.6.1            fastmap_1.2.0       rbibutils_2.3      \n#>  [31] shiny_1.10.0        digest_0.6.37       OpenMx_2.21.13     \n#>  [34] fdrtool_1.2.18      colorspace_2.1-1    rprojroot_2.0.4    \n#>  [37] Hmisc_5.2-3         timechange_0.3.0    abind_1.4-8        \n#>  [40] compiler_4.4.2      withr_3.0.2         glasso_1.11        \n#>  [43] htmlTable_2.4.3     backports_1.5.0     carData_3.0-5      \n#>  [46] R.utils_2.13.0      ggsignif_0.6.4      corpcor_1.6.10     \n#>  [49] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [52] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [55] nnet_7.3-20         R.oo_1.27.0         glue_1.8.0         \n#>  [58] quadprog_1.5-8      nlme_3.1-167        promises_1.3.2     \n#>  [61] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [64] cluster_2.1.8.1     reshape2_1.4.4      generics_0.1.3     \n#>  [67] gtable_0.3.6        tzdb_0.5.0          R.methodsS3_1.8.2  \n#>  [70] data.table_1.17.0   hms_1.1.3           tidygraph_1.3.1    \n#>  [73] car_3.1-3           sem_3.1-16          pillar_1.10.1      \n#>  [76] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [79] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [82] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [85] reformulas_0.4.0    V8_6.0.2            stats4_4.4.2       \n#>  [88] xfun_0.51           qgraph_1.9.8        arm_1.14-4         \n#>  [91] stringi_1.8.4       yaml_2.3.10         pacman_0.5.1       \n#>  [94] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#>  [97] mi_1.1              cli_3.6.4           RcppParallel_5.1.10\n#> [100] rpart_4.1.24        xtable_1.8-4        Rdpack_2.6.3       \n#> [103] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [106] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [109] jpeg_0.1-10         lme4_1.1-36         mvtnorm_1.3-3      \n#> [112] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-28    \n#> [115] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "03_analisi_fattoriale_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
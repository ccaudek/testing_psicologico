{
  "hash": "909dcade2e47b8b539dea94207dc4e30",
  "result": {
    "engine": "knitr",
    "markdown": "# Il modello statistico dell'analisi fattoriale {#sec-fa-statistical-model-fa}\n\n**Prerequisiti**\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n\n**Concetti e Competenze Chiave**\n\n**Preparazione del Notebook**\n\n\n\n\n::: {.cell vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |> source()\n\n# Carica pacchetti aggiuntivi\npacman::p_load(lavaan)\n```\n:::\n\n\n\n\n## Modello monofattoriale\n\nIl punto di partenza dell'*analisi fattoriale esplorativa* è\nrappresentato da una marice di dimensioni $p \\times p$ (dove $p$ è il\nnumero di variabili osservate) che contiene i coefficienti di\ncorrelazione (o di covarianza) tra le variabili. Il punto di arrivo è\nrappresentato da una matrice di dimensioni $p \\times k$ (dove $k$) è il\nnumero di fattori comuni che contiene i coefficienti (le *saturazioni*)\nche esprimono la relazione tra i fattori e le variabili osservate.\nConsidereremo ora il modello matematico dell'analisi fattoriale\nesplorativa, con un solo fattore comune, che rappresenta il caso più\nsemplice.\n\nCon $p$ variabili manifeste $Y_i$, il modello ad un fattore comune può\nessere espresso algebricamente nel modo seguente:\n\n$$\nY_i = \\mu_i + \\lambda_{i} \\xi + \\delta_i \\qquad i=1, \\dots, p\n$$ \n\ndove $\\xi$ rappresenta il fattore latente, chiamato anche *fattore comune*,\npoiché è comune a tutte le $Y_i$, i $\\delta_i$ sono invece specifici di\nogni variabile osservata e per tale ragione vengono chiamati *fattori\nspecifici* o *unici*, e infine i $\\lambda_i$ sono detti *saturazioni* (o\n*pesi*) fattoriali poiché consentono di valutare il peso del fattore\nlatente su ciascuna variabile osservata. Si suole assumere per comodità\nche $\\mu=0$, il che corrisponde a considerare le variabili $Y_i$ come\nottenute dagli scarti dalle medie $\\mu_i$ per $i = 1, \\dots, p$:\n\n$$\nY_i -\\mu_i = \\lambda_i \\xi + \\delta_i.\n$$\n\nSi assume che il fattore comune abbia media zero, $\\mathbb{E}(\\xi)=0$, e\nvarianza unitaria, $\\mathbb{V}(\\xi)=1$, che i fattori specifici abbiano media\nzero, $\\mathbb{E}(\\delta_j)=0$, e varianza $\\mathbb{V}(\\delta_j)=\\psi_{i}$, che i\nfattori specifici siano incorrelati tra loro, $\\mathbb{E}(\\delta_i \\delta_k)=0$, e che i fattori specifici siano incorrelati con il fattore comune, $\\mathbb{E}(\\delta_i \\xi)=0$.\n\nIn questo modello, poiché i fattori specifici sono tra loro incorrelati,\nl'interdipendenza tra le variabili manifeste è completamente spiegata\ndal fattore comune. Dalle ipotesi precedenti è possibile ricavare la\ncovarianza tra $Y_i$ e il fattore comune, la varianza della $i$-esima\nvariabile manifesta $Y_i$ e la covarianza tra due variabili manifeste\n$Y_i$ e $Y_k$.\n\n## Covarianza tra un indicatore e il fattore comune\n\nDal modello monofattoriale è possibile determinare l'espressione della\ncovarianza teorica tra una variabile manifesta $Y_i$ e il fattore comune\n$\\xi$: \n\n$$\nCov(Y_i,\\xi)=\\mathbb{E}(Y_i \\xi)-\\mathbb{E}(Y_i)\\mathbb{E}(\\xi).\n$$ \n\nDato che $\\mathbb{E}(\\xi)=0$, possiamo scrivere \n\n$$\n\\begin{equation}\n\\begin{aligned}\n  Cov(Y_i,\\xi) &= \\mathbb{E}(Y_i \\xi)=\\mathbb{E}[(\\lambda_i \\xi + \\delta_i) \\xi]\\notag\\\\\n  &=\\mathbb{E}(\\lambda_i \\xi^2 + \\delta_i \\xi)\\notag\\\\\n  &=\\lambda_i\\underbrace{\\mathbb{E}(\\xi^2)}_{\\mathbb{V}(\\xi)=1} + \\underbrace{\\mathbb{E}(\\delta_i \\xi)}_{Cov(\\delta_i, \\xi)=0}\\notag\\\\\n  &= \\lambda_i.\\notag\n\\end{aligned}\n\\end{equation}\n$$\n  \nNel modello a un solo fattore, dunque, la saturazione $\\lambda_j$ rappresenta la covarianza la variabile manifesta $Y_i$ e il fattore comune $\\xi$ e indica\nl'importanza del fattore nel determinare il punteggio osservato. Se le\nvariabili $Y_i$ sono standardizzate, la saturazione fattoriale\n$\\lambda_i$ corrisponde alla correlazione tra $Y_i$ e $\\xi$.\n\n## Espressione fattoriale della varianza\n\nNell'ipotesi che le variabili $Y_i$ abbiano media nulla, la varianza di $Y_i$\n\n$$\n\\begin{equation}\n  \\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) -[\\mathbb{E}(Y_i)]^2 = \\mathbb{E}(Y_i^2)\\notag\n\\end{equation}\n$$\n\nè data da\n\n$$\n\\begin{equation}\n\\begin{aligned}\n  \\mathbb{V}(Y_i) &= \\mathbb{E}[(\\lambda_i \\xi + \\delta_i)^2 ]\\notag\\\\\n  &=\\lambda_i^2 \\underbrace{\\mathbb{E}(\\xi^2) }_{\\mathbb{V}(\\xi)=1} + \\underbrace{\\mathbb{E}(\\delta_i^2) }_{\\mathbb{V}(\\delta_i)=\\psi_{i}} + 2\\lambda_i \\underbrace{\\mathbb{E}(\\xi \\delta_i) }_{Cov(\\xi, \\delta_{i})=0}\\notag\\\\\n  &=\\lambda^2_i + \\psi_{i}.\n\\end{aligned}\n\\end{equation}\n$$\n\nLa quantità $\\lambda^2_i$ è denominata *comunalità* della $i$-esima variabile\nmanifesta e corrisponde alla quota della varianza della $Y_i$ spiegata\ndal fattore comune. Di conseguenza $\\psi_{i}$ è la parte residua della\nvarianza di $Y_i$ non spiegata dal fattore comune ed è denominata\n*unicità* di $Y_i$. Nel caso di variabili standardizzate, l'unicità\ndiventa uguale a \n\n$$\n\\psi_{i}=1-\\lambda^2_i.\n$$ \n\nIn definitiva, la varianza totale di una variabile osservata può essere divisa in una quota che ciascuna variabile condivide con le altre variabili ed è spiegata dal\nfattore comune (questa quota è chiamata *comunalità* ed è uguale uguale\nal quadrato della saturazione della variabile osservata nel fattore\ncomune, ovvero $h^2_i = \\lambda_i^2$), e in una quota che è spiegata dal\nfattore specifico (questa parte è chiamata *unicità* ed è\nuguale a $u_i = \\psi_{i}$).\n\n**Esempio.** Riprendiamo l'analisi della matrice di correlazioni di Spearman.\nNell'output prodotto dalla funzione `factanal()` viene riportata la\nquantità denominata `SS loadings`. Tale quantità indica la porzione della varianza totale delle 4 variabili manifeste che viene spiegata dal fattore comune. Ciascuna variabile\nstandardizzata contribuisce con un'unità di varianza; nel caso presente,\ndunque la varianza totale è uguale a 4. Si ricordi che, nella statistica multivariata, per *varianza totale* si intende la somma delle varianze delle variabili manifeste (nel linguaggio dell'algebra matriciale questa quantità corrisponde alla *traccia* della matrice di covarianze). La quota della varianza totale spiegata dal modello, invece, è data dalla somma delle comunalità delle quattro variabili, ovvero dalla somma delle saturazioni fattoriali innalzate al quadrato.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nSpearman <- matrix(c(\n  1.0, .78, .70, .66,\n  .78, 1.0, .64, .54,\n  .70, .64, 1.0, .45,\n  .66, .54, .45, 1.0\n),\nbyrow = TRUE, ncol = 4\n)\nrownames(Spearman) <- c(\"C\", \"E\", \"M\", \"P\")\ncolnames(Spearman) <- c(\"C\", \"E\", \"M\", \"P\")\nSpearman |>\n  print()\n#>      C    E    M    P\n#> C 1.00 0.78 0.70 0.66\n#> E 0.78 1.00 0.64 0.54\n#> M 0.70 0.64 1.00 0.45\n#> P 0.66 0.54 0.45 1.00\n```\n:::\n\n\n\n\nEseguiamo l'analisi fattoriale:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nfm <- factanal(covmat = Spearman, factors = 1)\nfm |>\n    print()\n#> \n#> Call:\n#> factanal(factors = 1, covmat = Spearman)\n#> \n#> Uniquenesses:\n#>     C     E     M     P \n#> 0.086 0.329 0.460 0.539 \n#> \n#> Loadings:\n#>   Factor1\n#> C 0.956  \n#> E 0.819  \n#> M 0.735  \n#> P 0.679  \n#> \n#>                Factor1\n#> SS loadings      2.587\n#> Proportion Var   0.647\n#> \n#> The degrees of freedom for the model is 2 and the fit was 0.023\n```\n:::\n\n\n\n\nLe saturazioni fattoriali sono:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nL <- c(fm$load[1], fm$load[2], fm$load[3], fm$load[4])\nprint(L)\n#> [1] 0.956 0.819 0.735 0.679\n```\n:::\n\n\n\n\nFacendo il prodotto interno otteniamo:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nt(L) %*% L \n#>      [,1]\n#> [1,] 2.59\n```\n:::\n\n\n\n\nIn termini proporzionali, la quota della varianza totale delle variabile manifeste che viene spiegata dal modello ad un fattore comune è dunque uguale a $2.587 / 4 = 0.647$. Questa quantità è indicata nell'output con la denominazione `Proportion Var`.\n\nSi dice unicità (*uniqueness*) la quota della varianza della variabile considerata che non viene spiegata dalla soluzione fattoriale:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nround(fm$uniqueness, 3) |>\n    print()\n#>     C     E     M     P \n#> 0.086 0.329 0.460 0.539\n```\n:::\n\n\n\n\nLa comunalità (ovvero, la quota di varianza di ciascuna variabile manifesta che viene spiegata dal fattore comune) può essere trovata come:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nround(1 - fm$uniqueness, 3) |>\n    print()\n#>     C     E     M     P \n#> 0.914 0.671 0.540 0.461\n```\n:::\n\n\n\n\noppure con\n\n\n\n\n::: {.cell layout-align=\"center\" lines_to_next_cell='0' vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nL^2 |>\n    round(3) |>\n    print()\n#> [1] 0.914 0.671 0.540 0.461\n```\n:::\n\n\n\n\n## Covarianza tra due variabili manifeste\n\nNell'ipotesi che le variabili $Y_i$ abbiano media nulla, la covarianza\ntra $Y_i$ e $Y_k$\n\n$$\nCov(Y_i, Y_k)=\\mathbb{E}(Y_i Y_k) -\n\\mathbb{E}(Y_i)\\mathbb{E}(Y_k)=\\mathbb{E}(Y_i Y_k)\n$$\n\nè uguale al prodotto delle corrispondenti saturazioni fattoriali:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n Cov(Y_i, Y_k) &= \\mathbb{E}(Y_i Y_k) \\notag\\\\\n  & =\\mathbb{E}[(\\lambda_i \\xi + \\delta_i)(\\lambda_k \\xi +  \\delta_k)]\\notag\\\\\n  &=\\mathbb{E}(\\lambda_i\\lambda_k\\xi^2 + \\lambda_i  \\xi \\delta_k + \\lambda_k \\delta_i \\xi + \\delta_i \\delta_k)\\notag\\\\\n  &=\\lambda_i\\lambda_k\\underbrace{\\mathbb{E}(\\xi^2)}_{\\mathbb{V}(\\xi)=1}+\\lambda_i\\underbrace{\\mathbb{E}(\\xi \\delta_k)}_{Cov(\\xi, \\delta_k) =0}+\\notag\\\\ \\;&+\\lambda_k\\underbrace{\\mathbb{E}(\\delta_i \\xi)}_{Cov(\\delta_i, \\xi) =0} +\\underbrace{\\mathbb{E}(\\delta_i \\delta_k)}_{Cov(\\delta_i, \\delta_k)=0}\\notag\\\\\n  &=\\lambda_i\\lambda_k.\n\\end{aligned}\n\\end{equation}\n$$\n\n## Correlazioni osservate e correlazioni riprodotte dal modello\n\nIn generale possiamo affermare che il modello monofattoriale è adeguato\nse si verifica che $Cov(Y_i, Y_k \\mid \\xi) = 0$\n($i, k = 1, \\dots,p; \\; i\\neq k$), ossia se il fattore comune spiega\ntutta la covarianza tra le variabili osservate. La matrice di\ncorrelazioni riprodotte dal modello è chiamata $\\boldsymbol{\\Sigma}$ e\npuò essere espressa come:\n\n$$\n\\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^\\prime + \\boldsymbol{\\Psi}\n$$\n\nIn altri termini, il modello monofattoriale è adeguato se è nulla la\ndifferenza tra la matrice di correlazioni osservate e la matrice di\ncorrelazioni riprodotte dal modello. Per i dati di Spearman, le\ncorrelazioni riprodotte dal modello ad un fattore sono\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nround(L %*% t(L) + diag(fm$uniq), 3)\n#>       [,1]  [,2]  [,3]  [,4]\n#> [1,] 1.000 0.784 0.703 0.649\n#> [2,] 0.784 1.000 0.602 0.556\n#> [3,] 0.703 0.602 1.000 0.499\n#> [4,] 0.649 0.556 0.499 1.000\n```\n:::\n\n\n\n\nLa matrice delle differenze tra le correlazioni campionarie e quelle\nriprodotte è\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nround(Spearman - (L %*% t(L) + diag(fm$uniq)), 3) \n#>        C      E      M      P\n#> C  0.000 -0.004 -0.003  0.011\n#> E -0.004  0.000  0.038 -0.016\n#> M -0.003  0.038  0.000 -0.049\n#> P  0.011 -0.016 -0.049  0.000\n```\n:::\n\n\n\n\nLo scarto maggiore tra le correlazioni campionarie e quelle riprodotte è\nuguale a 0.049. Si può dunque concludere che il modello monofattoriale\nspiega in maniera ragionevole i dati di Spearman.\n\n## Bontà di adattamento del modello ai dati\n\nLa verifica della bontà di adattamento del modello ai dati si determina\nmediante un test statistico che valuta la differenza tra la matrice di\ncorrelazioni (o di covarianze) osservata e la matrice di correlazioni (o\ncovarianze) predetta dal modello fattoriale. L'ipotesi nulla che viene\nvalutata è che la matrice delle correlazioni residue sia dovuta\nsemplicemente agli errori di campionamento, ovvero che la matrice di\ncorrelazioni predetta dal modello $\\boldsymbol{\\Sigma}(\\theta)$ sia\nuguale alla matrice di correlazioni $\\boldsymbol{\\Sigma}$ nella\npopolazione.\n\nLa statistica test $v$ è una funzione della differenza tra la matrice\nriprodotta $\\boldsymbol{S}(\\theta)$ e quella osservata $\\boldsymbol{S}$\n\n$$\nv = f\\left[\\boldsymbol{S}(\\theta) - \\boldsymbol{S}\\right]\n$$\n\ne si distribuisce come una $\\chi^2$ con $\\nu$ gradi di libertà\n\n$$\n\\nu = p(p+1)/ 2 - q,\n$$\n\ndove $p$ è il numero di variabili manifeste e\n$q$ è il numero di parametri stimati dal modello fattoriale (ovvero,\n$\\lambda$ e $\\psi$). \n\nLa statistica $v$ assume valore 0 se i parametri del modello riproducono esattamente la matrice di correlazioni tra le variabili nella popolazione. Tanto maggiore è la statistica $v$ tanto maggiore è la discrepanza tra le correlazioni osservate e quelle\npredette dal modello fattoriale. \n\nUn risultato statisticamente significativo (es., $p$ \\< .05) -- il quale suggerisce che una tale differenza *non* è uguale a zero -- rivela dunque una discrepanza tra il modello e i dati. Il test del modello fattoriale mediante la statistica $\\chi^2$\nsegue dunque una logica diversa da quella utilizzata nei normali test di\nipotesi statistiche: *un risultato statisticamente significativo indica una mancanza di adattamento del modello ai dati*.\n\nL'applicazione del test $\\chi^2$ per valutare la bontà di adattamento del modello ai dati richiede che ciascuna variabile manifesta sia distribuita normalmente -- più precisamente, richiede che le variabili manifeste siano un campione casuale che deriva da una normale\nmultivariata. Questo requisito non è facile da rispettare in pratica.\n\nTuttavia, il limite principale della statistica $\\chi^2$ è che essa dipende fortemente dalle dimensioni del campione: al crescere delle dimensioni campionarie è più facile ottenere un risultato statisticamente significativo (ovvero, concludere che vi è un cattivo adattamento del modello ai dati). Per questa ragione, la bontà di adattamento del modello ai dati viene valutata da molteplici indici, non soltanto dalla statistica $\\chi^2$. Più comune è calcolare il rapporto $\\chi^2 / \\nu$ e usare tale rapporto per valutare la bontà dell'adattamento. Valori minori di 3 o 4 suggeriscono che il modello ben si adatta ai dati.\n\n## L'errore standard della misurazione e il modello fattoriale\n\nIn questa sezione, approfondiamo la connessione tra l'errore standard di misurazione, un concetto fondamentale della Classical Test Theory (CTT), e l'applicazione del modello fattoriale. Questa connessione ci permette di reinterpretare l'errore standard di misurazione attraverso il prisma dell'analisi fattoriale. Procediamo con un'esposizione dettagliata.\n\nAll'interno della CTT, si afferma che il punteggio ottenuto ($X$) in un test corrisponde alla somma del valore vero ($T$) e dell'errore di misurazione ($E$), dove $E$ è considerato una variabile casuale indipendente da $T$. Se focalizziamo l'attenzione sul soggetto $i$-esimo, la formula diventa $X_i = T_i + E_i$, con $T_i$ rappresentante il valore vero e $E_i$ l'errore di misurazione, quest'ultimo avente media zero.\n\nTrasformiamo questa relazione nel contesto di un modello fattoriale monofattoriale che coinvolge $p$ variabili osservate (o item). Per ogni item, la relazione è espressa come:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n Y_{1i} &=  \\lambda_1 \\xi_i + \\delta_{1i} \\notag\\\\\n Y_{2i} &=  \\lambda_2 \\xi_i + \\delta_{2i} \\notag\\\\\n  \\dots\\notag\\\\\n Y_{pi} &=  \\lambda_p \\xi_i + \\delta_{pi}, \\notag\n \\end{aligned}\n \\end{equation}\n $$\n\ndove $Y_{ji}$ rappresenta il punteggio osservato per l'item $j$ del soggetto $i$, $\\lambda_j$ è il carico fattoriale dell'item $j$ sul fattore comune $\\xi_i$, e $\\delta_{ji}$ è l'errore unico associato all'item $j$ per il soggetto $i$.\n\nIl punteggio totale $X_i$ per il soggetto $i$-esimo deriva dalla somma dei punteggi di ciascun item, il che si traduce in:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n X_i &= \\sum_{j=1}^p Y_{ji} = \\sum_{j=1}^p \\lambda_j \\xi_i + \\sum_{j=1}^p \\delta_{ji}\\notag\\\\[12pt]\n  &=  \\left( \\sum_{j=1}^p \\lambda_j \\right) \\xi_i  +  \\sum_{j=1}^p \\delta_{ji} \\notag\\\\[12pt]\n  &= T_i + E_i\\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nRispettando la struttura della CTT, la varianza del punteggio osservato $X_i$ si decompone in due componenti fondamentali: la varianza del valore vero $\\sigma^2_{T_i}$ e la varianza dell'errore $\\sigma^2_{E_i}$. Nel contesto dell'analisi fattoriale, $\\sigma^2_{T_i}$ corrisponde al quadrato della somma dei carichi fattoriali:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n \\sigma^2_{T_i} &= \\mathbb{V}\\left[ \\left( \\sum_{j=1}^p \\lambda_j \\right) \\xi_i \\right]\\notag\\\\\n &= \\left( \\sum_{j=1}^p \\lambda_j \\right)^2 \\mathbb{V}(\\xi_i)\\notag\\\\\n &= \\left( \\sum_{j=1}^p \\lambda_j \\right)^2 \\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nInoltre, considerando la varianza dell'errore di misurazione $\\sigma^2_{E_i}$ nel contesto fattoriale, questa è equivalente alla somma delle varianze degli errori unici ($\\delta_{ji}$), ovvero le unicità:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n \\sigma^2_{E_i} &= \\mathbb{V}\\left( \\sum_{j=1}^p \\delta_{ji} \\right)\\notag\\\\\n &= \\sum_{j=1}^p \\mathbb{V}\\left( \\delta_{ji} \\right)\\notag\\\\\n &= \\sum_{j=1}^p \\Psi_j\\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nPertanto, nel contesto dell'analisi fattoriale, l'errore standard di misurazione per il punteggio totale del test è quantificabile come la radice quadrata della somma delle unicità:\n\n$$\n\\begin{equation}\n\\sigma_{E} = \\sqrt{\\sum_{j=1}^p \\Psi_j}\n\\end{equation}\n$$(eq-err-stnd-meas-FA)\n\nQuesto collegamento tra la CTT e l'analisi fattoriale offre una prospettiva rinnovata sull'errore standard di misurazione, arricchendo la nostra comprensione della precisione dei test psicometrici.\n\n## Un esempio concreto\n\nApplichiamo ora il risultato precedente ad un caso concreto. Consideriamo i dati utilizzati nella validazione italiana del *Cognitive Style Questionnaire - Short Form* (CSQ-SF, Meins et al. 2012). Il CSQ-SF viene utilizzato per misurare la vulnerabilità all'ansia e alla depressione. È costituito da cinque sottoscale: *Internality*, *Globality*, *Stability*, *Negative consequences* e *Self-worth*. \n\nLeggiamo i dati in $\\textsf{R}$:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ncsq <- rio::import(here::here(\"data\", \"csq540.csv\"))\n```\n:::\n\n\n\n\nIl numero di partecipanti è\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nn <- nrow(csq)\nn\n#> [1] 540\n```\n:::\n\n\n\n\nLe statistiche descrittive si ottengono con la seguente istruzione:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\npsych::describe(csq, type = 2) \n#>   vars   n mean    sd median trimmed   mad min max range  skew kurtosis\n#> I    1 540 47.8  5.78     48    47.9  4.45  21  64    43 -0.31     1.07\n#> G    2 540 45.0 11.94     42    44.5 11.86  16  78    62  0.34    -0.70\n#> S    3 540 44.6 12.18     42    44.2 13.34  16  77    61  0.27    -0.77\n#> N    4 540 22.0  6.92     21    21.9  7.41   8  39    31  0.21    -0.74\n#> W    5 540 44.0 13.10     43    43.7 13.34  16  79    63  0.31    -0.53\n#>     se\n#> I 0.25\n#> G 0.51\n#> S 0.52\n#> N 0.30\n#> W 0.56\n```\n:::\n\n\n\n\nEsaminiamo la matrice di correlazione:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\npsych::pairs.panels(csq) \n```\n\n::: {.cell-output-display}\n![](03_analisi_fattoriale_2_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nLa sottoscala di *Internality* è problematica, come messo anche in evidenza dall'autore del test. La consideriamo comunque in questa analisi statistica.\n\nSpecifichiamo il modello unifattoriale nella sintassi di `lavaan`:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nmod_csq <- \"\n   F =~ NA*I + G + S + N + W\n   F ~~ 1*F\n\" \n```\n:::\n\n\n\n\nAdattiamo il modello ai dati:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nfit <- lavaan:::cfa(\n  mod_csq,\n  data = csq\n)\n```\n:::\n\n\n\n\nEsaminiamo i risultati:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsummary(\n  fit, \n  standardized = TRUE,\n  fit.measures = TRUE\n) |>\n  print()\n#> lavaan 0.6-19 ended normally after 26 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        10\n#> \n#>   Number of observations                           540\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                46.716\n#>   Degrees of freedom                                 5\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              2361.816\n#>   Degrees of freedom                                10\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.982\n#>   Tucker-Lewis Index (TLI)                       0.965\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -8741.781\n#>   Loglikelihood unrestricted model (H1)      -8718.423\n#>                                                       \n#>   Akaike (AIC)                               17503.562\n#>   Bayesian (BIC)                             17546.478\n#>   Sample-size adjusted Bayesian (SABIC)      17514.734\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.124\n#>   90 Percent confidence interval - lower         0.093\n#>   90 Percent confidence interval - upper         0.158\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    0.989\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.033\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   F =~                                                                  \n#>     I                 0.725    0.253    2.867    0.004    0.725    0.126\n#>     G               -11.322    0.384  -29.481    0.000  -11.322   -0.949\n#>     S               -11.342    0.398  -28.513    0.000  -11.342   -0.932\n#>     N                -6.163    0.233  -26.398    0.000   -6.163   -0.891\n#>     W               -11.598    0.444  -26.137    0.000  -11.598   -0.886\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     F                 1.000                               1.000    1.000\n#>    .I                32.840    2.000   16.420    0.000   32.840    0.984\n#>    .G                14.038    1.473    9.532    0.000   14.038    0.099\n#>    .S                19.508    1.718   11.353    0.000   19.508    0.132\n#>    .N                 9.847    0.725   13.573    0.000    9.847    0.206\n#>    .W                36.892    2.685   13.737    0.000   36.892    0.215\n```\n:::\n\n\n\n\nEsaminiamo solo le stime dei parametri del modello:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nparameterEstimates(fit) |>\n    print()\n#>    lhs op rhs     est    se      z pvalue ci.lower ci.upper\n#> 1    F =~   I   0.725 0.253   2.87  0.004    0.229     1.22\n#> 2    F =~   G -11.322 0.384 -29.48  0.000  -12.075   -10.57\n#> 3    F =~   S -11.342 0.398 -28.51  0.000  -12.122   -10.56\n#> 4    F =~   N  -6.163 0.233 -26.40  0.000   -6.621    -5.71\n#> 5    F =~   W -11.598 0.444 -26.14  0.000  -12.467   -10.73\n#> 6    F ~~   F   1.000 0.000     NA     NA    1.000     1.00\n#> 7    I ~~   I  32.840 2.000  16.42  0.000   28.920    36.76\n#> 8    G ~~   G  14.038 1.473   9.53  0.000   11.151    16.92\n#> 9    S ~~   S  19.508 1.718  11.35  0.000   16.140    22.88\n#> 10   N ~~   N   9.847 0.725  13.57  0.000    8.425    11.27\n#> 11   W ~~   W  36.892 2.685  13.74  0.000   31.628    42.16\n```\n:::\n\n\n\n\nRecuperiamo le specificità:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\npsi <- parameterEstimates(fit)$est[7:11]\npsi |>\n    print()\n#> [1] 32.84 14.04 19.51  9.85 36.89\n```\n:::\n\n\n\n\nStimiamo l'errore standard della misurazione con la \\@ref(eq:err-stnd-meas-FA):\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsqrt(sum(psi)) |>\n    print()\n#> [1] 10.6\n```\n:::\n\n\n\n\nApplichiamo ora la formula della TCT:\n\n$$\n\\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}}.\n$$\n\nPer trovare $\\sigma$ calcoliamo prima il punteggio totale:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ntot_score <- rowSums(csq)\n```\n:::\n\n\n\n\nLa deviazione standard di `tot_score` ci fornisce una stima di $\\sigma_X$:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsigma <- sd(tot_score)\nsigma |>\n    print()\n#> [1] 41.3\n```\n:::\n\n\n\n\nPer applicare la formula della TCT abbiamo bisogno dell'attendibilità. La stimiamo usando la funzione `reliability` del pacchetto `semTools` dall'oggetto creato da `lavaan:::cfa()`:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nrel <- semTools::reliability(fit)\nrel |>\n    print()\n#>            F\n#> alpha  0.851\n#> omega  0.933\n#> omega2 0.933\n#> omega3 0.927\n#> avevar 0.792\n```\n:::\n\n\n\n\nUtilizzando $\\Omega$ otteniamo:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsigma * sqrt(1- rel[2]) |>\n    print()\n#> [1] 0.259\n#> [1] 10.7\n```\n:::\n\n\n\n\nSi noti come il risultato sia molto simile a quello trovato con la formula della TCT.\n\n### Correlazioni osservate e riprodotte\n\nLe correlazioni riprodotte dal modello si ottengono nel modo seguente dall'oggetto `fit`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ncor_mat <- lavInspect(fit, \"cor.ov\")\ncor_mat |>\n    print()\n#>        I      G      S      N      W\n#> I  1.000                            \n#> G -0.119  1.000                     \n#> S -0.117  0.885  1.000              \n#> N -0.112  0.846  0.830  1.000       \n#> W -0.111  0.841  0.825  0.789  1.000\n```\n:::\n\n\n\n\nAbbiamo visto come il modello unifattoriale predice che la correlazione tra due variabili manifeste sia il prodotto delle rispettive correlazioni fattoriali. Estraiamo le saturazioni fattoriali.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nl <- inspect(fit, what=\"std\")$lambda\nl |>\n    print()\n#>        F\n#> I  0.126\n#> G -0.949\n#> S -0.932\n#> N -0.891\n#> W -0.886\n```\n:::\n\n\n\n\nPer esempio, se consideriamo `I` e `G`, la correlazione predetta dal modello fattoriale tra queste due sottoscale è data dal prodotto delle rispettive saturazioni fattoriali.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nl[1] * l[2] \n#> [1] -0.119\n```\n:::\n\n\n\n\nLa matrice di correlazioni riprodotte riportata sopra mostra il risultato di questo prodotto per ciascuna coppia di variabili manifeste.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nl %*% t(l) |> round(3) |>\n    print()\n#>        I      G      S      N      W\n#> I  0.016 -0.119 -0.117 -0.112 -0.111\n#> G -0.119  0.901  0.885  0.846  0.841\n#> S -0.117  0.885  0.868  0.830  0.825\n#> N -0.112  0.846  0.830  0.794  0.789\n#> W -0.111  0.841  0.825  0.789  0.785\n```\n:::\n\n\n\n\n### Scomposizione della varianza\n\nConsideriamo la variabile manifesta `W`. Calcoliamo la varianza.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nvar(csq$W) |> print()\n#> [1] 172\n```\n:::\n\n\n\n\nLa varianza *riprodotta* di questa variabile, secondo il modello fattoriale, dovrebbe esere uguale alla somma di due componenti: la varianza predetta dall'effetto causale del fattore latente e la varianza residua.  La varianza predetta dall'effetto causale del fattore latente è uguale alla saturazione elevata al quadrato:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n(-11.598)^2 \n#> [1] 135\n```\n:::\n\n\n\n\nCalcolo ora la proporzione di varianza residua normalizzando rispetto alla varianza osservata (non a quella riprodotta dal modello):\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n1 - (-11.598)^2 / var(csq$W) \n#> [1] 0.217\n```\n:::\n\n\n\n\nIl valore così ottenuto è molto simile al valore della varianza residua di `W`. \n\nRipeto i calcoli per la variabile `G`\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n1 - (-11.322)^2 / var(csq$G) \n#> [1] 0.1\n```\n:::\n\n\n\n\ne per la variabile `I`\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n1 - (0.725)^2 / var(csq$I) \n#> [1] 0.984\n```\n:::\n\n\n\n\nIn tutti i casi, i valori ottenuti sono molto simili alle varianze residue ipotizzate dal modello unifattoriale.\n\n### Correlazione tra variabili manifeste e fattore comune\n\nUn modo per verificare il fatto che, nel modello unifattoriale, la saturazione fattoriale della $i$-esima variabile manifesta è uguale alla correlazione tra i punteggi osservati sulla i$-esima variabile manifesta e il fattore latente è quella di calcolare le correlazioni tra le variabili manifeste e i punteggi fattoriali. I punteggi fattoriali rappresentano una *stima* del punteggio \"vero\", ovvero del punteggio che ciascun rispondente otterrebbe in assenza di errori di misurazione. Vedremo in seguito come si possono stimare i punteggi fattoriali. Per ora ci limitiamo a calcolarli usando `lavaan`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nhead(lavPredict(fit)) |>\n    print()\n#>           F\n#> [1,]  0.269\n#> [2,] -0.911\n#> [3,]  0.187\n#> [4,] -0.332\n#> [5,]  0.831\n#> [6,]  1.153\n```\n:::\n\n\n\n\nAbbiamo un punteggio diverso per ciascuno dei 540 individui che appartengono al campione di dati esaminato.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ndim(lavPredict(fit))\n#> [1] 540   1\n```\n:::\n\n\n\n\nCalcoliamo ora le correlazioni tra i valori osservati su ciascuna delle cinque scale del CSQ e le stime dei punteggi veri.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nc(\n  cor(csq$I, lavPredict(fit)),\n  cor(csq$G, lavPredict(fit)),\n  cor(csq$S, lavPredict(fit)),\n  cor(csq$N, lavPredict(fit)),\n  cor(csq$W, lavPredict(fit))\n) |> \n  round(3) |>\n    print()\n#> [1]  0.128 -0.970 -0.952 -0.910 -0.905\n```\n:::\n\n\n\n\nSi noti che i valori ottenui sono molto simili ai valori delle saturazioni fattoriali. La piccola differenza tra le correlazioni ottenute e i valori delle saturazioni fattoriali dipende dal fatto che abbiamo *stimato* i punteggi fattoriali.\n\n\n\n\n::: {.cell layout-align=\"center\" lines_to_next_cell='0' vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ninspect(fit, what=\"std\")$lambda |>\n    print()\n#>        F\n#> I  0.126\n#> G -0.949\n#> S -0.932\n#> N -0.891\n#> W -0.886\n```\n:::\n\n\n\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] ggokabeito_0.1.0  see_0.10.0        MASS_7.3-64       viridis_0.6.5    \n#>  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#>  [9] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n#> [13] lavaan_0.6-19     psych_2.4.12      scales_1.3.0      markdown_1.13    \n#> [17] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#> [25] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] rio_1.2.3           emmeans_1.10.7      zoo_1.8-12         \n#>  [22] igraph_2.1.4        mime_0.12           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-2        R6_2.5.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] digest_0.6.37       OpenMx_2.21.13      fdrtool_1.2.18     \n#>  [34] colorspace_2.1-1    rprojroot_2.0.4     Hmisc_5.2-2        \n#>  [37] timechange_0.3.0    abind_1.4-8         compiler_4.4.2     \n#>  [40] withr_3.0.2         glasso_1.11         htmlTable_2.4.3    \n#>  [43] backports_1.5.0     carData_3.0-5       R.utils_2.12.3     \n#>  [46] ggsignif_0.6.4      corpcor_1.6.10      gtools_3.9.5       \n#>  [49] tools_4.4.2         pbivnorm_0.6.0      foreign_0.8-88     \n#>  [52] zip_2.3.2           httpuv_1.6.15       nnet_7.3-20        \n#>  [55] R.oo_1.27.0         glue_1.8.0          quadprog_1.5-8     \n#>  [58] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [61] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8      \n#>  [64] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [67] tzdb_0.4.0          R.methodsS3_1.8.2   data.table_1.16.4  \n#>  [70] hms_1.1.3           car_3.1-3           sem_3.1-16         \n#>  [73] pillar_1.10.1       rockchalk_1.8.157   later_1.4.1        \n#>  [76] splines_4.4.2       lattice_0.22-6      survival_3.8-3     \n#>  [79] kutils_1.73         tidyselect_1.2.1    miniUI_0.1.1.1     \n#>  [82] pbapply_1.7-2       reformulas_0.4.0    stats4_4.4.2       \n#>  [85] xfun_0.50           qgraph_1.9.8        arm_1.14-4         \n#>  [88] stringi_1.8.4       yaml_2.3.10         pacman_0.5.1       \n#>  [91] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#>  [94] mi_1.1              cli_3.6.3           RcppParallel_5.1.10\n#>  [97] rpart_4.1.24        xtable_1.8-4        Rdpack_2.6.2       \n#> [100] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [103] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [106] jpeg_0.1-10         lme4_1.1-36         mvtnorm_1.3-3      \n#> [109] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-28    \n#> [112] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "03_analisi_fattoriale_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
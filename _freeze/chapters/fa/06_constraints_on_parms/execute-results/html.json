{
  "hash": "a811f4fc3114133bd91736a5bed1f42b",
  "result": {
    "engine": "knitr",
    "markdown": "# Attendibilità e modello fattoriale {#sec-fa-reliability}\n\n**Prerequisiti**\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n\n**Concetti e Competenze Chiave**\n\n**Preparazione del Notebook**\n\n\n\n\n::: {.cell vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |> source()\n\n# Carica pacchetti aggiuntivi\npacman::p_load(lavaan, modelsummary)\n```\n:::\n\n\n\n\nIn questo capitolo esamineremo il problema relativo alla valutazione dell'affidabilità di uno strumento mediante l'impiego della tecnica dell'analisi fattoriale. Saranno differenziati tre distinti modelli che delineano le connessioni tra gli indicatori e il sottostante fattore latente comune (modelli congenerico, tau-equivalente, parallelo). Saranno presentati altresì tre diversi indici volti a caratterizzare l'affidabilità, intesa come coerenza interna, in accordo con il modello adottato. Tali indici includono l'indice omega di McDonald, l'indice alpha di Cronbach e l'indice rho, derivato dalla formula \"profetica\" di Spearman-Brown.\n\nSarà evidente che l'utilizzo dell'indice alpha di Cronbach è giustificato soltanto se particolari condizioni specifiche vengono soddisfatte, circostanza che si verifica piuttosto raramente nei dati empirici. A causa di tale ragione, in linea generale, risulta più opportuno adottare l'indice omega di McDonald quale misura di coerenza interna.\n\n## Teoria classica dei test e analisi fattoriale\n\n@mcdonald2013test illustra come la teoria classica dei test possa essere correlata al modello dell'analisi fattoriale. La figura rappresenta, attraverso i termini del modello fattoriale, la relazione che sussiste tra i punteggi $Y$, derivanti dalla somministrazione di un test composto da cinque item, e i punteggi veri.\n\n::: {#fig-like}\n![](../../figures/factmod1.png){width=\"55%\"}\n\nDiagramma di percorso del modello monofattoriale.\n:::\n\nEsistono diverse strategie per stimare l'attendibilità in situazioni in cui viene somministrato un unico test. In questo contesto, analizzeremo tre metodologie che possono essere implementate attraverso l'analisi fattoriale: l'$\\alpha$ di Cronbach, l'$\\omega$ di McDonald e il metodo di Spearman-Brown.\n\nIl coefficiente $\\alpha$ rappresenta il principale indice utilizzato per quantificare l'attendibilità come misura di coerenza interna o omogeneità. Approfondiremo come questo indice rappresenti il limite inferiore dell'attendibilità di un test, a condizione che siano soddisfatte alcune ipotesi. Tuttavia, se queste assunzioni non vengono rispettate, l'$\\alpha$ si rivela un stimatore distorto dell'attendibilità.\n\nPrima di esaminare le diverse metodologie per stimare l'attendibilità in termini di coerenza interna, è essenziale distinguere tra le tre diverse forme che il modello unifattoriale può assumere. Queste tre forme corrispondono al modello con indicatori congenerici, al modello $\\tau$-equivalente e al modello parallelo.\n\n## Modello fattoriale e CTT\n\nConsiderando un insieme di item osservati $X_1, X_2, \\dots, X_p$, con $p>2$, i punteggi ottenuti da questi item sono composti da due elementi distinti: una componente di punteggio vero e una componente di errore.\n\n$$\n\\begin{equation}\n\\begin{aligned}\nX_1 &=T_1+E_1,\\notag\\\\ \nX_2 &=T_2+E_2,\\notag\\\\ \n&\\dots\\notag\\\\ \nX_p &=T_p+E_p.\\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nIn linea con l'approccio delineato da @mcdonald2013test, questa decomposizione tra la componente vera e quella di errore può essere formalizzata mediante l'utilizzo dei parametri del modello fattoriale. L'equazione $X_i = T_i + E_i$ può quindi essere riformulata come segue:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i, \\quad{i=1, \\dots, p},\n$$ \n\nIn questa equazione, $X_i$ rappresenta il punteggio osservato per l'item $i$-esimo (espresso in termini di scarti dalla media), $\\lambda_i$ è il carico fattoriale associato all'item $i$-esimo, $\\xi$ costituisce il fattore comune e $\\delta_i$ è la componente residuale del punteggio osservato per l'item $i$-esimo. Tale formulazione si basa sulle assunzioni del modello monofattoriale. Nello specifico, si ipotizza che $\\xi$ e $\\delta_i$ siano incorrelati per ogni item $i$, e che $\\delta_i$ e $\\delta_k$ siano incorrelati per ogni coppia $i \\neq k$.\n\n## Classi di modelli\n\nNell'ambito dei modelli monofattoriali, possiamo distinguere tre scenari principali:\n\n1. **Modello con indicatori congenerici:** Questo modello rappresenta il caso più generale, in cui non vi sono restrizioni imposte sulla struttura degli indicatori. Gli indicatori sono correlati in quanto riflettono un fattore comune, ma possono avere carichi fattoriali diversi e specificità uniche.\n\n2. **Modello con indicatori $\\tau$-equivalenti:** In questo scenario, tutti gli indicatori hanno lo stesso carico fattoriale, il che implica che misurano il fattore comune con la stessa forza. Tuttavia, possono differire per quanto riguarda la loro varianza e specificità.\n\n3. **Modello con indicatori paralleli:** Qui, gli indicatori non solo condividono lo stesso carico fattoriale, ma presentano anche identica varianza degli errori. Questo indica una completa equivalenza tra gli indicatori, mostrando una struttura molto più rigida rispetto al modello $\\tau$-equivalente.\n\nIl modello con indicatori congenerici funge da base più flessibile, mentre i modelli con indicatori $\\tau$-equivalenti e paralleli introducono vincoli crescenti che specificano relazioni sempre più strette tra gli indicatori.\n\n### Indicatori congenerici\n\nGli indicatori *congenerici* rappresentano misure di uno stesso costrutto, ma non è necessario che riflettano tale costrutto con la medesima intensità. Nel contesto degli indicatori congenerici all'interno del modello monofattoriale, non vengono introdotte limitazioni né sulle saturazioni fattoriali né sulle specificità:\n\n$$\n\\lambda_1\\neq \\lambda_2 \\neq \\dots\\neq \\lambda_p,\n$$\n\n$$\n\\psi_{11}\\neq \\psi_{22} \\neq \\dots\\neq \\psi_{pp}.\n$$ \n\nIl modello mono-fattoriale con indicatori congenerici è dunque\n\n$$\n\\begin{equation}\nX_i = \\lambda_i \\xi + \\delta_i.\n\\end{equation}\n$$ {#eq-mod-tau-eq}\n\nDalle assunzioni precedenti possiamo derivare la matrice $\\boldsymbol{\\Sigma}$ riprodotta in base al modello congenerico la quale risulta essere uguale a\n\n$$\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{11} & \\sigma_{12} & \\dots & \\sigma_{1p}, \\\\\n        \\sigma_{21} & \\sigma_{22} & \\dots & \\sigma_{2p}. \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{p1} & \\sigma_{p2} & \\dots & \\sigma_{pp} \n      \\end{array} \n    \\right].\n$$ \n    \nSi noti come tutte le varianze e tutte le covarianze siano tra loro diverse.\n\n### Indicatori tau-equivalenti\n\nNel caso di indicatori $\\tau$-equivalenti, si ha che\n\n$$\n\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda,\n$$\n\n$$\n\\psi_{11}\\neq \\psi_{22} \\neq \\dots\\neq \\psi_{pp}.\n$$ \n\nIl modello monofattoriale con indicatori $\\tau$-equivalenti diventa dunque\n\n$$\n\\begin{equation}\nX_i = \\lambda \\xi + \\delta_i, \n\\end{equation}\n$$ {#eq-mod-tau-eq}\n\novvero \n\n$$\n\\begin{equation}\nX_i = \\tau + \\delta_i,\n\\end{equation}\n$$ {#eq-mod-tau-eq}\n\ndove $\\tau=\\lambda \\xi$ è l'attributo comune scalato nell'unità di misura dell'indicatore. Secondo il modello dell'@eq-mod-tau-eq, tutte le $p(p-1)$ covarianze tra gli item\ndel test devono essere uguali, ovvero\n\n$$\n\\begin{equation}\n\\sigma_{ik} = \\lambda^2=\\sigma^2_T,\n\\end{equation}\n$$ {#eq-cov-tau-eq}\n\nper $i\\neq k$. Gli elementi sulla diagonale principale della matrice di varianze e covarianze saranno invece\n\n$$\n\\begin{equation}\n\\sigma_{ii} = \\lambda^2 + \\psi_{ii} =\\sigma^2_T + \\psi_{ii}.\n\\end{equation}\n$$ {#eq-var-tau}\n\nLa matrice $\\boldsymbol{\\Sigma}$ riprodotta in base al modello $\\tau$-equivalente è dunque uguale a\n\n$$\n\\begin{equation}\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{T}^2 + \\psi_{11} & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 + \\psi_{22} & \\dots & \\sigma_{T}^2 \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 + \\psi_{pp} \n      \\end{array} \n    \\right].\n\\end{equation}\n$$ {#eq-sigma-tau-eq}\n    \nTutte le covarianze sono uguali, mentre le varianze sono tra loro diverse.\n\n### Indicatori paralleli\n\nNel caso di indicatori paralleli si ha che\n\n$$\n\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda,\n$$\n\n$$\n\\psi_{11}=\\psi_{22}=\\dots=\\psi_{pp}=\\psi.\n$$ \n\nIl modello costituito da indicatori paralleli impone dunque un'ulteriore restrizione che riguarda le varianze degli item, ovvero:\n\n$$\n\\sigma_{ii} = \\lambda^2 + \\psi =\\sigma^2_T + \\sigma^2.\n$$ \n\nLa struttura di varianze e covarianze imposta dal modello per indicatori paralleli è\ndunque tale da richiedere l'uguaglianza tra tutte le covarianze tra gli\nitem e l'uguaglianza tra tutte le varianze degli item. La matrice\n$\\boldsymbol{\\Sigma}$ riprodotta in base al modello con indicatori\nparalleli è dunque uguale a \n\n$$\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{T}^2 + \\sigma^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 + \\sigma^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 +\\sigma^2 \\notag\n      \\end{array} \n    \\right].\n$$\n\n\n## Metodo dei minimi quadrati non pesati\n\nNel contesto del modello unifattoriale, la varianza di ciascun indicatore è decomposta in due componenti: la componente $\\sigma^2_T$, attribuibile all'effetto del fattore latente comune, e la componente $\\psi$, riferita all'influenza del fattore specifico. @mcdonald2013test dimostra come sia possibile ottenere stime di tali componenti dai dati osservati. Queste stime vengono successivamente impiegate per calcolare l'affidabilità interna del test mediante le formule degli indici $\\alpha$ di Cronbach e $\\omega$ di McDonald.\n\nIn precedenza, abbiamo esaminato come la varianza del punteggio vero possa essere equivalente alla covarianza tra due forme parallele dello stesso test: $\\sigma^2_T = \\sigma_{XX^\\prime}$. Nel caso di indicatori $\\tau$-equivalenti, la matrice $\\boldsymbol{\\Sigma}$ prevista dal modello risulta essere:\n\n$$\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{T}^2 + \\psi_{11} & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 + \\psi_{22} & \\dots & \\sigma_{T}^2 \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 + \\psi_{pp} \\notag\n      \\end{array}\n    \\right],\n$$\n\nossia, tutte le covarianze sono equivalenti tra loro. Nel caso degli indicatori $\\tau$-equivalenti, dunque, una stima $\\hat{\\sigma}^2_T$ di $\\sigma^2_T$ si ottiene calcolando la media delle covarianze della matrice **S**:\n\n$$\n\\begin{equation}\n\\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} {\\sum \\sum}_{i \\neq k} s_{ik}.\n\\end{equation}\n$$ {#eq-sigma-t}\n\nQuesto metodo di stima di $\\sigma^2_T$ è noto come \"metodo dei minimi quadrati non pesati\" @mcdonald2013test.\n\nInoltre, nel caso di indicatori $\\tau$-equivalenti, la stima di $\\psi_{ii}$ nell'@eq-var-tau è calcolata come:\n\n$$\n\\hat{\\psi}_{ii }= s_{ii} - \\hat{\\sigma}_T^2,\n$$\n\nper ogni item $i$.\n\nPer quanto riguarda gli *indicatori paralleli*, la stima di $\\sigma^2_T$ è ancora basata sull'@eq-sigma-t, ovvero sulla media delle covarianze della matrice $\\boldsymbol{\\Sigma}$. Tuttavia, la stima del valore costante $\\psi$ è ottenuta tramite l'equazione:\n\n$$\n\\begin{equation}\n\\hat{\\psi} = \\frac{1}{p} \\sum_i (s_{ii} - \\hat{\\sigma}_T^2)\n\\end{equation}\n$$ {#eq-psi-par-st}\n\n## Varianza del punteggio totale di un test\n\nConsideriamo un test omogeneo costituito da $p$ item, il cui punteggio totale $Y$ è dato dalla somma dei punteggi individuali degli item, espressi come $Y = \\sum_{i=1}^p X_i$. Analizziamo la varianza di $Y$ utilizzando un modello unifattoriale.\n\nIn un modello congenerico con un singolo fattore comune, il punteggio di ciascun item $i$, $X_i$, può essere rappresentato dalla seguente equazione:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i,\n$$\n\ndove $\\lambda_i$ rappresenta la carica fattoriale dell'item $i$ sul fattore comune $\\xi$, e $\\delta_i$ è l'errore specifico associato all'item. Questa formulazione è analoga all'equazione $X_i = T_i + E_i$ della teoria classica dei test, dove $T_i$ è il vero punteggio e $E_i$ l'errore di misurazione.\n\nIl punteggio totale, essendo la somma di tutti gli item, si esprime come $\\sum_i (\\lambda_i \\xi + \\delta_i)$. La varianza del punteggio totale può quindi essere calcolata come segue:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n  \\mathbb{V}(Y) &= \\mathbb{V}\\left[ \\sum_i  (\\lambda_i \\xi + \\delta_i)  \\right] \\\\\n  &= \\mathbb{V}\\left[ \\left( \\sum_i \\lambda_i\\right) \\xi + \\sum_i \\delta_i\\right] \\\\\n  &=  \\left(\\sum_i \\lambda_i\\right)^2 \\mathbb{V}(\\xi) +  \\sum_i  \\mathbb{V}(\\delta_i) \\\\\n  &= \\left(\\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii},\n\\end{aligned}\n\\end{equation}\n$$ {#eq-var-y}\n\ndove $\\mathbb{V}(\\xi) = 1$ per ipotesi. La varianza di $Y$ si decompone in due parti principali: la prima parte, $(\\sum_i \\lambda_i)^2$, rappresenta la varianza attribuibile al fattore comune, riflettendo la variazione legata all'attributo misurato dagli item; la seconda parte, $\\sum_i \\psi_{ii}$, corrisponde alla somma delle varianze degli errori specifici di ciascun item, rappresentando la variazione dovuta agli errori di misurazione.\n\n## Stima dell'attendibilità\n\n### Coefficiente Omega\n\nDopo aver analizzato la varianza del punteggio totale di un test come indicato nella precedente equazione:\n\n$$\n\\mathbb{V}(Y) = \\left( \\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii},\n$$\n\nsi introduce il coefficiente di affidabilità $\\omega$. @mcdonald2013test definisce $\\omega$ come il rapporto tra la varianza attribuibile al fattore comune e la varianza totale del punteggio. Basandosi sui parametri del modello monofattoriale, il coefficiente $\\omega$ può essere formulato come segue:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n\\omega &= \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\mathbb{V}(Y)} \\\\\n&= \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2  + \\sum_{i=1}^p \\psi_{ii}}\n\\end{aligned}\n\\end{equation}\n$$ {#eq-omega}\n\nQuesto coefficiente $\\omega$ offre una stima quantitativa dell'affidabilità di un test, basata sui parametri del modello congenerico e utilizzando i dati raccolti da una singola somministrazione del test. La sua utilità risiede nel quantificare quanto della varianza osservata nel punteggio totale è effettivamente spiegata dal fattore comune misurato dal test.\n\n#### Un esempio concreto\n\nConsideriamo nuovamente la scala *Openness* del dataframe `bfi` discussi nel capitolo @ctt-3-notebook. Leggiamo i dati in R.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ndata(bfi, package = \"psych\")\n```\n:::\n\n\n\n\nÈ necessario ricodificare due item.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nbfi$O2r <- 7 - bfi$O2\nbfi$O5r <- 7 - bfi$O5\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ncor(\n    bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], \n    use = \"pairwise.complete.obs\"\n) |>\n    round(2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.00 0.21 0.40 0.18 0.24\n#> O2r 0.21 1.00 0.26 0.07 0.32\n#> O3  0.40 0.26 1.00 0.19 0.31\n#> O4  0.18 0.07 0.19 1.00 0.18\n#> O5r 0.24 0.32 0.31 0.18 1.00\n```\n:::\n\n\n\n\nEseguiamo l'analisi fattoriale confermativa con `lavaan`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nmod <- \"\n    f =~ NA*O1 + O2r + O3 + O4 + O5r\n    f ~~ 1*f\n\"\n\nfit <- cfa(mod, data = bfi, std.ov = TRUE, std.lv = TRUE)\n```\n:::\n\n\n\n\nEstraiamo le saturazioni fattoriali e le specificità dall'oggetto `fit`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nlambda <- inspect(fit, what = \"std\")$lambda\npsy <- diag(inspect(fit, what = \"est\")$theta)\n```\n:::\n\n\n\n\nCalcoliamo il coefficiente $\\omega$\n\n$$\n\\omega = \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2  + \\sum_{i=1}^p \\psi_{ii}}\n$$\n\nusando i parametri del modello fattoriale.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsum(lambda)^2 / (sum(lambda)^2 + sum(psy)) \n#> [1] 0.618\n```\n:::\n\n\n\n\nRipetiamo i calcoli usando la funzione `compRelSEM` del pacchetto `semTools`.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsemTools::compRelSEM(fit, tau.eq = FALSE)\n#>     f \n#> 0.618\n```\n:::\n\n\n\n\nIl coefficiente $\\omega=0.62$ può essere interpretato dicendo che il 62% della varianza del punteggio totale $Y$ della sottoscala Openness viene spiegato dal fattore comune latente.\n\n#### Coefficiente $\\omega$ e assunzioni della teoria classica dei test\n\nIl calcolo del coefficiente $\\omega$ si appoggia su un'assunzione fondamentale della teoria classica dei test: che non esistano covarianze tra gli errori specifici degli item, ossia $\\psi_{ik}=0$ per ogni $i \\neq k$. Tuttavia, questa ipotesi potrebbe non reggere in contesti di dati empirici. Bollen (1980) sottolinea che, qualora le covarianze tra errori specifici non siano trascurabili, l'equazione per $\\omega$ dovrebbe essere modificata come segue:\n\n$$\n\\begin{equation}\n\\omega = \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2  + \\sum_{i=1}^p \\psi_{ii} + \\sum_{i, k, i\\neq k}^p \\psi_{ik}}.\n\\end{equation}\n$$\n\nPer verificare la validità dell'assunzione di indipendenza tra gli errori specifici, si può ricorrere a un'analisi fattoriale confermativa. Se l'analisi rivela correlazioni significative tra molti errori specifici, potrebbe essere necessario incorporare ulteriori fattori nel modello per accomodare queste covarianze. Questo può suggerire una struttura non più unidimensionale, indicando la presenza di diverse sottoscale all'interno del test. Tuttavia, anche con l'identificazione di tali sottoscale, le covarianze tra i fattori specifici possono rimanere inesplicate. In tali casi, l'uso dell'equazione modificata per $\\omega$ diventa indispensabile.\n\n#### Interpretazione del Coefficiente $\\omega$\n\n@mcdonald2013test propone diverse interpretazioni del coefficiente $\\omega$ che aiutano a comprenderne il significato nel contesto della teoria dei test:\n- $\\omega$ può essere visto come il quadrato della correlazione tra il punteggio totale $Y$ e il fattore comune $\\xi$, che rappresenta anche la correlazione tra $Y$ e il punteggio vero. Questo si allinea alla definizione classica di affidabilità, espressa come $\\rho_{XT}^2 = \\sigma^2_{\\tau}/\\sigma^2_X$, dove $\\sigma^2_{\\tau}$ è la varianza del punteggio vero e $\\sigma^2_X$ quella del punteggio osservato.\n- $\\omega$ descrive anche la correlazione tra due applicazioni ipotetiche del test, $Y$ e $Y'$, che condividono le stesse somme (o medie) delle cariche fattoriali e delle varianze specifiche nel contesto di un modello a singolo fattore.\n- $\\omega$ rappresenta il quadrato della correlazione tra il punteggio totale di $p$ item e il punteggio medio di un insieme infinito di item all'interno di un dominio omogeneo, dove i $p$ item analizzati sono un sottoinsieme rappresentativo.\n\nIn sintesi, il coefficiente $\\omega$ fornisce una misura di quanto il punteggio totale di un test sia rappresentativo del fattore latente che il test intende misurare. Attraverso la correlazione, l'omogeneità e la consistenza osservata tra diverse somministrazioni o versioni di un test, $\\omega$ aiuta a interpretare la qualità e l'affidabilità del test stesso.\n\n### Coefficienti $\\alpha$ e $\\omega$ nel modello $\\tau$-equivalente\n\nNel contesto dei modelli monofattoriali, i coefficienti $\\omega$ e $\\alpha$ offrono stime dell'attendibilità, ma in contesti distinti. Il coefficiente $\\omega$ è utile per i modelli con indicatori congenerici, mentre il coefficiente $\\alpha$ è specifico per i modelli con indicatori $\\tau$-equivalenti.\n\nIn un modello $\\tau$-equivalente, dove ciascun item ha la stessa carica fattoriale $\\lambda$, la varianza di ogni item si scompone in una parte dovuta al punteggio vero e una parte d'errore, espressa come $\\sigma_{ii} = \\lambda^2 + \\psi_{ii} = \\sigma^2_T + \\sigma^2_i$. In questo scenario, la formula per il coefficiente $\\omega$ si semplifica nel seguente modo:\n\n$$\n\\omega = \\frac{\\left( \\sum_i \\lambda_i \\right)^2}{\\left( \\sum_i \\lambda_i \\right)^2  + \\sum_i \\psi_{ii}} = \\frac{p^2 \\lambda^2}{\\sigma^2_Y} = \\frac{p^2 \\sigma_T^2}{\\sigma_Y^2},\n$$\n\ndove $Y$ rappresenta il punteggio totale del test.\n\nApplicando il metodo dei minimi quadrati non pesati, possiamo derivare la stima seguente per $\\omega$:\n\n$$\n\\hat{\\omega} = \\frac{p^2 \\hat{\\sigma}_T^2}{s_Y^2},\n$$\n\ndove $\\hat{\\sigma}_T^2$ è stimato come:\n\n$$\n\\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} \\sum \\sum_{i \\neq k} s_{ik}.\n$$\n\nIntegrando questa stima nella formula precedente, otteniamo:\n\n$$\n\\hat{\\omega} = \\frac{p}{p-1}\\frac{\\sum \\sum_{i \\neq k} s_{ik}}{s_Y^2}.\n$$\n\nPer gli indicatori $\\tau$-equivalenti, quindi, $\\omega$ può essere stimato da:\n\n$$\n\\hat{\\omega} = \\frac{p}{p-1}\\left(1-\\frac{\\sum_i s_{ii}}{s_Y^2}\\right).\n$$ (eq-alpha-camp)\n\nQuesta stima di $\\omega$ ha un parallelo nei valori di popolazione definiti da $\\alpha$, che si esprime come:\n\n$$\n\\alpha = \\frac{p}{p-1}\\left(1-\\frac{\\sum_{i=1}^p \\sigma_{ii}}{\\sigma_Y^2}\\right) = \\frac{p}{p-1}\\frac{\\sum_{i \\neq k}^p \\text{Cov}(X_i, X_k)}{\\mathbb{V}(Y)}.\n$$ {#eq-alpha-pop}\n\nIn condizioni ideali del modello $\\tau$-equivalente, i valori di $\\alpha$ e $\\omega$ convergono. Tuttavia, $\\alpha$ tende a sottostimare $\\omega$, posizionandosi come un limite inferiore per $\\omega$. Data questa natura conservativa di $\\alpha$, alcuni ricercatori lo preferiscono a $\\omega$, sebbene questa proprietà valga solamente quando le assunzioni del modello $\\tau$-equivalente sono rigorosamente rispettate.\n\n#### Un esempio concreto\n\nConsideriamo la matrice di varianze e covarianze della sottoscala Openness. \n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nC <- cov(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nC |> \n    round(2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.28 0.38 0.54 0.25 0.36\n#> O2r 0.38 2.45 0.50 0.13 0.67\n#> O3  0.54 0.50 1.49 0.29 0.50\n#> O4  0.25 0.13 0.29 1.49 0.29\n#> O5r 0.36 0.67 0.50 0.29 1.76\n```\n:::\n\n\n\n\nCalcoliamo il coefficiente $\\alpha$ usando l'eq. {eq}`eq-alpha-camp`:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\np <- 5\nalpha <- (p / (p - 1)) * (1 - tr(C) / sum(C))\nalpha\n#> [1] 0.6\n```\n:::\n\n\n\n\n### La formula \"profetica\" di Spearman-Brown\n\nLa formula profetica di Spearman-Brown è impiegata per calcolare l'affidabilità nei modelli di misurazione che utilizzano indicatori paralleli. Supponiamo di avere un test composto da $p$ item paralleli, in cui ogni item ha la stessa carica fattoriale $\\lambda$ e la stessa varianza dell'errore specifico $\\psi$, ovvero $\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda$ e $\\psi_{11}=\\psi_{22}=\\dots=\\psi_{pp}=\\psi$.\n\nLa proporzione di varianza nel punteggio totale del test spiegata dalla variabile latente è quindi:\n\n$$\n\\left(\\sum_i \\lambda_i \\right)^2 = (p \\lambda)^2 = p^2 \\lambda^2.\n$$\n\nDefinendo l'affidabilità di un singolo item, $\\rho_1$, come\n\n$$\n\\rho_1 = \\frac{\\lambda^2}{\\lambda^2 + \\psi},\n$$\n\nper $p$ item paralleli, l'affidabilità del test, $\\rho_p$, diventa:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n  \\rho_p &= \\frac{p^2 \\lambda^2}{p^2 \\lambda^2 + p \\psi} \\\\\n         &= \\frac{p \\lambda^2}{ p \\lambda^2 + \\psi} \\\\\n         &= \\frac{p \\lambda^2}{(p-1) \\lambda^2 + (\\lambda^2 + \\psi)}.\n\\end{aligned}\n\\end{equation}\n$$\n\nSfruttando l'affidabilità di un singolo item $\\rho_1$, possiamo riformulare $\\rho_p$ come:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n  \\rho_p &= \\frac{p \\rho_1}{(p-1)\\rho_1 + 1}.\n\\end{aligned}\n\\end{equation}\n$$ (eq-spearman-brown-der)\n\nQuesta espressione, derivata qui sopra, mostra come l'affidabilità $\\rho_p$ di un test composto da $p$ item paralleli possa essere calcolata a partire dall'affidabilità di un singolo item. Tale formula è nota come \"formula di predizione\" di Spearman-Brown (*Spearman-Brown prophecy formula*). \n\nIn contesti con item paralleli, è importante notare che le misure di affidabilità $\\omega$, $\\alpha$, e $\\rho_p$ risultano equivalenti.\n\n#### Un esempio concreto\n\nPoniamoci il problema di calcolare l'attendibilità della sottoscala Openness utilizzando la formula di Spearman-Brown. Ipotizziamo dunque che gli item della scala Openness siano paralleli. La matrice di correlazione è:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nR <- cor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nround(R, 3)\n#>        O1   O2r    O3    O4   O5r\n#> O1  1.000 0.214 0.395 0.178 0.239\n#> O2r 0.214 1.000 0.262 0.068 0.325\n#> O3  0.395 0.262 1.000 0.195 0.311\n#> O4  0.178 0.068 0.195 1.000 0.179\n#> O5r 0.239 0.325 0.311 0.179 1.000\n```\n:::\n\n\n\n\nSeguendo @mcdonald2013test, supponiamo di calcolare l'attendibilità di un singolo item ($\\rho_1$) come la correlazione media tra gli item:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nrr <- NULL\np <- 5\nk <- 1\nfor (i in 1:p) {\n  for (j in 1:p) {\n    if (j != i) {\n      rr[k] <- R[i, j]\n    }\n    k <- k + 1\n  }\n}\nro_1 <- mean(rr, na.rm = TRUE)\nprint(ro_1)\n#> [1] 0.237\n```\n:::\n\n\n\n\nApplicando la formula di Spearman-Brown, la stima dell'attendibilità del\ntest diventa pari a\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n(p * ro_1) / ((p - 1) * ro_1 + 1) |>\n    round(3)\n#> [1] 0.608\n```\n:::\n\n\n\n\n## Commenti e considerazioni conclusive\n\nIl coefficiente $\\alpha$ di Cronbach è uno degli indici di affidabilità più diffusi in psicometria. Tuttavia, la sua efficacia dipende strettamente dalla $\\tau$-equivalenza degli item, che presuppongono un tratto latente unidimensionale. Nella pratica, questa condizione è spesso violata: molti test misurano più di un fattore, e le comunalità degli item non sono uniformi, mettendo in discussione la validità dell'ipotesi di $\\tau$-equivalenza. Se gli errori sono incorrelati, il coefficiente $\\alpha$ può sottostimare l'affidabilità; se invece gli errori sono correlati, può sovrastimarla.\n\nData questa limitazione, l'utilizzo del coefficiente $\\omega$ di McDonald è generalmente più consigliabile. Il coefficiente $\\omega$ fornisce una stima più robusta dell'affidabilità in vari contesti, inclusi quelli con assunzioni meno restrittive rispetto alla $\\tau$-equivalenza. Altri indici come il $glb$ (*Greatest Lower Bound*), discusso da Ten Berge e Sočan (2004), e l'indice $\\beta$ di Revelle (1979), rappresentano alternative valide al coefficiente $\\alpha$, offrendo diversi vantaggi metodologici a seconda delle specifiche esigenze di misurazione e delle caratteristiche dei dati analizzati.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] modelsummary_2.3.0 ggokabeito_0.1.0   see_0.10.0        \n#>  [4] MASS_7.3-64        viridis_0.6.5      viridisLite_0.4.2 \n#>  [7] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#> [10] patchwork_1.3.0    bayesplot_1.11.1   semTools_0.5-6    \n#> [13] semPlot_1.1.6      lavaan_0.6-19      psych_2.4.12      \n#> [16] scales_1.3.0       markdown_1.13      knitr_1.49        \n#> [19] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1     \n#> [22] dplyr_1.1.4        purrr_1.0.4        readr_2.1.5       \n#> [25] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#> [28] tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-12          igraph_2.1.4       \n#>  [22] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-2        R6_2.6.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-2         timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [46] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [49] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [52] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [55] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [58] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8      \n#>  [61] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [64] tzdb_0.4.0          data.table_1.16.4   hms_1.1.3          \n#>  [67] car_3.1-3           tables_0.9.31       sem_3.1-16         \n#>  [70] pillar_1.10.1       rockchalk_1.8.157   later_1.4.1        \n#>  [73] splines_4.4.2       lattice_0.22-6      survival_3.8-3     \n#>  [76] kutils_1.73         tidyselect_1.2.1    miniUI_0.1.1.1     \n#>  [79] pbapply_1.7-2       reformulas_0.4.0    stats4_4.4.2       \n#>  [82] xfun_0.50           qgraph_1.9.8        arm_1.14-4         \n#>  [85] stringi_1.8.4       yaml_2.3.10         pacman_0.5.1       \n#>  [88] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#>  [91] mi_1.1              cli_3.6.4           RcppParallel_5.1.10\n#>  [94] rpart_4.1.24        xtable_1.8-4        Rdpack_2.6.2       \n#>  [97] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [100] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [103] jpeg_0.1-10         lme4_1.1-36         mvtnorm_1.3-3      \n#> [106] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-28    \n#> [109] mnormt_2.1.1\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "8a43fbb28bccc3b4ea8a13bea052abb4",
  "result": {
    "engine": "knitr",
    "markdown": "# Attendibilità e modello fattoriale {#sec-fa-reliability}\n\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- calcolare e interpretare i punteggi fattoriali.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, semPlot, modelsummary)\n```\n:::\n\n\n\n\n:::\n\n## Introduzione\n\nIn questo capitolo affronteremo il tema della **valutazione dell’affidabilità** di uno strumento psicometrico tramite l’**analisi fattoriale**. Verranno introdotti tre modelli teorici che descrivono le diverse relazioni possibili tra gli indicatori osservati e un **fattore latente comune**: il **modello congenerico**, il **modello tau-equivalente** e il **modello parallelo**.\n\nPer ciascuno di questi modelli sarà discusso un indice specifico volto a quantificare l’affidabilità intesa come **coerenza interna**. Gli indici presentati saranno:  \n\n- l’**indice omega** di McDonald,  \n- l’**indice alpha** di Cronbach,  \n- l’**indice rho**, derivato dalla formula “profetica” di Spearman-Brown.\n\nSi mostrerà come l’impiego dell’indice alpha di Cronbach sia **giustificato solo in presenza di specifiche condizioni**, le quali risultano però **raramente soddisfatte** nei dati empirici. Per tale motivo, nella pratica applicativa, è spesso preferibile fare riferimento all’**indice omega di McDonald**, che fornisce una stima più accurata della coerenza interna.\n\n\n## Teoria classica dei test e analisi fattoriale\n\nCome illustrato da @mcdonald2013test, la **teoria classica dei test (CTT)** può essere messa in relazione diretta con il modello dell’**analisi fattoriale confermativa**. La figura seguente rappresenta, in termini fattoriali, il legame tra i punteggi osservati $Y$ ottenuti da un test composto da cinque item e i corrispondenti **punteggi veri**.\n\n::: {#fig-like}\n![](../../figures/factmod1.png){width=\"55%\"}\n\nDiagramma di percorso del modello monofattoriale.\n:::\n\nQuando si somministra un unico test, esistono diverse strategie per stimarne l’affidabilità. In questo contesto, ci concentreremo su **tre approcci** implementabili tramite l’analisi fattoriale:  \n\n- il coefficiente $\\alpha$ di **Cronbach**,  \n- il coefficiente $\\omega$ di **McDonald**,  \n- l’indice $\\rho$ derivato dalla **formula di Spearman-Brown**.\n\nTra questi, il coefficiente $\\alpha$ di Cronbach è l’indice più diffuso per la stima dell’affidabilità come **coerenza interna** o **omogeneità** tra gli item. Tuttavia, approfondiremo come esso rappresenti una **stima al ribasso** dell’affidabilità del test, valida solo a patto che siano rispettate alcune ipotesi. In caso contrario, l’$\\alpha$ può risultare uno **stimatore distorto**.\n\nPrima di analizzare nel dettaglio le tre metodologie, è necessario distinguere tra **tre configurazioni possibili** del modello unifattoriale, corrispondenti a:  \n\n- modello con **indicatori congenerici**,  \n- modello **$\\tau$-equivalente**,  \n- modello **parallelo**.\n\n\n## Modello fattoriale e teoria classica dei test\n\nConsideriamo un insieme di $p$ item osservati, denotati con $X_1, X_2, \\dots, X_p$ (dove $p > 2$). Secondo la teoria classica dei test, ciascun punteggio osservato $X_i$ può essere scomposto in due componenti: \n\n- il **punteggio vero** $T_i$,  \n- un **errore casuale** $E_i$:\n\n$$\n\\begin{aligned}\nX_1 &= T_1 + E_1, \\\\\nX_2 &= T_2 + E_2, \\\\\n&\\dots \\\\\nX_p &= T_p + E_p.\n\\end{aligned}\n$$\n\nSeguendo l’approccio proposto da @mcdonald2013test, questa decomposizione può essere reinterpretata nel contesto dell’**analisi fattoriale**. La relazione tra punteggio vero ed errore viene descritta nel seguente modo:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i, \\quad \\text{per } i = 1, \\dots, p,\n$$\n\ndove:\n\n- $X_i$ è il punteggio osservato dell’item $i$-esimo (espresso come scarto dalla media),\n- $\\lambda_i$ è il **carico fattoriale**, che rappresenta il contributo del fattore comune $\\xi$ all’item $i$,\n- $\\xi$ è il **fattore latente comune** (ipotizzato con media zero e varianza unitaria),\n- $\\delta_i$ è l’**errore specifico** (residuo) associato all’item $i$.\n\nQuesta formulazione si basa sulle **ipotesi classiche del modello monofattoriale**:  \n\n- il fattore comune $\\xi$ è **incorrelato** con ciascun errore $\\delta_i$,  \n- gli errori $\\delta_i$ sono **mutuamente incorrelati** ($\\text{Cov}(\\delta_i, \\delta_j) = 0$ per ogni $i \\neq j$).\n\nQuesta struttura consente di **collegare direttamente** i concetti della teoria classica dei test con il formalismo dell’analisi fattoriale e di derivare in modo coerente gli indici di affidabilità basati su modelli fattoriali.\n\n## Classi di modelli\n\nNel contesto dei modelli monofattoriali, è possibile distinguere **tre principali configurazioni** teoriche, ciascuna caratterizzata da un diverso insieme di assunzioni riguardanti la relazione tra gli **indicatori osservati** e il **fattore latente comune**. Queste tre configurazioni si collocano lungo un continuum che va da una maggiore flessibilità a una maggiore restrizione strutturale.\n\n### Modello congenerico\n\nIl **modello con indicatori congenerici** rappresenta la formulazione più generale e flessibile. In questo modello:\n\n- ogni indicatore è influenzato dal **medesimo fattore latente**,  \n- i **carichi fattoriali** ($\\lambda_i$) possono variare da un indicatore all’altro,  \n- anche le **varianze degli errori** ($\\delta_i$) sono libere di differire.\n\nIn altre parole, ciascun indicatore misura lo stesso costrutto latente, ma può farlo con una diversa intensità e con un diverso grado di errore. Questo modello riflette realisticamente la maggior parte delle situazioni empiriche e costituisce il punto di partenza per valutazioni più complesse.\n\n### Modello tau-equivalente\n\nIl **modello $\\tau$-equivalente** è una **restrizione del modello congenerico** in cui si assume che:\n\n- **tutti gli indicatori abbiano lo stesso carico fattoriale** ($\\lambda_i = \\lambda$ per ogni $i$),\n- le **varianze degli errori** possono comunque differire tra gli indicatori.\n\nQuesto implica che ogni indicatore contribuisce in egual misura alla misurazione del fattore latente, pur potendo avere un diverso grado di specificità residua. Il coefficiente $\\alpha$ di Cronbach si basa proprio su questo modello e fornisce una stima attendibile solo se tale assunzione è soddisfatta.\n\n### Modello parallelo\n\nIl **modello con indicatori paralleli** rappresenta il caso più restrittivo. In esso si assume che:\n\n- tutti gli indicatori abbiano **lo stesso carico fattoriale** ($\\lambda_i = \\lambda$),\n- e che le **varianze degli errori** siano **identiche** tra gli indicatori ($\\text{Var}(\\delta_i) = \\sigma^2$ per ogni $i$).\n\nIn questa configurazione, gli indicatori sono considerati completamente **equivalenti** sia nella misura del fattore latente che nella quantità di errore associato. È il modello sottostante alla **formula di Spearman-Brown**, utilizzata, ad esempio, per prevedere l’affidabilità in funzione della lunghezza del test.\n\n### Confronto tra i modelli\n\nI tre modelli possono essere letti come una **gerarchia di assunzioni**:\n\n| Modello             | Carichi fattoriali | Varianze degli errori | Grado di restrizione |\n|---------------------|--------------------|------------------------|-----------------------|\n| Congenerico         | Liberi             | Libere                 | Basso                 |\n| Tau-equivalente     | Uguali             | Libere                 | Medio                 |\n| Parallelo           | Uguali             | Uguali                 | Alto                  |\n\\ \n\nAll’aumentare dei vincoli imposti al modello, cresce la semplicità e la forza esplicativa teorica, ma **diminuisce la flessibilità rispetto ai dati reali**. È quindi essenziale scegliere il modello coerente con la struttura empirica degli item, poiché ogni indice di affidabilità presuppone uno di questi modelli:\n\n- **Omega** di McDonald è coerente con il **modello congenerico**,  \n- **Alpha** di Cronbach assume il **modello $\\tau$-equivalente**,  \n- **Rho** di Spearman-Brown richiede il **modello parallelo**.\n\nNelle sezioni successive esamineremo in dettaglio ciascuno di questi indici e illustreremo come stimarli e interpretarli correttamente in funzione della struttura del modello.\n\n\n## Modelli monofattoriali: indicatori congenerici, τ-equivalenti e paralleli\n\n### Indicatori *congenerici*\n\nGli **indicatori congenerici** rappresentano misure di uno stesso costrutto latente, ma non è richiesto che lo riflettano con la stessa intensità né con lo stesso grado di precisione. Nel **modello monofattoriale congenerico**, non vengono imposti vincoli né sui **carichi fattoriali** né sulle **varianze degli errori specifici**:\n\n$$\n\\lambda_1 \\neq \\lambda_2 \\neq \\dots \\neq \\lambda_p, \\quad \\psi_{11} \\neq \\psi_{22} \\neq \\dots \\neq \\psi_{pp}.\n$$\n\nIl modello è descritto, come già visto, dall’equazione:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i, \\quad i = 1, \\dots, p.\n$$\n\nLa **matrice di varianze e covarianze** riprodotta dal modello è:\n\n$$\n\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\dots & \\sigma_{1p} \\\\\n\\sigma_{21} & \\sigma_{22} & \\dots & \\sigma_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{p1} & \\sigma_{p2} & \\dots & \\sigma_{pp}\n\\end{bmatrix},\n$$\n\ndove ogni elemento può assumere un valore diverso. Le **covarianze** tra gli item sono tutte positive (poiché condividono il fattore comune), ma **non necessariamente uguali** tra loro, e lo stesso vale per le **varianze**.\n\nQuesto è il modello più flessibile, adatto a situazioni empiriche in cui gli item non sono perfettamente equivalenti ma riflettono lo stesso costrutto. Il coefficiente **omega** di McDonald è coerente con questo modello.\n\n\n### Indicatori *τ-equivalenti*\n\nIl modello con **indicatori $\\tau$-equivalenti** introduce un vincolo importante: tutti gli item presentano **lo stesso carico fattoriale**. Tuttavia, le varianze residue possono ancora differire:\n\n$$\n\\lambda_1 = \\lambda_2 = \\dots = \\lambda_p = \\lambda, \\quad \\psi_{11} \\neq \\psi_{22} \\neq \\dots \\neq \\psi_{pp}.\n$$\n\nL’equazione del modello diventa quindi:\n\n$$\nX_i = \\lambda \\xi + \\delta_i,\n$$\n\noppure, definendo $\\tau = \\lambda \\xi$ come componente comune scalata nell’unità dell’indicatore:\n\n$$\nX_i = \\tau + \\delta_i.\n$$\n\nIn questo modello, le **covarianze tra gli item** sono tutte uguali, poiché dipendono solo dalla varianza della componente comune:\n\n$$\n\\sigma_{ik} = \\lambda^2 = \\sigma_T^2, \\quad \\text{per } i \\neq k. \n$$\n\nInvece, le **varianze degli item** possono differire a causa delle varianze residue:\n\n$$\n\\sigma_{ii} = \\lambda^2 + \\psi_{ii} = \\sigma_T^2 + \\psi_{ii}.\n$$\n\nLa matrice delle varianze e covarianze risultante è dunque:\n\n$$\n\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n\\sigma_T^2 + \\psi_{11} & \\sigma_T^2 & \\dots & \\sigma_T^2 \\\\\n\\sigma_T^2 & \\sigma_T^2 + \\psi_{22} & \\dots & \\sigma_T^2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_T^2 & \\sigma_T^2 & \\dots & \\sigma_T^2 + \\psi_{pp}\n\\end{bmatrix}.\n$$\n\nIl coefficiente **alpha di Cronbach** assume implicitamente che gli item soddisfino questa struttura. Tuttavia, in molte applicazioni empiriche questa assunzione è violata, rendendo l’$\\alpha$ un **sottostimatore distorto** dell’affidabilità reale.\n\n### Indicatori *paralleli*\n\nIl modello con **indicatori paralleli** rappresenta il caso più restrittivo. Oltre a imporre **carichi fattoriali uguali**, richiede anche che **tutte le varianze residue** siano identiche:\n\n$$\n\\lambda_1 = \\lambda_2 = \\dots = \\lambda_p = \\lambda, \\quad \\psi_{11} = \\psi_{22} = \\dots = \\psi_{pp} = \\psi.\n$$\n\nDi conseguenza, tutte le **varianze osservate** risultano uguali:\n\n$$\n\\sigma_{ii} = \\lambda^2 + \\psi = \\sigma_T^2 + \\sigma^2, \\quad \\text{per ogni } i.\n$$\n\nAnche tutte le **covarianze tra item** restano uguali:\n\n$$\n\\sigma_{ik} = \\lambda^2 = \\sigma_T^2, \\quad \\text{per } i \\neq k.\n$$\n\nLa matrice $\\boldsymbol{\\Sigma}$ assume quindi la seguente forma simmetrica e omogenea:\n\n$$\n\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n\\sigma_T^2 + \\sigma^2 & \\sigma_T^2 & \\dots & \\sigma_T^2 \\\\\n\\sigma_T^2 & \\sigma_T^2 + \\sigma^2 & \\dots & \\sigma_T^2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_T^2 & \\sigma_T^2 & \\dots & \\sigma_T^2 + \\sigma^2\n\\end{bmatrix}.\n$$\n\nQuesto modello si colloca all’estremo del continuum di restrizione e viene assunto dalla **formula di Spearman-Brown**, impiegata per stimare l’effetto dell’aumento del numero di item sull’affidabilità.\n\n\n### Riepilogo concettuale\n\n| Modello             | Carichi fattoriali | Varianze errori | Varianze osservate | Covarianze | Indice coerente |\n|---------------------|--------------------|------------------|--------------------|------------|-----------------|\n| Congenerico         | Diversi            | Diverse           | Diverse            | Diverse    | Omega           |\n| Tau-equivalente     | Uguali             | Diverse           | Diverse            | Uguali     | Alpha           |\n| Parallelo           | Uguali             | Uguali            | Uguali             | Uguali     | Rho             |\n\\ \n\nComprendere queste tre configurazioni è fondamentale per scegliere **l’indice di affidabilità appropriato** e per valutare **la validità delle assunzioni** nei modelli di misura psicometrica.\n\n\n## Metodo dei minimi quadrati non pesati\n\nNel contesto del **modello unifattoriale**, la **varianza osservata di ciascun indicatore** può essere scomposta in due componenti principali:\n\n- la **varianza spiegata** dal fattore latente comune, denotata con $\\sigma^2_T$;\n- la **varianza residua o specifica**, indicata con $\\psi$.\n\nCome illustrato da @mcdonald2013test, è possibile stimare queste due componenti direttamente a partire dalla **matrice di covarianza empirica** degli item. Tali stime sono poi impiegate per calcolare indici di **affidabilità interna** come $\\alpha$ di Cronbach e $\\omega$ di McDonald.\n\nIn precedenza, abbiamo visto che la **varianza del punteggio vero** può essere interpretata come la **covarianza tra due forme parallele** dello stesso test:\n\n$$\n\\sigma_T^2 = \\sigma_{XX'}.\n$$\n\nNel caso specifico del **modello $\\tau$-equivalente**, la **matrice teorica delle varianze e covarianze** degli item assume la forma:\n\n$$\n\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n\\sigma_T^2 + \\psi_{11} & \\sigma_T^2 & \\dots & \\sigma_T^2 \\\\\n\\sigma_T^2 & \\sigma_T^2 + \\psi_{22} & \\dots & \\sigma_T^2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_T^2 & \\sigma_T^2 & \\dots & \\sigma_T^2 + \\psi_{pp}\n\\end{bmatrix},\n$$\n\ndove tutte le **covarianze fuori diagonale** sono uguali a $\\sigma_T^2$, mentre le **varianze diagonali** variano in funzione delle specificità degli item.\n\n### Stima della varianza del punteggio vero\n\nNel modello $\\tau$-equivalente, una stima della **varianza del fattore comune**, $\\hat{\\sigma}_T^2$, può essere ottenuta calcolando la **media delle covarianze osservate** tra gli item, ovvero i valori fuori diagonale della matrice empirica $\\mathbf{S}$:\n\n$$\n\\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} \\sum_{i \\neq k} s_{ik}.\n$$ {#eq-sigma-t}\n\nQuesta stima è nota come **metodo dei minimi quadrati non pesati** (*unweighted least squares*), in quanto si basa su una media semplice delle covarianze, senza introdurre pesi differenziati tra item.\n\n### Stima delle varianze specifiche\n\nUna volta stimata la varianza comune $\\hat{\\sigma}_T^2$, è possibile ottenere la stima della **varianza residua specifica** per ciascun item sottraendo la parte comune dalla varianza totale osservata:\n\n$$\n\\hat{\\psi}_{ii} = s_{ii} - \\hat{\\sigma}_T^2.\n$$\n\nQuesta operazione va effettuata per ciascun item $i = 1, \\dots, p$.\n\n### Caso del modello parallelo\n\nNel **modello parallelo**, si assume che anche le **varianze degli errori** siano uguali tra tutti gli item. In tal caso, la stima della varianza comune $\\hat{\\sigma}_T^2$ rimane invariata (è ancora la media delle covarianze osservate), ma la **stima della varianza specifica $\\psi$**, essendo costante per tutti gli item, si ottiene come **media delle differenze** tra le varianze osservate e la varianza comune:\n\n$$\n\\hat{\\psi} = \\frac{1}{p} \\sum_{i=1}^{p} (s_{ii} - \\hat{\\sigma}_T^2).\n$$ {#eq-psi-par-st}\n\n\n## Varianza del punteggio totale di un test\n\nConsideriamo ora un **test composto da $p$ item**, e definiamo il **punteggio totale** come:\n\n$$\nY = \\sum_{i=1}^{p} X_i.\n$$\n\nNel contesto di un **modello monofattoriale congenerico**, ogni item è modellato come:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i,\n$$\n\ndove:\n\n- $\\lambda_i$ è il **carico fattoriale** dell’item $i$ sul **fattore comune** $\\xi$;\n- $\\delta_i$ è il **residuo specifico**, ossia la parte del punteggio non spiegata dal fattore.\n\nQuesta formulazione è coerente con la teoria classica dei test ($X_i = T_i + E_i$), dove il punteggio vero corrisponde alla componente $\\lambda_i \\xi$ e l’errore di misura alla componente $\\delta_i$.\n\n### Decomposizione della varianza del punteggio totale\n\nPoiché il punteggio totale $Y$ è la somma di tutti gli item, possiamo scriverlo come:\n\n$$\nY = \\sum_{i=1}^{p} X_i = \\sum_{i=1}^{p} (\\lambda_i \\xi + \\delta_i).\n$$\n\nLa **varianza del punteggio totale**, assumendo che $\\xi$ abbia varianza unitaria e che sia incorrelato con i residui $\\delta_i$, si calcola nel seguente modo:\n\n$$\n\\begin{aligned}\n\\mathbb{V}(Y) &= \\mathbb{V} \\left[ \\sum_i (\\lambda_i \\xi + \\delta_i) \\right] \\\\\n&= \\mathbb{V} \\left[ \\left( \\sum_i \\lambda_i \\right) \\xi + \\sum_i \\delta_i \\right] \\\\\n&= \\left( \\sum_i \\lambda_i \\right)^2 \\mathbb{V}(\\xi) + \\sum_i \\mathbb{V}(\\delta_i) \\\\\n&= \\left( \\sum_i \\lambda_i \\right)^2 + \\sum_i \\psi_{ii}.\n\\end{aligned}\n$$ {#eq-var-y}\n\nQuesta equazione mostra chiaramente che la varianza del punteggio totale si scompone in:\n\n- una **componente sistematica** legata al **fattore comune**: $(\\sum_i \\lambda_i)^2$;\n- una **componente casuale** dovuta agli **errori specifici**: $\\sum_i \\psi_{ii}$.\n\nLa **proporzione della varianza totale attribuibile al fattore comune** rappresenta, in ultima analisi, ciò che intendiamo per **affidabilità del test**, ed è su questa base che vengono costruiti gli indici $\\alpha$, $\\omega$ e $\\rho$.\n\n\n## Stima dell’attendibilità\n\n### Coefficiente $\\omega$\n\nCome visto in precedenza, la **varianza del punteggio totale** $Y$ di un test costituito da $p$ item, nel contesto di un modello monofattoriale congenerico, può essere scomposta in due componenti:\n\n$$\n\\mathbb{V}(Y) = \\left( \\sum_{i=1}^{p} \\lambda_i \\right)^2 + \\sum_{i=1}^{p} \\psi_{ii}.\n$$\n\nSulla base di questa decomposizione, @mcdonald2013test propone il **coefficiente $\\omega$** come misura dell’**affidabilità** del test, intesa come **proporzione della varianza totale spiegata dal fattore comune**:\n\n$$\n\\omega = \\frac{\\left( \\sum_{i=1}^{p} \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^{p} \\lambda_i \\right)^2 + \\sum_{i=1}^{p} \\psi_{ii}}.\n$$ {#eq-omega}\n\nQuesto coefficiente è coerente con il **modello congenerico** e consente di stimare l’affidabilità di un test a partire da una singola somministrazione, utilizzando i parametri dell’analisi fattoriale.\n\nIn termini interpretativi, $\\omega$ indica **quanto della varianza osservata nel punteggio totale è realmente riconducibile al costrutto latente che il test intende misurare**.\n\n\n#### Esempio pratico: sottoscala *Openness* del dataset `bfi`\n\nUtilizziamo il pacchetto `psych` per caricare il dataset e ricodificare gli item invertiti.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(bfi, package = \"psych\")\nbfi$O2r <- 7 - bfi$O2\nbfi$O5r <- 7 - bfi$O5\n```\n:::\n\n\n\n\n\nEsaminiamo la matrice di correlazione tra gli item della scala *Openness*.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\") |>\n  round(2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.00 0.21 0.40 0.18 0.24\n#> O2r 0.21 1.00 0.26 0.07 0.32\n#> O3  0.40 0.26 1.00 0.19 0.31\n#> O4  0.18 0.07 0.19 1.00 0.18\n#> O5r 0.24 0.32 0.31 0.18 1.00\n```\n:::\n\n\n\n\n\nEseguiamo quindi l’analisi fattoriale confermativa con il pacchetto `lavaan`, specificando una soluzione monofattoriale standardizzata:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- \"\n  f =~ NA*O1 + O2r + O3 + O4 + O5r\n  f ~~ 1*f\n\"\nfit <- cfa(mod, data = bfi, std.ov = TRUE, std.lv = TRUE)\n```\n:::\n\n\n\n\n\nEstraiamo le **saturazioni fattoriali** ($\\lambda_i$) e le **varianze specifiche** ($\\psi_{ii}$):\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda <- inspect(fit, \"std\")$lambda\npsy <- diag(inspect(fit, \"est\")$theta)\n```\n:::\n\n\n\n\n\nApplichiamo ora la formula per calcolare $\\omega$:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum(lambda)^2 / (sum(lambda)^2 + sum(psy))\n#> [1] 0.6181\n```\n:::\n\n\n\n\n\nPossiamo confrontare il risultato con quello ottenuto tramite la funzione `compRelSEM()` del pacchetto `semTools`, che calcola $\\omega$ direttamente dal modello `lavaan`:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsemTools::compRelSEM(fit, tau.eq = FALSE)\n#>     f \n#> 0.618\n```\n:::\n\n\n\n\n\nNel nostro esempio, otteniamo $\\omega \\approx 0.62$, il che implica che circa **il 62% della varianza del punteggio totale nella scala Openness è spiegato dal fattore latente comune**.\n\n\n### Ipotesi del modello e possibili violazioni\n\nLa formula classica di $\\omega$ si basa su una **ipotesi fondamentale della teoria classica dei test**: l’**assenza di covarianza tra gli errori specifici** degli item, ovvero:\n\n$$\n\\psi_{ik} = 0 \\quad \\text{per ogni } i \\neq k.\n$$\n\nTuttavia, nei dati reali questa assunzione può essere violata. Se esistono **covarianze significative tra gli errori specifici**, la stima classica di $\\omega$ risulta **sovrastimata**. In questi casi, come sottolineato da Bollen (1980), è necessario utilizzare una formula **corretta** che tenga conto anche delle covarianze tra errori:\n\n$$\n\\omega = \\frac{\\left( \\sum_{i=1}^{p} \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^{p} \\lambda_i \\right)^2 + \\sum_{i=1}^{p} \\psi_{ii} + \\sum_{i \\neq k} \\psi_{ik}}.\n$$\n\nPer valutare la presenza di covarianze spurie tra gli errori, è possibile consultare gli **indici di modifica (modification indices)** forniti dall’analisi fattoriale confermativa. Se le correlazioni residue tra item sono elevate, ciò può indicare la presenza di **dimensioni latenti aggiuntive**, suggerendo che il test **non è unidimensionale**.\n\n### Interpretazioni del coefficiente $\\omega$\n\nIl coefficiente $\\omega$ può essere interpretato da diversi punti di vista, tutti coerenti con la teoria classica dei test:\n\n- **Correlazione quadrata tra punteggio totale e fattore comune**:  \n  $\\omega$ rappresenta il quadrato della correlazione tra il punteggio totale $Y$ e il fattore latente $\\xi$, cioè $\\rho_{Y\\xi}^2$.\n\n- **Correlazione tra forme parallele del test**:  \n  In un contesto ipotetico in cui si somministrano due versioni equivalenti del test, $\\omega$ rappresenta la correlazione attesa tra i due punteggi totali.\n\n- **Affidabilità nel dominio**:  \n  $\\omega$ può essere visto come la correlazione tra il punteggio ottenuto su $p$ item e quello che si otterrebbe da una somministrazione con un **numero infinito di item** tratti dallo stesso dominio latente (i.e., stesso costrutto).\n\nIn conclusione, il coefficiente $\\omega$ rappresenta oggi una **alternativa più robusta** e teoricamente fondata rispetto al tradizionale $\\alpha$ di Cronbach. A differenza di $\\alpha$, $\\omega$ **non richiede l’assunzione di $\\tau$-equivalenza** tra gli item ed è pertanto utilizzabile in un **modello congenerico**, più realistico nella maggior parte delle applicazioni empiriche.\n\nIn sintesi:\n\n- $\\omega$ misura la **quota di varianza del punteggio totale attribuibile al costrutto latente**;\n- è **più flessibile e accurato** rispetto ad altri indici;\n- può essere stimato direttamente da un **modello fattoriale confermativo**, anche su una **singola somministrazione** del test.\n\n\n\n### Coefficienti $\\omega$ e $\\alpha$ nel modello $\\tau$-equivalente\n\nNel contesto dei modelli monofattoriali, i coefficienti $\\omega$ e $\\alpha$ offrono due approcci distinti alla **stima dell’affidabilità**, differenziandosi in funzione delle **assunzioni strutturali** sugli item:\n\n- $\\omega$ è coerente con il **modello congenerico**, in cui i carichi fattoriali e le varianze residue possono variare tra item;\n- $\\alpha$ si basa sul **modello $\\tau$-equivalente**, che assume **carichi fattoriali uguali** ma consente varianze residue differenti.\n\nNel modello $\\tau$-equivalente, ciascun item ha la stessa carica fattoriale $\\lambda$, e la varianza totale dell’item può essere scritta come:\n\n$$\n\\sigma_{ii} = \\lambda^2 + \\psi_{ii} = \\sigma_T^2 + \\sigma^2_i.\n$$\n\nLa varianza del punteggio totale $Y$ (somma dei $p$ item) sarà:\n\n$$\n\\sigma_Y^2 = p^2 \\lambda^2 + \\sum_{i=1}^p \\psi_{ii}.\n$$\n\nIn questo contesto, il coefficiente $\\omega$ assume la forma semplificata:\n\n$$\n\\omega = \\frac{p^2 \\lambda^2}{\\sigma_Y^2} = \\frac{p^2 \\sigma_T^2}{\\sigma_Y^2}.\n$$\n\nApplicando il **metodo dei minimi quadrati non pesati**, possiamo stimare $\\omega$ nel modo seguente:\n\n$$\n\\hat{\\omega} = \\frac{p^2 \\hat{\\sigma}_T^2}{s_Y^2},\n$$\n\ndove $\\hat{\\sigma}_T^2$ è la media delle covarianze osservate tra item:\n\n$$\n\\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} \\sum_{i \\neq k} s_{ik}.\n$$\n\nSostituendo questa espressione, otteniamo:\n\n$$\n\\hat{\\omega} = \\frac{p}{p-1} \\cdot \\frac{\\sum_{i \\neq k} s_{ik}}{s_Y^2}.\n$$\n\nOppure, espressa in funzione delle varianze:\n\n$$\n\\hat{\\omega} = \\frac{p}{p-1} \\left( 1 - \\frac{\\sum_{i=1}^p s_{ii}}{s_Y^2} \\right).\n$$ {#eq-alpha-camp}\n\nQuesta formula coincide con quella classica per il coefficiente $\\alpha$, che nei valori di popolazione si scrive:\n\n$$\n\\alpha = \\frac{p}{p - 1} \\left( 1 - \\frac{\\sum_{i=1}^p \\sigma_{ii}}{\\sigma_Y^2} \\right)\n       = \\frac{p}{p - 1} \\cdot \\frac{\\sum_{i \\neq k} \\text{Cov}(X_i, X_k)}{\\mathbb{V}(Y)}.\n$$ {#eq-alpha-pop}\n\nSotto le assunzioni del modello $\\tau$-equivalente, **$\\alpha$ e $\\omega$ coincidono**. Tuttavia, in presenza di carichi fattoriali disuguali (modello congenerico), **$\\alpha$ tende a sottostimare $\\omega$**, rendendolo un **limite inferiore** dell’affidabilità. Questa proprietà conservativa di $\\alpha$ è stata spesso invocata come argomento a favore del suo utilizzo, ma essa **non è garantita** al di fuori del modello $\\tau$-equivalente.\n\n\n#### Esempio pratico: $\\alpha$ per la sottoscala *Openness*\n\nCalcoliamo ora il coefficiente $\\alpha$ a partire dalla matrice di covarianze empirica:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nC <- cov(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nround(C, 2)\n#>       O1  O2r   O3   O4  O5r\n#> O1  1.28 0.38 0.54 0.25 0.36\n#> O2r 0.38 2.45 0.50 0.13 0.67\n#> O3  0.54 0.50 1.49 0.29 0.50\n#> O4  0.25 0.13 0.29 1.49 0.29\n#> O5r 0.36 0.67 0.50 0.29 1.76\n```\n:::\n\n\n\n\n\nApplichiamo la formula dell’$\\alpha$ campionaria:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- 5\nalpha <- (p / (p - 1)) * (1 - tr(C) / sum(C))\nalpha\n#> [1] 0.6002\n```\n:::\n\n\n\n\n\n### La formula \"profetica\" di Spearman-Brown\n\nLa **formula profetica di Spearman-Brown** è utilizzata per **prevedere l’affidabilità** di un test costruito da item **paralleli**, cioè:\n\n- tutti gli item hanno **lo stesso carico fattoriale** $\\lambda$;\n- tutte le **varianze residue sono uguali**: $\\psi_{ii} = \\psi$.\n\nIn questo caso, la **varianza del punteggio totale** è:\n\n$$\n\\sigma_Y^2 = p^2 \\lambda^2 + p \\psi.\n$$\n\nL’affidabilità del test è allora:\n\n$$\n\\rho_p = \\frac{p^2 \\lambda^2}{p^2 \\lambda^2 + p \\psi}\n       = \\frac{p \\lambda^2}{p \\lambda^2 + \\psi}.\n$$\n\nSe definiamo l’affidabilità di un **singolo item** come:\n\n$$\n\\rho_1 = \\frac{\\lambda^2}{\\lambda^2 + \\psi},\n$$\n\nla **formula di Spearman-Brown** esprime l’affidabilità del test come:\n\n$$\n\\rho_p = \\frac{p \\rho_1}{(p - 1) \\rho_1 + 1}.\n$$ {#eq-spearman-brown-der}\n\nQuesta formula è particolarmente utile quando si vuole **prevedere l’effetto dell’aggiunta di nuovi item** su un test esistente, ed è stata storicamente uno strumento fondamentale nello sviluppo dei test psicometrici.\n\nNel modello parallelo, i coefficienti $\\alpha$, $\\omega$ e $\\rho_p$ **coincidono**, poiché tutte le assunzioni richieste per ciascuno sono soddisfatte simultaneamente.\n\n#### Esempio pratico: Spearman-Brown per la sottoscala *Openness*\n\nIpotizziamo che gli item della scala *Openness* siano **paralleli**. In questo caso, possiamo calcolare l’affidabilità del test a partire dalla **correlazione media tra item**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nR <- cor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nround(R, 3)\n#>        O1   O2r    O3    O4   O5r\n#> O1  1.000 0.214 0.395 0.178 0.239\n#> O2r 0.214 1.000 0.262 0.068 0.325\n#> O3  0.395 0.262 1.000 0.195 0.311\n#> O4  0.178 0.068 0.195 1.000 0.179\n#> O5r 0.239 0.325 0.311 0.179 1.000\n```\n:::\n\n\n\n\n\nCalcoliamo la media delle correlazioni inter-item:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- 5\nrr <- NULL\nk <- 1\nfor (i in 1:p) {\n  for (j in 1:p) {\n    if (j != i) rr[k] <- R[i, j]\n    k <- k + 1\n  }\n}\nro_1 <- mean(rr, na.rm = TRUE)\nprint(ro_1)\n#> [1] 0.2365\n```\n:::\n\n\n\n\n\nApplichiamo la formula di Spearman-Brown:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(p * ro_1) / ((p - 1) * ro_1 + 1) |>\n  round(3)\n#> [1] 0.6078\n```\n:::\n\n\n\n\n\nIl risultato fornisce una **stima dell’affidabilità complessiva** del test *sotto l’ipotesi di parallelismo degli item*. Confrontare questo valore con quelli ottenuti tramite $\\omega$ e $\\alpha$ può essere utile per riflettere sulla **validità delle assunzioni sottostanti** al modello utilizzato.\n\n### Conclusioni\n\n| Modello                  | Assunzioni principali                  | Coefficiente coerente | Formula |\n|--------------------------|----------------------------------------|------------------------|---------|\n| Congenerico              | $\\lambda_i$ e $\\psi_{ii}$ liberi       | $\\omega$               | Varianza spiegata / totale |\n| $\\tau$-equivalente       | $\\lambda_i = \\lambda$; $\\psi_{ii}$ liberi | $\\alpha$, $\\omega$    | $\\alpha$ = $\\omega$ |\n| Parallelo                | $\\lambda_i = \\lambda$; $\\psi_{ii} = \\psi$ | $\\rho$, $\\omega$, $\\alpha$ | $\\omega = \\alpha = \\rho$ |\n\\\n\nLa scelta dell’indice di affidabilità più appropriato **dipende sempre dalle ipotesi del modello di misura**. È quindi fondamentale:\n\n- comprendere la struttura del proprio strumento;\n- valutare empiricamente la bontà del modello (con CFA o EFA);\n- interpretare ciascun coefficiente alla luce delle **assunzioni teoriche sottostanti**.\n\n## Riflessioni Conclusive\n\nNel corso di questo capitolo abbiamo analizzato tre principali coefficienti di **affidabilità interna** – $\\alpha$, $\\omega$, e $\\rho$ – ciascuno associato a un diverso modello di misura monofattoriale:\n\n| Coefficiente | Modello sottostante         | Ipotesi sui carichi $\\lambda$ | Ipotesi sugli errori $\\psi_{ii}$ | Correlazioni residue tra errori | Interpretabile come… |\n|--------------|-----------------------------|-------------------------------|------------------------------|-------------------------------|------------------------|\n| $\\omega$     | Congenerico                 | Liberi                        | Liberi                       | Nessuna (idealmente zero)     | Varianza spiegata / totale |\n| $\\alpha$     | $\\tau$-equivalente          | Uguali                        | Liberi                       | Nessuna                       | Limite inferiore di $\\omega$ |\n| $\\rho$       | Parallelo                   | Uguali                        | Uguali                       | Nessuna                       | Predizione su test allungato |\n\n### Scelte operative\n\n- Il coefficiente **$\\alpha$ di Cronbach** è il più diffuso in ambito psicometrico per la sua semplicità computazionale. Tuttavia, **è valido solo quando gli item sono $\\tau$-equivalenti**, ovvero misurano lo stesso costrutto con intensità uguale ma con varianze d’errore potenzialmente differenti.\n  \n  Nella pratica, tale ipotesi è **raramente soddisfatta**: spesso gli item mostrano carichi diversi, oppure strutture multidimensionali latenti. In questi casi, $\\alpha$ può **sottostimare** l’affidabilità se gli errori sono incorrelati, oppure **sovrastimarla** se gli errori sono correlati.\n\n- Il coefficiente **$\\omega$ di McDonald** costituisce un'alternativa più **generale e robusta**, poiché richiede **ipotesi meno restrittive**. È compatibile con il modello congenerico, che riflette con maggiore realismo la struttura empirica di molti test. In questo senso, $\\omega$ rappresenta la **scelta raccomandata** per stimare l'affidabilità interna in presenza di carichi fattoriali disuguali.\n\n- La **formula di Spearman-Brown** ($\\rho$) trova il suo uso ideale quando si assume il modello più restrittivo con **item paralleli**. Sebbene meno flessibile, essa è utile per **stimare l’impatto della lunghezza del test** sull’affidabilità, rispondendo alla domanda: “Cosa succederebbe se raddoppiassi il numero di item?”\n\n\n### Indici alternativi\n\nOltre a $\\alpha$ e $\\omega$, la letteratura psicometrica propone altri indici più sofisticati:\n\n- Il **GLB** (*Greatest Lower Bound*) di Ten Berge e Sočan (2004), che fornisce il limite inferiore teoricamente più alto dell’affidabilità. Tuttavia, è computazionalmente più complesso e sensibile alla struttura dei dati.\n\n- L’indice **$\\beta$ di Revelle** (1979), che misura la coerenza del sottoinsieme peggiore di item (worst split-half), ed è utile per rilevare problemi di dimensionalità.\n\nQuesti indici possono essere utili in situazioni in cui si sospetta che **l’unidimensionalità sia violata** o in cui si desidera esplorare diverse prospettive sulla coerenza interna di una scala.\n\n\n### Considerazioni finali\n\nIn sintesi:\n\n- Il coefficiente $\\alpha$ dovrebbe essere usato con **cautela**, solo quando le condizioni teoriche del modello $\\tau$-equivalente sono **empiricamente verificate**.\n- Il coefficiente $\\omega$ è da **preferire nella maggior parte delle applicazioni**, in quanto fornisce una **misura più realistica e flessibile** dell’affidabilità.\n- Nessun coefficiente è “migliore” in senso assoluto: la scelta dipende sempre dalla **struttura latente del test**, dalla **qualità dei dati** e dallo **scopo dell’analisi**.\n\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] modelsummary_2.3.0 ggokabeito_0.1.0   see_0.11.0        \n#>  [4] MASS_7.3-65        viridis_0.6.5      viridisLite_0.4.2 \n#>  [7] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#> [10] patchwork_1.3.0    bayesplot_1.11.1   semTools_0.5-6    \n#> [13] semPlot_1.1.6      lavaan_0.6-19      psych_2.4.12      \n#> [16] scales_1.3.0       markdown_1.13      knitr_1.50        \n#> [19] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1     \n#> [22] dplyr_1.1.4        purrr_1.0.4        readr_2.1.5       \n#> [25] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#> [28] tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.1      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.2.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [22] mime_0.13           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-3        R6_2.6.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-3         timechange_0.3.0   \n#>  [37] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [40] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [43] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [46] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [49] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [52] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [55] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [58] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8.1    \n#>  [61] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [64] tzdb_0.5.0          data.table_1.17.0   hms_1.1.3          \n#>  [67] car_3.1-3           tables_0.9.31       sem_3.1-16         \n#>  [70] pillar_1.10.1       rockchalk_1.8.157   later_1.4.1        \n#>  [73] splines_4.4.2       lattice_0.22-6      survival_3.8-3     \n#>  [76] kutils_1.73         tidyselect_1.2.1    miniUI_0.1.1.1     \n#>  [79] pbapply_1.7-2       reformulas_0.4.0    stats4_4.4.2       \n#>  [82] xfun_0.51           qgraph_1.9.8        arm_1.14-4         \n#>  [85] stringi_1.8.4       yaml_2.3.10         pacman_0.5.1       \n#>  [88] boot_1.3-31         evaluate_1.0.3      codetools_0.2-20   \n#>  [91] mi_1.1              cli_3.6.4           RcppParallel_5.1.10\n#>  [94] rpart_4.1.24        xtable_1.8-4        Rdpack_2.6.3       \n#>  [97] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [100] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [103] jpeg_0.1-10         lme4_1.1-36         mvtnorm_1.3-3      \n#> [106] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-28    \n#> [109] mnormt_2.1.1\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "8e9c62136dc768959126480d63002bcd",
  "result": {
    "engine": "knitr",
    "markdown": "# I punteggi fattoriali {#sec-fa-factor-scores}\n\n**Prerequisiti**\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n\n**Concetti e Competenze Chiave**\n\n**Preparazione del Notebook**\n\n\n\n\n::: {.cell vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |> source()\n\n# Carica pacchetti aggiuntivi\npacman::p_load(lavaan, semPlot, corrplot, tidyr, kableExtra)\n```\n:::\n\n\n\n\nUno dei momenti più difficili nel processo di sviluppo di un test\npsicometrico è quello dell'interpretazione dei fattori. La verifica del\nlivello di affidabilità rivela il grado di precisione delle misure\nottenute ma non fornisce alcuna informazione sulla natura di ciò che si\nsta misurando. Non esistono specifiche indicazioni che guidino il lavoro\ninterpretativo. Dipende, perciò, dalla capacità e dall'esperienza del\nricercatore cogliere il significato comune delle variabili confluite in\nun fattore, attenendosi alla realtà delle singole variabili senza\nfornire interpretazioni fantasiose. È importante rendersi conto che sia\nla scelta del metodo di estrazione dei fattori, sia il problema del\nnumero dei fattori da estrarre, sia la scelta del metodo con cui\neffettuare la rotazione, rendono molto arbitraria l'interpretazione\ndella soluzione fattoriale.\n\nI passaggi teorici necessari per interpretare una matrice fattoriale\nruotata possono essere descritti nel modo seguente.\n\n1.  Si definisce un livello arbitrario per le saturazioni che ci indichi\n    il limite oltre il quale non riteniamo le variabili sufficientemente\n    importanti per caratterizzare quel determinato fattore. Solitamente\n    si sceglie la soglia di .40. In casi particolari è possibile usare\n    valori maggiori o minori di questo, a seconda che si abbia un numero\n    ristretto o troppo ampio di variabili da interpretare.\n\n2.  Si ordinano le saturazioni delle variabili del fattore in ordine\n    decrescente (in valore assoluto), fermandosi al livello prescelto.\n\n3.  Si scrive accanto ad ogni saturazione la denominazione della\n    variabile corrispondente (o il testo dell'item).\n\n4.  Tenendo presente il dominio di indagine, le teorie di riferimento ed\n    eventuali risultati precedenti, si cerca di stabilire quale sia il\n    tratto, caratteristica o aspetto che queste variabili abbiano in\n    comune, in modo da poter in modo da poter \"nominare\" il fattore che\n    definisce questo tratto comune. In questo processo interpretativo\n    gli item con le saturazioni maggiori contribuiscono in misura\n    maggiore alla definizione del carattere comune del fattore e,\n    viceversa, ciò che è stato individuato come tratto comune delle\n    variabili deve comparire in maggior grado nelle variabili più\n    sature.\n\n5.  Il segno negativo di una saturazione indica solamente un'opposizione\n    rispetto alle saturazioni positive. Il tratto comune alle variabili\n    dovrebbe essere pensato come un continuum che passa dalla sua\n    massima presenza al suo opposto. Per procedere all'interpretazione\n    conviene iniziare dalle variabili il cui segno è più frequente e\n    considerarle come se fossero positive; di conseguenza, le altre\n    (siano esse di segno positivo o negativo) devono essere considerate\n    di segno opposto.\n\n6.  Nel caso in cui non si riesca a riscontrare nessun tratto comune\n    alle variabili del fattore, si dovrà concludere che il fattore non è\n    interpretabile e che le variabili sono state tra loro associate per\n    un errore attribuibile o al campione o alla misurazione delle\n    variabili stesse. Normalmente i \"primi\" fattori estratti sono\n    facilmente interpretabili mentre gli \"ultimi\", soprattutto se ne\n    sono stati estratti molti o se la matrice delle correlazioni\n    iniziale fra le variabili contiene molti valori bassi, sono spesso\n    difficilmente interpretabili o saturi di una sola variabile e quindi\n    fattori specifici di quella variabile. In linea di massima se i\n    fattori non interpretabili sono molti è meglio non considerare\n    affatto i risultati dell'analisi fattoriale.\n\n### Esempio di interpretazione\n\nIl WISC-III (Wechsler Intelligence Scale For Children - III) valuta\nl'abilità intellettiva di soggetti dai 6 ai 16 anni e 11 mesi. I subtest\nsono stati selezionati per valutare diverse abilità mentali, che tutte\ninsieme indicano l'abilità intellettiva generale del bambino. Alcuni gli\nrichiedono un ragionamento astratto, altri si focalizzano sulla memoria,\naltri ancora richiedono certe abilità percettive e così via.\n\nSi consideri la matrice di correlazione tra i subtest della scala\nWISC-III riportata dal manuale.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nlower <- '\n1\n.66      1\n.57\t.55      1\n.70\t.69\t.54       1\n.56\t.59\t.47\t.64      1\n.34\t.34\t.43\t.35\t.29      1\n.47\t.45\t.39\t.45\t.38\t.25      1\n.21\t.20\t.27\t.26\t.25\t.23\t.18      1\n.40\t.39\t.35\t.40\t.35\t.20\t.37\t.28      1\n.48\t.49\t.52\t.46\t.40\t.32\t.52\t.27\t.41      1\n.41\t.42\t.39\t.41\t.34\t.26\t.49\t.24\t.37\t.61      1\n.35\t.35\t.41\t.35\t.34\t.28\t.33\t.53\t.36\t.45\t.38      1\n.18\t.18\t.22\t.17\t.17\t.14\t.24\t.15\t.23\t.31\t.29\t.24     1\n'\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nwisc_III_cov <- getCov(\n  lower,\n  names = c(\n    \"INFO\", \"SIM\", \"ARITH\", \"VOC\", \"COMP\", \"DIGIT\", \"PICTCOM\",\n    \"CODING\", \"PICTARG\", \"BLOCK\", \"OBJECT\", \"SYMBOL\", \"MAZES\"\n  )\n)\n```\n:::\n\n\n\n\nEseguiamo l'analisi fattoriale con il metodo delle componenti principali\ne una rotazione Varimax:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nf_pc <- psych::principal(wisc_III_cov, nfactors = 3, rotate = \"varimax\")\nprint(f_pc)\n#> Principal Components Analysis\n#> Call: psych::principal(r = wisc_III_cov, nfactors = 3, rotate = \"varimax\")\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>           RC1  RC3  RC2   h2   u2 com\n#> INFO     0.80 0.25 0.09 0.72 0.28 1.2\n#> SIM      0.81 0.25 0.08 0.72 0.28 1.2\n#> ARITH    0.65 0.26 0.28 0.57 0.43 1.7\n#> VOC      0.83 0.19 0.13 0.75 0.25 1.2\n#> COMP     0.75 0.14 0.16 0.60 0.40 1.2\n#> DIGIT    0.45 0.06 0.36 0.34 0.66 2.0\n#> PICTCOM  0.43 0.61 0.02 0.56 0.44 1.8\n#> CODING   0.10 0.09 0.88 0.79 0.21 1.0\n#> PICTARG  0.34 0.45 0.27 0.39 0.61 2.6\n#> BLOCK    0.41 0.66 0.22 0.66 0.34 1.9\n#> OBJECT   0.31 0.71 0.14 0.62 0.38 1.5\n#> SYMBOL   0.23 0.32 0.74 0.70 0.30 1.6\n#> MAZES   -0.06 0.71 0.11 0.51 0.49 1.1\n#> \n#>                        RC1  RC3  RC2\n#> SS loadings           3.80 2.37 1.74\n#> Proportion Var        0.29 0.18 0.13\n#> Cumulative Var        0.29 0.47 0.61\n#> Proportion Explained  0.48 0.30 0.22\n#> Cumulative Proportion 0.48 0.78 1.00\n#> \n#> Mean item complexity =  1.5\n#> Test of the hypothesis that 3 components are sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.07 \n#> \n#> Fit based upon off diagonal values = 0.97\n```\n:::\n\n\n\n\nSi noti che i primi cinque subtest possiedono saturazioni maggiori di $0.6$ sul primo fattore. Dato che questi test sono tutti presentati verbalmente e richiedono delle risposte verbali, tale fattore può essere denominato *Comprensione Verbale*.\n\nI subtest \"Cifrario\" e \"Ricerca di simboli\" saturano sul secondo fattore. Entrambi i subtest misurano la velocità dei processi di codifica o ricerca. Questo fattore, dunque, può essere denominato *Velocità di elaborazione*.\n\nInfine, i subtest \"Completamento di figure,\" \"Disegno con i cubi,\" \"Riordinamento di storie figurate\" e \"Labirinti\" saturano sul terzo fattore. Tutti questi test condividono una componente geometrica o configurazionale: misurano infatti le abilità necessarie per la manipolazione o la disposizione di immagini, oggetti, blocchi. Questo fattore, dunque, può essere denominato *Organizzazione percettiva*.\n\nNel caso di una rotazione ortogonale, la comunalità di ciascuna sottoscala è uguale alla somma delle saturazioni fattoriali al quadrato della sottoscala nei fattori. \n\nPer le 13 sottoscale del WISC-III abbiamo:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nh2 <- rep(0,13)\nfor (i in 1:13) {\n  h2[i] <- sum(f_pc$loadings[i, ]^2)\n}\nround(h2, 2)\n#>  [1] 0.72 0.72 0.57 0.75 0.60 0.34 0.56 0.79 0.39 0.66 0.62 0.70 0.51\n```\n:::\n\n\n\n\nQuesti risultati replicano quelli riportati nel manuale del test\nWISC-III.\n\n## Punteggi fattoriali\n\nFino ad ora abbiamo considerato le strategie di costruzione del modello\nbasate sulla stima e sull'interpretazione delle saturazioni fattoriali e\ndelle comunalità. Questo è il primo passo nella costruzione del modello\nfattoriale. È però possibile compiere un passo ulteriore, ovvero quello\ndella stima dei punteggi fattoriali (*factor scores*) i quali risultano\nutili sia per interpretare i risultati dell'analisi fattoriale che per\nfare diagnostica. I punteggi fattoriali forniscono le previsioni dei\nlivelli dei fattori latenti per ogni rispondente. Esistono vari metodi\ndi stima dei punteggi fattoriali. Tra questi troviamo il metodo di\nThomson basato sulla regressione e il metodo di Bartlett basato sulla\nmassima verosimiglianza. Entrambi questi metodi sono implementati nel\nsoftware .\n\n### Stima dei punteggi fattoriali\n\nSi definiscono punteggi fattoriali i valori assunti dai fattori comuni\n(inosservabili) in corrispondenza delle osservazioni campionarie. Il\nmetodo di Thomson stima i punteggi fattoriali in base all'approccio\ndella regressione multipla, ovvero, impiegando la matrice delle\ncorrelazioni tra le variabili e la matrice di struttura (ovvero, la\nmatrice delle correlazioni delle variabili con i fattori). Per ottenere\nle stime dei punteggi fattoriali con il metodo di Thomson è necessario\nspecificare nella funzione `factanal()` l'opzione\n`scores = \"regression\"`.\n\n### Dimostrazione di Thurstone\n\nPrima di descrivere il metodo della regressione, esaminiamo la\ndimostrazione che Thurstone (1947) ha fornito per illustrare il\nsignificato dei punteggi fattoriali (si veda Loehlin, 1987). L'idea è\nquella di esaminare la stima dei punteggi fattoriali in una situazione\nin cui i tali punteggi sono conosciuti, in maniera tale da potere\ncontrollare il risultato dell'analisi.\n\nSi consideri un insieme di 1000 scatole di cui conosciamo le dimensioni\n$x, y, z$:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1e3\nx <- rnorm(n, 100, 1.5)\ny <- rnorm(n, 200, 1.5)\nz <- rnorm(n, 300, 1.5)\n```\n:::\n\n\n\n\nIl problema è quello di stimare le dimensioni delle scatole disponendo\nsoltanto di una serie di misure indirette, corrotte dal rumore di\nmisura. Thurstone (1947) utilizzò le seguenti trasformazioni delle\ndimensioni delle scatole (si veda Jennrich, 2007).\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ns <- 40\ny1 <- rnorm(n, mean(x), s)\ny2 <- rnorm(n, mean(y), s)\ny3 <- rnorm(n, mean(z), s)\ny4 <- x * y + rnorm(n, 0, s)\ny5 <- x * z + rnorm(n, 0, s)\ny6 <- y * z + rnorm(n, 0, s)\ny7 <- x^2 * y + rnorm(n, 0, s)\ny8 <- x * y^2 + rnorm(n, 0, s)\ny9 <- x^2 * z + rnorm(n, 0, s)\ny10 <- x * z^2 + rnorm(n, 0, s)\ny11 <- y^2 * z + rnorm(n, 0, s)\ny12 <- y * z^2 + rnorm(n, 0, s)\ny13 <- y^2 * z + rnorm(n, 0, s)\ny14 <- y * z^2 + rnorm(n, 0, s)\ny15 <- x / y + rnorm(n, 0, s)\ny16 <- y / x + rnorm(n, 0, s)\ny17 <- x / z + rnorm(n, 0, s)\ny18 <- z / x + rnorm(n, 0, s)\ny19 <- y / z + rnorm(n, 0, s)\ny20 <- z / y + rnorm(n, 0, s)\ny21 <- 2 * x + 2*y + rnorm(n, 0, s)\ny22 <- 2 * x + 2*z + rnorm(n, 0, s)\ny23 <- 2 * y + 2*z + rnorm(n, 0, s)\n```\n:::\n\n\n\n\nEseguiamo l'analisi fattoriale con una soluzione a tre fattori sui dati\ncosì creati.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nY <- cbind(\n  y1, y2, y3, y4, y5, y6, y7, y8, y9, \n  y10, y11, y12, y13, y14, y15, y16, \n  y17, y18, y19, y20, y21, y22, y23\n)\n\nfa <- factanal(\n  Y, \n  factors = 3, \n  scores = \"regression\",\n  lower = 0.01\n)\n```\n:::\n\n\n\n\nL'opzione `scores = \"regression\"` richiede il calcolo dei punteggi\nfattoriali con il metodo della regressione. Nel caso di una rotazione\nVarimax (default della funzione `factanal()`), i punteggi fattoriali\nrisultano ovviamente incorrelati:\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ncor(\n  cbind(fa$scores[, 1], fa$scores[, 2], fa$scores[, 3])\n  ) %>% \n  round(3)\n#>        [,1]  [,2]   [,3]\n#> [1,]  1.000 0.002 -0.001\n#> [2,]  0.002 1.000  0.005\n#> [3,] -0.001 0.005  1.000\n```\n:::\n\n\n\n\nGeneriamo ora i diagrammi di dispersione che mettono in relazione le\ndimensioni originarie delle scatole ($x, y, z$) con i punteggi\nfattoriali sui tre fattori. Se l'analisi ha successo, ci aspettiamo\nun'alta correlazione tra i punteggi fattoriali di ogni fattore e una\nsola delle dimensioni delle scatole $x$, $y$, $z$.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\np1 <- tibble(x, fs1 = fa$scores[, 1]) %>% \n  ggplot(aes(x, fs1)) +\n  geom_point(alpha = 0.2)\np2 <- tibble(y, fs1 = fa$scores[, 1]) %>% \n  ggplot(aes(y, fs1)) +\n  geom_point(alpha = 0.2)\np3 <- tibble(z, fs1 = fa$scores[, 1]) %>% \n  ggplot(aes(z, fs1)) +\n  geom_point(alpha = 0.2)\n\np4 <- tibble(x, fs2 = fa$scores[, 2]) %>% \n  ggplot(aes(x, fs2)) +\n  geom_point(alpha = 0.2)\np5 <- tibble(y, fs2 = fa$scores[, 2]) %>% \n  ggplot(aes(y, fs2)) +\n  geom_point(alpha = 0.2)\np6 <- tibble(z, fs2 = fa$scores[, 2]) %>% \n  ggplot(aes(z, fs2)) +\n  geom_point(alpha = 0.2)\n\np7 <- tibble(x, fs3 = fa$scores[, 3]) %>% \n  ggplot(aes(x, fs3)) +\n  geom_point(alpha = 0.2)\np8 <- tibble(y, fs3 = fa$scores[, 3]) %>% \n  ggplot(aes(y, fs3)) +\n  geom_point(alpha = 0.2)\np9 <- tibble(z, fs3 = fa$scores[, 3]) %>% \n  ggplot(aes(z, fs3)) +\n  geom_point(alpha = 0.2)\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n(p1 | p2 | p3) /\n(p4 | p5 | p6) /\n(p7 | p8 | p9) \n```\n\n::: {.cell-output-display}\n![](05_factor_scores_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nI risultati riportati nella figura confermano le aspettative.\n\nIl metodo della regressione pone il problema della stima dei punteggi\nfattoriali nei termini di una ideale regressione di ogni fattore\nrispetto a tutte le variabili osservate. Per il fattore $j$-esimo, si\npuò scrivere la seguente equazione: \n\n$$\n\\begin{aligned}\nF_j =& \\beta_{1j}y_1 + \\dots + \\beta_{pm}y_p + \\varepsilon_j\n\\end{aligned}\n$$ \n\ndove $F_j$ sono i punteggi fattoriali e $y$ sono le variabili osservate standardizzate $(Y-\\bar{Y})/s$. In forma matriciale, il modello diventa\n\n$$\n\\textbf{F} = \\textbf{y} \\textbf{B} +\n\\boldsymbol{\\varepsilon}\n$$ \n\nI coefficienti parziali di regressione **B** sono ignoti. Tuttavia, possono essere calcolati utilizzando i metodi della regressione lineare. Nel modello di regressione, infatti, i coefficienti dei minimi quadrati possono essere calcolati utilizzando due matrici di correlazioni: la matrice $\\textbf{R}_{xx}$ (le\ncorrelazioni tra le variabili $X$) e la matrice $\\textbf{R}_{xy}$ (le\ncorrelazioni tra le variabili $X$ e la variabile $Y$:\n\n$$\n\\hat{\\textbf{B}} = \\textbf{R}_{xx}^{-1}\\textbf{R}_{xy}\n$$ \n\nNel caso dell'analisi fattoriale, $\\textbf{R}_{xx}$ corrisponde alla\nmatrice delle correlazioni tra le variabili osservate e\n$\\textbf{R}_{xy}$ corrisponde alla matrice di struttura (la matrice\ndelle correlazioni tra le variabili osservate e i fattori). Se i fattori\nsono ortogonali, la matrice di struttura coincide con la matrice dei\npesi fattoriali $\\hat{\\boldsymbol{\\Lambda}}$.\n\nI coefficienti **B** dell'equazione precedente possono dunque essere trovati nel modo seguente:\n\n$$\n\\begin{equation}\n\\hat{\\textbf{B}} = \\textbf{R}_{yy}^{-1}\\textbf{R}_{xf}=\n\\textbf{R}^{-1}\\hat{\\boldsymbol{\\Lambda}}\n\\end{equation}\n$$\n\nUna volta stimati i coefficienti $\\hat{\\textbf{B}}$, i punteggi fattoriali si calcolano allo stesso modo dei punteggi teorici del modello di regressione:\n\n$$\n\\begin{equation}\n\\hat{\\textbf{F}} = \\textbf{y} \\hat{\\textbf{B}} = \\textbf{y}\n\\textbf{R}^{-1}\\hat{\\boldsymbol{\\Lambda}},\n\\end{equation}\n$$\n\ndove $\\textbf{y}$ è la matrice delle variabili osservate standardizzate $(Y-\\bar{Y})/s$.\n\n**Esercizio.** Si utilizzino i dati `dass21.txt` che corrispondono alla somministrazione del test DASS-21 a 334 partecipanti. Lo schema di codifica si può trovare seguendo questo [link](https://maic.qld.gov.au/wp-content/uploads/2016/07/DASS-21.pdf). Ci si focalizzi sulla sottoscala Stress del DASS-21. Si trovino i punteggi fattoriali usando la funzione `factanal()` e si replichi il risultato seguendo la procedura delineata sopra.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] kableExtra_1.4.0  corrplot_0.95     ggokabeito_0.1.0  see_0.9.0        \n#>  [5] MASS_7.3-64       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#>  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#> [13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12     \n#> [17] scales_1.3.0      markdown_1.13     knitr_1.49        lubridate_1.9.4  \n#> [21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n#> [25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#> [29] tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.6      zoo_1.8-12          igraph_2.1.4       \n#>  [22] mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3    \n#>  [25] Matrix_1.7-2        R6_2.5.1            fastmap_1.2.0      \n#>  [28] rbibutils_2.3       shiny_1.10.0        digest_0.6.37      \n#>  [31] OpenMx_2.21.13      fdrtool_1.2.18      colorspace_2.1-1   \n#>  [34] rprojroot_2.0.4     Hmisc_5.2-2         labeling_0.4.3     \n#>  [37] timechange_0.3.0    abind_1.4-8         compiler_4.4.2     \n#>  [40] withr_3.0.2         glasso_1.11         htmlTable_2.4.3    \n#>  [43] backports_1.5.0     carData_3.0-5       ggsignif_0.6.4     \n#>  [46] corpcor_1.6.10      gtools_3.9.5        tools_4.4.2        \n#>  [49] pbivnorm_0.6.0      foreign_0.8-88      zip_2.3.1          \n#>  [52] httpuv_1.6.15       nnet_7.3-20         glue_1.8.0         \n#>  [55] quadprog_1.5-8      nlme_3.1-167        promises_1.3.2     \n#>  [58] lisrelToR_0.3       grid_4.4.2          checkmate_2.3.2    \n#>  [61] cluster_2.1.8       reshape2_1.4.4      generics_0.1.3     \n#>  [64] gtable_0.3.6        tzdb_0.4.0          data.table_1.16.4  \n#>  [67] hms_1.1.3           xml2_1.3.6          car_3.1-3          \n#>  [70] sem_3.1-16          pillar_1.10.1       rockchalk_1.8.157  \n#>  [73] later_1.4.1         splines_4.4.2       lattice_0.22-6     \n#>  [76] survival_3.8-3      kutils_1.73         tidyselect_1.2.1   \n#>  [79] miniUI_0.1.1.1      pbapply_1.7-2       reformulas_0.4.0   \n#>  [82] svglite_2.1.3       stats4_4.4.2        xfun_0.50          \n#>  [85] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [88] yaml_2.3.10         pacman_0.5.1        boot_1.3-31        \n#>  [91] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [94] cli_3.6.3           RcppParallel_5.1.10 rpart_4.1.24       \n#>  [97] systemfonts_1.2.1   xtable_1.8-4        Rdpack_2.6.2       \n#> [100] munsell_0.5.1       Rcpp_1.0.14         coda_0.19-4.1      \n#> [103] png_0.1-8           XML_3.99-0.18       parallel_4.4.2     \n#> [106] jpeg_0.1-10         lme4_1.1-36         mvtnorm_1.3-3      \n#> [109] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-26    \n#> [112] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "05_factor_scores_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "c7c4e20f17ad65cc991f8cdda0dfcf69",
  "result": {
    "engine": "knitr",
    "markdown": "# Punteggio totale e modello fattoriale {#sec-fa-total-score}\n\n**Prerequisiti**\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n\n**Concetti e Competenze Chiave**\n\n**Preparazione del Notebook**\n\n\n\n\n::: {.cell vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |> source()\n\n# Carica pacchetti aggiuntivi\npacman::p_load(lavaan, modelsummary)\n```\n:::\n\n\n\n\nIn questo capitolo discute l'uso del punteggio totale del test quale misura del costrutto latente. Questa è una pratica largamente usata, ma solo in parte giustificata. Esamineremo a questo proposito le considerazioni di McNeish e Wolf (2020).\n\n## Punteggio totale e modello fattoriale parallelo\n\nMcNeish e Wolf (2020) richiamano l'attenzione sul fatto che usare il punteggio totale quale misura di un costrutto è possibile solo quando i dati soddisfano i vincoli di un modello fattoriale parallelo.\n\nConsideriamo l'esempio seguente, nel quale McNeish e Wolf (2020) esaminano i dati \"classici\" di Holzinger and Swineford (1939), i quali si riferiscono ai seguenti item:\n\n- Paragraph comprehension\n- Sentence completion\n- Word definitions\n- Speeded addition\n- Speeded dot counting\n- Discrimination between curved and straight letters\n\nLeggiamo i dati in R.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nd <- rio::import(\n  here::here(\"data\", \"1_Factor_Parallel.csv\")\n)\n```\n:::\n\n\n\n\nMcNeish e Wolf (2020) sottolineano il fatto che il punteggio totale \n\n$$\n\\text{Punteggio totale} = \\text{Item 1 + Item 2 + Item 3 + Item 4 + Item 5 + Item 6}\n$$\n\nrappresenta l'idea che ciasun item fornisca la stessa quantità di informazione relativamente alla misura del costrutto. Ciò può essere specificato da un modello fattoriale nel quale le saturazioni fattoriali degli item sono tutte uguali a 1. Questo corrisponde al modello parallelo che abbiamo discusso in precedenza. In tali circostanze, i punteggi fattoriali del test risultano perfettamente associati al punteggio totale (correlazione uguale a 1). Dunque, se tale modello fattoriale è giustificato dai dati, questo giustifica l'uso del punteggio totale del test quale misura del costrutto.\n\nÈ facile verificare tali affermazioni.  Implementiamo il modello parallelo.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nm_parallel <-\n  \"\n  # all loadings are fixed to one\n  f1 =~ 1*X4 + 1*X5 + 1*X6 + 1*X7 + 1*X8 + 1*X9\n  \n  # all residual variances constrained to same value\n  X4 ~~ theta*X4\n  X5 ~~ theta*X5\n  X6 ~~ theta*X6\n  X7 ~~ theta*X7\n  X8 ~~ theta*X8\n  X9 ~~ theta*X9\n\"\n```\n:::\n\n\n\n\nAdattiamo il modello parallelo ai dati forniti dagli autori.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nfit_parallel <- sem(m_parallel, data=d)\n```\n:::\n\n\n\n\nCalcoliamo il punteggio totale.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nd$ts <- with(\n  d,\n  X4 + X5 + X6 + X7 + X8 + X9\n)\n```\n:::\n\n\n\n\nCalcoliamo i punteggi fattoriali.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nscores <- lavPredict(fit_parallel, method=\"regression\")\nd$scores <- as.numeric(scores)\n```\n:::\n\n\n\n\nUn diagramma a dispersione tra il punteggio totale e i punteggi fattoriali conferma che i due sono perfettamente associati. Quindi, usare il punteggio totale o i punteggi fattoriali è equivalente.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nd |> \n  ggplot(aes(x=ts, y=scores)) + \n  geom_point()\n```\n\n::: {.cell-output-display}\n![](07_total_score_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nTuttavia, questa conclusione è valida solo se il modello parallelo è giustificato per i dati.  Se esaminiamo l'output di lavaan vediamo che, nel caso presente, questo non è vero.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# report output with fit measures and standardized estimates\nout = summary(fit_parallel, fit.measures = TRUE, standardized = TRUE)\nprint(out)\n#> lavaan 0.6-19 ended normally after 13 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         7\n#>   Number of equality constraints                     5\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               325.899\n#>   Degrees of freedom                                19\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               568.519\n#>   Degrees of freedom                                15\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.446\n#>   Tucker-Lewis Index (TLI)                       0.562\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2680.931\n#>   Loglikelihood unrestricted model (H1)      -2517.981\n#>                                                       \n#>   Akaike (AIC)                                5365.862\n#>   Bayesian (BIC)                              5373.276\n#>   Sample-size adjusted Bayesian (SABIC)       5366.933\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.232\n#>   90 Percent confidence interval - lower         0.210\n#>   90 Percent confidence interval - upper         0.254\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    1.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.206\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~                                                                 \n#>     X4                1.000                               0.633    0.551\n#>     X5                1.000                               0.633    0.551\n#>     X6                1.000                               0.633    0.551\n#>     X7                1.000                               0.633    0.551\n#>     X8                1.000                               0.633    0.551\n#>     X9                1.000                               0.633    0.551\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .X4      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X5      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X6      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X7      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X8      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X9      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>     f1                0.400    0.045    8.803    0.000    1.000    1.000\n```\n:::\n\n\n\n\nDunque, per questi dati, il punteggio totale può ovviamente essere calcolato. Ma *non fornisce una misura adeguata del costrutto*. Dunque, il punteggio totale non dovrebbe essere usato nel caso dei dati ottenuti con questo test.\n\n## Punteggio totale e modello fattoriale congenerico\n\nGli autori adattano ai dati un modello congenerico.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nm_congeneric <- \n'\n  #all loadings are uniquely estimated\n  f1 =~ NA*X4 + X5 + X6 + X7 + X8 + X9\n  #constrain factor variance to 1\n  f1 ~~ 1*f1\n'\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# Fit above model\nfit_congeneric <- sem(m_congeneric, data=d)\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nparameterEstimates(fit_congeneric, standardized = TRUE) %>%\n  dplyr::filter(op == \"=~\") %>%\n  dplyr::select(\n    \"Latent Factor\" = lhs,\n    Indicator = rhs,\n    B = est,\n    SE = se,\n    Z = z,\n    \"p-value\" = pvalue,\n    Beta = std.all\n  ) %>%\n  knitr::kable(\n    digits = 3, booktabs = TRUE, format = \"markdown\",\n    caption = \"Factor Loadings\"\n  )\n```\n\n::: {.cell-output-display}\n\n\nTable: Factor Loadings\n\n|Latent Factor |Indicator |     B|    SE|     Z| p-value|  Beta|\n|:-------------|:---------|-----:|-----:|-----:|-------:|-----:|\n|f1            |X4        | 0.963| 0.059| 16.27|   0.000| 0.824|\n|f1            |X5        | 1.121| 0.067| 16.84|   0.000| 0.846|\n|f1            |X6        | 0.894| 0.058| 15.45|   0.000| 0.792|\n|f1            |X7        | 0.195| 0.071|  2.77|   0.006| 0.170|\n|f1            |X8        | 0.185| 0.063|  2.94|   0.003| 0.180|\n|f1            |X9        | 0.278| 0.065|  4.25|   0.000| 0.258|\n\n\n:::\n:::\n\n\n\n\nSi noti che le saturazioni fattoriali sono molto diverse tra loro, suggerendo che il punteggio del costrutto si relaziona in modo diverso con ciascun item e che sarebbe inappropriato stimare il punteggio del costrutto assegnando un peso unitario agli item.\n\nMcNeish e Wolf (2020) calcolano poi i punteggi fattoriali del modello congenerico.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nscores_cong <- lavPredict(fit_congeneric, method=\"regression\")\nd$scores_cong <- as.numeric(scores_cong)\n```\n:::\n\n\n\n\nIl grafico seguente mostra la relazione tra i punteggi fattoriali e il punteggio totale.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nd |> \n  ggplot(aes(x=ts, y=scores_cong)) + \n  geom_point()\n```\n\n::: {.cell-output-display}\n![](07_total_score_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nNel caso presente, il coefficiente di determinazione tra punteggio totale e punteggi fattoriali è 0.77.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\ncor(d$ts, d$scores_cong)^2\n#> [1] 0.766\n```\n:::\n\n\n\n\nSecondo gli autori, ciò significa che due persone con un punteggio totale identico potrebbero avere punteggi di modello congenerico potenzialmente diversi perché hanno raggiunto il loro particolare punteggio totale approvando item diversi. Poiché il modello congenerico assegna pesi diversi agli item, ciascun item contribuisce in modo diverso al punteggio fattoriale del modello congenerico, il che non è vero per il punteggio totale. \n\nSi noti che, per i dati di Holzinger and Swineford (1939), neppure un modello congenerico ad un fattore si dimostra adeguato.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nout = summary(fit_congeneric, fit.measures = TRUE, standardized = TRUE)\nprint(out)\n#> lavaan 0.6-19 ended normally after 16 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        12\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               115.366\n#>   Degrees of freedom                                 9\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               568.519\n#>   Degrees of freedom                                15\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.808\n#>   Tucker-Lewis Index (TLI)                       0.680\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2575.664\n#>   Loglikelihood unrestricted model (H1)      -2517.981\n#>                                                       \n#>   Akaike (AIC)                                5175.328\n#>   Bayesian (BIC)                              5219.813\n#>   Sample-size adjusted Bayesian (SABIC)       5181.756\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.198\n#>   90 Percent confidence interval - lower         0.167\n#>   90 Percent confidence interval - upper         0.231\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    1.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.129\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~                                                                 \n#>     X4                0.963    0.059   16.274    0.000    0.963    0.824\n#>     X5                1.121    0.067   16.835    0.000    1.121    0.846\n#>     X6                0.894    0.058   15.450    0.000    0.894    0.792\n#>     X7                0.195    0.071    2.767    0.006    0.195    0.170\n#>     X8                0.185    0.063    2.938    0.003    0.185    0.180\n#>     X9                0.278    0.065    4.245    0.000    0.278    0.258\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     f1                1.000                               1.000    1.000\n#>    .X4                0.437    0.056    7.775    0.000    0.437    0.320\n#>    .X5                0.500    0.071    6.998    0.000    0.500    0.285\n#>    .X6                0.474    0.054    8.777    0.000    0.474    0.372\n#>    .X7                1.278    0.105   12.211    0.000    1.278    0.971\n#>    .X8                1.023    0.084   12.204    0.000    1.023    0.967\n#>    .X9                1.080    0.089   12.132    0.000    1.080    0.933\n```\n:::\n\n\n\n\nSe trascuriamo le considerazioni sulla struttura fattoriale e esaminiamo (per esempio) unicamente il coefficiente omega, finiamo per trovare una risposta accettabile, ma sbagliata.\n\n\n\n\n::: {.cell layout-align=\"center\" lines_to_next_cell='2' vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\npsych::omega(d[, 1:6])\n#> Omega \n#> Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n#>     digits = digits, title = title, sl = sl, labels = labels, \n#>     plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n#>     covar = covar)\n#> Alpha:                 0.72 \n#> G.6:                   0.76 \n#> Omega Hierarchical:    0.55 \n#> Omega H asymptotic:    0.65 \n#> Omega Total            0.84 \n#> \n#> Schmid Leiman Factor loadings greater than  0.2 \n#>       g  F1*  F2*   F3*   h2   h2   u2   p2  com\n#> X4 0.73            0.68 1.00 1.00 0.00 0.53 1.99\n#> X5 0.96                 0.92 0.92 0.08 1.00 1.01\n#> X6 0.69            0.22 0.54 0.54 0.46 0.90 1.22\n#> X7           0.56       0.33 0.33 0.67 0.03 1.15\n#> X8           0.75       0.59 0.59 0.41 0.05 1.12\n#> X9 0.22      0.49       0.29 0.29 0.71 0.16 1.41\n#> \n#> With Sums of squares  of:\n#>    g  F1*  F2*  F3*   h2 \n#> 2.02 0.00 1.11 0.54 2.67 \n#> \n#> general/max  0.75   max/min =   622\n#> mean percent general =  0.44    with sd =  0.43 and cv of  0.97 \n#> Explained Common Variance of the general factor =  0.55 \n#> \n#> The degrees of freedom are 0  and the fit is  0 \n#> The number of observations was  301  with Chi Square =  0.03  with prob <  NA\n#> The root mean square of the residuals is  0 \n#> The df corrected root mean square of the residuals is  NA\n#> \n#> Compare this with the adequacy of just a general factor and no group factors\n#> The degrees of freedom for just the general factor are 9  and the fit is  0.48 \n#> The number of observations was  301  with Chi Square =  142  with prob <  3.5e-26\n#> The root mean square of the residuals is  0.17 \n#> The df corrected root mean square of the residuals is  0.21 \n#> \n#> RMSEA index =  0.222  and the 10 % confidence intervals are  0.191 0.255\n#> BIC =  90.9 \n#> \n#> Measures of factor score adequacy             \n#>                                                  g   F1*  F2*  F3*\n#> Correlation of scores with factors            0.96  0.08 0.83 0.96\n#> Multiple R square of scores with factors      0.93  0.01 0.68 0.91\n#> Minimum correlation of factor score estimates 0.86 -0.99 0.36 0.83\n#> \n#>  Total, General and Subset omega for each subset\n#>                                                  g  F1*  F2*  F3*\n#> Omega total for total scores and subscales    0.84 0.92 0.66 0.86\n#> Omega general for total scores and subscales  0.55 0.92 0.04 0.61\n#> Omega group for total scores and subscales    0.27 0.00 0.61 0.25\n```\n\n::: {.cell-output-display}\n![](07_total_score_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nÈ invece necessario ipotizzare un modello congenerico a due fattori.\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nm2f_cong <- '\n  # all loadings are uniquely estimated on each factor\n  f1 =~ NA*X4 + X5 + X6\n  f2 =~ NA*X7 + X8 + X9\n  \n  # constrain factor variancse to 1\n  f1 ~~ 1*f1\n  f2 ~~ 1*f2\n  \n  # estimate factor covariance\n  f1 ~~ f2\n'\n```\n:::\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\n# Fit above model\nfit_2f_congeneric <- sem(m2f_cong, data=d)\n```\n:::\n\n\n\n\nSolo questo modello fornisce un adattamento adeguato ai dati.\n\n\n\n\n::: {.cell layout-align=\"center\" lines_to_next_cell='2' vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nout = summary(fit_2f_congeneric, fit.measures = TRUE, standardized = TRUE)\nprint(out)\n#> lavaan 0.6-19 ended normally after 18 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        13\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                14.736\n#>   Degrees of freedom                                 8\n#>   P-value (Chi-square)                           0.064\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               568.519\n#>   Degrees of freedom                                15\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.988\n#>   Tucker-Lewis Index (TLI)                       0.977\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2525.349\n#>   Loglikelihood unrestricted model (H1)      -2517.981\n#>                                                       \n#>   Akaike (AIC)                                5076.698\n#>   Bayesian (BIC)                              5124.891\n#>   Sample-size adjusted Bayesian (SABIC)       5083.662\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.053\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.095\n#>   P-value H_0: RMSEA <= 0.050                    0.402\n#>   P-value H_0: RMSEA >= 0.080                    0.159\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~                                                                 \n#>     X4                0.965    0.059   16.296    0.000    0.965    0.826\n#>     X5                1.123    0.067   16.845    0.000    1.123    0.847\n#>     X6                0.895    0.058   15.465    0.000    0.895    0.793\n#>   f2 =~                                                                 \n#>     X7                0.659    0.080    8.218    0.000    0.659    0.575\n#>     X8                0.733    0.077    9.532    0.000    0.733    0.712\n#>     X9                0.599    0.075    8.025    0.000    0.599    0.557\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 ~~                                                                 \n#>     f2                0.275    0.072    3.813    0.000    0.275    0.275\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     f1                1.000                               1.000    1.000\n#>     f2                1.000                               1.000    1.000\n#>    .X4                0.433    0.056    7.679    0.000    0.433    0.318\n#>    .X5                0.496    0.072    6.892    0.000    0.496    0.282\n#>    .X6                0.472    0.054    8.732    0.000    0.472    0.371\n#>    .X7                0.881    0.100    8.807    0.000    0.881    0.670\n#>    .X8                0.521    0.094    5.534    0.000    0.521    0.492\n#>    .X9                0.798    0.087    9.162    0.000    0.798    0.689\n```\n:::\n\n\n\n\nNel contesto di questi dati, l'utilizzo di un modello congenerico non è sufficiente a giustificare l'impiego del punteggio totale, che rappresenta la somma dei punteggi degli item. Questo perché, nel caso specifico, sommando i punteggi di tutti gli item, finiremmo per includere misurazioni di due costrutti distinti.\n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] modelsummary_2.3.0 ggokabeito_0.1.0   see_0.10.0        \n#>  [4] MASS_7.3-64        viridis_0.6.5      viridisLite_0.4.2 \n#>  [7] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#> [10] patchwork_1.3.0    bayesplot_1.11.1   semTools_0.5-6    \n#> [13] semPlot_1.1.6      lavaan_0.6-19      psych_2.4.12      \n#> [16] scales_1.3.0       markdown_1.13      knitr_1.49        \n#> [19] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1     \n#> [22] dplyr_1.1.4        purrr_1.0.4        readr_2.1.5       \n#> [25] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#> [28] tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1    jsonlite_1.8.9       magrittr_2.0.3      \n#>   [4] TH.data_1.1-3        estimability_1.5.1   farver_2.1.2        \n#>   [7] nloptr_2.1.1         rmarkdown_2.29       vctrs_0.6.5         \n#>  [10] minqa_1.2.8          base64enc_0.1-3      rstatix_0.7.2       \n#>  [13] htmltools_0.5.8.1    broom_1.0.7          Formula_1.2-5       \n#>  [16] htmlwidgets_1.6.4    plyr_1.8.9           sandwich_3.1-1      \n#>  [19] rio_1.2.3            emmeans_1.10.7       zoo_1.8-12          \n#>  [22] igraph_2.1.4         mime_0.12            lifecycle_1.0.4     \n#>  [25] pkgconfig_2.0.3      Matrix_1.7-2         R6_2.5.1            \n#>  [28] fastmap_1.2.0        rbibutils_2.3        shiny_1.10.0        \n#>  [31] digest_0.6.37        OpenMx_2.21.13       fdrtool_1.2.18      \n#>  [34] colorspace_2.1-1     rprojroot_2.0.4      Hmisc_5.2-2         \n#>  [37] labeling_0.4.3       timechange_0.3.0     abind_1.4-8         \n#>  [40] compiler_4.4.2       withr_3.0.2          glasso_1.11         \n#>  [43] htmlTable_2.4.3      backports_1.5.0      carData_3.0-5       \n#>  [46] R.utils_2.12.3       ggsignif_0.6.4       GPArotation_2024.3-1\n#>  [49] corpcor_1.6.10       gtools_3.9.5         tools_4.4.2         \n#>  [52] pbivnorm_0.6.0       foreign_0.8-88       zip_2.3.2           \n#>  [55] httpuv_1.6.15        nnet_7.3-20          R.oo_1.27.0         \n#>  [58] glue_1.8.0           quadprog_1.5-8       nlme_3.1-167        \n#>  [61] promises_1.3.2       lisrelToR_0.3        grid_4.4.2          \n#>  [64] checkmate_2.3.2      cluster_2.1.8        reshape2_1.4.4      \n#>  [67] generics_0.1.3       gtable_0.3.6         tzdb_0.4.0          \n#>  [70] R.methodsS3_1.8.2    data.table_1.16.4    hms_1.1.3           \n#>  [73] car_3.1-3            tables_0.9.31        sem_3.1-16          \n#>  [76] pillar_1.10.1        rockchalk_1.8.157    later_1.4.1         \n#>  [79] splines_4.4.2        lattice_0.22-6       survival_3.8-3      \n#>  [82] kutils_1.73          tidyselect_1.2.1     miniUI_0.1.1.1      \n#>  [85] pbapply_1.7-2        reformulas_0.4.0     stats4_4.4.2        \n#>  [88] xfun_0.50            qgraph_1.9.8         arm_1.14-4          \n#>  [91] stringi_1.8.4        yaml_2.3.10          pacman_0.5.1        \n#>  [94] boot_1.3-31          evaluate_1.0.3       codetools_0.2-20    \n#>  [97] mi_1.1               cli_3.6.3            RcppParallel_5.1.10 \n#> [100] rpart_4.1.24         xtable_1.8-4         Rdpack_2.6.2        \n#> [103] munsell_0.5.1        Rcpp_1.0.14          coda_0.19-4.1       \n#> [106] png_0.1-8            XML_3.99-0.18        parallel_4.4.2      \n#> [109] jpeg_0.1-10          lme4_1.1-36          mvtnorm_1.3-3       \n#> [112] openxlsx_4.2.8       rlang_1.1.5          multcomp_1.4-28     \n#> [115] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "07_total_score_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
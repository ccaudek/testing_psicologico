{
  "hash": "1dcc38218bd1232def653c5a527a4214",
  "result": {
    "engine": "knitr",
    "markdown": "# Punteggio totale e modello fattoriale {#sec-fa-total-score}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- comprendere le condizioni che giustificano l'uso del punteggio totale del test.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, modelsummary)\n```\n:::\n\n\n\n\n:::\n\n\n## Introduzione\n\nIn questo capitolo affrontiamo una questione centrale nella costruzione e interpretazione dei test psicometrici: **è corretto utilizzare il punteggio totale come misura del costrutto latente che il test intende rilevare?**\n\nL’uso del punteggio totale (cioè la semplice somma dei punteggi degli item) è una pratica diffusissima nella ricerca psicologica e nelle applicazioni cliniche. Tuttavia, tale uso è **giustificabile solo in circostanze ben precise**. Come mostrano @mcneish2020thinking, è necessario verificare che i dati raccolti rispettino determinate assunzioni. In caso contrario, il punteggio totale può essere **una misura fuorviante del costrutto**.\n\nPer comprendere quando il punteggio totale può essere considerato una misura adeguata del costrutto latente, dobbiamo considerare il legame tra il punteggio totale e i modelli di misura fattoriali, in particolare il modello parallelo e il modello congenerico.\n\n## Punteggio totale e modello fattoriale parallelo\n\n### Il modello parallelo\n\nSecondo @mcneish2020thinking, il punteggio totale può essere considerato una misura valida del costrutto solo se gli item soddisfano i requisiti del **modello fattoriale parallelo**. Questo modello implica:\n\n- **saturazioni fattoriali uguali per tutti gli item** (ad esempio, tutte uguali a 1);\n- **varianze residue uguali tra gli item**.\n\nIn termini psicometrici, questo significa assumere che **ogni item contribuisce nella stessa misura alla valutazione del costrutto**, e che ha lo stesso livello di \"rumore\" o errore.\n\n### Esempio: Dati di Holzinger e Swineford (1939)\n\n@mcneish2020thinking illustrano il problema usando i dati classici di Holzinger e Swineford. Gli item considerati sono:\n\n- Paragraph comprehension  \n- Sentence completion  \n- Word definitions  \n- Speeded addition  \n- Speeded dot counting  \n- Discrimination between curved and straight letters\n\nImportiamo i dati in R:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- rio::import(here::here(\"data\", \"1_Factor_Parallel.csv\"))\n```\n:::\n\n\n\n\n\nSupponiamo ora di voler stimare il costrutto sottostante utilizzando il punteggio totale:\n\n$$\n\\text{Punteggio totale} = \\text{Item 1 + Item 2 + Item 3 + Item 4 + Item 5 + Item 6}\n$$\n\nQuesto equivale ad assumere che **ogni item fornisca esattamente la stessa quantità di informazione** sul costrutto. Formalmente, ciò può essere espresso da un modello parallelo nel quale tutte le saturazioni fattoriali sono fissate a 1 e tutte le varianze residue sono uguali.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_parallel <- \"\n  f1 =~ 1*X4 + 1*X5 + 1*X6 + 1*X7 + 1*X8 + 1*X9\n  X4 ~~ theta*X4\n  X5 ~~ theta*X5\n  X6 ~~ theta*X6\n  X7 ~~ theta*X7\n  X8 ~~ theta*X8\n  X9 ~~ theta*X9\n\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_parallel <- sem(m_parallel, data = d)\n```\n:::\n\n\n\n\n\n\n### Confronto tra punteggio totale e punteggio fattoriale\n\nCalcoliamo ora il punteggio totale e i punteggi fattoriali stimati dal modello:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd$ts <- with(d, X4 + X5 + X6 + X7 + X8 + X9)\nd$scores <- as.numeric(lavPredict(fit_parallel, method=\"regression\"))\n```\n:::\n\n\n\n\n\nVisualizziamo la relazione tra i due:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(d, aes(x = ts, y = scores)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](07_total_score_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nSe il modello parallelo fosse corretto, il punteggio totale e il punteggio fattoriale dovrebbero essere **perfettamente correlati**. Tuttavia, l’output di `lavaan` mostra che il modello parallelo **non si adatta bene ai dati**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit_parallel, fit.measures = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 13 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         7\n#>   Number of equality constraints                     5\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                               325.899\n#>   Degrees of freedom                                19\n#>   P-value (Chi-square)                           0.000\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               568.519\n#>   Degrees of freedom                                15\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.446\n#>   Tucker-Lewis Index (TLI)                       0.562\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2680.931\n#>   Loglikelihood unrestricted model (H1)      -2517.981\n#>                                                       \n#>   Akaike (AIC)                                5365.862\n#>   Bayesian (BIC)                              5373.276\n#>   Sample-size adjusted Bayesian (SABIC)       5366.933\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.232\n#>   90 Percent confidence interval - lower         0.210\n#>   90 Percent confidence interval - upper         0.254\n#>   P-value H_0: RMSEA <= 0.050                    0.000\n#>   P-value H_0: RMSEA >= 0.080                    1.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.206\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~                                                                 \n#>     X4                1.000                               0.633    0.551\n#>     X5                1.000                               0.633    0.551\n#>     X6                1.000                               0.633    0.551\n#>     X7                1.000                               0.633    0.551\n#>     X8                1.000                               0.633    0.551\n#>     X9                1.000                               0.633    0.551\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>    .X4      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X5      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X6      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X7      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X8      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>    .X9      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n#>     f1                0.400    0.045    8.803    0.000    1.000    1.000\n```\n:::\n\n\n\n\n\nIn questo caso, **l’uso del punteggio totale non è giustificato**: gli item non contribuiscono in modo uniforme alla misura del costrutto, e le ipotesi del modello parallelo non sono rispettate.\n\n## Punteggio totale e modello congenerico\n\n### Il modello congenerico\n\nIl modello congenerico è una generalizzazione del modello parallelo. Qui si **ammette che gli item possano avere saturazioni fattoriali differenti** e varianze residue differenti. In pratica, si riconosce che alcuni item sono più informativi di altri.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_congeneric <- \"\n  f1 =~ NA*X4 + X5 + X6 + X7 + X8 + X9\n  f1 ~~ 1*f1\n\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_congeneric <- sem(m_congeneric, data = d)\n```\n:::\n\n\n\n\n\nAnalizziamo le saturazioni fattoriali:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparameterEstimates(fit_congeneric, standardized = TRUE) %>%\n  dplyr::filter(op == \"=~\") %>%\n  dplyr::select(\n    \"Latent Factor\" = lhs,\n    Indicator = rhs,\n    B = est,\n    SE = se,\n    Z = z,\n    \"p-value\" = pvalue,\n    Beta = std.all\n  ) %>%\n  knitr::kable(\n    digits = 3, booktabs = TRUE, format = \"markdown\",\n    caption = \"Factor Loadings\"\n  )\n```\n\n::: {.cell-output-display}\n\n\nTable: Factor Loadings\n\n|Latent Factor |Indicator |     B|    SE|      Z| p-value|  Beta|\n|:-------------|:---------|-----:|-----:|------:|-------:|-----:|\n|f1            |X4        | 0.963| 0.059| 16.274|   0.000| 0.824|\n|f1            |X5        | 1.121| 0.067| 16.835|   0.000| 0.846|\n|f1            |X6        | 0.894| 0.058| 15.450|   0.000| 0.792|\n|f1            |X7        | 0.195| 0.071|  2.767|   0.006| 0.170|\n|f1            |X8        | 0.185| 0.063|  2.938|   0.003| 0.180|\n|f1            |X9        | 0.278| 0.065|  4.245|   0.000| 0.258|\n\n\n:::\n:::\n\n\n\n\n\nCome si osserva, le saturazioni sono eterogenee. Ciò significa che **il costrutto latente si riflette diversamente nei vari item**. In tali casi, il punteggio totale—che attribuisce lo stesso peso a ciascun item—**è una misura distorta del costrutto**.\n\n### Confronto con i punteggi fattoriali del modello congenerico\n\nEsaminiamo la relazione tra i punteggi fattoriali del modello congenerico e il punteggio totale del test.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd$scores_cong <- as.numeric(lavPredict(fit_congeneric, method=\"regression\"))\n\nd |> \n  ggplot(aes(x = ts, y = scores_cong)) + \n  geom_point()\n\ncor(d$ts, d$scores_cong)^2\n#> [1] 0.766\n```\n\n::: {.cell-output-display}\n![](07_total_score_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nQui il coefficiente di determinazione è circa 0.77, il che implica che **due persone con lo stesso punteggio totale possono avere punteggi fattoriali molto diversi**, a seconda degli item approvati. Questo è un limite importante del punteggio totale, che non tiene conto del contributo specifico di ciascun item.\n\nSe ignoriamo le assunzioni del modello e guardiamo solo a un indice globale come l'**omega**, possiamo essere tratti in inganno:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npsych::omega(d[, 1:6])\n#> Omega \n#> Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n#>     digits = digits, title = title, sl = sl, labels = labels, \n#>     plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n#>     covar = covar)\n#> Alpha:                 0.72 \n#> G.6:                   0.76 \n#> Omega Hierarchical:    0.55 \n#> Omega H asymptotic:    0.65 \n#> Omega Total            0.84 \n#> \n#> Schmid Leiman Factor loadings greater than  0.2 \n#>       g  F1*  F2*   F3*   h2   h2   u2   p2  com\n#> X4 0.73            0.68 1.00 1.00 0.00 0.53 1.99\n#> X5 0.96                 0.92 0.92 0.08 1.00 1.01\n#> X6 0.69            0.22 0.54 0.54 0.46 0.90 1.22\n#> X7           0.56       0.33 0.33 0.67 0.03 1.15\n#> X8           0.75       0.59 0.59 0.41 0.05 1.12\n#> X9 0.22      0.49       0.29 0.29 0.71 0.16 1.41\n#> \n#> With Sums of squares  of:\n#>    g  F1*  F2*  F3*   h2 \n#> 2.02 0.00 1.11 0.54 2.67 \n#> \n#> general/max  0.75   max/min =   622.1\n#> mean percent general =  0.44    with sd =  0.43 and cv of  0.97 \n#> Explained Common Variance of the general factor =  0.55 \n#> \n#> The degrees of freedom are 0  and the fit is  0 \n#> The number of observations was  301  with Chi Square =  0.03  with prob <  NA\n#> The root mean square of the residuals is  0 \n#> The df corrected root mean square of the residuals is  NA\n#> \n#> Compare this with the adequacy of just a general factor and no group factors\n#> The degrees of freedom for just the general factor are 9  and the fit is  0.48 \n#> The number of observations was  301  with Chi Square =  142.3  with prob <  3.5e-26\n#> The root mean square of the residuals is  0.17 \n#> The df corrected root mean square of the residuals is  0.21 \n#> \n#> RMSEA index =  0.222  and the 10 % confidence intervals are  0.191 0.255\n#> BIC =  90.9 \n#> \n#> Measures of factor score adequacy             \n#>                                                  g   F1*  F2*  F3*\n#> Correlation of scores with factors            0.96  0.08 0.83 0.96\n#> Multiple R square of scores with factors      0.93  0.01 0.68 0.91\n#> Minimum correlation of factor score estimates 0.86 -0.99 0.36 0.83\n#> \n#>  Total, General and Subset omega for each subset\n#>                                                  g  F1*  F2*  F3*\n#> Omega total for total scores and subscales    0.84 0.92 0.66 0.86\n#> Omega general for total scores and subscales  0.55 0.92 0.04 0.61\n#> Omega group for total scores and subscales    0.27 0.00 0.61 0.25\n```\n\n::: {.cell-output-display}\n![](07_total_score_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nL’omega può risultare “accettabile” (`Omega Total  0.84`), ma ciò **non garantisce che il punteggio totale sia una misura valida del costrutto**.\n\n## Necessità di un modello a due fattori\n\nI dati suggeriscono invece la presenza di **due costrutti distinti**. Adattiamo quindi un **modello congenerico a due fattori**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2f_cong <- \"\n  f1 =~ NA*X4 + X5 + X6\n  f2 =~ NA*X7 + X8 + X9\n  f1 ~~ 1*f1\n  f2 ~~ 1*f2\n  f1 ~~ f2\n\"\nfit_2f_congeneric <- sem(m2f_cong, data = d)\nsummary(fit_2f_congeneric, fit.measures = TRUE, standardized = TRUE)\n#> lavaan 0.6-19 ended normally after 18 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        13\n#> \n#>   Number of observations                           301\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                14.736\n#>   Degrees of freedom                                 8\n#>   P-value (Chi-square)                           0.064\n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                               568.519\n#>   Degrees of freedom                                15\n#>   P-value                                        0.000\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.988\n#>   Tucker-Lewis Index (TLI)                       0.977\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)              -2525.349\n#>   Loglikelihood unrestricted model (H1)      -2517.981\n#>                                                       \n#>   Akaike (AIC)                                5076.698\n#>   Bayesian (BIC)                              5124.891\n#>   Sample-size adjusted Bayesian (SABIC)       5083.662\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.053\n#>   90 Percent confidence interval - lower         0.000\n#>   90 Percent confidence interval - upper         0.095\n#>   P-value H_0: RMSEA <= 0.050                    0.402\n#>   P-value H_0: RMSEA >= 0.080                    0.159\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.035\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Standard\n#>   Information                                 Expected\n#>   Information saturated (h1) model          Structured\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 =~                                                                 \n#>     X4                0.965    0.059   16.296    0.000    0.965    0.826\n#>     X5                1.123    0.067   16.845    0.000    1.123    0.847\n#>     X6                0.895    0.058   15.465    0.000    0.895    0.793\n#>   f2 =~                                                                 \n#>     X7                0.659    0.080    8.218    0.000    0.659    0.575\n#>     X8                0.733    0.077    9.532    0.000    0.733    0.712\n#>     X9                0.599    0.075    8.025    0.000    0.599    0.557\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>   f1 ~~                                                                 \n#>     f2                0.275    0.072    3.813    0.000    0.275    0.275\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n#>     f1                1.000                               1.000    1.000\n#>     f2                1.000                               1.000    1.000\n#>    .X4                0.433    0.056    7.679    0.000    0.433    0.318\n#>    .X5                0.496    0.072    6.892    0.000    0.496    0.282\n#>    .X6                0.472    0.054    8.732    0.000    0.472    0.371\n#>    .X7                0.881    0.100    8.807    0.000    0.881    0.670\n#>    .X8                0.521    0.094    5.534    0.000    0.521    0.492\n#>    .X9                0.798    0.087    9.162    0.000    0.798    0.689\n```\n:::\n\n\n\n\n\nIl modello mostra un buon adattamento. In questo scenario, **il punteggio totale aggrega item che misurano costrutti diversi**, perdendo così validità come indicatore di un singolo costrutto.\n\n## Conclusione\n\nL’uso del punteggio totale come stima del costrutto latente è una semplificazione che **deve essere giustificata empiricamente**: \n\n- é giustificato **solo se il modello parallelo è supportato dai dati**;\n- nel caso in cui gli item abbiano saturazioni diverse (modello congenerico), il punteggio totale **perde validità**;\n- se esistono **più costrutti latenti**, l’uso del punteggio totale può **introdurre errori sistematici**.\n\n**In sintesi:** prima di usare o interpretare un punteggio totale, è essenziale testare il modello fattoriale sottostante. I punteggi totali, per quanto comodi, possono essere ingannevoli [@mcneish2020thinking].\n\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] modelsummary_2.3.0 ggokabeito_0.1.0   see_0.11.0        \n#>  [4] MASS_7.3-65        viridis_0.6.5      viridisLite_0.4.2 \n#>  [7] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#> [10] patchwork_1.3.0    bayesplot_1.11.1   semTools_0.5-6    \n#> [13] semPlot_1.1.6      lavaan_0.6-19      psych_2.4.12      \n#> [16] scales_1.3.0       markdown_1.13      knitr_1.50        \n#> [19] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1     \n#> [22] dplyr_1.1.4        purrr_1.0.4        readr_2.1.5       \n#> [25] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#> [28] tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1    jsonlite_1.9.1       magrittr_2.0.3      \n#>   [4] TH.data_1.1-3        estimability_1.5.1   farver_2.1.2        \n#>   [7] nloptr_2.2.1         rmarkdown_2.29       vctrs_0.6.5         \n#>  [10] minqa_1.2.8          base64enc_0.1-3      rstatix_0.7.2       \n#>  [13] htmltools_0.5.8.1    broom_1.0.7          Formula_1.2-5       \n#>  [16] htmlwidgets_1.6.4    plyr_1.8.9           sandwich_3.1-1      \n#>  [19] rio_1.2.3            emmeans_1.10.7       zoo_1.8-13          \n#>  [22] igraph_2.1.4         mime_0.13            lifecycle_1.0.4     \n#>  [25] pkgconfig_2.0.3      Matrix_1.7-3         R6_2.6.1            \n#>  [28] fastmap_1.2.0        rbibutils_2.3        shiny_1.10.0        \n#>  [31] digest_0.6.37        OpenMx_2.21.13       fdrtool_1.2.18      \n#>  [34] colorspace_2.1-1     rprojroot_2.0.4      Hmisc_5.2-3         \n#>  [37] labeling_0.4.3       timechange_0.3.0     abind_1.4-8         \n#>  [40] compiler_4.4.2       withr_3.0.2          glasso_1.11         \n#>  [43] htmlTable_2.4.3      backports_1.5.0      carData_3.0-5       \n#>  [46] R.utils_2.13.0       ggsignif_0.6.4       GPArotation_2024.3-1\n#>  [49] corpcor_1.6.10       gtools_3.9.5         tools_4.4.2         \n#>  [52] pbivnorm_0.6.0       foreign_0.8-88       zip_2.3.2           \n#>  [55] httpuv_1.6.15        nnet_7.3-20          R.oo_1.27.0         \n#>  [58] glue_1.8.0           quadprog_1.5-8       nlme_3.1-167        \n#>  [61] promises_1.3.2       lisrelToR_0.3        grid_4.4.2          \n#>  [64] checkmate_2.3.2      cluster_2.1.8.1      reshape2_1.4.4      \n#>  [67] generics_0.1.3       gtable_0.3.6         tzdb_0.5.0          \n#>  [70] R.methodsS3_1.8.2    data.table_1.17.0    hms_1.1.3           \n#>  [73] car_3.1-3            tables_0.9.31        sem_3.1-16          \n#>  [76] pillar_1.10.1        rockchalk_1.8.157    later_1.4.1         \n#>  [79] splines_4.4.2        lattice_0.22-6       survival_3.8-3      \n#>  [82] kutils_1.73          tidyselect_1.2.1     miniUI_0.1.1.1      \n#>  [85] pbapply_1.7-2        reformulas_0.4.0     stats4_4.4.2        \n#>  [88] xfun_0.51            qgraph_1.9.8         arm_1.14-4          \n#>  [91] stringi_1.8.4        yaml_2.3.10          pacman_0.5.1        \n#>  [94] boot_1.3-31          evaluate_1.0.3       codetools_0.2-20    \n#>  [97] mi_1.1               cli_3.6.4            RcppParallel_5.1.10 \n#> [100] rpart_4.1.24         xtable_1.8-4         Rdpack_2.6.3        \n#> [103] munsell_0.5.1        Rcpp_1.0.14          coda_0.19-4.1       \n#> [106] png_0.1-8            XML_3.99-0.18        parallel_4.4.2      \n#> [109] jpeg_0.1-10          lme4_1.1-36          mvtnorm_1.3-3       \n#> [112] openxlsx_4.2.8       rlang_1.1.5          multcomp_1.4-28     \n#> [115] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "07_total_score_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "19e86437d1b139f97f267c6595c5a8fa",
  "result": {
    "engine": "knitr",
    "markdown": "# Il modello multifattoriale {#sec-fa-multifactor-model}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- calcolare e interpretare la correlazione parziale;\n- capire la teoria dei due fattori;\n- applicare e comprendere il metodo dell'annullamento della tetrade.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. \n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, semPlot, corrplot, tidyr, tidySEM, kableExtra)\n```\n:::\n\n\n\n:::\n\n\n## Fattori ortogonali\n\nLa teoria dei due fattori ha orientato per diversi anni le ricerche\nsull'intelligenza, finché Thurstone (1945) non propose una sua modifica,\nconosciuta come teoria multifattoriale. Secondo Thurstone la\ncovariazione tra le variabili manifeste non può essere spiegata da un\nunico fattore generale. Invece è necessario ipotizzare l'azione causale\ndi diversi fattori, definiti comuni, i quali si riferiscono solo ad\nalcune delle variabili considerate.\n\nIl modello plurifattoriale assume che ciascuna variabile manifesta sia\nespressa come funzione lineare di un certo numero $m$ di fattori comuni,\n$\\xi_1, \\xi_2, \\dots, \\xi_m$, responsabili della correlazione con le\naltre variabili, e di un solo fattore specifico (termine d'errore),\nresponsabile della variabilità della variabile stessa. Per $p$ variabili\nmanifeste, $Y_1, Y_2, \\dots, Y_p$, il modello fattoriale diventa quello\nindicato dal sistema di equazioni lineari descritto di seguito.\nIdealmente, $m$ dovrebbe essere molto più piccolo di $p$ così da\nconsentire una descrizione parsimoniosa delle variabili manifeste in\nfunzione di pochi fattori soggiacenti.\n\nLe variabili manifeste $Y$ sono indicizzate da $i = 1, \\dots, p.$ Le\nvariabili latenti $\\xi$ (fattori) sono indicizzate da $j = 1, \\dots, m.$\nI fattori specifici $\\delta$ sono indicizzati da $i = 1, \\dots, p.$ Le\nsaturazioni fattoriali si distinguono dunque tramite due indici, $i$ e\n$j$: il primo indice si riferisce alle variabili manifeste, il secondo\nsi riferisce ai fattori latenti.\n\nIndichiamo con $\\mu_i$, con $i=1, \\dots, p$ le medie delle $p$ variabili\nmanifeste $Y_1, Y_2, \\dots, Y_p$. Se non vi è alcun effetto delle\nvariabili comuni latenti, allora la variabile $Y_{ijk}$, dove $k$ è\nl'indice usato per i soggetti, sarà uguale a:\n\n$$\n\\begin{equation}\n\\begin{cases} \n  Y_{1k}    &= \\mu_1 + \\delta_{1k} \\\\\n&\\vdots\\\\\nY_{ik}   &= \\mu_i + \\delta_{ik}\\\\\n&\\vdots\\\\\nY_{pk}   &= \\mu_p + \\delta_{pk} \\notag\n\\end{cases}\n\\end{equation}\n$$\n\nSe invece le variabili manifeste rappresentano la somma\ndell'effetto causale di $m$ fattori comuni e di $p$ fattori specifici,\nallora possiamo scrivere: \n\n$$\n\\begin{equation}\n\\begin{cases} \n  Y_1  - \\mu_1  &= \\lambda_{11}\\xi_1 + \\dots + \\lambda_{1k}\\xi_k \\dots +\\lambda_{1m}\\xi_m + \\delta_1 \\\\\n&\\vdots\\\\\nY_i -  \\mu_i  &= \\lambda_{i1}\\xi_1 + \\dots +  \\lambda_{ik}\\xi_k \\dots +\\lambda_{im}\\xi_m + \\delta_i\\\\\n&\\vdots\\\\\nY_p - \\mu_p  &= \\lambda_{p1}\\xi_1 + \\dots +  \\lambda_{pk}\\xi_k \\dots +\\lambda_{pm}\\xi_m + \\delta_p \\notag\n\\end{cases}\n\\end{equation}\n$$\n\nNel precedente sistema di equazioni lineari,\n\n-   $\\xi_j$, con $j=1, \\dots, m$, rappresenta la $j$-esima variabile\n    inosservabile a fattore comune (ossia il $j$-esimo fattore comune a\n    tutte le variabili $Y_i$);\n-   $\\lambda_{ij}$ rappresenta il parametro, detto *saturazione* o\n    *peso* fattoriale, che riflette l'importanza del $j$-esimo fattore\n    comune nella composizione della $i$-esima variabile osservabile;\n-   $\\delta_i$ rappresenta il fattore specifico (o unico) di ogni\n    variabile manifesta $Y_i$.\n\nIn conclusione, secondo il modello multifattoriale, le variabili\nmanifeste $Y_i$, con $i=1, \\dots, p$, sono il risultato di una\n*combinazione lineare* di $m < p$ fattori inosservabili ad esse comuni\n$\\xi_j$, con $j=1, \\dots, m$, e di $p$ fattori specifici $\\delta_i$, con\n$i=1, \\dots, p$, anch'essi inosservabili e di natura residua.\n\n### Assunzioni del modello multifattoriale\n\nLe variabili inosservabili a fattore comune $\\xi_j$, con\n$j=1, \\dots, m$, in quanto latenti, non possiedono unità di misura.\nPertanto, per semplicità si assume che abbiano media zero,\n$\\mathbb{E}(\\xi_j)=0$, abbiano varianza unitaria,\n$\\mathbb{V} (\\xi_j)= \\mathbb{E}(\\xi_j^2) - [\\mathbb{E}(\\xi_j)]^2=1$, e siano incorrelate\ntra loro, $Cov(\\xi_j, \\xi_h)=0$, con $j, h = 1, \\dots, m; \\;j \\neq h$.\nSi assume inoltre che le variabili a fattore specifico $\\delta_i$ siano\ntra loro incorrelate, $Cov(\\delta_i,\\delta_k)=0$, con\n$i, k = 1, \\dots, p, \\; i \\neq k$, abbiano media zero,\n$\\mathbb{E}(\\delta_i)=0$, e varianza uguale a $\\mathbb{V} (\\delta_i) = \\psi_{ii}$.\nLa varianza $\\psi_{ii}$ è detta *varianza specifica* o *unicità* della\n$i$-esima variabile manifesta $Y_i$. Si assume infine che i fattori\nspecifici siano linearmente incorrelati con i fattori comuni, ovvero\n$Cov(\\xi_j, \\delta_i)=0$ per ogni $j=1, \\dots, m$ e per ogni\n$i=1\\dots,p$.\n\n### Interpretazione dei parametri del modello\n\n#### Covarianza tra variabili e fattori\n\nNell'ipotesi che le variabili $Y_i$ abbiano media nulla, la covarianza\ntra $Y_i$ e $\\xi_j$ è uguale alla saturazione fattoriale $\\lambda_{ij}$:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n  Cov(Y_i, \\xi_j) &= \\mathbb{E}(Y_i \\xi_j)\\notag\\\\\n  &=\\mathbb{E}\\left[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)\\xi_j \\right]\\notag\\\\\n  &= \\lambda_{i1}\\underbrace{\\mathbb{E}(\\xi_1\\xi_j)}_{=0} + \\dots + \n\\lambda_{ij}\\underbrace{\\mathbb{E}(\\xi_j^2)}_{=1} + \\dots \\notag\\\\\n& \\; + \\lambda_{im}\\underbrace{\\mathbb{E}(\\xi_m\\xi_j)}_{=0} +\n  \\underbrace{\\mathbb{E}(\\delta_i \\xi_j)}_{=0}\\notag\\\\\n  &= \\lambda_{ij}.\\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nAnche nel modello multifattoriale, dunque, le saturazioni fattoriali rappresentano le covarianze tra le variabili e i fattori:\n\n$$\nCov(Y_i, \\xi_j) = \\lambda_{ij} \\qquad i=1, \\dots, p; \\quad j= 1, \\dots, m. \n$$\n\nNaturalmente, se le variabili sono standardizzate, le saturazioni fattoriali diventano correlazioni: \n\n$$\nr_{ij} = \\lambda_{ij}. \n$$\n\n#### Espressione fattoriale della varianza\n\nCome nel modello monofattoriale, la varianza delle variabili manifeste\nsi decompone in una componente dovuta ai fattori comuni, chiamata\n*comunalità*, e in una componente specifica alle $Y_i$, chiamata\n*unicità*. Nell'ipotesi che le variabili $Y_i$ abbiano media nulla, la\nvarianza di $Y_i$ è uguale a \n\n$$\n\\begin{aligned}\n  \\mathbb{V} (Y_i) \n  &=\\mathbb{E}\\left[ (\\lambda_{i1} \\xi_1 + \\dots +\n    \\lambda_{im} \\xi_m + \\delta_i)^2 \\right].\n\\end{aligned}\n$$ {#eq-var-multifatt}\n\nCome si sviluppa il polinomio precedente? Il quadrato di un polinomio è uguale alla somma\ndei quadrati di tutti i termini più il doppio prodotto di ogni termine\nper ciascuno di quelli che lo seguono. Il valore atteso del quadrato del\nprimo termine è uguale a $\\lambda_{i1}^2\\mathbb{E}(\\xi_1^2)$ ma, essendo la\nvarianza di $\\xi_1$ uguale a $1$, otteniamo semplicemente\n$\\lambda_{i1}^2$. Lo stesso vale per i quadrati di tutti i termini\nseguenti tranne l'ultimo. Infatti, $\\mathbb{E}(\\delta_i^2)=\\psi_{ii}$. Per quel\nche riguarda i doppi prodotti, sono tutti nulli. In primo luogo perché,\nnel caso di fattori ortogonali, la covarianza tra i fattori comuni è\nnulla, $\\mathbb{E}(\\xi_j \\xi_h)=0$, con $j \\neq h$. In secondo luogo perché il\nfattori comuni cono incorrelati con i fattori specifici, quindi\n$\\mathbb{E}(\\delta_i \\xi_j)=0$.\n\nIn conclusione, \n\n$$\n\\begin{aligned}\n  \\mathbb{V}(Y_i) &= \\lambda_{i1}^2 + \\lambda_{i2}^2 + \\dots + \\lambda_{im}^2 + \\psi_{ii} \\notag\\\\\n  &= \\sum_{j=1}^m \\lambda_{ij}^2 + \\psi_{ii}\\notag\\\\\n  &= h_i^2 + \\psi_{ii}\\notag\\\\\n  &=\\text{communalità} + \\text{unicità},\\notag\n\\end{aligned}\n$$\n  \nla varianza della variabile manifesta $Y_i$ è suddivisa in due parti: il\nprimo addendo è definito comunalità poiché rappresenta la parte di\nvariabilità della $Y_i$ spiegata dai fattori comuni; il secondo addendo\nè invece definito varianza specifica (o unicità) poiché esprime la parte\ndi variabilità della $Y_i$ non spiegata dai fattori comuni.\n\n#### Espressione fattoriale della covarianza\n\nQuale esempio, consideriamo il caso di $p=5$ variabili osservabili e\n$m=2$ fattori ortogonali. Se le variabili manifeste sono 'centrate'\n(ovvero, se a ciascuna di esse sottraiamo la rispettiva media), allora\nil modello multifattoriale diventa \n\n$$\n\\begin{aligned}\n  Y_1 &= \\lambda_{11} \\xi_1 + \\lambda_{12} \\xi_2 + \\delta_1,\\notag\\\\\n  Y_2 &= \\lambda_{21} \\xi_1 + \\lambda_{22} \\xi_2 + \\delta_2,\\notag\\\\\n  Y_3 &= \\lambda_{31} \\xi_1 + \\lambda_{32} \\xi_2 + \\delta_3,\\notag\\\\\n  Y_4 &= \\lambda_{41} \\xi_1 + \\lambda_{42} \\xi_2 + \\delta_4,\\notag\\\\\n  Y_5 &= \\lambda_{51} \\xi_1 + \\lambda_{52} \\xi_2 + \\delta_5.\\notag\n\\end{aligned}\n$$\n\nNell'ipotesi che le variabili $Y_i$ abbiano media nulla, la\ncovarianza tra $Y_1$ e $Y_2$, ad esempio, è uguale a: \n\n$$\n\\begin{aligned}\n  Cov(Y_1, Y_2) &= \\mathbb{E}\\left( Y_1 Y_2\\right) \\notag\\\\\n  &= \\mathbb{E}\\left[ \n  (\\lambda_{11} \\xi_1 + \\lambda_{12} \\xi_2 + \\delta_1)\n   (\\lambda_{21} \\xi_1 + \\lambda_{22} \\xi_2 +  \\delta_2)\n  \\right]\\notag\\\\\n  &= \\lambda_{11} \\lambda_{21} \\mathbb{E}(\\xi_1^2) +\n      \\lambda_{11} \\lambda_{22} \\mathbb{E}(\\xi_1 \\xi_2) +\\notag \n      \\lambda_{11} \\mathbb{E}(\\xi_1 \\delta_2) +\\notag\\\\\n    &\\quad \\lambda_{12} \\lambda_{21}\\mathbb{E}(\\xi_1 \\xi_2)\\, + \n      \\lambda_{12} \\lambda_{22}\\mathbb{E}(\\xi^2_2)\\, + \n      \\lambda_{12} \\mathbb{E}(\\xi_2\\delta_2) +\\notag\\\\\n    &\\quad \\lambda_{21} \\mathbb{E}(\\xi_1\\delta_1) +\\notag \n     \\lambda_{22} \\mathbb{E}(\\xi_2\\delta_1) + \\mathbb{E}(\\delta_1 \\delta_2)\\notag\\\\\n   &= \\lambda_{11} \\lambda_{21} + \\lambda_{12} \\lambda_{22}.\\notag\n\\end{aligned}\n$$\n\nIn conclusione, la covarianza tra le variabili manifeste $Y_l$ e $Y_m$\nriprodotta dal modello è data dalla somma dei prodotti delle saturazioni\n$\\lambda_l \\lambda_m$ nei due fattori.\n\n**Esempio.** Consideriamo i dati riportati da @brown2015confirmatory, ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti:\n\n- anxiety (N1), \n- hostility (N2), \n- depression (N3), \n- self-consciousness (N4), \n- warmth (E1), \n- gregariousness (E2), \n- assertiveness (E3), \n- positive emotions (E4). \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvarnames <- c(\"N1\", \"N2\", \"N3\", \"N4\", \"E1\", \"E2\", \"E3\", \"E4\")\nsds <- '5.7  5.6  6.4  5.7  6.0  6.2  5.7  5.6'\n\ncors <- '\n    1.000\n    0.767  1.000 \n    0.731  0.709  1.000 \n    0.778  0.738  0.762  1.000 \n    -0.351  -0.302  -0.356  -0.318  1.000 \n    -0.316  -0.280  -0.300  -0.267  0.675  1.000 \n    -0.296  -0.289  -0.297  -0.296  0.634  0.651  1.000 \n    -0.282  -0.254  -0.292  -0.245  0.534  0.593  0.566  1.000\n'\n\npsychot_cor_mat <- getCov(cors, names = varnames)\nn <- 250\n```\n:::\n\n\n\n\nEseguiamo l'analisi fattoriale esplorativa con il metodo della massima verosimiglianza ipotizzando due fattori comuni incorrelati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn_facs <- 2\nfit_efa <- factanal(\n  covmat = psychot_cor_mat,\n  factors = n_facs,\n  rotation = \"varimax\",\n  n.obs = n\n)\n```\n:::\n\n\n\n\nEsaminiamo le saturazioni fattoriali:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda <- fit_efa$loadings\nlambda\n#> \n#> Loadings:\n#>    Factor1 Factor2\n#> N1  0.854  -0.228 \n#> N2  0.826  -0.194 \n#> N3  0.811  -0.233 \n#> N4  0.865  -0.186 \n#> E1 -0.202   0.773 \n#> E2 -0.139   0.829 \n#> E3 -0.158   0.771 \n#> E4 -0.147   0.684 \n#> \n#>                Factor1 Factor2\n#> SS loadings      2.923   2.526\n#> Proportion Var   0.365   0.316\n#> Cumulative Var   0.365   0.681\n```\n:::\n\n\n\n\nLa soluzione fattoriale conferma la presenza di due fattori: il primo fattore satura sulle scale di neutoricismo, il secono sulle scale di estroversione.\n\nLa correlazione riprodotta $r_{12}$ è uguale a $\\lambda_{11}\\lambda_{21} + \\lambda_{12}\\lambda_{22}$ \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda[1, 1] * lambda[2, 1] + lambda[1, 2] * lambda[2, 2]\n#> [1] 0.749\n```\n:::\n\n\n\n\ne corrisponde da vicino alla correlazione osservata 0.767.\n\nL'intera matrice di correlazioni riprodotte è\n$\\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\psi}$:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nRr <- lambda %*% t(lambda) + diag(fit_efa$uniq)\nRr |> \n  round(3)\n#>        N1     N2     N3     N4     E1     E2     E3     E4\n#> N1  1.000  0.749  0.745  0.781 -0.348 -0.307 -0.311 -0.281\n#> N2  0.749  1.000  0.715  0.751 -0.317 -0.276 -0.281 -0.254\n#> N3  0.745  0.715  1.000  0.745 -0.344 -0.306 -0.308 -0.279\n#> N4  0.781  0.751  0.745  1.000 -0.318 -0.274 -0.280 -0.254\n#> E1 -0.348 -0.317 -0.344 -0.318  1.000  0.669  0.628  0.558\n#> E2 -0.307 -0.276 -0.306 -0.274  0.669  1.000  0.661  0.587\n#> E3 -0.311 -0.281 -0.308 -0.280  0.628  0.661  1.000  0.550\n#> E4 -0.281 -0.254 -0.279 -0.254  0.558  0.587  0.550  1.000\n```\n:::\n\n\n\n\nLa differenza tra la matrice di correlazioni riprodotte e la matrice di\ncorrelazioni osservate è uguale a:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(psychot_cor_mat - Rr) |> \n  round(3)\n#>        N1     N2     N3     N4     E1     E2     E3     E4\n#> N1  0.000  0.018 -0.014 -0.003 -0.003 -0.009  0.015 -0.001\n#> N2  0.018  0.000 -0.006 -0.013  0.015 -0.004 -0.008  0.000\n#> N3 -0.014 -0.006  0.000  0.017 -0.012  0.006  0.011 -0.013\n#> N4 -0.003 -0.013  0.017  0.000  0.000  0.007 -0.016  0.009\n#> E1 -0.003  0.015 -0.012  0.000  0.000  0.006  0.006 -0.024\n#> E2 -0.009 -0.004  0.006  0.007  0.006  0.000 -0.010  0.006\n#> E3  0.015 -0.008  0.011 -0.016  0.006 -0.010  0.000  0.016\n#> E4 -0.001  0.000 -0.013  0.009 -0.024  0.006  0.016  0.000\n```\n:::\n\n\n\n\n## Fattori obliqui\n\nAnche nel caso di fattori comuni correlati è possibile esprimere nei\ntermini dei parametri del modello la covarianza teorica tra una\nvariabile manifesta $Y_i$ e uno dei fattori comuni, la covarianza\nteorica tra due variabili manifeste, e la comunalità di ciascuna\nvariabile manifesta. Dato però che i fattori comuni risultano correlati,\nl'espressione fattoriale di tali quantità è più complessa che nel caso\ndi fattori comuni ortogonali.\n\n### Covarianza teorica tra variabili e fattori\n\nIn base al modello multifattoriale con $m$ fattori comuni la variabile\n$Y_i$ è\n\n$$\nY_i = \\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i.\n(\\#eq:mod-multifact)\n$$ \n\nPoniamoci il problema di trovare la\ncovarianza teorica tra la variabile manifesta $Y_i$ e il fattore comune\n$\\xi_j$. Come in precedenza, il problema si riduce a quello di trovare\n$\\mathbb{E}(Y_i \\xi_j)$. Ne segue che \n\n$$\n\\begin{equation}\n\\begin{aligned}\n  Cov(Y_i, \\xi_j) &= \\mathbb{E}(Y_i \\xi_j)\\notag\\\\\n  &=\\mathbb{E}\\left[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{ij} \\xi_j + \\dots + \\lambda_{im} \\xi_m + \\delta_i)\\xi_j \\right]\\notag\\\\\n  &= \\lambda_{i1}\\underbrace{\\mathbb{E}(\\xi_1\\xi_j)}_{\\neq 0} + \\dots + \\lambda_{ij}\\underbrace{\\mathbb{E}(\\xi_j^2)}_{=1} + \\dots \\notag\\\\\n& \\quad + \\lambda_{im}\\underbrace{\\mathbb{E}(\\xi_m\\xi_j)}_{\\neq 0} + \\underbrace{\\mathbb{E}(\\delta_i \\xi_j)}_{=0}\\notag\\\\\n  &= \\lambda_{ij} + \\lambda_{i1} Cov(\\xi_1, \\xi_j) + \\dots + \\lambda_{im} Cov(\\xi_m, \\xi_j).\n\\end{aligned}\n\\end{equation}\n$$\n\nAd esempio, nel caso di tre fattori comuni $\\xi_1, \\xi_2, \\xi_3$, la\ncovarianza tra $Y_1$ e $\\xi_{1}$ diventa\n\n$$\n\\lambda_{11} + \\lambda_{12}Cov(\\xi_1, \\xi_2) + \\lambda_{13}Cov(\\xi_1, \\xi_3).\n$$\n\n### Espressione fattoriale della varianza\n\nPoniamoci ora il problema di trovare la varianza teorica della variabile\nmanifesta $Y_i$. In base al modello fattoriale, la variabile $Y_i$ è\nspecificata come nella \\@ref(eq:mod-multifact). La varianza di $Y_i$ è\n$\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) -[\\mathbb{E}(Y_i)]^2$. Però, avendo espresso $Y_i$ nei\ntermini della differenza dalla sua media, l'espressione della varianza\nsi riduce a $\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2)$. Dobbiamo dunque sviluppare\nl'espressione\n\n$$\n\\mathbb{E}(Y_i^2) = \\mathbb{E}[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)^2].\n$$\n\nIn conclusione, la varianza teorica di $Y_i$ è uguale a \n\n$$\n\\begin{equation}\n\\begin{split}\n\\mathbb{V}(Y_i) &= \\lambda_{i1}^2 + \\lambda_{i2}^2 + \\dots + \\lambda_{im}^2  + \\\\\n&\\quad 2 \\lambda_{i1} \\lambda_{i2} Cov(\\xi_1, \\xi_2) + \\dots + 2 \\lambda_{i,m-1} \\lambda_{im} Cov(\\xi_{m-1}, \\xi_m) + \\\\\n&\\quad \\psi_{ii}.\\notag\n\\end{split}\n\\end{equation}\n$$\n\nAd esempio, nel caso di tre fattori comuni, $\\xi_1, \\xi_2, \\xi_3$, la\nvarianza di $Y_1$ è \n\n$$\n\\begin{equation}\n\\begin{split}\n\\mathbb{V}(Y_1) = &\\lambda_{11}^2 + \\lambda_{12}^2 + \\lambda_{13}^2 +\\\\ \n&\\quad 2 \\lambda_{11} \\lambda_{12} Cov(\\xi_1, \\xi_2) + \\\\ \n&\\quad 2 \\lambda_{11} \\lambda_{13} Cov(\\xi_1, \\xi_3) + \\\\ \n&\\quad 2 \\lambda_{12} \\lambda_{13} Cov(\\xi_2, \\xi_3) + \\\\ \n&\\quad \\psi_{11}. \\notag\n\\end{split}\n\\end{equation}\n$$\n\n### Covarianza teorica tra due variabili\n\nConsideriamo ora il caso più semplice di due soli fattori comuni\ncorrelati e calcoliamo la covarianza tra $Y_1$ e $Y_2$:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n\\mathbb{E}(Y_1 Y_2) =\\mathbb{E}[(&\\lambda_{11}\\xi_1 + \\lambda_{12}\\xi_2+\\delta_1) (\\lambda_{21}\\xi_1 + \\lambda_{22}\\xi_2+\\delta_2)]\\notag\\\\\n=\\mathbb{E}( \n&\\lambda_{11}\\lambda_{21}\\xi_1^2 +\n\\lambda_{11}\\lambda_{22}\\xi_1\\xi_2 +\n\\lambda_{11}\\xi_1\\delta_2 +\\notag\\\\\n+&\\lambda_{12}\\lambda_{21}\\xi_1\\xi_2 +\n\\lambda_{12}\\lambda_{22}\\xi_2^2 +\n\\lambda_{12}\\xi_2\\delta_2 +\\notag\\\\\n+&\\lambda_{21}\\xi_1\\delta_1 +\n\\lambda_{22}\\xi_2\\delta_1 +\n\\delta_1\\delta_2).\\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nDistribuendo l'operatore di valore atteso, dato che $\\mathbb{E}(\\xi^2)=1$ e $\\mathbb{E}(\\xi \\delta)=0$, otteniamo\n\n$$\nCov(Y_1, Y_2) = \\lambda_{11} \\lambda_{21} + \\lambda_{12} \\lambda_{22} + \n\\lambda_{12} \\lambda_{21}Cov(\\xi_1, \\xi_2) +\\lambda_{11} \\lambda_{22}Cov(\\xi_1, \\xi_2).\n$$\n\nIn termini matriciali si scrive \n\n$$\n\\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi}, \n$$\n\ndove $\\boldsymbol{\\Phi}$ è la matrice di ordine $m \\times m$ di varianze\ne covarianze tra i fattori comuni e $\\boldsymbol{\\Psi}$ è una matrice\ndiagonale di ordine $p$ con le unicità delle variabili.\n\n**Esempio.** Consideriamo nuovamente i dati esaminati negli esercizi precedenti, ma questa volta il modello consente una correlazione tra i due fattori comuni:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefa_result <- fa(\n    psychot_cor_mat, \n    nfactors = 2, \n    n.obs = n, \n    rotate = \"oblimin\"\n)\nefa_result\n#> Factor Analysis using method =  minres\n#> Call: fa(r = psychot_cor_mat, nfactors = 2, n.obs = n, rotate = \"oblimin\")\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>      MR1   MR2   h2   u2 com\n#> N1  0.88 -0.02 0.78 0.22   1\n#> N2  0.85  0.01 0.72 0.28   1\n#> N3  0.83 -0.04 0.71 0.29   1\n#> N4  0.90  0.03 0.78 0.22   1\n#> E1 -0.05  0.77 0.63 0.37   1\n#> E2  0.03  0.86 0.71 0.29   1\n#> E3  0.00  0.79 0.63 0.37   1\n#> E4 -0.01  0.70 0.49 0.51   1\n#> \n#>                        MR1  MR2\n#> SS loadings           3.00 2.45\n#> Proportion Var        0.37 0.31\n#> Cumulative Var        0.37 0.68\n#> Proportion Explained  0.55 0.45\n#> Cumulative Proportion 0.55 1.00\n#> \n#>  With factor correlations of \n#>       MR1   MR2\n#> MR1  1.00 -0.43\n#> MR2 -0.43  1.00\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 2 factors are sufficient.\n#> \n#> df null model =  28  with the objective function =  5.02 with Chi Square =  1231\n#> df of  the model are 13  and the objective function was  0.04 \n#> \n#> The root mean square of the residuals (RMSR) is  0.01 \n#> The df corrected root mean square of the residuals is  0.02 \n#> \n#> The harmonic n.obs is  250 with the empirical chi square  1.73  with prob <  1 \n#> The total n.obs was  250  with Likelihood Chi Square =  9.65  with prob <  0.72 \n#> \n#> Tucker Lewis Index of factoring reliability =  1.01\n#> RMSEA index =  0  and the 90 % confidence intervals are  0 0.047\n#> BIC =  -62.1\n#> Fit based upon off diagonal values = 1\n#> Measures of factor score adequacy             \n#>                                                    MR1  MR2\n#> Correlation of (regression) scores with factors   0.96 0.94\n#> Multiple R square of scores with factors          0.93 0.87\n#> Minimum correlation of possible factor scores     0.85 0.75\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfa.diagram(efa_result)\n```\n\n::: {.cell-output-display}\n![](04_analisi_fattoriale_3_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nEsaminiamo la matrice delle correlazioni residue:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresiduals <- residuals(efa_result)\nresiduals\n#>    N1    N2    N3    N4    E1    E2    E3    E4   \n#> N1  0.22                                          \n#> N2  0.02  0.28                                    \n#> N3 -0.01  0.00  0.29                              \n#> N4  0.00 -0.01  0.02  0.22                        \n#> E1  0.00  0.01 -0.01  0.00  0.37                  \n#> E2 -0.01  0.00  0.01  0.01  0.01  0.29            \n#> E3  0.01 -0.01  0.01 -0.02  0.01 -0.01  0.37      \n#> E4  0.00  0.00 -0.01  0.01 -0.02  0.01  0.01  0.51\n```\n:::\n\n\n\n\nEsaminiamo più da vicino la matrice di correlazioni riprodotta dal modello, nel caso di fattori obliqui. Le saturazioni fattoriali sono:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estrai i carichi fattoriali (saturazioni fattoriali)\nlambda <- efa_result$loadings\n\n# Converti i carichi in una matrice 8 x 2 (assumendo 2 fattori)\n# e assegna i nomi appropriati alle righe e alle colonne\nlambda <- matrix(lambda[, 1:2], nrow = 8, ncol = 2)\nrownames(lambda) <- c(\"N1\", \"N2\", \"N3\", \"N4\", \"E1\", \"E2\", \"E3\", \"E4\")\ncolnames(lambda) <- c(\"Factor1\", \"Factor2\")\n\n# Stampa la matrice dei carichi\nlambda\n#>     Factor1 Factor2\n#> N1  0.87708 -0.0158\n#> N2  0.85228  0.0113\n#> N3  0.82658 -0.0368\n#> N4  0.89876  0.0312\n#> E1 -0.04859  0.7719\n#> E2  0.03470  0.8557\n#> E3  0.00282  0.7929\n#> E4 -0.00788  0.6955\n```\n:::\n\n\n\n\nLa matrice di intercorrelazoni fattoriali è\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estrai la matrice delle intercorrelazioni fattoriali\nPhi <- efa_result$Phi\n\n# Stampa la matrice delle intercorrelazioni\nPhi\n#>        MR1    MR2\n#> MR1  1.000 -0.431\n#> MR2 -0.431  1.000\n```\n:::\n\n\n\n\nLe varianze residue sono:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estrai le varianze residue\nPsi <- diag(efa_result$uniquenesses)\n\nPsi |>\n    round(2)\n#>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n#> [1,] 0.22 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n#> [2,] 0.00 0.28 0.00 0.00 0.00 0.00 0.00 0.00\n#> [3,] 0.00 0.00 0.29 0.00 0.00 0.00 0.00 0.00\n#> [4,] 0.00 0.00 0.00 0.22 0.00 0.00 0.00 0.00\n#> [5,] 0.00 0.00 0.00 0.00 0.37 0.00 0.00 0.00\n#> [6,] 0.00 0.00 0.00 0.00 0.00 0.29 0.00 0.00\n#> [7,] 0.00 0.00 0.00 0.00 0.00 0.00 0.37 0.00\n#> [8,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.51\n```\n:::\n\n\n\n\nMediante i parametri del modello  la matrice di correlazione si riproduce nel modo seguente:\n\n$$\n\\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi}. \n$$\n\nIn $\\textsf{R}$ scriviamo:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nR_hat <- lambda %*% Phi %*% t(lambda) + Psi\nR_hat |> \n  round(2)\n#>       N1    N2    N3    N4    E1    E2    E3    E4\n#> N1  1.00  0.75  0.75  0.78 -0.35 -0.31 -0.31 -0.28\n#> N2  0.75  1.00  0.71  0.75 -0.32 -0.28 -0.28 -0.25\n#> N3  0.75  0.71  1.00  0.74 -0.34 -0.31 -0.31 -0.28\n#> N4  0.78  0.75  0.74  1.00 -0.32 -0.27 -0.28 -0.25\n#> E1 -0.35 -0.32 -0.34 -0.32  1.00  0.67  0.63  0.55\n#> E2 -0.31 -0.28 -0.31 -0.27  0.67  1.00  0.67  0.59\n#> E3 -0.31 -0.28 -0.31 -0.28  0.63  0.67  1.00  0.55\n#> E4 -0.28 -0.25 -0.28 -0.25  0.55  0.59  0.55  1.00\n```\n:::\n\n\n\n\nLe correlazioni residue sono:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npsychot_cor_mat - R_hat |>\n  round(2)\n#>        N1     N2     N3     N4     E1     E2     E3     E4\n#> N1  0.000  0.017 -0.019 -0.002 -0.001 -0.006  0.014 -0.002\n#> N2  0.017  0.000 -0.001 -0.012  0.018  0.000 -0.009 -0.004\n#> N3 -0.019 -0.001  0.000  0.022 -0.016  0.010  0.013 -0.012\n#> N4 -0.002 -0.012  0.022  0.000  0.002  0.003 -0.016  0.005\n#> E1 -0.001  0.018 -0.016  0.002  0.000  0.005  0.004 -0.016\n#> E2 -0.006  0.000  0.010  0.003  0.005  0.000 -0.019  0.003\n#> E3  0.014 -0.009  0.013 -0.016  0.004 -0.019  0.000  0.016\n#> E4 -0.002 -0.004 -0.012  0.005 -0.016  0.003  0.016  0.000\n```\n:::\n\n\n\n\nPer fare un esempio relativo alla correlazione tra due indicatori, calcoliamo la correlazione predetta dal modello tra le variabili $Y_1$ e $Y_2$:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda[1, 1] * lambda[2, 1] + lambda[1, 2] * lambda[2, 2] +\n  lambda[1, 1] * lambda[2, 2] * Phi[1, 2] + \n  lambda[1, 2] * lambda[2, 1] * Phi[1, 2] \n#> [1] 0.749\n```\n:::\n\n\n\n\nQuesto valore si avvicina al valore contenuto dell'elemento (1, 2) della\nmatrice di correlazioni osservate:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npsychot_cor_mat[1, 2]\n#> [1] 0.767\n```\n:::\n\n\n\n\nUsando questa procedura possiamo riprodurre tutti gli elementi della matrice di correlazione osservata tramite i parametri stimati dal modello EFA replicando così il risultato che si trova con $\\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi}$. \n\n## Session Info\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] kableExtra_1.4.0  tidySEM_0.2.7     OpenMx_2.21.13    corrplot_0.95    \n#>  [5] ggokabeito_0.1.0  see_0.9.0         MASS_7.3-64       viridis_0.6.5    \n#>  [9] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#> [13] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n#> [17] lavaan_0.6-19     psych_2.4.12      scales_1.3.0      markdown_1.13    \n#> [21] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [25] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#> [29] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2         later_1.4.1           XML_3.99-0.18        \n#>   [4] rpart_4.1.24          fastDummies_1.7.5     lifecycle_1.0.4      \n#>   [7] Rdpack_2.6.2          rstatix_0.7.2         rprojroot_2.0.4      \n#>  [10] StanHeaders_2.32.10   globals_0.16.3        lattice_0.22-6       \n#>  [13] rockchalk_1.8.157     backports_1.5.0       magrittr_2.0.3       \n#>  [16] openxlsx_4.2.8        Hmisc_5.2-2           rmarkdown_2.29       \n#>  [19] httpuv_1.6.15         tmvnsim_1.0-2         qgraph_1.9.8         \n#>  [22] zip_2.3.1             pkgbuild_1.4.6        pbapply_1.7-2        \n#>  [25] minqa_1.2.8           multcomp_1.4-26       abind_1.4-8          \n#>  [28] quadprog_1.5-8        nnet_7.3-20           TH.data_1.1-3        \n#>  [31] sandwich_3.1-1        inline_0.3.21         listenv_0.9.1        \n#>  [34] arm_1.14-4            proto_1.0.0           parallelly_1.41.0    \n#>  [37] texreg_1.39.4         svglite_2.1.3         codetools_0.2-20     \n#>  [40] xml2_1.3.6            tidyselect_1.2.1      farver_2.1.2         \n#>  [43] lme4_1.1-36           matrixStats_1.5.0     stats4_4.4.2         \n#>  [46] base64enc_0.1-3       jsonlite_1.8.9        progressr_0.15.1     \n#>  [49] Formula_1.2-5         survival_3.8-3        emmeans_1.10.6       \n#>  [52] systemfonts_1.2.1     dbscan_1.2.2          tools_4.4.2          \n#>  [55] Rcpp_1.0.14           glue_1.8.0            mnormt_2.1.1         \n#>  [58] xfun_0.50             MplusAutomation_1.1.1 loo_2.8.0            \n#>  [61] withr_3.0.2           fastmap_1.2.0         boot_1.3-31          \n#>  [64] digest_0.6.37         mi_1.1                timechange_0.3.0     \n#>  [67] R6_2.5.1              mime_0.12             estimability_1.5.1   \n#>  [70] colorspace_2.1-1      gtools_3.9.5          jpeg_0.1-10          \n#>  [73] generics_0.1.3        data.table_1.16.4     corpcor_1.6.10       \n#>  [76] httr_1.4.7            htmlwidgets_1.6.4     pkgconfig_2.0.3      \n#>  [79] sem_3.1-16            gtable_0.3.6          bain_0.2.11          \n#>  [82] htmltools_0.5.8.1     carData_3.0-5         blavaan_0.5-8        \n#>  [85] png_0.1-8             reformulas_0.4.0      rstudioapi_0.17.1    \n#>  [88] tzdb_0.4.0            reshape2_1.4.4        curl_6.2.0           \n#>  [91] coda_0.19-4.1         checkmate_2.3.2       nlme_3.1-167         \n#>  [94] nloptr_2.1.1          zoo_1.8-12            parallel_4.4.2       \n#>  [97] miniUI_0.1.1.1        nonnest2_0.5-8        foreign_0.8-88       \n#> [100] pillar_1.10.1         grid_4.4.2            vctrs_0.6.5          \n#> [103] RANN_2.6.2            promises_1.3.2        car_3.1-3            \n#> [106] xtable_1.8-4          cluster_2.1.8         GPArotation_2024.3-1 \n#> [109] htmlTable_2.4.3       evaluate_1.0.3        pbivnorm_0.6.0       \n#> [112] gsubfn_0.7            mvtnorm_1.3-3         cli_3.6.3            \n#> [115] kutils_1.73           compiler_4.4.2        rlang_1.1.5          \n#> [118] rstantools_2.4.0      future.apply_1.11.3   ggsignif_0.6.4       \n#> [121] fdrtool_1.2.18        plyr_1.8.9            stringi_1.8.4        \n#> [124] rstan_2.32.6          pander_0.6.5          QuickJSR_1.5.1       \n#> [127] munsell_0.5.1         lisrelToR_0.3         CompQuadForm_1.4.3   \n#> [130] V8_6.0.0              pacman_0.5.1          Matrix_1.7-2         \n#> [133] hms_1.1.3             glasso_1.11           future_1.34.0        \n#> [136] shiny_1.10.0          rbibutils_2.3         igraph_2.1.4         \n#> [139] broom_1.0.7           RcppParallel_5.1.10\n```\n:::\n",
    "supporting": [
      "04_analisi_fattoriale_3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "b50791f346e698b0a0842c7f2effd47c",
  "result": {
    "engine": "knitr",
    "markdown": "# Relazioni test-criterio {#sec-validity-rel-test-criterion}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- valutare l'accuratezza della classificazione di un test calcolando il punteggio AUC.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Prediction* del testo di @petersen2024principles.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readxl, haven, ROCit, psych, modelsummary)\n```\n:::\n\n\n\n:::\n\n\n## Introduzione\n\nIn questo capitolo, approfondiamo un aspetto specifico della validità già discusso: la relazione tra test e criterio. Per analizzare questo concetto in maniera sistematica, utilizzeremo un approccio quantitativo basato sulla regressione logistica. Questo strumento permette di valutare in modo dettagliato e rigoroso come i punteggi di un test siano correlati o predittivi rispetto a un criterio esterno specifico. Tale analisi offre una comprensione più completa della validità di uno strumento psicometrico, evidenziandone l’utilità pratica e teorica.\n\nIn particolare, ci concentreremo sulla capacità dei test di predire o differenziare fenomeni specifici attraverso la Relazione Test-Criterio. L’uso della regressione logistica consente di identificare le relazioni chiave tra le variabili e di quantificare il grado di validità di un test in contesti applicativi, fornendo così uno strumento fondamentale per la valutazione della qualità psicometrica.\n\n## Categorie di Evidenze Basate su Relazioni con Altre Variabili\n\nIn psicometria, diverse categorie di evidenze vengono utilizzate per valutare le relazioni tra i punteggi dei test e altre variabili. Tra le principali troviamo:\n\n1. **Relazioni Test-Criterio**  \n   Queste analisi si concentrano sull’utilizzo dei punteggi di un test per prevedere il rendimento o lo stato attuale in ambiti specifici, come il successo accademico o lavorativo.\n\n2. **Differenze tra Gruppi**  \n   Si valuta se i punteggi dei test mostrano differenze tra gruppi definiti da criteri specifici, ad esempio tra individui con e senza una diagnosi clinica.\n\n3. **Prove di Convergenza e Discriminazione**  \n   Si esplora se i punteggi di un test sono correlati con altri test che misurano costrutti simili (validità convergente) e se sono meno correlati con test che misurano costrutti diversi (validità discriminante).\n\nUn elemento cruciale nelle analisi basate sulle relazioni test-criterio è la selezione di un criterio appropriato e l'adozione di metodi quantitativi per esaminare questa relazione. Quando il criterio è di natura categorica, come il superamento o il fallimento di un esame, la **regressione logistica** rappresenta una tecnica essenziale.\n\n## Regressione Logistica\n\nLa regressione logistica è un metodo statistico utilizzato per analizzare la relazione tra una variabile dipendente binaria e una o più variabili indipendenti. Essa stima la probabilità che un’osservazione appartenga a una determinata categoria della variabile dipendente, sulla base dei valori delle variabili esplicative.\n\n### Modellazione della Relazione\n\nConsideriamo una variabile dipendente $Y_i$, che per ogni osservazione $i$ ($i = 1, \\dots, n$) assume due modalità, ad esempio *successo* e *insuccesso*. Ogni osservazione è associata a un vettore di variabili esplicative ($x_1, \\dots, x_p$); per semplicità, analizziamo il caso con una singola variabile indipendente.\n\nIl logaritmo del rapporto di probabilità (*odds*) tra successo e insuccesso è modellato come funzione lineare del predittore:\n\n$$\n\\eta_i = \\logit(\\pi_i) = \\alpha + \\beta x_i,\n$$\n\ndove $\\pi_i = Pr(Y=1 | X=x_i)$ rappresenta la probabilità che l’evento $Y = 1$ si verifichi, dato il valore della variabile indipendente $x_i$.\n\n### Distribuzione e Funzione di Collegamento\n\nNel caso di osservazioni indipendenti, si assume che $Y_i$ segua una distribuzione binomiale:\n\n$$\nY_i \\sim Bin(n_i, \\pi_i),\n$$\n\ndove $n_i$ rappresenta il numero di prove per ciascun valore $x_i$ (pari a 1 per dati individuali). La funzione di collegamento (*link function*) stabilisce la relazione tra il predittore lineare $\\eta_i$ e la probabilità $\\pi_i$:\n\n$$\n\\pi_i = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n$$\n\n### Applicazioni in Psicometria\n\nNel contesto dei test psicometrici, la regressione logistica è utilizzata per determinare quanto i punteggi di un test predicano un risultato categorico. Ad esempio, possiamo valutare la probabilità che studenti con determinati punteggi in un test di ammissione universitario abbiano successo accademico nel primo anno.\n\nQuesta tecnica consente di:\n\n- **Quantificare la validità predittiva** di uno strumento di misura.  \n- **Identificare soglie critiche** nei punteggi che separano categorie di interesse.  \n- **Fornire interpretazioni robuste** sull’efficacia del test in contesti pratici.\n\nIn sintesi, la regressione logistica rappresenta un potente strumento per esplorare la relazione tra punteggi di un test e criteri esterni, permettendo analisi precise e approfondite. Nel nostro esempio, studiare la probabilità di successo accademico in funzione dei punteggi di un test offre insight pratici e migliora l’affidabilità dell’interpretazione dei risultati psicometrici.\n\n## Un Esempio Pratico\n\nPer illustrare l'applicazione pratica della regressione logistica nella validazione di test psicometrici, analizziamo i dati dello studio [*Pitfalls When Using Area Under the Curve to Evaluate Item Content for Early Screening Tests for Autism*](https://journals.sagepub.com/doi/10.1177/07342829211067128) di Lucas, Brewer e Young (2022).\n\nIl campione raccolto da Nah et al. (2018) comprende 270 bambini di età compresa tra 12 e 36 mesi (M = 25.4, SD = 7.0). Secondo la diagnosi clinica effettuata basandosi sui criteri del DSM-5, 106 bambini erano stati diagnosticati con ASD (*Autism Spectrum Disorder*, disturbo dello spettro autistico), 86 mostravano uno sviluppo non tipico (non-TD), e 78 erano in sviluppo tipico (TD). Per semplicità, considereremo solo i gruppi ASD e non-TD.\n\nIl test in esame è l'*Autism Detection in Early Childhood* (ADEC), una checklist comportamentale composta da 16 item, progettata per rilevare comportamenti pre-verbali predittivi dell'autismo nei bambini sotto i tre anni (Young, 2007).\n\n### Preparazione dei Dati\n\nIniziamo importando e pre-elaborando i dati. Li scarichiamo da una fonte pubblica, ricodificando le diagnosi per includere solo i gruppi ASD e non-TD.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Scaricamento e caricamento dei dati\ntmp_path <- tempfile(fileext = \"xlsx\")\ndownload.file(\"https://osf.io/download/tsm7x/\", destfile = tmp_path)\ndat1 <- readxl::read_xlsx(tmp_path, na = \"NA\")\n\n# Ricodifica delle diagnosi\ndat1$asd <- recode(\n    dat1$`Diagnosis(1=Non-typically developing; 2=ASD; 3=Neurotypical)`,\n    `1` = \"Non-TD\",\n    `2` = \"ASD\",\n    `3` = \"TD\"\n)\n# Filtraggio per escludere il gruppo TD\ndat1_sub <- filter(dat1, asd != \"TD\")\n```\n:::\n\n\n\n\nCalcoliamo il punteggio totale ADEC per ogni bambino, trattando i valori mancanti in due modi: lasciandoli come `NA` o considerandoli come 0.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Punteggio totale ADEC\ndat1_sub$ADEC <- rowSums(dplyr::select(dat1_sub, ADEC_I01:ADEC_I16), na.rm = FALSE)\ndat1_sub$ADEC_rm_na <- rowSums(dplyr::select(dat1_sub, ADEC_I01:ADEC_I16), na.rm = TRUE)\n```\n:::\n\n\n\n\n### Modello di Regressione Logistica\n\nVogliamo analizzare come il punteggio totale ADEC sia associato alla probabilità di diagnosi di ASD. Per fare ciò, trasformiamo la variabile diagnostica in un formato binario: 1 per ASD e 0 per non-TD.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Codifica binaria della diagnosi\ndat1_sub$y <- ifelse(dat1_sub$asd == \"ASD\", 1, 0)\n```\n:::\n\n\n\n\nApplichiamo la regressione logistica con la funzione `glm()`.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Rimuovi righe con valori mancanti nei predittori\ndat1_sub <- na.omit(dat1_sub)\n\n# Modello di regressione logistica\nfm <- glm(y ~ ADEC, family = binomial(link = \"logit\"), data = dat1_sub)\nsummary(fm)\n#> \n#> Call:\n#> glm(formula = y ~ ADEC, family = binomial(link = \"logit\"), data = dat1_sub)\n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)   -3.765      0.581   -6.48  9.0e-11\n#> ADEC           0.354      0.052    6.82  9.4e-12\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 247.73  on 179  degrees of freedom\n#> Residual deviance: 131.12  on 178  degrees of freedom\n#> AIC: 135.1\n#> \n#> Number of Fisher Scoring iterations: 6\n```\n:::\n\n\n\n\n### Interpretazione e Visualizzazione\n\nCostruiamo un grafico che mostra la probabilità stimata di diagnosi di ASD in funzione del punteggio totale ADEC.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilità predette\npredictions <- predict(fm, type = \"response\")\nplot_data <- data.frame(ADEC = dat1_sub$ADEC, Prob_Y_1 = predictions)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Grafico\nggplot(plot_data, aes(x = ADEC, y = Prob_Y_1)) +\n    geom_line() +\n    geom_point() +\n    xlab(\"Punteggio Totale ADEC\") +\n    ylab(\"Probabilità di ASD\") +\n    ggtitle(\"Probabilità di ASD in funzione del punteggio ADEC\")\n```\n\n::: {.cell-output-display}\n![](02_other_variables_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nIl grafico evidenzia una relazione sigmoidale: per punteggi ADEC bassi, la probabilità di ASD è bassa; aumenta gradualmente con l’aumentare del punteggio.\n\n### Valutazione dell'Accuratezza del Modello\n\nPer valutare la capacità del modello di distinguere tra ASD e non-TD, utilizziamo una curva ROC (*Receiver Operating Characteristic*) e calcoliamo l'area sotto la curva (AUC).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della sensibilità e specificità\ncompute_sens <- function(cut) {\n  tp <- sum(dat1_sub$ADEC >= cut & dat1_sub$y == 1)\n  fn <- sum(dat1_sub$ADEC < cut & dat1_sub$y == 1)\n  tp / (tp + fn)\n}\n\ncompute_spec <- function(cut) {\n  tn <- sum(dat1_sub$ADEC < cut & dat1_sub$y == 0)\n  fp <- sum(dat1_sub$ADEC >= cut & dat1_sub$y == 0)\n  tn / (tn + fp)\n}\n\ncuts <- seq(min(dat1_sub$ADEC, na.rm = TRUE), max(dat1_sub$ADEC, na.rm = TRUE), length.out = 100)\nsens <- sapply(cuts, compute_sens)\nspec <- sapply(cuts, compute_spec)\n\n# Curva ROC\nroc_data <- data.frame(Sensitivity = sens, Specificity = spec)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(roc_data, aes(x = 1 - Specificity, y = Sensitivity)) +\n    geom_line() +\n    xlab(\"1 - Specificità\") +\n    ylab(\"Sensibilità\") +\n    ggtitle(\"Curva ROC\")\n```\n\n::: {.cell-output-display}\n![](02_other_variables_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nCalcoliamo l’AUC come misura aggregata della capacità discriminativa del modello.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo AUC\nauc <- sum(diff(1 - spec) * (sens[-1] + sens[-length(sens)]) / 2)\nauc\n#> [1] -0.921\n```\n:::\n\n\n\n\nIn conclusione, l’AUC calcolata è pari a 0.92, indicando un’eccellente capacità predittiva del test ADEC nel discriminare tra bambini con ASD e non-TD. Questo risultato supporta la validità del test come strumento diagnostico precoce per identificare bambini a rischio di sviluppare un disturbo dello spettro autistico, sottolineandone l’utilità per interventi tempestivi e mirati.\n\n## Utilizzo del Pacchetto ROCit\n\nIl pacchetto **ROCit** offre un modo semplice ed efficace per calcolare e visualizzare la curva ROC, consentendo di ottenere gli stessi risultati presentati precedentemente con maggiore praticità. Questo pacchetto integra funzionalità per calcolare l'AUC e i relativi intervalli di confidenza, utili per una valutazione approfondita delle prestazioni del modello.\n\nEcco un esempio di utilizzo con il punteggio totale ADEC:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creazione della curva ROC\nroc_adec <- rocit(score = dat1_sub$ADEC, class = dat1_sub$asd == \"ASD\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione della curva ROC\nplot(roc_adec)\n```\n\n::: {.cell-output-display}\n![](02_other_variables_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nÈ possibile ottenere un riepilogo dettagliato dei risultati:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Riepilogo dei risultati della curva ROC\nsummary(roc_adec)\n#>                           \n#>  Method used: empirical   \n#>  Number of positive(s): 99\n#>  Number of negative(s): 81\n#>  Area under curve: 0.9206\n```\n:::\n\n\n\n\nE calcolare gli intervalli di confidenza per l'AUC:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo degli intervalli di confidenza per l'AUC\nciAUC(roc_adec)\n#>                                                           \n#>    estimated AUC : 0.920626013218606                      \n#>    AUC estimation method : empirical                      \n#>                                                           \n#>    CI of AUC                                              \n#>    confidence level = 95%                                 \n#>    lower = 0.880257283328194     upper = 0.960994743109017\n```\n:::\n\n\n\n\nL'utilizzo di **ROCit** semplifica il processo di analisi ROC, offrendo funzioni dedicate per la visualizzazione grafica, il calcolo dell'AUC e l'interpretazione dei risultati. Inoltre, la possibilità di includere intervalli di confidenza migliora la robustezza delle conclusioni, fornendo un quadro più chiaro della capacità predittiva del test.\n\n## Riflessioni Conclusive\n\nQuesto capitolo ha illustrato l'importanza della regressione logistica e del calcolo della curva ROC, con particolare attenzione all'Area Under the Curve (AUC), come strumenti fondamentali per valutare la validità di criterio di un test psicometrico. In particolare:\n\n- **Regressione logistica**: Consente di modellare la relazione tra i punteggi di un test e la probabilità di appartenenza a un gruppo diagnostico, fornendo stime precise e interpretabili.  \n- **Curva ROC e AUC**: Valutano la capacità discriminativa del test, permettendo di identificare il trade-off tra sensibilità e specificità in base ai diversi punti di taglio.\n\nQuesti strumenti offrono una base solida per l'applicazione pratica del test, garantendo una valutazione accurata della validità di criterio. L'adozione di tecniche statistiche robuste contribuisce a migliorare la qualità delle diagnosi, a supportare decisioni informate e a ottimizzare l'efficacia degli interventi mirati.\n\nIn conclusione, la corretta valutazione della validità di criterio è essenziale per garantire risultati affidabili e utili sia nella pratica clinica che nella ricerca. L'analisi presentata in questo capitolo dimostra come l'integrazione di approcci statistici avanzati possa rafforzare la fiducia nell'uso di test psicometrici per la classificazione diagnostica e la progettazione di interventi personalizzati.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered} \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] modelsummary_2.2.0 ROCit_2.1.2        haven_2.5.4       \n#>  [4] readxl_1.4.3       ggokabeito_0.1.0   see_0.9.0         \n#>  [7] MASS_7.3-64        viridis_0.6.5      viridisLite_0.4.2 \n#> [10] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#> [13] patchwork_1.3.0    bayesplot_1.11.1   semTools_0.5-6    \n#> [16] semPlot_1.1.6      lavaan_0.6-19      psych_2.4.12      \n#> [19] scales_1.3.0       markdown_1.13      knitr_1.49        \n#> [22] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1     \n#> [25] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n#> [28] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#> [31] tidyverse_2.0.0    here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.8.9      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.1.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         cellranger_1.1.0   \n#>  [16] Formula_1.2-5       htmlwidgets_1.6.4   plyr_1.8.9         \n#>  [19] sandwich_3.1-1      emmeans_1.10.6      zoo_1.8-12         \n#>  [22] igraph_2.1.4        mime_0.12           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-2        R6_2.5.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] digest_0.6.37       OpenMx_2.21.13      fdrtool_1.2.18     \n#>  [34] colorspace_2.1-1    rprojroot_2.0.4     Hmisc_5.2-2        \n#>  [37] labeling_0.4.3      timechange_0.3.0    abind_1.4-8        \n#>  [40] compiler_4.4.2      withr_3.0.2         glasso_1.11        \n#>  [43] htmlTable_2.4.3     backports_1.5.0     carData_3.0-5      \n#>  [46] ggsignif_0.6.4      corpcor_1.6.10      gtools_3.9.5       \n#>  [49] tools_4.4.2         pbivnorm_0.6.0      foreign_0.8-88     \n#>  [52] zip_2.3.1           httpuv_1.6.15       nnet_7.3-20        \n#>  [55] glue_1.8.0          quadprog_1.5-8      nlme_3.1-167       \n#>  [58] promises_1.3.2      lisrelToR_0.3       grid_4.4.2         \n#>  [61] checkmate_2.3.2     cluster_2.1.8       reshape2_1.4.4     \n#>  [64] generics_0.1.3      gtable_0.3.6        tzdb_0.4.0         \n#>  [67] data.table_1.16.4   hms_1.1.3           car_3.1-3          \n#>  [70] tables_0.9.31       sem_3.1-16          pillar_1.10.1      \n#>  [73] rockchalk_1.8.157   later_1.4.1         splines_4.4.2      \n#>  [76] lattice_0.22-6      survival_3.8-3      kutils_1.73        \n#>  [79] tidyselect_1.2.1    miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [82] reformulas_0.4.0    stats4_4.4.2        xfun_0.50          \n#>  [85] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [88] yaml_2.3.10         pacman_0.5.1        boot_1.3-31        \n#>  [91] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [94] cli_3.6.3           RcppParallel_5.1.10 rpart_4.1.24       \n#>  [97] xtable_1.8-4        Rdpack_2.6.2        munsell_0.5.1      \n#> [100] Rcpp_1.0.14         coda_0.19-4.1       png_0.1-8          \n#> [103] XML_3.99-0.18       parallel_4.4.2      jpeg_0.1-10        \n#> [106] lme4_1.1-36         mvtnorm_1.3-3       insight_1.0.1      \n#> [109] openxlsx_4.2.8      rlang_1.1.5         multcomp_1.4-26    \n#> [112] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "02_other_variables_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
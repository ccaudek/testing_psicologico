{
  "hash": "6dd325e5031daa171b703c393b78cc67",
  "result": {
    "engine": "knitr",
    "markdown": "# Valutazione della matrice di correlazione {#sec-extraction-cor-matrix}\n\n::: callout-important\n## In questo capitolo imparerai a:\n\n- esaminare la matrice di correlazione tra le variabili come passo preliminare di un'analisi fattoriale.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Factor Analysis and Principal Component Analysis* del testo di @petersen2024principles.\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(lavaan, corrr, psych)\n```\n:::\n\n\n\n\n:::\n\n## Introduzione\n\nPrima di eseguire un'analisi fattoriale esplorativa (EFA), √® fondamentale valutare se i dati soddisfano i presupposti minimi richiesti. Il primo passo consiste nell'esaminare la **matrice di correlazione** tra le variabili. Se il **determinante** di questa matrice √® pari a zero, significa che esiste **collinearit√† perfetta** tra alcune variabili: in questo caso, l‚Äôanalisi fattoriale non pu√≤ essere effettuata perch√© non sarebbe possibile distinguere contributi distinti dei fattori latenti.\n\nTuttavia, anche se il determinante √® diverso da zero, non √® detto che i dati siano adatti all‚ÄôEFA. √à necessario che le variabili mostrino **correlazioni sufficientemente elevate** tra loro, altrimenti l‚Äôanalisi potrebbe produrre **soluzioni instabili o difficili da interpretare**. Correlazioni troppo deboli indicano che non esistono dimensioni comuni sottostanti e quindi non ha senso estrarre dei fattori.\n\nPer valutare l‚Äôadeguatezza dei dati, possiamo:\n\n- **ispezionare visivamente** la matrice di correlazione,\n- calcolare il **test di sfericit√† di Bartlett**,\n- calcolare l‚Äô**indice di adeguatezza campionaria KMO** (Kaiser-Meyer-Olkin).\n\nQuesti strumenti forniscono informazioni complementari sull'opportunit√† di procedere con un‚Äôanalisi fattoriale.\n\n\n## Analisi Preliminari\n\nPer illustrare il procedimento, utilizziamo il dataset `HolzingerSwineford1939`, che contiene **301 osservazioni** relative a **punteggi di abilit√† mentale** su diverse prove cognitive. In questa analisi considereremo le variabili `x1`‚Äì`x9`.\n\nCominciamo con l'importazione del dataset e la verifica dell‚Äôintegrit√† dei dati.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Caricamento del dataset e visualizzazione iniziale\ndata(HolzingerSwineford1939)\nglimpse(HolzingerSwineford1939)\n#> Rows: 301\n#> Columns: 15\n#> $ id     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, ‚Ä¶\n#> $ sex    <int> 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2,‚Ä¶\n#> $ ageyr  <int> 13, 13, 13, 13, 12, 14, 12, 12, 13, 12, 12, 12, 12, 12, 12,‚Ä¶\n#> $ agemo  <int> 1, 7, 1, 2, 2, 1, 1, 2, 0, 5, 2, 11, 7, 8, 6, 1, 11, 5, 8, ‚Ä¶\n#> $ school <fct> Pasteur, Pasteur, Pasteur, Pasteur, Pasteur, Pasteur, Paste‚Ä¶\n#> $ grade  <int> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,‚Ä¶\n#> $ x1     <dbl> 3.333, 5.333, 4.500, 5.333, 4.833, 5.333, 2.833, 5.667, 4.5‚Ä¶\n#> $ x2     <dbl> 7.75, 5.25, 5.25, 7.75, 4.75, 5.00, 6.00, 6.25, 5.75, 5.25,‚Ä¶\n#> $ x3     <dbl> 0.375, 2.125, 1.875, 3.000, 0.875, 2.250, 1.000, 1.875, 1.5‚Ä¶\n#> $ x4     <dbl> 2.333, 1.667, 1.000, 2.667, 2.667, 1.000, 3.333, 3.667, 2.6‚Ä¶\n#> $ x5     <dbl> 5.75, 3.00, 1.75, 4.50, 4.00, 3.00, 6.00, 4.25, 5.75, 5.00,‚Ä¶\n#> $ x6     <dbl> 1.2857, 1.2857, 0.4286, 2.4286, 2.5714, 0.8571, 2.8571, 1.2‚Ä¶\n#> $ x7     <dbl> 3.391, 3.783, 3.261, 3.000, 3.696, 4.348, 4.696, 3.391, 4.5‚Ä¶\n#> $ x8     <dbl> 5.75, 6.25, 3.90, 5.30, 6.30, 6.65, 6.20, 5.15, 4.65, 4.55,‚Ä¶\n#> $ x9     <dbl> 6.361, 7.917, 4.417, 4.861, 5.917, 7.500, 4.861, 3.667, 7.3‚Ä¶\n\n# Selezione delle variabili di interesse\nhz <- HolzingerSwineford1939 |>\n  dplyr::select(x1:x9)\n\n# Visualizzazione delle prime 5 righe\nhz |> slice(1:5)\n#>      x1   x2    x3    x4   x5     x6    x7   x8    x9\n#> 1 3.333 7.75 0.375 2.333 5.75 1.2857 3.391 5.75 6.361\n#> 2 5.333 5.25 2.125 1.667 3.00 1.2857 3.783 6.25 7.917\n#> 3 4.500 5.25 1.875 1.000 1.75 0.4286 3.261 3.90 4.417\n#> 4 5.333 7.75 3.000 2.667 4.50 2.4286 3.000 5.30 4.861\n#> 5 4.833 4.75 0.875 2.667 4.00 2.5714 3.696 6.30 5.917\n```\n:::\n\n\n\n\n\n### Valutazione dei Dati Mancanti\n\nPrima di esaminare le correlazioni, √® importante verificare **l‚Äôeventuale presenza di dati mancanti**, poich√© anche pochi valori mancanti possono alterare significativamente la matrice di correlazione.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Controllo dei dati mancanti\nhz |> summarise(across(everything(), ~ sum(is.na(.))))\n#>   x1 x2 x3 x4 x5 x6 x7 x8 x9\n#> 1  0  0  0  0  0  0  0  0  0\n```\n:::\n\n\n\n\n\nIn questo caso, **non sono presenti dati mancanti**. In presenza di dati mancanti, sar√† necessario adottare strategie appropriate (es. imputazione, listwise deletion, ecc.) prima di procedere.\n\n> üîç *Nota didattica:* In genere, per l‚Äôanalisi fattoriale √® preferibile utilizzare una matrice di correlazione calcolata su dati completi, perch√© la presenza di dati mancanti pu√≤ distorcere le relazioni tra le variabili.\n\n### Esplorazione delle Distribuzioni\n\nUn controllo preliminare utile √® l‚Äôesame della **forma delle distribuzioni** delle variabili, in particolare **asimmetria** (skewness) e **curtosi** (kurtosis), che possono indicare violazioni di normalit√†.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescribe(hz)\n#>    vars   n mean   sd median trimmed  mad  min   max range  skew kurtosis\n#> x1    1 301 4.94 1.17   5.00    4.96 1.24 0.67  8.50  7.83 -0.25     0.31\n#> x2    2 301 6.09 1.18   6.00    6.02 1.11 2.25  9.25  7.00  0.47     0.33\n#> x3    3 301 2.25 1.13   2.12    2.20 1.30 0.25  4.50  4.25  0.38    -0.91\n#> x4    4 301 3.06 1.16   3.00    3.02 0.99 0.00  6.33  6.33  0.27     0.08\n#> x5    5 301 4.34 1.29   4.50    4.40 1.48 1.00  7.00  6.00 -0.35    -0.55\n#> x6    6 301 2.19 1.10   2.00    2.09 1.06 0.14  6.14  6.00  0.86     0.82\n#> x7    7 301 4.19 1.09   4.09    4.16 1.10 1.30  7.43  6.13  0.25    -0.31\n#> x8    8 301 5.53 1.01   5.50    5.49 0.96 3.05 10.00  6.95  0.53     1.17\n#> x9    9 301 5.37 1.01   5.42    5.37 0.99 2.78  9.25  6.47  0.20     0.29\n#>      se\n#> x1 0.07\n#> x2 0.07\n#> x3 0.07\n#> x4 0.07\n#> x5 0.07\n#> x6 0.06\n#> x7 0.06\n#> x8 0.06\n#> x9 0.06\n```\n:::\n\n\n\n\n\nIn questo caso, i valori di asimmetria e curtosi sono **sufficientemente contenuti**, quindi non √® necessario trasformare le variabili. Tuttavia, se ci fossero valori molto estremi, una trasformazione (log, z-score, Box-Cox) potrebbe essere utile.\n\n\n### Ispezione della Matrice di Correlazione\n\nUna **matrice di correlazione** √® la base concettuale dell'analisi fattoriale: essa mostra quanto ogni variabile √® associata con le altre. In presenza di **gruppi di variabili altamente correlate tra loro e poco correlate con le altre**, √® plausibile che esistano **fattori comuni sottostanti**.\n\nVisualizziamo la matrice utilizzando il pacchetto `corrr`:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor_tb <- correlate(hz)\n\ncor_tb |>\n  rearrange() |>\n  rplot(colors = c(\"red\", \"white\", \"blue\"))\n```\n\n::: {.cell-output-display}\n![](01_val_matrici_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\nIl grafico mostra tre blocchi distinti:\n\n- **x4‚Äìx6**: un primo gruppo fortemente correlato tra loro,\n- **x1‚Äìx3**: un secondo gruppo coeso,\n- **x7‚Äìx9**: un terzo gruppo distinto.\n\nQuesta struttura √® coerente con l‚Äôidea che i punteggi derivino da **tre fattori latenti** diversi.\n\n\n## Test di Sfericit√† di Bartlett\n\nIl **test di sfericit√† di Bartlett** verifica se la matrice di correlazione differisce significativamente da una matrice identit√† (cio√® una matrice in cui tutte le variabili sono incorrelate).\n\n**Ipotesi nulla**: le variabili non sono correlate tra loro.  \n**Ipotesi alternativa**: esistono correlazioni significative tra le variabili.\n\nLa formula del test √®:\n\n$$\n\\chi^2 = -\\left[n - 1 - \\frac{1}{6}(2p + 5)\\right] \\ln |\\boldsymbol{R}|,\n$$\n\ndove:\n\n- $n$ = numerosit√† campionaria,\n- $p$ = numero di variabili,\n- $|\\boldsymbol{R}|$ = determinante della matrice di correlazione.\n\nIl test restituisce una **statistica $\\chi^2$** con $p(p - 1)/2$ gradi di libert√†.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor_mat <- cor(hz)\n\nout = cortest.bartlett(R = cor_mat, n = 301)\nprint(out)\n#> $chisq\n#> [1] 904.1\n#> \n#> $p.value\n#> [1] 1.912e-166\n#> \n#> $df\n#> [1] 36\n```\n:::\n\n\n\n\n\nRisultato: la statistica √® altamente significativa ‚Üí **possiamo rifiutare l‚Äôipotesi nulla**. Le variabili sono sufficientemente correlate per proseguire con l‚Äôanalisi fattoriale.\n\n> üìå *Nota:* Il test di Bartlett √® molto sensibile alla numerosit√† campionaria: con campioni ampi, anche correlazioni deboli possono risultare statisticamente ‚Äúsignificative‚Äù. √à quindi opportuno integrare il test con altri indici, come il KMO.\n\n\n## Indice KMO (Kaiser-Meyer-Olkin)\n\nL‚Äôindice **KMO** misura quanto le correlazioni osservate siano spiegabili da **fattori latenti comuni**, piuttosto che da correlazioni parziali tra le variabili (che rappresentano associazioni \"spuriate\").\n\nLa formula √®:\n\n$$\n\\text{KMO} = \\frac{\\sum_i \\sum_j r^2_{ij}}{\\sum_i \\sum_j r^2_{ij} + \\sum_i \\sum_j p^2_{ij}},\n$$\n\ndove $r_{ij}$ sono le correlazioni osservate, e $p_{ij}$ le correlazioni parziali.\n\nValori possibili:\n\n- **0.90‚Äì1.00**: eccellente (*meravigliosa*)\n- **0.80‚Äì0.89**: molto buona (*meritevole*)\n- **0.70‚Äì0.79**: buona (*media*)\n- **0.60‚Äì0.69**: discreta (*mediocre*)\n- **0.50‚Äì0.59**: scarsa (*miserabile*)\n- **< 0.50**: inadeguata (*inaccettabile*)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nout = KMO(cor_mat)\nprint(out)\n#> Kaiser-Meyer-Olkin factor adequacy\n#> Call: KMO(r = cor_mat)\n#> Overall MSA =  0.75\n#> MSA for each item = \n#>   x1   x2   x3   x4   x5   x6   x7   x8   x9 \n#> 0.81 0.78 0.73 0.76 0.74 0.81 0.59 0.68 0.79\n```\n:::\n\n\n\n\n\nNel nostro caso, il valore KMO √® **attorno a 0.70**, quindi l‚Äôadeguatezza √® **buona**, ma non eccellente. Possiamo proseguire con l‚Äôanalisi, pur restando consapevoli che la qualit√† dei dati potrebbe essere migliorata (es. con la revisione degli item).\n\n\n## Riflessioni conclusive\n\nLe analisi preliminari condotte sul dataset `HolzingerSwineford1939` indicano che:\n\n- le **correlazioni tra variabili** sono presenti e coerenti con una struttura a pi√π fattori,\n- il **test di Bartlett** conferma che la matrice di correlazione √® diversa da una matrice identit√†,\n- l‚Äô**indice KMO** suggerisce un‚Äôadeguatezza campionaria soddisfacente, anche se non ottimale.\n\nQuesti risultati ci consentono di procedere con l‚Äôanalisi fattoriale esplorativa, ma evidenziano anche la necessit√† di **valutazioni critiche** in fase interpretativa. L‚Äôuso combinato di pi√π strumenti diagnostici consente di fondare l‚Äôanalisi su basi solide e di trarre conclusioni pi√π affidabili riguardo alla struttura latente dei dati.\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.3.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] corrr_0.4.4       ggokabeito_0.1.0  see_0.11.0        MASS_7.3-65      \n#>  [5] viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1   \n#>  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6   \n#> [13] semPlot_1.1.6     lavaan_0.6-19     psych_2.4.12      scales_1.3.0     \n#> [17] markdown_1.13     knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#> [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#> [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#> [29] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] rstudioapi_0.17.1   jsonlite_1.9.1      magrittr_2.0.3     \n#>   [4] TH.data_1.1-3       estimability_1.5.1  farver_2.1.2       \n#>   [7] nloptr_2.2.1        rmarkdown_2.29      vctrs_0.6.5        \n#>  [10] minqa_1.2.8         base64enc_0.1-3     rstatix_0.7.2      \n#>  [13] htmltools_0.5.8.1   broom_1.0.7         Formula_1.2-5      \n#>  [16] htmlwidgets_1.6.4   plyr_1.8.9          sandwich_3.1-1     \n#>  [19] emmeans_1.10.7      zoo_1.8-13          igraph_2.1.4       \n#>  [22] iterators_1.0.14    mime_0.13           lifecycle_1.0.4    \n#>  [25] pkgconfig_2.0.3     Matrix_1.7-3        R6_2.6.1           \n#>  [28] fastmap_1.2.0       rbibutils_2.3       shiny_1.10.0       \n#>  [31] digest_0.6.37       OpenMx_2.21.13      fdrtool_1.2.18     \n#>  [34] colorspace_2.1-1    rprojroot_2.0.4     Hmisc_5.2-3        \n#>  [37] seriation_1.5.7     labeling_0.4.3      timechange_0.3.0   \n#>  [40] abind_1.4-8         compiler_4.4.2      withr_3.0.2        \n#>  [43] glasso_1.11         htmlTable_2.4.3     backports_1.5.0    \n#>  [46] carData_3.0-5       ggsignif_0.6.4      corpcor_1.6.10     \n#>  [49] gtools_3.9.5        tools_4.4.2         pbivnorm_0.6.0     \n#>  [52] foreign_0.8-88      zip_2.3.2           httpuv_1.6.15      \n#>  [55] nnet_7.3-20         glue_1.8.0          quadprog_1.5-8     \n#>  [58] nlme_3.1-167        promises_1.3.2      lisrelToR_0.3      \n#>  [61] grid_4.4.2          checkmate_2.3.2     cluster_2.1.8.1    \n#>  [64] reshape2_1.4.4      generics_0.1.3      gtable_0.3.6       \n#>  [67] tzdb_0.5.0          ca_0.71.1           data.table_1.17.0  \n#>  [70] hms_1.1.3           car_3.1-3           sem_3.1-16         \n#>  [73] foreach_1.5.2       pillar_1.10.1       rockchalk_1.8.157  \n#>  [76] later_1.4.1         splines_4.4.2       lattice_0.22-6     \n#>  [79] survival_3.8-3      kutils_1.73         tidyselect_1.2.1   \n#>  [82] registry_0.5-1      miniUI_0.1.1.1      pbapply_1.7-2      \n#>  [85] reformulas_0.4.0    stats4_4.4.2        xfun_0.51          \n#>  [88] qgraph_1.9.8        arm_1.14-4          stringi_1.8.4      \n#>  [91] yaml_2.3.10         pacman_0.5.1        boot_1.3-31        \n#>  [94] evaluate_1.0.3      codetools_0.2-20    mi_1.1             \n#>  [97] cli_3.6.4           RcppParallel_5.1.10 rpart_4.1.24       \n#> [100] xtable_1.8-4        Rdpack_2.6.3        munsell_0.5.1      \n#> [103] Rcpp_1.0.14         coda_0.19-4.1       png_0.1-8          \n#> [106] XML_3.99-0.18       parallel_4.4.2      jpeg_0.1-10        \n#> [109] lme4_1.1-36         mvtnorm_1.3-3       openxlsx_4.2.8     \n#> [112] rlang_1.1.5         TSP_1.2-4           multcomp_1.4-28    \n#> [115] mnormt_2.1.1\n```\n:::\n",
    "supporting": [
      "01_val_matrici_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
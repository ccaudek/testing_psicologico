{
  "hash": "4ad35488d79aebff6ad9865e7d73b99a",
  "result": {
    "engine": "knitr",
    "markdown": "# Determinare il numero dei fattori {#sec-extraction-number-factors}\n\n::: callout-important\n## In questo capitolo imparerai:\n\n- determinare il numero di fattori da estrarre nell'analisi fattoriale.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere l'articolo *How many factors to retain in exploratory factor analysis? A critical overview of factor retention methods* [@goretzko2025many].\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(devtools)\n# install_github(\"jmbh/fspe\")\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  lavaan, psych, paran, fspe, nFactors, semTools, EFAtools, MASS,\n  EFAfactors, EGAnet, latentFactoR, REFA\n)\n```\n:::\n\n\n\n\n:::\n\n\n## Introduzione\n\nL’Analisi Fattoriale Esplorativa (EFA) è uno strumento fondamentale nella costruzione e valutazione di test psicologici. Essa consente di esplorare la struttura latente sottostante a un insieme di variabili osservate. Uno degli aspetti più delicati dell'EFA è la **determinazione del numero di fattori da estrarre**, nota anche come *factor retention*. Una scelta errata può compromettere l’intera analisi, portando a:\n\n- **Sottofattorizzazione**: sottostimare il numero di fattori, rischiando di distorcere la struttura latente e generare caricamenti spurii (cross-loadings);\n- **Sovrafattorizzazione**: estrarre più fattori del necessario, introducendo elementi poco interpretabili. Questo errore è meno grave, purché venga riconosciuto e gestito opportunamente.\n\n### Tre domande fondamentali sulla dimensionalità di un test\n\n1. **Quante dimensioni?** Alcuni test misurano un solo costrutto latente, altri ne misurano diversi.\n2. **Le dimensioni sono correlate?** Se sì, è opportuno utilizzare metodi di rotazione obliqua.\n3. **Cosa significano le dimensioni?** L’interpretazione teorica dei fattori è cruciale per l’applicazione pratica del test.\n\nQuesto capitolo presenta e confronta i principali approcci proposti per determinare il numero ottimale di fattori, illustrandone i presupposti, i punti di forza e le limitazioni.\n\n## Metodi basati sugli autovalori\n\n### Kaiser-Guttman Rule\n\nRetiene i fattori con autovalore > 1 (solo per matrici di correlazione). Anche se molto diffuso, è fortemente sconsigliato: ha una tendenza sistematica alla **sovrafattorizzazione**. È inappropriato per dati non standardizzati o con bassa comunalità.\n\n### Scree Test (Cattell)\n\nGrafico degli autovalori decrescenti: il numero di fattori corrisponde al punto prima del \"gomito\". Soggettivo e a bassa affidabilità.\n\n### Valore medio degli autovalori\n\nRetiene i fattori con autovalore maggiore della media degli autovalori. Alternativa alla regola di Kaiser, ma ancora euristica.\n\n### Metodi Avanzati\n\n- **Empirical Kaiser Criterion (EKC)**: corregge per numerosità campionaria e varianza cumulata. Buona performance solo in strutture semplici e unidimensionali.\n- **STOC** e **STAF**: automatizzano lo scree test via algoritmi (es. accelerazione della pendenza) -- implementate in `nFactors`.\n\n## Metodi Basati sulla Simulazione\n\n### Parallel Analysis (PA)\n\nConsiderata lo \"standard aureo\". Confronta gli autovalori empirici con quelli derivati da dati casuali:\n\n- variante standard: usa la media degli autovalori simulati;\n- variante di Glorfeld: usa il 95° percentile per essere più conservativa;\n- funzioni: `fa.parallel()` del pacchetto `psych`.\n\n### Comparison Data (CD)\n\nUsa bootstrap e riproduce la matrice di correlazione. Confronta soluzioni adiacenti con un test di Mann-Whitney sugli RMSE. Utile con fattori correlati, ma tende a sovrafattorizzare se non ben calibrato. Implementato in `EFAtools`.\n\n## Approcci basati sul confronto tra modelli\n\n### Criteri Informativi: AIC, BIC\n\nUtilizzano la verosimiglianza e penalizzano la complessità del modello.\n\n- AIC: tende a selezionare modelli più complessi;\n- BIC: più conservativo.\n\n### Indici di Fit: \n\nGli indicici di fit come RMSEA, CFI, SRMR, ecc. sono usati più comunemente in CFA, ma sono meno affidabili in EFA a causa della dipendenza da dimensione campionaria e altri fattori.\n\n### Metodo Hull\n\nIl **metodo Hull** (Lorenzo-Seva, Timmerman, & Kiers, 2011) è un approccio grafico per la determinazione del numero ottimale di fattori. L’idea di base è bilanciare **bontà dell’adattamento** e **parsimonia del modello** (cioè la semplicità).\n\nCome funziona:\n\n1. si adattano diversi modelli fattoriali con un numero crescente di fattori;\n2. per ciascun modello, si registra un indice di fit (es. CFI) e i **gradi di libertà**;\n3. si costruisce il **\"convex hull\"**, ovvero il contorno convesso che racchiude i punti CFI ~ gradi di libertà;\n4. si identifica il punto sul contorno del hull che rappresenta il miglior compromesso tra **fit accettabile** e **modello semplice** (cioè con più gradi di libertà).\n\nVantaggi:\n\n- tende a evitare la **sovrafattorizzazione**, comune in altri metodi;\n- ha buone prestazioni quando il modello è **ben sovradeterminato** (cioè ogni fattore è misurato da molte variabili);\n- è adatto anche in presenza di **fattori correlati**.\n\n## Minimum Average Partial (MAP)\n\nTest che valuta la media delle correlazioni parziali residue dopo estrazione di i componenti. Retiene il numero di componenti che minimizza questa media. È implementato in `vss()` del pacchetto `psych`.\n\n## Approcci moderni\n\n### Analisi Esplorativa della Rete (EGA)\n\nL’**Exploratory Graph Analysis (EGA)** è un metodo alternativo all’analisi fattoriale esplorativa (EFA), che non si basa sull’ipotesi di **fattori latenti comuni**, ma sull’identificazione di **comunità di variabili** all’interno di un **modello a rete**.\n\n- In EGA, le **variabili osservate** (es. item di un test) sono rappresentate come **nodi** di una rete.\n- Le **connessioni** (archi) tra i nodi riflettono **correlazioni parziali** standardizzate, cioè relazioni tra due variabili controllando per tutte le altre.\n- Il modello statistico di base è il **Gaussian Graphical Model (GGM)**, stimato con un metodo di **massima verosimiglianza penalizzata** (regularization), che tende ad annullare le correlazioni più deboli, producendo reti **sparse** (con pochi collegamenti).\n- All’interno di questa rete, le variabili **fortemente collegate tra loro** tendono a raggrupparsi in **comunità** (clusters), che vengono interpretate come **fattori**.\n\nVantaggi dell’EGA:\n\n- è particolarmente utile in condizioni in cui:\n  - le **comunalità sono basse** (cioè le variabili condividono poca varianza comune),\n  - i dati sono **ordinali** o non normalmente distribuiti.\n- rispetto all’EFA tradizionale, EGA è più robusto a **strutture complesse o deboli**.\n\nCome viene determinato il numero di fattori?\n\nIl numero di comunità (e quindi di fattori) viene identificato attraverso **algoritmi di rilevamento delle comunità**, come il **walktrap algorithm**, che cerca sottogruppi fortemente interconnessi all’interno della rete.\n\nIn sintesi, EGA fornisce una rappresentazione grafica e interpretabile della struttura fattoriale dei dati, e può essere usato per **decidere quanti fattori estrarre** in un’analisi esplorativa.\n\n## Metodi Basati su Machine Learning\n\n### Factor Forest (ML)\n\nApproccio machine learning addestrato su dati simulati. Molto preciso, ma dipende da modelli preaddestrati. Implementato in `latentFactoR`.\n\n### Comparison Data Forest (CDF)\n\nVersione più leggera del Factor Forest basata su CD + Random Forest. Meno accurata ma più accessibile. Implementazione disponibile su OSF.\n\n### Regularized EFA (REFA)\n\nUtilizza penalizzazioni (LASSO, Ridge, MC+) per ottenere strutture sparse. Può essere utile per l’identificazione automatica dei fattori. Implementazioni: `fanc`, `regsem`, `lslx`.\n\n\n## Implementazione in R\n\nPer confrontare i metodi discussi per la scelta del numero $m$ di fattori usiamo una matrice di correlazioni calcolata sulle sottoscale della WAIS. Le 11 sottoscale del test sono le seguenti:\n\n- X1 = Information\n- X2 = Comprehension\n- X3 = Arithmetic\n- X4 = Similarities\n- X5 = Digit.span\n- X6 = Vocabulary\n- X7 = Digit.symbol\n- X8 = Picture.completion\n- X9 = Block.design\n- X10 = Picture.arrangement\n- X11 = Object.\n\nI dati sono stati ottenuti dal manuale della III edizione.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvarnames <- c(\n    \"IN\", \"CO\", \"AR\", \"SI\", \"DS\", \"VO\", \"SY\", \"PC\",\n    \"BD\", \"PA\", \"OA\", \"AG\", \"ED\"\n)\ntemp <- matrix(c(\n    1, 0.67, 0.62, 0.66, 0.47, 0.81, 0.47, 0.60, 0.49, 0.51, 0.41,\n    -0.07, 0.66, .67, 1, 0.54, 0.60, 0.39, 0.72, 0.40, 0.54, 0.45,\n    0.49, 0.38, -0.08, 0.52, .62, .54, 1, 0.51, 0.51, 0.58, 0.41,\n    0.46, 0.48, 0.43, 0.37, -0.08, 0.49, .66, .60, .51, 1, 0.41,\n    0.68, 0.49, 0.56, 0.50, 0.50, 0.41, -0.19, 0.55, .47, .39, .51,\n    .41, 1, 0.45, 0.45, 0.42, 0.39, 0.42, 0.31, -0.19, 0.43,\n    .81, .72, .58, .68, .45, 1, 0.49, 0.57, 0.46, 0.52, 0.40, -0.02,\n    0.62, .47, .40, .41, .49, .45, .49, 1, 0.50, 0.50, 0.52, 0.46,\n    -0.46, 0.57, .60, .54, .46, .56, .42, .57, .50, 1, 0.61, 0.59,\n    0.51, -0.28, 0.48, .49, .45, .48, .50, .39, .46, .50, .61, 1,\n    0.54, 0.59, -0.32, 0.44, .51, .49, .43, .50, .42, .52, .52, .59,\n    .54, 1, 0.46, -0.37, 0.49, .41, .38, .37, .41, .31, .40, .46, .51,\n    .59, .46, 1, -0.28, 0.40, -.07, -.08, -.08, -.19, -.19, -.02,\n    -.46, -.28, -.32, -.37, -.28, 1, -0.29, .66, .52, .49, .55, .43,\n    .62, .57, .48, .44, .49, .40, -.29, 1\n), nrow = 13, ncol = 13, byrow = TRUE)\n\ncolnames(temp) <- varnames\nrownames(temp) <- varnames\n\nwais_cor <- temp[1:11, 1:11]\nwais_cor\n#>      IN   CO   AR   SI   DS   VO   SY   PC   BD   PA   OA\n#> IN 1.00 0.67 0.62 0.66 0.47 0.81 0.47 0.60 0.49 0.51 0.41\n#> CO 0.67 1.00 0.54 0.60 0.39 0.72 0.40 0.54 0.45 0.49 0.38\n#> AR 0.62 0.54 1.00 0.51 0.51 0.58 0.41 0.46 0.48 0.43 0.37\n#> SI 0.66 0.60 0.51 1.00 0.41 0.68 0.49 0.56 0.50 0.50 0.41\n#> DS 0.47 0.39 0.51 0.41 1.00 0.45 0.45 0.42 0.39 0.42 0.31\n#> VO 0.81 0.72 0.58 0.68 0.45 1.00 0.49 0.57 0.46 0.52 0.40\n#> SY 0.47 0.40 0.41 0.49 0.45 0.49 1.00 0.50 0.50 0.52 0.46\n#> PC 0.60 0.54 0.46 0.56 0.42 0.57 0.50 1.00 0.61 0.59 0.51\n#> BD 0.49 0.45 0.48 0.50 0.39 0.46 0.50 0.61 1.00 0.54 0.59\n#> PA 0.51 0.49 0.43 0.50 0.42 0.52 0.52 0.59 0.54 1.00 0.46\n#> OA 0.41 0.38 0.37 0.41 0.31 0.40 0.46 0.51 0.59 0.46 1.00\n```\n:::\n\n\n\n\n\n##  Metodi basati sugli autovalori\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcola gli autovalori della matrice di correlazione WAIS\nwais_eigen <- eigen(wais_cor)\neigenvalues <- wais_eigen$values\nprint(eigenvalues)\n#>  [1] 6.0745 1.0150 0.7462 0.5868 0.5083 0.4312 0.4233 0.3766 0.3510 0.3101\n#> [11] 0.1770\n```\n:::\n\n\n\n\n\n### Kaiser-Guttman Rule\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkaiser_rule <- sum(eigenvalues > 1)\ncat(\"Numero di fattori secondo la regola di Kaiser:\", kaiser_rule, \"\\n\")\n#> Numero di fattori secondo la regola di Kaiser: 2\n```\n:::\n\n\n\n\n\n**Spiegazione**: la regola di Kaiser suggerisce di mantenere i fattori con autovalori maggiori di 1.  \n*Problema*: è noto che **sovrastima** il numero di fattori, specialmente in campioni piccoli o quando le comunalità sono basse.\n\n### Scree Plot (Cattell)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Scree plot\nplot(eigenvalues, type = \"b\", pch = 19, main = \"Scree plot (Cattell)\", \n     xlab = \"Numero di fattori\", ylab = \"Autovalore\")\nabline(h = 1, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n**Spiegazione**: Il numero ottimale di fattori corrisponde al punto **prima del \"gomito\"** nella curva degli autovalori decrescenti.  \n*Problema*: il metodo è **visivo e soggettivo**, quindi ha bassa affidabilità.\n\n### Regola del valore medio degli autovalori\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean_val <- mean(eigenvalues)\nmean_rule <- sum(eigenvalues > mean_val)\ncat(\"Numero di fattori secondo la regola del valore medio:\", mean_rule, \"\\n\")\n#> Numero di fattori secondo la regola del valore medio: 2\n```\n:::\n\n\n\n\n\n**Spiegazione**: mantiene solo i fattori con autovalori superiori alla media.  \nQuesta è una **variante della regola di Kaiser**, meno estrema, ma comunque euristica.\n\n### Metodi avanzati con il pacchetto `nFactors`\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Metodo EKC (Empirical Kaiser Criterion)\nekc_result <- efa.ekc(sample.cov = wais_cor, sample.nobs = 300)  # Specificare N = numerosità stimata\nekc_result\n#> \n#>  Empirical Kaiser Criterion suggests 4 factors.\n#>  Traditional Kaiser Criterion suggests 2 factors.\n#> \n#>    Sample   Ref\n#> 1   6.074 1.420\n#> 2   1.015 0.699\n#> 3   0.746 0.617\n#> 4   0.587 0.562\n#> 5   0.508 0.523\n#> 6   0.431 0.490\n#> 7   0.423 0.465\n#> 8   0.377 0.431\n#> 9   0.351 0.397\n#> 10  0.310 0.346\n#> 11  0.177 0.251\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n**Spiegazione**: EKC è una versione empiricamente corretta della regola di Kaiser, che **tiene conto del campione**, della **forma della distribuzione**, e della **varianza spiegata cumulativa**.  \nÈ più affidabile, soprattutto in strutture semplici.\n\n### STOC e STAF (versioni automatizzate dello Scree Test)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcola autovalori simulati\nnfac <- nFactors::nScree(x = eigenvalues)\nsummary(nfac)\n#> Report For a nScree Class \n#> \n#> Details: components \n#> \n#>    Eigenvalues Prop Cumu Par.Analysis Pred.eig     OC Acc.factor     AF\n#> 1            6    1    1            1        1                NA (< AF)\n#> 2            1    0    1            1        1 (< OC)          5       \n#> 3            1    0    1            1        1                 0       \n#> 4            1    0    1            1        1                 0       \n#> 5            1    0    1            1        0                 0       \n#> 6            0    0    1            1        0                 0       \n#> 7            0    0    1            1        0                 0       \n#> 8            0    0    1            1        0                 0       \n#> 9            0    0    1            1        0                 0       \n#> 10           0    0    1            1       NA                 0       \n#> 11           0    0    1            1       NA                NA       \n#> \n#> \n#>  Number of factors retained by index \n#> \n#>   noc naf nparallel nkaiser\n#> 1   2   1         2       2\n\n# Plot per confronto\nplotnScree(nfac)\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n**Spiegazione**:\n\n- **STOC** = Optimal Coordinate\n- **STAF** = Acceleration Factor  \nSono versioni **statistiche** dello scree test, che usano variazioni nella pendenza degli autovalori.\n\n\n## Metodi basati sulla simulazione\n\n### Parallel Analysis (PA)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Variante standard: confronto con media degli autovalori simulati\nset.seed(123)  # Per replicabilità\nfa.parallel(wais_cor, n.obs = 300, fa = \"fa\", fm = \"ml\", \n            main = \"Parallel Analysis (media simulata)\")\n#> Parallel analysis suggests that the number of factors =  2  and the number of components =  NA\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n\n### Spiegazione\n\n- Confronta gli **autovalori osservati** con quelli ottenuti da **dati casuali**.\n- Se l’autovalore osservato > simulato → **mantieni** il fattore.\n- Il metodo è **molto affidabile**, specie se il numero di soggetti (`n.obs`) è corretto.\n- La **variante di Glorfeld** (non mostrata) è più **conservativa** (riduce il rischio di sovrafattorizzare).\n\n\n### Comparison Data (CD)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Metodo Comparison Data\n# Richiede che i dati siano in formato \"raw\" (non solo matrice di correlazione)\n# Quindi, simuliamo dati coerenti con la matrice di correlazione per scopi didattici:\n\nset.seed(123)\nN <- 300  # ipotetica numerosità campionaria\nwais_sim <- mvrnorm(N, mu = rep(0, 11), Sigma = wais_cor)\ncolnames(wais_sim) <- colnames(wais_cor)\n\n# Applica il metodo Comparison Data\ncd_result <- EFAtools::CD(\n  x = wais_sim,\n  n_factors_max = 6,        # Numero massimo di fattori da testare\n  N_pop = 10000,             # Dimensione della popolazione simulata\n  N_samples = 500,           # Numero di campioni bootstrap\n  alpha = 0.3,               # Soglia per il test di Mann-Whitney\n  use = \"pairwise.complete.obs\",  # Gestione dei dati mancanti\n  cor_method = \"pearson\",    # Metodo di correlazione\n  max_iter = 50              # Iterazioni massime\n)\n\n# Mostra il riepilogo dei risultati\ncd_result\n#> The number of factors suggested by CD is .\n```\n:::\n\n\n\n\n\n### Spiegazione\n\n- Il metodo **Comparison Data (CD)** simula set di dati \"riprodotti\" con un certo numero di fattori.\n- Confronta il **RMSE** delle soluzioni successive con un **test di Mann-Whitney**.\n- Il numero ottimale di fattori è quello **oltre il quale non si osserva un miglioramento significativo**.\n- *Attenzione*: può **sovrafattorizzare** se `max_factors` è troppo alto o se i dati sono rumorosi.\n- Molto utile con **fattori correlati** e **strutture complesse**.\n\n**In sintesi**:\n\n- **PA (Parallel Analysis)** è il metodo di riferimento, raccomandato dalla maggior parte delle linee guida (es. Fabrigar et al., 1999).\n- **CD (Comparison Data)** è utile in presenza di **fattori obliqui** o **bassa comunalità**, ma può richiedere **parametri aggiustati** per una stima più accurata.\n-  Evita di usare **un solo criterio**: combina i risultati con quelli basati sugli **autovalori** e sulle **analisi di bontà di adattamento** (RMSEA, BIC, ecc.).\n\n## Indici di informazione\n\nConsideriamo ora un'implementazione in R per determinare il numero di fattori da estrarre dalla matrice di correlazione WAIS utilizzando metodi basati sugli indici di informazione.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(wais_cor)  # Dovrebbe essere 11x11\n#> [1] 11 11\n```\n:::\n\n\n\n\n\n1. **Criteri Informativi AIC e BIC**:\n\n   - Calcolo di AIC e BIC per modelli con 1-5 fattori.\n   - Visualizzazione grafica per identificare il punto di minimo.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo il numero di fattori usando AIC e BIC\nfa_fit <- function(nfactors, x, n.obs = 100) {\n  fit <- fa(x, nfactors = nfactors, fm = \"ml\", n.obs = n.obs)\n  chi <- fit$STATISTIC\n  df <- fit$dof\n  pval <- fit$PVAL\n  aic <- chi - 2 * df\n  bic <- chi - df * log(n.obs)\n  list(nfactors = nfactors, chi = chi, df = df, pval = pval, aic = aic, bic = bic)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Assumiamo una dimensione campionaria di 100 \nn.obs <- 100\n\n# Calcoliamo AIC e BIC per diversi numeri di fattori\nresults <- data.frame()\nfor (i in 1:5) {\n  res <- fa_fit(i, wais_cor, n.obs)\n  results <- rbind(results, data.frame(\n    nfactors = i,\n    chi_square = res$chi,\n    df = res$df,\n    p_value = res$pval,\n    aic = res$aic,\n    bic = res$bic\n  ))\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizziamo i risultati\nprint(results)\n#>   nfactors chi_square df  p_value    aic     bic\n#> 1        1     69.589 44 0.008288 -18.41 -133.04\n#> 2        2     15.998 34 0.996287 -52.00 -140.58\n#> 3        3      8.244 25 0.999341 -41.76 -106.89\n#> 4        4      3.515 17 0.999787 -30.48  -74.77\n#> 5        5      1.229 10 0.999561 -18.77  -44.82\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Grafici per AIC e BIC\npar(mfrow = c(1, 2))\nplot(results$nfactors, results$aic, type = \"b\", main = \"AIC per numero di fattori\", \n     xlab = \"Numero di fattori\", ylab = \"AIC\", xaxt = \"n\")\naxis(1, at = 1:5)\nabline(v = which.min(results$aic), col = \"red\", lty = 2)\n\nplot(results$nfactors, results$bic, type = \"b\", main = \"BIC per numero di fattori\", \n     xlab = \"Numero di fattori\", ylab = \"BIC\", xaxt = \"n\")\naxis(1, at = 1:5)\nabline(v = which.min(results$bic), col = \"red\", lty = 2)\npar(mfrow = c(1, 1))\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n2. **Indici di Fit da CFA**:\n\n   - Implementazione di CFI, TLI, RMSEA e SRMR.\n   - Grafici per valutare quando questi indici raggiungono valori accettabili.\n   - Criteri di riferimento: CFI > 0.95, RMSEA < 0.05.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definiamo i modelli CFA per diversi numeri di fattori\nfit_indices <- data.frame()\n\nfor (i in 1:5) {\n  # Estraiamo prima i fattori con analisi fattoriale esplorativa\n  fa_result <- fa(wais_cor, nfactors = i, fm = \"ml\", rotate = \"varimax\")\n  \n  # Creiamo il modello CFA basato sui loadings più alti\n  model_syntax <- \"\"\n  for (j in 1:i) {\n    # Seleziona le variabili con i loadings più alti per ciascun fattore\n    vars <- names(sort(abs(fa_result$loadings[, j]), decreasing = TRUE)[1:ceiling(11/i)])\n    model_syntax <- paste0(model_syntax, \"F\", j, \" =~ \", paste(vars, collapse = \" + \"), \"\\n\")\n  }\n  \n  # Eseguiamo la CFA\n  try({\n    fit <- cfa(model_syntax, sample.cov = wais_cor, sample.nobs = n.obs)\n    indices <- fitMeasures(fit, c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\", \"aic\", \"bic\"))\n    \n    fit_indices <- rbind(fit_indices, data.frame(\n      nfactors = i, \n      chisq = indices[\"chisq\"], \n      df = indices[\"df\"], \n      pvalue = indices[\"pvalue\"],\n      cfi = indices[\"cfi\"], \n      tli = indices[\"tli\"], \n      rmsea = indices[\"rmsea\"], \n      srmr = indices[\"srmr\"],\n      aic = indices[\"aic\"], \n      bic = indices[\"bic\"]\n    ))\n  }, silent = TRUE)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizziamo gli indici di fit\nprint(fit_indices)\n#>        nfactors  chisq df   pvalue    cfi    tli  rmsea    srmr  aic  bic\n#> chisq         1 74.162 44 0.002985 0.9476 0.9345 0.0828 0.05991 2598 2655\n#> chisq1        2 15.429 32 0.994044 1.0000 1.0430 0.0000 0.02935 2302 2362\n#> chisq2        3 16.482 30 0.978282 1.0000 1.0383 0.0000 0.03198 2319 2384\n#> chisq3        4 13.998 27 0.981271 1.0000 1.0429 0.0000 0.02705 2348 2420\n#> chisq4        5  5.737 20 0.999209 1.0000 1.0635 0.0000 0.01502 2353 2444\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizziamo graficamente gli indici di fit\nif (nrow(fit_indices) > 0) {\n  par(mfrow = c(2, 2))\n  plot(fit_indices$nfactors, fit_indices$cfi, type = \"b\", main = \"CFI per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"CFI\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  abline(h = 0.95, col = \"red\", lty = 2)\n  \n  plot(fit_indices$nfactors, fit_indices$rmsea, type = \"b\", main = \"RMSEA per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"RMSEA\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  abline(h = 0.05, col = \"red\", lty = 2)\n  \n  plot(fit_indices$nfactors, fit_indices$aic, type = \"b\", main = \"AIC (CFA) per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"AIC\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  \n  plot(fit_indices$nfactors, fit_indices$bic, type = \"b\", main = \"BIC (CFA) per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"BIC\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  par(mfrow = c(1, 1))\n}\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n3. **Test del Chi-Quadrato**:\n\n   - Confronto incrementale tra modelli con diverso numero di fattori.\n   - Test della significatività della differenza di fit.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcoliamo la differenza di chi-quadrato tra modelli consecutivi\nif (nrow(results) > 1) {\n  chi_diff <- data.frame(\n    comparison = character(),\n    chi_diff = numeric(),\n    df_diff = numeric(),\n    p_value = numeric()\n  )\n  \n  for (i in 2:nrow(results)) {\n    chi_diff_val <- results$chi_square[i-1] - results$chi_square[i]\n    df_diff_val <- results$df[i-1] - results$df[i]\n    p_val <- 1 - pchisq(chi_diff_val, df_diff_val)\n    \n    chi_diff <- rbind(chi_diff, data.frame(\n      comparison = paste(i-1, \"vs\", i),\n      chi_diff = chi_diff_val,\n      df_diff = df_diff_val,\n      p_value = p_val\n    ))\n  }\n  \n  print(\"Test del chi-quadrato per confronto di modelli:\")\n  print(chi_diff)\n}\n#> [1] \"Test del chi-quadrato per confronto di modelli:\"\n#>   comparison chi_diff df_diff   p_value\n#> 1     1 vs 2   53.591      10 5.782e-08\n#> 2     2 vs 3    7.754       9 5.591e-01\n#> 3     3 vs 4    4.729       8 7.861e-01\n#> 4     4 vs 5    2.286       7 9.423e-01\n```\n:::\n\n\n\n\n\n4. **Sintesi dei Risultati**:\n\n   - Riepilogo delle indicazioni dai vari indici.\n   - Raccomandazione sul numero ottimale di fattori.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncat(\"\\nSintesi dei risultati:\\n\")\n#> \n#> Sintesi dei risultati:\ncat(\"Numero di fattori suggerito da AIC:\", which.min(results$aic), \"\\n\")\n#> Numero di fattori suggerito da AIC: 2\ncat(\"Numero di fattori suggerito da BIC:\", which.min(results$bic), \"\\n\")\n#> Numero di fattori suggerito da BIC: 2\n\nif (nrow(fit_indices) > 0) {\n  # Per CFI vogliamo valori > 0.95\n  good_cfi <- which(fit_indices$cfi > 0.95)\n  if (length(good_cfi) > 0) {\n    cat(\"Numero minimo di fattori con CFI > 0.95:\", min(good_cfi), \"\\n\")\n  }\n  \n  # Per RMSEA vogliamo valori < 0.05\n  good_rmsea <- which(fit_indices$rmsea < 0.05)\n  if (length(good_rmsea) > 0) {\n    cat(\"Numero minimo di fattori con RMSEA < 0.05:\", min(good_rmsea), \"\\n\")\n  }\n}\n#> Numero minimo di fattori con CFI > 0.95: 2 \n#> Numero minimo di fattori con RMSEA < 0.05: 2\n\nif (nrow(chi_diff) > 0) {\n  # Per il test chi-quadrato, cerchiamo il primo confronto non significativo\n  non_sig <- which(chi_diff$p_value > 0.05)\n  if (length(non_sig) > 0) {\n    cat(\"Basato sul test del chi-quadrato, il numero ottimale di fattori è:\", as.numeric(substr(chi_diff$comparison[min(non_sig)], 1, 1)), \"\\n\")\n  }\n}\n#> Basato sul test del chi-quadrato, il numero ottimale di fattori è: 2\n```\n:::\n\n\n\n\n\n## Metodo Hull\n\nIl metodo è implementato nel pacchetto [`EFAtools`](https://cran.r-project.org/web/packages/EFAtools/index.html) in R (Steiner & Gruber, 2020).\n\nNel grafico risultante, si osserva la curva dei valori di CFI in funzione dei gradi di libertà. Il metodo Hull seleziona il punto \"di gomito\", dove il modello ha ancora un buon fit ma con la massima parsimonia. In alcuni casi, il metodo può suggerire ad esempio che **una soluzione a un fattore è preferibile**, se l’aggiunta di ulteriori fattori non migliora significativamente l’adattamento.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nHull(\n  wais_sim,\n  fa = \"fa\",\n  nfact = 6,\n  cor.type = \"pearson\",\n  use = \"pairwise.complete.obs\",\n  vis = TRUE,\n  plot = TRUE\n)\n#> The number of factors suggested by Hull is 1 .\n#> The number of factors suggested by Hull is 1 .\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n## Metodo MAP \n\nIl **MAP test** valuta, per ogni possibile numero di componenti estratti, quanto rimane di correlazione \"spuria\" nei residui. Il numero ottimale è quello che **minimizza la media delle correlazioni parziali residue**, cioè quello che riesce a \"pulire\" meglio la matrice di correlazione iniziale.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Applica il metodo MAP con la funzione vss()\nvss_map <- vss(\n  x = wais_cor,\n  n = 6,          # numero massimo di fattori/componenti da testare\n  n.obs = 100,     # numero di osservazioni\n  rotate = \"none\", # nessuna rotazione per mantenere interpretabilità\n  plot = FALSE     # non mostrare il grafico automaticamente\n)\nvss_map\n#> \n#> Very Simple Structure\n#> Call: vss(x = wais_cor, n = 6, rotate = \"none\", n.obs = 100, plot = FALSE)\n#> VSS complexity 1 achieves a maximimum of 0.92  with  2  factors\n#> VSS complexity 2 achieves a maximimum of 0.95  with  5  factors\n#> \n#> The Velicer MAP achieves a minimum of 0.03  with  2  factors \n#> BIC achieves a minimum of  -140.3  with  2  factors\n#> Sample Size adjusted BIC achieves a minimum of  -32.93  with  2  factors\n#> \n#> Statistics by number of factors \n#>   vss1 vss2   map dof chisq   prob sqresid  fit RMSEA  BIC SABIC complex\n#> 1 0.92 0.00 0.033  44 72.00 0.0049     3.2 0.92 0.079 -131   8.3     1.0\n#> 2 0.92 0.94 0.029  34 16.27 0.9956     2.3 0.94 0.000 -140 -32.9     1.2\n#> 3 0.83 0.95 0.044  25  8.40 0.9992     1.7 0.96 0.000 -107 -27.8     1.4\n#> 4 0.92 0.95 0.071  17  3.94 0.9995     1.7 0.96 0.000  -74 -20.7     1.4\n#> 5 0.92 0.95 0.107  10  1.46 0.9990     1.5 0.96 0.000  -45 -13.0     1.5\n#> 6 0.92 0.95 0.150   4  0.31 0.9894     1.4 0.96 0.000  -18  -5.5     1.6\n#>   eChisq   SRMR eCRMS eBIC\n#> 1 41.515 0.0614 0.069 -161\n#> 2  8.201 0.0273 0.035 -148\n#> 3  2.926 0.0163 0.024 -112\n#> 4  1.115 0.0101 0.018  -77\n#> 5  0.326 0.0054 0.013  -46\n#> 6  0.082 0.0027 0.010  -18\n```\n:::\n\n\n\n\n\n\n### Sintesi dei principali risultati\n\n| Metodo                           | Numero ottimale di fattori | Valore ottimale |\n|----------------------------------|-----------------------------|------------------|\n| **MAP (Velicer)**                | **2**                       | 0.03 (minimo)    |\n| **BIC**                          | **2**                       | -140.3 (minimo)  |\n| **BIC corretto per n (SABIC)**   | **2**                       | -32.93 (minimo)  |\n| **VSS complessità 1**            | 2                           | 0.92 (massimo)   |\n| **VSS complessità 2**            | 5                           | 0.95 (massimo)   |\n\n\n### Velicer MAP\n\n- Valuta la **media delle correlazioni parziali residue**.\n- L’obiettivo è minimizzare la varianza residua non spiegata dai fattori.\n- **Risultato**: minimo a **2 fattori**, con valore 0.03 → suggerisce **2 fattori**.\n\n### BIC e SABIC\n\n- Criteri informativi che bilanciano bontà del fit e parsimonia.\n- Più basso è il valore, meglio è.\n- Entrambi i criteri (sia BIC classico che SABIC) raggiungono il **minimo a 2 fattori**.\n\n### SS (Very Simple Structure)\n\n- Misura quanto bene una struttura semplice (con pochi caricamenti per variabile) si adatta ai dati.\n- Due versioni:\n  - **Complessità 1**: solo il caricamento maggiore per ogni variabile.\n  - **Complessità 2**: primi due caricamenti per variabile.\n- Complessità 1 → massimo a **2 fattori** (0.92)\n- Complessità 2 → massimo a **5 fattori** (0.95)\n\n🔎 *Nota*: VSS complessità 2 è più permissiva e tende a favorire strutture più complesse.\n\n**Interpretazione complessiva.**\n\nTutti i criteri **basati su residui o penalizzazione della complessità** (MAP, BIC, SABIC, VSS-1) **concordano nel suggerire una soluzione a 2 fattori**.\n\nSolo VSS-2 (più permissivo) suggerisce **5 fattori**, ma questa soluzione è meno parsimoniosa e più soggetta a sovrafattorizzazione.\n\nIn sintesi, sulla base di criteri oggettivi e parsimoniosi come **MAP**, **BIC**, **SABIC**, e **VSS a complessità 1**, una soluzione a **2 fattori** sembra ottimale per questi dati WAIS. L’adozione di criteri informativi e basati sui residui, come MAP e BIC, è fortemente raccomandata rispetto a metodi più soggettivi o sovraestimanti come Kaiser o Scree test.\n\n\n## Exploratory Graph Analysis (EGA)\n\nL’**Exploratory Graph Analysis (EGA)** è un metodo innovativo per identificare la struttura latente dei dati basato su modelli a rete, piuttosto che sui tradizionali modelli fattoriali. È implementato nel pacchetto [`EGAnet`](https://cran.r-project.org/package=EGAnet), sviluppato da Golino e colleghi. Il metodo è stato introdotto da **Golino & Epskamp (2017)** e perfezionato in studi successivi (Christensen, Golino & Silvia, 2020; Golino et al., 2020).\n\n### Caratteristiche principali di EGA:\n\n- Utilizza il **graphical lasso** per stimare le correlazioni parziali tra variabili, costruendo così una rete sparsa (solo le relazioni più forti restano).\n- Identifica **comunità di variabili** all’interno della rete, che corrispondono a **fattori latenti**.\n- È particolarmente utile quando:\n  - le **comunalità sono basse**,\n  - la **struttura fattoriale non è ben definita**,\n  - si lavora con **dati ordinali o non normali**.\n\nApplichiamo l’EGA alla matrice di correlazione delle **11 sottoscale della WAIS**.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Applica l'EGA alla matrice di correlazione WAIS\nega_result <- EGA(\n  data = wais_cor,        # Matrice di correlazione tra le 11 sottoscale\n  n = 300,                # Numero di soggetti nel campione\n  model = \"glasso\",       # Metodo di stima: graphical lasso\n  type = \"correlation\",   # Specifica che stiamo passando una matrice di correlazione\n  plot.EGA = TRUE         # Visualizza il grafo delle comunità (dimensioni)\n)\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n- **`model = \"glasso\"`**: applica una penalizzazione (lasso) per ridurre il numero di connessioni deboli tra variabili.\n- **`plot.EGA = TRUE`**: mostra un grafo con le sottoscale collegate in base alla loro correlazione condizionale.\n- **`ega_result$wc`**: contiene l’assegnazione di ciascuna variabile a una **comunità**, interpretata come un **fattore latente**.\n\n**Interpretazione dei risultati**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Riepilogo generale\nsummary(ega_result)\n#> Model: GLASSO (EBIC with gamma = 0.5)\n#> Correlations: auto\n#> Lambda: 0.081 (n = 100, ratio = 0.1)\n#> \n#> Number of nodes: 11\n#> Number of edges: 48\n#> Edge density: 0.873\n#> \n#> Non-zero edge weights: \n#>      M    SD   Min   Max\n#>  0.099 0.088 0.003 0.421\n#> \n#> ----\n#> \n#> Algorithm:  Louvain\n#> \n#> Number of communities:  1\n#> \n#> IN CO AR SI DS VO SY PC BD PA OA \n#>  1  1  1  1  1  1  1  1  1  1  1 \n#> \n#> ----\n#> \n#> Unidimensional Method: Louvain\n#> Unidimensional: Yes\n#> \n#> ----\n#> \n#> TEFI: 0\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Numero di dimensioni individuate (cioè di comunità)\nlength(unique(ega_result$wc))\n#> [1] 1\n```\n:::\n\n\n\n\n\n**Vantaggi:**\n\n- **non richiede ipotesi forti sulla distribuzione dei dati**;\n- **più robusto** dei metodi classici (EFA, PA) in presenza di **comunalità basse**;\n- offre una **visualizzazione intuitiva** delle relazioni tra variabili.\n\n> 💡 *EGA può essere utilizzato sia per esplorare la dimensionalità di un set di item sia per decidere quanti fattori mantenere prima di una conferma con CFA.*\n\n\n## Riflessioni Conclusive\n\nDeterminare il numero di fattori da estrarre in un'Analisi Fattoriale Esplorativa (EFA) rappresenta una delle sfide metodologiche più complesse nella costruzione di strumenti psicometrici. Nessun metodo è infallibile o universalmente valido: ogni tecnica presenta vantaggi, limiti e assunzioni specifiche. Per questo motivo, la **triangolazione** di più metodi e la riflessione teorica guidano le scelte più solide.\n\n### 1. La scelta del numero di fattori: tra tecniche classiche e moderne\n\nLe tecniche tradizionali, come la regola di Kaiser e lo scree test, sono state largamente impiegate per la loro semplicità, ma risultano oggi superate per via della loro tendenza sistematica alla **sovra- o sotto-fattorizzazione**. In particolare:\n\n- La **Parallel Analysis (PA)** si conferma il metodo più raccomandato, grazie alla sua capacità di distinguere fattori reali da quelli generati dal rumore;\n- Il metodo **Comparison Data (CD)** si dimostra utile con strutture complesse o fattori correlati, ma va calibrato attentamente;\n- I criteri **informativi** (AIC, BIC) e gli **indici di adattamento del modello** (RMSEA, CFI) aggiungono elementi preziosi per valutare la bontà della soluzione, specialmente quando integrati con la CFA;\n- Metodi recenti come **MAP**, **Hull**, **EGA** o **Factor Forest** offrono soluzioni promettenti, soprattutto in contesti con comunalità basse, dati non normali o ordinali.\n\n### 2. Replicabilità: validare ciò che si scopre\n\nIdentificare una struttura fattoriale coerente è solo il primo passo. Per attribuire **validità e generalizzabilità** a una soluzione esplorativa, occorre valutarne la **replicabilità**:\n\n- **Replicazione in campioni indipendenti** e **validazione incrociata** servono a testare la stabilità della struttura in sottogruppi differenti;\n- La **CFA** permette di verificare, in modo formale, se una struttura fattoriale individuata in EFA è confermata da nuovi dati;\n- Tecniche di **ricampionamento** (come il bootstrap) offrono ulteriori strumenti per stimare l’incertezza legata alla soluzione ottenuta.\n\nUna struttura replicabile è più probabilmente una rappresentazione fedele dei costrutti latenti piuttosto che un artefatto del campione specifico.\n\n### 3. Cosa fare con i fattori: applicazioni e criticità\n\nDopo aver identificato i fattori, è cruciale decidere **come utilizzarli**:\n\n- Nei **Modelli di Equazioni Strutturali (SEM)**, i fattori possono essere usati come predittori, mediatori, moderatori o esiti, con il vantaggio di modellare esplicitamente l’errore di misura;\n- Al di fuori dei SEM, l’uso di **punteggi fattoriali** (calcolati come media, somma o compositi ponderati) va considerato con cautela, poiché può trascurare errori di misura o differenze di importanza tra variabili;\n- In certi casi, **compositi a pesi unitari** possono essere preferibili a quelli ponderati, specialmente per garantire maggiore generalizzabilità e robustezza cross-campione.\n\nLa scelta operativa su come rappresentare e usare i fattori dovrebbe sempre essere coerente con le finalità della ricerca e con le caratteristiche dei dati.\n\n### 4. Una visione integrata\n\nIn definitiva, la **determinazione del numero di fattori**, la **replicabilità** della soluzione e il **modo in cui i fattori vengono utilizzati** sono aspetti interdipendenti di un processo rigoroso e cumulativo. Una buona pratica psicometrica non si limita a identificare la struttura che “funziona meglio” nel proprio campione, ma valuta la stabilità della soluzione, il suo significato teorico e la sua applicazione pratica.\n\n> ✏️ *La validità di uno strumento psicologico non si esaurisce nella bontà del suo adattamento al campione corrente, ma nella sua capacità di riflettere stabilmente e in modo interpretabile i costrutti che intende misurare.*\n\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.4\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] REFA_0.1.0         latentFactoR_0.0.6 EGAnet_2.2.0      \n#>  [4] EFAfactors_1.2.1   EFAtools_0.4.6     nFactors_2.4.1.1  \n#>  [7] lattice_0.22-7     fspe_0.1.2         paran_1.5.3       \n#> [10] ggokabeito_0.1.0   see_0.11.0         MASS_7.3-65       \n#> [13] viridis_0.6.5      viridisLite_0.4.2  ggpubr_0.6.0      \n#> [16] ggExtra_0.10.1     gridExtra_2.3      patchwork_1.3.0   \n#> [19] bayesplot_1.11.1   semTools_0.5-7     semPlot_1.1.6     \n#> [22] lavaan_0.6-19      psych_2.5.3        scales_1.3.0      \n#> [25] markdown_2.0       knitr_1.50         lubridate_1.9.4   \n#> [28] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n#> [31] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1       \n#> [34] tibble_3.2.1       ggplot2_3.5.2      tidyverse_2.0.0   \n#> [37] here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2          later_1.4.2            XML_3.99-0.18         \n#>   [4] rpart_4.1.24           lifecycle_1.0.4        Rdpack_2.6.4          \n#>   [7] rstatix_0.7.2          rprojroot_2.0.4        rockchalk_1.8.157     \n#>  [10] backports_1.5.0        magrittr_2.0.3         openxlsx_4.2.8        \n#>  [13] Hmisc_5.2-3            rmarkdown_2.29         yaml_2.3.10           \n#>  [16] httpuv_1.6.15          qgraph_1.9.8           zip_2.3.2             \n#>  [19] reticulate_1.42.0      RColorBrewer_1.1-3     pbapply_1.7-2         \n#>  [22] minqa_1.2.8            multcomp_1.4-28        abind_1.4-8           \n#>  [25] quadprog_1.5-8         nnet_7.3-20            TH.data_1.1-3         \n#>  [28] sandwich_3.1-1         arm_1.14-4             codetools_0.2-20      \n#>  [31] tidyselect_1.2.1       farver_2.1.2           lme4_1.1-37           \n#>  [34] stats4_4.4.2           base64enc_0.1-3        ddpcr_1.15.2          \n#>  [37] jsonlite_2.0.0         Formula_1.2-5          survival_3.8-3        \n#>  [40] emmeans_1.11.0         tools_4.4.2            sna_2.8               \n#>  [43] Rcpp_1.0.14            glue_1.8.0             mnormt_2.1.1          \n#>  [46] xfun_0.52              ranger_0.17.0          withr_3.0.2           \n#>  [49] fastmap_1.2.0          GGally_2.2.1           boot_1.3-31           \n#>  [52] digest_0.6.37          mi_1.1                 timechange_0.3.0      \n#>  [55] R6_2.6.1               mime_0.13              estimability_1.5.1    \n#>  [58] colorspace_2.1-1       gtools_3.9.5           jpeg_0.1-11           \n#>  [61] generics_0.1.3         data.table_1.17.0      corpcor_1.6.10        \n#>  [64] htmlwidgets_1.6.4      ggstats_0.9.0          pkgconfig_2.0.3       \n#>  [67] sem_3.1-16             gtable_0.3.6           SimCorMultRes_1.9.0   \n#>  [70] htmltools_0.5.8.1      carData_3.0-5          parallelMap_1.5.1     \n#>  [73] png_0.1-8              reformulas_0.4.0       rstudioapi_0.17.1     \n#>  [76] tzdb_0.5.0             reshape2_1.4.4         statnet.common_4.11.0 \n#>  [79] coda_0.19-4.1          checkmate_2.3.2        nlme_3.1-168          \n#>  [82] nloptr_2.2.1           proxy_0.4-27           zoo_1.8-13            \n#>  [85] parallel_4.4.2         miniUI_0.1.1.1         foreign_0.8-90        \n#>  [88] pillar_1.10.2          grid_4.4.2             vctrs_0.6.5           \n#>  [91] mlr_2.19.2             promises_1.3.2         car_3.1-3             \n#>  [94] OpenMx_2.21.13         xtable_1.8-4           cluster_2.1.8.1       \n#>  [97] GPArotation_2024.3-1   htmlTable_2.4.3        evaluate_1.0.3        \n#> [100] BBmisc_1.13            pbivnorm_0.6.0         mvtnorm_1.3-3         \n#> [103] cli_3.6.4              kutils_1.73            compiler_4.4.2        \n#> [106] rlang_1.1.5            ggsignif_0.6.4         fdrtool_1.2.18        \n#> [109] RcppArmadillo_14.4.1-1 plyr_1.8.9             stringi_1.8.7         \n#> [112] network_1.19.0         munsell_0.5.1          lisrelToR_0.3         \n#> [115] pacman_0.5.1           Matrix_1.7-3           ParamHelpers_1.14.2   \n#> [118] hms_1.1.3              glasso_1.11            shiny_1.10.0          \n#> [121] evd_2.3-7.1            rbibutils_2.3          ineq_0.2-13           \n#> [124] igraph_2.1.4           broom_1.0.8            RcppParallel_5.1.10   \n#> [127] fastmatch_1.1-6        xgboost_1.7.9.1\n```\n:::\n",
    "supporting": [
      "03_numero_fattori_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
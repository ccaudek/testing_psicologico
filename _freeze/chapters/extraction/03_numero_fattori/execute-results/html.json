{
  "hash": "4ad35488d79aebff6ad9865e7d73b99a",
  "result": {
    "engine": "knitr",
    "markdown": "# Determinare il numero dei fattori {#sec-extraction-number-factors}\n\n::: callout-important\n## In questo capitolo imparerai:\n\n- determinare il numero di fattori da estrarre nell'analisi fattoriale.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere l'articolo *How many factors to retain in exploratory factor analysis? A critical overview of factor retention methods* [@goretzko2025many].\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(devtools)\n# install_github(\"jmbh/fspe\")\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  lavaan, psych, paran, fspe, nFactors, semTools, EFAtools, MASS,\n  EFAfactors, EGAnet, latentFactoR, REFA\n)\n```\n:::\n\n\n\n\n:::\n\n\n## Introduzione\n\nL‚ÄôAnalisi Fattoriale Esplorativa (EFA) √® uno strumento fondamentale nella costruzione e valutazione di test psicologici. Essa consente di esplorare la struttura latente sottostante a un insieme di variabili osservate. Uno degli aspetti pi√π delicati dell'EFA √® la **determinazione del numero di fattori da estrarre**, nota anche come *factor retention*. Una scelta errata pu√≤ compromettere l‚Äôintera analisi, portando a:\n\n- **Sottofattorizzazione**: sottostimare il numero di fattori, rischiando di distorcere la struttura latente e generare caricamenti spurii (cross-loadings);\n- **Sovrafattorizzazione**: estrarre pi√π fattori del necessario, introducendo elementi poco interpretabili. Questo errore √® meno grave, purch√© venga riconosciuto e gestito opportunamente.\n\n### Tre domande fondamentali sulla dimensionalit√† di un test\n\n1. **Quante dimensioni?** Alcuni test misurano un solo costrutto latente, altri ne misurano diversi.\n2. **Le dimensioni sono correlate?** Se s√¨, √® opportuno utilizzare metodi di rotazione obliqua.\n3. **Cosa significano le dimensioni?** L‚Äôinterpretazione teorica dei fattori √® cruciale per l‚Äôapplicazione pratica del test.\n\nQuesto capitolo presenta e confronta i principali approcci proposti per determinare il numero ottimale di fattori, illustrandone i presupposti, i punti di forza e le limitazioni.\n\n## Metodi basati sugli autovalori\n\n### Kaiser-Guttman Rule\n\nRetiene i fattori con autovalore > 1 (solo per matrici di correlazione). Anche se molto diffuso, √® fortemente sconsigliato: ha una tendenza sistematica alla **sovrafattorizzazione**. √à inappropriato per dati non standardizzati o con bassa comunalit√†.\n\n### Scree Test (Cattell)\n\nGrafico degli autovalori decrescenti: il numero di fattori corrisponde al punto prima del \"gomito\". Soggettivo e a bassa affidabilit√†.\n\n### Valore medio degli autovalori\n\nRetiene i fattori con autovalore maggiore della media degli autovalori. Alternativa alla regola di Kaiser, ma ancora euristica.\n\n### Metodi Avanzati\n\n- **Empirical Kaiser Criterion (EKC)**: corregge per numerosit√† campionaria e varianza cumulata. Buona performance solo in strutture semplici e unidimensionali.\n- **STOC** e **STAF**: automatizzano lo scree test via algoritmi (es. accelerazione della pendenza) -- implementate in `nFactors`.\n\n## Metodi Basati sulla Simulazione\n\n### Parallel Analysis (PA)\n\nConsiderata lo \"standard aureo\". Confronta gli autovalori empirici con quelli derivati da dati casuali:\n\n- variante standard: usa la media degli autovalori simulati;\n- variante di Glorfeld: usa il 95¬∞ percentile per essere pi√π conservativa;\n- funzioni: `fa.parallel()` del pacchetto `psych`.\n\n### Comparison Data (CD)\n\nUsa bootstrap e riproduce la matrice di correlazione. Confronta soluzioni adiacenti con un test di Mann-Whitney sugli RMSE. Utile con fattori correlati, ma tende a sovrafattorizzare se non ben calibrato. Implementato in `EFAtools`.\n\n## Approcci basati sul confronto tra modelli\n\n### Criteri Informativi: AIC, BIC\n\nUtilizzano la verosimiglianza e penalizzano la complessit√† del modello.\n\n- AIC: tende a selezionare modelli pi√π complessi;\n- BIC: pi√π conservativo.\n\n### Indici di Fit: \n\nGli indicici di fit come RMSEA, CFI, SRMR, ecc. sono usati pi√π comunemente in CFA, ma sono meno affidabili in EFA a causa della dipendenza da dimensione campionaria e altri fattori.\n\n### Metodo Hull\n\nIl **metodo Hull** (Lorenzo-Seva, Timmerman, & Kiers, 2011) √® un approccio grafico per la determinazione del numero ottimale di fattori. L‚Äôidea di base √® bilanciare **bont√† dell‚Äôadattamento** e **parsimonia del modello** (cio√® la semplicit√†).\n\nCome funziona:\n\n1. si adattano diversi modelli fattoriali con un numero crescente di fattori;\n2. per ciascun modello, si registra un indice di fit (es. CFI) e i **gradi di libert√†**;\n3. si costruisce il **\"convex hull\"**, ovvero il contorno convesso che racchiude i punti CFI ~ gradi di libert√†;\n4. si identifica il punto sul contorno del hull che rappresenta il miglior compromesso tra **fit accettabile** e **modello semplice** (cio√® con pi√π gradi di libert√†).\n\nVantaggi:\n\n- tende a evitare la **sovrafattorizzazione**, comune in altri metodi;\n- ha buone prestazioni quando il modello √® **ben sovradeterminato** (cio√® ogni fattore √® misurato da molte variabili);\n- √® adatto anche in presenza di **fattori correlati**.\n\n## Minimum Average Partial (MAP)\n\nTest che valuta la media delle correlazioni parziali residue dopo estrazione di i componenti. Retiene il numero di componenti che minimizza questa media. √à implementato in `vss()` del pacchetto `psych`.\n\n## Approcci moderni\n\n### Analisi Esplorativa della Rete (EGA)\n\nL‚Äô**Exploratory Graph Analysis (EGA)** √® un metodo alternativo all‚Äôanalisi fattoriale esplorativa (EFA), che non si basa sull‚Äôipotesi di **fattori latenti comuni**, ma sull‚Äôidentificazione di **comunit√† di variabili** all‚Äôinterno di un **modello a rete**.\n\n- In EGA, le **variabili osservate** (es. item di un test) sono rappresentate come **nodi** di una rete.\n- Le **connessioni** (archi) tra i nodi riflettono **correlazioni parziali** standardizzate, cio√® relazioni tra due variabili controllando per tutte le altre.\n- Il modello statistico di base √® il **Gaussian Graphical Model (GGM)**, stimato con un metodo di **massima verosimiglianza penalizzata** (regularization), che tende ad annullare le correlazioni pi√π deboli, producendo reti **sparse** (con pochi collegamenti).\n- All‚Äôinterno di questa rete, le variabili **fortemente collegate tra loro** tendono a raggrupparsi in **comunit√†** (clusters), che vengono interpretate come **fattori**.\n\nVantaggi dell‚ÄôEGA:\n\n- √® particolarmente utile in condizioni in cui:\n  - le **comunalit√† sono basse** (cio√® le variabili condividono poca varianza comune),\n  - i dati sono **ordinali** o non normalmente distribuiti.\n- rispetto all‚ÄôEFA tradizionale, EGA √® pi√π robusto a **strutture complesse o deboli**.\n\nCome viene determinato il numero di fattori?\n\nIl numero di comunit√† (e quindi di fattori) viene identificato attraverso **algoritmi di rilevamento delle comunit√†**, come il **walktrap algorithm**, che cerca sottogruppi fortemente interconnessi all‚Äôinterno della rete.\n\nIn sintesi, EGA fornisce una rappresentazione grafica e interpretabile della struttura fattoriale dei dati, e pu√≤ essere usato per **decidere quanti fattori estrarre** in un‚Äôanalisi esplorativa.\n\n## Metodi Basati su Machine Learning\n\n### Factor Forest (ML)\n\nApproccio machine learning addestrato su dati simulati. Molto preciso, ma dipende da modelli preaddestrati. Implementato in `latentFactoR`.\n\n### Comparison Data Forest (CDF)\n\nVersione pi√π leggera del Factor Forest basata su CD + Random Forest. Meno accurata ma pi√π accessibile. Implementazione disponibile su OSF.\n\n### Regularized EFA (REFA)\n\nUtilizza penalizzazioni (LASSO, Ridge, MC+) per ottenere strutture sparse. Pu√≤ essere utile per l‚Äôidentificazione automatica dei fattori. Implementazioni: `fanc`, `regsem`, `lslx`.\n\n\n## Implementazione in R\n\nPer confrontare i metodi discussi per la scelta del numero $m$ di fattori usiamo una matrice di correlazioni calcolata sulle sottoscale della WAIS. Le 11 sottoscale del test sono le seguenti:\n\n- X1 = Information\n- X2 = Comprehension\n- X3 = Arithmetic\n- X4 = Similarities\n- X5 = Digit.span\n- X6 = Vocabulary\n- X7 = Digit.symbol\n- X8 = Picture.completion\n- X9 = Block.design\n- X10 = Picture.arrangement\n- X11 = Object.\n\nI dati sono stati ottenuti dal manuale della III edizione.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvarnames <- c(\n    \"IN\", \"CO\", \"AR\", \"SI\", \"DS\", \"VO\", \"SY\", \"PC\",\n    \"BD\", \"PA\", \"OA\", \"AG\", \"ED\"\n)\ntemp <- matrix(c(\n    1, 0.67, 0.62, 0.66, 0.47, 0.81, 0.47, 0.60, 0.49, 0.51, 0.41,\n    -0.07, 0.66, .67, 1, 0.54, 0.60, 0.39, 0.72, 0.40, 0.54, 0.45,\n    0.49, 0.38, -0.08, 0.52, .62, .54, 1, 0.51, 0.51, 0.58, 0.41,\n    0.46, 0.48, 0.43, 0.37, -0.08, 0.49, .66, .60, .51, 1, 0.41,\n    0.68, 0.49, 0.56, 0.50, 0.50, 0.41, -0.19, 0.55, .47, .39, .51,\n    .41, 1, 0.45, 0.45, 0.42, 0.39, 0.42, 0.31, -0.19, 0.43,\n    .81, .72, .58, .68, .45, 1, 0.49, 0.57, 0.46, 0.52, 0.40, -0.02,\n    0.62, .47, .40, .41, .49, .45, .49, 1, 0.50, 0.50, 0.52, 0.46,\n    -0.46, 0.57, .60, .54, .46, .56, .42, .57, .50, 1, 0.61, 0.59,\n    0.51, -0.28, 0.48, .49, .45, .48, .50, .39, .46, .50, .61, 1,\n    0.54, 0.59, -0.32, 0.44, .51, .49, .43, .50, .42, .52, .52, .59,\n    .54, 1, 0.46, -0.37, 0.49, .41, .38, .37, .41, .31, .40, .46, .51,\n    .59, .46, 1, -0.28, 0.40, -.07, -.08, -.08, -.19, -.19, -.02,\n    -.46, -.28, -.32, -.37, -.28, 1, -0.29, .66, .52, .49, .55, .43,\n    .62, .57, .48, .44, .49, .40, -.29, 1\n), nrow = 13, ncol = 13, byrow = TRUE)\n\ncolnames(temp) <- varnames\nrownames(temp) <- varnames\n\nwais_cor <- temp[1:11, 1:11]\nwais_cor\n#>      IN   CO   AR   SI   DS   VO   SY   PC   BD   PA   OA\n#> IN 1.00 0.67 0.62 0.66 0.47 0.81 0.47 0.60 0.49 0.51 0.41\n#> CO 0.67 1.00 0.54 0.60 0.39 0.72 0.40 0.54 0.45 0.49 0.38\n#> AR 0.62 0.54 1.00 0.51 0.51 0.58 0.41 0.46 0.48 0.43 0.37\n#> SI 0.66 0.60 0.51 1.00 0.41 0.68 0.49 0.56 0.50 0.50 0.41\n#> DS 0.47 0.39 0.51 0.41 1.00 0.45 0.45 0.42 0.39 0.42 0.31\n#> VO 0.81 0.72 0.58 0.68 0.45 1.00 0.49 0.57 0.46 0.52 0.40\n#> SY 0.47 0.40 0.41 0.49 0.45 0.49 1.00 0.50 0.50 0.52 0.46\n#> PC 0.60 0.54 0.46 0.56 0.42 0.57 0.50 1.00 0.61 0.59 0.51\n#> BD 0.49 0.45 0.48 0.50 0.39 0.46 0.50 0.61 1.00 0.54 0.59\n#> PA 0.51 0.49 0.43 0.50 0.42 0.52 0.52 0.59 0.54 1.00 0.46\n#> OA 0.41 0.38 0.37 0.41 0.31 0.40 0.46 0.51 0.59 0.46 1.00\n```\n:::\n\n\n\n\n\n##  Metodi basati sugli autovalori\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcola gli autovalori della matrice di correlazione WAIS\nwais_eigen <- eigen(wais_cor)\neigenvalues <- wais_eigen$values\nprint(eigenvalues)\n#>  [1] 6.0745 1.0150 0.7462 0.5868 0.5083 0.4312 0.4233 0.3766 0.3510 0.3101\n#> [11] 0.1770\n```\n:::\n\n\n\n\n\n### Kaiser-Guttman Rule\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkaiser_rule <- sum(eigenvalues > 1)\ncat(\"Numero di fattori secondo la regola di Kaiser:\", kaiser_rule, \"\\n\")\n#> Numero di fattori secondo la regola di Kaiser: 2\n```\n:::\n\n\n\n\n\n**Spiegazione**: la regola di Kaiser suggerisce di mantenere i fattori con autovalori maggiori di 1.  \n*Problema*: √® noto che **sovrastima** il numero di fattori, specialmente in campioni piccoli o quando le comunalit√† sono basse.\n\n### Scree Plot (Cattell)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Scree plot\nplot(eigenvalues, type = \"b\", pch = 19, main = \"Scree plot (Cattell)\", \n     xlab = \"Numero di fattori\", ylab = \"Autovalore\")\nabline(h = 1, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n**Spiegazione**: Il numero ottimale di fattori corrisponde al punto **prima del \"gomito\"** nella curva degli autovalori decrescenti.  \n*Problema*: il metodo √® **visivo e soggettivo**, quindi ha bassa affidabilit√†.\n\n### Regola del valore medio degli autovalori\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean_val <- mean(eigenvalues)\nmean_rule <- sum(eigenvalues > mean_val)\ncat(\"Numero di fattori secondo la regola del valore medio:\", mean_rule, \"\\n\")\n#> Numero di fattori secondo la regola del valore medio: 2\n```\n:::\n\n\n\n\n\n**Spiegazione**: mantiene solo i fattori con autovalori superiori alla media.  \nQuesta √® una **variante della regola di Kaiser**, meno estrema, ma comunque euristica.\n\n### Metodi avanzati con il pacchetto `nFactors`\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Metodo EKC (Empirical Kaiser Criterion)\nekc_result <- efa.ekc(sample.cov = wais_cor, sample.nobs = 300)  # Specificare N = numerosit√† stimata\nekc_result\n#> \n#>  Empirical Kaiser Criterion suggests 4 factors.\n#>  Traditional Kaiser Criterion suggests 2 factors.\n#> \n#>    Sample   Ref\n#> 1   6.074 1.420\n#> 2   1.015 0.699\n#> 3   0.746 0.617\n#> 4   0.587 0.562\n#> 5   0.508 0.523\n#> 6   0.431 0.490\n#> 7   0.423 0.465\n#> 8   0.377 0.431\n#> 9   0.351 0.397\n#> 10  0.310 0.346\n#> 11  0.177 0.251\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n**Spiegazione**: EKC √® una versione empiricamente corretta della regola di Kaiser, che **tiene conto del campione**, della **forma della distribuzione**, e della **varianza spiegata cumulativa**.  \n√à pi√π affidabile, soprattutto in strutture semplici.\n\n### STOC e STAF (versioni automatizzate dello Scree Test)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcola autovalori simulati\nnfac <- nFactors::nScree(x = eigenvalues)\nsummary(nfac)\n#> Report For a nScree Class \n#> \n#> Details: components \n#> \n#>    Eigenvalues Prop Cumu Par.Analysis Pred.eig     OC Acc.factor     AF\n#> 1            6    1    1            1        1                NA (< AF)\n#> 2            1    0    1            1        1 (< OC)          5       \n#> 3            1    0    1            1        1                 0       \n#> 4            1    0    1            1        1                 0       \n#> 5            1    0    1            1        0                 0       \n#> 6            0    0    1            1        0                 0       \n#> 7            0    0    1            1        0                 0       \n#> 8            0    0    1            1        0                 0       \n#> 9            0    0    1            1        0                 0       \n#> 10           0    0    1            1       NA                 0       \n#> 11           0    0    1            1       NA                NA       \n#> \n#> \n#>  Number of factors retained by index \n#> \n#>   noc naf nparallel nkaiser\n#> 1   2   1         2       2\n\n# Plot per confronto\nplotnScree(nfac)\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n**Spiegazione**:\n\n- **STOC** = Optimal Coordinate\n- **STAF** = Acceleration Factor  \nSono versioni **statistiche** dello scree test, che usano variazioni nella pendenza degli autovalori.\n\n\n## Metodi basati sulla simulazione\n\n### Parallel Analysis (PA)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Variante standard: confronto con media degli autovalori simulati\nset.seed(123)  # Per replicabilit√†\nfa.parallel(wais_cor, n.obs = 300, fa = \"fa\", fm = \"ml\", \n            main = \"Parallel Analysis (media simulata)\")\n#> Parallel analysis suggests that the number of factors =  2  and the number of components =  NA\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n\n### Spiegazione\n\n- Confronta gli **autovalori osservati** con quelli ottenuti da **dati casuali**.\n- Se l‚Äôautovalore osservato > simulato ‚Üí **mantieni** il fattore.\n- Il metodo √® **molto affidabile**, specie se il numero di soggetti (`n.obs`) √® corretto.\n- La **variante di Glorfeld** (non mostrata) √® pi√π **conservativa** (riduce il rischio di sovrafattorizzare).\n\n\n### Comparison Data (CD)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Metodo Comparison Data\n# Richiede che i dati siano in formato \"raw\" (non solo matrice di correlazione)\n# Quindi, simuliamo dati coerenti con la matrice di correlazione per scopi didattici:\n\nset.seed(123)\nN <- 300  # ipotetica numerosit√† campionaria\nwais_sim <- mvrnorm(N, mu = rep(0, 11), Sigma = wais_cor)\ncolnames(wais_sim) <- colnames(wais_cor)\n\n# Applica il metodo Comparison Data\ncd_result <- EFAtools::CD(\n  x = wais_sim,\n  n_factors_max = 6,        # Numero massimo di fattori da testare\n  N_pop = 10000,             # Dimensione della popolazione simulata\n  N_samples = 500,           # Numero di campioni bootstrap\n  alpha = 0.3,               # Soglia per il test di Mann-Whitney\n  use = \"pairwise.complete.obs\",  # Gestione dei dati mancanti\n  cor_method = \"pearson\",    # Metodo di correlazione\n  max_iter = 50              # Iterazioni massime\n)\n\n# Mostra il riepilogo dei risultati\ncd_result\n#> The number of factors suggested by CD is .\n```\n:::\n\n\n\n\n\n### Spiegazione\n\n- Il metodo **Comparison Data (CD)** simula set di dati \"riprodotti\" con un certo numero di fattori.\n- Confronta il **RMSE** delle soluzioni successive con un **test di Mann-Whitney**.\n- Il numero ottimale di fattori √® quello **oltre il quale non si osserva un miglioramento significativo**.\n- *Attenzione*: pu√≤ **sovrafattorizzare** se `max_factors` √® troppo alto o se i dati sono rumorosi.\n- Molto utile con **fattori correlati** e **strutture complesse**.\n\n**In sintesi**:\n\n- **PA (Parallel Analysis)** √® il metodo di riferimento, raccomandato dalla maggior parte delle linee guida (es. Fabrigar et al., 1999).\n- **CD (Comparison Data)** √® utile in presenza di **fattori obliqui** o **bassa comunalit√†**, ma pu√≤ richiedere **parametri aggiustati** per una stima pi√π accurata.\n-  Evita di usare **un solo criterio**: combina i risultati con quelli basati sugli **autovalori** e sulle **analisi di bont√† di adattamento** (RMSEA, BIC, ecc.).\n\n## Indici di informazione\n\nConsideriamo ora un'implementazione in R per determinare il numero di fattori da estrarre dalla matrice di correlazione WAIS utilizzando metodi basati sugli indici di informazione.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(wais_cor)  # Dovrebbe essere 11x11\n#> [1] 11 11\n```\n:::\n\n\n\n\n\n1. **Criteri Informativi AIC e BIC**:\n\n   - Calcolo di AIC e BIC per modelli con 1-5 fattori.\n   - Visualizzazione grafica per identificare il punto di minimo.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo il numero di fattori usando AIC e BIC\nfa_fit <- function(nfactors, x, n.obs = 100) {\n  fit <- fa(x, nfactors = nfactors, fm = \"ml\", n.obs = n.obs)\n  chi <- fit$STATISTIC\n  df <- fit$dof\n  pval <- fit$PVAL\n  aic <- chi - 2 * df\n  bic <- chi - df * log(n.obs)\n  list(nfactors = nfactors, chi = chi, df = df, pval = pval, aic = aic, bic = bic)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Assumiamo una dimensione campionaria di 100 \nn.obs <- 100\n\n# Calcoliamo AIC e BIC per diversi numeri di fattori\nresults <- data.frame()\nfor (i in 1:5) {\n  res <- fa_fit(i, wais_cor, n.obs)\n  results <- rbind(results, data.frame(\n    nfactors = i,\n    chi_square = res$chi,\n    df = res$df,\n    p_value = res$pval,\n    aic = res$aic,\n    bic = res$bic\n  ))\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizziamo i risultati\nprint(results)\n#>   nfactors chi_square df  p_value    aic     bic\n#> 1        1     69.589 44 0.008288 -18.41 -133.04\n#> 2        2     15.998 34 0.996287 -52.00 -140.58\n#> 3        3      8.244 25 0.999341 -41.76 -106.89\n#> 4        4      3.515 17 0.999787 -30.48  -74.77\n#> 5        5      1.229 10 0.999561 -18.77  -44.82\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Grafici per AIC e BIC\npar(mfrow = c(1, 2))\nplot(results$nfactors, results$aic, type = \"b\", main = \"AIC per numero di fattori\", \n     xlab = \"Numero di fattori\", ylab = \"AIC\", xaxt = \"n\")\naxis(1, at = 1:5)\nabline(v = which.min(results$aic), col = \"red\", lty = 2)\n\nplot(results$nfactors, results$bic, type = \"b\", main = \"BIC per numero di fattori\", \n     xlab = \"Numero di fattori\", ylab = \"BIC\", xaxt = \"n\")\naxis(1, at = 1:5)\nabline(v = which.min(results$bic), col = \"red\", lty = 2)\npar(mfrow = c(1, 1))\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n2. **Indici di Fit da CFA**:\n\n   - Implementazione di CFI, TLI, RMSEA e SRMR.\n   - Grafici per valutare quando questi indici raggiungono valori accettabili.\n   - Criteri di riferimento: CFI > 0.95, RMSEA < 0.05.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definiamo i modelli CFA per diversi numeri di fattori\nfit_indices <- data.frame()\n\nfor (i in 1:5) {\n  # Estraiamo prima i fattori con analisi fattoriale esplorativa\n  fa_result <- fa(wais_cor, nfactors = i, fm = \"ml\", rotate = \"varimax\")\n  \n  # Creiamo il modello CFA basato sui loadings pi√π alti\n  model_syntax <- \"\"\n  for (j in 1:i) {\n    # Seleziona le variabili con i loadings pi√π alti per ciascun fattore\n    vars <- names(sort(abs(fa_result$loadings[, j]), decreasing = TRUE)[1:ceiling(11/i)])\n    model_syntax <- paste0(model_syntax, \"F\", j, \" =~ \", paste(vars, collapse = \" + \"), \"\\n\")\n  }\n  \n  # Eseguiamo la CFA\n  try({\n    fit <- cfa(model_syntax, sample.cov = wais_cor, sample.nobs = n.obs)\n    indices <- fitMeasures(fit, c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\", \"aic\", \"bic\"))\n    \n    fit_indices <- rbind(fit_indices, data.frame(\n      nfactors = i, \n      chisq = indices[\"chisq\"], \n      df = indices[\"df\"], \n      pvalue = indices[\"pvalue\"],\n      cfi = indices[\"cfi\"], \n      tli = indices[\"tli\"], \n      rmsea = indices[\"rmsea\"], \n      srmr = indices[\"srmr\"],\n      aic = indices[\"aic\"], \n      bic = indices[\"bic\"]\n    ))\n  }, silent = TRUE)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizziamo gli indici di fit\nprint(fit_indices)\n#>        nfactors  chisq df   pvalue    cfi    tli  rmsea    srmr  aic  bic\n#> chisq         1 74.162 44 0.002985 0.9476 0.9345 0.0828 0.05991 2598 2655\n#> chisq1        2 15.429 32 0.994044 1.0000 1.0430 0.0000 0.02935 2302 2362\n#> chisq2        3 16.482 30 0.978282 1.0000 1.0383 0.0000 0.03198 2319 2384\n#> chisq3        4 13.998 27 0.981271 1.0000 1.0429 0.0000 0.02705 2348 2420\n#> chisq4        5  5.737 20 0.999209 1.0000 1.0635 0.0000 0.01502 2353 2444\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizziamo graficamente gli indici di fit\nif (nrow(fit_indices) > 0) {\n  par(mfrow = c(2, 2))\n  plot(fit_indices$nfactors, fit_indices$cfi, type = \"b\", main = \"CFI per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"CFI\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  abline(h = 0.95, col = \"red\", lty = 2)\n  \n  plot(fit_indices$nfactors, fit_indices$rmsea, type = \"b\", main = \"RMSEA per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"RMSEA\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  abline(h = 0.05, col = \"red\", lty = 2)\n  \n  plot(fit_indices$nfactors, fit_indices$aic, type = \"b\", main = \"AIC (CFA) per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"AIC\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  \n  plot(fit_indices$nfactors, fit_indices$bic, type = \"b\", main = \"BIC (CFA) per numero di fattori\", \n       xlab = \"Numero di fattori\", ylab = \"BIC\", xaxt = \"n\")\n  axis(1, at = 1:5)\n  par(mfrow = c(1, 1))\n}\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n3. **Test del Chi-Quadrato**:\n\n   - Confronto incrementale tra modelli con diverso numero di fattori.\n   - Test della significativit√† della differenza di fit.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcoliamo la differenza di chi-quadrato tra modelli consecutivi\nif (nrow(results) > 1) {\n  chi_diff <- data.frame(\n    comparison = character(),\n    chi_diff = numeric(),\n    df_diff = numeric(),\n    p_value = numeric()\n  )\n  \n  for (i in 2:nrow(results)) {\n    chi_diff_val <- results$chi_square[i-1] - results$chi_square[i]\n    df_diff_val <- results$df[i-1] - results$df[i]\n    p_val <- 1 - pchisq(chi_diff_val, df_diff_val)\n    \n    chi_diff <- rbind(chi_diff, data.frame(\n      comparison = paste(i-1, \"vs\", i),\n      chi_diff = chi_diff_val,\n      df_diff = df_diff_val,\n      p_value = p_val\n    ))\n  }\n  \n  print(\"Test del chi-quadrato per confronto di modelli:\")\n  print(chi_diff)\n}\n#> [1] \"Test del chi-quadrato per confronto di modelli:\"\n#>   comparison chi_diff df_diff   p_value\n#> 1     1 vs 2   53.591      10 5.782e-08\n#> 2     2 vs 3    7.754       9 5.591e-01\n#> 3     3 vs 4    4.729       8 7.861e-01\n#> 4     4 vs 5    2.286       7 9.423e-01\n```\n:::\n\n\n\n\n\n4. **Sintesi dei Risultati**:\n\n   - Riepilogo delle indicazioni dai vari indici.\n   - Raccomandazione sul numero ottimale di fattori.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncat(\"\\nSintesi dei risultati:\\n\")\n#> \n#> Sintesi dei risultati:\ncat(\"Numero di fattori suggerito da AIC:\", which.min(results$aic), \"\\n\")\n#> Numero di fattori suggerito da AIC: 2\ncat(\"Numero di fattori suggerito da BIC:\", which.min(results$bic), \"\\n\")\n#> Numero di fattori suggerito da BIC: 2\n\nif (nrow(fit_indices) > 0) {\n  # Per CFI vogliamo valori > 0.95\n  good_cfi <- which(fit_indices$cfi > 0.95)\n  if (length(good_cfi) > 0) {\n    cat(\"Numero minimo di fattori con CFI > 0.95:\", min(good_cfi), \"\\n\")\n  }\n  \n  # Per RMSEA vogliamo valori < 0.05\n  good_rmsea <- which(fit_indices$rmsea < 0.05)\n  if (length(good_rmsea) > 0) {\n    cat(\"Numero minimo di fattori con RMSEA < 0.05:\", min(good_rmsea), \"\\n\")\n  }\n}\n#> Numero minimo di fattori con CFI > 0.95: 2 \n#> Numero minimo di fattori con RMSEA < 0.05: 2\n\nif (nrow(chi_diff) > 0) {\n  # Per il test chi-quadrato, cerchiamo il primo confronto non significativo\n  non_sig <- which(chi_diff$p_value > 0.05)\n  if (length(non_sig) > 0) {\n    cat(\"Basato sul test del chi-quadrato, il numero ottimale di fattori √®:\", as.numeric(substr(chi_diff$comparison[min(non_sig)], 1, 1)), \"\\n\")\n  }\n}\n#> Basato sul test del chi-quadrato, il numero ottimale di fattori √®: 2\n```\n:::\n\n\n\n\n\n## Metodo Hull\n\nIl metodo √® implementato nel pacchetto [`EFAtools`](https://cran.r-project.org/web/packages/EFAtools/index.html) in R (Steiner & Gruber, 2020).\n\nNel grafico risultante, si osserva la curva dei valori di CFI in funzione dei gradi di libert√†. Il metodo Hull seleziona il punto \"di gomito\", dove il modello ha ancora un buon fit ma con la massima parsimonia. In alcuni casi, il metodo pu√≤ suggerire ad esempio che **una soluzione a un fattore √® preferibile**, se l‚Äôaggiunta di ulteriori fattori non migliora significativamente l‚Äôadattamento.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nHull(\n  wais_sim,\n  fa = \"fa\",\n  nfact = 6,\n  cor.type = \"pearson\",\n  use = \"pairwise.complete.obs\",\n  vis = TRUE,\n  plot = TRUE\n)\n#> The number of factors suggested by Hull is 1 .\n#> The number of factors suggested by Hull is 1 .\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n## Metodo MAP \n\nIl **MAP test** valuta, per ogni possibile numero di componenti estratti, quanto rimane di correlazione \"spuria\" nei residui. Il numero ottimale √® quello che **minimizza la media delle correlazioni parziali residue**, cio√® quello che riesce a \"pulire\" meglio la matrice di correlazione iniziale.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Applica il metodo MAP con la funzione vss()\nvss_map <- vss(\n  x = wais_cor,\n  n = 6,          # numero massimo di fattori/componenti da testare\n  n.obs = 100,     # numero di osservazioni\n  rotate = \"none\", # nessuna rotazione per mantenere interpretabilit√†\n  plot = FALSE     # non mostrare il grafico automaticamente\n)\nvss_map\n#> \n#> Very Simple Structure\n#> Call: vss(x = wais_cor, n = 6, rotate = \"none\", n.obs = 100, plot = FALSE)\n#> VSS complexity 1 achieves a maximimum of 0.92  with  2  factors\n#> VSS complexity 2 achieves a maximimum of 0.95  with  5  factors\n#> \n#> The Velicer MAP achieves a minimum of 0.03  with  2  factors \n#> BIC achieves a minimum of  -140.3  with  2  factors\n#> Sample Size adjusted BIC achieves a minimum of  -32.93  with  2  factors\n#> \n#> Statistics by number of factors \n#>   vss1 vss2   map dof chisq   prob sqresid  fit RMSEA  BIC SABIC complex\n#> 1 0.92 0.00 0.033  44 72.00 0.0049     3.2 0.92 0.079 -131   8.3     1.0\n#> 2 0.92 0.94 0.029  34 16.27 0.9956     2.3 0.94 0.000 -140 -32.9     1.2\n#> 3 0.83 0.95 0.044  25  8.40 0.9992     1.7 0.96 0.000 -107 -27.8     1.4\n#> 4 0.92 0.95 0.071  17  3.94 0.9995     1.7 0.96 0.000  -74 -20.7     1.4\n#> 5 0.92 0.95 0.107  10  1.46 0.9990     1.5 0.96 0.000  -45 -13.0     1.5\n#> 6 0.92 0.95 0.150   4  0.31 0.9894     1.4 0.96 0.000  -18  -5.5     1.6\n#>   eChisq   SRMR eCRMS eBIC\n#> 1 41.515 0.0614 0.069 -161\n#> 2  8.201 0.0273 0.035 -148\n#> 3  2.926 0.0163 0.024 -112\n#> 4  1.115 0.0101 0.018  -77\n#> 5  0.326 0.0054 0.013  -46\n#> 6  0.082 0.0027 0.010  -18\n```\n:::\n\n\n\n\n\n\n### Sintesi dei principali risultati\n\n| Metodo                           | Numero ottimale di fattori | Valore ottimale |\n|----------------------------------|-----------------------------|------------------|\n| **MAP (Velicer)**                | **2**                       | 0.03 (minimo)    |\n| **BIC**                          | **2**                       | -140.3 (minimo)  |\n| **BIC corretto per n (SABIC)**   | **2**                       | -32.93 (minimo)  |\n| **VSS complessit√† 1**            | 2                           | 0.92 (massimo)   |\n| **VSS complessit√† 2**            | 5                           | 0.95 (massimo)   |\n\n\n### Velicer MAP\n\n- Valuta la **media delle correlazioni parziali residue**.\n- L‚Äôobiettivo √® minimizzare la varianza residua non spiegata dai fattori.\n- **Risultato**: minimo a **2 fattori**, con valore 0.03 ‚Üí suggerisce **2 fattori**.\n\n### BIC e SABIC\n\n- Criteri informativi che bilanciano bont√† del fit e parsimonia.\n- Pi√π basso √® il valore, meglio √®.\n- Entrambi i criteri (sia BIC classico che SABIC) raggiungono il **minimo a 2 fattori**.\n\n### SS (Very Simple Structure)\n\n- Misura quanto bene una struttura semplice (con pochi caricamenti per variabile) si adatta ai dati.\n- Due versioni:\n  - **Complessit√† 1**: solo il caricamento maggiore per ogni variabile.\n  - **Complessit√† 2**: primi due caricamenti per variabile.\n- Complessit√† 1 ‚Üí massimo a **2 fattori** (0.92)\n- Complessit√† 2 ‚Üí massimo a **5 fattori** (0.95)\n\nüîé *Nota*: VSS complessit√† 2 √® pi√π permissiva e tende a favorire strutture pi√π complesse.\n\n**Interpretazione complessiva.**\n\nTutti i criteri **basati su residui o penalizzazione della complessit√†** (MAP, BIC, SABIC, VSS-1) **concordano nel suggerire una soluzione a 2 fattori**.\n\nSolo VSS-2 (pi√π permissivo) suggerisce **5 fattori**, ma questa soluzione √® meno parsimoniosa e pi√π soggetta a sovrafattorizzazione.\n\nIn sintesi, sulla base di criteri oggettivi e parsimoniosi come **MAP**, **BIC**, **SABIC**, e **VSS a complessit√† 1**, una soluzione a **2 fattori** sembra ottimale per questi dati WAIS. L‚Äôadozione di criteri informativi e basati sui residui, come MAP e BIC, √® fortemente raccomandata rispetto a metodi pi√π soggettivi o sovraestimanti come Kaiser o Scree test.\n\n\n## Exploratory Graph Analysis (EGA)\n\nL‚Äô**Exploratory Graph Analysis (EGA)** √® un metodo innovativo per identificare la struttura latente dei dati basato su modelli a rete, piuttosto che sui tradizionali modelli fattoriali. √à implementato nel pacchetto [`EGAnet`](https://cran.r-project.org/package=EGAnet), sviluppato da Golino e colleghi. Il metodo √® stato introdotto da **Golino & Epskamp (2017)** e perfezionato in studi successivi (Christensen, Golino & Silvia, 2020; Golino et al., 2020).\n\n### Caratteristiche principali di EGA:\n\n- Utilizza il **graphical lasso** per stimare le correlazioni parziali tra variabili, costruendo cos√¨ una rete sparsa (solo le relazioni pi√π forti restano).\n- Identifica **comunit√† di variabili** all‚Äôinterno della rete, che corrispondono a **fattori latenti**.\n- √à particolarmente utile quando:\n  - le **comunalit√† sono basse**,\n  - la **struttura fattoriale non √® ben definita**,\n  - si lavora con **dati ordinali o non normali**.\n\nApplichiamo l‚ÄôEGA alla matrice di correlazione delle **11 sottoscale della WAIS**.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Applica l'EGA alla matrice di correlazione WAIS\nega_result <- EGA(\n  data = wais_cor,        # Matrice di correlazione tra le 11 sottoscale\n  n = 300,                # Numero di soggetti nel campione\n  model = \"glasso\",       # Metodo di stima: graphical lasso\n  type = \"correlation\",   # Specifica che stiamo passando una matrice di correlazione\n  plot.EGA = TRUE         # Visualizza il grafo delle comunit√† (dimensioni)\n)\n```\n\n::: {.cell-output-display}\n![](03_numero_fattori_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n- **`model = \"glasso\"`**: applica una penalizzazione (lasso) per ridurre il numero di connessioni deboli tra variabili.\n- **`plot.EGA = TRUE`**: mostra un grafo con le sottoscale collegate in base alla loro correlazione condizionale.\n- **`ega_result$wc`**: contiene l‚Äôassegnazione di ciascuna variabile a una **comunit√†**, interpretata come un **fattore latente**.\n\n**Interpretazione dei risultati**:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Riepilogo generale\nsummary(ega_result)\n#> Model: GLASSO (EBIC with gamma = 0.5)\n#> Correlations: auto\n#> Lambda: 0.081 (n = 100, ratio = 0.1)\n#> \n#> Number of nodes: 11\n#> Number of edges: 48\n#> Edge density: 0.873\n#> \n#> Non-zero edge weights: \n#>      M    SD   Min   Max\n#>  0.099 0.088 0.003 0.421\n#> \n#> ----\n#> \n#> Algorithm:  Louvain\n#> \n#> Number of communities:  1\n#> \n#> IN CO AR SI DS VO SY PC BD PA OA \n#>  1  1  1  1  1  1  1  1  1  1  1 \n#> \n#> ----\n#> \n#> Unidimensional Method: Louvain\n#> Unidimensional: Yes\n#> \n#> ----\n#> \n#> TEFI: 0\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Numero di dimensioni individuate (cio√® di comunit√†)\nlength(unique(ega_result$wc))\n#> [1] 1\n```\n:::\n\n\n\n\n\n**Vantaggi:**\n\n- **non richiede ipotesi forti sulla distribuzione dei dati**;\n- **pi√π robusto** dei metodi classici (EFA, PA) in presenza di **comunalit√† basse**;\n- offre una **visualizzazione intuitiva** delle relazioni tra variabili.\n\n> üí° *EGA pu√≤ essere utilizzato sia per esplorare la dimensionalit√† di un set di item sia per decidere quanti fattori mantenere prima di una conferma con CFA.*\n\n\n## Riflessioni Conclusive\n\nDeterminare il numero di fattori da estrarre in un'Analisi Fattoriale Esplorativa (EFA) rappresenta una delle sfide metodologiche pi√π complesse nella costruzione di strumenti psicometrici. Nessun metodo √® infallibile o universalmente valido: ogni tecnica presenta vantaggi, limiti e assunzioni specifiche. Per questo motivo, la **triangolazione** di pi√π metodi e la riflessione teorica guidano le scelte pi√π solide.\n\n### 1. La scelta del numero di fattori: tra tecniche classiche e moderne\n\nLe tecniche tradizionali, come la regola di Kaiser e lo scree test, sono state largamente impiegate per la loro semplicit√†, ma risultano oggi superate per via della loro tendenza sistematica alla **sovra- o sotto-fattorizzazione**. In particolare:\n\n- La **Parallel Analysis (PA)** si conferma il metodo pi√π raccomandato, grazie alla sua capacit√† di distinguere fattori reali da quelli generati dal rumore;\n- Il metodo **Comparison Data (CD)** si dimostra utile con strutture complesse o fattori correlati, ma va calibrato attentamente;\n- I criteri **informativi** (AIC, BIC) e gli **indici di adattamento del modello** (RMSEA, CFI) aggiungono elementi preziosi per valutare la bont√† della soluzione, specialmente quando integrati con la CFA;\n- Metodi recenti come **MAP**, **Hull**, **EGA** o **Factor Forest** offrono soluzioni promettenti, soprattutto in contesti con comunalit√† basse, dati non normali o ordinali.\n\n### 2. Replicabilit√†: validare ci√≤ che si scopre\n\nIdentificare una struttura fattoriale coerente √® solo il primo passo. Per attribuire **validit√† e generalizzabilit√†** a una soluzione esplorativa, occorre valutarne la **replicabilit√†**:\n\n- **Replicazione in campioni indipendenti** e **validazione incrociata** servono a testare la stabilit√† della struttura in sottogruppi differenti;\n- La **CFA** permette di verificare, in modo formale, se una struttura fattoriale individuata in EFA √® confermata da nuovi dati;\n- Tecniche di **ricampionamento** (come il bootstrap) offrono ulteriori strumenti per stimare l‚Äôincertezza legata alla soluzione ottenuta.\n\nUna struttura replicabile √® pi√π probabilmente una rappresentazione fedele dei costrutti latenti piuttosto che un artefatto del campione specifico.\n\n### 3. Cosa fare con i fattori: applicazioni e criticit√†\n\nDopo aver identificato i fattori, √® cruciale decidere **come utilizzarli**:\n\n- Nei **Modelli di Equazioni Strutturali (SEM)**, i fattori possono essere usati come predittori, mediatori, moderatori o esiti, con il vantaggio di modellare esplicitamente l‚Äôerrore di misura;\n- Al di fuori dei SEM, l‚Äôuso di **punteggi fattoriali** (calcolati come media, somma o compositi ponderati) va considerato con cautela, poich√© pu√≤ trascurare errori di misura o differenze di importanza tra variabili;\n- In certi casi, **compositi a pesi unitari** possono essere preferibili a quelli ponderati, specialmente per garantire maggiore generalizzabilit√† e robustezza cross-campione.\n\nLa scelta operativa su come rappresentare e usare i fattori dovrebbe sempre essere coerente con le finalit√† della ricerca e con le caratteristiche dei dati.\n\n### 4. Una visione integrata\n\nIn definitiva, la **determinazione del numero di fattori**, la **replicabilit√†** della soluzione e il **modo in cui i fattori vengono utilizzati** sono aspetti interdipendenti di un processo rigoroso e cumulativo. Una buona pratica psicometrica non si limita a identificare la struttura che ‚Äúfunziona meglio‚Äù nel proprio campione, ma valuta la stabilit√† della soluzione, il suo significato teorico e la sua applicazione pratica.\n\n> ‚úèÔ∏è *La validit√† di uno strumento psicologico non si esaurisce nella bont√† del suo adattamento al campione corrente, ma nella sua capacit√† di riflettere stabilmente e in modo interpretabile i costrutti che intende misurare.*\n\n\n## Session Info\n\n\n\n\n\n::: {.cell layout-align=\"center\" vscode='{\"languageId\":\"r\"}'}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.4\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] REFA_0.1.0         latentFactoR_0.0.6 EGAnet_2.2.0      \n#>  [4] EFAfactors_1.2.1   EFAtools_0.4.6     nFactors_2.4.1.1  \n#>  [7] lattice_0.22-7     fspe_0.1.2         paran_1.5.3       \n#> [10] ggokabeito_0.1.0   see_0.11.0         MASS_7.3-65       \n#> [13] viridis_0.6.5      viridisLite_0.4.2  ggpubr_0.6.0      \n#> [16] ggExtra_0.10.1     gridExtra_2.3      patchwork_1.3.0   \n#> [19] bayesplot_1.11.1   semTools_0.5-7     semPlot_1.1.6     \n#> [22] lavaan_0.6-19      psych_2.5.3        scales_1.3.0      \n#> [25] markdown_2.0       knitr_1.50         lubridate_1.9.4   \n#> [28] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n#> [31] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1       \n#> [34] tibble_3.2.1       ggplot2_3.5.2      tidyverse_2.0.0   \n#> [37] here_1.0.1        \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] splines_4.4.2          later_1.4.2            XML_3.99-0.18         \n#>   [4] rpart_4.1.24           lifecycle_1.0.4        Rdpack_2.6.4          \n#>   [7] rstatix_0.7.2          rprojroot_2.0.4        rockchalk_1.8.157     \n#>  [10] backports_1.5.0        magrittr_2.0.3         openxlsx_4.2.8        \n#>  [13] Hmisc_5.2-3            rmarkdown_2.29         yaml_2.3.10           \n#>  [16] httpuv_1.6.15          qgraph_1.9.8           zip_2.3.2             \n#>  [19] reticulate_1.42.0      RColorBrewer_1.1-3     pbapply_1.7-2         \n#>  [22] minqa_1.2.8            multcomp_1.4-28        abind_1.4-8           \n#>  [25] quadprog_1.5-8         nnet_7.3-20            TH.data_1.1-3         \n#>  [28] sandwich_3.1-1         arm_1.14-4             codetools_0.2-20      \n#>  [31] tidyselect_1.2.1       farver_2.1.2           lme4_1.1-37           \n#>  [34] stats4_4.4.2           base64enc_0.1-3        ddpcr_1.15.2          \n#>  [37] jsonlite_2.0.0         Formula_1.2-5          survival_3.8-3        \n#>  [40] emmeans_1.11.0         tools_4.4.2            sna_2.8               \n#>  [43] Rcpp_1.0.14            glue_1.8.0             mnormt_2.1.1          \n#>  [46] xfun_0.52              ranger_0.17.0          withr_3.0.2           \n#>  [49] fastmap_1.2.0          GGally_2.2.1           boot_1.3-31           \n#>  [52] digest_0.6.37          mi_1.1                 timechange_0.3.0      \n#>  [55] R6_2.6.1               mime_0.13              estimability_1.5.1    \n#>  [58] colorspace_2.1-1       gtools_3.9.5           jpeg_0.1-11           \n#>  [61] generics_0.1.3         data.table_1.17.0      corpcor_1.6.10        \n#>  [64] htmlwidgets_1.6.4      ggstats_0.9.0          pkgconfig_2.0.3       \n#>  [67] sem_3.1-16             gtable_0.3.6           SimCorMultRes_1.9.0   \n#>  [70] htmltools_0.5.8.1      carData_3.0-5          parallelMap_1.5.1     \n#>  [73] png_0.1-8              reformulas_0.4.0       rstudioapi_0.17.1     \n#>  [76] tzdb_0.5.0             reshape2_1.4.4         statnet.common_4.11.0 \n#>  [79] coda_0.19-4.1          checkmate_2.3.2        nlme_3.1-168          \n#>  [82] nloptr_2.2.1           proxy_0.4-27           zoo_1.8-13            \n#>  [85] parallel_4.4.2         miniUI_0.1.1.1         foreign_0.8-90        \n#>  [88] pillar_1.10.2          grid_4.4.2             vctrs_0.6.5           \n#>  [91] mlr_2.19.2             promises_1.3.2         car_3.1-3             \n#>  [94] OpenMx_2.21.13         xtable_1.8-4           cluster_2.1.8.1       \n#>  [97] GPArotation_2024.3-1   htmlTable_2.4.3        evaluate_1.0.3        \n#> [100] BBmisc_1.13            pbivnorm_0.6.0         mvtnorm_1.3-3         \n#> [103] cli_3.6.4              kutils_1.73            compiler_4.4.2        \n#> [106] rlang_1.1.5            ggsignif_0.6.4         fdrtool_1.2.18        \n#> [109] RcppArmadillo_14.4.1-1 plyr_1.8.9             stringi_1.8.7         \n#> [112] network_1.19.0         munsell_0.5.1          lisrelToR_0.3         \n#> [115] pacman_0.5.1           Matrix_1.7-3           ParamHelpers_1.14.2   \n#> [118] hms_1.1.3              glasso_1.11            shiny_1.10.0          \n#> [121] evd_2.3-7.1            rbibutils_2.3          ineq_0.2-13           \n#> [124] igraph_2.1.4           broom_1.0.8            RcppParallel_5.1.10   \n#> [127] fastmatch_1.1-6        xgboost_1.7.9.1\n```\n:::\n",
    "supporting": [
      "03_numero_fattori_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
[
  {
    "objectID": "chapters/measurement/01_scores_scales.html",
    "href": "chapters/measurement/01_scores_scales.html",
    "title": "1  Punteggi e scale",
    "section": "",
    "text": "1.1 Punteggi Grezzi e Trasformati\nNell’ambito dei test psicometrici, il punteggio grezzo costituisce la valutazione più immediata e si basa sulla somma delle risposte categorizzate, come quelle corrette o errate, o vero o falso. Nonostante la sua immediatezza, il punteggio grezzo presenta limitazioni interpretative, poiché non considera fattori contestuali quali il numero totale di domande o il livello di difficoltà di queste.\nPer mitigare queste limitazioni, i punteggi grezzi vengono spesso convertiti in formati che permettono un’interpretazione più contestualizzata, quali i punteggi standardizzati o scalati. Queste trasformazioni facilitano l’interpretazione dei risultati ottenuti.\nL’interpretazione dei risultati dei test necessita di un riferimento comparativo. A seconda del contesto, può essere utile confrontare le prestazioni con una norma di riferimento o con criteri specifici.\nLe interpretazioni basate sulla norma confrontano la performance di un individuo con quella di un gruppo di riferimento o normativo, offrendo una valutazione relativa alla prestazione tipica o “normale”. Un esempio è rappresentato dai test di intelligenza. Al contrario, le interpretazioni basate sul criterio valutano le prestazioni rispetto a un livello di competenza specifico, indipendentemente dalla performance altrui.\nUn altro approccio interpretativo è offerto dalla Teoria della Risposta agli Item (IRT), che fornisce un’analisi avanzata delle prestazioni nei test, permettendo un’esplorazione dettagliata delle risposte individuali.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#interpretazioni-basate-sulla-norma-norm-referenced",
    "href": "chapters/measurement/01_scores_scales.html#interpretazioni-basate-sulla-norma-norm-referenced",
    "title": "1  Punteggi e scale",
    "section": "1.2 Interpretazioni Basate sulla Norma (Norm-Referenced)",
    "text": "1.2 Interpretazioni Basate sulla Norma (Norm-Referenced)\nPer valutare la performance in un test psicologico, può essere utile confrontarla con quella di un gruppo predefinito. I punteggi grezzi acquisiscono significato quando messi a confronto con le prestazioni di un gruppo normativo. In questo contesto, i punteggi grezzi vengono trasformati in punteggi derivati basati sulle performance di un gruppo normativo specifico.\nUn aspetto cruciale in queste interpretazioni è la pertinenza del gruppo di riferimento. È fondamentale che questo gruppo sia rappresentativo degli individui ai quali il test è destinato o con cui il partecipante viene confrontato.\nLa selezione del campione normativo, chiamato anche campione di standardizzazione, segue il principio del campionamento casuale stratificato proporzionale, assicurando che il campione rifletta proporzionalmente le caratteristiche demografiche nazionali. Tale rappresentatività è vitale per l’interpretazione basata sulla norma, rendendo necessaria l’accurata selezione e descrizione del campione da parte degli sviluppatori del test.\nQuando si utilizzano questi test, è cruciale valutare se il campione di standardizzazione è rappresentativo per l’uso previsto e se le caratteristiche demografiche del campione corrispondono a quelle dei soggetti testati. La pertinenza e l’attualità del campione, insieme alla sua dimensione, sono fattori chiave per garantire interpretazioni valide e affidabili.\nUna considerazione finale riguardante le interpretazioni basate sulla norma è l’importanza della standardizzazione nella somministrazione. È fondamentale che il campione di riferimento venga sottoposto al test nelle stesse condizioni e secondo le stesse procedure amministrative che saranno utilizzate nella pratica effettiva. Di conseguenza, quando il test viene somministrato in contesti clinici, è cruciale che l’utente del test segua attentamente le procedure amministrative prescritte. Ad esempio, nel caso di test standardizzati, è essenziale leggere le istruzioni testuali esattamente come sono fornite e rispettare rigorosamente i limiti di tempo. Sarebbe irragionevole confrontare la performance dell’esaminando in un test a tempo con quella di un campione di standardizzazione che ha avuto più o meno tempo per completare gli item. Questa necessità di seguire procedure standardizzate si applica a tutti i test standardizzati, sia quelli con interpretazioni basate sulla norma che quelli basati sul criterio.\n\n1.2.1 Punteggi Derivati\nIn ambito psicometrico, i punteggi derivati da test possono assumere diverse forme, ciascuna con implicazioni specifiche per l’interpretazione dei dati. Esploreremo le tipologie più comuni:\n\nPunteggi Standardizzati:\n\nQuesti punteggi trasformano i punteggi grezzi (ad esempio, il numero di risposte corrette) in misure standardizzate. Ciò permette di ottenere valori invarianti rispetto a variabili come l’età dell’individuo.\nSi calcolano stabilendo una media e una deviazione standard specifiche a priori.\nEsempi:\n\nz-scores: Misurano la distanza di un punteggio dalla media, espressa in deviazioni standard. Hanno una media di 0 e una deviazione standard di 1.\nT-scores: Trasformano i punteggi in valori positivi, con una media di 50 e una deviazione standard di 10.\nPunteggi di QI: Tipici delle scale di intelligenza, hanno una media di 100 e una deviazione standard di 15.\n\n\nPunteggi Standardizzati Normalizzati:\n\nQuando i punteggi originali non seguono una distribuzione normale, si utilizzano trasformazioni non lineari per normalizzarli.\nEsempi:\n\nStanine: Suddividono i punteggi in 9 categorie (da 1 a 9).\nPunteggi scalati di Wechsler: Utilizzati nei test di intelligenza di Wechsler.\nEquivalenti della Curva Normale (NCE): Esprimono la posizione di un punteggio rispetto alla distribuzione normale.\n\n\nRanghi Percentili:\n\nVanno da 1 a 99 e indicano la posizione relativa di un soggetto rispetto alla popolazione.\nAd esempio, un punteggio al 75° percentile significa che il soggetto ha ottenuto un risultato migliore del 75% della popolazione.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#interpretazioni-basate-su-criteri",
    "href": "chapters/measurement/01_scores_scales.html#interpretazioni-basate-su-criteri",
    "title": "1  Punteggi e scale",
    "section": "1.3 Interpretazioni Basate su Criteri",
    "text": "1.3 Interpretazioni Basate su Criteri\nL’approccio delle valutazioni basate su criteri specifici è diventato sempre più rilevante nel mondo dell’educazione e della psicometria a partire dagli anni Sessanta. Questo approccio, noto anche come valutazione basata su contenuti, dominio o obiettivi, si concentra sulla misurazione delle competenze individuali rispetto a standard definiti, piuttosto che sul confronto con le prestazioni di un gruppo di riferimento.\nEcco alcune metodologie e applicazioni comuni:\n\nPercentuale di Risposte Corrette:\n\nQuesto metodo fornisce un’indicazione diretta delle competenze di uno studente.\nAd esempio, se uno studente risponde correttamente all’85% delle domande di matematica, l’insegnante può valutare le sue abilità in modo specifico.\n\nTest di Padronanza:\n\nQuesti test determinano se uno studente ha acquisito una competenza specifica.\nAd esempio, gli esami per la patente di guida valutano se lo studente ha raggiunto il livello di padronanza richiesto.\n\nValutazioni Basate su Standard:\n\nQueste valutazioni classificano i risultati in categorie di prestazione (ad esempio, base, competente, avanzato).\nSpesso, i punteggi vengono correlati a voti letterali basati su una percentuale di correttezza.\n\n\nI punti di forza delle valutazioni basate su criteri includono:\n\nComparazione con Standard Predefiniti:\n\nValutano il raggiungimento di competenze o obiettivi specifici, indipendentemente dalle prestazioni altrui.\nQuesto approccio evita il bias derivante dal confronto con altri studenti.\n\nFocalizzazione su Competenze Specifiche:\n\nQuesti test richiedono una definizione precisa dell’area di conoscenza o abilità valutata.\nSono ideali per valutare aree di contenuto specifiche.\n\n\n\n1.3.0.1 Benefici\n\nValutazione Mirata delle Competenze: Fornisce una verifica concreta del conseguimento delle conoscenze e abilità delineate dal programma di studi.\nPersonalizzazione dell’Insegnamento: Identifica le aree di debolezza, consentendo un approccio didattico più focalizzato e personalizzato.\n\nIn conclusione, le valutazioni basate su criteri rappresentano un’alternativa preziosa ai metodi di valutazione tradizionali, specialmente in contesti in cui è fondamentale misurare le competenze individuali. Questo approccio è in crescente adozione in ambiti educativi e formativi, enfatizzando l’importanza dell’acquisizione di conoscenze e abilità mirate.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#analisi-comparativa-tra-valutazioni-normative-e-basate-su-criteri",
    "href": "chapters/measurement/01_scores_scales.html#analisi-comparativa-tra-valutazioni-normative-e-basate-su-criteri",
    "title": "1  Punteggi e scale",
    "section": "1.4 Analisi Comparativa tra Valutazioni Normative e Basate su Criteri",
    "text": "1.4 Analisi Comparativa tra Valutazioni Normative e Basate su Criteri\nLa distinzione tra valutazioni normative (norm-referenced) e basate su criteri (criterion-referenced) è fondamentale per interpretare le prestazioni individuali nei test. Sebbene un test possa teoricamente adottare entrambi gli approcci interpretativi, di solito si orienta verso uno dei due, a seconda dell’obiettivo specifico.\nEcco una panoramica delle differenze:\n\nValutazioni Normative:\n\nVersatilità: Si applicano a test che valutano una vasta gamma di dimensioni, come attitudini, risultati scolastici, interessi, atteggiamenti e comportamenti.\nAmpio Quadro: Ideali per esplorare costrutti generali come l’attitudine generale o l’intelligenza.\nSelezione delle Domande: Preferiscono domande di difficoltà intermedia, evitando quelle troppo semplici o complesse.\n\nValutazioni Basate su Criteri:\n\nSpecificità: Associate principalmente a test che mirano a valutare conoscenze o competenze specifiche.\nFocalizzazione: Concentrate su abilità e competenze ben definite.\nCalibrazione delle Domande: La difficoltà delle domande è tarata in base alle conoscenze o abilità specifiche da valutare.\n\n\nÈ importante notare che queste interpretazioni non sono mutuamente esclusive. Alcuni test offrono sia valutazioni normative che basate su criteri, fornendo una visione completa delle prestazioni relative rispetto a un gruppo di riferimento e del livello di competenza in un ambito specifico. Questa dualità interpretativa è preziosa in vari contesti.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#analisi-dei-punteggi-secondo-la-teoria-della-risposta-agli-item",
    "href": "chapters/measurement/01_scores_scales.html#analisi-dei-punteggi-secondo-la-teoria-della-risposta-agli-item",
    "title": "1  Punteggi e scale",
    "section": "1.5 Analisi dei Punteggi secondo la Teoria della Risposta agli Item",
    "text": "1.5 Analisi dei Punteggi secondo la Teoria della Risposta agli Item\nLa Teoria della Risposta agli Item (IRT) rappresenta un notevole avanzamento nel campo della psicometria, fornendo strumenti essenziali per valutare con precisione le capacità e i tratti latenti degli individui.\nFondamenti e Principi dell’IRT: L’IRT si basa sull’assunto che ogni persona possieda un livello di un tratto latente, come l’intelligenza, che è indipendente dalle specifiche domande del test o dal metodo di valutazione utilizzato. Attraverso l’applicazione di modelli matematici complessi, l’IRT consente di posizionare ogni individuo su un continuum di tratto latente, offrendo una misurazione delle capacità più precisa rispetto ai tradizionali punteggi grezzi.\nVantaggi dei Punteggi basati sull’IRT: I punteggi derivati dall’IRT presentano significativi vantaggi. Essi sono trattati come punteggi a intervalli costanti, consentendo comparazioni valide tra le performance di soggetti o gruppi diversi. Inoltre, questi punteggi mantengono una deviazione standard uniforme attraverso diverse fasce d’età, rendendoli particolarmente adatti per monitorare l’evoluzione o il progresso delle abilità nel tempo.\nApplicazioni Pratiche e Prospettive Future dell’IRT: Una delle applicazioni più innovative dell’IRT è lo sviluppo dei test adattivi computerizzati (CAT), in cui le domande vengono selezionate dinamicamente in base alle risposte precedenti del candidato. Questo metodo consente valutazioni precise ed efficienti delle abilità in tempo reale. Ad esempio, i punteggi IRT, come i W-scores nel Woodcock-Johnson IV, vengono utilizzati per analizzare variazioni nelle capacità cognitive legate ai processi di apprendimento o ai declini cognitivi.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#quali-tipi-di-punteggi-usare",
    "href": "chapters/measurement/01_scores_scales.html#quali-tipi-di-punteggi-usare",
    "title": "1  Punteggi e scale",
    "section": "1.6 Quali tipi di punteggi usare?",
    "text": "1.6 Quali tipi di punteggi usare?",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#la-selezione-del-punteggio-appropriato-per-la-valutazione",
    "href": "chapters/measurement/01_scores_scales.html#la-selezione-del-punteggio-appropriato-per-la-valutazione",
    "title": "1  Punteggi e scale",
    "section": "1.7 La Selezione del Punteggio Appropriato per la Valutazione",
    "text": "1.7 La Selezione del Punteggio Appropriato per la Valutazione\nDeterminare il tipo di punteggio più adeguato per un test è essenziale per ottenere informazioni specifiche e pertinenti dalla valutazione. Le diverse categorie di punteggi forniscono risposte a domande distinte riguardo alle prestazioni degli esaminandi:\n\nPunteggi Grezzi:\n\nRappresentano la quantità totale di risposte corrette accumulate da un individuo.\nOffrono una visione immediata del livello di prestazione e permettono di stabilire un ordine tra i partecipanti.\nSono utili per identificare rapidamente il posizionamento relativo di un individuo all’interno di un gruppo.\n\nPunteggi Norm-Referenced Standard:\n\nForniscono un confronto diretto tra le prestazioni di un individuo e quelle di un gruppo normativo.\nConsentono di interpretare la prestazione su una scala relativa, facilitando la comprensione del rendimento in termini di posizione all’interno di una popolazione di riferimento.\n\nPunteggi Criterion-Referenced:\n\nIndicano se un individuo ha raggiunto un determinato standard di competenza.\nSono particolarmente indicati per valutare il conseguimento di obiettivi specifici o competenze chiave.\n\nPunteggi Basati sull’IRT (Inclusi i Punteggi Rasch):\n\nOffrono una misurazione su scala a intervalli costanti, riflettendo la posizione di un individuo su un continuum di un tratto latente.\nSono ideali per tracciare il progresso nel tempo o confrontare le prestazioni attraverso diverse valutazioni di un medesimo tratto.\n\n\nAd esempio, nel caso di Giovanni, che ha beneficiato di un programma di supporto alla lettura: - Punteggi Norm-Referenced: Fornirebbero insight su come le capacità di lettura di Giovanni si confrontano con quelle dei suoi coetanei dopo l’intervento. - Punteggi Rasch o IRT: Consentirebbero di valutare l’evoluzione precisa delle competenze di lettura di Giovanni, misurando il progresso a partire dal suo livello iniziale. - Punteggi Grezzi: Darebbero indicazioni sul miglioramento assoluto, sebbene privi della capacità di riflettere le variazioni in termini di difficoltà degli item o di altri fattori. - Punteggi Criterion-Referenced: Stabilirebbero se Giovanni ha raggiunto specifici obiettivi di competenza in lettura definiti a priori.\nIn contesti educativi, l’uso di punteggi norm-referenced standardizzati per età può essere preferibile per determinare se uno studente sta progredendo adeguatamente rispetto ai suoi pari. In contesti clinici, come nella gestione della depressione, i punteggi criterion-referenced possono offrire una valutazione mirata del raggiungimento di soglie di miglioramento clinico significativo.\nIn conclusione, la scelta del tipo di punteggio da utilizzare è guidata dal contesto di valutazione e dall’obiettivo specifico della misurazione. Diverse tipologie di punteggi illuminano aspetti distinti delle prestazioni, rendendoli più o meno adatti a seconda delle esigenze informative della valutazione.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#significato-e-applicazione-delle-norme-e-dei-punteggi-standardizzati",
    "href": "chapters/measurement/01_scores_scales.html#significato-e-applicazione-delle-norme-e-dei-punteggi-standardizzati",
    "title": "1  Punteggi e scale",
    "section": "1.8 Significato e Applicazione delle Norme e dei Punteggi Standardizzati",
    "text": "1.8 Significato e Applicazione delle Norme e dei Punteggi Standardizzati\nPer chiarire questi concetti, esaminiamo i dati della Tabella 2.1 di {cite:t}bandalos2018measurement. Con degli esempi numerici, analizzeremo vari tipi di punteggi normativi, tra cui:\n\nPunteggi Percentili: Che indicano la posizione relativa di un individuo all’interno del gruppo normativo.\nPunteggi Standardizzati e Normalizzati: Che trasformano i punteggi grezzi in una scala standard per facilitare il confronto tra diversi individui o gruppi.\nStanini: Un metodo di punteggio che divide i punteggi in intervalli standardizzati.\nEquivalenti alla Curva Normale: Che adattano i punteggi a una distribuzione normale.\n\nNei capitoli successivi esamineremo come calcolare i punteggi basati sulla teoria IRT.\nIniziamo a leggere i dati.\n\nraw_score &lt;- c(\n    26, 25, 33, 31, 26, 34, 29, 36, 25, 29, 28, 32, 25,\n    30, 27, 31, 30, 30, 35, 30, 27, 26, 34, 32, 26, 34,\n    30, 28, 28, 31, 30, 27, 26, 29, 29, 33, 27, 35, 26,\n    27, 28, 29, 28, 27, 34, 36, 26, 26, 34, 30, 34, 27\n)\n\n\n1.8.1 Distribuzione di frequenze\n\nfreq &lt;- table(raw_score) # frequency\ncumfreq &lt;- cumsum(freq) # cumulative frequency\nperc &lt;- prop.table(freq) * 100 # percentage\ncumperc &lt;- cumsum(perc) # cumulative percentage\npr &lt;- (cumperc - 0.5 * perc) # percentile rank\ncbind(freq, cumfreq, perc, cumperc, pr)\n\n\nA matrix: 12 x 5 of type dbl\n\n\n\nfreq\ncumfreq\nperc\ncumperc\npr\n\n\n\n\n25\n3\n3\n5.769231\n5.769231\n2.884615\n\n\n26\n8\n11\n15.384615\n21.153846\n13.461538\n\n\n27\n7\n18\n13.461538\n34.615385\n27.884615\n\n\n28\n5\n23\n9.615385\n44.230769\n39.423077\n\n\n29\n5\n28\n9.615385\n53.846154\n49.038462\n\n\n30\n7\n35\n13.461538\n67.307692\n60.576923\n\n\n31\n3\n38\n5.769231\n73.076923\n70.192308\n\n\n32\n2\n40\n3.846154\n76.923077\n75.000000\n\n\n33\n2\n42\n3.846154\n80.769231\n78.846154\n\n\n34\n6\n48\n11.538462\n92.307692\n86.538462\n\n\n35\n2\n50\n3.846154\n96.153846\n94.230769\n\n\n36\n2\n52\n3.846154\n100.000000\n98.076923\n\n\n\n\n\n\n\n1.8.2 Punteggi Percentili\nI punteggi percentili sono un modo efficace per interpretare e confrontare i punteggi di un individuo con quelli di un campione normativo. Un punteggio percentile indica la posizione relativa di un individuo all’interno di un gruppo normativo. Più specificamente, un punteggio percentile mostra la percentuale di persone nel campione normativo che ha ottenuto un punteggio uguale o inferiore a quello dell’individuo in questione.\nPer esemplificare il concetto, consideriamo il calcolo di un quantile di ordine 0.74. Questo significa che stiamo cercando il valore al di sotto del quale si trova il 74% dei punteggi nel campione normativo. In altre parole, un individuo con un punteggio corrispondente a questo quantile ha superato il 74% delle persone nel gruppo normativo.\nIl calcolo dei punteggi percentili può essere effettuato attraverso l’analisi statistica dei dati di un campione rappresentativo. Questi dati vengono ordinati in modo crescente, e si identifica il punteggio che corrisponde al percentile desiderato. Nel caso del quantile 0.74, si cerca il punteggio che si trova alla posizione che corrisponde al 74% della lunghezza totale dell’elenco ordinato dei punteggi.\n\n# P74\nquantile(raw_score, .74)\n\n74%: 31.74\n\n\n\n# Use a different type (see https://en.wikipedia.org/wiki/Quantile#Estimating_quantiles_from_a_sample)\nquantile(raw_score, .74, type = 6)\n\n74%: 32\n\n\nI punteggi percentili sono particolarmente utili perché offrono una comprensione intuitiva della posizione di un individuo rispetto agli altri. Tuttavia, è importante notare che essi rappresentano una scala ordinale e, pertanto, le differenze tra i punteggi percentili non sono necessariamente uniformi o proporzionali attraverso l’intera gamma di punteggi.\nIn conclusione, i punteggi percentili sono uno strumento fondamentale nella valutazione psicologica e educativa, poiché forniscono un modo diretto e facilmente interpretabile per valutare le prestazioni di un individuo in confronto a un campione normativo.\n\n\n1.8.3 Punteggi Standardizzati\nI punteggi standardizzati rappresentano una trasformazione essenziale nel campo della psicometria, che consente di convertire i punteggi grezzi ottenuti in un test in una scala unificata. Questa trasformazione permette di confrontare i risultati di individui o gruppi in maniera equa e coerente, superando le variazioni di scala o di difficoltà tra diversi test.\n\n1.8.3.1 Principi Fondamentali dei Punteggi Standardizzati\n\nMedia e Deviazione Standard Predefinite: I punteggi standardizzati sono calcolati in modo tale da avere una media e una deviazione standard specifiche, stabilite in anticipo. Per esempio, spesso si utilizza una media di 100 e una deviazione standard di 15 (come nei test di intelligenza) o una media di 0 e una deviazione standard di 1 (come negli z-score).\nRisultati Confrontabili: Attraverso questa standardizzazione, i punteggi diventano direttamente confrontabili. Un punteggio standardizzato rispetto a una media di 100 e una deviazione standard di 15, ad esempio, permette di valutare rapidamente se un punteggio è al di sopra, al di sotto o vicino alla media del campione normativo.\n\n\n\n1.8.3.2 Come Funziona la Trasformazione\nIl processo di standardizzazione implica la sottrazione della media del campione normativo dal punteggio grezzo di un individuo, seguita dalla divisione del risultato per la deviazione standard del campione normativo. In termini matematici, se $ X $ è un punteggio grezzo, $ $ è la media del campione normativo e $ $ è la deviazione standard del campione normativo, allora il punteggio standardizzato $ Z $ è calcolato come:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}.\n\\]\n\n\n1.8.3.3 Utilità dei Punteggi Standardizzati\n\nComparabilità: Rendono i punteggi ottenuti da test diversi o da campioni diversi direttamente comparabili.\nInterpretazione Facilitata: Forniscono un modo semplice per interpretare i punteggi individuali in termini di posizione relativa rispetto alla media del campione normativo.\nAdattabilità: Sono utili in una varietà di contesti, da test educativi a valutazioni cliniche.\n\nIn conclusione, i punteggi standardizzati sono uno strumento cruciale nella psicometria e nella valutazione educativa. Trasformando i punteggi grezzi in una scala comune con media e deviazione standard specifiche, facilitano il confronto e l’interpretazione dei risultati dei test, rendendo più accessibile l’analisi e la valutazione delle prestazioni individuali e di gruppo.\nNel caso dell’esempio, i calcoli si svolgono in R nel modo seguente:\n\nz_score &lt;- (raw_score - mean(raw_score)) / sd(raw_score)\nc(mean = mean(z_score), sd = sd(z_score))\n\nmean-5.61516645146954e-16sd1\n\n\n\n\n1.8.3.4 Punteggi T\nI punteggi T sono una forma specifica di punteggi standardizzati, utilizzati frequentemente nella psicometria per rendere più accessibili e interpretabili i risultati dei test. A differenza dei punteggi z, che tipicamente hanno una media di 0 e una deviazione standard di 1, i punteggi T sono trasformati in modo da avere una media fissata a 50 e una deviazione standard di 10.\n\n\n1.8.3.5 Caratteristiche Principali dei Punteggi T\n\nMedia e Deviazione Standard: La media fissata a 50 e la deviazione standard di 10 sono scelte per offrire una scala più intuitiva e di facile lettura rispetto agli z-score. Questa trasformazione sposta la scala degli z-score in una gamma numericamente più familiare e più semplice da interpretare per la maggior parte delle persone.\nCalcolo dei Punteggi T: Il calcolo dei punteggi T avviene trasformando prima i punteggi grezzi in z-score e poi convertendo questi z-score nella scala dei punteggi T. Matematicamente, se $ Z $ è lo z-score, il punteggio T corrispondente $ T $ è calcolato come:\n\\[\nT = 50 + 10 \\times Z.\n\\]\nQuesta formula adatta lo z-score in una scala che inizia da 50 e si allarga in entrambe le direzioni con incrementi standard di 10 per ogni deviazione standard.\n\n\n\n1.8.3.6 Utilizzo dei Punteggi T\n\nFacilità di Interpretazione: I punteggi T sono particolarmente utili quando si desidera presentare i risultati dei test in un formato che sia immediatamente comprensibile, senza la necessità di ulteriori calcoli o trasformazioni.\nComparabilità: Consentono di confrontare i risultati di test diversi in modo più diretto, grazie alla loro scala standardizzata.\nAmpio Utilizzo: Sono ampiamente usati in vari ambiti della valutazione psicologica, inclusi l’educazione, la ricerca e la pratica clinica.\n\nIn sintesi, i punteggi T offrono un modo efficace e standardizzato per interpretare i risultati dei test, rendendo i dati più accessibili e immediatamente comprensibili. La loro trasformazione da z-score a una scala con media 50 e deviazione standard 10 facilita la comprensione e la comparazione dei punteggi tra diversi test e diversi individui.\nSvolgendo i calcoli in R otteniamo\n\nT_score &lt;- z_score * 10 + 50\nc(mean = mean(T_score), sd = sd(T_score))\n\nmean50sd10\n\n\n\n\n\n1.8.4 Punteggi Stanini\nI punteggi Stanini rappresentano un metodo standardizzato per categorizzare i risultati dei test in psicometria, utilizzando una scala di nove intervalli. Ogni intervallo è definito da un cut-off di 10 punti, rendendo questo sistema particolarmente intuitivo e facile da interpretare. La scala Stanini è progettata per fornire una visione chiara e semplificata della posizione relativa di un individuo all’interno di un gruppo normativo.\n\n1.8.4.1 Caratteristiche dei Punteggi Stanini\n\nIntervalli di Scala: La scala Stanini è divisa in nove intervalli, con ogni intervallo corrispondente a un punteggio specifico. Ad esempio, un punteggio Stanini di 1 indica i punteggi più bassi, mentre un punteggio di 9 rappresenta i punteggi più alti.\nFacilità di Interpretazione: I punteggi Stanini offrono un modo semplice e diretto per comprendere i risultati dei test, permettendo una rapida valutazione del livello relativo di prestazione di un individuo rispetto alla popolazione di riferimento.\n\n\n\n1.8.4.2 Calcolo dei Punteggi Stanini\nPer calcolare i punteggi Stanini, è necessario seguire alcuni passaggi:\n\nDeterminare Media e Deviazione Standard: Inizialmente, si calcolano la media e la deviazione standard dei dati del campione normativo.\nApplicare la Formula dei Punteggi Stanini: Per ogni punteggio grezzo, si applica la seguente formula per calcolare il punteggio Stanini corrispondente:\n\\[\n\\text{Stanine} = \\left( \\frac{\\text{Punteggio Grezzo} - \\text{Media}}{\\text{Deviazione Standard}} \\right) \\times 2 + 5.\n\\]\nQuesta formula trasforma il punteggio grezzo in un valore sulla scala Stanini.\nArrotondare al Numero Intero Più Vicino: Infine, si arrotonda il risultato al numero intero più vicino per ottenere il punteggio Stanini finale.\n\n\n\n1.8.4.3 Applicazioni dei Punteggi Stanini\n\nSemplificazione dell’Analisi: I punteggi Stanini sono particolarmente utili in contesti educativi e di ricerca, dove è necessario semplificare l’analisi e la comunicazione dei risultati.\nValutazione Rapida: Forniscono agli insegnanti, ai clinici e ai ricercatori uno strumento rapido per valutare il posizionamento di un individuo rispetto ai coetanei o alla popolazione di riferimento.\n\nIn sintesi, i punteggi Stanini offrono un metodo efficace e semplificato per interpretare i risultati dei test psicometrici. La loro struttura a intervalli permette una categorizzazione chiara dei punteggi, rendendo più agevole la comprensione e la comparazione delle prestazioni relative degli individui.\nPer l’esempio presente abbiamo:\n\nmean_score &lt;- mean(raw_score)\nsd_score &lt;- sd(raw_score)\n\nstanine_scores &lt;- round((raw_score - mean_score) / sd_score * 2 + 5)\nprint(stanine_scores)\n\n [1] 3 2 7 6 3 8 5 9 2 5 4 7 2 5 3 6 5 5 8 5 3 3 8 7 3 8 5 4 4 6 5 3 3 5 5 7 3 8\n[39] 3 3 4 5 4 3 8 9 3 3 8 5 8 3\n\n\nÈ importante ricordare che la trasformazione in punti z non cambia la forma della distribuzione.\n\nplot(density(raw_score))\n\n\n\n\n\n\n\n\n\nplot(density(z_score))\n\n\n\n\n\n\n\n\n\nplot(density(T_score))\n\n\n\n\n\n\n\n\n\nplot(density(stanine_scores))\n\n\n\n\n\n\n\n\n\n\n\n1.8.5 Equivalenti alla Curva Normale (NCE)\nGli Equivalenti alla Curva Normale, noti come NCE (dall’inglese “Normal Curve Equivalents”), sono un tipo di punteggio standardizzato utilizzato in ambito psicometrico. Questi punteggi vengono calcolati per trasformare i punteggi grezzi ottenuti in un test in una scala che rifletta una distribuzione approssimativamente normale. L’obiettivo principale dei punteggi NCE è quello di rendere i punteggi di diverse misure o test direttamente confrontabili, mantenendo una distribuzione che si allinea strettamente con una curva normale standard.\n\n1.8.5.1 Caratteristiche dei Punteggi NCE\n\nDistribuzione Normalizzata: I punteggi NCE sono progettati per aderire a una distribuzione normale. Ciò significa che, a differenza di altri tipi di punteggi, i NCE si allineano più da vicino con le caratteristiche di una curva di distribuzione gaussiana, con la maggior parte dei punteggi concentrati intorno alla media e una distribuzione simmetrica verso gli estremi.\nFacilità di Comparazione: Grazie alla loro standardizzazione, i punteggi NCE consentono un confronto diretto e significativo tra le prestazioni in diversi test o misure. Questo è particolarmente utile in contesti educativi e clinici dove è necessario interpretare e confrontare i risultati di diversi test.\n\n\n\n1.8.5.2 Calcolo e Utilizzo dei Punteggi NCE\nIl calcolo dei punteggi NCE si basa sulla trasformazione dei punteggi grezzi in modo che si adattino a una distribuzione normalizzata. Questo processo implica l’uso di formule matematiche che riallineano i dati grezzi su una scala standard, considerando la media e la deviazione standard del campione normativo.\nUna volta calcolati, i punteggi NCE offrono una visione chiara e immediata delle prestazioni relative di un individuo o di un gruppo, rispetto a un campione normativo. Questo tipo di punteggio è particolarmente utile quando i punteggi grezzi provengono da distribuzioni che non seguono una curva normale, consentendo così un’interpretazione più accurata e standardizzata dei risultati.\n\n\n1.8.5.3 Applicazioni Pratiche dei Punteggi NCE\nI punteggi NCE trovano impiego in una varietà di contesti, tra cui:\n\nValutazioni Educative: In ambito scolastico, per confrontare le prestazioni degli studenti in test diversi.\nRicerca Psicologica: Per analizzare e confrontare i risultati di diversi studi o misure psicometriche.\nPratica Clinica: Nella valutazione di clienti o pazienti utilizzando diversi strumenti diagnostici.\n\nIn conclusione, i punteggi Equivalenti alla Curva Normale rappresentano uno strumento psicometrico potente per standardizzare e confrontare efficacemente i risultati di diversi test o misure, assicurando che questi siano interpretati all’interno di un quadro coerente e comparabile.\nPer i dati dell’esempio abbiamo:\n\n# Using normal quantile\nqnorm_pr &lt;- qnorm(pr / 100)\n# Convert raw scores\nnormalized_zscore &lt;- as.vector(qnorm_pr[as.character(raw_score)])\n\nIn alternativa, è possibile usare la trasformazione di Box-Cox, che è una tecnica parametrica che cerca di correggere le asimmetrie e trasformare i dati in una forma che approssima una distribuzione normale. È efficace per i dati positivi. La trasformazione è definita come segue:\n\\[\ny(\\lambda) = \\begin{cases} \\frac{x^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0 \\\\ \\log(x) & \\text{se } \\lambda = 0 \\end{cases},\n\\]\ndove \\(x\\) è il valore originale e \\(\\lambda\\) è il parametro di trasformazione che viene spesso trovato attraverso la massimizzazione della verosimiglianza.\nSupponiamo di voler utilizzare la trasformazione di Box-Cox sul nostro set di dati. La procedura è la seguente. Questo codice utilizza la funzione boxcox dal pacchetto MASS per trovare il valore di \\(\\lambda\\) che massimizza la log-verosimiglianza della trasformazione di Box-Cox applicata ai dati. Poi, utilizza questo \\(\\lambda\\) per trasformare i dati.\n\n# Dati di esempio\nset.seed(123) # Per rendere l'esempio riproducibile\ndata &lt;- raw_score\n\n# Trova il miglior lambda per la trasformazione di Box-Cox\nbc &lt;- boxcox(data ~ 1, lambda = seq(-2, 2, by = 0.1))\n\n# Calcola la trasformazione di Box-Cox con il lambda ottimale\nlambda_opt &lt;- bc$x[which.max(bc$y)]\ndata_transformed &lt;- (data^lambda_opt - 1) / lambda_opt\n\n\n\n\n\n\n\n\nAvendo trovato i dati trasformati con la procedura Box-Cox, li confrontiamo con gli Equivalenti alla Curva Normale (NCE) calcolati con la procedura usuale.\n\nplot(normalized_zscore, data_transformed)\n\n\n\n\n\n\n\n\n\nplot(density(normalized_zscore)) # the shape will be closer to normal\n\n\n\n\n\n\n\n\n\nplot(density((data_transformed - mean(data_transformed)) / sd(data_transformed)))\n\n\n\n\n\n\n\n\nSi osservi che i dati NCE presentano una distribuzione più simile a una curva a forma campanulare rispetto ai dati grezzi.\n\nlillie.test(normalized_zscore)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  normalized_zscore\nD = 0.085801, p-value = 0.4426\n\n\n\nlillie.test(data_transformed)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  data_transformed\nD = 0.12456, p-value = 0.04274",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#riflessioni-finali-sui-metodi-di-trasformazione-dei-punteggi",
    "href": "chapters/measurement/01_scores_scales.html#riflessioni-finali-sui-metodi-di-trasformazione-dei-punteggi",
    "title": "1  Punteggi e scale",
    "section": "1.9 Riflessioni Finali sui Metodi di Trasformazione dei Punteggi",
    "text": "1.9 Riflessioni Finali sui Metodi di Trasformazione dei Punteggi\nLa trasformazione dei punteggi grezzi in formati più interpretabili è una pratica cruciale in psicometria. Due sono i principali approcci utilizzati per attribuire significato ai punteggi di un test: il riferimento normativo e il riferimento criteriale.\n\n1.9.1 Riferimento Normativo\nNel riferimento normativo, si confronta il punteggio di un individuo con quello medio del gruppo normativo, ovvero gli altri soggetti che hanno svolto lo stesso test. Ci sono diversi tipi di punteggi normati, ciascuno con i suoi specifici vantaggi e limitazioni:\n\nPunteggi Percentili: Questi punteggi sono intuitivi e offrono un’indicazione immediata della posizione relativa di un individuo all’interno di un gruppo. Tuttavia, sono una scala ordinale e non si prestano bene a calcoli matematici più complessi.\nPunteggi Standardizzati: Gli z-score e i T-scores rientrano in questa categoria. Sono scalari a intervallo, quindi adatti a operazioni matematiche. Mantengono la forma distributiva originale dei punteggi grezzi, rendendo più agevole la loro elaborazione statistica.\n\n\n\n1.9.2 Riferimento Criteriale\nAl contrario del riferimento normativo, il riferimento criteriale confronta i punteggi di un individuo con uno standard prestabilito o un criterio specifico, piuttosto che con i punteggi di altri individui.\n\n\n1.9.3 Trasformazioni per la Normalizzazione\nPer ottenere una distribuzione dei punteggi più vicina alla curva normale, si possono utilizzare trasformazioni come gli stanini o gli NCE (Normal Curve Equivalents). Questi metodi di normalizzazione aiutano a standardizzare la distribuzione dei punteggi, facilitando così l’interpretazione e l’analisi dei dati psicometrici.\nIn conclusione, la scelta del metodo di trasformazione dei punteggi dipende dagli obiettivi specifici della valutazione e dall’interpretazione desiderata. La comprensione di queste diverse tecniche è essenziale per una corretta interpretazione dei risultati dei test e per l’analisi psicometrica più generale.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#considerazioni-conclusive",
    "href": "chapters/measurement/01_scores_scales.html#considerazioni-conclusive",
    "title": "1  Punteggi e scale",
    "section": "1.10 Considerazioni Conclusive",
    "text": "1.10 Considerazioni Conclusive\nQuesto capitolo fornisce una panoramica sui diversi tipi di punteggi dei test e il loro significato. Iniziamo notando che i punteggi grezzi, sebbene facili da calcolare, di solito forniscono poche informazioni utili sul rendimento di un esaminando in un test. Di conseguenza, di solito trasformiamo i punteggi grezzi in punteggi derivati, che possono essere di riferimento normativo o al criterio. I punteggi di riferimento normativo confrontano il rendimento di un esaminando con quello di altre persone nel campione di standardizzazione, mentre quelli al criterio confrontano il rendimento con un livello di competenza specificato. È importante valutare l’adeguatezza del campione di standardizzazione quando si utilizzano punteggi di riferimento normativo.\nPer interpretazioni basate sui punteggi di riferimento normativo, è utile conoscere la distribuzione normale e i punteggi standard di riferimento. Questi ultimi hanno una media predefinita e una deviazione standard. Esistono anche punteggi normalizzati quando i punteggi non seguono una distribuzione normale. Altri tipi di punteggi di riferimento normativo includono il rango percentile e i punteggi basati su età o livello di scolarità. Tuttavia, questi ultimi sono da evitare, se possibile, a favore di punteggi standard e ranghi percentile.\nI punteggi al criterio confrontano il rendimento con un livello specifico di competenza. Sono utili per valutare abilità in domini specifici, ma richiedono una chiara definizione del dominio. A volte, un test può produrre entrambi i tipi di punteggi. Forniamo anche una panoramica dei punteggi basati sulla teoria della risposta agli item (IRT), che sono utili per misurare i cambiamenti nel tempo.\nIn conclusione, i diversi tipi di punteggi dei test forniscono informazioni per rispondere a diverse domande e devono essere scelti in base alle esigenze specifiche dell’analisi dei dati del test.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#esercizi",
    "href": "chapters/measurement/01_scores_scales.html#esercizi",
    "title": "1  Punteggi e scale",
    "section": "1.11 Esercizi",
    "text": "1.11 Esercizi\nBandalos, capitolo 2, E1, E2, E5, E6, E7, E8, E9, E12",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/01_scores_scales.html#session-info",
    "href": "chapters/measurement/01_scores_scales.html#session-info",
    "title": "1  Punteggi e scale",
    "section": "1.12 Session Info",
    "text": "1.12 Session Info\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 15.0\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] nortest_1.0-4     MASS_7.3-61       ggokabeito_0.1.0  viridis_0.6.5    \n [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    bayesplot_1.11.1 \n [9] gridExtra_2.3     patchwork_1.3.0   semTools_0.5-6    semPlot_1.1.6    \n[13] lavaan_0.6-18     psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n[17] knitr_1.48        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n[21] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n[25] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.16.0  jsonlite_1.8.9     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5.1 farver_2.1.2      \n  [7] nloptr_2.1.1       rmarkdown_2.28     vctrs_0.6.5       \n [10] minqa_1.2.8        base64enc_0.1-3    rstatix_0.7.2     \n [13] htmltools_0.5.8.1  broom_1.0.6        Formula_1.2-5     \n [16] htmlwidgets_1.6.4  plyr_1.8.9         sandwich_3.1-1    \n [19] emmeans_1.10.4     zoo_1.8-12         uuid_1.2-1        \n [22] igraph_2.0.3       mime_0.12          lifecycle_1.0.4   \n [25] pkgconfig_2.0.3    Matrix_1.7-0       R6_2.5.1          \n [28] fastmap_1.2.0      shiny_1.9.1        digest_0.6.37     \n [31] OpenMx_2.21.12     fdrtool_1.2.18     colorspace_2.1-1  \n [34] rprojroot_2.0.4    Hmisc_5.1-3        fansi_1.0.6       \n [37] timechange_0.3.0   abind_1.4-8        compiler_4.4.1    \n [40] withr_3.0.1        glasso_1.11        htmlTable_2.4.3   \n [43] backports_1.5.0    carData_3.0-5      ggsignif_0.6.4    \n [46] corpcor_1.6.10     gtools_3.9.5       tools_4.4.1       \n [49] pbivnorm_0.6.0     foreign_0.8-87     zip_2.3.1         \n [52] httpuv_1.6.15      nnet_7.3-19        glue_1.7.0        \n [55] quadprog_1.5-8     promises_1.3.0     nlme_3.1-166      \n [58] lisrelToR_0.3      grid_4.4.1         pbdZMQ_0.3-13     \n [61] checkmate_2.3.2    cluster_2.1.6      reshape2_1.4.4    \n [64] generics_0.1.3     gtable_0.3.5       tzdb_0.4.0        \n [67] data.table_1.16.0  hms_1.1.3          car_3.1-2         \n [70] utf8_1.2.4         sem_3.1-16         pillar_1.9.0      \n [73] IRdisplay_1.1      rockchalk_1.8.157  later_1.3.2       \n [76] splines_4.4.1      lattice_0.22-6     survival_3.7-0    \n [79] kutils_1.73        tidyselect_1.2.1   miniUI_0.1.1.1    \n [82] pbapply_1.7-2      stats4_4.4.1       xfun_0.47         \n [85] qgraph_1.9.8       arm_1.14-4         stringi_1.8.4     \n [88] boot_1.3-31        evaluate_1.0.0     codetools_0.2-20  \n [91] mi_1.1             cli_3.6.3          RcppParallel_5.1.9\n [94] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [97] repr_1.1.7         munsell_0.5.1      Rcpp_1.0.13       \n[100] coda_0.19-4.1      png_0.1-8          XML_3.99-0.17     \n[103] parallel_4.4.1     jpeg_0.1-10        lme4_1.1-35.5     \n[106] mvtnorm_1.3-1      openxlsx_4.2.7.1   crayon_1.5.3      \n[109] rlang_1.1.4        multcomp_1.4-26    mnormt_2.1.1",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Punteggi e scale</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E1_likert.html",
    "href": "chapters/measurement/E1_likert.html",
    "title": "2  ✏️ Esercizi",
    "section": "",
    "text": "2.1 Scaling Likert\nIn questo tutorial esamineremo i dati di un questionario ordinale. Gli obiettivi saranno il punteggio totale e lo scaling normativo.\nIl Strengths and Difficulties Questionnaire (SDQ) è un breve questionario di screening comportamentale riguardante bambini e adolescenti di età compresa tra 3 e 16 anni. Esiste in diverse versioni consultabili su http://www.sdqinfo.org/. Dal sito è possibile scaricare il questionario, il metodo di scoring e le norme del test.\nLa versione autovalutativa (SDQ Pupil) include 25 item che misurano 5 scale (faccette), con 5 item ciascuna:\nAi partecipanti viene chiesto di valutare ciascuna domanda utilizzando le seguenti opzioni di risposta: 0 = “Non vero” 1 = “Un po’ vero” 2 = “Certamente vero”\nNOTA che alcuni item del SDQ sono reverse: item a punteggio invertito – punteggi più alti della scala corrispondono a punteggi inferiori degli item. Ad esempio, l’item “Di solito faccio quello che mi dicono” (variabile ubbidisce) è reverse dei Problemi di Condotta. Ci sono 5 item di questo tipo nel SDQ; sono contrassegnati nella tabella sopra con asterischi (*).\nI partecipanti a questo studio sono alunni di seconda media della stessa scuola (N=228). Si tratta di un campione di comunità e non ci aspettiamo che molti bambini abbiano punteggi al di sopra delle soglie cliniche. Il SDQ è stato somministrato due volte, la prima volta quando i bambini hanno appena iniziato la scuola secondaria (erano in anno 7), e un anno dopo (erano in anno 8).",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E1_likert.html#scaling-likert",
    "href": "chapters/measurement/E1_likert.html#scaling-likert",
    "title": "2  ✏️ Esercizi",
    "section": "",
    "text": "Sintomi Emotivi somatico preoccupazioni triste attaccamento paura\nProblemi di Condotta scatti ubbidisce* litiga mente ruba\nIperattività irrequietezza agitato distratto riflessivo* attento*\nProblemi con i Peer solitario amico* popolare* vittima di bullismo vecchio migliore amico\nPro-sociale prendersi cura condivide gentilezza aiuta",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E1_likert.html#emotional-symptoms-scale",
    "href": "chapters/measurement/E1_likert.html#emotional-symptoms-scale",
    "title": "2  ✏️ Esercizi",
    "section": "2.2 Emotional Symptoms scale",
    "text": "2.2 Emotional Symptoms scale\nQuesta scala non contiene item reverse.\nImportiamo i dati in R.\n\nload(\"../../data/data_sdq/SDQ.RData\")\nglimpse(SDQ)\n\nRows: 228\nColumns: 51\n$ Gender   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ consid   &lt;dbl&gt; 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2~\n$ restles  &lt;dbl&gt; 2, 0, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0~\n$ somatic  &lt;dbl&gt; 2, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, 1, 1~\n$ shares   &lt;dbl&gt; 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2~\n$ tantrum  &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 0~\n$ loner    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0~\n$ obeys    &lt;dbl&gt; 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2~\n$ worries  &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 1, 0~\n$ caring   &lt;dbl&gt; 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2~\n$ fidgety  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0~\n$ friend   &lt;dbl&gt; 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2~\n$ fights   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ unhappy  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0~\n$ popular  &lt;dbl&gt; 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2~\n$ distrac  &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0~\n$ clingy   &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 0, 2, 2, 0~\n$ kind     &lt;dbl&gt; 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2~\n$ lies     &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ bullied  &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0~\n$ helpout  &lt;dbl&gt; 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2~\n$ reflect  &lt;dbl&gt; 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2~\n$ steals   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ oldbest  &lt;dbl&gt; 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1~\n$ afraid   &lt;dbl&gt; 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, 1, 0~\n$ attends  &lt;dbl&gt; 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2~\n$ consid2  &lt;dbl&gt; 1, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 1, NA, 2, 2, NA, 1, 2, 2, ~\n$ restles2 &lt;dbl&gt; 0, 1, 2, 1, NA, 0, 1, 1, 0, 0, NA, 2, NA, 0, 1, NA, 1, 1, 2, ~\n$ somatic2 &lt;dbl&gt; 0, 1, 1, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 1, NA, 0, 1, 2, ~\n$ shares2  &lt;dbl&gt; 1, 2, 2, 1, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 1, ~\n$ tantrum2 &lt;dbl&gt; 0, 1, 2, 0, NA, 0, 2, 0, 0, 0, NA, 2, NA, 0, 1, NA, 1, 0, 2, ~\n$ loner2   &lt;dbl&gt; 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 1, 0, NA, 0, 0, 1, ~\n$ obeys2   &lt;dbl&gt; 2, 1, 2, 1, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 1, NA, 1, 2, 1, ~\n$ worries2 &lt;dbl&gt; 0, 0, 1, 0, NA, NA, 1, 0, 0, 0, NA, 1, NA, 1, 2, NA, 0, 0, 2,~\n$ caring2  &lt;dbl&gt; 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 2, ~\n$ fidgety2 &lt;dbl&gt; 0, 1, 0, 0, NA, 0, 1, 0, 0, 0, NA, 2, NA, 0, 0, NA, 1, 0, 2, ~\n$ friend2  &lt;dbl&gt; 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 1, 2, NA, 2, 2, 2, ~\n$ fights2  &lt;dbl&gt; 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0, 0, ~\n$ unhappy2 &lt;dbl&gt; 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 0, 0, NA, 0, 0, 1, ~\n$ popular2 &lt;dbl&gt; 2, 1, 1, 2, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 1, ~\n$ distrac2 &lt;dbl&gt; 0, 0, 0, 2, NA, 0, 2, 1, 0, 0, NA, 1, NA, 0, 1, NA, 1, 0, 2, ~\n$ clingy2  &lt;dbl&gt; 1, 1, 1, 0, NA, 1, 1, 1, 0, 0, NA, 1, NA, 0, 0, NA, 2, 0, 2, ~\n$ kind2    &lt;dbl&gt; 2, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 2, ~\n$ lies2    &lt;dbl&gt; 1, 0, 0, 0, NA, 0, 1, 0, 1, 0, NA, 1, NA, 0, 0, NA, 1, 0, 0, ~\n$ bullied2 &lt;dbl&gt; 0, 0, 0, 0, NA, 0, 2, 0, 0, 0, NA, 0, NA, 0, 0, NA, 0, 0, 0, ~\n$ helpout2 &lt;dbl&gt; 1, 1, 1, 2, NA, 2, 2, 1, 2, 1, NA, 2, NA, 2, 1, NA, 0, 2, 1, ~\n$ reflect2 &lt;dbl&gt; 1, 1, 2, 1, NA, 2, 1, 2, 1, 2, NA, 1, NA, 2, 1, NA, 1, 2, 1, ~\n$ steals2  &lt;dbl&gt; 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0, 0, ~\n$ oldbest2 &lt;dbl&gt; 0, 0, 1, 0, NA, 1, 0, 1, 1, 0, NA, 1, NA, 0, 0, NA, 0, 0, 1, ~\n$ afraid2  &lt;dbl&gt; 0, 1, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0, 2, ~\n$ attends2 &lt;dbl&gt; 1, 1, 2, 0, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 2, NA, 1, 1, 0, ~\n\n\nSelezioniamo solo gli item della Emotional Symptoms scale.\n\nitems_emotion &lt;- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nsdq_emo &lt;- SDQ[, items_emotion]  \nsdq_emo |&gt;\n    head()\n\n\nA tibble: 6 x 5\n\n\nsomatic\nworries\nunhappy\nclingy\nafraid\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n2\n1\n0\n1\n0\n\n\n2\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n1\n1\n\n\n2\n1\n0\n1\n0\n\n\n1\n0\n0\n1\n0\n\n\n\n\n\nCalcoliamo il punteggio della scala.\n\nrowSums(sdq_emo) |&gt; print()\n\n  [1]  4  3  1  2  4  2  4  0  1  1  0  8  2  3  7  4  5  2  8  6  1  4  9  4  5\n [26]  9  0  3  3  1  0  2  6  3  9  4  4  0  7  1  3  6  4  5  4  1  4  1  0  5\n [51]  1  2  2  4  4  4  6  1  8  3  2  2  4  1  1  0  2  2  7  5  0 NA NA  1  1\n [76]  7  4  1  8  3  5  0  5  4  0  1  1  5  3  6  1  3  2  6  6  0  2  4  5  3\n[101]  3  1  1  7  2  3  5  5 NA  0  4  0  4  1  1  1  1  0  2  7  0  3  8  4  6\n[126] NA  2  4  7  1  0  0  1  0  4  3  0 10  5  2  1  6  1  2  1  0  1 NA  4  4\n[151]  2  4  7  5  6  1  0  5  3  1  3  3  6  4  2  3  1  0  3  3  0  3  0  0  0\n[176]  2  2  2  0  1  5  3  3  1  4  3  1  6  2  4  2 NA  0  2  5  5  0  2  2  3\n[201]  4  0  2  4  2  2  1  3  2  0  1  0  0  8  1  1  2  1  2  2  4  0  0  1  2\n[226]  2  1  6\n\n\nNotiamo che ci sono diversi punteggi mancanti, denotati da NA.\nUn primo metodo per affrontare i dati mancanti è semplicemente quello di ignorarli:\n\nrowSums(sdq_emo, na.rm = TRUE) |&gt; print()\n\n  [1]  4  3  1  2  4  2  4  0  1  1  0  8  2  3  7  4  5  2  8  6  1  4  9  4  5\n [26]  9  0  3  3  1  0  2  6  3  9  4  4  0  7  1  3  6  4  5  4  1  4  1  0  5\n [51]  1  2  2  4  4  4  6  1  8  3  2  2  4  1  1  0  2  2  7  5  0  2  7  1  1\n [76]  7  4  1  8  3  5  0  5  4  0  1  1  5  3  6  1  3  2  6  6  0  2  4  5  3\n[101]  3  1  1  7  2  3  5  5  4  0  4  0  4  1  1  1  1  0  2  7  0  3  8  4  6\n[126]  0  2  4  7  1  0  0  1  0  4  3  0 10  5  2  1  6  1  2  1  0  1  4  4  4\n[151]  2  4  7  5  6  1  0  5  3  1  3  3  6  4  2  3  1  0  3  3  0  3  0  0  0\n[176]  2  2  2  0  1  5  3  3  1  4  3  1  6  2  4  2  4  0  2  5  5  0  2  2  3\n[201]  4  0  2  4  2  2  1  3  2  0  1  0  0  8  1  1  2  1  2  2  4  0  0  1  2\n[226]  2  1  6\n\n\nTuttavia, questa non è una buona idea. Anche per il fatto che, in questo modo non verrà calcolato il punteggio totale di 7 partecipanti. Possiamo identificare le colonne in cui ci sono dei valori mancanti usando summary().\n\nsummary(sdq_emo)\n\n    somatic          worries          unhappy           clingy      \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :1.0000  \n Mean   :0.6106   Mean   :0.6211   Mean   :0.3172   Mean   :0.8421  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :2.0000   Max.   :2.0000   Max.   :2.0000   Max.   :2.0000  \n NA's   :2        NA's   :1        NA's   :1                        \n     afraid    \n Min.   :0.00  \n 1st Qu.:0.00  \n Median :0.00  \n Mean   :0.48  \n 3rd Qu.:1.00  \n Max.   :2.00  \n NA's   :3     \n\n\n\nsdq_emo &lt;- sdq_emo %&gt;%\n    mutate_at(vars(somatic:afraid), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))\n\nQuesta istruzione utilizza la funzione mutate_at del pacchetto dplyr per applicare una trasformazione a colonne specifiche (da somatic a afraid). All’interno della funzione di trasformazione, essa controlla se ogni valore è mancante (NA). Se lo è, lo sostituisce con la media della colonna usando mean(., na.rm = TRUE), che calcola la media escludendo eventuali valori mancanti.\nPossiamo ora calcolare il punteggio della scala per ciascun partecipante.\n\nSDQ$s_emotion &lt;- rowSums(sdq_emo)\nSDQ$s_emotion |&gt; print()\n\n  [1]  4  3  1  2  4  2  4  0  1  1  0  8  2  3  7  4  5  2  8  6  1  4  9  4  5\n [26]  9  0  3  3  1  0  2  6  3  9  4  4  0  7  1  3  6  4  5  4  1  4  1  0  5\n [51]  1  2  2  4  4  4  6  1  8  3  2  2  4  1  1  0  2  2  7  5  0 NA NA  1  1\n [76]  7  4  1  8  3  5  0  5  4  0  1  1  5  3  6  1  3  2  6  6  0  2  4  5  3\n[101]  3  1  1  7  2  3  5  5 NA  0  4  0  4  1  1  1  1  0  2  7  0  3  8  4  6\n[126] NA  2  4  7  1  0  0  1  0  4  3  0 10  5  2  1  6  1  2  1  0  1 NA  4  4\n[151]  2  4  7  5  6  1  0  5  3  1  3  3  6  4  2  3  1  0  3  3  0  3  0  0  0\n[176]  2  2  2  0  1  5  3  3  1  4  3  1  6  2  4  2 NA  0  2  5  5  0  2  2  3\n[201]  4  0  2  4  2  2  1  3  2  0  1  0  0  8  1  1  2  1  2  2  4  0  0  1  2\n[226]  2  1  6\n\n\nUn istogramma si ottiene nel modo seguente.\n\nSDQ |&gt;\n    ggplot(aes(x = s_emotion)) +\n    geom_histogram(bins = 10)\n\nWarning message:\n\"Removed 6 rows containing non-finite outside the scale range (`stat_bin()`).\"\n\n\n\n\n\n\n\n\n\n\nhist(SDQ$s_emotion)\n\n\n\n\n\n\n\n\nPiù utile è un KDE plot.\n\nSDQ |&gt;\n    ggplot(aes(x = s_emotion)) +\n    geom_density()\n\nWarning message:\n\"Removed 6 rows containing non-finite outside the scale range\n(`stat_density()`).\"\n\n\n\n\n\n\n\n\n\nPossiamo ottenere le statistiche descrittive della scala usando la funzione describe del pacchetto psych.\n\ndescribe(SDQ$s_emotion)\n\n\nA psych: 1 x 13\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nX1\n1\n222\n2.837838\n2.301054\n2\n2.61236\n2.9652\n0\n10\n10\n0.7454236\n-0.08749808\n0.1544367\n\n\n\n\n\nCome si può vedere, la mediana (il punteggio al di sotto del quale si trova la metà del campione) di s_emotion è 2, mentre la media è più alta e pari a 2.87. Questo perché la distribuione dei punteggi è asimmetrica positiva; in questo caso, la mediana è più rappresentativa della tendenza centrale. Queste statistiche sono coerenti con la nostra osservazione dell’istogramma, che mostra un forte floor effect.\nDi seguito sono riportati i valori di soglia per i casi “Normali”, “Borderline” e “Anormali” per i Sintomi Emotivi forniti dal publisher del test (vedi https://sdqinfo.org/). Questi sono i punteggi che distinguono i casi probabilmente borderline e anormali dai casi “normali”.\nNormale: 0-5 Borderline: 6 Anormale: 7-10\n\ntable(SDQ$s_emotion &lt;= 5)\n\n\nFALSE  TRUE \n   33   195 \n\n\nIn questo campione, dunque, l’85% dei partecipanti è classificato nell’intervallo Normale.\n\ntable(SDQ$s_emotion &lt;= 5)[2] / length(SDQ$s_emotion)\n\nTRUE: 0.855263157894737\n\n\nIn maniera equivalente otteniamo\n\ntable(SDQ$s_emotion == 6)[2] / length(SDQ$s_emotion)\n\nTRUE: 0.0570175438596491\n\n\n\ntable(SDQ$s_emotion &gt;= 7)[2] / length(SDQ$s_emotion)\n\nTRUE: 0.0833333333333333",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E1_likert.html#item-reverse",
    "href": "chapters/measurement/E1_likert.html#item-reverse",
    "title": "2  ✏️ Esercizi",
    "section": "2.3 Item reverse",
    "text": "2.3 Item reverse\nLa scala Conduct Problems contiene item reverse. Esaminiamo lo scoring di questo tipo di item.\n\nitems_conduct &lt;- c(\"tantrum\", \"obeys\", \"fights\", \"lies\", \"steals\")\n\nPer i Problemi di Condotta, abbiamo solo un item reverse, obeys.\ntantrum    obeys*      fights       lies       steals\nPer invertire il codice di questo item, useremo una funzione dedicata del pacchetto psych, reverse.code(). Questa funzione ha la forma generale reverse.code(keys, items,…). L’argomento keys è un vettore di valori 1 o -1, dove -1 implica l’inversione dell’item. L’argomento items sono i nomi delle variabili che vogliamo valutare.\n\nR_conduct &lt;- reverse.code(keys = c(1, -1, 1, 1, 1), SDQ[, items_conduct]) |&gt; as.data.frame()\nR_conduct |&gt; head()\n\n\nA data.frame: 6 x 5\n\n\n\ntantrum\nobeys-\nfights\nlies\nsteals\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n0\n\n\n5\n1\n2\n0\n2\n0\n\n\n6\n0\n0\n0\n0\n0\n\n\n\n\n\n\nSDQ[, items_conduct] |&gt; head()\n\n\nA tibble: 6 x 5\n\n\ntantrum\nobeys\nfights\nlies\nsteals\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n2\n0\n0\n0\n\n\n0\n2\n0\n0\n0\n\n\n0\n2\n0\n0\n0\n\n\n0\n2\n0\n0\n0\n\n\n1\n0\n0\n2\n0\n\n\n0\n2\n0\n0\n0\n\n\n\n\n\nAnche in questo caso ci sono dei dati mancanti.\n\nsummary(R_conduct)\n\n    tantrum           obeys-           fights           lies       \n Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.000   Median :0.0000  \n Mean   :0.5708   Mean   :0.5789   Mean   :0.193   Mean   :0.5442  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.000   3rd Qu.:1.0000  \n Max.   :2.0000   Max.   :2.0000   Max.   :2.000   Max.   :2.0000  \n NA's   :2                                         NA's   :2       \n     steals     \n Min.   :0.000  \n 1st Qu.:0.000  \n Median :0.000  \n Mean   :0.185  \n 3rd Qu.:0.000  \n Max.   :2.000  \n NA's   :1      \n\n\n\nR_conduct &lt;- R_conduct %&gt;%\n    mutate_at(vars(tantrum:steals), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))\n\nCalcoliamo ora il punteggio totale.\n\nSDQ$s_conduct &lt;- rowMeans(R_conduct)\n\n\nSDQ |&gt;\n    ggplot(aes(x = s_conduct)) +\n    geom_histogram(bins = 10)",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E1_likert.html#session-info",
    "href": "chapters/measurement/E1_likert.html#session-info",
    "title": "2  ✏️ Esercizi",
    "section": "2.4 Session Info",
    "text": "2.4 Session Info\n\nsessionInfo() \n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 15.0\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n [5] ggExtra_0.10.1    bayesplot_1.11.1  gridExtra_2.3     patchwork_1.3.0  \n [9] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-18     psych_2.4.6.26   \n[13] scales_1.3.0      markdown_1.13     knitr_1.48        lubridate_1.9.3  \n[17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n[25] tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.16.0  jsonlite_1.8.9     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5.1 farver_2.1.2      \n  [7] nloptr_2.1.1       rmarkdown_2.28     vctrs_0.6.5       \n [10] minqa_1.2.8        base64enc_0.1-3    rstatix_0.7.2     \n [13] htmltools_0.5.8.1  broom_1.0.6        Formula_1.2-5     \n [16] htmlwidgets_1.6.4  plyr_1.8.9         sandwich_3.1-1    \n [19] emmeans_1.10.4     zoo_1.8-12         uuid_1.2-1        \n [22] igraph_2.0.3       mime_0.12          lifecycle_1.0.4   \n [25] pkgconfig_2.0.3    Matrix_1.7-0       R6_2.5.1          \n [28] fastmap_1.2.0      shiny_1.9.1        digest_0.6.37     \n [31] OpenMx_2.21.12     fdrtool_1.2.18     colorspace_2.1-1  \n [34] rprojroot_2.0.4    Hmisc_5.1-3        labeling_0.4.3    \n [37] fansi_1.0.6        timechange_0.3.0   abind_1.4-8       \n [40] compiler_4.4.1     withr_3.0.1        glasso_1.11       \n [43] htmlTable_2.4.3    backports_1.5.0    carData_3.0-5     \n [46] ggsignif_0.6.4     MASS_7.3-61        corpcor_1.6.10    \n [49] gtools_3.9.5       tools_4.4.1        pbivnorm_0.6.0    \n [52] foreign_0.8-87     zip_2.3.1          httpuv_1.6.15     \n [55] nnet_7.3-19        glue_1.7.0         quadprog_1.5-8    \n [58] promises_1.3.0     nlme_3.1-166       lisrelToR_0.3     \n [61] grid_4.4.1         pbdZMQ_0.3-13      checkmate_2.3.2   \n [64] cluster_2.1.6      reshape2_1.4.4     generics_0.1.3    \n [67] gtable_0.3.5       tzdb_0.4.0         data.table_1.16.0 \n [70] hms_1.1.3          car_3.1-2          utf8_1.2.4        \n [73] sem_3.1-16         pillar_1.9.0       IRdisplay_1.1     \n [76] rockchalk_1.8.157  later_1.3.2        splines_4.4.1     \n [79] lattice_0.22-6     survival_3.7-0     kutils_1.73       \n [82] tidyselect_1.2.1   miniUI_0.1.1.1     pbapply_1.7-2     \n [85] stats4_4.4.1       xfun_0.47          qgraph_1.9.8      \n [88] arm_1.14-4         stringi_1.8.4      boot_1.3-31       \n [91] evaluate_1.0.0     codetools_0.2-20   mi_1.1            \n [94] cli_3.6.3          RcppParallel_5.1.9 IRkernel_1.3.2    \n [97] rpart_4.1.23       xtable_1.8-4       repr_1.1.7        \n[100] munsell_0.5.1      Rcpp_1.0.13        coda_0.19-4.1     \n[103] png_0.1-8          XML_3.99-0.17      parallel_4.4.1    \n[106] jpeg_0.1-10        lme4_1.1-35.5      mvtnorm_1.3-1     \n[109] openxlsx_4.2.7.1   crayon_1.5.3       rlang_1.1.4       \n[112] multcomp_1.4-26    mnormt_2.1.1",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E2_optimal_scoring.html",
    "href": "chapters/measurement/E2_optimal_scoring.html",
    "title": "3  ✏️ Esercizi",
    "section": "",
    "text": "3.1 Ottimizzazione dello scoring dei dati di questionari ordinali\nPrecedentemente, nell’Esercizio sulla scala Likert, abbiamo effettuato lo scoring del questionario Strengths and Difficulties Questionnaire (SDQ) utilizzando l’approccio chiamato “Likert scaling”, in cui le categorie di risposta “non vero”, “un po’ vero” e “certamente vero” sono state assegnate ai numeri interi consecutivi 0-1-2. Oltre a riflettere il presunto grado crescente di accordo in queste opzioni di risposta, l’assegnazione dei numeri interi era arbitraria, poiché non c’era una particolare ragione per cui abbiamo assegnato 0-1-2 anziché, ad esempio, 1-2-3. Un tale modo arbitrario di valutare le risposte degli item è chiamato anche “measurement by fiat”. In questo tutorial, cercheremo di trovare punteggi “ottimali” per le risposte ordinate al SDQ. “Ottimale” significa che i punteggi che assegniamo alle risposte non sono solo dei punteggi qualsiasi, ma sono i “migliori” tra tutti gli altri possibili punteggi in base a qualche criterio statistico.\nEsistono molti modi per “ottimizzare” i punteggi degli item; qui, massimizzeremo il rapporto tra la varianza del punteggio totale e la somma delle varianze dei punteggi degli item. In psicometria, il soddisfacimento di questo criterio porta alla massimizzazione della somma delle correlazioni degli item (e quindi della “coerenza interna” del punteggio del test misurata dall’alpha di Cronbach).\nsource(\"../../code/_common.R\")\nlibrary(\"aspect\")\nImportiamo nuovamente i dati del Strengths and Difficulties Questionnaire (SDQ).\nload(\"../data/data_sdq/SDQ.RData\")\nglimpse(SDQ)\n\nRows: 228\nColumns: 51\n$ Gender   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ consid   &lt;dbl&gt; 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2…\n$ restles  &lt;dbl&gt; 2, 0, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0…\n$ somatic  &lt;dbl&gt; 2, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, 1, 1…\n$ shares   &lt;dbl&gt; 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2…\n$ tantrum  &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 0…\n$ loner    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0…\n$ obeys    &lt;dbl&gt; 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2…\n$ worries  &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 1, 0…\n$ caring   &lt;dbl&gt; 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2…\n$ fidgety  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0…\n$ friend   &lt;dbl&gt; 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2…\n$ fights   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ unhappy  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0…\n$ popular  &lt;dbl&gt; 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2…\n$ distrac  &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0…\n$ clingy   &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 0, 2, 2, 0…\n$ kind     &lt;dbl&gt; 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2…\n$ lies     &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ bullied  &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0…\n$ helpout  &lt;dbl&gt; 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2…\n$ reflect  &lt;dbl&gt; 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2…\n$ steals   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ oldbest  &lt;dbl&gt; 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1…\n$ afraid   &lt;dbl&gt; 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, 1, 0…\n$ attends  &lt;dbl&gt; 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2…\n$ consid2  &lt;dbl&gt; 1, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 1, NA, 2, 2, NA, 1, 2, 2, …\n$ restles2 &lt;dbl&gt; 0, 1, 2, 1, NA, 0, 1, 1, 0, 0, NA, 2, NA, 0, 1, NA, 1, 1, 2, …\n$ somatic2 &lt;dbl&gt; 0, 1, 1, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 1, NA, 0, 1, 2, …\n$ shares2  &lt;dbl&gt; 1, 2, 2, 1, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 1, …\n$ tantrum2 &lt;dbl&gt; 0, 1, 2, 0, NA, 0, 2, 0, 0, 0, NA, 2, NA, 0, 1, NA, 1, 0, 2, …\n$ loner2   &lt;dbl&gt; 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 1, 0, NA, 0, 0, 1, …\n$ obeys2   &lt;dbl&gt; 2, 1, 2, 1, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 1, NA, 1, 2, 1, …\n$ worries2 &lt;dbl&gt; 0, 0, 1, 0, NA, NA, 1, 0, 0, 0, NA, 1, NA, 1, 2, NA, 0, 0, 2,…\n$ caring2  &lt;dbl&gt; 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 2, …\n$ fidgety2 &lt;dbl&gt; 0, 1, 0, 0, NA, 0, 1, 0, 0, 0, NA, 2, NA, 0, 0, NA, 1, 0, 2, …\n$ friend2  &lt;dbl&gt; 2, 2, 1, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 1, 2, NA, 2, 2, 2, …\n$ fights2  &lt;dbl&gt; 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0, 0, …\n$ unhappy2 &lt;dbl&gt; 0, 0, 1, 0, NA, 0, 0, 0, 0, 0, NA, 1, NA, 0, 0, NA, 0, 0, 1, …\n$ popular2 &lt;dbl&gt; 2, 1, 1, 2, NA, 2, 1, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 1, …\n$ distrac2 &lt;dbl&gt; 0, 0, 0, 2, NA, 0, 2, 1, 0, 0, NA, 1, NA, 0, 1, NA, 1, 0, 2, …\n$ clingy2  &lt;dbl&gt; 1, 1, 1, 0, NA, 1, 1, 1, 0, 0, NA, 1, NA, 0, 0, NA, 2, 0, 2, …\n$ kind2    &lt;dbl&gt; 2, 2, 2, 2, NA, 2, 2, 2, 2, 2, NA, 2, NA, 2, 2, NA, 1, 2, 2, …\n$ lies2    &lt;dbl&gt; 1, 0, 0, 0, NA, 0, 1, 0, 1, 0, NA, 1, NA, 0, 0, NA, 1, 0, 0, …\n$ bullied2 &lt;dbl&gt; 0, 0, 0, 0, NA, 0, 2, 0, 0, 0, NA, 0, NA, 0, 0, NA, 0, 0, 0, …\n$ helpout2 &lt;dbl&gt; 1, 1, 1, 2, NA, 2, 2, 1, 2, 1, NA, 2, NA, 2, 1, NA, 0, 2, 1, …\n$ reflect2 &lt;dbl&gt; 1, 1, 2, 1, NA, 2, 1, 2, 1, 2, NA, 1, NA, 2, 1, NA, 1, 2, 1, …\n$ steals2  &lt;dbl&gt; 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0, 0, …\n$ oldbest2 &lt;dbl&gt; 0, 0, 1, 0, NA, 1, 0, 1, 1, 0, NA, 1, NA, 0, 0, NA, 0, 0, 1, …\n$ afraid2  &lt;dbl&gt; 0, 1, 0, 0, NA, 0, 0, 0, 0, 0, NA, 2, NA, 0, 0, NA, 0, 0, 2, …\n$ attends2 &lt;dbl&gt; 1, 1, 2, 0, NA, 2, 2, 2, 2, 1, NA, 1, NA, 2, 2, NA, 1, 1, 0, …\nPer analizzare solo gli item che misurano i Sintomi Emotivi, è conveniente creare un nuovo data frame.\nitems_emotion &lt;- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nsdq_emo &lt;- SDQ[, items_emotion]\nsdq_emo |&gt;\n    head()\n\n\nA tibble: 6 × 5\n\n\nsomatic\nworries\nunhappy\nclingy\nafraid\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n2\n1\n0\n1\n0\n\n\n2\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n1\n1\n\n\n2\n1\n0\n1\n0\n\n\n1\n0\n0\n1\n0\nAffrontiamo il problema dei dati mancanti come discusso in precedenza.\nsdq_emo &lt;- sdq_emo %&gt;%\n    mutate_at(vars(somatic:afraid), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))\nEliminiamo i valori decimali.\nsdq_emo &lt;- round(sdq_emo)\nemotional_symptoms &lt;- c(\"somatic\", \"worries\", \"unhappy\", \"clingy\", \"afraid\")\nresult &lt;- lapply(emotional_symptoms, function(x) sort(unique(sdq_emo[[x]])))\nresult |&gt; print()\n\n[[1]]\n[1] 0 1 2\n\n[[2]]\n[1] 0 1 2\n\n[[3]]\n[1] 0 1 2\n\n[[4]]\n[1] 0 1 2\n\n[[5]]\n[1] 0 1 2\nTrasformiamo il data frame in una matrice.\nM &lt;- sdq_emo |&gt; as.matrix()\nM\n\n\nA matrix: 228 × 5 of type dbl\n\n\nsomatic\nworries\nunhappy\nclingy\nafraid\n\n\n\n\n2\n1\n0\n1\n0\n\n\n2\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n1\n1\n\n\n2\n1\n0\n1\n0\n\n\n1\n0\n0\n1\n0\n\n\n0\n1\n1\n2\n0\n\n\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n0\n0\n\n\n2\n2\n1\n1\n2\n\n\n0\n0\n0\n0\n2\n\n\n0\n1\n0\n2\n0\n\n\n1\n2\n1\n2\n1\n\n\n2\n0\n0\n1\n1\n\n\n1\n1\n0\n2\n1\n\n\n1\n1\n0\n0\n0\n\n\n1\n2\n2\n2\n1\n\n\n1\n1\n1\n2\n1\n\n\n1\n0\n0\n0\n0\n\n\n2\n1\n0\n0\n1\n\n\n2\n2\n2\n1\n2\n\n\n0\n1\n1\n1\n1\n\n\n1\n2\n0\n0\n2\n\n\n2\n2\n2\n2\n1\n\n\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n2\n0\n\n\n1\n0\n1\n1\n0\n\n\n0\n0\n0\n1\n0\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n1\n0\n0\n1\n0\n\n\n1\n0\n0\n1\n1\n\n\n1\n1\n0\n1\n1\n\n\n0\n0\n0\n0\n0\n\n\n0\n2\n0\n0\n0\n\n\n1\n1\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n\n\n1\n0\n0\n1\n0\n\n\n0\n0\n0\n1\n0\n\n\n1\n0\n0\n2\n0\n\n\n0\n1\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n\n\n1\n2\n1\n2\n2\n\n\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n1\n1\n\n\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n2\n0\n\n\n1\n0\n0\n0\n1\n\n\n1\n0\n1\n1\n1\n\n\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n\n\n1\n0\n0\n0\n1\n\n\n0\n1\n0\n1\n0\n\n\n0\n1\n0\n0\n0\n\n\n2\n1\n1\n1\n1\nImplementiamo lo scaling ottimale con la funzione corAspect().\nopt &lt;- corAspect(M, aspect = \"aspectSum\", level = \"ordinal\")\nEsaminiamo il risultato ottenuto.\nattributes(opt)\n\n\n    $names\n        \n'loss''catscores''cormat''eigencor''indmat''scoremat''data''burtmat''niter''call'\n\n    $class\n        'aspect'\nopt$scoremat\n\n\nA matrix: 228 × 5 of type dbl\n\n\n\nsomatic\nworries\nunhappy\nclingy\nafraid\n\n\n\n\n1\n1.9720960\n0.4454555\n-0.6009399\n0.2369782\n-0.7685934\n\n\n2\n1.9720960\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n3\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n1.0085914\n\n\n4\n-0.9013969\n-0.8540365\n-0.6009399\n0.2369782\n1.0085914\n\n\n5\n1.9720960\n0.4454555\n-0.6009399\n0.2369782\n-0.7685934\n\n\n6\n0.5862099\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n7\n-0.9013969\n0.4454555\n1.3931034\n1.6170823\n-0.7685934\n\n\n8\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n9\n0.5862099\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n10\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n1.0085914\n\n\n11\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n12\n1.9720960\n2.0964116\n1.3931034\n0.2369782\n1.9509426\n\n\n13\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n1.9509426\n\n\n14\n-0.9013969\n0.4454555\n-0.6009399\n1.6170823\n-0.7685934\n\n\n15\n0.5862099\n2.0964116\n1.3931034\n1.6170823\n1.0085914\n\n\n16\n1.9720960\n-0.8540365\n-0.6009399\n0.2369782\n1.0085914\n\n\n17\n0.5862099\n0.4454555\n-0.6009399\n1.6170823\n1.0085914\n\n\n18\n0.5862099\n0.4454555\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n19\n0.5862099\n2.0964116\n2.6586118\n1.6170823\n1.0085914\n\n\n20\n0.5862099\n0.4454555\n1.3931034\n1.6170823\n1.0085914\n\n\n21\n0.5862099\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n22\n1.9720960\n0.4454555\n-0.6009399\n-1.1988603\n1.0085914\n\n\n23\n1.9720960\n2.0964116\n2.6586118\n0.2369782\n1.9509426\n\n\n24\n-0.9013969\n0.4454555\n1.3931034\n0.2369782\n1.0085914\n\n\n25\n0.5862099\n2.0964116\n-0.6009399\n-1.1988603\n1.9509426\n\n\n26\n1.9720960\n2.0964116\n2.6586118\n1.6170823\n1.0085914\n\n\n27\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n28\n0.5862099\n-0.8540365\n-0.6009399\n1.6170823\n-0.7685934\n\n\n29\n0.5862099\n-0.8540365\n1.3931034\n0.2369782\n-0.7685934\n\n\n30\n-0.9013969\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n199\n0.5862099\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n200\n0.5862099\n-0.8540365\n-0.6009399\n0.2369782\n1.0085914\n\n\n201\n0.5862099\n0.4454555\n-0.6009399\n0.2369782\n1.0085914\n\n\n202\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n203\n-0.9013969\n2.0964116\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n204\n0.5862099\n0.4454555\n1.3931034\n-1.1988603\n1.0085914\n\n\n205\n0.5862099\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n206\n0.5862099\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n207\n-0.9013969\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n208\n0.5862099\n-0.8540365\n-0.6009399\n1.6170823\n-0.7685934\n\n\n209\n-0.9013969\n0.4454555\n-0.6009399\n0.2369782\n-0.7685934\n\n\n210\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n211\n-0.9013969\n0.4454555\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n212\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n213\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n214\n0.5862099\n2.0964116\n1.3931034\n1.6170823\n1.9509426\n\n\n215\n-0.9013969\n0.4454555\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n216\n-0.9013969\n-0.8540365\n-0.6009399\n0.2369782\n-0.7685934\n\n\n217\n-0.9013969\n-0.8540365\n-0.6009399\n0.2369782\n1.0085914\n\n\n218\n0.5862099\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n219\n-0.9013969\n-0.8540365\n-0.6009399\n1.6170823\n-0.7685934\n\n\n220\n0.5862099\n-0.8540365\n-0.6009399\n-1.1988603\n1.0085914\n\n\n221\n0.5862099\n-0.8540365\n1.3931034\n0.2369782\n1.0085914\n\n\n222\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n223\n-0.9013969\n-0.8540365\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n224\n-0.9013969\n0.4454555\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n225\n0.5862099\n-0.8540365\n-0.6009399\n-1.1988603\n1.0085914\n\n\n226\n-0.9013969\n0.4454555\n-0.6009399\n0.2369782\n-0.7685934\n\n\n227\n-0.9013969\n0.4454555\n-0.6009399\n-1.1988603\n-0.7685934\n\n\n228\n1.9720960\n0.4454555\n1.3931034\n0.2369782\n1.0085914\nEsaminiamo la relazione tra lo scoring basato sul metodo Likert con lo scoring ottimale.\nplot(opt$scoremat[, 1], sdq_emo$somatic)\nplot(opt$scoremat[, 5], sdq_emo$afraid)\nGuardando ai grafici ottenuti, si può notare che 1) i punteggi per le categorie successive aumentano quasi linearmente; 2) le categorie sono approssimativamente equidistanti. Concludiamo che per la valutazione degli item ordinali nella scala dei Sintomi Emotivi del SDQ, la scala Likert è appropriata, e non si può ottenere molto di più dall’ottimizzazione della scala rispetto alla semplice scala Likert di base.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E2_optimal_scoring.html#session-info",
    "href": "chapters/measurement/E2_optimal_scoring.html#session-info",
    "title": "3  ✏️ Esercizi",
    "section": "3.2 Session Info",
    "text": "3.2 Session Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] aspect_1.0-6       ggokabeito_0.1.0   viridis_0.6.5      viridisLite_0.4.2 \n [5] ggpubr_0.6.0       ggExtra_0.10.1     bayesplot_1.11.1   gridExtra_2.3     \n [9] patchwork_1.2.0    semTools_0.5-6.920 semPlot_1.1.6      lavaan_0.6-17     \n[13] psych_2.4.1        scales_1.3.0       markdown_1.12      knitr_1.45        \n[17] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[21] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[25] ggplot2_3.5.0      tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5   nloptr_2.0.3      \n  [7] rmarkdown_2.26     vctrs_0.6.5        minqa_1.2.6       \n [10] base64enc_0.1-3    rstatix_0.7.2      htmltools_0.5.7   \n [13] broom_1.0.5        Formula_1.2-5      htmlwidgets_1.6.4 \n [16] plyr_1.8.9         sandwich_3.1-0     emmeans_1.10.0    \n [19] zoo_1.8-12         uuid_1.2-0         igraph_2.0.2      \n [22] mime_0.12          lifecycle_1.0.4    pkgconfig_2.0.3   \n [25] Matrix_1.6-5       R6_2.5.1           fastmap_1.1.1     \n [28] shiny_1.8.0        digest_0.6.34      OpenMx_2.21.11    \n [31] fdrtool_1.2.17     colorspace_2.1-0   rprojroot_2.0.4   \n [34] Hmisc_5.1-1        fansi_1.0.6        timechange_0.3.0  \n [37] abind_1.4-5        compiler_4.3.3     withr_3.0.0       \n [40] glasso_1.11        htmlTable_2.4.2    backports_1.4.1   \n [43] carData_3.0-5      ggsignif_0.6.4     MASS_7.3-60.0.1   \n [46] corpcor_1.6.10     gtools_3.9.5       tools_4.3.3       \n [49] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [52] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [55] quadprog_1.5-8     nlme_3.1-164       promises_1.2.1    \n [58] lisrelToR_0.3      grid_4.3.3         pbdZMQ_0.3-11     \n [61] checkmate_2.3.1    cluster_2.1.6      reshape2_1.4.4    \n [64] generics_0.1.3     gtable_0.3.4       tzdb_0.4.0        \n [67] data.table_1.15.2  hms_1.1.3          car_3.1-2         \n [70] utf8_1.2.4         sem_3.1-15         pillar_1.9.0      \n [73] IRdisplay_1.1      rockchalk_1.8.157  later_1.3.2       \n [76] splines_4.3.3      lattice_0.22-5     survival_3.5-8    \n [79] kutils_1.73        tidyselect_1.2.0   miniUI_0.1.1.1    \n [82] pbapply_1.7-2      stats4_4.3.3       xfun_0.42         \n [85] qgraph_1.9.8       arm_1.13-1         stringi_1.8.3     \n [88] boot_1.3-29        evaluate_0.23      codetools_0.2-19  \n [91] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [94] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [97] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n[100] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n[103] parallel_4.3.3     ellipsis_0.3.2     jpeg_0.1-10       \n[106] lme4_1.1-35.1      mvtnorm_1.2-4      openxlsx_4.2.5.2  \n[109] crayon_1.5.2       rlang_1.1.3        multcomp_1.4-25   \n[112] mnormt_2.1.1",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E3_thurstone.html",
    "href": "chapters/measurement/E3_thurstone.html",
    "title": "4  ✏️ Esercizi",
    "section": "",
    "text": "4.1 Introduzione allo Scaling di Thurstone\nLo scaling di Thurstone, sviluppato da Louis Leon Thurstone nel 1931, è un approccio statistico che mira a modellare dati di ranking soggettivo. I dati di ranking soggettivo si producono quando le persone ordinano un insieme di elementi o stimoli secondo un criterio particolare. Questo tipo di dati è particolarmente utile quando è più semplice per i partecipanti esprimere una preferenza relativa piuttosto che stime quantitative precise.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E3_thurstone.html#introduzione-allo-scaling-di-thurstone",
    "href": "chapters/measurement/E3_thurstone.html#introduzione-allo-scaling-di-thurstone",
    "title": "4  ✏️ Esercizi",
    "section": "",
    "text": "4.1.1 Il Modello Thurstoniano\nIl modello Thurstoniano rappresenta un approccio statistico per analizzare e interpretare le preferenze o i ranking individuali rispetto a vari oggetti o stimoli. Questo modello si basa sull’idea che esista una scala latente, ovvero una dimensione non direttamente osservabile, attorno alla quale si distribuiscono i ranking individuali. In altre parole, ogni individuo assegna un punteggio ad ogni oggetto basandosi su criteri personali, ma queste valutazioni individuali sono influenzate da una percezione collettiva o aggregata che può essere descritta su una scala continua latente.\nIl principale obiettivo del modello Thurstoniano è di trasformare queste medie di ranking latenti aggregati, che esistono su una scala continua, in un ranking discreto che possiamo interpretare più facilmente. Per farlo, il modello si avvale di alcune ipotesi chiave:\n\nDistribuzione Gaussiana: Si assume che il ranking latente per ciascun oggetto possa essere descritto da una distribuzione gaussiana.\nMedia Differenziata, Varianza Costante: Il modello presuppone che le distribuzioni gaussiane dei ranking per ciascun oggetto differiscano tra loro solo per la media, mantenendo costante la varianza (scaling di Thurstone caso V). Questo implica che, sebbene gli oggetti possano avere livelli di preferenza medi diversi (alcuni potrebbero essere generalmente preferiti ad altri), la variabilità delle valutazioni (quanto le opinioni dei rispondenti differiscono tra loro) è la stessa per tutti gli oggetti.\n\nPer posizionare gli oggetti sulla scala di Thurstone, si procede nel seguente modo:\n\nSi calcola la proporzione di rispondenti che preferiscono un oggetto rispetto a ciascuno degli altri.\nSi determinano i corrispondenti percentile (z-scores) della distribuzione cumulativa normale, che ci dicono quante deviazioni standard un valore è distante dalla media.\nSi calcola la media di questi z-scores per ciascun oggetto.\n\nEsempio Pratico:\nImmaginiamo di avere tre oggetti: A, B e C. Dopo aver raccolto le preferenze, scopriamo che:\n\nIl 70% dei rispondenti preferisce A rispetto a B e C.\nIl 50% dei rispondenti preferisce B rispetto ad A, ma solo il 30% lo preferisce a C.\nIl 80% dei rispondenti preferisce C rispetto a B, ma solo il 50% lo preferisce ad A.\n\nTrasformando queste percentuali in z-scores, possiamo ottenere una misura della “distanza” di ciascun oggetto dalla media sulla scala latente. Mediando questi z-scores, possiamo creare un ranking discreto che riflette le preferenze medie aggregate, permettendoci di interpretare quali oggetti sono generalmente preferiti rispetto ad altri secondo il modello Thurstoniano.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E3_thurstone.html#studio-sulle-preferenze-riguardanti-le-caratteristiche-delloccupazione-ideale",
    "href": "chapters/measurement/E3_thurstone.html#studio-sulle-preferenze-riguardanti-le-caratteristiche-delloccupazione-ideale",
    "title": "4  ✏️ Esercizi",
    "section": "4.2 Studio sulle preferenze riguardanti le caratteristiche dell’occupazione ideale",
    "text": "4.2 Studio sulle preferenze riguardanti le caratteristiche dell’occupazione ideale\nI dati utilizzati in questo studio sono stati raccolti nell’ambito di una ricerca sulla motivazione lavorativa condotta da Ilke Inceoglu. Nel corso di questa indagine, 1079 partecipanti sono stati invitati a classificare nove aspetti lavorativi in base all’importanza che desideravano che fossero presenti nella loro occupazione ideale:\n\nAmbiente di Supporto (Supporto)\nLavoro Stimolante (Sfida)\nProgressione di Carriera (Carriera)\nLavoro Etico (Etica)\nControllo sul Lavoro, Impatto Personale (Autonomia)\nSviluppo (Sviluppo)\nInterazione Sociale (Interazione)\nAmbiente Competitivo (Competizione)\nAmbiente Piacevole e Sicuro (Sicurezza)\n\nUn punteggio di 1 attribuito a qualsiasi aspetto lavorativo indica che tale aspetto era il più importante per quel partecipante, mentre un punteggio di 9 indica che era il meno importante.\n\nJobFeatures &lt;- rio::import(\"../data/JobFeatures.txt\")\nglimpse(JobFeatures)\n\nRows: 1,079\nColumns: 9\n$ Support     &lt;int&gt; 8, 7, 5, 7, 1, 6, 5, 1, 1, 7, 6, 8, 5, 9, 8, 1, 6, 7, 4, 2~\n$ Challenge   &lt;int&gt; 3, 5, 8, 6, 4, 1, 4, 9, 3, 4, 2, 1, 4, 8, 6, 7, 4, 4, 1, 3~\n$ Career      &lt;int&gt; 4, 1, 1, 8, 8, 3, 7, 2, 7, 6, 3, 4, 6, 1, 3, 5, 8, 3, 5, 4~\n$ Ethics      &lt;int&gt; 5, 6, 9, 9, 3, 7, 2, 8, 4, 1, 9, 3, 7, 5, 9, 6, 7, 5, 9, 8~\n$ Autonomy    &lt;int&gt; 2, 2, 6, 3, 9, 8, 3, 7, 9, 8, 4, 6, 3, 7, 5, 2, 3, 8, 2, 1~\n$ Development &lt;int&gt; 6, 8, 2, 4, 2, 5, 6, 5, 2, 5, 1, 2, 2, 6, 1, 3, 1, 2, 6, 5~\n$ Interaction &lt;int&gt; 1, 3, 3, 2, 6, 2, 1, 4, 6, 9, 5, 5, 1, 4, 2, 8, 2, 6, 3, 6~\n$ Competition &lt;int&gt; 7, 9, 4, 5, 7, 4, 9, 6, 8, 3, 7, 7, 9, 2, 7, 9, 9, 1, 7, 9~\n$ Safety      &lt;int&gt; 9, 4, 7, 1, 5, 9, 8, 3, 5, 2, 8, 9, 8, 3, 4, 4, 5, 9, 8, 7~\n\n\nConsideriamo i dati del primo rispondente:\n\nJobFeatures[1, ]\n\n\nA data.frame: 1 x 9\n\n\n\nSupport\nChallenge\nCareer\nEthics\nAutonomy\nDevelopment\nInteraction\nCompetition\nSafety\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\n8\n3\n4\n5\n2\n6\n1\n7\n9\n\n\n\n\n\nQuesto rispondente ha risposto assegnando la caratteristica più importante dell’impego a “Interaction”, seguita da “Autonomy”. L’ultima preferenza è “Safety”.\nEseguiamo lo scaling di Thurstone usando la funzione thurstone del pacchetto psych:\n\nscaling &lt;- psych::thurstone(JobFeatures, ranks = TRUE)\n\nGli attributi dell’oggetto scaling prodotto da thurstone() possono essere elencati nel modo seguente.\n\nattributes(scaling)\n\n\n    $names\n        \n'scale''GF''choice''residual''Call'\n\n    $class\n        \n'psych''thurstone'\n\n\n\n\nI risultati dello scaling si ottengono nel modo seguente. Sono elencati nell’ordine fornito sopra, ovvero Support, Challenge, Career, Ethics, Autonomy, Development, Interaction, Competition e Safety.\nUna media alta indica che i partecipanti attribuiscono un alto valore a questo aspetto lavorativo rispetto agli altri. Tuttavia, poiché le preferenze sono sempre relative, è impossibile identificare in maniera univoca tutte le medie. Pertanto, una delle medie deve essere fissata a un valore arbitrario. È consuetudine fissare la media dell’aspetto meno preferito a 0. Quindi, tutte le altre medie sono positive.\n\nscaling$scale |&gt; print()\n\n[1] 0.97 0.93 0.91 0.92 0.60 1.04 0.63 0.00 0.23\n\n\nLa media più bassa (0.0) corrisponde all’8° aspetto, Competizione, mentre la media più alta (1.04) corrisponde al 6° aspetto, Sviluppo. Ciò significa che l’ambiente competitivo era il meno desiderato, mentre le opportunità di sviluppo personale erano le più desiderate dalle persone nel loro lavoro ideale. Gli altri aspetti sono stati valutati come aventi un’importanza relativa intermedia a queste due, con Sicurezza che ha una media bassa (0.23) - appena superiore a 0 per la Competizione, mentre Supporto, Sfida, Carriera ed Etica hanno medie simili (intorno a 0.9). Autonomia e Interazione hanno medie moderate simili intorno a 0.6.\nL’istruzione seguente produce una matrice 9x9 contenente le proporzioni dei partecipanti nel campione che hanno preferito l’aspetto nella colonna rispetto all’aspetto nella riga. Nella matrice risultante, le righe e le colonne seguono l’ordine delle variabili nel file originale.\n\nscaling$choice |&gt; round(2)\n\n\nA matrix: 9 x 9 of type dbl\n\n\n0.50\n0.47\n0.47\n0.47\n0.36\n0.51\n0.36\n0.20\n0.23\n\n\n0.53\n0.50\n0.47\n0.49\n0.38\n0.53\n0.36\n0.17\n0.28\n\n\n0.53\n0.53\n0.50\n0.50\n0.38\n0.52\n0.39\n0.19\n0.26\n\n\n0.53\n0.51\n0.50\n0.50\n0.36\n0.52\n0.38\n0.19\n0.26\n\n\n0.64\n0.62\n0.62\n0.64\n0.50\n0.67\n0.51\n0.29\n0.34\n\n\n0.49\n0.47\n0.48\n0.48\n0.33\n0.50\n0.29\n0.15\n0.20\n\n\n0.64\n0.64\n0.61\n0.62\n0.49\n0.71\n0.50\n0.22\n0.30\n\n\n0.80\n0.83\n0.81\n0.81\n0.71\n0.85\n0.78\n0.50\n0.61\n\n\n0.77\n0.72\n0.74\n0.74\n0.66\n0.80\n0.70\n0.39\n0.50\n\n\n\n\n\nIl valore maggiore è\n\nmax(scaling$choice)\n\n0.852641334569045\n\n\nQuesto valore, 0.8526, rappresenta la proporzione di partecipanti che hanno preferito l’8° aspetto, Competizione, al 6° aspetto, Sviluppo, ed è il valore più grande nella matrice precedente: questa coppia di caratteristiche ha la preferenza più decisa per un aspetto rispetto all’altro.\nLa preferenza più decisa in termini di proporzioni di persone che scelgono un aspetto rispetto all’altro deve avere la maggiore distanza/differenza sulla scala delle preferenze soggettive (il 6° aspetto, Sviluppo, deve avere una preferenza percepita media molto più alta dell’8° aspetto, Competizione). Questo risultato è effettivamente in linea con i risultati per le medie di utilità, dove la media dello Sviluppo è la più alta con un valore di 1.04 e la Competizione è la più bassa con un valore di 0.\nConsideriamo i residui del modello:\n\nscaling$residual\n\n\nA matrix: 9 x 9 of type dbl\n\n\n0.000000000\n0.0133479521\n0.001732662\n0.0077151838\n-0.005872352\n0.020341170\n0.008084655\n-0.036657121\n0.007039854\n\n\n-0.013347952\n0.0000000000\n0.022201895\n0.0003878924\n-0.005625238\n0.011115950\n0.018649360\n0.009672656\n-0.040301391\n\n\n-0.001732662\n-0.0222018946\n0.000000000\n0.0073806440\n0.004543318\n0.028230409\n0.001106985\n-0.004628757\n-0.008671076\n\n\n-0.007715184\n-0.0003878924\n-0.007380644\n0.0000000000\n0.010887738\n0.027845520\n0.007400479\n-0.012284446\n-0.010646760\n\n\n0.005872352\n0.0056252384\n-0.004543318\n-0.0108877381\n0.000000000\n-0.005140288\n0.006785811\n-0.012984302\n0.017008932\n\n\n-0.020341170\n-0.0111159497\n-0.028230409\n-0.0278455199\n0.005140288\n0.000000000\n0.049380030\n0.002756144\n0.015651117\n\n\n-0.008084655\n-0.0186493603\n-0.001106985\n-0.0074004791\n-0.006785811\n-0.049380030\n0.000000000\n0.042051948\n0.041174300\n\n\n0.036657121\n-0.0096726558\n0.004628757\n0.0122844463\n0.012984302\n-0.002756144\n-0.042051948\n0.000000000\n-0.021145626\n\n\n-0.007039854\n0.0403013911\n0.008671076\n0.0106467596\n-0.017008932\n-0.015651117\n-0.041174300\n0.021145626\n0.000000000\n\n\n\n\n\nL’istruzione precedente produce una matrice 9x9 contenente le differenze tra le proporzioni osservate (la matrice delle scelte) e le proporzioni attese (proporzioni che preferiscono l’aspetto nella riga rispetto all’aspetto nella colonna, che sarebbe atteso in base alle distribuzioni normali standard delle preferenze soggettive intorno alle medie scalate come sopra). Gli scarti tra i valori attesi e quelli osservati sono il modo più diretto di misurare se un modello (in questo caso, il modello proposto da Thurstone) “si adatta” ai dati osservati. Gli scarti piccoli (vicini allo zero) indicano che ci sono piccole discrepanze tra le scelte osservate e le scelte previste dal modello; il che significa che il modello che abbiamo adottato è piuttosto buono.\nInfine, esaminiamo un indice di bontà di adattamento:\n\nscaling$GF\n\n0.998754828963899\n\n\nIl valore GF (Goodness of Fit) viene calcolato come 1 meno la somma dei residui al quadrato divisi per i valori osservati al quadrato. Quando i residui sono quasi zero, i loro rapporti al quadrato rispetto alle proporzioni osservate dovrebbero anch’essi avvicinarsi a zero. Di conseguenza, l’indice di bontà di adattamento di un modello ben adattato dovrebbe essere vicino a 1.\nNella nostra analisi, tutti i residui sono notevolmente piccoli, indicando una stretta corrispondenza tra le scelte osservate (proporzioni di preferenze per una caratteristica rispetto a un’altra). Questo allineamento preciso si riflette nell’indice GF, che è quasi 1, suggerendo che il modello di Thurstone cattura adeguatamente le proprietà dei dati relativi alle caratteristiche dell’occupazione ideale.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E3_thurstone.html#considerazioni-conclusive",
    "href": "chapters/measurement/E3_thurstone.html#considerazioni-conclusive",
    "title": "4  ✏️ Esercizi",
    "section": "4.3 Considerazioni conclusive",
    "text": "4.3 Considerazioni conclusive\nQuesta metodologia, introdotta da Louis Leon Thurstone negli anni ’20, rappresenta una delle forme più semplici e intuitive di scaling, dove per “scaling” si intende il processo di costruzione di un ordinamento di valori lungo un continuum psicologico. Lo scaling thurstoniano si basa sulla premessa che sia possibile ordinare stimoli o concetti secondo il grado in cui incarnano una certa proprietà psicologica, creando così una scala di misura che riflette le percezioni, le attitudini o i giudizi degli individui.\nUno degli aspetti centrali dello scaling di Thurstone, in particolare il caso V della sua legge del giudizio comparativo, è l’assunzione che le distribuzioni di ranking degli stimoli abbiano varianze uguali. Questa ipotesi, pur facilitando la modellizzazione matematica e l’interpretazione dei dati, è stata oggetto di critiche poiché difficilmente riscontrabile nella pratica. Le varianze possono variare significativamente tra gli stimoli a seconda della coerenza dei giudizi degli individui e della natura degli stimoli stessi. Questa limitazione ha stimolato lo sviluppo e l’adozione di metodi alternativi più flessibili per affrontare la complessità dello scaling psicologico.\nNel panorama contemporaneo, l’approccio più diffuso e metodologicamente avanzato per lo scaling psicologico deriva dalla Teoria della Risposta all’Item (IRT). L’IRT supera alcune delle limitazioni intrinseche allo scaling thurstoniano offrendo un quadro teorico e metodologico che considera la probabilità di una certa risposta a un item in funzione delle caratteristiche dell’item stesso e del livello dell’attributo psicologico del rispondente. Questo approccio permette di gestire in modo più efficace la varianza tra gli stimoli e di fornire stime più accurate delle proprietà psicometriche degli items e delle caratteristiche degli individui.\nIn conclusione, mentre lo scaling thurstoniano ha rappresentato un passo fondamentale nello sviluppo degli strumenti di misurazione in psicologia, l’evoluzione metodologica e teorica ha portato a preferire approcci basati sull’IRT. Questo non diminuisce il valore storico e didattico dello scaling di Thurstone, che continua a essere un esempio introduttivo prezioso per comprendere i concetti fondamentali dello scaling psicologico. Tuttavia, è nell’ambito della IRT che attualmente si trovano le soluzioni più robuste e sofisticate per affrontare le sfide della misurazione psicologica, guidando la ricerca e l’applicazione pratica nel campo della psicometria contemporanea.",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/measurement/E3_thurstone.html#sesssion-info",
    "href": "chapters/measurement/E3_thurstone.html#sesssion-info",
    "title": "4  ✏️ Esercizi",
    "section": "4.4 Sesssion Info",
    "text": "4.4 Sesssion Info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] rio_1.0.1         ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2\n [5] ggpubr_0.6.0      ggExtra_0.10.1    bayesplot_1.11.0  gridExtra_2.3    \n [9] patchwork_1.2.0   semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-17    \n[13] psych_2.4.1       scales_1.3.0      markdown_1.12     knitr_1.45       \n[17] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n[21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n[25] ggplot2_3.4.4     tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.4.1 nloptr_2.0.3      \n  [7] rmarkdown_2.25     vctrs_0.6.5        minqa_1.2.6       \n [10] base64enc_0.1-3    rstatix_0.7.2      htmltools_0.5.7   \n [13] broom_1.0.5        Formula_1.2-5      htmlwidgets_1.6.4 \n [16] plyr_1.8.9         sandwich_3.1-0     emmeans_1.10.0    \n [19] zoo_1.8-12         uuid_1.2-0         igraph_2.0.1.1    \n [22] mime_0.12          lifecycle_1.0.4    pkgconfig_2.0.3   \n [25] Matrix_1.6-5       R6_2.5.1           fastmap_1.1.1     \n [28] shiny_1.8.0        digest_0.6.34      OpenMx_2.21.11    \n [31] fdrtool_1.2.17     colorspace_2.1-0   rprojroot_2.0.4   \n [34] Hmisc_5.1-1        fansi_1.0.6        timechange_0.3.0  \n [37] abind_1.4-5        compiler_4.3.2     withr_3.0.0       \n [40] glasso_1.11        htmlTable_2.4.2    backports_1.4.1   \n [43] carData_3.0-5      R.utils_2.12.3     ggsignif_0.6.4    \n [46] MASS_7.3-60.0.1    corpcor_1.6.10     gtools_3.9.5      \n [49] tools_4.3.2        pbivnorm_0.6.0     foreign_0.8-86    \n [52] httpuv_1.6.14      zip_2.3.1          nnet_7.3-19       \n [55] R.oo_1.26.0        glue_1.7.0         quadprog_1.5-8    \n [58] promises_1.2.1     nlme_3.1-164       lisrelToR_0.3     \n [61] grid_4.3.2         pbdZMQ_0.3-11      checkmate_2.3.1   \n [64] cluster_2.1.6      reshape2_1.4.4     generics_0.1.3    \n [67] gtable_0.3.4       tzdb_0.4.0         R.methodsS3_1.8.2 \n [70] data.table_1.15.0  hms_1.1.3          car_3.1-2         \n [73] utf8_1.2.4         sem_3.1-15         pillar_1.9.0      \n [76] IRdisplay_1.1      rockchalk_1.8.157  later_1.3.2       \n [79] splines_4.3.2      lattice_0.22-5     survival_3.5-7    \n [82] kutils_1.73        tidyselect_1.2.0   miniUI_0.1.1.1    \n [85] pbapply_1.7-2      stats4_4.3.2       xfun_0.42         \n [88] qgraph_1.9.8       arm_1.13-1         stringi_1.8.3     \n [91] boot_1.3-28.1      evaluate_0.23      codetools_0.2-19  \n [94] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [97] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n[100] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n[103] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n[106] parallel_4.3.2     ellipsis_0.3.2     jpeg_0.1-10       \n[109] lme4_1.1-35.1      mvtnorm_1.2-4      openxlsx_4.2.5.2  \n[112] crayon_1.5.2       rlang_1.1.3        multcomp_1.4-25   \n[115] mnormt_2.1.1",
    "crumbs": [
      "Punteggi e scale",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✏️ Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html",
    "href": "chapters/ctt/01_ctt_1.html",
    "title": "5  Fondamenti teorici",
    "section": "",
    "text": "5.1 Introduzione\nLa teoria classica dei test (Classic Test Theory, CTT) è una teoria fondamentale utilizzata in psicometria per valutare e misurare le caratteristiche psicologiche degli individui attraverso l’uso di test e questionari. Secondo questa teoria, il punteggio ottenuto da un individuo in un test è influenzato da due componenti principali: il punteggio vero dell’individuo sulla caratteristica misurata e l’errore casuale di misurazione.\nIl punteggio vero rappresenta la misura effettiva della caratteristica che si intende valutare nel soggetto. Tuttavia, a causa di vari fattori come l’errore di misurazione, le distrazioni o l’incertezza dell’individuo durante il test, il punteggio osservato può deviare dal punteggio vero. Questa discrepanza tra il punteggio vero e il punteggio osservato viene definita errore di misurazione.\nLa teoria classica dei test si focalizza sulla quantificazione della relazione tra il punteggio vero, il punteggio osservato e l’errore di misurazione. Attraverso l’uso di statistiche come la media, la deviazione standard e il coefficiente di affidabilità, questa teoria fornisce una base concettuale per la costruzione dei test, l’interpretazione dei risultati e l’analisi dell’affidabilità del test stesso.\nÈ importante notare che negli ultimi anni sono state sviluppate altre teorie, come la teoria della risposta all’item o la teoria della generalizzabilità (Generalizability Theory), che cercano di superare alcune delle limitazioni della teoria classica dei test. Tuttavia, nonostante queste nuove teorie, la teoria classica dei test continua ad essere ampiamente utilizzata e costituisce ancora una base fondamentale per la valutazione e la misurazione delle caratteristiche psicologiche degli individui.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#tipi-di-costrutti-e-modelli-latenti",
    "href": "chapters/ctt/01_ctt_1.html#tipi-di-costrutti-e-modelli-latenti",
    "title": "5  Fondamenti teorici",
    "section": "5.2 Tipi di Costrutti e Modelli Latenti",
    "text": "5.2 Tipi di Costrutti e Modelli Latenti\nUn costrutto è un concetto, spesso considerato una idea latente o fenomeno non direttamente osservabile (Petersen 2024). Ad esempio, la depressione può essere un costrutto perché non possiamo misurare direttamente il livello di depressione di una persona, ma lo inferiamo attraverso indicatori indiretti come umore basso, perdita di interesse, difficoltà nel sonno, ecc. Gli indicatori sono misure che riflettono il costrutto.\nEsistono due tipi principali di costrutti: costrutti riflessivi e costrutti formativi.\n\n5.2.1 1. Costrutto Riflessivo\nIn un costrutto riflessivo, il costrutto causa le misure e gli indicatori riflettono il costrutto (Bollen e Lennox 1991). Ad esempio, l’estroversione è un costrutto riflessivo perché la risposta agli indicatori come “piacere di parlare con sconosciuti” o “andare a feste” riflette il livello di estroversione della persona. Gli indicatori sono correlati perché riflettono tutti un unico costrutto latente. La consistenza interna tra gli indicatori è quindi attesa.\n\n\n5.2.2 2. Costrutto Formativo\nIn un costrutto formativo, invece, le misure causano il costrutto (Bollen e Lennox 1991). Ad esempio, lo stato socioeconomico (SES) può essere formato dall’educazione, dal reddito e dal prestigio occupazionale di una persona. Gli indicatori formano il costrutto e potrebbero non essere correlati tra loro, in contrasto con i costrutti riflessivi.\n\n\n5.2.3 Differenze tra Costrutti Riflessivi e Formativi\n\nCorrelazioni tra indicatori: Gli indicatori riflessivi sono correlati, mentre quelli formativi non lo devono necessariamente essere.\nCampionamento degli indicatori: Nei costrutti formativi è essenziale campionare tutti gli aspetti del costrutto, mentre nei riflessivi gli indicatori possono essere intercambiabili.\nCorrelazioni ottimali: Nei costrutti riflessivi, alte correlazioni tra indicatori sono desiderabili, mentre nei formativi correlazioni troppo alte possono creare multicollinearità.\n\n\n\n5.2.4 Come Stimare\n\nCostrutti riflessivi: Devono essere stimati con modelli latenti come SEM, analisi fattoriale o teoria della risposta dell’item (IRT).\nCostrutti formativi: Possono essere stimati con medie pesate o tramite SEM.\n\n\n\n5.2.5 Conclusione\nPrima di stimare un costrutto, è importante comprendere la sua natura teorica. I costrutti riflessivi richiedono modelli che riflettano la varianza comune tra gli indicatori, mentre i costrutti formativi possono essere stimati con medie o punteggi sommativi. La teoria è essenziale per guidare la scelta del metodo di stima.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#la-teoria-classica",
    "href": "chapters/ctt/01_ctt_1.html#la-teoria-classica",
    "title": "5  Fondamenti teorici",
    "section": "5.3 La Teoria Classica",
    "text": "5.3 La Teoria Classica\nLa Teoria Classica dei Test (CTT), originariamente sviluppata da Spearman (1904) e successivamente formalizzata da Lord e Novick (1968), offre un quadro teorico che descrive come i punteggi ottenuti da un test psicometrico siano legati a un costrutto latente.\nUno dei concetti fondamentali all’interno della CTT riguarda l’affidabilità dei punteggi ottenuti dai test. L’affidabilità, in questo contesto, indica la capacità del test di produrre risultati coerenti e stabili in diverse occasioni. Questo concetto può essere compreso attraverso l’equazione fondamentale della CTT:\n\\[\nX = T + E,\n\\tag{5.1}\\]\ndove \\(X\\) rappresenta il punteggio osservato nel test, \\(T\\) è il punteggio vero (ovvero la rappresentazione della variabile latente di interesse), e \\(E\\) rappresenta l’errore di misurazione.\nUn aspetto di particolare rilevanza all’interno della CTT riguarda la varianza dell’errore. Maggiore è questa varianza, minore sarà la precisione con cui il punteggio vero si riflette nei punteggi osservati. In un contesto ideale, gli errori di misurazione sarebbero tutti nulli, garantendo punteggi esatti per ogni partecipante. Tuttavia, a causa delle inevitabili imperfezioni, si verifica una certa variazione negli errori. La deviazione standard associata a questi errori è chiamata errore standard di misurazione e viene indicata con \\(\\sigma_E\\). Uno degli obiettivi principali della CTT è stimare \\(\\sigma_E\\) al fine di valutare la qualità di una scala psicometrica.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#le-due-componenti-del-punteggio-osservato",
    "href": "chapters/ctt/01_ctt_1.html#le-due-componenti-del-punteggio-osservato",
    "title": "5  Fondamenti teorici",
    "section": "5.4 Le due componenti del punteggio osservato",
    "text": "5.4 Le due componenti del punteggio osservato\nL’Equazione 5.1 rappresenta il cuore del modello, sottolineando che il punteggio osservato è il risultato dell’addizione del punteggio vero e dell’errore di misurazione.\nL’obiettivo principale della CTT è quantificare l’errore di misurazione (rappresentato da \\(\\sigma_E\\)) per valutare l’affidabilità del test e ottenere una stima dell’errore standard di misurazione. L’affidabilità del test riflette la precisione con cui il test può misurare il punteggio vero (Coaley, 2014). Si calcola come il rapporto tra la varianza dei punteggi veri e la varianza dei punteggi osservati. Un’alta affidabilità indica una ridotta incertezza dovuta all’errore di misurazione (\\(\\sigma_E\\)), indicando che il punteggio osservato (\\(X\\)) fornisce una misura accurata del punteggio vero (\\(T\\)). Al contrario, una bassa affidabilità indica un elevato errore di misurazione (\\(\\sigma_E\\)) e una significativa discrepanza tra il punteggio osservato e il punteggio vero.\nLa stima dell’errore standard di misurazione comporta il calcolo della deviazione standard della variabile casuale \\(E\\) (ossia \\(\\sigma_E\\)), che rappresenta l’errore di misurazione influente sui punteggi veri. Questa stima offre un’indicazione della dispersione dei punteggi osservati attorno ai punteggi veri, causata dall’errore di misurazione.\nNelle prossime sezioni, esploreremo come il concetto chiave di attendibilità nella CTT possa essere collegato al coefficiente di determinazione nel contesto del modello statistico di regressione lineare. Inoltre, vedremo come l’errore standard di misurazione della CTT possa essere associato all’errore standard nella regressione.\n\n5.4.1 Il punteggio vero\nL’Equazione 5.1 ci spiega che il punteggio osservato è il risultato della combinazione di due componenti: una componente sistematica (il punteggio vero) e una componente aleatoria (l’errore di misurazione). Ma cosa rappresenta esattamente il punteggio vero? La Teoria Classica dei Test (CTT) attribuisce diverse interpretazioni al concetto di punteggio vero.\n\nDa un punto di vista psicologico, la CTT considera il test come una selezione casuale di domande da un insieme più ampio di domande che riflettono il costrutto da misurare (Nunnally 1994; Kline 2013). In questo contesto, il punteggio vero rappresenta il punteggio che un partecipante otterrebbe se rispondesse a tutte le domande dell’insieme completo. L’errore di misurazione riflette quindi quanto le domande selezionate rappresentano l’intero insieme di domande relative al costrutto.\nIn modo equivalente, il punteggio vero può essere considerato come il punteggio non influenzato da fattori esterni al costrutto, come effetti di apprendimento, fatica, memoria, motivazione, e così via. Poiché è concepito come un processo completamente casuale, la componente aleatoria non introduce alcun bias nella tendenza centrale della misurazione (la media di \\(E\\) è assunta essere uguale a 0).\nDal punto di vista statistico, il punteggio vero è un punteggio inosservabile che rappresenta il valore atteso di infinite misurazioni del punteggio ottenute:\n\n\\[\nT = \\mathbb{E}(X) \\equiv \\mu_X \\equiv \\mu_{T}.\n\\]\nCombinando le definizioni presentate sopra, Lord e Novick (1968) concepiscono il punteggio vero come la media dei punteggi che un soggetto otterrebbe se il test venisse somministrato ripetutamente nelle stesse condizioni, senza effetti di apprendimento o fatica.\n\n\n5.4.2 Somministrazioni ripetute\nNel modello della Teoria Classica dei Test (CTT) possiamo distinguere due tipi di esperimenti casuali: uno in cui l’unità di osservazione (l’individuo) è considerata come una variabile campionaria, e l’altro in cui il punteggio per un determinato individuo è trattato come una variabile casuale.\nUn importante risultato è dato dalla combinazione di questi due esperimenti casuali, dimostrando che i risultati della CTT, sviluppata ipotizzando somministrazioni ripetute immaginarie del test allo stesso individuo nelle stesse condizioni, si estendono al caso di una singola somministrazione del test su un campione di individui (Allen e Yen 2001). Questo risultato ci permette di attribuire un significato empirico alle quantità discusse dalla CTT quando consideriamo la somministrazione del test a una popolazione di individui:\n\n\\(\\sigma^2_X\\) rappresenta la varianza del punteggio osservato nella popolazione,\n\\(\\sigma^2_T\\) rappresenta la varianza del punteggio vero nella popolazione,\n\\(\\sigma^2_E\\) rappresenta la varianza della componente d’errore nella popolazione.\n\n\n\n5.4.3 Le assunzioni sul punteggio ottenuto\nLa CTT assume che la media del punteggio osservato \\(X\\) sia uguale alla media del punteggio vero,\n\\[\n\\mu_X \\equiv \\mu_{T},\n\\tag{5.2}\\]\nin altri termini, assume che il punteggio osservato fornisca una stima statisticamente corretta dell’abilità latente (punteggio vero).\nIn pratica, il punteggio osservato non sarà mai uguale all’abilità latente, ma corrisponde solo ad uno dei possibili punteggi che il soggetto può ottenere, subordinatamente alla sua abilità latente. L’errore della misura è la differenza tra il punteggio osservato e il punteggio vero:\n\\[\nE \\equiv X - T.\n\\]\nIn base all’assunzione secondo cui il valore atteso dei punteggi è uguale alla media del valore vero, segue che\n\\[\n\\mathbb{E}(E) = \\mathbb{E}(X - T) = \\mathbb{E}(X) - \\mathbb{E}(T) = \\mu_{T} - \\mu_{T} = 0,\n\\]\novvero, il valore atteso degli errori è uguale a zero.\nPer dare un contenuto concreto alle affermazioni precedenti, consideriamo la seguente simulazione svolta in \\(\\textsf{R}\\). In tale simulazione il punteggio vero \\(T\\) e l’errore \\(E\\) sono creati in modo tale da soddisfare i vincoli della CTT: \\(T\\) e \\(E\\) sono variabili casuali gaussiane tra loro incorrelate. Nella simulazione generiamo 100 coppie di valori \\(X\\) e \\(T\\) con i seguenti parametri: \\(T \\sim \\mathcal{N}(\\mu_T = 12, \\sigma^2_T = 6)\\), \\(E \\sim \\mathcal{N}(\\mu_E = 0, \\sigma^2_T = 3)\\):\n\nset.seed(8394)\n\nn &lt;- 100\nSigma &lt;- matrix(c(6, 0, 0, 3), byrow = TRUE, ncol = 2)\nmu &lt;- c(12, 0)\ndat &lt;- mvrnorm(n, mu, Sigma, empirical = TRUE)\nT &lt;- dat[, 1]\nE &lt;- dat[, 2]\n\nLe istruzioni precedenti (empirical = TRUE) creano un campione di valori nei quali le medie e la matrice di covarianze assumono esattamente i valori richiesti. Possiamo dunque immaginare tale insieme di dati come la “popolazione”.\nSecondo la CTT, il punteggio osservato è \\(X = T + E\\). Simuliamo dunque il punteggio osservato \\(X\\) come:\n\nX &lt;- T + E\n\nLe prime 6 osservazioni così ottenute sono:\n\ntibble(X, T, E) |&gt; head()\n\n\nA tibble: 6 x 3\n\n\nX\nT\nE\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n15.698623\n16.765359\n-1.0667358\n\n\n13.657503\n12.248096\n1.4094073\n\n\n6.731979\n7.852136\n-1.1201563\n\n\n14.621813\n14.233699\n0.3881133\n\n\n10.606647\n10.187035\n0.4196115\n\n\n12.370288\n13.329971\n-0.9596831\n\n\n\n\n\nUn diagramma di dispersione è fornito nella figura seguente:\n\ntibble(X, T) |&gt;\nggplot(aes(T, X)) +\n    geom_point(position = position_jitter(w = .3, h = .3)) +\n    geom_abline(col = \"blue\")\n\n\n\n\n\n\n\n\nSecondo la CTT, il valore atteso di \\(T\\) è uguale al valore atteso di \\(X\\). Verifichiamo questa assunzione nei nostri dati\n\nmean(T) == mean(X)\n\nTRUE\n\n\nL’errore deve avere media zero:\n\nmean(E)\n\n-1.33660443824013e-17\n\n\nLe varianze dei punteggi veri, dei punteggi osservati e degli errori sono rispettivamente uguali a:\n\nc(var(T), var(X), var(E))  \n\n[1] 6 9 3",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#lerrore-standard-della-misurazione-sigma_e",
    "href": "chapters/ctt/01_ctt_1.html#lerrore-standard-della-misurazione-sigma_e",
    "title": "5  Fondamenti teorici",
    "section": "5.5 L’errore standard della misurazione \\(\\sigma_E\\)",
    "text": "5.5 L’errore standard della misurazione \\(\\sigma_E\\)\nLa radice quadrata della varianza degli errori di misurazione, ovvero la deviazione standard degli errori, \\(\\sigma_E\\), è la quantità fondamentale della CTT ed è chiamata errore standard della misurazione. La stima dell’errore standard della misurazione costituisce uno degli obiettivi più importanti della CTT.\nNel caso presente, abbiamo:\n\nsqrt(var(E))\n\n1.73205080756888\n\n\nRicordiamo che la deviazione standard indica quanto i dati di una distribuzione si discostano dalla media di quella distribuzione. È simile allo scarto tipico, ovvero la distanza media tra i valori della distribuzione e la loro media. Possiamo dunque utilizzare questa proprietà per descrivere il modo in cui la CTT interpreta la quantità \\(\\sigma_E\\): l’errore standard della misurazione \\(\\sigma_E\\) ci dice qual è, approssimativamente, la quantità attesa di variazione del punteggio osservato, se il test venisse somministrato ripetute volte al medesimo rispondente sotto le stesse condizioni (ovvero, in assenza di effetti di apprendimento o di fatica).",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#assiomi-della-teoria-classica",
    "href": "chapters/ctt/01_ctt_1.html#assiomi-della-teoria-classica",
    "title": "5  Fondamenti teorici",
    "section": "5.6 Assiomi della Teoria Classica",
    "text": "5.6 Assiomi della Teoria Classica\nLa CTT assume che gli errori siano delle variabili casuali incorrelate tra loro\n\\[\n\\rho(E_i, E_k \\mid T) = 0, \\qquad\\text{con}\\; i \\neq k,\n\\]\ne incorrelate con il punteggio vero,\n\\[\n\\rho(E, T) = 0,\n\\]\nle quali seguono una distribuzione gaussiana con media zero e deviazione standard pari a \\(\\sigma_E\\):\n\\[\nE \\sim \\mathcal{N}(0, \\sigma_E).\n\\]\nLa quantità \\(\\sigma_E\\) è appunto l’errore standard della misurazione. Sulla base di tali assunzioni la CTT deriva la formula dell’attendibilità di un test. Si noti che le assunzioni della CTT hanno una corrispondenza puntuale con le assunzioni su cui si basa il modello di regressione lineare.\nVerifichiamo le assunzioni per i dati dell’esempio.\n\ncor(E, T)\n\n-4.22920527591589e-17\n\n\n\nplot(density(E))\ncurve(dnorm(x, mean(E), sd(E)), add = TRUE, col = \"red\")",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#misure-parallele-tau-equivalenti-essenzialmente-tau-equivalenti-e-congenetiche",
    "href": "chapters/ctt/01_ctt_1.html#misure-parallele-tau-equivalenti-essenzialmente-tau-equivalenti-e-congenetiche",
    "title": "5  Fondamenti teorici",
    "section": "5.7 Misure parallele, \\(\\tau\\)-equivalenti, essenzialmente \\(\\tau\\)-equivalenti e congenetiche",
    "text": "5.7 Misure parallele, \\(\\tau\\)-equivalenti, essenzialmente \\(\\tau\\)-equivalenti e congenetiche\nNell’ambito della CTT, le misure della stessa entità (che possono essere item, sottoscale o test) possono essere classificate in base al loro livello di similarità. In questa sezione, verranno definiti quattro livelli di similarità: misure parallele, \\(\\tau\\)-equivalenti, essenzialmente \\(\\tau\\)-equivalenti e congeneriche. È importante notare che questi livelli sono gerarchici nel senso che il livello più alto (misure parallele) richiede la maggiore similarità, mentre i livelli inferiori nella gerarchia consentono una minore similarità nelle proprietà del test. Ad esempio, le misure parallele devono avere varianze di vero punteggio uguali, mentre le misure congenetiche non richiedono questa condizione.\nUn modo utile per comprendere questi livelli è riflettere sulle relazioni tra i punteggi veri di coppie di misure {cite:p}komaroff1997effect. Nella CTT, la relazione tra i punteggi veri su due misure (\\(t_i\\) e \\(t_j\\)) è espressa come:\n\\[\nt_i = a_{ij }+ b_{ij} * t_{j}.\n\\]\nSe il termine \\(b_{ij}\\) non è zero, le due misure hanno quote di punteggio vero differenti. Se il termine \\(a_{ij}\\) non è zero, le medie del punteggio vero delle misure sono diverse. I termini \\(a_{ij}\\) e \\(b_{ij}\\) sono sottoscritti per entrambe le misure (\\(i\\) e \\(j\\)), indicando che queste costanti possono variare tra le coppie di misure (anche se possono essere uguali tra tutte le coppie di misure).\n\n5.7.1 Misure parallele\nLe misure parallele rappresentano il tipo di similarità più forte tra le misure. Per le misure parallele, \\(a_{ij}\\) = 0 e \\(b_{ij}\\) = 1 per tutte le coppie di misure. Ciò implica che i punteggi veri di tutte le misure sono esattamente uguali. Di conseguenza, le varianze dei punteggi veri delle misure saranno anch’esse uguali. Le misure parallele presentano anche varianze di errore uguali. Queste proprietà (medie dei punteggi veri uguali, varianze dei punteggi veri uguali e varianze di errore uguali) implicano che le misure parallele avranno anche medie dei punteggi osservati uguali e varianze dei punteggi osservati uguali. Inoltre, i punteggi osservati avranno correlazioni uguali tra loro. Quest’ultima proprietà deriva dal fatto che i punteggi osservati sulle misure parallele sono perfettamente correlati linearmente. Le misure parallele, quindi, catturano un costrutto comune e misurano tale costrutto con la stessa precisione.\nSimuliamo i punteggi di due test paralleli in R.\n\nset.seed(2237) # setting the seed ensure reproducibility\nnum_person &lt;- 1000 # number of respondents\n# True scores for Test 1\nt1 &lt;- rnorm(num_person, mean = 20, sd = 5)\n# Error scores for Test 1\ne1 &lt;- rnorm(num_person, mean = 0, sd = 2)\n# Observed scores for Test 1\nx1 &lt;- t1 + e1\n# True scores for Test 2\nt2 &lt;- t1 # parallel tests have equal true scores\n# Error scores for Test 2\ne2 &lt;- rnorm(num_person, mean = 0, sd = 2)\n# Observed scores for Test 2\nx2 &lt;- t2 + e2\n\n\n# Merge into a data frame\ntest_df &lt;- data.frame(x1, x2)\n# Get means and variances\nmv &lt;- datasummary(x1 + x2 ~ Mean + Var,\n    data = test_df,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx2\n20.31\n30.27\n\n\n\n\n\n\ncor(test_df$x1, test_df$x2)\n\n0.865310361839848\n\n\nNel caso di due test paralleli, le medie e le varianze dei punteggi osservati sono (teoricamente) uguali; la correlazione descrive l’affidabilità del test.\n\n\n5.7.2 Misure \\(\\tau\\)-equivalenti\nLe misure \\(\\tau\\)-equivalenti, talvolta chiamate misure con equivalenza dei punteggi veri, presentano una forma di similarità leggermente più debole rispetto alle misure parallele. Come le misure parallele, le misure \\(\\tau\\)-equivalenti hanno \\(a_{ij}\\) = 0 e \\(b_{ij}\\) = 1 per tutte le coppie di misure; ciò significa che hanno varianze dei punteggi veri uguali. Tuttavia, le misure \\(\\tau\\)-equivalenti non sono obbligate ad avere varianze di errore uguali. È importante notare che la \\(\\tau\\)-equivalenza non richiede necessariamente varianze di errore diverse, ma semplicemente consente la possibilità di varianze di errore diverse. La \\(\\tau\\)-equivalenza, quindi, rilassa il vincolo che le varianze di errore debbano essere uguali. Pertanto, sebbene le misure \\(\\tau\\)-equivalenti debbano avere varianze dei punteggi veri uguali, possono o meno avere varianze di punteggio osservato uguali. Le misure \\(\\tau\\)-equivalenti presentano anche covarianze dei punteggi veri (e dei punteggi osservati) uguali tra loro.\nSimuliamo due misure \\(\\tau\\)-equivalenti.\n\nset.seed(2237) # setting the seed ensure reproducibility\nnum_person &lt;- 1000 # number of respondents\n# True scores for Test 1\nt1 &lt;- rnorm(num_person, mean = 20, sd = 5)\n# Error scores for Test 1\ne1 &lt;- rnorm(num_person, mean = 0, sd = 2)\n# Observed scores for Test 1\nx1 &lt;- t1 + e1\n# True scores for Test 2\nt2 &lt;- t1 # parallel tests have equal true scores\n# Error scores for Test 2\ne2 &lt;- rnorm(num_person, mean = 0, sd = 2)\n# Observed scores for Test 2\nx2 &lt;- t2 + e2\n\nSe conosciamo i punteggi veri, le stime dell’affidabilità di x1 e x2 sono:\n\n# Reliability for x1\nvar(t1) / var(x1)\n\n0.878424313030747\n\n\n\n# Reliability for x2\nvar(t2) / var(x2)\n\n0.847351804948915\n\n\n\n# Merge into a data frame\ntest_df &lt;- data.frame(x1, x2)\n# Get means and variances\nmv &lt;- datasummary(x1 + x2 ~ Mean + Var,\n    data = test_df,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx2\n20.31\n30.27\n\n\n\n\n\n\ncor(test_df$x1, test_df$x2)\n\n0.865310361839848\n\n\nIn conclusione, nel caso di due test \\(\\tau\\)-equivalenti, le medie e le varianze dei punteggi osservati sono (teoricamente) uguali. Anche in questo caso, la correlazione descrive l’affidabilità del test.\n\n\n5.7.3 Misure essenzialmente \\(\\tau\\)-equivalenti\nLe misure essenzialmente \\(\\tau\\)-equivalenti sono una forma leggermente più debole di \\(\\tau\\)-equivalenza in cui \\(a_{ij} \\neq 0\\) ma \\(b_{ij} = 1\\). Ciò significa che i punteggi veri delle misure essenzialmente \\(\\tau\\)-equivalenti possono differire per una costante additiva. Ad esempio, in una coppia di misure essentially \\(\\tau\\)-equivalenti, un punteggio vero potrebbe essere 2 in più dell’altro. Sebbene la \\(\\tau\\)-equivalenza essenziale ammetta differenze costanti tra i punteggi veri, ciò non è obbligatorio. Alcuni elementi di un insieme \\(\\tau\\)-equivalente possono avere medie di punteggio vero che differiscono per una costante e altri no. È importante notare che se due punteggi veri differiscono per una costante, sarebbero comunque perfettamente correlati linearmente. E sebbene tali punteggi veri possano avere medie diverse, non avrebbero varianze diverse. Pertanto, le loro varianze di punteggio vero sarebbero uguali, anche se le varianze di punteggio osservato potrebbero essere diverse poiché le misure essenzialmente \\(\\tau\\)-equivalenti possono avere varianze di errore diverse. I punteggi veri delle misure essenzialmente \\(\\tau\\)-equivalenti sono perfettamente correlati linearmente, quindi queste misure avrebbero covarianze di punteggio vero uguali tra loro. Tuttavia, né i punteggi \\(\\tau\\)-equivalenti né quelli essenazialmente \\(\\tau\\)-equivalenti avranno correlazioni uguali. Questo perché possono avere varianze di punteggio osservato e deviazioni standard diverse.\n\n# True scores for Test 3\nt3 &lt;- 5 + t1 # essentially tau-equivalent tests\n# Error scores for Test 3 (larger error SDs)\ne3 &lt;- rnorm(num_person, mean = 0, sd = 4)\n# Observed scores for Test 2\nx3 &lt;- t3 + e3\n\n\n# Merge into a data frame\ntest_df2 &lt;- data.frame(x1, x3)\n# Get means and variances\nmv &lt;- datasummary(x1 + x3 ~ Mean + Var,\n    data = test_df2,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx3\n25.41\n41.50\n\n\n\n\n\nSe conosciamo i punteggi veri, la stima dell’affidabilità di x3 è:\n\n# Reliability for x3\nvar(t3) / var(x3)\n\n0.618012243898734\n\n\nIn conclusione, nel caso di test essenzialmente \\(\\tau\\)-equivalenti, le medie e le varianze dei punteggi osservati sono diverse; la correlazione non è uguale all’affidabilità.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#misure-congeneriche",
    "href": "chapters/ctt/01_ctt_1.html#misure-congeneriche",
    "title": "5  Fondamenti teorici",
    "section": "5.8 Misure congeneriche",
    "text": "5.8 Misure congeneriche\nInfine, per le misure congeneriche, si ha \\(a_{ij} \\neq 0\\) e \\(b_{ij} \\neq 1\\). Le misure congeneriche non sono soggette a nessuna delle restrizioni precedenti. Non è richiesto che abbiano varianze di errore, varianze di punteggio vero, varianze di punteggio osservato, covarianze di punteggio osservato, correlazioni di punteggio osservato o medie uguali tra di loro. Le misure congeneriche hanno quindi le ipotesi meno restrittive e, di conseguenza, possono differire maggiormente tra loro rispetto alle altre tipologie.\n\n# True scores for Test 4\nt4 &lt;- 2 + 0.8 * t1\n# Error scores for Test 4 (larger error SDs)\ne4 &lt;- rnorm(num_person, mean = 0, sd = 3)\n# Observed scores for Test 2\nx4 &lt;- t4 + e4\n\n\n# Merge into a data frame\ntest_df3 &lt;- data.frame(x1, x4)\n# Get means and variances\nmv &lt;- datasummary(x1 + x4 ~ Mean + Var,\n    data = test_df3,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx4\n18.27\n24.23\n\n\n\n\n\nSe conosciamo i punteggi veri, la stima dell’affidabilità di x4 è:\n\n# Reliability for x4\nvar(t4) / var(x4)\n\n0.677398252481377\n\n\nNel caso di test congenerici, le medie e le varianze dei punteggi osservati sono diverse; la correlazione non è uguale all’affidabilità. Per distinguere test congenerici dai test essenzialmente \\(\\tau\\)-equivalenti sono necessari più di due test.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#considerazioni-conclusive",
    "href": "chapters/ctt/01_ctt_1.html#considerazioni-conclusive",
    "title": "5  Fondamenti teorici",
    "section": "5.9 Considerazioni conclusive",
    "text": "5.9 Considerazioni conclusive\nIn conclusione, il presente capitolo ha fornito una panoramica dei concetti fondamentali della CTT e ha introdotto quattro tipologie di misure. Le misure parallele sono caratterizzate da una forte somiglianza tra i punteggi veri di tutte le misure, mentre le misure \\(\\tau\\)-equivalenti mostrano un’equivalenza nelle varianze dei punteggi veri. Le misure essenzialmente \\(\\tau\\)-equivalenti, invece, consentono una certa variabilità nei punteggi veri, mentre le misure congeneriche presentano la minore restrizione tra le quattro tipologie, consentendo differenze sia nelle medie che nelle varianze dei punteggi veri. Comprendere queste differenze tra i tipi di misure è essenziale per valutare l’affidabilità e la validità di un test, nonché per interpretare correttamente i risultati ottenuti. Nelle prossime sezioni del corso, approfondiremo ulteriormente questi concetti e affronteremo l’applicazione pratica della CTT nello sviluppo e nella valutazione dei test psicometrici. Per un’approfondimento più dettagliato su questi temi, si consiglia di consultare McDonald (2013) e Lord e Novick (1968).",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/01_ctt_1.html#session-info",
    "href": "chapters/ctt/01_ctt_1.html#session-info",
    "title": "5  Fondamenti teorici",
    "section": "5.10 Session Info",
    "text": "5.10 Session Info\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 15.0\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] MASS_7.3-61        modelsummary_2.2.0 ggokabeito_0.1.0   viridis_0.6.5     \n [5] viridisLite_0.4.2  ggpubr_0.6.0       ggExtra_0.10.1     bayesplot_1.11.1  \n [9] gridExtra_2.3      patchwork_1.3.0    semTools_0.5-6     semPlot_1.1.6     \n[13] lavaan_0.6-18      psych_2.4.6.26     scales_1.3.0       markdown_1.13     \n[17] knitr_1.48         lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n[21] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[25] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.16.0  jsonlite_1.8.9     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5.1 farver_2.1.2      \n  [7] nloptr_2.1.1       rmarkdown_2.28     vctrs_0.6.5       \n [10] minqa_1.2.8        base64enc_0.1-3    rstatix_0.7.2     \n [13] htmltools_0.5.8.1  broom_1.0.6        Formula_1.2-5     \n [16] htmlwidgets_1.6.4  plyr_1.8.9         sandwich_3.1-1    \n [19] emmeans_1.10.4     zoo_1.8-12         uuid_1.2-1        \n [22] igraph_2.0.3       mime_0.12          lifecycle_1.0.4   \n [25] pkgconfig_2.0.3    Matrix_1.7-0       R6_2.5.1          \n [28] fastmap_1.2.0      shiny_1.9.1        digest_0.6.37     \n [31] OpenMx_2.21.12     fdrtool_1.2.18     colorspace_2.1-1  \n [34] rprojroot_2.0.4    Hmisc_5.1-3        labeling_0.4.3    \n [37] fansi_1.0.6        timechange_0.3.0   abind_1.4-8       \n [40] compiler_4.4.1     withr_3.0.1        glasso_1.11       \n [43] htmlTable_2.4.3    backports_1.5.0    carData_3.0-5     \n [46] ggsignif_0.6.4     corpcor_1.6.10     gtools_3.9.5      \n [49] tools_4.4.1        pbivnorm_0.6.0     foreign_0.8-87    \n [52] zip_2.3.1          httpuv_1.6.15      nnet_7.3-19       \n [55] glue_1.7.0         quadprog_1.5-8     promises_1.3.0    \n [58] nlme_3.1-166       lisrelToR_0.3      grid_4.4.1        \n [61] pbdZMQ_0.3-13      checkmate_2.3.2    cluster_2.1.6     \n [64] reshape2_1.4.4     generics_0.1.3     gtable_0.3.5      \n [67] tzdb_0.4.0         data.table_1.16.0  hms_1.1.3         \n [70] car_3.1-2          utf8_1.2.4         tables_0.9.31     \n [73] sem_3.1-16         pillar_1.9.0       IRdisplay_1.1     \n [76] rockchalk_1.8.157  later_1.3.2        splines_4.4.1     \n [79] lattice_0.22-6     survival_3.7-0     kutils_1.73       \n [82] tidyselect_1.2.1   miniUI_0.1.1.1     pbapply_1.7-2     \n [85] stats4_4.4.1       xfun_0.47          qgraph_1.9.8      \n [88] arm_1.14-4         stringi_1.8.4      boot_1.3-31       \n [91] evaluate_1.0.0     codetools_0.2-20   mi_1.1            \n [94] cli_3.6.3          RcppParallel_5.1.9 IRkernel_1.3.2    \n [97] rpart_4.1.23       xtable_1.8-4       repr_1.1.7        \n[100] munsell_0.5.1      Rcpp_1.0.13        coda_0.19-4.1     \n[103] png_0.1-8          XML_3.99-0.17      parallel_4.4.1    \n[106] jpeg_0.1-10        lme4_1.1-35.5      mvtnorm_1.3-1     \n[109] insight_0.20.4     openxlsx_4.2.7.1   crayon_1.5.3      \n[112] rlang_1.1.4        multcomp_1.4-26    mnormt_2.1.1      \n\n\n\n\n\n\nAllen, Mary J, e Wendy M Yen. 2001. Introduction to measurement theory. Waveland Press.\n\n\nBollen, Kenneth, e Richard Lennox. 1991. «Conventional wisdom on measurement: A structural equation perspective.» Psychological bulletin 110 (2): 305–14.\n\n\nKline, Paul. 2013. Handbook of psychological testing. Routledge.\n\n\nLord, Frederic M, e Melvin R Novick. 1968. Statistical theories of mental test scores. Addison-Wesley.\n\n\nMcDonald, Roderick P. 2013. Test theory: A unified treatment. Psychology Press.\n\n\nNunnally, Jum C. 1994. Psychometric theory. McGraw-Hill.\n\n\nPetersen, Isaac T. 2024. Principles of psychological assessment: With applied examples in R. CRC Press.\n\n\nSpearman, C. 1904. «General intelligence objectively determined and measured». American Journal of Psychology 15: 201–93.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fondamenti teorici</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html",
    "href": "chapters/ctt/02_ctt_2.html",
    "title": "6  L’affidabilità del test",
    "section": "",
    "text": "6.1 Introduzione\nL’affidabilità è un principio fondamentale nella teoria della misurazione, essenziale per garantire coerenza, stabilità e precisione nelle misurazioni effettuate in vari contesti. Nell’ambito del testing psicologico, è cruciale che i punteggi mostrino un grado di consistenza accettabile per essere considerati significativi. Questo concetto è particolarmente rilevante, poiché i punteggi possono variare a seconda delle specifiche condizioni di misurazione, rendendo necessario l’impiego di diversi metodi per valutare l’affidabilità di un test.\nEsploriamo i vari metodi utilizzati per valutare l’affidabilità:\nCentrali in queste misurazioni sono l’errore di misurazione e l’errore standard di misurazione. Quest’ultimo offre un modo per quantificare l’errore di misurazione. La teoria della generalizzabilità e la teoria della risposta all’item, entrambe moderne teorie dei test, forniscono strumenti sofisticati per analizzare e interpretare l’errore di misurazione, migliorando così la precisione dei test.\nIn questo capitolo, ci concentreremo sulla comprensione dell’affidabilità secondo la Teoria Classica dei Test (CTT), esaminando come misurare la consistenza e garantire l’accuratezza delle valutazioni psicologiche. Questa approfondita analisi dell’affidabilità è fondamentale per assicurare la validità e l’efficacia delle misurazioni psicologiche.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html#introduzione",
    "href": "chapters/ctt/02_ctt_2.html#introduzione",
    "title": "6  L’affidabilità del test",
    "section": "",
    "text": "Affidabilità Test-Retest (Coefficiente di Stabilità): Questo metodo valuta la coerenza dei punteggi nel tempo. Si somministra lo stesso test a un gruppo di individui in due momenti distinti, e la correlazione tra i punteggi ottenuti fornisce un’indicazione dell’affidabilità. Tuttavia, la limitazione di questo metodo risiede nel fatto che variazioni nelle condizioni ambientali o psicologiche possono influenzare i risultati nel tempo.\nAffidabilità delle Forme Alternative (Coefficiente di Equivalenza): Utile quando esistono diverse versioni di un test, questo metodo serve a verificare se queste versioni producono punteggi simili e coerenti. È cruciale per assicurare che le diverse forme del test siano equivalenti in termini di difficoltà e contenuto.\nConsistenza Interna: Questo metodo misura il grado in cui gli elementi individuali di un test sono correlati tra loro. È particolarmente importante in test che includono molteplici item, dove la consistenza interna alta suggerisce che gli item misurano lo stesso costrutto in modo uniforme.\nAffidabilità Inter-Osservatori: Questo approccio valuta la coerenza tra le valutazioni di diversi osservatori. È fondamentale in situazioni dove più persone valutano lo stesso fenomeno, assicurando che i loro giudizi siano uniformi e affidabili.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html#lattendibilità-del-test",
    "href": "chapters/ctt/02_ctt_2.html#lattendibilità-del-test",
    "title": "6  L’affidabilità del test",
    "section": "6.2 L’attendibilità del test",
    "text": "6.2 L’attendibilità del test\nPer definire l’attendibilità, la CTT si basa su due informazioni chiave:\n\nLa varianza dei punteggi osservati.\nLa correlazione tra il punteggio osservato e il punteggio vero.\n\nVedremo come ottenere queste informazioni utilizzando le assunzioni del modello statistico alla base della CTT.\n\n6.2.1 La varianza del punteggio osservato\nLa varianza del punteggio osservato \\(X\\) è uguale alla somma della varianza del punteggio vero e della varianza dell’errore di misurazione:\n\\[\n\\sigma^2_X =   \\sigma_T^2 + \\sigma_E^2.\n\\tag{6.1}\\]\nLa dimostrazione è la seguente. La varianza del punteggio osservato è uguale a\n\\[\n\\sigma^2_X =  \\mathbb{V}(T+E) =  \\sigma_T^2 + \\sigma_E^2 + 2 \\sigma_{TE}.\n\\tag{6.2}\\]\nDato che \\(\\sigma_{TE}=\\rho_{TE}\\sigma_T \\sigma_E=0\\), in quanto \\(\\rho_{TE}=0\\), ne segue che\n\\[\n\\sigma^2_X =   \\sigma_T^2 + \\sigma_E^2.\n\\]\nPer fare un esempio concreto, riprendiamo la simulazione del capitolo precedente.\n\nset.seed(8394)\n\nn &lt;- 100\nSigma &lt;- matrix(c(6, 0, 0, 3), byrow = TRUE, ncol = 2)\nmu &lt;- c(12, 0)\ndat &lt;- mvrnorm(n, mu, Sigma, empirical = TRUE)\nT &lt;- dat[, 1]\nE &lt;- dat[, 2]\nX &lt;- T + E\n\ntibble(X, T, E) |&gt; head()\n\n\nA tibble: 6 × 3\n\n\nX\nT\nE\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n15.698623\n16.765359\n-1.0667358\n\n\n13.657503\n12.248096\n1.4094073\n\n\n6.731979\n7.852136\n-1.1201563\n\n\n14.621813\n14.233699\n0.3881133\n\n\n10.606647\n10.187035\n0.4196115\n\n\n12.370288\n13.329971\n-0.9596831\n\n\n\n\n\n\nvar(X) == var(T) + var(E)\n\nTRUE\n\n\n\n\n6.2.2 La covarianza tra punteggio osservato e punteggio vero\nLa covarianza tra punteggio osservato \\(X\\) e punteggio vero \\(T\\) è uguale alla varianza del punteggio vero:\n\\[\n\\sigma_{X T} = \\sigma_T^2.\n\\tag{6.3}\\]\nLa dimostrazione è la seguente. La covarianza tra punteggio osservato e punteggio vero è uguale a\n\\[\n\\begin{aligned}\n\\sigma_{X T} &= \\mathbb{E}(XT) - \\mathbb{E}(X)\\mathbb{E}(T)\\notag\\\\\n&=  \\mathbb{E}[(T+E)T] - \\mathbb{E}(T+E)\\mathbb{E}(T)\\notag\\\\\n&=  \\mathbb{E}(T^2) + \\underbrace{\\mathbb{E}(ET)}_{=0} - [\\mathbb{E}(T)]^2 -  \\underbrace{\\mathbb{E}(E)}_{=0} \\mathbb{E}(T)\\notag\\\\\n&=\\mathbb{E}(T^2) - [\\mathbb{E}(T)]^2\\notag \\\\\n&= \\sigma_T^2.\n\\end{aligned}\n\\]\nVerifichiamo per i dati dell’esempio.\n\ncov(X, T) == var(T)\n\nTRUE\n\n\n\n\n6.2.3 Correlazione tra punteggio osservato e punteggio vero\nLa correlazione tra punteggio osservato \\(X\\) e punteggio vero \\(T\\) è uguale al rapporto tra la covarianza tra \\(X\\) e \\(T\\) divisa per il prodotto delle due deviazioni standard:\n\\[\n\\rho_{XT} = \\frac{\\sigma_{XT}}{\\sigma_X \\sigma_T} = \\frac{\\sigma^2_{T}}{\\sigma_X \\sigma_T} = \\frac{\\sigma_{T}}{\\sigma_X}.\n\\tag{6.4}\\]\nDunque, la correlazione tra il punteggio osservato e il punteggio vero è uguale al rapporto tra la deviazione standard dei punteggi veri e la deviazione standard dei punteggi osservati.\nVerifichiamo per i dati dell’esempio.\n\ncor(X, T) \n\n0.816496580927726\n\n\n\nsd(T) / sd(X)\n\n0.816496580927726\n\n\n\n\n6.2.4 Definizione e significato dell’attendibilità\nSulla base dell’Equazione 6.4, possiamo giungere alla definizione di attendibilità. La Teoria della Misurazione Classica (CTT) definisce l’attendibilità di un test (o di un singolo elemento) come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato. In altre parole, l’attendibilità rappresenta il quadrato della correlazione tra il punteggio osservato \\(X\\) e il punteggio vero \\(T\\):\n\\[\n\\begin{equation}\n\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_{X}^2}.\n\\end{equation}\n\\]\nQuesta formula è il concetto fondamentale della CTT e misura il livello di variazione del punteggio vero rispetto alla variazione del punteggio osservato.\nAdesso possiamo procedere a verificare questa relazione utilizzando i dati forniti nell’esempio.\n\ncor(X, T)^2\n\n0.666666666666667\n\n\n\nvar(T) / var(X)\n\n0.666666666666667\n\n\nDato che \\(\\sigma^2_X = \\sigma_T^2 + \\sigma_E^2\\), in base alla {ref}eq-reliability-1 possiamo scrivere\n\\[\n\\begin{equation}\n\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2} =\\frac{\\sigma_{X}^2 - \\sigma^2_E}{\\sigma_X^2} = 1-\\frac{\\sigma_{E}^2}{\\sigma_{X}^2}.\n\\end{equation}\n\\tag{6.5}\\]\n\n1 - (var(E) / var(X))\n\n0.666666666666667\n\n\nDall’Equazione 6.5, possiamo dedurre che il coefficiente di affidabilità assume il valore di \\(1\\) quando la varianza degli errori \\(\\sigma_{E}^2\\) è nulla, e assume il valore di \\(0\\) quando la varianza degli errori è uguale alla varianza del punteggio osservato. Quindi, il coefficiente di affidabilità è un valore assoluto situato nell’intervallo tra \\(0\\) e \\(1\\).",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html#attendibilità-e-modello-di-regressione-lineare",
    "href": "chapters/ctt/02_ctt_2.html#attendibilità-e-modello-di-regressione-lineare",
    "title": "6  L’affidabilità del test",
    "section": "6.3 Attendibilità e modello di regressione lineare",
    "text": "6.3 Attendibilità e modello di regressione lineare\nIn parole semplici, la CTT si basa sul modello di regressione lineare, dove i punteggi osservati sono considerati come variabile dipendente e i punteggi veri come variabile indipendente. Il coefficiente di attendibilità \\(\\rho_{XT}^2\\) rappresenta la proporzione di varianza nella variabile dipendente spiegata dalla variabile indipendente in un modello di regressione lineare con una pendenza unitaria e un’intercetta di zero. In altre parole, il coefficiente di attendibilità è equivalente al coefficiente di determinazione del modello di regressione.\nPer rendere questo concetto più chiaro, possiamo tornare a considerare i dati simulati come esempio.\nLa motivazione di questa simulazione è quella di mettere in relazione il coefficiente di attendibilità, calcolato con la formula della CTT (come abbiamo fatto sopra), con il modello di regressione lineare. Analizziamo dunque i dati della simulazione mediante il seguente modello di regressione lineare:\n\\[\nX = a + b T + E.\n\\]\nUsando \\(\\textsf{R}\\) otteniamo:\n\nfm &lt;- lm(X ~ T)\nsummary(fm)\n\n\nCall:\nlm(formula = X ~ T)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.4343 -0.9720 -0.0865  1.0803  3.7347 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 9.948e-15  8.746e-01       0        1    \nT           1.000e+00  7.143e-02      14   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.741 on 98 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6633 \nF-statistic:   196 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nSi noti che la retta di regressione ha intercetta 0 e pendenza 1. Questo è coerente con l’assunzione \\(\\mathbb{E}(X) = \\mathbb{E}(T)\\). Ma il risultato più importante di questa simulazione è che il coefficiente di determinazione (\\(R^2\\) = 0.67) del modello di regressione \\(X = 0 + 1 \\times T + E\\) è identico al coefficiente di attendibilità calcolato con la formula \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\):\n\nvar(T) / var(X)\n\n0.666666666666667\n\n\nQuesti risultati ci permettono di interpretare il coefficiente di affidabilità nel seguente modo: l’affidabilità di un test rappresenta la porzione di varianza presente nel punteggio osservato \\(X\\) che viene spiegata dalla regressione di \\(X\\) rispetto al punteggio vero \\(T\\). Questo risultato è stato ottenuto mediante una regressione lineare, dove il coefficiente angolare \\(\\beta\\) è uguale a 1 e l’intercetta \\(\\alpha\\) è uguale a 0.\nInoltre, ricordiamo che la radice quadrata della varianza degli errori è l’errore standard della misurazione, \\(\\sigma_E\\). La quantità \\(\\sqrt{\\sigma_E^2}\\) fornisce una misura della dispersione del punteggio osservato attorno al valore vero, nella condizione ipotetica di ripetute somministrazioni del test:\n\nsqrt(var(E) * 99 / 98)\n\n1.74086537242199\n\n\nL’output della funzione lm() rende chiaro che l’errore standard della misurazione della CTT è identico all’errore standard della regressione nel caso di un modello di regressione definito come abbiamo fatto sopra.\nNel codice precedente è stato incluso il termine correttivo 99/98. Questa correzione è necessaria poiché, mentre R calcola la deviazione standard con \\(n-1\\) al denominatore, l’errore standard della regressione richiede \\(n-2\\) al denominatore.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html#misurazioni-parallele-e-affidabilità",
    "href": "chapters/ctt/02_ctt_2.html#misurazioni-parallele-e-affidabilità",
    "title": "6  L’affidabilità del test",
    "section": "6.4 Misurazioni parallele e affidabilità",
    "text": "6.4 Misurazioni parallele e affidabilità\nL’equazione \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\) definisce il coefficiente di affidabilità, ma non ci fornisce gli strumenti pratici per calcolarlo direttamente. Questo perché la varianza del punteggio reale \\(\\sigma_{T}^2\\) rappresenta un valore sconosciuto. Il metodo utilizzato dalla CTT per ottenere una stima empirica dell’attendibilità è quello delle forme parallele del test. In pratica, se è possibile creare versioni alternative del test che siano equivalenti in termini di contenuto, modalità di risposta e caratteristiche statistiche, allora diventa possibile ottenere una stima empirica del coefficiente di affidabilità.\nSecondo la CTT, due test \\(X=T+E\\) e \\(X^\\prime=T^\\prime+E^\\prime\\) sono considerati misurazioni parallele della stessa abilità latente quando:\n\n\\(T = T^\\prime\\),\n\\(\\mathbb{V}(E) = \\mathbb{V}(E^\\prime)\\).\n\nQueste premesse implicano che \\(\\mathbb{E}(X) = \\mathbb{E}(X^\\prime)\\).\nLa dimostrazione procede come segue. Considerando che \\(\\mathbb{E}(X) = T\\) e \\(\\mathbb{E}(X^\\prime) = T\\), è evidente che \\(\\mathbb{E}(X) =\\mathbb{E}(X^\\prime)\\) poiché \\(\\mathbb{E}(E) = \\mathbb{E}(E^\\prime) = 0\\).\nIn modo analogo, l’uguaglianza delle varianze nei punteggi osservati delle due misurazioni parallele deve essere verificata, cioè \\(\\mathbb{V}(X) = \\mathbb{V}(X^\\prime)\\).\nQuesta dimostrazione si sviluppa come segue. Per \\(X\\), possiamo scrivere\n\\[\\mathbb{V}(X) = \\mathbb{V}(T + E) = \\mathbb{V}(T) + \\mathbb{V}(E);\\]\nmentre per \\(X^\\prime\\) possiamo scrivere\n\\[\\mathbb{V}(X^\\prime) = \\mathbb{V}(T^\\prime + E^\\prime) = \\mathbb{V}(T^\\prime) + \\mathbb{V}(E^\\prime).\\]\nPoiché sappiamo che \\(\\mathbb{V}(E) = \\mathbb{V}(E^\\prime)\\) e che \\(T = T^\\prime\\), possiamo dedurre che \\(\\mathbb{V}(X) = \\mathbb{V}(X^\\prime)\\).\nIn aggiunta, è importante notare che per costruzione gli errori \\(E\\) e \\(E^\\prime\\) sono incorrelati sia con \\(T\\) che tra di loro.\n\n6.4.1 La correlazione tra due forme parallele del test\nOra procediamo a dimostrare che, secondo le ipotesi della Teoria della CTT, la correlazione tra due versioni parallele di un test è effettivamente equivalente al rapporto tra la varianza del punteggio reale e la varianza del punteggio osservato. Come discusso nel capitolo precedente, le misurazioni parallele rappresentano il grado più elevato di somiglianza tra due diverse versioni di un test.\nLa dimostrazione è la seguente. Consideriamo, senza perdita di generalità, che \\(\\mathbb{E}(X) = \\mathbb{E}(X') = \\mathbb{E}(T) = 0\\). Questa scelta ci consente di scrivere:\n\\[\n\\begin{aligned}\n\\rho_{X X^\\prime} &= \\frac{\\sigma(X, X^\\prime)}{\\sigma(X) \\sigma(X^\\prime)} \\\\\n&= \\frac{\\mathbb{E}(XX^\\prime)}{\\sigma(X) \\sigma(X^\\prime)} \\\\\n&= \\frac{\\mathbb{E}[(T+E)(T+E^\\prime)]}{\\sigma(X) \\sigma(X^\\prime)} \\\\\n&= \\frac{\\mathbb{E}(T^2) + \\mathbb{E}(TE^\\prime) + \\mathbb{E}(TE) + \\mathbb{E}(EE^\\prime)}{\\sigma(X) \\sigma(X^\\prime)}.\n\\end{aligned}\n\\]\nTuttavia, sappiamo che \\(\\mathbb{E}(TE) = \\mathbb{E}(TE^\\prime) = \\mathbb{E}(EE^\\prime) = 0\\). Inoltre, \\(\\sigma(X) = \\sigma(X^\\prime) = \\sigma_X\\). Pertanto, giungiamo a:\n\\[\n\\rho_{X X^\\prime} = \\frac{\\mathbb{E}(T^2)}{\\sigma_X \\sigma_X} = \\frac{\\sigma^2_T}{\\sigma^2_X}.\n\\] {#eq:3-3-5}\nNotiamo che il risultato ottenuto, insieme all’equazione che definisce il coefficiente di affidabilità \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\), presentano entrambi la stessa espressione a destra del segno di uguale. Questo conduce a un risultato cruciale: il coefficiente di affidabilità, ossia il quadrato della correlazione tra il punteggio osservato e il punteggio reale, è identico alla correlazione tra i punteggi osservati di due versioni parallele del test:\n\\[\n\\rho^2_{XT} =  \\rho_{XX^\\prime}.\n\\tag{6.6}\\]\nQuesta conclusione è di notevole importanza in quanto consente di esprimere la variabile inosservabile \\(\\rho^2_{XT}\\) in termini della variabile osservabile \\(\\rho_{XX^\\prime}\\), la quale può essere calcolata in base ai punteggi osservati delle due forme parallele del test. Fondamentalmente, la stima di \\(\\rho^2_{XT}\\) si semplifica nella stima di \\(\\rho^2_{XX^\\prime}\\). Questo spiega l’importanza dell’equazione {eq}eq-rho2xt-rhoxx nella CTT. Inoltre, è da sottolineare che l’equazione {ref}eq:rho2xt-rhoxx fornisce una giustificazione per l’utilizzo della correlazione split-half come misura di affidabilità.\n\n\n6.4.2 La correlazione tra punteggio osservato e punteggio vero\nEsaminiamo adesso la correlazione tra il punteggio osservato e il punteggio reale. L’Equazione 6.6 può essere riformulata come segue:\n\\[\n\\rho_{XT} = \\sqrt{\\rho_{XX^\\prime}}.\n\\]\nIn altre parole, la radice quadrata del coefficiente di affidabilità equivale alla correlazione tra il punteggio osservato e il punteggio reale.\nProcediamo ora a verificare questa relazione utilizzando i dati dell’esempio.\n\nsqrt(var(T) / var(X))\n\n0.816496580927726\n\n\n\ncor(X, T)\n\n0.816496580927726\n\n\n\n\n6.4.3 I fattori che influenzano l’attendibilità\nConsiderando le tre equazioni:\n\\[\n\\rho^2_{XT} = \\rho_{XX'},\\quad\n\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}, \\quad\n\\rho_{XT}^2 = 1-\\frac{\\sigma_{E}^2}{\\sigma_X^2},\n\\]\npossiamo affermare che esistono tre modi equivalenti per giungere alla conclusione che l’attendibilità di un test è elevata. L’attendibilità di un test è considerata alta quando si verificano le seguenti condizioni:\n\nLa correlazione tra le forme parallele del test è elevata.\nLa varianza del punteggio vero è ampia rispetto alla varianza del punteggio osservato.\nLa varianza dell’errore di misurazione è ridotta rispetto alla varianza del punteggio osservato.\n\nQueste considerazioni rivestono un’importanza fondamentale nella progettazione di un test. In particolare, l’equazione \\(\\rho^2_{XT} = \\rho_{XX'}\\) fornisce un criterio per la selezione degli item da includere nel test. Se interpretiamo \\(\\rho_{XX'}\\) come la correlazione tra due item, allora gli item che presentano la correlazione più elevata tra di loro dovrebbero essere inclusi nel test. In questo modo, l’attendibilità del test aumenta, poiché gli item selezionati risultano fortemente correlati con il punteggio vero.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html#conclusioni",
    "href": "chapters/ctt/02_ctt_2.html#conclusioni",
    "title": "6  L’affidabilità del test",
    "section": "6.5 Conclusioni",
    "text": "6.5 Conclusioni\nL’affidabilità costituisce un concetto fondamentale all’interno della teoria della misurazione, poiché si riferisce alla coerenza dei punteggi in varie situazioni, come diverse configurazioni di item, versioni del test o momenti di somministrazione. Nel corso di questo capitolo, abbiamo esplorato le basi teoriche dell’affidabilità. All’interno della CTT, l’affidabilità è definita come la correlazione tra il punteggio vero e il punteggio osservato, oppure, equivalentemente, come uno meno la correlazione tra il punteggio di errore e il punteggio osservato. Dal momento che il punteggio vero non è direttamente osservabile, è necessario ricorrere a metodi alternativi per stimare l’affidabilità. Il metodo proposto dalla CTT per ottenere tale stima è quello della correlazione dei punteggi ottenuti da due test paralleli.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/02_ctt_2.html#session-info",
    "href": "chapters/ctt/02_ctt_2.html#session-info",
    "title": "6  L’affidabilità del test",
    "section": "6.6 Session Info",
    "text": "6.6 Session Info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] MASS_7.3-60.0.1    modelsummary_1.4.5 ggokabeito_0.1.0   viridis_0.6.5     \n [5] viridisLite_0.4.2  ggpubr_0.6.0       ggExtra_0.10.1     bayesplot_1.11.1  \n [9] gridExtra_2.3      patchwork_1.2.0    semTools_0.5-6     semPlot_1.1.6     \n[13] lavaan_0.6-17      psych_2.4.1        scales_1.3.0       markdown_1.12     \n[17] knitr_1.45         lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n[21] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[25] tibble_3.2.1       ggplot2_3.4.4      tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5   nloptr_2.0.3      \n  [7] rmarkdown_2.25     vctrs_0.6.5        minqa_1.2.6       \n [10] base64enc_0.1-3    rstatix_0.7.2      htmltools_0.5.7   \n [13] broom_1.0.5        Formula_1.2-5      htmlwidgets_1.6.4 \n [16] plyr_1.8.9         sandwich_3.1-0     emmeans_1.10.0    \n [19] zoo_1.8-12         uuid_1.2-0         igraph_2.0.2      \n [22] mime_0.12          lifecycle_1.0.4    pkgconfig_2.0.3   \n [25] Matrix_1.6-5       R6_2.5.1           fastmap_1.1.1     \n [28] shiny_1.8.0        digest_0.6.34      OpenMx_2.21.11    \n [31] fdrtool_1.2.17     colorspace_2.1-0   rprojroot_2.0.4   \n [34] Hmisc_5.1-1        fansi_1.0.6        timechange_0.3.0  \n [37] abind_1.4-5        compiler_4.3.2     withr_3.0.0       \n [40] glasso_1.11        htmlTable_2.4.2    backports_1.4.1   \n [43] carData_3.0-5      ggsignif_0.6.4     corpcor_1.6.10    \n [46] gtools_3.9.5       tools_4.3.2        pbivnorm_0.6.0    \n [49] foreign_0.8-86     zip_2.3.1          httpuv_1.6.14     \n [52] nnet_7.3-19        glue_1.7.0         quadprog_1.5-8    \n [55] nlme_3.1-164       promises_1.2.1     lisrelToR_0.3     \n [58] grid_4.3.2         pbdZMQ_0.3-11      checkmate_2.3.1   \n [61] cluster_2.1.6      reshape2_1.4.4     generics_0.1.3    \n [64] gtable_0.3.4       tzdb_0.4.0         data.table_1.15.0 \n [67] hms_1.1.3          car_3.1-2          utf8_1.2.4        \n [70] tables_0.9.17      sem_3.1-15         pillar_1.9.0      \n [73] IRdisplay_1.1      rockchalk_1.8.157  later_1.3.2       \n [76] splines_4.3.2      lattice_0.22-5     survival_3.5-8    \n [79] kutils_1.73        tidyselect_1.2.0   miniUI_0.1.1.1    \n [82] pbapply_1.7-2      stats4_4.3.2       xfun_0.42         \n [85] qgraph_1.9.8       arm_1.13-1         stringi_1.8.3     \n [88] boot_1.3-29        evaluate_0.23      codetools_0.2-19  \n [91] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [94] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [97] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n[100] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n[103] parallel_4.3.2     ellipsis_0.3.2     jpeg_0.1-10       \n[106] lme4_1.1-35.1      mvtnorm_1.2-4      insight_0.19.8    \n[109] openxlsx_4.2.5.2   crayon_1.5.2       rlang_1.1.3       \n[112] multcomp_1.4-25    mnormt_2.1.1",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>L'affidabilità del test</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html",
    "href": "chapters/ctt/03_ctt_3.html",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "",
    "text": "7.1 Introduzione\nNel capitolo precedente abbiamo evidenziato come i punteggi dei test possano variare in diverse situazioni, ad esempio, in relazione alle differenze tra insiemi di item o alle variazioni tra diverse somministrazioni o valutazioni. A tal fine, sono stati sviluppati vari metodi per valutare l’affidabilità, o quanto i risultati del test siano stabili e coerenti, considerando diversi tipi di errori casuali.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#la-definizione-di-attendibilità",
    "href": "chapters/ctt/03_ctt_3.html#la-definizione-di-attendibilità",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.2 La Definizione di Attendibilità",
    "text": "7.2 La Definizione di Attendibilità\nLa Teoria Classica dei Test (CTT) assume che il “punteggio osservato” \\(X\\) sia composto da due componenti: il “punteggio vero” \\(T\\) e l’errore di misurazione \\(E\\). Formalmente, questa relazione può essere espressa come \\(X = T + E\\), dove \\(E\\) rappresenta l’errore di misurazione che si sovrappone al “punteggio vero” \\(T\\).\nSecondo questa definizione, l’errore per una singola misurazione è dato dalla differenza tra il “punteggio osservato” e il “punteggio vero”, cioè \\(E = X - T\\). È importante notare che l’errore atteso è zero (\\(E(X) = 0\\)), e che non vi è alcuna correlazione o covarianza tra l’errore e il “punteggio vero” (\\(Cov(E,T) = 0\\)).\nCon queste premesse, l’affidabilità può essere definita come il quadrato della correlazione tra il “punteggio vero” e il “punteggio osservato”, ossia \\(\\rho^2_{XT}\\). In altre parole, rappresenta la frazione di varianza del “punteggio osservato” che è spiegata dal “punteggio vero”. Un’alta affidabilità (\\(\\rho^2_{XT} = 1\\)) indica che l’errore di misurazione è praticamente assente, mentre un valore inferiore indica la presenza di un errore significativo.\nUn’altra prospettiva per comprendere l’affidabilità è considerare la relazione tra le varianze del “punteggio osservato”, del “punteggio vero” e dell’errore. Secondo l’assunzione di indipendenza tra l’errore e il “punteggio vero”, le varianze osservate, vere e di errore sono correlate secondo l’equazione \\(\\sigma^2_X = \\sigma^2_T + \\sigma^2_E\\). Di conseguenza, \\(\\rho^2_{XT}\\) può essere interpretato come la proporzione di varianza del “punteggio osservato” spiegata dal “punteggio vero”, o come 1 meno il rapporto della varianza dell’errore rispetto alla varianza del “punteggio osservato”.\nIn sintesi, l’affidabilità di un test può essere concepita in diversi modi, riflettendo la sua relazione con il concetto di “punteggio vero” e l’errore di misurazione. La sfida successiva è quella di stimare l’affidabilità in modo accurato, tenendo conto di queste considerazioni.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#approcci-per-stimare-laffidabilità",
    "href": "chapters/ctt/03_ctt_3.html#approcci-per-stimare-laffidabilità",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.3 Approcci per Stimare l’Affidabilità",
    "text": "7.3 Approcci per Stimare l’Affidabilità\nPer stimare l’affidabilità (\\(\\rho_{TT'}\\)), ci troviamo di fronte alla sfida di dover stimare una delle due componenti non direttamente osservabili: il punteggio vero o la varianza dell’errore. Ma come possiamo affrontare questa sfida? La risposta è complessa e dipende da come intendiamo concettualizzare la varianza dell’errore (\\(\\sigma^2_E\\)).\n\nAffidabilità delle Forme Parallele: Se il nostro interesse principale è misurare quanto accuratamente possiamo stimare il punteggio vero dai dati osservati, potrebbe essere più appropriato considerare \\(\\sigma^2_E\\) come l’incertezza nella nostra stima attraverso ripetute somministrazioni di una misura equivalente. Questo approccio ci porta alla definizione di affidabilità delle forme parallele.\nConsistenza Interna: Se invece vogliamo valutare se più elementi su una scala riflettono lo stesso costrutto sottostante, possiamo utilizzare un concetto simile all’Alpha di Cronbach (\\(\\alpha\\)). Questo ci porta alla definizione di affidabilità come consistenza interna.\nCoerenza Temporale (Affidabilità Test-Retest): Se ci interessa la coerenza di una misura nel tempo, allora \\(\\sigma^2_E\\) potrebbe essere meglio interpretato come la varianza non comune attraverso diverse somministrazioni della stessa misura su un periodo di tempo arbitrario. Questo concetto ci conduce alla definizione di coerenza temporale o affidabilità test-retest.\n\nIn sostanza, le equazioni dell’affidabilità presentate in precedenza possono essere applicate a ciascuno dei tre tipi di affidabilità descritti sopra. La differenza fondamentale risiede nella nostra concezione e nel calcolo di \\(\\sigma^2_E\\), che varia a seconda del contesto e degli obiettivi specifici dell’analisi.\n\n7.3.1 Affidabilità come Consistenza Interna\nIniziamo esaminando tre scenari distinti che illustrano le possibili relazioni tra gli item di un test: quelli con indicatori congenerici, tau-equivalenti e paralleli. Nell’ambito della CTT, sono disponibili due indicatori principali per valutare l’affidabilità in termini di coerenza interna, a seconda del tipo di relazione tra gli item presunta: l’indice alpha di Cronbach per gli item tau-equivalenti e l’indice di Spearman-Brown per gli item paralleli.\nOltre alla consistenza interna, esistono altre misure di affidabilità, tra cui la affidabilità test-retest, la affidabilità tra forme alternative, la affidabilità tra valutatori, la affidabilità dei punteggi compositi e la affidabilità dei punteggi delle differenze.\nAl centro della misurazione dell’affidabilità c’è l’errore di misurazione, e in precedenza abbiamo esaminato come lo standard error of measurement sia uno dei metodi per valutare l’errore di misurazione.\nVa notato che ci riferiamo all’affidabilità come una stima, poiché l’affidabilità assoluta o precisa dei risultati della valutazione non può essere conosciuta con certezza. Proprio come ci sono sempre degli errori nei punteggi dei test, ci sono anche degli errori nei nostri tentativi di misurare l’affidabilità. Tuttavia, i metodi di stima dell’affidabilità che discuteremo sono considerati stime conservative e rappresentano il limite inferiore della vera affidabilità dei punteggi dei test. In altre parole, l’affidabilità effettiva dei punteggi dei test è almeno altrettanto alta, se non superiore, rispetto all’affidabilità stimata (Reynolds, 1999).\n\n7.3.1.1 Coefficienti di consistenza interna\nLa CTT presenta il metodo delle forme parallele come un approccio parziale per stimare l’attendibilità dei test. Questo metodo prevede la somministrazione di due test distinti, indicati come \\(X\\) e \\(X^\\prime\\), che valutano lo stesso costrutto, a un campione di individui nello stesso momento. In questo contesto, la correlazione tra i punteggi totali dei due test, \\(\\rho^2_{XT} = \\rho_{XX^\\prime}\\), rappresenta l’indicatore principale dell’attendibilità. Tuttavia, è cruciale che le due versioni del test siano effettivamente parallele, secondo la definizione fornita dalla teoria classica dei test, affinché questa relazione sia valida.\nNella pratica, risulta impraticabile somministrare lo stesso test due volte agli stessi partecipanti “nelle stesse condizioni”, come richiesto dal metodo delle forme parallele. Di conseguenza, la stima dell’attendibilità deve basarsi sui dati raccolti attraverso una singola somministrazione del test. La CTT risponde a questa sfida introducendo specifici indicatori di coerenza interna, mirati a valutare l’affidabilità.\nQuesti indicatori di coerenza interna costituiscono la soluzione proposta dalla CTT per affrontare tale problematica. La loro logica si basa sull’idea che una correlazione tra i punteggi di diversi item che misurano lo stesso costrutto rifletta la varianza condivisa del punteggio reale, anziché la varianza condivisa dell’errore. Considerando che gli errori casuali dovrebbero mancare di una varianza condivisa, i coefficienti di coerenza interna riflettono la correlazione tra gli item all’interno del test, offrendo così un’indicazione dell’affidabilità generale della scala di misurazione.\nOltre a questo, gli item stessi possono rappresentare una fonte di errore nei punteggi dei test. Problemi come formulazioni confuse, item non coerenti con il costrutto, linguaggio poco comprensibile o item con risposte ambigue possono emergere quando gli item non sono formulati in modo adeguato. Tali problemi possono portare a risposte inconsistenti per due ragioni: innanzitutto, i partecipanti potrebbero reagire in modi diversi agli item problematici; in secondo luogo, tali item interferiscono con la capacità dei partecipanti di esprimere il loro reale livello del costrutto.\nPer valutare la coerenza delle risposte tra gli item all’interno di una scala, vengono impiegati i coefficienti di consistenza interna. Questi coefficienti si basano sull’assunto che una correlazione tra due punteggi osservati, che misurano lo stesso costrutto, rifletta la varianza condivisa del punteggio reale, non la varianza condivisa dell’errore. Dal momento che gli errori casuali dovrebbero mancare di varianza condivisa, i coefficienti di consistenza interna riflettono la correlazione tra gli item del test e forniscono un’indicazione dell’affidabilità complessiva della scala.\nQuando si valuta l’attendibilità con una singola somministrazione del test, sono disponibili vari approcci. In questo capitolo, esamineremo due metodi proposti dalla CTT: l’indice \\(\\alpha\\) di Cronbach e il metodo di Spearman-Brown. L’indice \\(\\alpha\\) è l’indicatore più comunemente usato per valutare l’attendibilità in termini di coerenza interna o omogeneità. Analizzeremo come questo indice rappresenta il valore minimo possibile dell’attendibilità di un test, sotto determinate ipotesi soddisfatte, e come, allo stesso tempo, può fornire una valutazione distorta dell’attendibilità se le assunzioni che delineeremo non sono rispettate.\nTuttavia, prima di esplorare dettagliatamente questi due diversi metodi di stima dell’attendibilità come coerenza interna, è essenziale distinguere tra tre diverse tipologie di relazioni tra gli item: item congenerici, item \\(\\tau\\)-equivalenti e item paralleli.\n\n\n7.3.1.2 Test paralleli\nSimuliamo i punteggi di due test paralleli.\n\nset.seed(2237) # setting the seed ensure reproducibility\nnum_person &lt;- 1000 # number of respondents\n# True scores for Test 1\nt1 &lt;- rnorm(num_person, mean = 20, sd = 5)\n# Error scores for Test 1\ne1 &lt;- rnorm(num_person, mean = 0, sd = 2)\n# Observed scores for Test 1\nx1 &lt;- t1 + e1\n# True scores for Test 2\nt2 &lt;- t1 # parallel tests have equal true scores\n# Error scores for Test 2\ne2 &lt;- rnorm(num_person, mean = 0, sd = 2)\n# Observed scores for Test 2\nx2 &lt;- t2 + e2\n\n# Merge into a data frame\ntest_df &lt;- data.frame(x1, x2)\n\nmv &lt;- datasummary(x1 + x2 ~ Mean + Var,\n    data = test_df,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx2\n20.31\n30.27\n\n\n\n\n\n\n# Correlation\ncor(test_df) |&gt;\n    round(2)\n\n\nA matrix: 2 x 2 of type dbl\n\n\n\nx1\nx2\n\n\n\n\nx1\n1.00\n0.87\n\n\nx2\n0.87\n1.00\n\n\n\n\n\n\nvar(t1) / var(x1)\n\n0.878424313030747\n\n\n\nvar(t2) / var(x2)\n\n0.847351804948915\n\n\nIn conclusione, per test paralleli: - le medie e le varianze dei punteggi osservati sono statisticamente uguali; - la correlazione è uguale all’attendibilità.\n\n\n7.3.1.3 Test \\(\\tau\\)-equivalenti\n\n# True scores for Test 3\nt3 &lt;- 5 + t1 # essentially tau-equivalent tests\n# Error scores for Test 3 (larger error SDs)\ne3 &lt;- rnorm(num_person, mean = 0, sd = 4)\n# Observed scores for Test 2\nx3 &lt;- t3 + e3\n\n# Merge into a data frame\ntest_df2 &lt;- data.frame(x1, x3)\n# Get means and variances\nmv &lt;- datasummary(x1 + x3 ~ Mean + Var,\n    data = test_df2,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx3\n25.41\n41.50\n\n\n\n\n\n\n# Correlation\ncor(test_df2) |&gt;\n    round(2)\n\n\nA matrix: 2 x 2 of type dbl\n\n\n\nx1\nx3\n\n\n\n\nx1\n1.00\n0.72\n\n\nx3\n0.72\n1.00\n\n\n\n\n\nSe conosciamo i punteggi veri, l’attendibilità di X3 si trova come\n\n# Reliability for x3\nvar(t3) / var(x3)\n\n0.618012243898734\n\n\nIn conclusione, per test tau-equivalenti: - le medie e le varianze dei punteggi osservati sono diverse; - correlazione \\(\\neq\\) attendibilità.\n\n\n7.3.1.4 Test congenerici\n\n# True scores for Test 4\nt4 &lt;- 2 + 0.8 * t1\n# Error scores for Test 4 (larger error SDs)\ne4 &lt;- rnorm(num_person, mean = 0, sd = 3)\n# Observed scores for Test 2\nx4 &lt;- t4 + e4\n\n# Merge into a data frame\ntest_df3 &lt;- data.frame(x1, x4)\n# Get means and variances\nmv &lt;- datasummary(x1 + x4 ~ Mean + Var,\n    data = test_df3,\n    output = \"data.frame\"\n)\nmv\n\n\nA data.frame: 2 x 3\n\n\n\nMean\nVar\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nx1\n20.41\n29.20\n\n\nx4\n18.27\n24.23\n\n\n\n\n\n\n# Correlation\ncor(test_df3) |&gt;\n    round(2)\n\n\nA matrix: 2 x 2 of type dbl\n\n\n\nx1\nx4\n\n\n\n\nx1\n1.00\n0.73\n\n\nx4\n0.73\n1.00\n\n\n\n\n\nSe conosciamo i punteggi veri, l’attendibilità di X4 si trova come\n\n# Reliability for x4\nvar(t4) / var(x4)\n\n0.677398252481377\n\n\nIn conclusione, per test congenerici: - le medie e le varianze dei punteggi osservati sono diverse; - correlazione \\(\\neq\\) attendibilità; - sono necessari più di due test per distinguere test congenerici e test \\(\\tau\\)-equivalenti.\n\n\n7.3.1.5 Coefficiente \\(\\alpha\\) di Cronbach\nIl coefficiente \\(\\alpha\\) consente la stima dell’affidabilità nel contesto di indicatori \\(\\tau\\)-equivalenti. In queste circostanze, l’attendibilità viene valutata utilizzando l’equazione:\n\\[\n\\alpha = \\frac{{k}}{{k-1}} \\left( 1 - \\frac{{\\sum_{i=1}^{k} \\sigma_{X_i}^{2}}}{{\\sigma_{X}^{2}}} \\right)\n\\]\ndove: - \\(k\\) è il numero di item nel test, - \\(\\sigma_{i}^{2}\\) rappresenta la varianza del punteggio dell’item \\(i\\), - \\(\\sigma_{X}^{2}\\) è la varianza totale dei punteggi del test.\nUna derivazione della formula del coefficiente alpha di Cronbach è fornita nel capitolo {ref}reliability-fa-notebook.\nFu Guttman nel 1945 a scoprire questo coefficiente, anche se erroneamente attribuito a Cronbach. È spesso noto come coefficiente \\(\\alpha\\) di Guttman-Cronbach o G-C \\(\\alpha\\).\nQuando il modello di \\(\\tau\\)-equivalenza è applicabile, il coefficiente \\(\\alpha\\) costituisce un limite inferiore dell’affidabilità, in altri termini, il coefficiente \\(\\alpha\\) offre una stima prudente dell’affidabilità. Questa caratteristica è considerata uno dei principali vantaggi di questo indice. Tuttavia, è fondamentale notare che questa natura conservativa del coefficiente \\(\\alpha\\) vale solo se le ipotesi del modello \\(\\tau\\)-equivalente sono rispettate.\nIl coefficiente di attendibilità \\(\\alpha\\) è ampiamente utilizzato nell’ambito della psicometria. Tuttavia, come menzionato in precedenza, quando l’assunzione di \\(\\tau\\)-equivalenza non è valida, \\(\\alpha\\) può perdere la sua proprietà conservativa e sovrastimare l’attendibilità del test (Sijtsma, 2009). In tal caso, è necessario valutare attentamente l’adeguatezza dell’utilizzo del coefficiente \\(\\alpha\\) come indicatore di affidabilità.\nEsempio. Per illustrare la procedura di calcolo del coefficiente \\(\\alpha\\), useremo i dati bfi contenuti nel pacchetto psych. Il dataframe bfi comprende 25 item di autovalutazione della personalità. Sono riportati i dati di 2800 soggetti. Ci concentreremo qui sulla sottoscala Openness. - O1: Am full of ideas; - O2: Avoid difficult reading material; - O3: Carry the conversation to a higher level; - O4: Spend time reflecting on things; - O5: Will not probe deeply into a subject.\nLeggiamo i dati in R.\n\ndata(bfi, package = \"psych\")\nhead(bfi[c(\"O1\", \"O2\", \"O3\", \"O4\", \"O5\")])\n\n\nA data.frame: 6 x 5\n\n\n\nO1\nO2\nO3\nO4\nO5\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n61617\n3\n6\n3\n4\n3\n\n\n61618\n4\n2\n4\n3\n3\n\n\n61620\n4\n2\n5\n5\n2\n\n\n61621\n3\n3\n4\n3\n5\n\n\n61622\n3\n3\n4\n3\n3\n\n\n61623\n4\n3\n5\n6\n1\n\n\n\n\n\nEsaminiamo la correlazione tra gli item della sottoscale Openness.\n\ncor(bfi[c(\"O1\", \"O2\", \"O3\", \"O4\", \"O5\")], use = \"pairwise.complete.obs\") |&gt;\n    round(2)\n\n\nA matrix: 5 x 5 of type dbl\n\n\n\nO1\nO2\nO3\nO4\nO5\n\n\n\n\nO1\n1.00\n-0.21\n0.40\n0.18\n-0.24\n\n\nO2\n-0.21\n1.00\n-0.26\n-0.07\n0.32\n\n\nO3\n0.40\n-0.26\n1.00\n0.19\n-0.31\n\n\nO4\n0.18\n-0.07\n0.19\n1.00\n-0.18\n\n\nO5\n-0.24\n0.32\n-0.31\n-0.18\n1.00\n\n\n\n\n\nÈ necessario ricodificare due item.\n\nbfi$O2r &lt;- 7 - bfi$O2\nbfi$O5r &lt;- 7 - bfi$O5\n\n\ncor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\") |&gt;\n    round(2)\n\n\nA matrix: 5 x 5 of type dbl\n\n\n\nO1\nO2r\nO3\nO4\nO5r\n\n\n\n\nO1\n1.00\n0.21\n0.40\n0.18\n0.24\n\n\nO2r\n0.21\n1.00\n0.26\n0.07\n0.32\n\n\nO3\n0.40\n0.26\n1.00\n0.19\n0.31\n\n\nO4\n0.18\n0.07\n0.19\n1.00\n0.18\n\n\nO5r\n0.24\n0.32\n0.31\n0.18\n1.00\n\n\n\n\n\nConsideriamo la matrice di varianze e covarianze della sottoscala Openness.\n\nC &lt;- cov(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nC |&gt; round(2)\n\n\nA matrix: 5 x 5 of type dbl\n\n\n\nO1\nO2r\nO3\nO4\nO5r\n\n\n\n\nO1\n1.28\n0.38\n0.54\n0.25\n0.36\n\n\nO2r\n0.38\n2.45\n0.50\n0.13\n0.67\n\n\nO3\n0.54\n0.50\n1.49\n0.29\n0.50\n\n\nO4\n0.25\n0.13\n0.29\n1.49\n0.29\n\n\nO5r\n0.36\n0.67\n0.50\n0.29\n1.76\n\n\n\n\n\nCalcoliamo alpha:\n\np &lt;- 5\nalpha &lt;- (p / (p - 1)) * (1 - tr(C) / sum(C))\nalpha\n\n0.600172514820215\n\n\nLo stesso risultato si ottiene utilizzando la funzione alpha() contenuta nel pacchetto psych:\n\npsych::alpha(C)\n\n\nReliability analysis   \nCall: psych::alpha(x = C)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n       0.6      0.61    0.57      0.24 1.5     0.23\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt -0.49   0.6  0.95\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\nO1       0.53      0.53    0.48      0.22 1.1 0.0092  0.23\nO2r      0.57      0.57    0.51      0.25 1.3 0.0076  0.22\nO3       0.50      0.50    0.44      0.20 1.0 0.0071  0.20\nO4       0.61      0.62    0.56      0.29 1.6 0.0044  0.29\nO5r      0.51      0.53    0.47      0.22 1.1 0.0115  0.20\n\n Item statistics \n       r r.cor r.drop\nO1  0.65  0.52   0.39\nO2r 0.60  0.43   0.33\nO3  0.69  0.59   0.45\nO4  0.52  0.29   0.22\nO5r 0.66  0.52   0.42\n\n\n\n\n7.3.1.6 Metodi alternativi per la stima del coefficiente di attendibilità\nCi sono altri coefficienti di consistenza interna oltre al coefficiente alpha di Cronbach. Alcuni esempi includono il coefficiente KR-20 e il coefficiente KR-21, che vengono utilizzati con item dicotomici (ossia con risposte a due alternative, come vero/falso).\n\n\n7.3.1.7 Coefficiente KR-20\nLa formula di Kuder-Richardson-20 (KR-20) è un caso particolare del coefficiente α. Se ogni item è dicotomico, il coefficiente α diventa il KR-20. Il coefficiente Coefficiente KR-20 si calcola con la formula:\n\\[\nKR\\_20 = \\frac{{k}}{{k-1}} \\left( 1 - \\frac{{p(1-p)}}{{\\sigma_{X}^{2}}} \\right)\n\\]\ndove: - \\(k\\) è il numero di item nel test, - \\(p\\) è la proporzione di individui che rispondono correttamente all’item, - \\(\\sigma_{X}^{2}\\) è la varianza totale dei punteggi del test.\nEsempio. Per fare un esempio, consideriamo il data-set LSAT contenuto nel pacchetto ltm.\n\nKR20 &lt;- function(responses) {\n    # Get number of items (N) and individuals\n    n.items &lt;- ncol(responses)\n    n.persons &lt;- nrow(responses)\n    # get p_j for each item\n    p &lt;- colMeans(responses)\n    # Get total scores (X)\n    x &lt;- rowSums(responses)\n    # observed score variance\n    var.x &lt;- var(x) * (n.persons - 1) / n.persons\n    # Apply KR-20 formula\n    rel &lt;- (n.items / (n.items - 1)) * (1 - sum(p * (1 - p)) / var.x)\n    return(rel)\n}\n\n\ndata(LSAT)\nhead(LSAT)\n\n\nA data.frame: 6 x 5\n\n\n\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n1\n\n\n5\n0\n0\n0\n0\n1\n\n\n6\n0\n0\n0\n0\n1\n\n\n\n\n\n\nKR20(LSAT)\n\n0.294997192215955\n\n\n\n\n7.3.1.8 Coefficiente KR-21\nIl coefficiente Coefficiente KR-21 si calcola con la formula:\n\\[\nKR\\_21 = \\frac{{k}}{{k-1}} \\left( 1 - \\frac{{\\frac{{\\sum_{i=1}^{k} p_{i}(1-p_{i})}}{{\\sigma_{X}^{2}}}}}{{1 - \\frac{{\\sum_{i=1}^{k} p_{i}}}{k}}} \\right)\n\\]\ndove: - \\(k\\) è il numero di item nel test, - \\(p_{i}\\) è la proporzione di individui che rispondono correttamente all’item \\(i\\), - \\(\\sigma_{X}^{2}\\) è la varianza totale dei punteggi del test.\n\n\n7.3.1.9 La formula “profetica” di Spearman-Brown\nL’indice di Spearman-Brown stima l’attendibilità nel caso di \\(p\\) indicatori paralleli:\n\\[\n\\begin{equation}\n  \\rho_p = \\frac{p \\rho_1}{(p-1)\\rho_1 + 1},\n\\end{equation}\n\\] (eq-spearman-brown-der)\ndove \\(\\rho_1\\) rappresenta l’attendibilità di un singolo elemento.\nUna derivazione della formula Spearman-Brown è fornita nel capitolo {ref}reliability-fa-notebook.\nL’equazione {eq}eq-spearman-brown-der esprime l’attendibilità \\(\\rho_p\\) di un test composto da \\(p\\) elementi paralleli in termini dell’attendibilità di un singolo elemento. Questa equazione è universalmente riconosciuta come la formula “profetica” di Spearman-Brown (Spearman-Brown prophecy formula).\nPer fare un esempio concreto, poniamoci il problema di calcolare l’attendibilità della sottoscala Openness utilizzando la formula di Spearman-Brown. Ipotizziamo dunque che gli item della scala Openness siano paralleli. La matrice di correlazione è:\n\nR &lt;- cor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nR |&gt; round(2)\n\n\nA matrix: 5 x 5 of type dbl\n\n\n\nO1\nO2r\nO3\nO4\nO5r\n\n\n\n\nO1\n1.00\n0.21\n0.40\n0.18\n0.24\n\n\nO2r\n0.21\n1.00\n0.26\n0.07\n0.32\n\n\nO3\n0.40\n0.26\n1.00\n0.19\n0.31\n\n\nO4\n0.18\n0.07\n0.19\n1.00\n0.18\n\n\nO5r\n0.24\n0.32\n0.31\n0.18\n1.00\n\n\n\n\n\nSupponiamo di calcolare l’attendibilità di un singolo item (\\(\\rho_1\\)) come la correlazione media tra gli item:\n\nrr &lt;- NULL\np &lt;- 5\nk &lt;- 1\nfor (i in 1:p) {\n    for (j in 1:p) {\n        if (j != i) {\n            rr[k] &lt;- R[i, j]\n        }\n        k &lt;- k + 1\n    }\n}\nro_1 &lt;- mean(rr, na.rm = TRUE)\nro_1\n\n0.236538319550858\n\n\nApplicando la formula di Spearman-Brown, la stima dell’attendibilità del test diventa pari a\n\n(p * ro_1) / ((p - 1) * ro_1 + 1)\n\n0.607707322439719\n\n\n\n\n\n7.3.2 Forme parallele del test\nIn alcune situazioni, è possibile avere a disposizione diverse versioni di un test che sono progettate per essere interscambiabili, in modo tale che la specifica versione del test non influenzi i punteggi ottenuti dai partecipanti. Queste forme alternative del test sono comuni soprattutto nel campo dell’educazione, dove spesso vengono preparate diverse versioni al fine di prevenire frodi o imbrogli. Inoltre, anche i ricercatori possono adottare forme alternative in studi che coinvolgono pre-test e post-test, al fine di evitare che i partecipanti beneficiino degli effetti di pratica o memoria. Tuttavia, è di fondamentale importanza determinare se i punteggi ottenuti da queste diverse versioni sono coerenti, poiché la mancanza di equivalenza tra le forme potrebbe condurre a conclusioni errate riguardo alle variazioni dei punteggi.\nLe principali fonti di errore di misurazione per le forme alternative di test cognitivi derivano dalle differenze nei contenuti, nella difficoltà e nella complessità cognitiva degli item. Per quanto riguarda i test non-cognitivi, le differenze nei contenuti e nell’intensità degli item sono motivo di attenzione. Gli sviluppatori di forme alternative adottano diverse procedure al fine di garantire l’equivalenza tra le varie versioni, basandosi sulla stessa tabella di specifiche che stabilisce la proporzione di item per i diversi domini di contenuto e i livelli cognitivi o non-cognitivi. Inoltre, vengono appaiati gli item in base alla loro difficoltà e alla loro capacità discriminante.\nI coefficienti di equivalenza, noti anche come affidabilità delle forme alternative, valutano la similitudine tra due o più versioni di un test. Per calcolare questi coefficienti, le diverse forme vengono somministrate agli stessi partecipanti e i punteggi ottenuti vengono correlati. Tuttavia, vi sono alcune considerazioni legate alla somministrazione dei test e alla possibile fatica dei partecipanti. Al fine di affrontare tali problematiche, possono essere adottate strategie come il bilanciamento dell’ordine di somministrazione e l’introduzione di un breve intervallo di tempo tra le diverse versioni. Inoltre, è importante considerare gli effetti della pratica o della memoria, i quali potrebbero influenzare i punteggi ottenuti nel secondo test somministrato. L’impiego del bilanciamento tra gruppi può contribuire a controllare tali effetti.\n\n\n7.3.3 Attendibilità test-retest\nInfine, esaminiamo il concetto di “affidabilità test-retest”, che si riferisce alla coerenza o stabilità dei punteggi di un test in diverse occasioni nel corso del tempo. Questo tipo di affidabilità riveste una particolare importanza nelle situazioni in cui i punteggi vengono ottenuti in momenti diversi e confrontati, come nel caso di test effettuati prima e dopo un intervento. Inoltre, è di rilievo quando i punteggi del test vengono utilizzati per prendere decisioni diagnostiche, di selezione o di collocazione. Tuttavia, è importante sottolineare che l’affidabilità test-retest non è adatta per valutare costrutti che non sono noti per la loro stabilità nel tempo. Ciò deriva dal fatto che l’analisi della stabilità di un test potrebbe essere influenzata da effettivi cambiamenti nei livelli veri del costrutto tra i partecipanti. Di conseguenza, è essenziale che i ricercatori siano consapevoli in anticipo della stabilità del costrutto che intendono misurare. È importante notare che molti costrutti di interesse nelle scienze sociali sono generalmente considerati stabili nel tempo, come ad esempio la creatività, l’abilità cognitiva e alcune caratteristiche della personalità.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#affidabilità-dei-punteggi-compositi",
    "href": "chapters/ctt/03_ctt_3.html#affidabilità-dei-punteggi-compositi",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.4 Affidabilità dei punteggi compositi",
    "text": "7.4 Affidabilità dei punteggi compositi\nL’affidabilità dei punteggi compositi si riferisce alla misura in cui più punteggi ottenuti da diverse fonti possono essere combinati per creare un punteggio complessivo. Ad esempio, nella valutazione educativa, la determinazione delle votazioni spesso si basa su un punteggio complessivo ottenuto da diverse prove e altre valutazioni somministrate durante un periodo di valutazione o un semestre. Molti test psicologici standardizzati includono diverse sottoscale che vengono combinate per formare un punteggio complessivo.\nIl vantaggio dei punteggi compositi è che la loro affidabilità è generalmente maggiore rispetto a quella dei punteggi individuali delle sottoscale (o item) che contribuiscono al punteggio composto. Più precisamente, l’affidabilità di un punteggio composto è il risultato del numero di punteggi inclusi nel composto, dell’affidabilità dei punteggi individuali e della correlazione tra questi punteggi. Più punteggi sono inclusi nel composto, più alta è la correlazione tra di essi e maggiore è l’affidabilità individuale, maggiore è l’affidabilità del composto. Come abbiamo notato in precedenza, i test rappresentano semplicemente dei campioni del dominio che si intende misurare, e la combinazione di misurazioni multiple è analoga all’aumento del numero di osservazioni o della dimensione del campione.\nPer fare un esempio, supponiamo di avere due variabili aleatorie, $ X $ e $ Y $, che rappresentano i punteggi di due subtest diversi. L’affidabilità (indicata come $ $) di un test è legata alla varianza del test stesso. Un modo per esprimere l’affidabilità è attraverso il rapporto tra la varianza del vero punteggio (quello che il test intende misurare) e la varianza totale del test. Supponendo che il vero punteggio e l’errore di misura siano indipendenti, la varianza totale del test è la somma della varianza del vero punteggio e della varianza dell’errore.\nQuando combiniamo più subtest in un punteggio composito, stiamo in effetti aumentando la varianza del vero punteggio (poiché stiamo combinando più misurazioni del costrutto che vogliamo misurare) mentre l’errore di misura, supposto indipendente tra i subtest, si somma meno che proporzionalmente.\nPer rendere queste affermazioni più concrete, consideriamo un esempio numerico nel quale supponiamo che i subtest siano correlati (il che è spesso il caso in psicometria, dove diversi subtest possono misurare aspetti correlati di un costrutto più ampio).\n\n7.4.1 Calcolo per il Puniteggio Composito\nPer esempio, dati due subtest con una varianza del vero punteggio di 25 ciascuno e una covarianza di 15 (dovuta al vero punteggio), la varianza del vero punteggio nel composito è data da:\n\\[ \\text{Var}(Z_{vero}) = 25 + 25 + 2 \\cdot 15 = 80 \\]\nLa varianza totale nel composito, tenendo conto anche della varianza dell’errore di misura, sarà:\n\\[ \\text{Var}(Z_{totale}) = 35 + 35 + 2 \\cdot 15 = 100 \\]\nIl rapporto tra la varianza del vero punteggio e la varianza totale nel composito è:\n\\[ \\text{Rapporto} = \\frac{\\text{Var}(Z_{vero})}{\\text{Var}(Z_{totale})} = \\frac{80}{100} = 0.8 \\]\n\n\n7.4.2 Confronto con un Singolo Subtest\nLa varianza del vero punteggio in un singolo subtest è data (come da ipotesi) da 25.\nLa varianza totale in un singolo subtest è la somma della varianza del vero punteggio e quella dell’errore di misura, quindi 35 (25 di vero punteggio + 10 di errore).\nIl rapporto tra la varianza del vero punteggio e la varianza totale in un singolo subtest è:\n\\[ \\text{Rapporto} = \\frac{\\text{Var}(X_{vero})}{\\text{Var}(X_{totale})} = \\frac{25}{35} \\approx 0.714 \\]\nIl confronto mostra che l’affidabilità del punteggio composito (0.8) è maggiore di quella di un singolo subtest (circa 0.714). Questo esemplifica come la correlazione positiva tra i subtest possa effettivamente aumentare l’affidabilità del punteggio composito rispetto ai subtest individuali.\nQuindi, il vantaggio di combinare i punteggi dai subtest in un punteggio composito emerge principalmente quando i subtest sono in qualche modo correlati e/o quando la varianza dell’errore di misura è ridotta rispetto alla varianza del vero punteggio. In pratica, l’uso di punteggi compositi è spesso giustificato dall’idea che essi forniscono una misura più completa e rappresentativa del costrutto di interesse, riducendo l’impatto dell’errore di misura specifico di ciascun subtest.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#laffidabilità-dei-punteggi-differenza",
    "href": "chapters/ctt/03_ctt_3.html#laffidabilità-dei-punteggi-differenza",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.5 L’affidabilità dei Punteggi Differenza",
    "text": "7.5 L’affidabilità dei Punteggi Differenza\nCi sono numerose situazioni in cui ricercatori e clinici vogliono considerare la differenza tra due punteggi. Qui, la variabile di interesse è un punteggio differenza che viene calcolato come:\n\\[ D = X - Y, \\]\ndove X è il punteggio su un test e Y su un altro. Ad esempio, un approccio alla diagnosi delle difficoltà di apprendimento prevede il calcolo dei punteggi differenza sottraendo il punteggio di un esaminando in un test di rendimento (ad esempio, comprensione della lettura) dal suo QI. Si presume che se la discrepanza è negativa e sufficientemente ampia (ad esempio, due o più deviazioni standard), l’esaminando non sta dimostrando un rendimento accademico commisurato all’attitudine. Se ulteriori valutazioni escludono una serie di spiegazioni come opportunità educative inadeguate o problemi sensoriali (ad esempio, problemi visivi o uditivi), la discrepanza potrebbe riflettere una difficoltà di apprendimento intrinseca.\nUn altro esempio comune dell’utilizzo dei punteggi differenza si ha quando uno psicologo vuole considerare i guadagni (o le perdite) nella performance di un test nel tempo. Ad esempio, un ricercatore potrebbe voler determinare se un trattamento specifico ha portato a un miglioramento nelle prestazioni su un determinato compito. Ciò è spesso realizzato somministrando test prima e dopo l’intervento.\nIn queste situazioni, la variabile di interesse è un punteggio differenza. Quando si trattano punteggi differenza, è però importante ricordare che l’affidabilità dei punteggi differenza è tipicamente considerevolmente inferiore rispetto alle affidabilità dei punteggi individuali. Come regola generale, l’affidabilità dei punteggi differenza diminuisce all’aumentare della correlazione tra le misure individuali.\nLa formula per l’affidabilità dei punteggi differenza è data da:\n\\[\nr_{dd} = \\frac{0.5 (r_{xx} + r_{yy}) - r_{xy}}{1 - r_{xy}}\n\\],\ndove \\(r_{xx}\\) e \\(r_{yy}\\) sono le affidabilità delle due componenti della differenza e \\(r_{xy}\\) è la loro correlazione. Facciamo un esempio numerico varianza la correlazione tra le due componenti.\n\nrdd &lt;- function(rxx, ryy, rxy) {\n    (0.5 * (rxx + ryy) - rxy) / (1 - rxy)\n}\n\nseq(0.01, 0.81, by = 0.1)\n\n\n0.010.110.210.310.410.510.610.710.81\n\n\n\nrxx &lt;- 0.9\nryy &lt;- 0.8\n\nrdd(rxx, ryy, seq(0.01, 0.81, by = 0.1))\n\n\n0.8484848484848490.8314606741573040.8101265822784810.7826086956521740.7457627118644070.6938775510204080.6153846153846160.4827586206896550.210526315789474\n\n\nSi vede che, all’aumentare di \\(r_{xy}\\), l’affidabilità del punteggio differenza diminuisce.\nIn sintesi, si dovrebbe essere cauti nell’interpretare i punteggi differenza. L’affidabilità dei punteggi differenza è tipicamente considerevolmente inferiore rispetto alle affidabilità dei punteggi individuali. Per aggravare il problema, i punteggi differenza sono spesso calcolati utilizzando punteggi che hanno correlazioni piuttosto forti tra loro (ad esempio, punteggi di QI e di rendimento; punteggi pre e post test).",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#scelta-del-coefficiente-di-affidabilità-in-funzione-del-contesto",
    "href": "chapters/ctt/03_ctt_3.html#scelta-del-coefficiente-di-affidabilità-in-funzione-del-contesto",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.6 Scelta del Coefficiente di Affidabilità in Funzione del Contesto",
    "text": "7.6 Scelta del Coefficiente di Affidabilità in Funzione del Contesto\nLa selezione di un coefficiente di affidabilità adeguato dipende da vari fattori, inclusa la natura del costrutto psicologico e l’utilizzo previsto dei punteggi del test. È essenziale considerare il contesto specifico in cui il test verrà impiegato per determinare l’indice di affidabilità più appropriato.\n\n7.6.1 Affidabilità Test-Retest\nL’affidabilità test-retest è rilevante quando un test viene somministrato ripetutamente agli stessi soggetti. Questo tipo di affidabilità misura la stabilità dei punteggi nel tempo, rendendola particolarmente utile per test che sono sensibili agli errori di misurazione legati al tempo. Ad esempio, se un test è impiegato per predire il comportamento futuro di un individuo, l’affidabilità test-retest fornisce una stima significativa dell’errore dovuto alla variabilità temporale.\n\n\n7.6.2 Affidabilità della Coerenza Interna\nQuando un test è previsto per essere somministrato una sola volta, è più pertinente considerare la coerenza interna. Ci sono due approcci principali:\n\nAffidabilità Split-Half: Questo metodo stima l’errore dovuto alla varianza del campionamento del contenuto. È adatto per test con contenuti eterogenei, dove l’eterogeneità è intenzionale. Ad esempio, in un test che valuta più costrutti psicologici (come depressione, ansia, rabbia, impulsività), l’approccio split-half può essere preferibile. Qui, si divide idealmente il test in due parti, con un numero equo di item per ogni tratto o caratteristica in ciascuna metà.\nCoefficienti Alfa e KR-20: Questi coefficienti stimano l’errore dovuto sia al campionamento del contenuto che all’eterogeneità di questo. Sono applicabili quando il test misura un’area di conoscenza omogenea o un singolo tratto. Per esempio, un test che valuta specificamente l’umore depressivo potrebbe avvalersi efficacemente del coefficiente alfa o del KR-20, poiché si focalizza su un dominio omogeneo.\n\n\n\n7.6.3 Affidabilità delle Forme Alternate\nSe esistono diverse forme di un test, è importante stimare l’affidabilità delle forme alternate. Questo approccio misura la consistenza dei punteggi tra diverse versioni del test, garantendo che le varie forme siano equivalenti e affidabili.\n\n\n7.6.4 Affidabilità Intervalutatori\nNel caso in cui il test richieda un giudizio soggettivo da parte dei valutatori, diventa cruciale considerare l’affidabilità intervalutatori. Questo tipo di affidabilità valuta la consistenza dei giudizi tra diversi valutatori, assicurando che le valutazioni siano obiettive e non dipendano significativamente dall’interpretazione individuale.\nIn sintesi, la scelta del coefficiente di affidabilità dipende dal contesto specifico del test, dalla natura del costrutto da misurare e dall’uso previsto dei risultati del test. È fondamentale valutare attentamente questi fattori per garantire la validità e l’accuratezza delle misurazioni psicologiche.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#linee-guida-sulla-scelta-e-valutazione-dei-coefficienti-di-affidabilità",
    "href": "chapters/ctt/03_ctt_3.html#linee-guida-sulla-scelta-e-valutazione-dei-coefficienti-di-affidabilità",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.7 Linee Guida sulla Scelta e Valutazione dei Coefficienti di Affidabilità",
    "text": "7.7 Linee Guida sulla Scelta e Valutazione dei Coefficienti di Affidabilità\nLa scelta e la valutazione dei coefficienti di affidabilità in ambito psicometrico sono processi complessi influenzati da diversi fattori.\n\n7.7.1 Significato e Importanza dei Coefficienti di Affidabilità\nI coefficienti di affidabilità possono essere interpretati come la proporzione della varianza dei punteggi di un test attribuibile a differenze reali tra gli individui nel costrutto valutato. Idealmente, vorremmo che questi coefficienti raggiungessero il valore di 1.0, indicando che il 100% della varianza dei punteggi di test è dovuto a vere differenze tra gli individui. Tuttavia, a causa dell’errore di misurazione, una misura perfettamente affidabile non esiste. Non vi è una risposta univoca su quale sia un livello accettabile di affidabilità; ciò dipende da vari fattori come il costrutto misurato, il tempo disponibile per il test, l’uso dei punteggi e il metodo di stima dell’affidabilità.\n\n\n7.7.2 Fattori da Considerare nella Valutazione dell’Affidabilità\n\n7.7.2.1 Il Costrutto\nAlcuni costrutti sono più difficili da misurare rispetto ad altri a causa della complessità del dominio degli item. Ad esempio, le variabili di personalità sono generalmente più difficili da misurare rispetto alle abilità cognitive. Pertanto, un livello di affidabilità accettabile per un test sulla “dipendenza” potrebbe essere inadeguato per un test sull’intelligenza. È importante considerare la natura del costrutto e la sua difficoltà di misurazione.\n\n\n7.7.2.2 Tempo Disponibile per il Test\nSe il tempo disponibile per il test è limitato, ciò può influenzare l’affidabilità. Un numero limitato di item può aumentare l’errore nel campionamento del dominio del test. Ad esempio, test rapidi per lo screening dei problemi di lettura richiederanno standard di affidabilità diversi rispetto a test più lunghi, come quelli per l’intelligenza.\n\n\n7.7.2.3 Uso dei Punteggi del Test\nL’uso previsto dei punteggi del test è un altro fattore cruciale. Test diagnostici che influenzano decisioni importanti su un individuo richiedono standard di affidabilità più elevati rispetto ai test utilizzati per ricerche di gruppo o screening. Ad esempio, test sull’intelligenza utilizzati nella diagnosi di disabilità intellettuali richiedono un’alta affidabilità.\n\n\n7.7.2.4 Metodo di Stima dell’Affidabilità\nIl metodo scelto per stimare l’affidabilità può influenzare la grandezza dei coefficienti di affidabilità. Alcuni metodi, come KR-20 e il coefficiente alfa, tendono a produrre stime di affidabilità minori rispetto al metodo split-half. È importante considerare il metodo utilizzato quando si valutano e si confrontano l’affidabilità di diversi test.\n\n\n\n7.7.3 Linee Guida Generali per i Coefficienti di Affidabilità\nSebbene molti fattori meritino considerazione, possiamo fornire alcune linee guida generali:\n\nPer decisioni importanti che hanno un impatto significativo e non facilmente reversibile sugli individui, si dovrebbero aspettare coefficienti di affidabilità di 0.90 o addirittura 0.95.\nStime di affidabilità di 0.80 o superiori sono generalmente accettabili per molti test di rendimento e personalità.\nPer test creati da insegnanti o usati per lo screening, si aspettano stime di affidabilità di almeno 0.70.\nAlcuni suggeriscono che coefficienti di affidabilità fino a 0.60 possano essere accettabili per ricerche di gruppo, ma è consigliabile cautela nell’usare test con affidabilità al di sotto di 0.70.\n\nIn sintesi, la valutazione dell’affidabilità di un test psicometrico richiede un’attenta considerazione di diversi fattori chiave, e gli standard di accettabilità variano in base al contesto specifico del test e al suo uso previsto.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#considerazioni-conclusive",
    "href": "chapters/ctt/03_ctt_3.html#considerazioni-conclusive",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.8 Considerazioni conclusive",
    "text": "7.8 Considerazioni conclusive\nIn conclusione, la valutazione dell’affidabilità di un test richiede l’impiego di diversi coefficienti che tengono conto delle varie fonti di errore. I coefficienti di consistenza interna si concentrano sull’errore derivante dalle fluttuazioni delle risposte tra gli item, mentre quelli di equivalenza esaminano la coerenza dei punteggi tra diverse versioni del test. I coefficienti di stabilità misurano la coerenza dei punteggi nel corso del tempo. È di fondamentale importanza selezionare il tipo di affidabilità appropriato in base allo scopo del test, al fine di ottenere informazioni affidabili e utili per le decisioni basate sui punteggi ottenuti dal test.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/03_ctt_3.html#session-info",
    "href": "chapters/ctt/03_ctt_3.html#session-info",
    "title": "7  Metodi di stima dell’affidabilità",
    "section": "7.9 Session Info",
    "text": "7.9 Session Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ltm_1.2-0          polycor_0.8-1      msm_1.7.1          MASS_7.3-60.0.1   \n [5] modelsummary_1.4.5 ggokabeito_0.1.0   viridis_0.6.5      viridisLite_0.4.2 \n [9] ggpubr_0.6.0       ggExtra_0.10.1     bayesplot_1.11.1   gridExtra_2.3     \n[13] patchwork_1.2.0    semTools_0.5-6     semPlot_1.1.6      lavaan_0.6-17     \n[17] psych_2.4.1        scales_1.3.0       markdown_1.12      knitr_1.45        \n[21] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[25] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[29] ggplot2_3.5.0      tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] nloptr_2.0.3       rmarkdown_2.26     vctrs_0.6.5       \n  [7] minqa_1.2.6        base64enc_0.1-3    rstatix_0.7.2     \n [10] htmltools_0.5.7    broom_1.0.5        Formula_1.2-5     \n [13] htmlwidgets_1.6.4  plyr_1.8.9         uuid_1.2-0        \n [16] admisc_0.35        igraph_2.0.2       mime_0.12         \n [19] lifecycle_1.0.4    pkgconfig_2.0.3    Matrix_1.6-5      \n [22] R6_2.5.1           fastmap_1.1.1      shiny_1.8.0       \n [25] digest_0.6.34      OpenMx_2.21.11     fdrtool_1.2.17    \n [28] colorspace_2.1-0   rprojroot_2.0.4    Hmisc_5.1-1       \n [31] fansi_1.0.6        timechange_0.3.0   abind_1.4-5       \n [34] compiler_4.3.3     withr_3.0.0        glasso_1.11       \n [37] htmlTable_2.4.2    backports_1.4.1    carData_3.0-5     \n [40] ggsignif_0.6.4     corpcor_1.6.10     gtools_3.9.5      \n [43] tools_4.3.3        pbivnorm_0.6.0     foreign_0.8-86    \n [46] zip_2.3.1          httpuv_1.6.14      nnet_7.3-19       \n [49] glue_1.7.0         quadprog_1.5-8     nlme_3.1-164      \n [52] promises_1.2.1     lisrelToR_0.3      grid_4.3.3        \n [55] pbdZMQ_0.3-11      checkmate_2.3.1    cluster_2.1.6     \n [58] reshape2_1.4.4     generics_0.1.3     gtable_0.3.4      \n [61] tzdb_0.4.0         data.table_1.15.2  hms_1.1.3         \n [64] car_3.1-2          utf8_1.2.4         tables_0.9.17     \n [67] sem_3.1-15         pillar_1.9.0       IRdisplay_1.1     \n [70] rockchalk_1.8.157  later_1.3.2        splines_4.3.3     \n [73] lattice_0.22-5     survival_3.5-8     kutils_1.73       \n [76] tidyselect_1.2.0   miniUI_0.1.1.1     pbapply_1.7-2     \n [79] stats4_4.3.3       xfun_0.42          expm_0.999-9      \n [82] qgraph_1.9.8       arm_1.13-1         stringi_1.8.3     \n [85] boot_1.3-29        evaluate_0.23      mi_1.1            \n [88] cli_3.6.2          RcppParallel_5.1.7 IRkernel_1.3.2    \n [91] rpart_4.1.23       xtable_1.8-4       repr_1.1.6        \n [94] munsell_0.5.0      Rcpp_1.0.12        coda_0.19-4.1     \n [97] png_0.1-8          XML_3.99-0.16.1    parallel_4.3.3    \n[100] ellipsis_0.3.2     jpeg_0.1-10        lme4_1.1-35.1     \n[103] mvtnorm_1.2-4      insight_0.19.8     openxlsx_4.2.5.2  \n[106] crayon_1.5.2       rlang_1.1.3        mnormt_2.1.1",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodi di stima dell'affidabilità</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html",
    "href": "chapters/ctt/04_err_std_mis.html",
    "title": "8  L’errore standard della misurazione",
    "section": "",
    "text": "8.1 Introduzione\nI coefficienti di affidabilità che abbiamo discusso nel capitolo precedente rappresentano una misura proporzionale della varianza osservata di un test che è attribuibile alla varianza reale. Questi coefficienti sono fondamentali per confrontare l’affidabilità dei punteggi ottenuti da diverse procedure di valutazione. In generale, preferiremo selezionare il test che produce i punteggi con la migliore affidabilità. Tuttavia, una volta scelto il test, il nostro focus si sposta sull’interpretazione dei punteggi.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#errore-standard-di-misurazione-sem",
    "href": "chapters/ctt/04_err_std_mis.html#errore-standard-di-misurazione-sem",
    "title": "8  L’errore standard della misurazione",
    "section": "8.2 Errore Standard di Misurazione (SEM)",
    "text": "8.2 Errore Standard di Misurazione (SEM)\nL’Errore Standard di Misurazione (SEM) diventa una statistica più pratica quando l’attenzione è rivolta all’interpretazione dei punteggi di un test. Il SEM è definito come la deviazione standard della distribuzione dei punteggi che un individuo otterrebbe se fosse sottoposto a un numero infinito di forme parallele del test, costituite da item campionati casualmente dallo stesso dominio di contenuto.\nPer comprendere meglio, immaginiamo di creare un numero infinito di forme parallele di un test e di far svolgere queste forme alla stessa persona, senza che vi siano effetti di trasferimento. La presenza dell’errore di misurazione impedirebbe alla persona di ottenere sempre lo stesso punteggio. Anche se ogni test rappresenta ugualmente bene il dominio di contenuto, il candidato potrebbe ottenere risultati migliori in alcuni test e peggiori in altri, semplicemente a causa di errori casuali (ad esempio, la fortuna nel conoscere le risposte agli item selezionati per una versione del test ma non per un’altra). Prendendo i punteggi ottenuti in tutti questi test, si otterrebbe una distribuzione di punteggi. La media di questa distribuzione rappresenta il punteggio vero (T) dell’individuo, mentre il SEM è la deviazione standard di questa distribuzione di punteggi di errore.\nOvviamente, non è possibile attuare questi procedimenti nella realtà, quindi dobbiamo stimare il SEM utilizzando le informazioni disponibili. Esamineremo qui l’approccio utilizzato dalla Teoria Classica dei Test (CTT) per raggiungere questo obiettivo.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#stima-di-sem",
    "href": "chapters/ctt/04_err_std_mis.html#stima-di-sem",
    "title": "8  L’errore standard della misurazione",
    "section": "8.3 Stima di SEM",
    "text": "8.3 Stima di SEM\nSecondo Lord (1968), l’errore \\(E = X - T\\) rappresenta la variabile aleatoria di interesse primario nella CTT. L’obiettivo della CTT è stimare il punteggio vero di ogni rispondente e confrontare le stime ottenute per rispondenti diversi. La grandezza dell’errore \\(E\\) fornisce informazioni essenziali in questo contesto. La discrepanza tra il punteggio osservato e il punteggio vero può essere misurata utilizzando la deviazione standard degli errori \\(E\\), conosciuta appunto come “Errore Standard della Misurazione” o SEM. Il SEM è quindi lo strumento impiegato dalla CTT per stimare in che misura un punteggio osservato differisce dal punteggio vero.\nNel presente capitolo esploreremo come sia possibile stimare la deviazione standard dell’errore (\\(\\sigma_E\\)) in un campione di osservazioni. Questo consente di comprendere meglio la precisione dei punteggi ottenuti attraverso un test psicometrico e di interpretare in modo più accurato i risultati.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#lincertezza-della-misura",
    "href": "chapters/ctt/04_err_std_mis.html#lincertezza-della-misura",
    "title": "8  L’errore standard della misurazione",
    "section": "8.4 L’incertezza della misura",
    "text": "8.4 L’incertezza della misura\nIn base alla CTT, è possibile stimare l’errore standard della misurazione utilizzando una formula che dipende dalla deviazione standard della distribuzione dei punteggi del test e dall’attendibilità del test. Mediante questa formula, è possibile ottenere una stima dell’errore standard associato a un singolo punteggio, il quale indica quanto il punteggio osservato può variare rispetto al vero punteggio di un individuo:\n\\[\n\\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}},\n\\] (eq-err-stnd-mis)\ndove \\(\\sigma_X\\) rappresenta la deviazione standard dei punteggi ottenuti da un campione di soggetti e \\(\\rho_{XX^\\prime}\\) è il coefficiente di attendibilità. Attraverso questo calcolo, si ottiene l’errore standard della misurazione sottraendo l’attendibilità del test da 1, quindi calcolando la radice quadrata del risultato e moltiplicandolo per la deviazione standard dei punteggi del test.\nLa logica alla base dell’errore standard della misurazione si fonda sull’assunzione che se una persona dovesse sostenere numerosi test equivalenti, i punteggi ottenuti seguirebbero una distribuzione normale con il vero punteggio dell’individuo come media. In altre parole, possiamo immaginare che l’individuo affronti ripetutamente versioni identiche del test, in circostanze simili e senza ricordare le risposte precedenti. In tale contesto ipotetico, l’errore standard della misurazione rappresenterebbe la deviazione standard tra queste misurazioni ripetute.\nLa formula sopra indicata evidenzia come l’errore standard della misurazione (\\(\\sigma_E\\)) sia strettamente correlato all’attendibilità del test: all’aumentare dell’attendibilità del test, l’errore standard della misurazione diminuisce. Se l’attendibilità del test si avvicina a 0, l’errore standard della misurazione tende a diventare uguale alla deviazione standard dei punteggi osservati del test. In contrasto, se l’attendibilità del test raggiunge 1, l’errore standard della misurazione si riduce a zero: in una situazione di perfetta affidabilità, in cui non vi è alcun errore di misurazione, \\(\\sigma_E\\) assume valore zero.\n\n8.4.1 Interpretazione\nLa Teoria Classica dei Test (CTT) postula che, se un individuo dovesse ripetere un test un numero infinito di volte, mantenendo inalterate le condizioni di somministrazione, i punteggi ottenuti si distribuirebbero in maniera normale attorno al suo vero punteggio. L’errore standard di misura (SEM) viene quindi definito come la stima della deviazione standard di questa distribuzione ipotetica di punteggi. Di conseguenza, un SEM elevato indica una maggiore incertezza nell’utilizzo del test per valutare l’abilità latente dell’individuo.\nSecondo McDonald, invece, il termine di errore (E) segue una distribuzione di propensione, che riflette le variazioni casuali nelle prestazioni di un individuo nel tempo a causa di test. Queste variazioni possono essere influenzate da fattori quali lo stato d’animo, la motivazione e altre variabili contestuali. L’errore standard di misura, in questo contesto, fornisce una quantificazione della deviazione standard dei punteggi attesi per un individuo, se fosse possibile testarlo un numero infinito di volte (o attraverso test equivalenti) in condizioni identiche, assumendo che il suo vero punteggio rimanga invariato.\nIl coefficiente di attendibilità, la varianza dell’errore e l’errore standard di misura rappresentano metriche che riflettono la precisione di un test psicometrico, ciascuna fornendo un tipo di insight specifico sulla precisione:\n\nL’errore standard di misura (SEM) offre una stima della precisione di un punteggio osservato per un individuo, offrendo una base per inferenze riguardo l’affidabilità di quel punteggio specifico. Al contrario, il coefficiente di attendibilità non si presta a una interpretazione così diretta in relazione ai punteggi individuali.\nIl SEM è calcolato nell’unità di misura dei punteggi del test, facilitando la comprensione e l’interpretazione della variabilità attorno al punteggio osservato di un individuo. Diversamente, la varianza dell’errore è espressa come il quadrato delle unità di misura del punteggio, rendendola meno intuitiva per interpretazioni dirette riguardanti la precisione del punteggio.\nIl coefficiente di attendibilità quantifica il rapporto tra la varianza dei punteggi veri e la varianza totale dei punteggi osservati, risultando in un indice senza unità di misura (adimensionale). Questo lo distingue dal SEM e dalla varianza dell’errore, in quanto l’attendibilità valuta la consistenza relativa dei punteggi all’interno dell’intero test piuttosto che la precisione di un singolo punteggio osservato.\n\nEsempio 1. Consideriamo un esempio in cui un test di intelligenza fornisce un punteggio medio di 100 con una deviazione standard di 15. Supponiamo inoltre che l’attendibilità di questo test sia pari a 0.73. Vogliamo calcolare l’errore standard della misurazione.\nUtilizzando la formula dell’errore standard della misurazione, otteniamo:\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\sigma_E &= \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}} \\notag\\\\\n&= 15 \\sqrt{1 - 0.73} \\notag\\\\\n&= 7.79.\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nIl valore 7.79 rappresenta l’errore standard atteso nei punteggi ottenuti da un singolo individuo se il test fosse somministrato più volte sotto identiche condizioni. In altre parole, ci aspettiamo che i punteggi variino in media di circa 8 punti tra diverse somministrazioni del test.\nInoltre, possiamo utilizzare l’errore standard della misurazione per calcolare un intervallo di confidenza intorno al vero punteggio del rispondente. Utilizzando la proprietà della distribuzione gaussiana, possiamo stimare che il 95% dei punteggi ottenuti da ripetute somministrazioni del test si troveranno nell’intervallo:\n\\[\n\\text{punteggio vero del rispondente} \\pm 1.96 \\cdot \\text{errore standard della misurazione}.\n\\]\nNel nostro caso, questo intervallo sarebbe pari a \\(2 \\cdot 1.96 \\cdot 7.79 = 30.54\\) punti. Quindi, ci aspettiamo che i punteggi del QI di un singolo rispondente varino all’interno di un intervallo di 30 punti se il test fosse somministrato molte volte sotto le stesse condizioni.\nQuesto esempio dimostra che se un test ha un’attendibilità di 0.73 e una deviazione standard dei punteggi di 15, la misurazione del test su un singolo individuo risulterebbe poco affidabile a causa dell’ampio errore di misurazione. A titolo di confronto, la Full Scale IQ (FSIQ) della WAIS-IV {cite:p}wechsler2008wechsler ha un’attendibilità split-half di 0.98 e un errore standard di misurazione di 2.16.\nL’errore standard della misurazione può anche essere calcolato utilizzando la funzione SE.Means() del pacchetto psychometric.\n\nSE.Meas(15, .73)\n\n7.79422863405995\n\n\nEsempio 2. Continuando con l’esempio precedente, per gli ipotetici dati riportati sopra, poniamoci ora la seguente domanda: qual è la probabilità che un rispondente ottenga un punteggio minore o uguale a 116 nel test, se il suo punteggio vero fosse uguale a 120?\nIl problema si risolve rendendosi conto che i punteggi del rispondente si distribuiscono normalmente attorno al punteggio vero di 120, con una deviazione standard uguale a 7.79. Dobbiamo dunque trovare l’area sottesa alla normale \\(\\mathcal{N}(120, 7.79)\\) nell’intervallo \\([-\\infty, 116]\\). Utilizzando R, la soluzione si trova nel modo seguente:\n\npnorm(116, 120, 7.79)\n\n0.303808211691303\n\n\nSe la variabile aleatoria che corrisponde al punteggio osservato segue una distribuzione \\(\\mathcal{N}(120, 7.79)\\), la probabilità che il rispondente ottenga un punteggio minore o uguale a 116 è dunque uguale a 0.30.\nEsempio 3. Sempre per l’esempio discusso, poniamoci ora la seguente domanda: quale intervallo di valori centrato sul punteggio vero contiene, con una probabilità di 0.95, i punteggi che il rispondente otterrebbe in ipotetiche somministrazioni ripetute del test sotto le stesse identiche condizioni?\nDobbiamo trovare i quantili della distribuzione \\(\\mathcal{N}(120, 7.79)\\) a cui sono associate le probabilità di 0.025 e 0.975. La soluzione è data da:\n\nqnorm(c(.025, .975), 120, 7.79)\n\n\n104.731880560433135.268119439567\n\n\nL’intervallo cercato è dunque \\([104.7, 135.3]\\).\nEsempio 4. Calcoliamo ora l’errore standard di misurazione utilizzando un campione di dati grezzi. Esamineremo un set di dati discusso da {cite:t}brown2015confirmatory. Il set di dati grezzi contiene 9 indicatori utilizzati per misurare la depressione maggiore così come è definita nel DSM-IV:\n\nMDD1: depressed mood;\nMDD2: loss of interest in usual activities;\nMDD3: weight/appetite change;\nMDD4: sleep disturbance;\nMDD5: psychomotor agitation/retardation;\nMDD6: fatigue/loss of energy;\nMDD7: feelings of worthlessness/guilt;\nMDD8: concentration difficulties;\nMDD9: thoughts of death/suicidality.\n\nImportiamo i dati:\n\ndf &lt;- readRDS(\n    here::here(\"data\", \"mdd_sex.RDS\")\n) |&gt;\n    dplyr::select(-sex)\n\nCi sono 750 osservazioni:\n\ndim(df) |&gt; print()\n\n[1] 750   9\n\n\n\nhead(df)\n\n\nA data.frame: 6 x 9\n\n\n\nmdd1\nmdd2\nmdd3\nmdd4\nmdd5\nmdd6\nmdd7\nmdd8\nmdd9\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\n5\n4\n1\n6\n5\n6\n5\n4\n2\n\n\n2\n5\n5\n5\n5\n4\n5\n4\n5\n4\n\n\n3\n4\n5\n4\n2\n6\n6\n0\n0\n0\n\n\n4\n5\n5\n3\n3\n5\n5\n6\n4\n0\n\n\n5\n5\n5\n0\n5\n0\n4\n6\n0\n0\n\n\n6\n6\n6\n4\n6\n4\n6\n5\n6\n2\n\n\n\n\n\nCalcoliamo il coefficiente di attendibilità \\(\\alpha\\) di Cronbach con la funzione alpha() del pacchetto psych.\n\nres &lt;- psych::alpha(df)\nalpha &lt;- res$total$raw_alpha\nalpha\n\n0.753150463775787\n\n\nCalcoliamo un vettore che contiene il punteggio totale del test per ciascun individuo:\n\ntotal_score &lt;- rowSums(df)\n\nTroviamo l’errore standard di misurazione:\n\nsd(total_score) * sqrt(1 - alpha)\n\n5.29643177867088\n\n\nConfrontiamo il risultato con quello ottenuto con la funzione SE.Meas():\n\nSE.Meas(sd(total_score), alpha)\n\n5.29643177867088",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#dimostrazione",
    "href": "chapters/ctt/04_err_std_mis.html#dimostrazione",
    "title": "8  L’errore standard della misurazione",
    "section": "8.5 Dimostrazione",
    "text": "8.5 Dimostrazione\nEsaminiamo ora la derivazione della formula per l’errore standard di misurazione, \\(\\sigma_E = \\sigma_X \\sqrt{1 - \\rho_{XX^\\prime}}\\). Per arrivare a questa formula, seguiremo due passaggi chiave: innanzitutto, calcoleremo la varianza del punteggio vero e successivamente rappresenteremo il punteggio osservato come la somma della varianza del punteggio vero e la varianza dell’errore.\nIniziamo definendo il coefficiente di attendibilità come \\(\\rho_{XX^\\prime} = \\frac{\\sigma^2_T}{\\sigma^2_X}\\), in cui \\(\\sigma^2_T\\) è la varianza del punteggio vero e \\(\\sigma^2_X\\) è la varianza del punteggio osservato. Utilizzando questa definizione, possiamo riscrivere \\(\\sigma^2_T\\) come \\(\\sigma^2_T = \\rho_{XX^\\prime} \\sigma^2_X\\), considerando che \\(X\\) e \\(X^\\prime\\) sono forme parallele di un test.\nDato che \\(\\sigma_X = \\sigma_{X^\\prime}\\), possiamo scrivere l’equazione precedente come \\(\\sigma^2_T = \\rho_{XX^\\prime} \\sigma_X \\sigma_{X^\\prime}\\). Inoltre, la covarianza tra \\(X\\) e \\(X^\\prime\\) è definita come \\(\\sigma_{XX^\\prime} = \\rho_{XX^\\prime} \\sigma_X \\sigma_{X^\\prime}\\). Da qui, possiamo affermare che \\(\\sigma^2_T = \\sigma_{XX^\\prime}\\), ovvero che la varianza del punteggio vero equivale alla covarianza tra due misurazioni parallele.\nOra, passiamo a calcolare la varianza dell’errore, \\(\\sigma^2_E\\). La varianza del punteggio osservato è espressa come \\(\\sigma^2_X = \\sigma^2_T + \\sigma^2_E\\). Utilizzando la definizione di attendibilità, possiamo riscrivere questa equazione come \\(\\sigma^2_X = \\rho_{XX^\\prime} \\sigma^2_X + \\sigma^2_E\\), da cui otteniamo:\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\sigma^2_E &= \\sigma^2_X - \\sigma^2_X \\rho_{XX^\\prime} \\\\\n&= \\sigma^2_X (1 - \\rho_{XX^\\prime}).\n\\end{aligned}\n\\end{equation}\n\\]\nDi conseguenza, la varianza dell’errore di misurazione, \\(\\sigma^2_E\\), può essere espressa come il prodotto di due fattori: il primo rappresenta la varianza del punteggio osservato, mentre il secondo equivale a uno meno la correlazione tra le due forme parallele del test (\\(\\rho_{XX^\\prime}\\)). In conclusione, abbiamo calcolato l’incognita \\(\\sigma^2_E\\) in termini di due quantità osservabili, \\(\\sigma^2_X\\) e \\(\\rho_{XX^\\prime}\\).",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#relazione-tra-affidabilità-e-sem",
    "href": "chapters/ctt/04_err_std_mis.html#relazione-tra-affidabilità-e-sem",
    "title": "8  L’errore standard della misurazione",
    "section": "8.6 Relazione tra Affidabilità e SEM",
    "text": "8.6 Relazione tra Affidabilità e SEM\nSi osserva che, all’aumentare dell’affidabilità di un test, l’Errore Standard di Misurazione (SEM) diminuisce. Questa relazione inversa è coerente con il fatto che il coefficiente di affidabilità riflette la proporzione della varianza dei punteggi osservati dovuta alla varianza dei punteggi veri, e il SEM è una stima dell’errore presente nei punteggi del test. Quindi, maggiore è l’affidabilità dei punteggi di un test, minore è il SEM, e maggior fiducia possiamo avere nella precisione dei punteggi del test. Viceversa, minore è l’affidabilità di un test, maggiore è il SEM, e minore è la nostra fiducia nella precisione dei punteggi del test.\nPer esempio, con un coefficiente di affidabilità perfetto pari a 1.0, il SEM sarebbe uguale a 0, indicando l’assenza di errore nella misurazione e che il punteggio ottenuto rappresenta il punteggio vero. Un coefficiente di affidabilità pari a 0, invece, produrrebbe un SEM uguale alla deviazione standard (SD) dei punteggi ottenuti, indicando che tutta la varianza dei punteggi del test è dovuta a errori.\nIl SEM è tradizionalmente utilizzato nel calcolo di intervalli o bande intorno ai punteggi osservati, all’interno dei quali ci si aspetta che cada il punteggio vero. Ora passeremo a questa applicazione del SEM.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#intervallo-di-confidenza-e-errore-standard-di-misurazione-sem",
    "href": "chapters/ctt/04_err_std_mis.html#intervallo-di-confidenza-e-errore-standard-di-misurazione-sem",
    "title": "8  L’errore standard della misurazione",
    "section": "8.7 Intervallo di Confidenza e Errore Standard di Misurazione (SEM)",
    "text": "8.7 Intervallo di Confidenza e Errore Standard di Misurazione (SEM)\nL’intervallo di confidenza rappresenta un range di punteggi che include il vero punteggio di un individuo con una probabilità prescritta. Generalmente, utilizziamo il SEM per calcolare gli intervalli di confidenza. Il SEM fornisce informazioni sulla distribuzione dei punteggi osservati intorno ai punteggi veri.\nAd esempio, se un individuo ha un punteggio vero di 70 in un test con un SEM di 3, ci aspetteremmo che ottenga punteggi tra 67 e 73 due terzi delle volte, a patto che non ci siano cambiamenti nelle prestazioni a causa della ripetizione del test.\n\n# Definiamo il punteggio vero e il SEM\npunteggio_vero &lt;- 70\nSEM &lt;- 3\n\npnorm(73, 70, 3) - pnorm(67, 70, 3)\n\n0.682689492137086\n\n\nPer ottenere un intervallo di confidenza del 95%, determiniamo il numero di deviazioni standard che comprendono il 95% dei punteggi in una distribuzione. Con un punteggio vero di 70 e un SEM di 3, l’intervallo di confidenza del 95% sarebbe 70 ± 3(1.96), ovvero 70 ± 5.88. Quindi, in questa situazione, ci aspetteremmo che il punteggio osservato dell’individuo sia tra 64.12 e 75.88, il 95% delle volte.\n\n# Calcoliamo il valore critico Z per il livello di confidenza del 95%\nlivello_confidenza &lt;- 0.95\nz_critico &lt;- qnorm((1 + livello_confidenza) / 2)\n\n# Calcoliamo l'errore standard dell'intervallo\nerrore_standard_intervallo &lt;- SEM * z_critico\n\n# Calcoliamo l'intervallo di confidenza\nintervallo_confidenza_inf &lt;- punteggio_vero - errore_standard_intervallo\nintervallo_confidenza_sup &lt;- punteggio_vero + errore_standard_intervallo\n\n# Stampiamo l'intervallo di confidenza\ncat(\"L'intervallo di confidenza al 95% e' [\", intervallo_confidenza_inf, \", \", intervallo_confidenza_sup, \"]\\n\")\n\nL'intervallo di confidenza al 95% e' [ 64.12011 ,  75.87989 ]\n\n\n\n8.7.1 Relazione tra Affidabilità, SEM e Intervalli di Confidenza\nÈ utile notare la relazione tra l’affidabilità di un punteggio di test, il SEM e gli intervalli di confidenza. Ricordiamo che all’aumentare dell’affidabilità dei punteggi, il SEM diminuisce. La stessa relazione esiste tra l’affidabilità dei punteggi di test e gli intervalli di confidenza. Man mano che l’affidabilità dei punteggi di test aumenta (denotando meno errore di misurazione), gli intervalli di confidenza diventano più piccoli (denotando maggiore precisione nella misurazione).\n\n\n8.7.2 Vantaggio del SEM e dell’Uso degli Intervalli di Confidenza\nIl SEM e l’utilizzo degli intervalli di confidenza forniscono ci ricordano che l’errore di misurazione è un elemento intrinseco a tutti i punteggi e che dovremmo interpretare tali punteggi con cautela. Troppo spesso, si tende a interpretare un singolo punteggio numerico come se fosse assolutamente preciso, trascurando la presenza di errori associati.\nPer esempio, se si riporta che Alice ha un QI totale di 113, i suoi genitori potrebbero essere inclini a interpretare questo dato come un’indicazione precisa del QI di Alice, assumendo che sia esattamente 113. Tuttavia, anche quando si utilizzano test di alta qualità per misurare il QI, i punteggi ottenuti non sono privi di errore. Il SEM e gli intervalli di confidenza sono strumenti utili che ci consentono di quantificare e illustrare questa inevitabile incertezza associata ai punteggi di misurazione. Essi ci avvertono che ogni punteggio contiene una certa dose di errore e ci invitano a considerare i risultati con una visione più prudente e completa.\n\n\n8.7.3 Problema nel Calcolare l’Intervallo di Confidenza\nUn problema potenziale con l’approccio descritto sopra è che non conosciamo il vero punteggio dell’esaminato, ma solo il punteggio osservato. È comune usare il SEM per stabilire intervalli di confidenza intorno ai punteggi ottenuti. Tuttavia, è importante sottolineare che questa pratica non è corretta {cite:p}charter1996revisiting.\n\nIn spite of {cite:t}dudek1979continuing’s reminder that the SEM should not be used to construct confidence intervals, many test manuals, computer-scoring programs, and texts in psychology and education continue to do so. Because authors of many textbooks and manuals make these errors, it is understandable that those who learned from and look to these sources for guidance also make these errors. In summary, the SEM should not be used to construct confidence intervals for test scores (p. 1141).\n\nÈ invece possibile costruire gli intervalli di confidenza basati su punteggi veri stimati e sull’errore standard della stima (SEE). Questo approccio verrà descritto nel prossimo capitolo.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#considerazioni-conclusive",
    "href": "chapters/ctt/04_err_std_mis.html#considerazioni-conclusive",
    "title": "8  L’errore standard della misurazione",
    "section": "8.8 Considerazioni conclusive",
    "text": "8.8 Considerazioni conclusive\nNel contesto della CTT, le stime di affidabilità si rivelano uno strumento fondamentale per valutare la coerenza dei test. Tuttavia, quando si affrontano decisioni relative al singolo individuo, come ad esempio determinare se un candidato supera un esame, diventa più vantaggioso fare riferimento all’errore standard di misurazione (SEM). Il SEM rende evidente quanto i punteggi di un test siano suscettibili di fluttuazioni casuali se lo stesso test venisse ripetuto più volte dallo stesso esaminando. In generale, un SEM più ridotto corrisponde a un intervallo di fluttuazioni casuali più stretto. Ciò implica che, grazie a un SEM più basso, i punteggi rifletteranno in modo più coerente le vere capacità dell’esaminando.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/04_err_std_mis.html#session-info",
    "href": "chapters/ctt/04_err_std_mis.html#session-info",
    "title": "8  L’errore standard della misurazione",
    "section": "8.9 Session Info",
    "text": "8.9 Session Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] psychometric_2.4  multilevel_2.7    MASS_7.3-60.0.1   nlme_3.1-164     \n [5] ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n [9] ggExtra_0.10.1    bayesplot_1.11.1  gridExtra_2.3     patchwork_1.2.0  \n[13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-17     psych_2.4.1      \n[17] scales_1.3.0      markdown_1.12     knitr_1.45        lubridate_1.9.3  \n[21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.0    \n[29] tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] nloptr_2.0.3       rmarkdown_2.26     vctrs_0.6.5       \n  [7] minqa_1.2.6        base64enc_0.1-3    rstatix_0.7.2     \n [10] htmltools_0.5.7    broom_1.0.5        Formula_1.2-5     \n [13] htmlwidgets_1.6.4  plyr_1.8.9         uuid_1.2-0        \n [16] igraph_2.0.2       mime_0.12          lifecycle_1.0.4   \n [19] pkgconfig_2.0.3    Matrix_1.6-5       R6_2.5.1          \n [22] fastmap_1.1.1      shiny_1.8.0        digest_0.6.34     \n [25] OpenMx_2.21.11     fdrtool_1.2.17     colorspace_2.1-0  \n [28] rprojroot_2.0.4    Hmisc_5.1-1        fansi_1.0.6       \n [31] timechange_0.3.0   abind_1.4-5        compiler_4.3.3    \n [34] withr_3.0.0        glasso_1.11        htmlTable_2.4.2   \n [37] backports_1.4.1    carData_3.0-5      ggsignif_0.6.4    \n [40] corpcor_1.6.10     gtools_3.9.5       tools_4.3.3       \n [43] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [46] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [49] quadprog_1.5-8     promises_1.2.1     lisrelToR_0.3     \n [52] grid_4.3.3         pbdZMQ_0.3-11      checkmate_2.3.1   \n [55] cluster_2.1.6      reshape2_1.4.4     generics_0.1.3    \n [58] gtable_0.3.4       tzdb_0.4.0         data.table_1.15.2 \n [61] hms_1.1.3          car_3.1-2          utf8_1.2.4        \n [64] sem_3.1-15         pillar_1.9.0       IRdisplay_1.1     \n [67] rockchalk_1.8.157  later_1.3.2        splines_4.3.3     \n [70] lattice_0.22-5     kutils_1.73        tidyselect_1.2.0  \n [73] miniUI_0.1.1.1     pbapply_1.7-2      stats4_4.3.3      \n [76] xfun_0.42          qgraph_1.9.8       arm_1.13-1        \n [79] stringi_1.8.3      boot_1.3-29        evaluate_0.23     \n [82] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [85] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [88] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n [91] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n [94] parallel_4.3.3     ellipsis_0.3.2     jpeg_0.1-10       \n [97] lme4_1.1-35.1      openxlsx_4.2.5.2   crayon_1.5.2      \n[100] rlang_1.1.3        mnormt_2.1.1",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'errore standard della misurazione</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html",
    "href": "chapters/ctt/05_err_std_stima.html",
    "title": "9  La stima del punteggio vero",
    "section": "",
    "text": "9.1 Introduzione\nUno dei principali scopi della valutazione psicologica è stimare il punteggio vero del soggetto. Il punteggio osservato \\(X\\) differisce dal punteggio vero \\(T\\) a causa dell’errore di misurazione: \\(X = T + E\\). Ora poniamoci l’obiettivo di utilizzare i concetti della Teoria Classica per stimare il punteggio vero di un soggetto, utilizzando il suo punteggio osservato e l’affidabilità del test. Questa stima risulta particolarmente utile quando è necessario costruire un intervallo di confidenza per il punteggio vero del soggetto.\nPer costruire l’intervallo di confidenza del vero punteggio, sono necessarie due misurazioni:\nCominciamo affrontando il problema della stima del vero punteggio.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#introduzione",
    "href": "chapters/ctt/05_err_std_stima.html#introduzione",
    "title": "9  La stima del punteggio vero",
    "section": "",
    "text": "Una stima del vero punteggio.\nL’errore standard della stima (ossia, una stima della deviazione standard della distribuzione delle stime del punteggio vero che si otterrebbero se il test venisse somministrato infinite volte nelle stesse condizioni).",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#il-paradosso-di-kelley",
    "href": "chapters/ctt/05_err_std_stima.html#il-paradosso-di-kelley",
    "title": "9  La stima del punteggio vero",
    "section": "9.2 Il paradosso di Kelley",
    "text": "9.2 Il paradosso di Kelley\nNegli anni ’20, Kelly ha dimostrato come sia possibile stimare il punteggio vero del rispondente utilizzando un modello di regressione. La formula di Kelley si fonda sull’equivalenza algebrica che lega l’attendibilità al quadrato del coefficiente di correlazione tra i punteggi osservati e quelli veri. Pertanto, la stima del punteggio vero di un rispondente può essere calcolata nel seguente modo:\n\\[\n\\begin{equation}\n\\hat{T} = \\mu_x + \\rho  (X - \\mu_x),\n\\end{equation}\n\\] (eq-kelly)\ndove \\(X\\) rappresenta il punteggio osservato, \\(\\mu_x\\) è la media dei punteggi ottenuti da tutti i partecipanti nel campione, e \\(\\rho\\) è l’attendibilità del test.\nQuando l’attendibilità è perfetta (\\(\\rho = 1\\)), il punteggio vero coincide con il punteggio osservato. Nel caso di attendibilità nulla (dove tutta la varianza è attribuibile all’errore di misurazione), la stima più accurata del punteggio vero è semplicemente la media del campione. Per valori di \\(\\rho\\) compresi tra 0 e 1, la stima del punteggio vero si discosta dal punteggio osservato in direzione della media campionaria. In questo modo, la stima del punteggio vero illustra il concetto di regressione verso la media dei punteggi osservati, considerando l’attendibilità del test.\nLa formula del punteggio vero può essere interpretata nel modo seguente: per stimare il vero punteggio di un individuo, si parte dalla media della distribuzione di tutti i partecipanti e si procede in direzione del punteggio osservato. Tuttavia, il punteggio osservato non viene raggiunto completamente; l’entità dello spostamento è proporzionale all’attendibilità del test. Ciò implica che la stima del punteggio vero di un individuo, a seconda del valore di \\(\\rho\\), tiene conto anche della sua posizione rispetto alla media del gruppo. Se il soggetto si trova al di sotto della media, la stima del punteggio vero sarà maggiorata e viceversa. Questo fenomeno è noto come il “paradosso di Kelley”.\nÈ cruciale mettere in evidenza una discrepanza tra la formula di Kelley e l’intuizione comune che suggerisce il punteggio osservato come una stima accurata del vero punteggio (cioè \\(\\hat{T} = X\\)). Tuttavia, questo punto di vista è valido solo quando la misura è perfettamente attendibile (\\(\\rho = 1\\)). Al contrario, quando \\(\\rho = 0\\), la formula di Kelley suggerisce di utilizzare la media dei punteggi osservati come stima del vero punteggio, implicando che il punteggio osservato non rifletta necessariamente il vero punteggio, ma solo l’errore di misurazione.\nIn pratica, è estremamente improbabile che \\(\\rho\\) sia esattamente uguale a zero. Invece, con valori di \\(\\rho\\) compresi tra 0 e 1, la stima del punteggio vero si troverà in una posizione intermedia tra il punteggio osservato e la media della popolazione. Per una comprensione più dettagliata di questo concetto, possiamo fare riferimento a Kelley (1947), il quale ha osservato che:\n\nThis is an interesting equation in that it expresses the estimate of true ability as the weighted sum of two separate estimates, – one based upon the individual’s observed score, \\(X_1\\) (\\(X\\) nella notazione corrente) and the other based upon the mean of the group to which he belongs, \\(M_1\\) (\\(\\mu_x\\) nella notazione corrente). If the test is highly reliable, much weight is given to the test score and little to the group mean, and vice versa.\n\nPer chiarire l’eq. {eq}eq-kelly e la sua derivazione in termini di predizione del punteggio vero a partire dal punteggio osservato, iniziamo esaminando il modello di base di regressione lineare semplice. Questo modello stabilisce una relazione diretta tra il punteggio osservato \\(X\\) e il punteggio vero \\(T\\), una relazione che inizialmente abbiamo descritto con la formula \\(X = 0 + 1 \\cdot T + E\\). Il nostro interesse specifico qui, però, si sposta verso la predizione del punteggio vero \\(T\\) utilizzando il punteggio osservato \\(X\\), attraverso un modello di regressione. La formula per questa predizione assume la forma:\n\\[\nT = \\alpha + \\beta X + \\varepsilon.\n\\]\nRiorganizzando le variabili in termini di deviazioni dalla loro media (\\(x = X - \\bar{X}\\) e \\(\\tau = T - \\mathbb{E}(T)\\)), e considerando l’intercetta \\(\\alpha\\) come 0, il modello si semplifica in \\(\\hat{\\tau} = \\beta x\\), dove \\(\\hat{\\tau}\\) rappresenta la nostra stima del punteggio vero come deviazione dalla media. La questione centrale diventa quindi il calcolo di \\(\\beta\\), che è la pendenza della retta di regressione nel nostro modello semplificato.\nIl valore di \\(\\beta\\) viene definito come \\(\\beta = \\frac{\\sigma_{\\tau x}}{\\sigma^2_x}\\), che ci permette di esprimere il modello come:\n\\[\n\\hat{\\tau} = \\frac{\\sigma_{\\tau x}}{\\sigma^2_x} x.\n\\]\nIntroducendo la correlazione tra \\(x\\) (o \\(X\\)) e \\(\\tau\\) (o \\(T\\)), denotata \\(\\rho_{\\tau x}\\), e sostituendo la covarianza con il prodotto della correlazione per le deviazioni standard dei punteggi, riscriviamo l’equazione come:\n\\[\n\\hat{\\tau} = \\rho_{\\tau x}\\frac{\\sigma_{\\tau}}{\\sigma_x} x.\n\\]\nQuesto ci porta a considerare la definizione di attendibilità, secondo cui la varianza del punteggio vero può essere espressa come \\(\\sigma^2_{\\tau} = \\sigma^2_x \\rho_{xx^\\prime}\\). La stima del punteggio vero, in termini di deviazioni dalla media, diventa quindi una funzione del coefficiente di attendibilità e della deviazione del punteggio osservato dalla sua media:\n\\[\n\\hat{\\tau} = \\rho_{\\tau x} \\sqrt{\\rho_{xx^\\prime}} x.\n\\]\nAvendo dimostrato che \\(\\rho^2_{\\tau x} = \\rho_{xx^\\prime}\\), possiamo ulteriormente semplificare la nostra stima del punteggio vero come:\n\\[\n\\hat{\\tau} = \\rho_{xx^\\prime} x.\n\\]\nQuesto ci indica che la stima del punteggio vero (in termini di deviazioni dalla media) si ottiene moltiplicando il punteggio osservato, anch’esso espresso come deviazione dalla media, per il coefficiente di attendibilità.\nPer ritornare alla formula in termini di punteggi grezzi, aggiungiamo la media dei punteggi osservati \\(\\bar{X}\\) alla nostra equazione, ottenendo così la stima del punteggio vero grezzo \\(\\hat{T}\\):\n\\[\n\\hat{T} = \\rho_{XX^\\prime} (X - \\bar{X}) + \\bar{X}.\n\\]\nEspandendo e riorganizzando l’equazione, arriviamo a una forma che chiarisce la relazione tra la media dei punteggi osservati, il coefficiente di attendibilità, e il punteggio osservato grezzo:\n\\[\n\\hat{T} = \\bar{X} + \\rho_{XX^\\prime} (X - \\bar{X}).\n\\]\nQuesta equazione finale dimostra come la stima del punteggio vero grezzo possa essere calcolata regolando il punteggio osservato per la media dei punteggi e il coefficiente di attendibilità.\nNel contesto di dati campionari, dove il coefficiente di attendibilità popolazionale \\(\\rho_{XX^\\prime}\\) viene sostituito con il suo corrispettivo campionario \\(r_{XX^\\prime}\\), la formula diventa:\n\\[\n\\hat{T} = \\bar{X} + r_{XX^\\prime} (X - \\bar{X}),\n\\]\noffrendo un metodo pratico per stimare il punteggio vero di un individuo a partire dal suo punteggio osservato, con l’aggiunta della media dei punteggi osservati e il coefficiente di attendibilità campionario.\nEsercizio. Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a \\(\\bar{X} = 100\\), si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a \\(X\\) = 115.\nLa stima del punteggio vero \\(\\hat{T}\\) è uguale a\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\hat{T} &= \\bar{X} + r_{XX^\\prime}  (X - \\bar{X})\\notag\\\\\n&= 100 + 0.80 \\cdot (115 - 100) = 112.\n\\end{aligned}\n\\end{equation}\n\\]\nIn alternativa, possiamo usare la funzione Est.true del pacchetto psychometric.\n\nEst.true(115, 100, .8)\n\n112",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#lerrore-standard-della-stima-nel-modello-di-regressione-di-kelley",
    "href": "chapters/ctt/05_err_std_stima.html#lerrore-standard-della-stima-nel-modello-di-regressione-di-kelley",
    "title": "9  La stima del punteggio vero",
    "section": "9.3 L’Errore Standard della Stima nel Modello di Regressione di Kelley",
    "text": "9.3 L’Errore Standard della Stima nel Modello di Regressione di Kelley\nNell’ambito del modello di regressione di Kelley, uno strumento fondamentale per valutare la precisione delle stime del punteggio vero ottenute dai punteggi osservati è l’errore standard della stima. Questo indice quantifica quanto le nostre stime del punteggio vero possano variare se ripetessimo il test più volte sotto le stesse condizioni. Denotiamo l’errore standard della stima con \\(\\sigma_{\\hat{T}}\\), dove \\(\\hat{T}\\) rappresenta la stima del valore vero.\n\n9.3.1 Importanza dell’Errore Standard della Stima\nL’errore standard della stima è cruciale per comprendere quanto sia affidabile la stima del punteggio vero. Un errore standard più piccolo indica una stima più precisa. Matematicamente, l’errore standard della stima si calcola come:\n\\[\n\\sigma_{\\hat{T}} = \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 -\\rho_{XX^\\prime})},\n\\] (eq-std-err-estimate)\ndove \\(\\sigma_X\\) è la deviazione standard dei punteggi osservati, e \\(\\rho_{XX^\\prime}\\) rappresenta il coefficiente di correlazione tra i punteggi osservati e i punteggi veri. Questa formula assume una distribuzione normale dei punteggi e una relazione lineare tra i punteggi osservati e i punteggi veri.\nPer dati campionari, utilizziamo una formula leggermente modificata per calcolare l’errore standard della stima:\n\\[\ns_{\\hat{T}} = s_X \\sqrt{r_{XX^\\prime} (1-r_{XX^\\prime})},\n\\]\nqui \\(s_X\\) indica la deviazione standard campionaria, e \\(r_{XX^\\prime}\\) è il coefficiente di affidabilità campionario.\n\n\n9.3.2 Derivazione dell’Errore Standard della Stima\nPer derivare l’equazione dell’errore standard di stima, {eq}eq-std-err-estimate, iniziamo con la definizione dell’errore \\(\\varepsilon\\), che rappresenta la discrepanza tra il punteggio reale \\(T\\) e il punteggio stimato \\(\\hat{T}\\), come illustrato nella formula:\n\\[\n\\varepsilon = T - \\hat{T}.\n\\]\nSi sottolinea la distinzione tra l’errore di misurazione, indicato con \\(E = X - T\\) (dove \\(E\\) quantifica l’errore di misurazione, ovvero la differenza tra il punteggio osservato \\(X\\) e il punteggio reale \\(T\\)), e l’errore \\(\\varepsilon = T - \\hat{T}\\) (che esprime la discrepanza tra il punteggio reale \\(T\\) e la sua stima \\(\\hat{T}\\)).\nAdottando la formula \\(\\hat{T} = \\bar{X} + \\rho_{XX^\\prime} (X - \\bar{X})\\) per esprimere \\(\\hat{T}\\), si può calcolare la varianza di \\(\\varepsilon\\) come segue:\n\\[\n\\begin{aligned}\n\\mathbb{V}(\\varepsilon) &=  \\mathbb{V}(T - \\hat{T}) \\\\\n&= \\mathbb{V}(T - \\bar{X} - \\rho_{XX^\\prime} X + \\rho_{XX^\\prime}\\bar{X}).\n\\end{aligned}\n\\]\nDato che l’aggiunta di una costante non altera la varianza di una variabile aleatoria, possiamo semplificare l’espressione a:\n\\[\n\\mathbb{V}(\\varepsilon) = \\mathbb{V}(T - \\rho_{XX^\\prime}X).\n\\]\nSfruttando la regola della varianza per la somma di variabili aleatorie, incluso il caso in cui una variabile è moltiplicata per una costante, arriviamo a:\n\\[\n\\begin{aligned}\n\\mathbb{V}(\\varepsilon) &= \\mathbb{V}(T) + \\rho_{XX^\\prime}^2 \\mathbb{V}(X) - 2 \\rho_{XX^\\prime} \\mbox{Cov}(X,T) \\\\\n&= \\sigma^2_T + \\rho_{XX^\\prime}^2 \\sigma^2_X - 2 \\rho_{XX^\\prime} \\sigma_{XT}.\n\\end{aligned}\n\\]\nCon \\(\\sigma_{XT} = \\sigma^2_T\\), possiamo ridurre ulteriormente l’espressione a:\n\\[\n\\sigma^2_{\\varepsilon} = \\sigma^2_T + \\left(\\frac{\\sigma_T^2}{\\sigma_X^2}\\right)^2 \\sigma^2_X - 2 \\frac{\\sigma_T^2}{\\sigma_X^2} \\sigma_{XT}.\n\\]\nSemplificando, otteniamo:\n\\[\n\\begin{aligned}\n\\sigma^2_{\\varepsilon} &= \\sigma^2_T + \\frac{\\sigma_T^4}{\\sigma_X^4} \\sigma^2_X - 2 \\frac{\\sigma_T^2}{\\sigma_X^2} \\sigma_{XT} \\\\\n&= \\sigma^2_T \\left(1 + \\frac{\\sigma_T^2}{\\sigma_X^2} - 2 \\frac{\\sigma_{XT}}{\\sigma_X^2}\\right).\n\\end{aligned}\n\\]\nInfine, con \\(\\sigma_{XT} = \\sigma^2_T\\), semplifichiamo a:\n\\[\n\\begin{aligned}\n\\sigma^2_{\\varepsilon} &= \\sigma^2_T \\left(1 - \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\right).\n\\end{aligned}\n\\]\nQuesto ci porta alla formula dell’errore standard della stima \\(\\sigma_{\\varepsilon}\\):\n\\[\n\\begin{aligned}\n\\sigma_{\\varepsilon} &= \\sigma_T \\sqrt{1 - \\frac{\\sigma^2_T}{\\sigma^2_X}} \\\\\n&= \\sigma_T \\sqrt{\\frac{\\sigma^2_X - \\sigma^2_T}{\\sigma^2_X}} \\\\\n&= \\frac{\\sigma_T}{\\sigma_X} \\sqrt{\\sigma^2_X - \\sigma^2_T}.\n\\end{aligned}\n\\]\nConsiderando che \\(\\sigma^2_X = \\sigma^2_T + \\sigma^2_E\\), l’errore standard di stima diventa:\n\\[\n\\begin{aligned}\n\\sigma_{\\varepsilon} &= \\frac{\\sigma_T}{\\sigma_X} \\sqrt{\\sigma^2_E } \\\\\n&= \\frac{\\sigma_T}{\\sigma_X} \\sigma_E \\\\\n&= \\sqrt{\\rho_{XX^\\prime}} \\sigma_E.\n\\end{aligned}\n\\]\nDato che l’errore standard di misurazione è definito come \\(\\sigma_E = \\sigma_X \\sqrt{1 - \\rho_{XX^\\prime}}\\), possiamo concludere che:\n\\[\n\\begin{aligned}\n\\sigma_{\\varepsilon} &= \\sqrt{\\rho_{XX^\\prime}} \\sigma_E \\\\\n&= \\sqrt{\\rho_{XX^\\prime}} \\sigma_X \\sqrt{1-\\rho_{XX^\\prime}} \\\\\n&= \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 - \\rho_{XX^\\prime})}.\n\\end{aligned}\n\\]\nQuest’ultima espressione dimostra come l’errore standard della stima sia determinato dalla deviazione standard dei punteggi osservati, modulata dal coefficiente di correlazione tra i punteggi osservati e i punteggi veri.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#intervallo-di-confidenza-per-il-punteggio-vero",
    "href": "chapters/ctt/05_err_std_stima.html#intervallo-di-confidenza-per-il-punteggio-vero",
    "title": "9  La stima del punteggio vero",
    "section": "9.4 Intervallo di confidenza per il punteggio vero",
    "text": "9.4 Intervallo di confidenza per il punteggio vero\nSiamo ora finalmente nelle condizioni di potere calcolare l’intervallo di confidenza per il punteggio vero. Conoscendo l’errore standard della stima \\(\\sigma_{\\hat{T}}\\), l’intervallo di confidenza per il punteggio vero è dato da:\n\\[\n\\hat{T} \\pm z  \\sigma_{\\hat{T}},\n\\]\nladdove \\(\\hat{T}\\) è la stima del punteggio vero e \\(z\\) è il quantile della normale standardizzata al livello di probabilità desiderato. Se il campione è piccolo (minore di 30) è opportuno usare \\(t\\) anziché \\(z\\).\n\n9.4.1 Interpretazione\nNotiamo che l’intervallo \\(\\hat{T} \\pm z \\sigma_{\\hat{T}}\\) è centrato sulla stima puntuale del valore vero e la sua ampiezza dipende sia dal livello di confidenza desiderato (rappresentato dal quantile \\(z_{\\frac{\\alpha}{2}}\\)), sia dal grado di precisione dello stimatore, misurato dall’errore standard della stima, \\(\\sigma_{\\hat{T}} = \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 -\\rho_{XX^\\prime})}\\). È importante notare che l’errore standard della stima diventa sempre più grande man mano che diminuisce l’attendibilità \\(\\rho_{XX^\\prime}\\) del test.\nL’intervallo di confidenza indica quanto l’imprecisione della misura influisce sull’interpretazione dei dati. Più l’intervallo di confidenza è ampio, maggiore è l’incertezza nella valutazione dei risultati.\nEsercizio. {cite:t}charter1996revisiting ha esaminato l’effetto della variazione dell’attendibilità del test sull’ampiezza dell’intervallo di confidenza per il punteggio vero. Utilizzando come esempio i punteggi di QI (\\(\\mu\\) = 100, \\(\\sigma\\) = 15), Charter ha immaginato di variare il coefficiente di attendibilità del test utilizzato per la misurazione del QI. I valori presi in considerazione sono 0.55, 0.65, 0.75, 0.85 e 0.95. Ad esempio, supponiamo di avere un punteggio osservato pari a QI = 120 e un coefficiente di attendibilità del test \\(\\rho_{xx^\\prime}\\) pari a 0.65. In tali circostanze, la stima del punteggio vero è pari a\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\hat{T} &= \\bar{X} + r_{XX^\\prime}  (X - \\bar{X}) \\notag\\\\\n&= 100 + 0.65 (120 - 100)\\notag\\\\\n&= 113.\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nL’errore standard della stima è uguale a\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\sigma_{\\hat{T}} &= \\sigma_{X} \\sqrt{r_{XX^\\prime} (1 - r_{XX^\\prime})} \\notag\\\\\n&= 15 \\sqrt{0.65 (1 - 0.65)}\\notag\\\\\n&= 7.15.\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nL’intervallo di confidenza al 95% per la stima del punteggio vero diventa pertanto uguale a\n\\[\n113 \\pm 1.96 \\cdot 7.15 = [98.98, 127.02].\n\\]\nSi noti che si può calcolare l’errore standard della stima con la funzione SE.Est() del pacchetto psychometric.\n\nSE.Est(15, .65)\n\n7.15454401062709\n\n\nInoltre, la funzione CI.tscore() restituisce sia la stima del punteggio vero sia l’intervallo di fiducia al livello desiderato di significatività.\n\nCI.tscore(120, 100, 15, 0.65, level = 0.95)\n\n\nA data.frame: 1 x 4\n\n\nSE.Est\nLCL\nT.Score\nUCL\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n7.154544\n98.97735\n113\n127.0226",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#cut-off",
    "href": "chapters/ctt/05_err_std_stima.html#cut-off",
    "title": "9  La stima del punteggio vero",
    "section": "9.5 Cut-off",
    "text": "9.5 Cut-off\nGli intervalli di confidenza per il punteggio vero possono essere utilizzati per confrontare i limiti dell’intervallo con un cut-off. Ci sono tre possibili esiti: il limite inferiore dell’intervallo di confidenza è maggiore del cut-off, il limite superiore dell’intervallo è minore del cut-off, o il valore del cut-off è compreso all’interno dell’intervallo. Nel primo caso, lo psicologo può affermare, con un grado di certezza \\(1-\\alpha\\), che il valore vero del rispondente è superiore al cut-off. Nel secondo caso, lo psicologo può affermare, con un grado di certezza \\(1-\\alpha\\), che il valore vero del rispondente è inferiore al cut-off. Nel terzo caso, lo psicologo non può concludere né che il valore vero sia inferiore né che sia superiore al cut-off, con un certo grado di incertezza.\n\nSi considerino i punteggi del QI, per cui \\(\\bar{X}\\) = 100 e \\(s_X\\) = 15. Sia l’attendibilità del test \\(\\rho_{XX^\\prime}\\) = 0.95. Supponiamo che il rispondente abbia un QI = 130. Poniamo che il cut-off per ammettere il rispondente ad un corso avanzato sia 120. Ci sono tre alternative: il valore vero del rispondente è sicuramente maggiore di 120; il valore vero del rispondente è sicuramente inferiore di 120; le evidenze disponibili ci lasciano in dubbio se il punteggio vero sia maggiore o minore di 120. Svolgiamo i calcoli per trovare l’intervallo di confidenza al livello di certezza del 95%:\n\nxm &lt;- 100\nsx &lt;- 15\nrho &lt;- .95\nx &lt;- 130\nt.hat &lt;- xm + rho * (x - xm)\nt.hat\nse.t &lt;- sx * sqrt(rho * (1 - rho))\nse.t\nt.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t\n\n128.5\n\n\n3.26917420765551\n\n\n\n122.092536293808134.907463706192\n\n\nDato che il limite inferiore dell’intervallo di confidenza è maggiore del cut-off, lo psicologo conclude che il punteggio vero del rispondente è maggiore di 120. Quindi, raccomanda che il rispondente sia ammesso al corso avanzato.\nContinuando con l’esempio precedente, supponiamo che l’attendibilità del test abbia un valore simile a quello che solitamente si ottiene empiricamente, ovvero 0.80.\n\nxm &lt;- 100\nsx &lt;- 15\nrho &lt;- .8\nx &lt;- 130\nt.hat &lt;- xm + rho * (x - xm)\nt.hat\nse.t &lt;- sx * sqrt(rho * (1 - rho))\nse.t\nt.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t\n\n124\n\n\n6\n\n\n\n112.24021609276135.75978390724\n\n\nIn questo secondo esempio, l’intervallo di confidenza al 95% è \\([112.24,\n135.76]\\) e contiene il valore del cut-off. Dunque, la decisione dello psicologo è che non vi sono evidenze sufficienti che il vero valore del rispondente sia superiore al cut-off. Si noti come la diminuzione dell’attendibilità del test porta all’aumento delle dimensioni dell’intervallo di confidenza.\n\n9.6 Conclusioni\nLa teoria classica del punteggio vero si basa su un modello additivo, in cui il punteggio osservato \\(X\\) è considerato come la somma di due componenti: il punteggio vero stabile \\(T\\) e il punteggio di errore casuale \\(E\\). Si suppone che i punteggi di errore all’interno di un test non siano correlati né con i punteggi veri di quel test, né con i punteggi veri o di errore di altri test. I test paralleli hanno gli stessi punteggi veri e le stesse varianze di errore. I test che sono considerati “sostanzialmente equivalenti” o \\(\\tau\\)-equivalenti, differiscono solo per una costante additiva nei punteggi veri. Tuttavia, queste assunzioni possono essere violate in presenza di diverse condizioni che influenzano i punteggi dei test. Tuttavia, poiché non possiamo osservare direttamente \\(T\\) ed \\(E\\), non possiamo verificare direttamente l’adeguatezza di queste assunzioni, e possiamo solo fare delle supposizioni su quando sarebbero appropriate.\nÈ importante tenere a mente che i punteggi veri e quelli di errore sono concetti teorici e non osservabili. Ciò che possiamo osservare sono solamente i punteggi \\(X\\). Quando parliamo di punteggi veri, è essenziale considerare che il “punteggio vero”, cioè la media dei punteggi su ripetuti test indipendenti con lo stesso test, è un’astrazione teorica. Questo punteggio potrebbe non riflettere completamente l’attributo “vero” di interesse, a meno che il test non abbia una precisione perfetta, cioè che misuri esattamente ciò che afferma di misurare.\nL’approccio della teoria classica dei test (CTT) nel processo di sviluppo dei test presenta diversi vantaggi. In primo luogo, i concetti della CTT sono ampiamente diffusi e comprensibili. Inoltre, sono relativamente accessibili sia per l’apprendimento che per l’applicazione. Le statistiche descrittive dei test (come la media, la deviazione standard, l’intervallo, ecc.) e le analisi degli item (in particolare la facilità e la discriminazione degli item) possono essere calcolate facilmente. Inoltre, il modello CTT risponde a varie esigenze di misurazione, specialmente nello sviluppo di valutazioni di competenze e collocazione, utili per decisioni di ammissione, confronti tra programmi e valutazioni in vari contesti lavorativi. Infine, il modello CTT permette l’interpretazione dei punteggi degli esaminati sia al 0% che al 100% e delle stime di facilità degli item da 0.0 a 1.0, riflettendo risultati realistici. Tuttavia, queste interpretazioni non sono comuni nei modelli di teoria della risposta agli item (IRT).\nTuttavia, l’adozione della CTT presenta anche alcune limitazioni. In primo luogo, i test basati sulla CTT tendono a essere lunghi e composti da elementi omogenei. In secondo luogo, gli individui che svolgono test sviluppati con il metodo CTT potrebbero essere confrontati con item troppo facili o troppo difficili per le loro abilità. In terzo luogo, i risultati dei test CTT si applicano solo al campione considerato o a campioni molto simili. In quarto luogo, tali risultati si applicano solo alla selezione corrente di item. In quinto luogo, a causa della dipendenza dalla distribuzione normale, la CTT è adatta solo per lo sviluppo di test normativi. In sesto luogo, a causa della correlazione tra discriminazione degli item, affidabilità e alcune stime di validità, gli item e i test basati sulla CTT possono risultare sensibili alle differenze agli estremi della scala. Infine, sebbene gli errori di misurazione nei test CTT varino lungo tutto il range dei possibili punteggi (ossia, l’errore standard di misurazione è minore vicino alla media e aumenta man mano che i punteggi si discostano dalla media in entrambe le direzioni), l’errore standard di misurazione stimato nei CTT rappresenta una media su tutto questo intervallo.\n\n\n9.7 Session Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] psychometric_2.4  multilevel_2.7    MASS_7.3-60.0.1   nlme_3.1-164     \n [5] ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n [9] ggExtra_0.10.1    bayesplot_1.11.1  gridExtra_2.3     patchwork_1.2.0  \n[13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-17     psych_2.4.1      \n[17] scales_1.3.0      markdown_1.12     knitr_1.45        lubridate_1.9.3  \n[21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.0    \n[29] tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] nloptr_2.0.3       rmarkdown_2.26     vctrs_0.6.5       \n  [7] minqa_1.2.6        base64enc_0.1-3    rstatix_0.7.2     \n [10] htmltools_0.5.7    broom_1.0.5        Formula_1.2-5     \n [13] htmlwidgets_1.6.4  plyr_1.8.9         uuid_1.2-0        \n [16] igraph_2.0.2       mime_0.12          lifecycle_1.0.4   \n [19] pkgconfig_2.0.3    Matrix_1.6-5       R6_2.5.1          \n [22] fastmap_1.1.1      shiny_1.8.0        digest_0.6.34     \n [25] OpenMx_2.21.11     fdrtool_1.2.17     colorspace_2.1-0  \n [28] rprojroot_2.0.4    Hmisc_5.1-1        fansi_1.0.6       \n [31] timechange_0.3.0   abind_1.4-5        compiler_4.3.3    \n [34] withr_3.0.0        glasso_1.11        htmlTable_2.4.2   \n [37] backports_1.4.1    carData_3.0-5      ggsignif_0.6.4    \n [40] corpcor_1.6.10     gtools_3.9.5       tools_4.3.3       \n [43] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [46] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [49] quadprog_1.5-8     promises_1.2.1     lisrelToR_0.3     \n [52] grid_4.3.3         pbdZMQ_0.3-11      checkmate_2.3.1   \n [55] cluster_2.1.6      reshape2_1.4.4     generics_0.1.3    \n [58] gtable_0.3.4       tzdb_0.4.0         data.table_1.15.2 \n [61] hms_1.1.3          car_3.1-2          utf8_1.2.4        \n [64] sem_3.1-15         pillar_1.9.0       IRdisplay_1.1     \n [67] rockchalk_1.8.157  later_1.3.2        splines_4.3.3     \n [70] lattice_0.22-5     kutils_1.73        tidyselect_1.2.0  \n [73] miniUI_0.1.1.1     pbapply_1.7-2      stats4_4.3.3      \n [76] xfun_0.42          qgraph_1.9.8       arm_1.13-1        \n [79] stringi_1.8.3      boot_1.3-29        evaluate_0.23     \n [82] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [85] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [88] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n [91] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n [94] parallel_4.3.3     ellipsis_0.3.2     jpeg_0.1-10       \n [97] lme4_1.1-35.1      openxlsx_4.2.5.2   crayon_1.5.2      \n[100] rlang_1.1.3        mnormt_2.1.1",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#conclusioni",
    "href": "chapters/ctt/05_err_std_stima.html#conclusioni",
    "title": "9  La stima del punteggio vero",
    "section": "9.6 Conclusioni",
    "text": "9.6 Conclusioni\nLa teoria classica del punteggio vero si basa su un modello additivo, in cui il punteggio osservato \\(X\\) è considerato come la somma di due componenti: il punteggio vero stabile \\(T\\) e il punteggio di errore casuale \\(E\\). Si suppone che i punteggi di errore all’interno di un test non siano correlati né con i punteggi veri di quel test, né con i punteggi veri o di errore di altri test. I test paralleli hanno gli stessi punteggi veri e le stesse varianze di errore. I test che sono considerati “sostanzialmente equivalenti” o \\(\\tau\\)-equivalenti, differiscono solo per una costante additiva nei punteggi veri. Tuttavia, queste assunzioni possono essere violate in presenza di diverse condizioni che influenzano i punteggi dei test. Tuttavia, poiché non possiamo osservare direttamente \\(T\\) ed \\(E\\), non possiamo verificare direttamente l’adeguatezza di queste assunzioni, e possiamo solo fare delle supposizioni su quando sarebbero appropriate.\nÈ importante tenere a mente che i punteggi veri e quelli di errore sono concetti teorici e non osservabili. Ciò che possiamo osservare sono solamente i punteggi \\(X\\). Quando parliamo di punteggi veri, è essenziale considerare che il “punteggio vero”, cioè la media dei punteggi su ripetuti test indipendenti con lo stesso test, è un’astrazione teorica. Questo punteggio potrebbe non riflettere completamente l’attributo “vero” di interesse, a meno che il test non abbia una precisione perfetta, cioè che misuri esattamente ciò che afferma di misurare.\nL’approccio della teoria classica dei test (CTT) nel processo di sviluppo dei test presenta diversi vantaggi. In primo luogo, i concetti della CTT sono ampiamente diffusi e comprensibili. Inoltre, sono relativamente accessibili sia per l’apprendimento che per l’applicazione. Le statistiche descrittive dei test (come la media, la deviazione standard, l’intervallo, ecc.) e le analisi degli item (in particolare la facilità e la discriminazione degli item) possono essere calcolate facilmente. Inoltre, il modello CTT risponde a varie esigenze di misurazione, specialmente nello sviluppo di valutazioni di competenze e collocazione, utili per decisioni di ammissione, confronti tra programmi e valutazioni in vari contesti lavorativi. Infine, il modello CTT permette l’interpretazione dei punteggi degli esaminati sia al 0% che al 100% e delle stime di facilità degli item da 0.0 a 1.0, riflettendo risultati realistici. Tuttavia, queste interpretazioni non sono comuni nei modelli di teoria della risposta agli item (IRT).\nTuttavia, l’adozione della CTT presenta anche alcune limitazioni. In primo luogo, i test basati sulla CTT tendono a essere lunghi e composti da elementi omogenei. In secondo luogo, gli individui che svolgono test sviluppati con il metodo CTT potrebbero essere confrontati con item troppo facili o troppo difficili per le loro abilità. In terzo luogo, i risultati dei test CTT si applicano solo al campione considerato o a campioni molto simili. In quarto luogo, tali risultati si applicano solo alla selezione corrente di item. In quinto luogo, a causa della dipendenza dalla distribuzione normale, la CTT è adatta solo per lo sviluppo di test normativi. In sesto luogo, a causa della correlazione tra discriminazione degli item, affidabilità e alcune stime di validità, gli item e i test basati sulla CTT possono risultare sensibili alle differenze agli estremi della scala. Infine, sebbene gli errori di misurazione nei test CTT varino lungo tutto il range dei possibili punteggi (ossia, l’errore standard di misurazione è minore vicino alla media e aumenta man mano che i punteggi si discostano dalla media in entrambe le direzioni), l’errore standard di misurazione stimato nei CTT rappresenta una media su tutto questo intervallo.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/05_err_std_stima.html#session-info",
    "href": "chapters/ctt/05_err_std_stima.html#session-info",
    "title": "9  La stima del punteggio vero",
    "section": "9.7 Session Info",
    "text": "9.7 Session Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] psychometric_2.4  multilevel_2.7    MASS_7.3-60.0.1   nlme_3.1-164     \n [5] ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n [9] ggExtra_0.10.1    bayesplot_1.11.1  gridExtra_2.3     patchwork_1.2.0  \n[13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-17     psych_2.4.1      \n[17] scales_1.3.0      markdown_1.12     knitr_1.45        lubridate_1.9.3  \n[21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.0    \n[29] tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] nloptr_2.0.3       rmarkdown_2.26     vctrs_0.6.5       \n  [7] minqa_1.2.6        base64enc_0.1-3    rstatix_0.7.2     \n [10] htmltools_0.5.7    broom_1.0.5        Formula_1.2-5     \n [13] htmlwidgets_1.6.4  plyr_1.8.9         uuid_1.2-0        \n [16] igraph_2.0.2       mime_0.12          lifecycle_1.0.4   \n [19] pkgconfig_2.0.3    Matrix_1.6-5       R6_2.5.1          \n [22] fastmap_1.1.1      shiny_1.8.0        digest_0.6.34     \n [25] OpenMx_2.21.11     fdrtool_1.2.17     colorspace_2.1-0  \n [28] rprojroot_2.0.4    Hmisc_5.1-1        fansi_1.0.6       \n [31] timechange_0.3.0   abind_1.4-5        compiler_4.3.3    \n [34] withr_3.0.0        glasso_1.11        htmlTable_2.4.2   \n [37] backports_1.4.1    carData_3.0-5      ggsignif_0.6.4    \n [40] corpcor_1.6.10     gtools_3.9.5       tools_4.3.3       \n [43] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [46] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [49] quadprog_1.5-8     promises_1.2.1     lisrelToR_0.3     \n [52] grid_4.3.3         pbdZMQ_0.3-11      checkmate_2.3.1   \n [55] cluster_2.1.6      reshape2_1.4.4     generics_0.1.3    \n [58] gtable_0.3.4       tzdb_0.4.0         data.table_1.15.2 \n [61] hms_1.1.3          car_3.1-2          utf8_1.2.4        \n [64] sem_3.1-15         pillar_1.9.0       IRdisplay_1.1     \n [67] rockchalk_1.8.157  later_1.3.2        splines_4.3.3     \n [70] lattice_0.22-5     kutils_1.73        tidyselect_1.2.0  \n [73] miniUI_0.1.1.1     pbapply_1.7-2      stats4_4.3.3      \n [76] xfun_0.42          qgraph_1.9.8       arm_1.13-1        \n [79] stringi_1.8.3      boot_1.3-29        evaluate_0.23     \n [82] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [85] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [88] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n [91] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n [94] parallel_4.3.3     ellipsis_0.3.2     jpeg_0.1-10       \n [97] lme4_1.1-35.1      openxlsx_4.2.5.2   crayon_1.5.2      \n[100] rlang_1.1.3        mnormt_2.1.1",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>La stima del punteggio vero</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/06_ctt_applications.html",
    "href": "chapters/ctt/06_ctt_applications.html",
    "title": "10  Applicazioni della CTT",
    "section": "",
    "text": "10.1 Introduzione\nQuesto capitolo si focalizza sull’esplorazione di diverse applicazioni della Teoria Classica dei Test (CTT). Innanzitutto, verrà analizzato il metodo per determinare il numero di item necessari al fine di ottenere un livello specifico di affidabilità. Successivamente, si approfondirà il concetto di correlazione disattenuata e si esaminerà il metodo proposto per mitigare tale disattenuazione. Infine, verrà presentato l’utilizzo del metodo di Kelly per migliorare la stima dei punteggi reali a livello individuale, e sarà esaminato come i modelli bayesiani gerarchici rappresentino un’alternativa più moderna a tale approccio.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Applicazioni della CTT</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/06_ctt_applications.html#affidabilità-e-lunghezza-del-test",
    "href": "chapters/ctt/06_ctt_applications.html#affidabilità-e-lunghezza-del-test",
    "title": "10  Applicazioni della CTT",
    "section": "10.2 Affidabilità e lunghezza del test",
    "text": "10.2 Affidabilità e lunghezza del test\nL’affidabilità può essere utilizzata per determinare la lunghezza di un test. La formula di Spearman-Brown può essere adattata per calcolare il numero di item necessari al fine di raggiungere una specifica affidabilità:\n\\[\n\\begin{equation}\np = \\frac{\\rho_p(1 - \\rho_1)}{\\rho_1(1 - \\rho_p)},\n\\end{equation}\n\\] (eq-spearman-brown-item-number)\ndove \\(\\rho_1\\) rappresenta l’affidabilità stimata di un “item medio”, \\(\\rho_p\\) è il livello desiderato di affidabilità complessiva del test, e \\(p\\) è il numero di item nel test esteso.\nPer esempio, supponiamo che l’attendibilità di un test composto da 5 item sia 0.824, e che \\(\\rho_1\\) sia 0.479. Possiamo chiederci quanti item debbano essere aggiunti per raggiungere un livello di affidabilità pari a 0.95.\nPonendo \\(\\rho_p\\) a 0.95 e \\(\\rho_1\\) a 0.479, in base all’equazione {eq}eq-spearman-brown-item-number, otteniamo che:\n\nrho_1 &lt;- 0.479\n(.95 * (1 - rho_1)) / (rho_1 * (1 - .95))\n\n20.6659707724426\n\n\nPertanto, per ottenere un livello di affidabilità pari a 0.95 sono necessari almeno 21 item.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Applicazioni della CTT</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/06_ctt_applications.html#attenuazione",
    "href": "chapters/ctt/06_ctt_applications.html#attenuazione",
    "title": "10  Applicazioni della CTT",
    "section": "10.3 Attenuazione",
    "text": "10.3 Attenuazione\n\n10.3.1 Attenuazione e Correlazioni Disattenuate\nUn aspetto cruciale nell’analisi statistica riguarda il fenomeno dell’attenuazione, che si verifica quando l’incremento dell’errore di misurazione porta a una riduzione della correlazione osservata tra due variabili. Questo errore di misurazione tende a “nascondere” la vera associazione esistente tra le variabili, generando quello che è noto come effetto di attenuazione.\nLord e Novick (1967) hanno sottolineato che, nel tentativo di esplorare la relazione tra due costrutti, gli psicologi spesso ricorrono allo sviluppo di scale di misura. Se esiste una relazione lineare tra queste scale, è possibile calcolare il grado di correlazione attraverso il coefficiente di correlazione. Tuttavia, dato che le scale includono inevitabilmente un certo livello di errore, la correlazione empiricamente osservata tra di esse risulta inferiore rispetto alla correlazione “vera” tra i costrutti. In queste circostanze, è possibile ricorrere a formule specifiche per stimare la correlazione corretta tra i tratti latenti.\nSi può dimostrare che la correlazione tra i punteggi veri di due costrutti, \\(T_X\\) e \\(T_Y\\), può essere calcolata utilizzando la correlazione \\(\\rho_{XY}\\) tra i punteggi osservati \\(X\\) e \\(Y\\), e i coefficienti di affidabilità \\(\\rho_{XX'}\\) e \\(\\rho_{YY'}\\) dei due test, come segue:\n\\[\n\\begin{equation}\n\\rho(T_X, T_Y)  = \\frac{\\rho_{XY}}{\\sqrt{\\rho_{XX^\\prime} \\rho_{YY^\\prime}}}.\n\\end{equation}\n\\](eq-3-9-6)\nAnalogamente, la correlazione tra i punteggi osservati di un test e i punteggi veri di un secondo test può essere espressa attraverso la correlazione tra i punteggi osservati dei due test e il coefficiente di affidabilità del secondo test:\n\\[\n\\begin{equation}\n\\rho(X, T_Y)  = \\frac{\\rho_{XY}}{\\sqrt{\\rho_{YY^\\prime}}}.\n\\end{equation}\n\\](eq-3-9-7)\nQueste equazioni forniscono gli strumenti per calcolare le correlazioni disattenuate secondo la Teoria Classica dei Test (CTT).\nIl calcolo degli intervalli di confidenza per la correlazione corretta richiede un approccio che tenga conto dell’attenuazione dell’affidabilità. Applicando la formula di disattenuazione agli estremi dell’intervallo di confidenza osservato, possiamo ottenere stime più precise degli intervalli di confidenza per la correlazione tra i punteggi veri.\nPer fare un esempio, supponiamo di avere una correlazione osservata di 0.5 tra due misure, con affidabilità di 0.7 per la prima misura e 0.8 per la seconda misura. Vogliamo calcolare la correlazione disattenuata e il relativo intervallo di confidenza.\n\n# Parametri\nr_osservata &lt;- 0.5\nrho_X &lt;- 0.7\nrho_Y &lt;- 0.8\n\n# Calcolo della correlazione disattenuata\nr_corretta &lt;- r_osservata / sqrt(rho_X * rho_Y)\n\n# Stampa della correlazione disattenuata\nprint(paste(\"Correlazione disattenuata:\", r_corretta))\n\n# Calcolo approssimativo dell'intervallo di confidenza (per semplificazione)\n# NOTA: Questo è un esempio semplificato e non riflette il calcolo preciso degli intervalli di confidenza.\nCI_lower_observed &lt;- 0.4 # Limite inferiore osservato\nCI_upper_observed &lt;- 0.6 # Limite superiore osservato\n\nCI_lower_corrected &lt;- CI_lower_observed / sqrt(rho_X * rho_Y)\nCI_upper_corrected &lt;- CI_upper_observed / sqrt(rho_X * rho_Y)\n\n# Stampa dell'intervallo di confidenza corretto\nprint(paste(\"Intervallo di confidenza corretto: da\", CI_lower_corrected, \"a\", CI_upper_corrected))\n\n[1] \"Correlazione disattenuata: 0.668153104781061\"\n[1] \"Intervallo di confidenza corretto: da 0.534522483824849 a 0.801783725737273\"\n\n\n\n\n10.3.2 L’impiego delle Correlazioni Disattenuate\nL’uso delle correlazioni disattenuate risale al 1904 con Spearman, che le applicò in uno studio in cui \\(X\\) misurava la discriminazione dell’altezza del suono e \\(Y\\) l’intelligenza valutata da un insegnante. La correlazione tra queste due misure era \\(\\hat{\\rho}_{XY} = 0.38\\), con affidabilità di \\(\\hat{\\rho}_{XX'} = 0.25\\) e \\(\\hat{\\rho}_{YY'} = 0.55\\). Utilizzando le formule sopra citate, la correlazione predetta tra i punteggi veri di discriminazione del suono e l’intelligenza risultava essere \\(\\hat{\\rho}(X, T_Y) = 0.76\\), mentre tra i punteggi veri dei due costrutti era \\(\\hat{\\rho}(T_X, T_Y) = 1.025\\).\nQuesto esempio evidenzia come l’uso delle correlazioni disattenuate possa portare a stime eccessive, una problematica già rilevata nell’interazione tra Spearman e Karl Pearson. Spearman, attraverso l’applicazione della sua formula, sottolineò come le correlazioni empiriche basse proposte da Pearson potessero essere sottostimate a causa dell’errore di misurazione. Tuttavia, Pearson non accolse queste osservazioni, rimanendo scettico riguardo alla possibilità che la formula di Spearman generasse correlazioni superiori a 1 e rigettando l’idea di quantità non osservabili.\nNonostante queste controversie, Spearman proseguì nello studio delle variabili psicologiche, trovando in numerosi casi che le correlazioni disattenuate si avvicinavano all’unità, suggerendo un’associazione stretta tra variabili indicative dello stesso fenomeno. Queste osservazioni lo portarono a sviluppare ulteriormente l’analisi fattoriale.\nMcDonald (1999) avverte sull’utilizzo delle correlazioni disattenuate, evidenziando la necessità di cautela. Propone come alternativa più affidabile l’uso di modelli di equazioni strutturali per calcolare le correlazioni tra variabili latenti, ovvero quelle non influenzate da errori di misurazione, consentendo un’esplorazione diretta e più accurata delle ipotesi, inclusa la correlazione tra variabili latenti.",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Applicazioni della CTT</span>"
    ]
  },
  {
    "objectID": "chapters/ctt/06_ctt_applications.html#usare-laffidabilità-per-migliorare-linferenza-a-livello-individuale",
    "href": "chapters/ctt/06_ctt_applications.html#usare-laffidabilità-per-migliorare-linferenza-a-livello-individuale",
    "title": "10  Applicazioni della CTT",
    "section": "10.4 Usare l’Affidabilità per Migliorare l’Inferenza a Livello Individuale",
    "text": "10.4 Usare l’Affidabilità per Migliorare l’Inferenza a Livello Individuale\nUn altro uso importante dell’affidabilità è quello che ci consente di migliorare la nostra inferenza sui punteggi veri a livello individuale.\nKelley ha dimostrato – già nel 1920 (vedi Kelley, 1947) – che possiamo stimare i punteggi veri per ciascun individuo, regredendo i punteggi osservati sulla stima dell’affidabilità:\n\\[ \\hat{T} = \\bar{X} + r_{xx'}(X - \\bar{X}). \\]\nQui, \\(\\bar{X}\\) è la media dei punteggi osservati su tutti i soggetti, data da:\n\\[ \\bar{X} = \\frac{1}{N} \\sum_{i=1}^{N} X_i. \\]\nIntuitivamente, il punteggio vero per ciascun soggetto è stimato avvicinando il loro punteggio osservato verso la media dei punteggi a livello di gruppo in proporzione all’affidabilità della stima a livello individuale.\nIn aggiunta alla sua teoria che i punteggi osservati tendono ad essere regolati verso la media del gruppo quando si stima il vero punteggio, Kelley ha evidenziato come l’errore standard della stima del vero punteggio sia ridotto secondo la formula:\n\\[\n\\sigma_{\\hat{T}} = \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 -\\rho_{XX^\\prime})}.\n\\]\nQui, \\(\\sigma_{\\hat{T}}\\) rappresenta l’errore standard della stima del vero punteggio, \\(\\sigma_X\\) è la deviazione standard dei punteggi osservati, e \\(\\rho_{XX^\\prime}\\) indica il coefficiente di affidabilità tra i punteggi osservati e quelli veri. Questo errore standard per le stime dei punteggi veri è inferiore rispetto all’errore standard dei punteggi osservati, espresso come:\n\\[\nSE_{X} = \\sigma_{X} \\sqrt{1 - \\rho_{XX'}}.\n\\]\nIl confronto tra le due formule rivela che l’errore standard della stima del vero punteggio include un fattore aggiuntivo, \\(\\rho_{XX'}\\), che rappresenta il coefficiente di affidabilità. Questo evidenzia l’importanza del coefficiente di affidabilità nell’influenzare la precisione della stima del vero punteggio: un alto coefficiente di affidabilità contribuisce a ridurre l’errore standard della stima, migliorando così la precisione della stima del vero punteggio.\nLe equazioni di Kelley, scoperte nel 1920, anticipano di molti anni i principi alla base degli stimatori di James-Stein, che analogamente aggiustano le stime individuali avvicinandole alla media del gruppo. Questa affinità storica evidenzia un precedente significativo alla comprensione moderna di come le stime possano essere migliorate mediante l’incorporazione di informazioni aggiuntive.\nLa relazione tra le equazioni di Kelley e i concetti bayesiani offre una prospettiva ancora più profonda. Assumendo che i punteggi veri seguano una distribuzione a priori normale e che esista una distribuzione normale dei punteggi veri intorno ai punteggi osservati, l’approccio bayesiano empirico genera medie posteriori che corrispondono alle stime di Kelley dei punteggi veri. Questa equivalenza, come discussa da de Gruijter e van der Kamp nel 2008, stabilisce un ponte concettuale tra la psicometria classica e l’inferenza bayesiana, sottolineando come l’incorporazione di presupposti a priori possa affinare le nostre stime.\nQuesta connessione è ulteriormente rafforzata dall’uso di tecniche simili alla stima bayesiana empirica nei software di modellazione multilivello, come ad esempio il pacchetto lmer in R. Questi software si avvalgono della potenza dell’inferenza bayesiana per integrare informazioni di gruppo, migliorando così la precisione delle inferenze a livello individuale. La pratica di utilizzare informazioni a livello di gruppo per affinare le stime individuali non solo ha radici storiche profonde ma continua a essere una componente essenziale nell’evoluzione delle tecniche statistiche, dimostrando il suo valore nell’arricchire l’accuratezza e l’affidabilità delle inferenze statistiche.\nPer illustrare in modo pratico come avviene la stima dei punteggi veri, ossia il processo di pooling, eseguiremo una simulazione basata sul codice R di Nathaniel Haines. Questa simulazione genera dati seguendo una distribuzione binomiale per 20 soggetti, con una probabilità media di successo di 0.7. La simulazione considera tre diversi set di item: 10, 30 e 100, al fine di esaminare come le variazioni nel numero di item influenzino l’affidabilità ottenuta e, di conseguenza, gli effetti del pooling.\nIl codice inizia definendo il numero di soggetti e la varietà delle dimensioni degli item. Successivamente, genera un campione casuale di “punteggi veri” intorno a 0.7 per ogni soggetto. Viene poi definita una funzione per stimare l’errore standard della misurazione (al quadrato), basata sulla probabilità di successo per ogni item.\nPer ogni set di item, il codice simula i dati osservati per ogni soggetto utilizzando il suo “punteggio vero”. Calcola quindi la media del gruppo per i punteggi osservati, la affidabilità, e l’errore standard di misurazione, utilizzando l’approccio basato sulla varianza. Infine, stima i punteggi veri e gli errori standard associati sia per i punteggi osservati sia per quelli stimati.\nI risultati della simulazione vengono visualizzati in un grafico, che confronta i punteggi veri, osservati e stimati per ogni soggetto, evidenziando come la precisione della stima vari in funzione del numero di item. Il grafico include anche intervalli di confidenza al 95% per i punteggi osservati e stimati, e una linea orizzontale che rappresenta la media del gruppo per i punteggi osservati, offrendo una rappresentazione visiva dell’efficacia del processo di pooling nel recuperare i punteggi veri a partire da dati osservati affetti da errore di misurazione.\n\nset.seed(43202)\n\n# Number of subjects and items\nn_subj &lt;- 20\nn_items &lt;- c(10, 30, 100)\n\n# Random sample of \"true\" scores around .7\ntheta &lt;- rnorm(n_subj, .7, .1)\n\n# Estimate standard error of measurement (squared)\nest_se2 &lt;- function(x) {\n    # Success and failure probability\n    n &lt;- length(x)\n    p &lt;- mean(x)\n    q &lt;- 1 - p\n\n    sig2_ep_i &lt;- (p * q) / (n - 1)\n\n    return(sig2_ep_i)\n}\n\n# Estimate observed and true score\ndis_dat &lt;- foreach(i = seq_along(n_items), .combine = \"rbind\") %do% {\n    # Generate observed data for each subject using \"true\" score\n    X_all &lt;- foreach(t = seq_along(theta), .combine = \"rbind\") %do% {\n        rbinom(n_items[i], 1, prob = theta[t])\n    }\n\n    # group average observed score\n    X_bar &lt;- mean(rowMeans(X_all))\n\n    # Reliability\n    X &lt;- rowMeans(X_all)\n\n    # Standard arror of measurement approach\n    sig2_ep &lt;- mean(apply(X_all, 1, est_se2))\n    sig2_X &lt;- var(X)\n    rho &lt;- 1 - (sig2_ep / sig2_X)\n\n    foreach(t = seq_along(theta), .combine = \"rbind\") %do% {\n        # Using observed scores from parallel form 1\n        X_obs &lt;- X_all[t, ]\n        X_i &lt;- mean(X_obs)\n\n        data.frame(\n            subj_num = t,\n            n_items = n_items[i],\n            theta = theta[t],\n            rho = rho,\n            X = X_i,\n            se_obs = sd(X) * sqrt(1 - rho),\n            se_hat = sd(X) * sqrt(1 - rho) * sqrt(rho),\n            theta_hat = (1 - rho) * X_bar + rho * X_i\n        )\n    }\n}\n\n# Plot true, observed, and estimated true scores\ndis_dat %&gt;%\n    mutate(subj_num = reorder(subj_num, theta)) %&gt;%\n    ggplot(aes(x = subj_num, y = theta)) +\n    geom_point(color = I(\"black\")) +\n    geom_point(aes(x = subj_num, y = X),\n        color = I(\"#DCBCBC\"),\n        position = position_jitter(width = .2, height = 0, seed = 1)\n    ) +\n    geom_linerange(\n        aes(\n            x = subj_num,\n            ymin = X - 1.96 * se_obs,\n            ymax = X + 1.96 * se_obs\n        ),\n        color = I(\"#DCBCBC\"),\n        position = position_jitter(width = .2, height = 0, seed = 1)\n    ) +\n    geom_point(aes(x = subj_num, y = theta_hat),\n        color = I(\"#8F2727\"),\n        position = position_jitter(width = .2, height = 0, seed = 2)\n    ) +\n    geom_linerange(\n        aes(\n            x = subj_num,\n            ymin = theta_hat - 1.96 * se_hat,\n            ymax = theta_hat + 1.96 * se_hat\n        ),\n        color = I(\"#8F2727\"),\n        position = position_jitter(width = .2, height = 0, seed = 2)\n    ) +\n    geom_hline(yintercept = X_bar, linetype = 2, color = I(\"gray\")) +\n    annotate(\"text\",\n        x = 15, y = .4, label = expression(\"True\" ~ theta[i]),\n        color = \"black\", size = 5\n    ) +\n    annotate(\"text\",\n        x = 15, y = .3, label = expression(\"Obs\" ~ X[i]),\n        color = \"#DCBCBC\", size = 5\n    ) +\n    annotate(\"text\",\n        x = 15, y = .2, label = expression(\"Est\" ~ hat(theta)[i]),\n        color = \"#8F2727\", size = 5\n    ) +\n    facet_wrap(c(\"n_items\"), nrow = 1) +\n    ggtitle(\"Regression-Based True Score Estimates\") +\n    xlab(\"Subject\") +\n    ylab(\"Value\") +\n    theme_minimal(base_size = 15) +\n    theme(\n        panel.grid = element_blank(),\n        axis.text.x.bottom = element_blank()\n    )\n\nWarning message in is.na(x):\n\"is.na() applicato ad un oggetto di tipo 'expression' (ne lista, ne vettore)\"\nWarning message in is.na(x):\n\"is.na() applicato ad un oggetto di tipo 'expression' (ne lista, ne vettore)\"\nWarning message in is.na(x):\n\"is.na() applicato ad un oggetto di tipo 'expression' (ne lista, ne vettore)\"\n\n\n\n\n\n\n\n\n\nSi notino tre risultati di questa simulazione:\n\nle stime puntuali basate sulla regressione di Kelley (i punti neri nel grafico) risultano più vicine alla media a livello di gruppo (rappresentata dalla linea tratteggiata grigia orizzontale) di quanto lo siano le stime individuali “non corrette” (punti grigi);\nquesto effetto di “pooling” è tanto maggiore quanto minore è l’attendibilità (in questa simulazione l’attendibilità è stata manipolata variando il numero di item);\ngli intervalli di confidenza per i punteggi veri stimati sono più stretti rispetto a quelli dei punteggi osservati.\n\n\n10.4.1 Approccio Bayesiano\nNella seguente simulazione mostreremo come i risultati raggiunti con la regressione di Kelley possano essere replicati se i dati vengono analizzati con un modello gerarchico bayesiano.\nQuando si analizzano dati provenienti da questionari con risposte dicotomiche (ad esempio, vero/falso o corretto/errato), è possibile applicare la distribuzione di Bernoulli. In questo contesto, ogni risposta data a un item del questionario può essere vista come il risultato di un esperimento di Bernoulli. Se indichiamo con \\(X\\) una variabile casuale che segue tale distribuzione, la probabilità di ottenere un successo (ad esempio, una risposta corretta) è espressa come:\n\\[\n\\Pr(X=1) = p, \\quad \\text{e quindi} \\quad \\Pr(X=0) = 1 - p = q,\n\\]\ndove \\(p\\) indica la probabilità di successo e \\(q\\) quella di insuccesso.\nIntroduciamo il modello di Bernoulli tramite l’equazione logistica:\n\\[\np = \\frac{1}{1 + e^{-\\theta}}.\n\\]\nQuesta formula ci permette di modellare \\(p\\) in termini di \\(\\theta\\), un parametro che riflette una caratteristica o “abilità” dell’individuo. Il modello logistico assicura che \\(p\\), la probabilità di successo, sia sempre compresa nell’intervallo \\([0, 1]\\). Il parametro \\(\\theta\\) viene definito come:\n\\[\n\\theta = \\log\\left(\\frac{p}{1-p}\\right),\n\\]\ne può variare tra \\(-\\infty\\) e \\(+\\infty\\). Attraverso la trasformazione logistica, \\(\\theta\\) viene mappato in un valore di \\(p\\) che rispetta i limiti di una probabilità. Questa funzione di collegamento permette di interpretare il legame tra \\(\\theta\\) e \\(p\\).\nIl modello descritto sopra può essere considerato una forma estremamente semplificata della Teoria della Risposta all’Item (IRT), dove ogni persona è caratterizzata da un unico parametro di abilità (\\(\\theta\\)), e tutti gli item del test sono assunti avere uguale difficoltà e capacità di discriminazione, fissate convenzionalmente a 1.\nIl nostro obiettivo principale nell’analisi dei dati è quindi stimare il parametro \\(\\theta\\) per ogni individuo. La relazione tra \\(\\theta\\) e \\(p\\) è fondamentale: \\(\\theta\\) determina il valore di \\(p\\) attraverso la funzione logistica, che trasforma i valori di \\(\\theta\\) in probabilità \\(p\\) comprese tra 0 e 1. La stima di \\(\\theta\\) ci fornisce, di conseguenza, una misura della probabilità di successo di un individuo in risposta agli item del questionario.\nPer approfondire la nostra comprensione su come emergono le risposte osservate, è fondamentale definire la modalità con cui i parametri \\(\\theta\\) vengono generati per ogni individuo. Similmente a quanto avviene nella teoria classica dei test, dove si presume l’esistenza di una distribuzione di campionamento a livello di popolazione, nell’ambito della modellazione generativa bayesiana si postula una distribuzione generativa per il gruppo. In termini pratici, possiamo ipotizzare che i parametri \\(\\theta\\) individuali derivino da una distribuzione normale standardizzata:\n\\[\n\\theta \\sim \\mathcal{N}(0, 1)\n\\]\nNel contesto bayesiano, questa distribuzione di gruppo viene comunemente identificata come una distribuzione a priori per \\(\\theta\\). In alternativa, possiamo dedurre questi parametri direttamente dai dati:\n\\[\n\\theta \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\nDi conseguenza, si introduce un’ipotesi generativa riguardante i parametri di media \\(\\mu\\) e deviazione standard \\(\\sigma\\) del gruppo, che potrebbero essere descritti, in termini bayesiani tradizionali, come a priori del gruppo. Nel nostro esempio, supponiamo \\(\\mu = 0\\) e \\(\\sigma \\sim \\text{HalfNormal}(1)\\), dove \\(\\text{HalfNormal}(1)\\) rappresenta una distribuzione normale limitata ai valori positivi, coerente con il principio che le deviazioni standard debbano essere positive.\nQuesto approccio introduce un modello gerarchico: durante l’adattamento del modello, i parametri individuali influenzano quelli di gruppo, che a loro volta modellano nuovamente quelli individuali. Analogamente alle stime dei punteggi “veri” ottenuti tramite regressione nella teoria classica dei test, i nostri parametri individuali verranno regolati (“pooled”) verso la media di gruppo, portando a una riduzione degli intervalli di incertezza per le stime individuali.\nPer facilitare la comprensione di come queste assunzioni generative si traducano in pratica, eseguiamo la seguente simulazione.\n\nfile &lt;- file.path(\"hbern.stan\")\n\n\nmod &lt;- cmdstan_model(file)\n\n\nmod$print()\n\ndata {\n  int&lt;lower=0&gt; N;      // Number of subjects\n  int&lt;lower=0&gt; N_items; // Number of timepoints\n  array[N, N_items] int Y; // Binary responses for each subject and item\n}\n\nparameters {\n  real&lt;lower=0&gt; sigma_theta; // SD of individual effects\n  real mu_theta; // Mean of individual effects\n  \n  vector[N] theta_pr; // Non-centered individual-level parameters\n}\n\ntransformed parameters {\n  vector[N] theta = mu_theta + sigma_theta * theta_pr; // Individual-level effects\n}\n\nmodel {\n  // Priors\n  mu_theta ~ normal(0, 1);\n  sigma_theta ~ normal(0, 1);\n  theta_pr ~ normal(0, 1);\n  \n  // Likelihood\n  for (i in 1:N) {\n    for (j in 1:N_items) {\n      Y[i, j] ~ bernoulli_logit(theta[i]);\n    }\n  }\n}\n\ngenerated quantities {\n  array[N] real p; // Success probability estimate for each individual\n  \n  for (i in 1:N) {\n    p[i] = inv_logit(theta[i]);\n  }\n}\n\n\nIl codice Stan presentato adotta una parametrizzazione non centrata (non-centered parameterization) per la parte di modello a livello di gruppo, una scelta motivata per migliorare l’efficienza computazionale e facilitare la convergenza degli algoritmi di stima, come il campionamento Hamiltoniano Monte Carlo (HMC) usato da Stan. Questa scelta di design è matematicamente equivalente al modello generativo descritto dalle equazioni precedenti, pur offrendo vantaggi pratici significativi in fase di implementazione.\nLa parametrizzazione non centrata è una strategia avanzata nella modellazione bayesiana, specialmente utile nei modelli gerarchici o multilivello. Essa differisce dalla parametrizzazione centrata, nella quale i parametri di gruppo sono direttamente definiti dai parametri individuali. Invece, con la parametrizzazione non centrata, i parametri individuali sono inizialmente espressi come variazioni indipendenti rispetto alla media e deviazione standard di gruppo, per poi essere trasformati.\nImplementazione nel codice Stan:\n\nDefinizione dei Parametri:\n\nsigma_theta denota la deviazione standard degli effetti individuali, indicando la variabilità dei parametri \\(\\theta\\) a livello personale.\nmu_theta rappresenta la media degli effetti individuali.\ntheta_pr corrisponde ai parametri individuali nella forma non centrata, esprimendo le deviazioni rispetto alla media di gruppo in unità standardizzate.\n\nTrasformazione dei Parametri:\n\nGli effetti individuali effettivi (theta) sono ottenuti trasformando theta_pr per allinearli attorno a mu_theta e adattarli alla scala definita da sigma_theta. Questo processo è sintetizzato dall’equazione theta = mu_theta + sigma_theta * theta_pr, che trasla e scala theta_pr per ottenere valori centrati e proporzionati correttamente.\n\nApplicazione nel Modello:\n\nAll’interno del modello, sia mu_theta che sigma_theta sono sottoposti a priori normali (normal(0, 1)), presupponendo una distribuzione iniziale per questi parametri a livello di gruppo. Anche theta_pr è assoggettato a una distribuzione normale standard come priori, rispecchiando l’approccio di considerare le variazioni in termini standardizzati.\nLa verosimiglianza del modello è calcolata usando una distribuzione di Bernoulli con una funzione di collegamento logit, basata sui valori di theta trasformati, per analizzare le risposte binarie Y fornite da ogni soggetto per ogni item.\n\n\nAttraverso questa struttura, il modello mira a una stima più stabile e accurata dei parametri, beneficiando della maggiore efficienza computazionale e della riduzione dei problemi di convergenza che spesso accompagnano la modellazione bayesiana gerarchica.\nSimuliamo i dati di un singolo soggetto.\n\n# Initialize parameters for a single subject\nn_subj &lt;- 1\nn_items &lt;- 30 # Example with 30 items for simplicity\n\n# Generate \"true\" theta for the subject\ntheta &lt;- rnorm(n_subj, .7, .1)\n\n# Generate observed data for the subject using \"true\" theta\nY &lt;- rbinom(n_items, 1, prob = theta)\n\nAdattiamo il modello gerarchico bayesiano ai dati.\n\nfit_bernoulli &lt;- mod$sample(\n    data = list(\n        N = n_subj,\n        N_items = n_items,\n        Y = matrix(Y, nrow = 1) # Ensure Y is a matrix even for a single subject\n    ),\n    iter_sampling = 2500,\n    iter_warmup = 500,\n    chains = 4,\n    parallel_chains = 4,\n    seed = 43202\n)\n\nCalcoliamo la media a posteriori di \\(\\theta\\) e l’intervallo di confidenza al 95%:\n\n# Extract posterior samples for parameter 'p'\nbayes_est &lt;- fit_bernoulli$draws(variables = \"p\")\n\nbayes_est_p &lt;- as.vector(bayes_est)\n\n# Calculate the mean of the Bayesian estimates for 'p'\nbayes_theta_est &lt;- mean(bayes_est_p)\n\n# Calculate the 95% HDI using quantiles for the flattened vector\nhdi_bounds &lt;- quantile(bayes_est_p, probs = c(0.025, 0.975))\n\n# Prepare the results with a single HDI for 'p'\nresults &lt;- data.frame(\n    subj_num = 1,\n    n_items = n_items,\n    theta = theta,\n    bayes_theta = bayes_theta_est,\n    bayes_lo = hdi_bounds[1], # Lower bound of HDI\n    bayes_hi = hdi_bounds[2] # Upper bound of HDI\n)\n\n# Print the corrected results\nprint(results)\n\n     subj_num n_items     theta bayes_theta  bayes_lo  bayes_hi\n2.5%        1      30 0.6185681   0.5909482 0.4230871 0.7531208\n\n\nAdesso svolgiamo la stessa simulazione considerando però 20 soggetti e facendo variare il numero di item del questionario (10, 30, 100).\n\nset.seed(43202)\n\nn_subj &lt;- 20\nn_items_vec &lt;- c(10, 30, 100)\n\n# Placeholder for results\nresults &lt;- list()\n\nfor (n_items in n_items_vec) {\n    for (subj in 1:n_subj) {\n        # Generate \"true\" theta for the subject\n        theta &lt;- rnorm(1, .7, .1)\n\n        # Generate observed data for the subject using \"true\" theta\n        Y &lt;- rbinom(n_items, 1, prob = theta)\n\n        # Fit the model\n        fit_bernoulli &lt;- mod$sample(\n            data = list(\n                N = 1,\n                N_items = n_items,\n                Y = matrix(Y, nrow = 1) # Ensure Y is a matrix\n            ),\n            iter_sampling = 2500,\n            iter_warmup = 500,\n            chains = 4,\n            parallel_chains = 4,\n            seed = 43202\n        )\n\n        # Extract and process posterior samples for 'p'\n        bayes_est_p &lt;- as.vector(fit_bernoulli$draws(variables = \"p\"))\n        bayes_theta_est &lt;- mean(bayes_est_p)\n        hdi_bounds &lt;- quantile(bayes_est_p, probs = c(0.025, 0.975))\n\n        # Collect results\n        results[[paste(subj, n_items)]] &lt;- data.frame(\n            subj_num = subj,\n            n_items = n_items,\n            theta = theta,\n            bayes_theta = bayes_theta_est,\n            bayes_lo = hdi_bounds[1],\n            bayes_hi = hdi_bounds[2]\n        )\n    }\n}\n\nCombiniamo tutti i risultati in un singolo data frame.\n\nall_results &lt;- bind_rows(results)\nall_results |&gt; head()\n\n\nA data.frame: 6 x 6\n\n\n\nsubj_num\nn_items\ntheta\nbayes_theta\nbayes_lo\nbayes_hi\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n2.5%...1\n1\n10\n0.6369682\n0.5763993\n0.3105686\n0.8190624\n\n\n2.5%...2\n2\n10\n0.7167035\n0.5004720\n0.2411716\n0.7542886\n\n\n2.5%...3\n3\n10\n0.7412891\n0.7314809\n0.4723178\n0.9255873\n\n\n2.5%...4\n4\n10\n0.6369442\n0.5767456\n0.3153395\n0.8209660\n\n\n2.5%...5\n5\n10\n0.6903750\n0.4990059\n0.2371964\n0.7604131\n\n\n2.5%...6\n6\n10\n0.6933872\n0.6540551\n0.3854844\n0.8781372\n\n\n\n\n\nCreiamo un grafico con i risultati ottenuti.\n\nggplot(all_results, aes(x = theta, y = bayes_theta)) +\n    geom_point() +\n    geom_errorbar(aes(ymin = bayes_lo, ymax = bayes_hi), width = 0.02) +\n    geom_hline(yintercept = 0.7, linetype = \"dashed\", color = \"gray\") + # Add dashed line at y = 0.7\n    # facet_wrap(~n_items, scales = \"free_x\", ncol = 1) + # Separate panels for each n_items, with a common y-axis\n    facet_wrap(c(\"n_items\"), nrow = 1) +\n    theme_minimal() +\n    labs(x = \"True Theta\", y = \"Estimated p\") +\n    ggtitle(\"Estimated p vs. True Theta for Different Numbers of Items\") +\n    theme(\n        panel.grid = element_blank(),\n        axis.text.x.bottom = element_blank()\n    )\n\n\n\n\n\n\n\n\nLo scopo di questa simulazione è quello di confrontare i risultati del modello gerarchico bayesiano con i risultati ottenuti mediante la tecnica di Kelly. Per gli stessi dati utilizzati nel modello gerarchico bayesiamo, calcoliamo dunque la stima dei punteggi veri e gli intervalli di confidenza al 95% secondo il metodo di Kelley.\nLa formula di Kelley per stimare i punteggi veri dai punteggi osservati coinvolge l’affidabilità del test e la media e la deviazione standard dei punteggi osservati:\n\\[\n\\text{Punteggio Vero} = \\text{Media} + (\\text{Affidabilità}) \\times (\\text{Punteggio Osservato} - \\text{Media}).\n\\]\nPer calcolare il CI al 95% per i punteggi veri, dobbiamo tener conto dell’errore standard di misurazione, che deriva dall’affidabilità del test:\n\\[\n\\text{SEM} = \\sigma \\times \\sqrt{1 - \\text{Affidabilità}},\n\\]\ndove $ $ è la deviazione standard dei punteggi osservati.\nDate la stima di SEM, l’intervallo di confidenza al 95% per il punteggio vero di un individuo può essere calcolato come segue:\n\\[\n\\text{CI} = \\text{Punteggio Vero} \\pm (1.96 \\times \\text{SEM}).\n\\]\nSvolgiamo ora i calcoli in R.\n\n# Assuming a reliability coefficient\nr_xx &lt;- 0.8\nZ_alpha &lt;- qnorm(0.975) # For a 95% CI\n\n# Calculate estimated true scores and CIs\nall_results$kelley_true_score &lt;- all_results$bayes_theta\nall_results$kelley_lo &lt;- all_results$bayes_theta - (Z_alpha * sqrt(1 - r_xx) * sd(all_results$bayes_theta))\nall_results$kelley_hi &lt;- all_results$bayes_theta + (Z_alpha * sqrt(1 - r_xx) * sd(all_results$bayes_theta))\n\nA questo punto possiamo generare un grarico che contiene sia la stima del punteggio vero basata sul metodo di Kelley, insieme all’intervallo di confidenza al 95% (colore grigio), sia le stime bayesiane trovate in precedenza (colore blue).\nPer semplicità, ho solo considerato il caso in cui la stima di Kelley si riferisce al caso di 100 items.\n\nggplot() +\n    geom_point(data = all_results, aes(x = theta - 0.02, y = bayes_theta, color = \"Bayesian Estimate\")) +\n    geom_errorbar(data = all_results, aes(x = theta - 0.02, ymin = bayes_lo, ymax = bayes_hi, color = \"Bayesian Estimate\"), width = 0.02) +\n    geom_point(data = all_results, aes(x = theta, y = kelley_true_score, color = \"Kelley's Estimate\")) +\n    geom_errorbar(data = all_results, aes(x = theta, ymin = kelley_lo, ymax = kelley_hi, color = \"Kelley's Estimate\"), width = 0.02) +\n    geom_hline(yintercept = 0.7, linetype = \"dashed\", color = \"gray\") +\n    facet_wrap(c(\"n_items\"), nrow = 1) +\n    theme_minimal() +\n    labs(x = \"True Theta\", y = \"Estimated Score\") +\n    ggtitle(\"Estimated Scores vs. True Theta for Different Numbers of Items\") +\n    theme(\n        panel.grid = element_blank(),\n        legend.position = \"bottom\"\n    ) + # Aggiunta della legenda in basso\n    scale_color_manual(values = c(\"Bayesian Estimate\" = \"blue\", \"Kelley's Estimate\" = \"darkgray\"))\n\n\n\n\n\n\n\n\nI risultati della simulazione completa sono riportati nella figura seguente.\n\n\n\n```tyuynlhs ../images/haynes_kelley.png\n\n\n\n\nheight: 350px\n\n\nname: haynes-kelley-fig\n\n\n\nStime dei punteggi veri basate sul metodo della regressione di Kelley e sulla regressione gerarchica bayesiana.\n\nI risultati della simulazione indicano che le stime medie a posteriori del modello bayesiano, così come gli intervalli di credibilità al 95% (definiti come intervalli di densità di probabilità più elevata), mostrano una notevole congruenza con le stime corrispondenti dei punteggi veri ottenute mediante la regressione di Kelley, insieme ai relativi intervalli di confidenza al 95%. Le stime puntuali prodotte da entrambi i metodi risultano quasi sovrapponibili. Considerando che i punteggi veri derivanti dalla regressione di Kelley posseggono un'interpretazione bayesiana, la similitudine tra i risultati non dovrebbe sorprendere eccessivamente. Tuttavia, una conferma empirica di questa corrispondenza fornisce una validazione più robusta.\n\nQuesto esempio illustra come i modelli bayesiani gerarchici siano capaci di generare stime dei \"punteggi veri\" comparabili a quelle prodotte dalla teoria classica dei test, offrendo l'ulteriore vantaggio di non richiedere il calcolo dell'affidabilità per giungere a tali stime. Al contrario, l'approccio bayesiano si basa sull'adozione di assunzioni generative e distribuzionali riguardo le relazioni sia tra i parametri del modello a diversi livelli (ad esempio, la struttura gerarchica delinea le connessioni tra i parametri individuali e quelli di gruppo) sia con i dati osservati. In questo modo, adottando la media posteriore come stima dell'aspettativa dei parametri a livello individuale, siamo in grado di ottenere le stime più accurate dei parametri reali che sottendono la generazione dei dati osservati.\n\n## Commenti e considerazioni conclusive\n\nIn questo capitolo, abbiamo analizzato diverse applicazioni pratiche della CTT. Ci siamo concentrati sulla comprensione dei concetti di attenuazione e sul metodo per determinare il numero di item necessari per ottenere un livello desiderato di affidabilità. Inoltre, abbiamo esaminato come stimare i punteggi veri individuali utilizzando due approcci differenti: la regressione di Kelley basata sulla CTT e la regressione gerarchica bayesiana. Approfondire questi argomenti ci ha permesso di ottenere una visione più completa e concreta sull'utilizzo e sull'applicazione della CTT, migliorando la nostra comprensione dei concetti chiave e delle implicazioni pratiche della teoria.\n\n## Session Info\n\n::: {#a719648c .cell vscode='{\"languageId\":\"r\"}' execution_count=18}\n``` {.r .cell-code}\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] parallel  stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] doParallel_1.0.17  iterators_1.0.14   cmdstanr_0.7.1     truncnorm_1.0-9   \n [5] ggridges_0.5.6     foreach_1.5.2      modelsummary_1.4.5 ggokabeito_0.1.0  \n [9] viridis_0.6.5      viridisLite_0.4.2  ggpubr_0.6.0       ggExtra_0.10.1    \n[13] bayesplot_1.11.1   gridExtra_2.3      patchwork_1.2.0    semTools_0.5-6    \n[17] semPlot_1.1.6      lavaan_0.6-17      psych_2.4.1        scales_1.3.0      \n[21] markdown_1.12      knitr_1.45         lubridate_1.9.3    forcats_1.0.0     \n[25] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n[29] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.0      tidyverse_2.0.0   \n[33] here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] tensorA_0.36.2.1     rstudioapi_0.15.0    jsonlite_1.8.8      \n  [4] magrittr_2.0.3       farver_2.1.1         nloptr_2.0.3        \n  [7] rmarkdown_2.26       vctrs_0.6.5          minqa_1.2.6         \n [10] base64enc_0.1-3      rstatix_0.7.2        htmltools_0.5.7     \n [13] distributional_0.4.0 broom_1.0.5          Formula_1.2-5       \n [16] htmlwidgets_1.6.4    plyr_1.8.9           uuid_1.2-0          \n [19] igraph_2.0.2         mime_0.12            lifecycle_1.0.4     \n [22] pkgconfig_2.0.3      Matrix_1.6-5         R6_2.5.1            \n [25] fastmap_1.1.1        shiny_1.8.0          digest_0.6.34       \n [28] OpenMx_2.21.11       fdrtool_1.2.17       colorspace_2.1-0    \n [31] ps_1.7.6             rprojroot_2.0.4      Hmisc_5.1-1         \n [34] labeling_0.4.3       fansi_1.0.6          timechange_0.3.0    \n [37] abind_1.4-5          compiler_4.3.3       withr_3.0.0         \n [40] glasso_1.11          htmlTable_2.4.2      backports_1.4.1     \n [43] carData_3.0-5        ggsignif_0.6.4       MASS_7.3-60.0.1     \n [46] corpcor_1.6.10       gtools_3.9.5         tools_4.3.3         \n [49] pbivnorm_0.6.0       foreign_0.8-86       zip_2.3.1           \n [52] httpuv_1.6.14        nnet_7.3-19          glue_1.7.0          \n [55] quadprog_1.5-8       nlme_3.1-164         promises_1.2.1      \n [58] lisrelToR_0.3        grid_4.3.3           pbdZMQ_0.3-11       \n [61] checkmate_2.3.1      cluster_2.1.6        reshape2_1.4.4      \n [64] generics_0.1.3       gtable_0.3.4         tzdb_0.4.0          \n [67] data.table_1.15.2    hms_1.1.3            car_3.1-2           \n [70] utf8_1.2.4           tables_0.9.17        sem_3.1-15          \n [73] pillar_1.9.0         IRdisplay_1.1        rockchalk_1.8.157   \n [76] posterior_1.5.0      later_1.3.2          splines_4.3.3       \n [79] lattice_0.22-5       kutils_1.73          tidyselect_1.2.0    \n [82] miniUI_0.1.1.1       pbapply_1.7-2        stats4_4.3.3        \n [85] xfun_0.42            qgraph_1.9.8         arm_1.13-1          \n [88] stringi_1.8.3        boot_1.3-29          codetools_0.2-19    \n [91] evaluate_0.23        mi_1.1               cli_3.6.2           \n [94] RcppParallel_5.1.7   IRkernel_1.3.2       rpart_4.1.23        \n [97] xtable_1.8-4         processx_3.8.3       repr_1.1.6          \n[100] munsell_0.5.0        Rcpp_1.0.12          coda_0.19-4.1       \n[103] png_0.1-8            XML_3.99-0.16.1      ellipsis_0.3.2      \n[106] jpeg_0.1-10          lme4_1.1-35.1        insight_0.19.8      \n[109] openxlsx_4.2.5.2     crayon_1.5.2         rlang_1.1.3         \n[112] mnormt_2.1.1        \n\n:::",
    "crumbs": [
      "CTT",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Applicazioni della CTT</span>"
    ]
  },
  {
    "objectID": "chapters/validity/01_validity.html",
    "href": "chapters/validity/01_validity.html",
    "title": "11  La validità del test",
    "section": "",
    "text": "11.1 Minacce alla Validità\nLa validità di un test può essere compromessa quando non misura integralmente o accuratamente il costrutto di interesse, o quando valuta elementi estranei a tale costrutto. Anche test con alta affidabilità possono cadere in queste insidie, portando a interpretazioni errate dei risultati. Ci concentreremo sui tipi di validità e le relative evidenze, esaminando come integrare diverse fonti di prova per costruire un solido argomento di validità per il test.\nSotto-Rappresentazione del Costrutto: Questa si verifica quando un test non misura aspetti importanti del costrutto specificato. Ad esempio, un test di matematica di terza elementare che valuta solo la divisione non rappresenta adeguatamente l’intero spettro di competenze matematiche richieste a quel livello. Per risolvere questo problema, il contenuto del test dovrebbe essere ampliato per riflettere tutte le abilità insegnate nel curriculum di matematica di terza elementare.\nVarianza Estranea al Costrutto: Si presenta quando il test misura caratteristiche, contenuti o competenze non collegati al costrutto del test. Un esempio potrebbe essere un test di matematica che richiede elevate competenze di comprensione del testo, misurando così anche la capacità di lettura invece che solo la matematica. Per affrontare questo problema, il design del test dovrebbe minimizzare le istruzioni scritte e assicurarsi che il livello di lettura sia adeguato.\nAltri Fattori Che Influenzano la Validità: Oltre alle caratteristiche del test stesso, fattori esterni possono influenzare la validità delle interpretazioni dei risultati. Questi includono:\nInoltre, la validità delle interpretazioni norm-referenced è influenzata dall’adeguatezza del gruppo di riferimento.\nLe diverse minacce alla validità richiedono un’attenta valutazione e una gestione strategica per assicurare che le interpretazioni dei risultati del test siano affidabili e appropriate.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>La validità del test</span>"
    ]
  },
  {
    "objectID": "chapters/validity/01_validity.html#minacce-alla-validità",
    "href": "chapters/validity/01_validity.html#minacce-alla-validità",
    "title": "11  La validità del test",
    "section": "",
    "text": "Caratteristiche dell’Esaminando:\n\nFattori personali, come l’ansia o la bassa motivazione, possono compromettere la validità.\n\nProcedura di Amministrazione e Valutazione:\n\nDeviazioni dalle procedure standard possono ridurre la validità. Anche le variazioni per accomodare esigenze speciali devono essere gestite con attenzione per mantenere la validità.\n\nIstruzione e Coaching:\n\nIstruzioni o coaching pre-test possono influenzare la validità, specialmente se gli esaminandi vengono addestrati specificamente a rispondere alle domande del test.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>La validità del test</span>"
    ]
  },
  {
    "objectID": "chapters/validity/01_validity.html#tipologie-di-validità-rispetto-a-tipologie-di-prove-di-validità-nel-contesto-dei-test-educativi-e-psicologici",
    "href": "chapters/validity/01_validity.html#tipologie-di-validità-rispetto-a-tipologie-di-prove-di-validità-nel-contesto-dei-test-educativi-e-psicologici",
    "title": "11  La validità del test",
    "section": "11.2 “Tipologie di Validità” rispetto a “Tipologie di Prove di Validità” nel Contesto dei Test Educativi e Psicologici",
    "text": "11.2 “Tipologie di Validità” rispetto a “Tipologie di Prove di Validità” nel Contesto dei Test Educativi e Psicologici\n\n11.2.1 Contestualizzazione Storica e Evoluzione Terminologica\nI documenti guida nella creazione e nell’uso dei test educativi e psicologici, come gli Standard dell’AERA e altri (2014), hanno subito significative evoluzioni nel corso degli anni. Originariamente, la validità nei test era distinta in tre categorie principali: validità di contenuto, criteriale e di costrutto, come delineato da Messick (1989).\n\nValidità di Contenuto: Questa misura la pertinenza e la rappresentatività del contenuto del test rispetto al dominio del costrutto. Essa si basa su giudizi professionali riguardo l’adeguatezza dei contenuti del test.\nValidità Criteriale: Implica l’esame delle relazioni tra i punteggi del test e variabili esterne direttamente legate al costrutto, utilizzando metodi come l’analisi di correlazione o di regressione.\nValidità di Costrutto: Si concentra sull’integrazione di diverse evidenze relative al significato e all’interpretazione dei punteggi del test.\n\nQuesti tipi di validità, inizialmente ampiamente accettati, hanno successivamente ceduto il passo a un approccio unitario alla validità. Questa visione olistica considera la validità non come categorie distinte, ma come modi differenti di raccogliere prove a sostegno delle interpretazioni dei punteggi del test. Gli Standard del 1985 (APA et al., 1985) hanno introdotto il termine “tipi di prove di validità”, sostituendo la precedente nomenclatura.\n\n\n11.2.2 Standard del 2014 e Categorie di Prove di Validità\nGli Standard più recenti {cite:p}AERA-APA-NCME2014 hanno ulteriormente sviluppato questo concetto, definendo la validità come un grado in cui tutte le evidenze supportano l’interpretazione intesa dei punteggi del test per l’uso specificato. Le cinque categorie di prove di validità sono:\n\nProve Basate sul Contenuto del Test: Comprendono analisi del contenuto del test, tipologie di domande o compiti, e linee guida per somministrazione e correzione.\nProve Basate sui Processi di Risposta: Includono analisi dei processi cognitivi e comportamentali coinvolti nelle risposte agli item del test.\nProve Basate sulla Struttura Interna: Riguardano le relazioni tra elementi e componenti del test.\nProve Basate sulle Relazioni con Altre Variabili: Si concentrano sull’esame delle correlazioni tra le prestazioni nel test e variabili esterne.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni attese e non attese derivanti dall’uso del test.\n\nLa selezione e la valutazione delle prove pertinenti dipendono da fattori come il costrutto misurato, l’intento d’uso dei punteggi del test e la popolazione valutata.\n\n\n11.2.3 Rilevanza nella Pratica e nella Ricerca\nQuesta evoluzione terminologica non è solo un cambiamento superficiale, ma riflette un mutamento profondo nella comprensione della validità. È cruciale per i professionisti, gli sviluppatori e gli utenti di test aderire a queste linee guida, sia per ragioni legali che etiche. La letteratura più recente tende a utilizzare la nuova nomenclatura, ma è importante riconoscere e comprendere anche la terminologia storica, specialmente quando si esaminano manuali di test più datati e si valutano le proprietà psicometriche di un test.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>La validità del test</span>"
    ]
  },
  {
    "objectID": "chapters/validity/01_validity.html#ottenere-evidenze-per-la-validità",
    "href": "chapters/validity/01_validity.html#ottenere-evidenze-per-la-validità",
    "title": "11  La validità del test",
    "section": "11.3 Ottenere evidenze per la validità",
    "text": "11.3 Ottenere evidenze per la validità\nLa validità è definita da {cite:p}AERA-APA-NCME2014 come “il grado in cui le evidenze e la teoria sostengono le interpretazioni dei punteggi del test per gli utilizzi proposti dei test”. Questa definizione implica che non è possibile ottenere prove a sostegno di tutte le possibili interpretazioni o utilizzi di un test. I test sono interpretati e utilizzati in molti modi, alcuni dei quali sono giustificabili e altri no. Il primo passo nella validazione del test, quindi, è specificare le interpretazioni e gli utilizzi intesi dei punteggi del test.\nConsideriamo dunque nel dettaglio i cinque tipi di prove di validità delineati negli Standard (2014): (1) prove basate sul contenuto del test, (2) prove basate sui processi di risposta, (3) prove basate sulla struttura interna, (4) prove basate sulle relazioni con altre variabili e (5) prove basate sulle conseguenze del test.\n\n11.3.1 Evidenza di Validità Basata sul Contenuto del Test\nSecondo quanto definito negli {cite:t}AERA-APA-NCME2014, l’evidenza di validità basata sul contenuto si riferisce alla misura in cui il contenuto di un test rappresenta adeguatamente il dominio che intende misurare. È importante riconoscere che spesso, nei contesti di test, non è possibile includere ogni elemento del dominio del costrutto. Questo può portare a una sotto-rappresentazione del costrutto o a una varianza non pertinente al costrutto, che minacciano la validità del test. Per mitigare queste minacce, i test devono essere attentamente pianificati per garantire che il loro contenuto rifletta equilibratamente e appropriatamente il dominio del costrutto.\nGli standard {cite:p}AERA-APA-NCME2014 enfatizzano l’importanza di esaminare la relazione tra il contenuto del test e il costrutto o dominio che il test è progettato per misurare. La validità basata sul contenuto si concentra su quanto bene gli elementi del test campionano i comportamenti o la materia di studio che il test è destinato a misurare. Questo tipo di evidenza di validità era in passato comunemente raggruppato sotto l’etichetta di “validità del contenuto”.\nNelle fasi iniziali dello sviluppo di un test, è essenziale definire chiaramente il costrutto o il dominio del contenuto da misurare. Successivamente, si sviluppa una tabella delle specifiche che funge da guida per lo sviluppo del test, delineando gli argomenti e gli obiettivi da coprire e la loro importanza relativa.\nDurante la fase di revisione del test, esperti del settore valutano sistematicamente il test per giudicare la corrispondenza tra il contenuto del test e il suo costrutto o dominio. Questi esperti affrontano due questioni principali: la rilevanza degli elementi e la copertura del contenuto. La rilevanza degli elementi si riferisce alla valutazione di ciascun elemento del test per determinare se rifletta contenuti essenziali nel dominio specificato. La copertura del contenuto valuta se gli elementi del test nel loro insieme coprono adeguatamente il dominio specificato.\nL’evidenza di validità basata sul contenuto è tipicamente qualitativa, ma può essere riportata in modo più quantitativo, come il numero e le qualifiche degli esperti coinvolti, il numero di revisioni effettuate e il loro grado di accordo su questioni relative al contenuto.\nQuesto tipo di evidenza di validità è particolarmente importante per i test di rendimento accademico e per i test utilizzati nella selezione e classificazione dei dipendenti, in quanto sono progettati per fornire un campione rappresentativo della conoscenza, del comportamento o delle abilità misurate.\n\n11.3.1.1 Validità di Faccia\nVa inoltre distinta la validità di faccia dalla validità basata sul contenuto. La validità di faccia si riferisce all’apparenza di un test e alla sua capacità di sembrare valido per persone non esperte, ma non riguarda ciò che il test misura effettivamente. Un test può sembrare valido, ma non essere tale alla luce di un’analisi tecnica approfondita del suo contenuto. Tuttavia, un buon grado di validità di faccia può aumentare la cooperazione degli esaminandi e la percezione pubblica dei risultati come significativi. In alcuni contesti, come quelli forensi, la validità di faccia può essere indesiderabile, ad esempio per evitare che gli esaminandi simulino risposte patologiche.\n\n\n\n11.3.2 Evidenza basata sui processi di risposta\nL’evidenza di validità basata sui processi di risposta riguarda l’analisi di come le risposte fornite dagli esaminandi corrispondano al costrutto che il test intende valutare. Questo tipo di evidenza di validità esamina se gli esaminandi utilizzino effettivamente i processi cognitivi previsti per rispondere alle domande del test. Ad esempio, in un test che misura la capacità di ragionamento matematico, è importante verificare che gli esaminandi stiano effettivamente applicando analisi e ragionamento piuttosto che ricorrendo a algoritmi matematici meccanici.\nQuesto tipo di evidenza è raccolta attraverso varie metodologie, come intervistare gli esaminandi sui loro processi di risposta e strategie, registrare indicatori comportamentali come tempi di risposta e movimenti oculari o analizzare i tipi di errori commessi. Se gli esaminandi non impiegano i processi cognitivi attesi, possono emergere dubbi sulla validità delle misurazioni ottenute e sulla capacità del test di valutare in modo attendibile il costrutto di interesse.\nInoltre, le indagini sui processi di risposta non si limitano solo agli individui che prendono il test, ma possono anche includere i professionisti dell’assessment che amministrano o valutano i test. È fondamentale che le loro azioni o processi siano in linea con il costrutto misurato. Molti test forniscono criteri specifici o rubriche intesi a guidare il processo di valutazione. Per esempio, il Wechsler Individual Achievement Test—Terza Edizione (WIAT-III) include un compito che richiede all’esaminando di scrivere un breve saggio. Per facilitare la valutazione, gli autori includono una rubrica di valutazione analitica che copre diverse categorie valutative, come l’uso di più paragrafi, un’introduzione (compresa una tesi e un riassunto), transizioni che mostrano le relazioni tra le idee, ragioni che supportano la tesi, elaborazioni che supportano ogni ragione e una conclusione che include una tesi e un riassunto delle ragioni presentate. Queste rubriche aiutano a garantire la coerenza della valutazione da parte di coloro che valutano i saggi e aiutano a evitare di attribuire credito a fattori irrilevanti che non indicano la capacità dell’esaminando di scrivere buoni saggi.\nIn sintesi, l’evidenza di validità basata sui processi di risposta è un aspetto cruciale per garantire che il test misuri effettivamente il costrutto previsto e che le risposte degli esaminandi riflettano i processi cognitivi appropriati. Questo approccio, sebbene non abbia ricevuto tanta attenzione quanto altre forme di evidenza di validità, ha un notevole potenziale e viene classificato tradizionalmente sotto la validità di costrutto.\n\n\n11.3.3 Evidenza basata sulla struttura interna\nL’evidenza basata sulla struttura interna di un test si focalizza sulla coerenza degli elementi del test con le dimensioni teoriche previste. Questo tipo di valutazione è cruciale per determinare se i punteggi di un test rappresentino accuratamente le dimensioni o i costrutti che si prevede di misurare.\nAlcuni test sono progettati per valutare una singola dimensione o un aspetto specifico, come l’estroversione o l’apertura mentale, mentre altri mirano a misurare costrutti più ampi e multidimensionali, come la personalità generale. L’analisi della struttura interna di un test permette di verificare se le relazioni tra gli elementi del test (o, nel caso di batterie di test, tra i test componenti) sono coerenti con il costrutto che il test è progettato per misurare.\nAd esempio, in un test di personalità generale, ci si aspetta che gli elementi relativi a diverse dimensioni della personalità siano correlati tra loro, contribuendo alla misurazione complessiva della personalità. Se gli elementi di un test non mostrano questa coerenza con la struttura multidimensionale ipotizzata, ciò può sollevare dubbi sulla validità delle interpretazioni dei punteggi ottenuti.\nUno strumento statistico spesso utilizzato per esaminare la struttura interna di un test è l’analisi fattoriale. Questa procedura sofisticata aiuta a determinare il numero di fattori o dimensioni concettualmente distinti che sottendono un test o una batteria di test. L’analisi fattoriale può quindi confermare se la struttura effettiva del test è coerente con la struttura ipotizzata del costrutto che misura.\nIn sintesi, l’evidenza basata sulla struttura interna è essenziale per valutare la validità di un test e assicurare che i suoi punteggi riflettano fedelmente le dimensioni o i costrutti teorizzati. Questa valutazione fornisce una base solida per l’interpretazione dei risultati del test, permettendo di stabilire in che misura il test possa essere utilizzato come misura affidabile delle dimensioni o dei costrutti desiderati.\n\n\n11.3.4 Evidenza di Validità Basata sulle Conseguenze del Testing\nL’evidenza di validità basata sulle conseguenze del testing è un aspetto cruciale nella valutazione della validità di un test psicometrico, secondo la prospettiva degli Standards {cite:p}AERA-APA-NCME2014. Questo tipo di evidenza si concentra sugli effetti che l’uso del test ha sulle persone testate e sugli esiti diretti delle misurazioni. È importante considerare non solo le conseguenze intenzionali, ovvero gli effetti voluti o previsti che il test dovrebbe generare, ma anche le conseguenze non intenzionali, come effetti imprevisti o negativi che potrebbero manifestarsi.\n\n11.3.4.1 Conseguenze Intenzionali e Non Intenzionali\nLe conseguenze intenzionali del testing sono legate agli scopi e agli utilizzi del test. Ad esempio, se un test viene utilizzato per la selezione di candidati per un ruolo specifico, l’obiettivo è identificare le persone più idonee. Invece, le conseguenze non intenzionali si riferiscono a effetti imprevisti, come discriminazioni ingiuste o influenze distorte sui partecipanti, che possono emergere dall’uso del test.\nL’analisi approfondita di queste conseguenze aiuta a garantire che il test non causi effetti dannosi e sia utilizzato in modo etico e appropriato. Questa valutazione è fondamentale per assicurare che il test fornisca misurazioni accurate e significative per gli scopi previsti.\n\n\n11.3.4.2 Consequentialità della Validità\nLa validità consequenziale si riferisce ai benefici specifici attesi dall’uso dei test. Ad esempio, l’uso di un test per l’assunzione di personale dovrebbe portare a migliori decisioni di assunzione, come minori costi di formazione e turnover. Questo tipo di validità pone la domanda: “Questi benefici vengono effettivamente raggiunti?” È particolarmente applicabile a test progettati per la selezione e la promozione.\n\n\n11.3.4.3 Valutazione delle Conseguenze Sociali e Politiche\nAlcuni autori hanno proposto un concetto di validità più ampio che incorpora questioni sociali e valori. Tuttavia, questa posizione è stata oggetto di critiche, poiché l’inclusione di questioni sociali e di valore potrebbe complicare il concetto di validità. Gli Standard AERA et al. (2014) sembrano evitare questa concezione più ampia della validità, distinguendo tra evidenze consequenziali direttamente legate al concetto di validità ed evidenze relative alla politica sociale.\n\n\n11.3.4.4 Considerazione delle Alternative all’Uso dei Test\nÈ anche importante considerare le conseguenze di non utilizzare i test. Anche se l’uso dei test può produrre alcuni effetti avversi, questi devono essere confrontati con gli effetti positivi e negativi delle alternative all’uso dei test psicologici. L’adozione di approcci più soggettivi al processo decisionale può aumentare la probabilità di pregiudizi culturali, etnici e di genere.\nIn conclusione, l’evidenza di validità basata sulle conseguenze del testing è un aspetto essenziale da considerare nella valutazione complessiva della validità di un test psicometrico. È necessario esaminare gli effetti sia voluti che non voluti dei test e garantire che il loro utilizzo sia eticamente appropriato e non causi danni, contribuendo così all’utilizzo responsabile e informato dei test nella pratica professionale.\n\n\n\n11.3.5 Evidenza di Validità Basata sulle Relazioni con Altre Variabili\nL’evidenza di validità basata sulle relazioni con altre variabili riguarda la correlazione tra i punteggi del test e altre variabili rilevanti. Questa forma di validità può includere le correlazioni dei punteggi del test con variabili teoricamente correlate, la capacità del test di predire risultati specifici, le differenze tra gruppi differenziati dal costrutto misurato e studi volti a identificare possibili contaminazioni dovute agli effetti del metodo.\n\n11.3.5.1 Relazioni Test-Criterio\nMolti test sono progettati per predire le prestazioni su una variabile definita come criterio. Il criterio può essere il rendimento accademico, la performance lavorativa o altri risultati importanti per l’utente del test. Questa tipologia di validità include studi predittivi, in cui si amministra il test, si attende un intervallo di tempo e poi si misura il criterio, e studi concorrenti, in cui il test e il criterio vengono misurati contemporaneamente.\nAd esempio, per validare il SAT come predittore del successo universitario, si potrebbe correlare il punteggio SAT degli studenti delle superiori con il loro GPA universitario dopo il primo anno. Questo tipo di studio può utilizzare il coefficiente di correlazione, noto come coefficiente di validità. La scelta tra studi predittivi e concorrenti dipende dall’obiettivo della valutazione e dal contesto di utilizzo del test.\n\n\n11.3.5.2 Confronto di Gruppi\nLa teoria può servire come base per raccogliere evidenze di validità esaminando come gruppi diversi (identificati da un criterio esterno) dovrebbero differire nel costrutto misurato dal test. Ad esempio, nella validazione di un nuovo test di intelligenza, si potrebbero confrontare i punteggi di gruppi con disabilità intellettuali e quelli con abilità intellettuali tipiche.\n\n\n11.3.5.3 Sensibilità e Specificità\nQuesti concetti sono importanti quando si utilizza un punteggio di test per classificare individui o caratteristiche in gruppi. La sensibilità di una misura si riferisce alla sua capacità di rilevare la presenza di una condizione, mentre la specificità si riferisce alla sua capacità di determinare l’assenza di una condizione.\n\n\n11.3.5.4 Validità convergente e Divergente\nL’evidenza di validità convergente si ottiene correlando un test con altri test che misurano costrutti simili o identici. Invece, l’evidenza di validità discriminante si ottiene correlando un test con misure di costrutti dissimili.\n\n\n11.3.5.5 Generalizzazione della Validità\nSi riferisce al grado in cui le relazioni test-criterio possono essere generalizzate a nuove situazioni senza ulteriori studi. La meta-analisi ha mostrato che la variabilità osservata nei coefficienti di validità è spesso dovuta a artefatti statistici, suggerendo che i coefficienti di validità possono essere generalizzati più di quanto si pensasse in passato.\nIn conclusione, l’evidenza di validità basata sulle relazioni con altre variabili è cruciale per stabilire la validità di un test. Essa comprende l’esame delle relazioni test-criterio, lo studio di gruppi contrastanti, la considerazione di modelli di teoria delle decisioni, e l’analisi di sensibilità e specificità, oltre alla ricerca di evidenze convergenti e divergenti. Queste approfondite indagini aiutano a garantire che i punteggi di un test riflettano accuratamente il costrutto che intendono misurare e siano utili nel contesto specifico in cui vengono applicati.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>La validità del test</span>"
    ]
  },
  {
    "objectID": "chapters/validity/01_validity.html#integrazione-delle-prove-di-validità",
    "href": "chapters/validity/01_validity.html#integrazione-delle-prove-di-validità",
    "title": "11  La validità del test",
    "section": "11.4 Integrazione delle Prove di Validità",
    "text": "11.4 Integrazione delle Prove di Validità\nGli Standards {cite:p}AERA-APA-NCME2014 definiscono la validazione come un processo di costruzione e valutazione di argomentazioni a favore e contro l’interpretazione intesa dei punteggi dei test e la loro rilevanza per l’uso proposto. Lo sviluppo di un argomento di validità comporta tipicamente l’integrazione di numerose linee di evidenza in un commento coerente. Diversi tipi di prove di validità sono più applicabili a diversi tipi di test. Ecco una breve rassegna delle applicazioni prominenti di diversi tipi di prove di validità:\n\nProve Basate sul Contenuto del Test: Sono spesso riportate con test di rendimento accademico e test utilizzati nella selezione dei dipendenti.\nProve Basate sulle Relazioni con Altre Variabili: Possono includere (1) relazioni test-criterio, applicabili quando i test sono usati per predire le prestazioni su un criterio esterno; (2) evidenze convergenti e discriminanti, utili con una varietà di test, inclusi test di intelligenza, di rendimento, test di personalità, ecc.; (3) evidenze di generalizzazione della validità, utili quando gli stessi o simili test sono usati ripetutamente in applicazioni simili.\nProve Basate sulla Struttura Interna: Utili con una varietà di test, ma tradizionalmente applicate con test che misurano costrutti teorici come la personalità o l’intelligenza.\nProve Basate sui Processi di Risposta: Utili con praticamente qualsiasi test che richiede agli esaminandi di impegnarsi in attività cognitive o comportamentali.\nProve Basate sulle Conseguenze del Testing: Applicabili soprattutto ai test progettati per la selezione e la promozione, ma utili con un’ampia gamma di test.\n\nLa maggior parte dei tipi di prove di validità ha applicazioni per una vasta gamma di test, il che è appropriato. L’integrazione di molteplici linee di ricerca o tipi di evidenza fornisce un argomento di validità più convincente. È importante ricordare che ogni interpretazione o uso inteso di un test deve essere validato. Se un test viene utilizzato per applicazioni diverse, ogni uso o applicazione deve essere validato, richiedendo diversi tipi di prove di validità.\nLa validità di un’interpretazione dei punteggi di un test dipende da tutte le prove disponibili relative alla qualità tecnica di un sistema di test. Componenti importanti di questa evidenza includono la costruzione attenta del test, l’affidabilità adeguata dei punteggi, l’amministrazione e la valutazione appropriate del test, la scalatura accurata dei punteggi e l’attenzione alla giustizia per gli esaminandi, come appropriato per l’interpretazione del test in questione.\nIn sintesi, la validità di un test è un strumento ben sviluppato e tecnicamente solido. Nel prossimo capitolo, forniremo ulteriori indicazioni pratiche per garantire la validità delle interpretazioni dei punteggi dei test. Questo processo inizia quando si inizia a pensare allo sviluppo di un test.\nInfine, lo sviluppo di un argomento di validità è un processo continuo che tiene conto delle ricerche esistenti e incorpora nuove scoperte scientifiche. Mentre gli sviluppatori di test sono tenuti a fornire prove iniziali della validità delle interpretazioni dei punteggi che propongono, la ricerca di ricercatori indipendenti successiva al rilascio del test è essenziale. Riviste professionali eccellenti pubblicano regolarmente articoli di ricerca empirica che coprono le proprietà psicometriche di diversi test. Inoltre, coloro che utilizzano i test sono tenuti a valutare le prove di validità e a formulare i propri giudizi sulla loro appropriateness nel proprio contesto e ambiente. Ciò pone i professionisti clinici che utilizzano i test psicologici nel ruolo finale e più responsabile nel processo di validazione.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>La validità del test</span>"
    ]
  },
  {
    "objectID": "chapters/validity/01_validity.html#conclusione",
    "href": "chapters/validity/01_validity.html#conclusione",
    "title": "11  La validità del test",
    "section": "11.5 Conclusione",
    "text": "11.5 Conclusione\nNella psicometria, la validità emerge come un concetto dinamico e sfaccettato, che richiede un’analisi approfondita e l’integrazione di varie forme di evidenza. Nel corso di questo capitolo, abbiamo esaminato le diverse dimensioni della validità, sottolineando l’importanza di un’analisi olistica nell’interpretazione dei punteggi dei test. È essenziale andare oltre la mera coerenza del contenuto del test con il costrutto target, includendo anche un esame dettagliato della sua struttura interna, dei processi cognitivi e comportamentali evocati nei rispondenti, e delle conseguenze, sia attese che inattese, derivanti dal suo impiego.\nConformemente agli Standards {cite:p}AERA-APA-NCME2014, la validità trascende la semplice analisi statistica per abbracciare il significato e la pertinenza delle interpretazioni dei punteggi dei test all’interno dei contesti specifici di utilizzo. Ciò implica un processo di indagine e aggiornamento continuo, che assimila nuove ricerche e avanzamenti nel settore. L’uso dei test psicometrici, pertanto, deve essere condotto con una consapevolezza critica delle loro limitazioni e potenzialità, assicurando che le decisioni basate sui loro risultati siano non solo accurate, ma anche etiche e ben fondate.\nIn conclusione, la validazione di un test psicometrico si configura come un processo dinamico, che sollecita una costante attenzione critica e un approccio responsabile da parte degli psicologi. La validità, dunque, non deve essere percepita come un attributo statico e inalterabile del test, ma piuttosto come un’analisi continua e progressiva della sua efficacia nel fornire interpretazioni dei risultati che siano pertinenti e rilevanti all’interno di diversi contesti di applicazione.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>La validità del test</span>"
    ]
  },
  {
    "objectID": "chapters/validity/02_other_variables.html",
    "href": "chapters/validity/02_other_variables.html",
    "title": "12  Relazioni test-criterio",
    "section": "",
    "text": "12.1 Analisi della Relazione Test-Criterio mediante la Regressione Logistica\nIn questo capitolo, esploriamo approfonditamente la relazione tra i punteggi dei test e vari criteri esterni, focalizzandoci su come i test possono predire o differenziare fenomeni specifici. Questo tipo di analisi è cruciale per valutare la validità dei test in contesti pratici e teorici.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Relazioni test-criterio</span>"
    ]
  },
  {
    "objectID": "chapters/validity/02_other_variables.html#analisi-della-relazione-test-criterio-mediante-la-regressione-logistica",
    "href": "chapters/validity/02_other_variables.html#analisi-della-relazione-test-criterio-mediante-la-regressione-logistica",
    "title": "12  Relazioni test-criterio",
    "section": "",
    "text": "12.1.1 Categorie di Evidenze basate su Relazioni con Altre Variabili\nIn psicometria, vengono utilizzate diverse categorie di prove per valutare le relazioni dei punteggi dei test con altre variabili:\n\nRelazioni Test-Criterio:\n\nQueste si concentrano sull’uso dei punteggi dei test per prevedere il rendimento o lo stato attuale in vari ambiti, come l’adattamento accademico o lavorativo.\n\nDifferenze tra Gruppi:\n\nAnalizziamo se i test evidenziano differenze significative nei punteggi tra gruppi definiti da criteri specifici, come la presenza o assenza di una diagnosi clinica.\n\nProve di Convergenza e Discriminazione:\n\nEsploriamo se i punteggi di un test sono correlati a quelli di altri test che misurano costrutti simili (validità convergente) e se sono meno correlati a test che misurano costrutti diversi (validità discriminante).\n\n\nQuando si affronta la questione delle relazioni test-criterio, un aspetto cruciale è la selezione di un criterio appropriato e la valutazione quantitativa della relazione tra il test e il criterio. In situazioni dove il criterio è di natura categorica, come il superamento o il fallimento di un test, la regressione logistica diventa uno strumento essenziale.\nLa regressione logistica è un metodo statistico usato per analizzare la relazione tra una variabile dipendente binaria e una o più variabili indipendenti. Questa tecnica stima la probabilità che un’osservazione appartenga a una delle categorie della variabile dipendente, basandosi sui valori delle variabili indipendenti.\nSupponiamo che una variabile risposta \\(Y_i\\) (per l’osservazione \\(i\\)-esima, con \\(i = 1, \\dots, n\\)) assuma due modalità, definite come successo e insuccesso. Ogni osservazione può essere associata a un vettore di variabili esplicative (\\(x_1, \\dots, x_p\\)), ma per semplicità, considereremo il caso di una singola variabile indipendente.\nNella regressione logistica, il logaritmo delle probabilità delle due categorie è modellato come una funzione lineare delle variabili indipendenti. Questo ci permette di esaminare come i cambiamenti nelle variabili indipendenti influenzino la probabilità di successo o insuccesso.\nNel contesto dei test psicometrici, la regressione logistica può essere usata per determinare il grado in cui i punteggi di un test sono predittivi di un risultato categorico. Ad esempio, possiamo valutare la probabilità che gli studenti con determinati punteggi ad un test di ammissione universitario riescano o meno nel loro primo anno accademico.\nQuesto metodo fornisce un quadro più chiaro della validità di un test nel predire risultati specifici, migliorando così l’affidabilità e l’applicabilità dei test in vari contesti. Attraverso l’uso della regressione logistica, possiamo quindi formulare interpretazioni più precise e informate dei risultati dei test, contribuendo a una migliore comprensione della validità di uno strumento psicometrico.\nNello specifico, possiamo dire che l’obiettivo della regressione logistica è studiare la relazione tra la probabilità di risposta\n\\[\nPr(Y=1 | X=x_i) \\equiv Pr(Y_i) \\equiv \\pi_i\n\\]\ne la variabile esplicativa \\(x\\).\nLa componente sistematica del modello è espressa come funzione lineare del predittore\n\\[\n\\eta_i = logit(\\pi_i) = \\alpha + \\beta x_i.\n\\]\nLa componente aleatoria del modello suppone l’esistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Nel caso di dati ragruppati, si assume che \\(Y_i\\) abbia una distribuzione binomiale\n\\[\nY_i \\sim Bin(n_i, \\pi_i),\n\\]\ncon parametri \\(n_i\\) e \\(\\pi_i\\). Per dati individuali (uno per ciascun valore \\(x_i\\)), \\(n_i=1, \\forall i\\).\nLa funzione link del modello trasforma il predittore lineare nel valore atteso della variabile risposta condizionato alla variabile \\(X\\):\n\\[\n\\begin{equation}\n\\pi_i = g(\\eta_i) = \\frac{e^{\\alpha + \\beta x_i}}{1+e^{\\alpha + \\beta x_i}}.\n\\end{equation}\n\\] (eq-reg-logistic-prob)\nIn sintesi, la regressione logistica è una tecnica statistica che stima la probabilità che l’evento \\(Y = 1\\) si verifichi per ciascun valore della variabile indipendente \\(X\\).\n\n\n12.1.2 Un Esempio Pratico\nPer fare un esempio pratico, consideriamo i dati dello studio Pitfalls When Using Area Under the Curve to Evaluate Item Content for Early Screening Tests for Autism di Lucas, Brewer e Young (2022).\nIl campione raccolto da Nah et al. (2018) include 270 bambini di età compresa tra 12 e 36 mesi (M = 25.4, SD = 7.0). Sulla base di una diagnosi clinica eseguita secondo il DSM-5, 106 bambini sono stati diagnosticati con ASD (Autism Spectrum Disorder, Disturbo dello Spettro Autistico), 86 erano in sviluppo non tipico (non-TD) e 78 erano considerati in sviluppo tipico (TD). Qui considereremo solo i gruppi ASD e non-TD.\nIl test di interesse è l’Autism Detection in Early Childhood (ADEC). Si tratta di una checklist comportamentale composta da 16 item, appositamente sviluppata per rilevare comportamenti pre-verbali che possono essere predittivi dell’autismo nei bambini di età inferiore ai tre anni (Young, 2007).\nLeggiamo i dati.\n\ntmp_path &lt;- tempfile(fileext = \"xlsx\") # temporary file\ndownload.file(\"https://osf.io/download/tsm7x/\", destfile = tmp_path)\ndat1 &lt;- readxl::read_xlsx(tmp_path, na = \"NA\")\ndat1$asd &lt;- recode(\n    dat1$`Diagnosis(1=Non-typically developing; 2=ASD; 3=Neurotypical)`,\n    `1` = \"Non-TD\",\n    `2` = \"ASD\",\n    `3` = \"TD\"\n)\n# Filter out Neurotypical\ndat1_sub &lt;- filter(dat1, asd != \"TD\")\nglimpse(dat1_sub)\n\nRows: 192\nColumns: 21\n$ ID                                                             &lt;dbl&gt; 2, 3, 4~\n$ `Sex (1=Male; 2=Female)`                                       &lt;dbl&gt; 1, 1, 2~\n$ `Age (in Months)`                                              &lt;dbl&gt; 12, 12,~\n$ ADEC_I01                                                       &lt;dbl&gt; 0, 2, 2~\n$ ADEC_I02                                                       &lt;dbl&gt; 0, 1, 2~\n$ ADEC_I03                                                       &lt;dbl&gt; 0, 0, 0~\n$ ADEC_I04                                                       &lt;dbl&gt; 0, 1, 2~\n$ ADEC_I05                                                       &lt;dbl&gt; 0, 1, 0~\n$ ADEC_I06                                                       &lt;dbl&gt; 0, 1, 2~\n$ ADEC_I07                                                       &lt;dbl&gt; 2, 2, 2~\n$ ADEC_I08                                                       &lt;dbl&gt; 0, 1, 1~\n$ ADEC_I09                                                       &lt;dbl&gt; 0, 0, 1~\n$ ADEC_I10                                                       &lt;dbl&gt; 0, 1, 2~\n$ ADEC_I11                                                       &lt;dbl&gt; 0, 1, 1~\n$ ADEC_I12                                                       &lt;dbl&gt; 1, 0, 0~\n$ ADEC_I13                                                       &lt;dbl&gt; 1, 1, 1~\n$ ADEC_I14                                                       &lt;dbl&gt; 1, 0, 1~\n$ ADEC_I15                                                       &lt;dbl&gt; 1, 2, 1~\n$ ADEC_I16                                                       &lt;dbl&gt; 0, 1, 1~\n$ `Diagnosis(1=Non-typically developing; 2=ASD; 3=Neurotypical)` &lt;dbl&gt; 1, 1, 1~\n$ asd                                                            &lt;chr&gt; \"Non-TD~\n\n\nIniziamo trovando il punteggio totale ADEC. Si noti che la somma sarà NA se un item è NA.\n\ndat1_sub$ADEC &lt;- rowSums(select(dat1_sub, ADEC_I01:ADEC_I16)) # NA if any item is NA\n# Or treat missing as 0\ndat1_sub$ADEC_rm_na &lt;- rowSums(select(dat1_sub, ADEC_I01:ADEC_I16), na.rm = TRUE)\n\nUtilizzeremo il modello di regressione logistica per esaminare la relazione tra il punteggio totale del test ADEC e la probabilità che il bambino appartenga al gruppo diagnostico ASD.\nEsaminiamo la distribuzione del punteggio totale di ADEC in base alla diagnosi:\n\nggplot(dat1_sub, aes(x = ADEC)) +\n    geom_histogram() +\n    facet_wrap(~asd)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nWarning message:\n\"Removed 12 rows containing non-finite outside the scale range (`stat_bin()`).\"\n\n\n\n\n\n\n\n\n\nRicodifichiamo asd in modo tale che assuma valore 1 per i bambini con ASD e 0 altrimenti.\n\ndat1_sub$y &lt;- ifelse(dat1_sub$asd == \"ASD\", 1, 0)\ndat1_sub$y\n\n\n000000010000001100000000000000001100000000010011011011101100100111110101111000111001111000110111110101101111001111000010111010111111011101011111111111011001111111111101110100011111111111001000\n\n\nEseguiamo l’analisi di regressione logistica usando la funzione ´glm()´.\n\nfm &lt;- glm(y ~ ADEC, family = binomial(link=\"logit\"), data = dat1_sub)\n\nEsaminiamo i risultati.\n\nsummary(fm)\n\n\nCall:\nglm(formula = y ~ ADEC, family = binomial(link = \"logit\"), data = dat1_sub)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.76480    0.58071  -6.483 8.99e-11 ***\nADEC         0.35447    0.05201   6.816 9.37e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 247.73  on 179  degrees of freedom\nResidual deviance: 131.12  on 178  degrees of freedom\n  (12 osservazioni eliminate a causa di valori mancanti)\nAIC: 135.12\n\nNumber of Fisher Scoring iterations: 6\n\n\nCreiamo un grafico che mostri la relazione tra la probabilità che Y = 1 (cioè la diagnosi di ASD per il bambino), calcolata utilizzando i coefficienti del modello di regressione logistica, e il punteggio ottenuto nella scala ADEC.\n\n# Filter out rows with missing values in ADEC column\ndat1_sub &lt;- na.omit(dat1_sub)\n# Predict the probabilities of y == 1 for the filtered data\npredictions &lt;- predict(fm, type = \"response\")\n# Create a data frame with ADEC and the predicted probabilities\nplot_data &lt;- data.frame(ADEC = dat1_sub$ADEC, Prob_Y_1 = predictions)\n\n# Plot the probability of y == 1 as a function of ADEC\nlibrary(ggplot2)\nggplot(plot_data, aes(x = ADEC, y = Prob_Y_1)) +\n    geom_line() +\n    geom_point() +\n    xlab(\"ADEC\") +\n    ylab(\"Probability of y == 1\") +\n    ggtitle(\"Probability of y == 1 vs. ADEC\")\n\n\n\n\n\n\n\n\nIl grafico presenta una curva sigmoidale che illustra come, per punteggi bassi nella scala ADEC, la probabilità di una diagnosi di autismo sia bassa, mentre per punteggi alti nella scala ADEC, la probabilità di una diagnosi di autismo sia alta.\n\n\n12.1.3 Accuratezza della classificazione\nUna volta compreso come il modello di regressione logistica associa a ciascun valore di \\(x\\) la probabilità dell’evento \\(y = 1\\), esaminiamo ora come sia possibile utilizzare questo modello per valutare l’accuratezza di una classificazione binaria. Nel nostro caso, la classificazione riguarda ciascuna osservazione nelle categorie ASD e Non-TD. In questo contesto, il modello di regressione logistica stima la probabilità di appartenenza a una delle due categorie basandosi sui valori di ADEC (eq. {eq}eq-reg-logistic-prob).\nPer effettuare la classificazione, dobbiamo stabilire un punto di taglio (cut-off) che separi le due categorie. Questo punto di taglio definisce il valore della variabile dipendente al di sopra del quale l’osservazione sarà assegnata alla categoria positiva (y = 1, ovvero ASD) e al di sotto del quale sarà assegnata alla categoria negativa (y = 0). La scelta del punto di taglio è critica poiché influisce sull’accuratezza delle previsioni del modello.\nI coefficienti di regressione stimati dalla regressione logistica sono i parametri del modello che descrivono la relazione tra la variabile indipendente ADEC e la probabilità di appartenenza alla categoria positiva (y = 1). Questi coefficienti ci consentono di calcolare la probabilità stimata di y = 1 per ciascuna osservazione, utilizzando l’eq. {eq}eq-reg-logistic-prob. Una volta calcolata la probabilità stimata di y = 1 per ogni osservazione, possiamo utilizzare un determinato punto di taglio (ad esempio, 0.5) per classificare le osservazioni nelle due categorie y = 0 e y = 1. Se la probabilità stimata è maggiore o uguale al punto di taglio, l’osservazione verrà classificata come y = 1 (positiva); altrimenti, verrà classificata come y = 0 (negativa).\nTuttavia, la scelta del punto di taglio non è banale e ha un impatto diretto sulla sensibilità (la proporzione dei casi positivi effettivi che il test identifica correttamente come positivi) e specificità (la proporzione dei casi negativi effettivi che il test identifica correttamente come negativi) del modello. Un punto di taglio più alto potrebbe aumentare la specificità, ma ridurre la sensibilità, mentre un punto di taglio più basso avrebbe l’effetto opposto.\nPer ottenere una valutazione più completa delle prestazioni del modello, consideriamo tutti i possibili punti di taglio e visualizziamo la relazione tra sensibilità e specificità tramite la curva ROC (Receiver Operating Characteristic). Questa curva è un grafico che mostra come variano sensibilità e specificità al variare del punto di taglio. Un elemento chiave della curva ROC è l’Area Under the Curve (AUC), che rappresenta una misura aggregata dell’accuratezza complessiva del modello. L’AUC calcola l’area sottesa alla curva ROC e riflette la capacità del modello di discriminare tra le due categorie di risultato. L’AUC, dunque, fornisce una misura sintetica dell’accuratezza del modello su tutta la gamma di possibili punti di taglio. Un valore di AUC pari a 1 indica una perfetta capacità di discriminazione, mentre un valore pari a 0.5 indica una capacità di discriminazione casuale.\nPer mostrare come trovare l’AUC, iniziamo calcolando l’accuratezza della classificazione mediante un valore di cut-off pari a 0.5, ad esempio.\n\n# Predict the probabilities of y == 1 for the filtered data\nprob_pred &lt;- predict(fm, type = \"response\")\n\n# Use cut-off 0.5 for classification\nclassification &lt;- ifelse(prob_pred &gt;= 0.5, 1, 0)\n\n# Classification accuracy\nmean(classification == dat1_sub$y)\n\n0.855555555555556\n\n\nCon il cut-off di 0.5, l’accuratezza è 0.855, ovvero l’86% dei casi è stato correttamente classificato dal test. Vogliamo però trovare l’accuratezza della classificazione per tutti i possibili valori di cut-off. Costruiamo dunque la curva ROC in R.\n\ncompute_sens &lt;- function(\n    cut, x = dat1_sub$ADEC,\n    crit = dat1_sub$asd == \"ASD\") {\n    tp &lt;- sum(x &gt;= cut & crit, na.rm = TRUE)\n    fn &lt;- sum(x &lt; cut & crit, na.rm = TRUE)\n    tp / (tp + fn)\n}\ncompute_spec &lt;- function(\n    cut, x = dat1_sub$ADEC,\n    crit = dat1_sub$asd == \"ASD\") {\n    tn &lt;- sum(x &lt; cut & !crit, na.rm = TRUE)\n    fp &lt;- sum(x &gt;= cut & !crit, na.rm = TRUE)\n    tn / (tn + fp)\n}\nsensitivity &lt;- lapply(32:0, compute_sens) |&gt;\n    unlist()\nspecificity &lt;- lapply(32:0, compute_spec) |&gt;\n    unlist()\ndata.frame(sensitivity, fpr = 1 - specificity) |&gt;\n    ggplot(aes(x = fpr, y = sensitivity)) +\n    geom_point() +\n    geom_line()\n\n\n\n\n\n\n\n\nUna volta costruita la curva ROC possiamo calcolare l’area sottesa alla curva ROC.\n\n# AUC\ndfpr &lt;- c(diff(1 - specificity), 0)\ndsens &lt;- c(diff(sensitivity), 0)\nsum(sensitivity * dfpr) + sum(dsens * dfpr) / 2\n\n0.920626013218606\n\n\nSe consideriamo tutti i possibili valori di cut-off, l’accuratezza risulta uguale a 0.92. Questo valore indica un’ottima capacità del modello di regressione logistica nel discriminare con precisione i bambini con diagnosi di autismo da quelli senza.\nQuesti risultati suggeriscono che la scala ADEC è uno strumento utile e valido per identificare precocemente i bambini a rischio di sviluppare un disturbo dello spettro autistico. La sua elevata accuratezza predittiva consente di fornire una valutazione tempestiva e accurata per l’intervento precoce e il supporto necessario ai bambini e alle loro famiglie. In conclusione, l’analisi di regressione logistica e il calcolo dell’AUC hanno fornito evidenze solide sulla validità predittiva della scala ADEC nella diagnosi precoce dell’autismo.\n\n12.1.3.1 Pacchetto ROCit\nSi noti che si possono ottenere gli stessi risultati trovati sopra usando le funzioni del pacchetto ROCit.\n\nroc_adec &lt;- rocit(dat1_sub$ADEC, class = dat1_sub$asd == \"ASD\")\n\n\nplot(roc_adec)\n\n\n\n\n\n\n\n\n\nsummary(roc_adec)\n\n                          \n Method used: empirical   \n Number of positive(s): 99\n Number of negative(s): 81\n Area under curve: 0.9206 \n\n\n\nciAUC(roc_adec)\n\n                                                          \n   estimated AUC : 0.920626013218606                      \n   AUC estimation method : empirical                      \n                                                          \n   CI of AUC                                              \n   confidence level = 95%                                 \n   lower = 0.880257283328194     upper = 0.960994743109017",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Relazioni test-criterio</span>"
    ]
  },
  {
    "objectID": "chapters/validity/02_other_variables.html#considerazioni-conclusive",
    "href": "chapters/validity/02_other_variables.html#considerazioni-conclusive",
    "title": "12  Relazioni test-criterio",
    "section": "12.2 Considerazioni conclusive",
    "text": "12.2 Considerazioni conclusive\nIn conclusione, il capitolo ha dimostrato l’utilizzo dell’analisi di regressione logistica e del calcolo dell’Area Under the Curve (AUC) come strumenti importanti per valutare la validità di criterio di un test, specialmente quando il criterio riguarda l’appartenenza a un gruppo diagnostico specifico.\nL’analisi di regressione logistica e il calcolo dell’AUC forniscono una valutazione accurata della capacità del test di classificare correttamente i partecipanti in base al criterio diagnostico desiderato. Questa valutazione accurata offre una solida base per l’applicazione pratica del test, consentendo decisioni informate e mirate nell’identificazione di individui con particolari caratteristiche o condizioni. Inoltre, l’utilizzo di questi strumenti statistici rappresenta un passo importante verso la validazione dei test, garantendo la qualità delle diagnosi e facilitando l’implementazione di interventi mirati ed efficaci. La corretta valutazione della validità di criterio è essenziale per ottenere risultati affidabili e utili nella pratica clinica e nella ricerca.",
    "crumbs": [
      "Validità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Relazioni test-criterio</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html",
    "href": "chapters/gtheory/01_gtheory.html",
    "title": "13  Teoria della generalizzabilità",
    "section": "",
    "text": "13.1 Introduzione\nNei precedenti capitoli è stato illustrato come la Teoria Classica dei Test (CTT) identifichi l’errore di misurazione come una fonte di varianza non spiegata e definisca l’affidabilità come la proporzione di varianza vera rispetto alla varianza totale, che include anche l’errore di misurazione. La teoria della generalizzabilità estende questo concetto nella CTT, consentendo di distinguere tra diverse fonti di errore di misurazione in casi di disegni complessi, come errori associati alle persone, alle occasioni e agli item.\nQuesto capitolo si concentra su un’applicazione specifica della teoria della generalizzabilità, che è quella di stimare l’affidabilità delle misure all’interno di un disegno longitudinale. Nel corso di questo tutorial, esploreremo come affrontare questa sfida utilizzando il framework della teoria della generalizzabilità. Nei capitoli successivi esamineremo un approccio alternativo per risolvere lo stesso problema, che è il Latent Growth Modeling.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#molteplici-fonti-di-errore-di-misurazione",
    "href": "chapters/gtheory/01_gtheory.html#molteplici-fonti-di-errore-di-misurazione",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.2 Molteplici fonti di errore di misurazione",
    "text": "13.2 Molteplici fonti di errore di misurazione\nLa Teoria della Generalizzabilità, nota anche come “Generalizability Theory,” è una teoria statistica che fornisce un quadro per studiare l’affidabilità e la validità delle misurazioni in diversi contesti. In questa teoria, i fattori che possono contribuire all’errore nelle misurazioni vengono chiamati “facets” (es. valutatori, compiti, occasioni). Ogni fattore può essere considerato fisso o casuale.\nLa terminologia utilizzata è la seguente:\n\nLe “condizioni” (condition) rappresentano i livelli dei vari fattori.\nL’oggetto di misurazione (Object of Measurement), che di solito sono le persone, non è considerato un fattore ma è sempre considerato casuale.\nL’“Universo delle Operazioni Ammissibili” (Universe of Admissible Operations, UAO) è un ampio insieme di condizioni alle quali si vogliono generalizzare i risultati osservati.\nLo “Score dell’Universo” (Universe Score) rappresenta il punteggio medio di una persona considerando tutte le possibili combinazioni di condizioni nell’UAO.\nLo studio “G” (G Study) mira a ottenere informazioni accurate sulla grandezza dei fattori di errore.\nLo studio “D” (D Study) riguarda la progettazione di uno scenario di misurazione con il livello desiderato di affidabilità utilizzando il minor numero possibile di condizioni.\n\nLa Teoria della Generalizzabilità è particolarmente utile quando si desidera valutare l’affidabilità e la validità delle misurazioni in situazioni complesse, in cui diversi fattori possono influenzare l’errore di misurazione.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#differenze-tra-la-teoria-g-e-la-ctt",
    "href": "chapters/gtheory/01_gtheory.html#differenze-tra-la-teoria-g-e-la-ctt",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.3 Differenze tra la teoria G e la CTT",
    "text": "13.3 Differenze tra la teoria G e la CTT\nLa Teoria G e la Teoria Classica dei Test (CTT) sono due approcci distinti per valutare l’affidabilità di un test psicometrico. La Teoria G fornisce una valutazione più completa delle fonti di errore di misurazione, consentendo di stimare simultaneamente molteplici fonti di errore in un’unica analisi. I coefficienti di affidabilità nella Teoria G tengono conto di tutte le fonti misurate di errore, fornendo una stima più accurata dell’affidabilità complessiva del test.\nD’altra parte, la Teoria CTT permette di stimare solo una fonte di errore di misurazione alla volta. I coefficienti di affidabilità nella Teoria CTT si concentrano su una sola fonte di errore e non forniscono una visione completa dell’affidabilità del test. Inoltre, la Teoria G offre un metodo per determinare il numero di livelli di ciascuna fonte di errore necessari per ottenere livelli di affidabilità accettabili. Ciò consente di ottimizzare il design del test e garantire che il test sia affidabile in diverse situazioni e condizioni. Infine, la Teoria G fornisce coefficienti di affidabilità sia per decisioni riferite a norme (come classificazioni rispetto a una distribuzione di riferimento) che per decisioni riferite a criteri specifici (come confronti con standard prestabiliti). D’altro canto, i coefficienti di affidabilità più comunemente utilizzati nella Teoria CTT sono più adatti per test riferiti a norme, mentre per test riferiti a criteri possono essere meno accurati.\nIn sintesi, la Teoria G offre una valutazione più completa e accurata dell’affidabilità di un test, considerando diverse fonti di errore e fornendo informazioni utili per ottimizzare il design del test. La Teoria CTT, sebbene più semplice, è limitata nella sua capacità di catturare la complessità delle fonti di errore di misurazione. Pertanto, la Teoria G è spesso preferita quando si tratta di valutare l’affidabilità di test psicometrici complessi e con molteplici fonti di variabilità.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#fattori-incrociati-o-nidificati",
    "href": "chapters/gtheory/01_gtheory.html#fattori-incrociati-o-nidificati",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.4 Fattori incrociati o nidificati",
    "text": "13.4 Fattori incrociati o nidificati\nUn concetto fondamentale della teoria della generalizzabilità è la gerarchia dei dati, che si riferisce alla struttura del disegno di ricerca. Esistono due tipi principali di disegni: annidati (nested) e incrociati (crossed). Nei disegni annidati, i livelli di un fattore sono contenuti all’interno dei livelli di un altro; nei disegni incrociati, ogni livello di un fattore si combina con tutti i livelli di un altro fattore.\nConsideriamo ad esempio uno studio in cui diversi psicologi valutano l’intelligenza di studenti in diverse scuole. Se ogni psicologo valuta gli studenti di tutte le scuole, allora i fattori “psicologo” e “scuola” sono incrociati. Ciò significa che tutte le combinazioni di psicologi e scuole sono rappresentate nel campione.\nD’altra parte, supponiamo che vi siano gruppi distinti di psicologi assegnati a diverse scuole. Ad esempio, un gruppo di psicologi potrebbe valutare gli studenti di una scuola, mentre un altro gruppo di psicologi potrebbe valutare gli studenti di un’altra scuola. In questo caso, i valutatori sono nidificati all’interno delle scuole. Ciò significa che ogni scuola ha un gruppo specifico di psicologi associati a essa per le valutazioni.\nLa distinzione tra fattori incrociati e nidificati è importante perché influisce sulla generalizzabilità delle conclusioni dello studio. Nel caso incrociato, le conclusioni possono essere generalizzate a tutte le combinazioni di valutatori e scuole presenti nel campione. Nel caso nidificato, le conclusioni possono essere generalizzate solo alle scuole specifiche associate ai rispettivi gruppi di valutatori.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#fattori-casuali-o-fissi",
    "href": "chapters/gtheory/01_gtheory.html#fattori-casuali-o-fissi",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.5 Fattori casuali o fissi",
    "text": "13.5 Fattori casuali o fissi\nUn secondo concetto fondamentale della teoria della generalizzabilità riguarda la distinzione tra fattori casuali e fattori fissi in un disegno di ricerca. Un fattore è detto casuale quando le sue condizioni specifiche nello studio sono viste come un campione di un universo più ampio di condizioni, e si presume che queste siano equivalenti e interscambiabili con qualsiasi altra condizione nello stesso universo (Universo delle Operazioni Ammissibili, UAO). Ciò consente di generalizzare i risultati dello studio a tutte le condizioni all’interno dell’UAO. Ad esempio, i valutatori in uno studio sono considerati un fattore casuale se si assume che le valutazioni di uno siano sostituibili con quelle di un altro.\nContrariamente, un fattore fisso si concentra su condizioni specifiche e predeterminate, che costituiscono il completo insieme di interesse per il ricercatore. Questo approccio è utilizzato quando lo scopo è analizzare l’effetto di queste condizioni particolari senza cercare di generalizzare i risultati oltre a queste. Ad esempio, consideriamo uno studio sull’effetto di diverse terapie sulla riduzione dell’ansia in pazienti affetti da disturbi d’ansia, dove si esaminano specificamente tre tipi di terapia: Terapia A, Terapia B e Terapia C. Se ogni paziente partecipa a una ed una sola di queste terapie, selezionata in modo casuale, il fattore “Tipo di Terapia” è considerato fisso perché l’intenzione è di valutare l’effetto specifico di queste terapie selezionate, non di altre potenziali terapie non incluse nello studio.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#la-teoria-g",
    "href": "chapters/gtheory/01_gtheory.html#la-teoria-g",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.6 La teoria G",
    "text": "13.6 La teoria G\nIn questo capitolo, esamineremo uno specifico uso della Teoria della Generalizzabilità in uno studio longitudinale. Specificamente, ci porremo il problema di stimare l’affidabilità delle misure dei partecipanti nel tempo.\nSupponiamo di condurre uno studio in cui vogliamo valutare le performance di diversi studenti nel corso del tempo. Raccogliamo i punteggi di cinque studenti (A, B, C, D, E) su un compito misurato in tre diverse occasioni temporali (T1, T2, T3). Il nostro obiettivo è comprendere come variano le performance tra gli studenti e nel corso del tempo. Il disegno è persona-per-tempo (5 persone x 3 occasioni di misurazione).\nL’equazione di decomposizione della varianza degli score osservati in questo disegno è la seguente:\n\\[\n\\sigma^2(X_{pt}) = \\sigma^2_p + \\sigma^2_t + \\sigma^2_{pt} + \\sigma^2_{pt,e},\n\\]\ndove: - \\(\\sigma^2_p\\): rappresenta l’effetto principale delle persone, ovvero quanto variano le performance tra gli studenti. - \\(\\sigma^2_t\\): indica l’effetto principale del tempo, ovvero quanto variano le performance degli studenti nel corso del tempo. - \\(\\sigma^2_{pt}\\): rappresenta l’interazione persona-per-tempo, ovvero quanto variano le performance degli studenti nel corso del tempo. - \\(\\sigma^2_{pt,e}\\): è la varianza residua o non misurata, che include l’errore casuale e altre fonti di varianza non considerate nel disegno.\nIn un secondo esempio, consideriamo un disegno a tre fattori. Supponiamo di condurre uno studio per valutare le performance di diversi studenti (A, B, C, D, E) su diversi compiti (item) nel corso del tempo (T1, T2, T3). Vogliamo comprendere come le performance degli studenti possono variare tra gli item, nel tempo e se ci sono interazioni tra questi fattori. Il disegno è persona-per-item-per-tempo (5 persone x 3 item x 3 occasioni di misura).\nL’equazione di decomposizione della varianza degli score osservati in questo disegno sarà la seguente:\n\\[\n\\sigma^2(X_{pit}) = \\sigma^2_p + \\sigma^2_i + \\sigma^2_t + \\sigma^2_{pi} + \\sigma^2_{pt} + \\sigma^2_{it} + \\sigma^2_{pit,e},\n\\]\ndove: - \\(\\sigma^2_p\\): rappresenta l’effetto principale delle persone, ovvero quanto variano le performance tra gli studenti. - \\(\\sigma^2_i\\): indica l’effetto principale degli item, ovvero quanto variano i punteggi dei compiti tra i diversi item. - \\(\\sigma^2_t\\): rappresenta l’effetto principale del tempo, ovvero quanto variano le performance degli studenti nel corso del tempo. - \\(\\sigma^2_{pi}\\): indica l’interazione persona-per-item, ovvero quanto variano le performance degli studenti tra i diversi compiti. - \\(\\sigma^2_{pt}\\): rappresenta l’interazione persona-per-tempo, ovvero quanto variano le performance degli studenti nel corso del tempo. - \\(\\sigma^2_{it}\\): indica l’interazione item-per-tempo, ovvero quanto variano i punteggi dei compiti nel corso del tempo. - \\(\\sigma^2_{pit,e}\\): è la varianza residua o non misurata, che include l’errore casuale e altre fonti di varianza non considerate nel disegno.\nQuesti modelli ci permettono di analizzare come ciascuna fonte di variabilità influenzi i punteggi osservati.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#affidabilità",
    "href": "chapters/gtheory/01_gtheory.html#affidabilità",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.7 Affidabilità",
    "text": "13.7 Affidabilità\nIl Cambiamento di Affidabilità, nota come Cambiamento di Affidabilità (RC, da Reliability Change), valuta in che misura le variazioni nei punteggi di soggetti, valutati ripetutamente nel tempo, riflettano cambiamenti reali piuttosto che essere causate da errori di misurazione. Questo indice è fondamentale in studi longitudinali, dove si osserva lo stesso gruppo di individui in più occasioni, per stabilire se i cambiamenti nei punteggi sono sistematici e affidabili, legati al tempo e alle caratteristiche uniche dei partecipanti. Un alto valore di RC indica che le misurazioni sono coerenti nel tempo, suggerendo che qualsiasi variazione rilevata rappresenti un vero cambiamento nel comportamento o nelle risposte dei soggetti. Pertanto, l’RC aiuta a distinguere tra cambiamenti autentici e fluttuazioni dovute a inesattezze nella raccolta dei dati.\nAd esempio, nel caso di un disegno a tre fattori (perone \\(\\times\\) item \\(\\times\\) tempo), la formula di RC è la seguente:\n\\[\nR_c = \\frac{\\sigma^2_{TP}}{\\sigma^2_{TP} + \\frac{1}{k}(\\sigma^2_{TPI} + \\sigma^2_{v})},\n\\]\ndove: - \\(R_c\\) rappresenta la misura di affidabilità focale (Reliability Change). - \\(\\sigma^2_{TP}\\) è la varianza tra il tempo e le persone (time by person variance). - \\(\\sigma^2_{TPI}\\) è la varianza dell’interazione tra il tempo, le persone e gli item. - \\(\\sigma^2_{v}\\) è la varianza dell’errore (error variance). - \\(k\\) è il numero di item utilizzati.\nIl numeratore contiene solo una componente, ovvero la varianza tra il tempo e le persone, \\(\\sigma^2_{TP}\\). Il denominatore invece contiene la stessa componente di varianza, sommata alla componente di varianza dell’errore, divisa per il numero di item \\(k\\). Si noti che la componente di varianza dell’errore è la somma \\(\\sigma^2_{TPI} + \\sigma^2_{v}\\).\n\n13.7.1 Un esempio concreto\nApplichiamo questi concetti ai dati di Bolger e Laurenceau (2013) riguardanti uno studio che ha coinvolto 50 persone valutate per 10 giorni su 4 item. Gli item sono “interessato,” “determinato,” “entusiasta” e “ispirato,” rispettivamente. Le valutazioni per ciascun item sono state fatte su una scala da 1 (per niente) a 5 (estremamente).\nNel contesto della Teoria della Generalizzabilità, possiamo esaminare la variabilità dei punteggi dei partecipanti e suddividerla nelle diverse fonti di errore, che in questo caso includono la variazione dovuta ai diversi partecipanti (fonte di errore “Valutatori”), a diversi giorni (fonte di errore “Giorni”) e agli item specifici utilizzati (fonte di errore “Item”). Possiamo valutare quanto della variazione totale nei punteggi è attribuibile a ciascuna di queste fonti di errore.\nPer ottenere misure più precise e generalizzabili degli stati emotivi delle persone, possiamo calcolare gli “Score dell’Universo” per ciascun individuo. Gli score dell’universo rappresentano la media dei loro punteggi su tutti gli item, in tutti i giorni e su tutti i partecipanti. Questi score ci forniranno una stima più accurata del livello medio di “interessato,” “determinato,” “entusiasta” e “ispirato” per ciascun partecipante, considerando tutte le fonti di errore specificate.\nInfine, utilizzando la Teoria della Generalizzabilità, possiamo progettare uno studio ottimale (“D Study”) per massimizzare l’affidabilità delle misurazioni con il minor numero possibile di partecipanti, giorni e item. In questo modo, otterremo misurazioni più affidabili senza la necessità di sottoporre i partecipanti a un numero eccessivo di giorni di valutazione o di utilizzare troppi item.\nIn questo esempio, ci poniamo la seguente domanda: “Le variazioni all’interno dei soggetti possono essere misurate in modo affidabile?” Per rispondere a questa domanda, dobbiamo specificare le dimensioni di generalizzabilità. In questo caso, le dimensioni sono i momenti nel tempo, le persone e gli item.\nPer condurre questa analisi, useremo un modello a effetti misti per ciascuna delle dimensioni specificate.\nIniziamo leggendo i dati di Bolger e Laurenceau (2013).\n\nfilepath &lt;- \"https://quantdev.ssri.psu.edu/sites/qdev/files/psychometrics.csv\"\nd &lt;- read.csv(filepath)\nhead(d)\n\n\nA data.frame: 6 x 4\n\n\n\nperson\ntime\nitem\ny\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\n301\n1\n1\n2\n\n\n2\n301\n1\n2\n2\n\n\n3\n301\n1\n3\n3\n\n\n4\n301\n1\n4\n4\n\n\n5\n301\n2\n1\n2\n\n\n6\n301\n2\n2\n3\n\n\n\n\n\nRicodifichiamo la variabile item in modo che sia categorica utilizzando la funzione factor().\n\nd$item &lt;- factor(d$item)\n\nIl pacchetto lme4 contiene la funzione lmer(), che permette di adattare un modello lineare a effetti misti a un specifico set di dati. Utilizzando il summary() del nostro modello, possiamo osservare gli effetti di ciascuna dimensione di generalizzabilità. Questo modello è specificato solo con l’intercetta (ANOVA con effetti casuali) allo scopo di comprendere le fonti di variabilità tra le diverse dimensioni.\n\nmodel1 &lt;- lmer(\n    y ~ 1 +\n        (1 | person) +\n        (1 | time) +\n        (1 | item) +\n        (1 | person:time) +\n        (1 | person:item) +\n        (1 | time:item),\n    data = d\n)\nsummary(model1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ 1 + (1 | person) + (1 | time) + (1 | item) + (1 | person:time) +  \n    (1 | person:item) + (1 | time:item)\n   Data: d\n\nREML criterion at convergence: 4046.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2721 -0.5311 -0.0105  0.5044  3.8613 \n\nRandom effects:\n Groups      Name        Variance  Std.Dev. \n person:time (Intercept) 2.553e-01 5.053e-01\n person:item (Intercept) 1.901e-01 4.360e-01\n person      (Intercept) 3.619e-01 6.016e-01\n time:item   (Intercept) 4.985e-03 7.060e-02\n time        (Intercept) 7.366e-09 8.583e-05\n item        (Intercept) 4.854e-02 2.203e-01\n Residual                2.995e-01 5.473e-01\nNumber of obs: 1802, groups:  \nperson:time, 455; person:item, 200; person, 50; time:item, 40; time, 10; item, 4\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   2.4340     0.1456   16.72\n\n\nUtilizzando la funzione VarCorr(), possiamo estrarre e salvare ciascun valore di varianza dalla tabella di riepilogo dei risultati.\n\n(personTime &lt;- VarCorr(model1)[[1]][1, 1]) # person:time\n\n0.255279541307926\n\n\n\n(personItem &lt;- VarCorr(model1)[[2]][1, 1]) # person:item\n\n0.190074153321712\n\n\n\n(person &lt;- VarCorr(model1)[[3]][1, 1]) # person\n\n0.36189689746911\n\n\n\n(timeItem &lt;- VarCorr(model1)[[4]][1,1]) #time:item \n\n0.00498471479702945\n\n\n\n(time &lt;- VarCorr(model1)[[5]][1,1]) #time \n\n7.36624370806228e-09\n\n\n\n(item &lt;- VarCorr(model1)[[6]][1, 1]) # item\n\n0.0485426397323054\n\n\n\n(residual &lt;- sigma(model1)^2) # residual\n\n0.299541741894979\n\n\nTornando alla nostra domanda iniziale: Esistono differenze affidabili all’interno di una persona nel corso del tempo?\nUtilizzeremo la seguente formula per calcolare il coefficiente di affidabilità:\n\\[\nR_c = \\frac{\\sigma^2_{\\text{persona:tempo}}}{\\sigma^2_{\\text{persona:tempo}} + \\frac{\\sigma^2_{\\text{persona:tempo:item}} + \\sigma^2_{\\text{errore}}}{k}},\n\\]\ndove \\(k\\) si riferisce al numero di elementi. Nel nostro caso, \\(k\\)=4.\nNon possiamo distinguere il termine \\(\\sigma^2_{\\text{persona:tempo:item}}\\) da \\(\\sigma^2_{\\text{errore}}\\), quindi useremo il termine di errore residuo.\n\nk &lt;- 4\n(Rc &lt;- personTime / (personTime + residual / k))\n\n0.773187828086126\n\n\nQuesto coefficiente rappresenta il grado di adeguatezza e sistematicità delle misurazioni ripetute. Utilizzando le stesse regole interpretative del coefficiente alfa di Cronbach, possiamo determinare che quattro elementi possono catturare il cambiamento all’interno di una persona in modo affidabile, con \\(R_c = 0.77\\).\nUn altro coefficiente di interesse è \\(R_{1F}\\), che viene calcolato come:\n\\[\nR_{1F} = \\frac{\\sigma^2_{\\text{persona}} + \\left(\\frac{\\sigma^2_{\\text{persona:item}}}{k}\\right)}{\\sigma^2_{\\text{persona}} + \\left(\\frac{\\sigma^2_{\\text{persona:item}}}{k}\\right) + \\left(\\frac{\\sigma^2_{\\text{errore}}}{k}\\right)}\n\\]\ndove \\(k\\) si riferisce al numero di item. Nel nostro caso, \\(k\\)=4.\nPer i dati presenti, abbiamo:\n\nk &lt;- 4\n(R1f &lt;- (person + (personItem / k)) / (person + (personItem / k) + (residual / k)))\n\n0.845374146701693\n\n\nIl coefficiente di affidabilità \\(R_{1F}\\) rappresenta la stima attesa dell’affidabilità tra le persone per un giorno fisso, una sorta di media degli alfa di Cronbach specifici per ogni giorno in diverse occasioni. Utilizzando le stesse regole interpretative del coefficiente alfa di Cronbach, possiamo concludere che quattro item possono catturare in modo affidabile le differenze tra le persone in qualsiasi giorno specifico, con \\(R_{1F}\\) = 0.85.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#conclusioni",
    "href": "chapters/gtheory/01_gtheory.html#conclusioni",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.8 Conclusioni",
    "text": "13.8 Conclusioni\nLa Teoria della Generalizzabilità (G theory) fornisce un quadro completo per stimare l’impatto di molteplici fonti di errore di misurazione simultaneamente. La G theory si basa su un modello ANOVA in cui i fattori sono chiamati “facet” (fattori) e i loro livelli sono noti come “conditions” (condizioni). Ad esempio, gli studenti potrebbero essere valutati su un insieme di compiti da un gruppo di valutatori in diverse occasioni. Compiti, valutatori e occasioni potrebbero tutti contribuire all’errore di misurazione e verrebbero considerati “facet” nel disegno della G theory. La varianza dovuta a questi “facet” e alle loro interazioni potrebbe essere stimata, e le loro relative contribuzioni alla varianza dell’errore di misurazione valutate.\nIl concetto di generalizzabilità o affidabilità nella G theory è analogo al concetto di affidabilità nella CTT. Nella G theory, l’interesse è rivolto al grado in cui i punteggi osservati ottenuti in un determinato insieme di condizioni possono essere generalizzati alla media del punteggio che potrebbe essere ottenuto in un insieme di condizioni più ampiamente definite, noto come “UAO” (Universal Attribute Object). L’UAO è definito dal ricercatore e include tutte le condizioni che produrrebbero punteggi accettabili. Il grado in cui i punteggi si generalizzano dalle condizioni osservate all’UAO è definito come affidabilità. Livelli elevati di affidabilità indicano che i punteggi ottenuti nelle condizioni osservate si generalizzeranno ai punteggi universali delle persone. Il punteggio universale è analogo al punteggio vero nella CTT e può essere concepito come il punteggio medio che una persona otterrebbe se sottoposta a ripetuti test in tutte le possibili combinazioni di condizioni presenti nell’UAO.",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/gtheory/01_gtheory.html#session-info",
    "href": "chapters/gtheory/01_gtheory.html#session-info",
    "title": "13  Teoria della generalizzabilità",
    "section": "13.9 Session Info",
    "text": "13.9 Session Info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tidyr_1.3.1   lme4_1.1-35.1 Matrix_1.6-5 \n\nloaded via a namespace (and not attached):\n [1] crayon_1.5.2     vctrs_0.6.5      nlme_3.1-164     cli_3.6.2       \n [5] rlang_1.1.3      purrr_1.0.2      generics_0.1.3   jsonlite_1.8.8  \n [9] minqa_1.2.6      glue_1.7.0       htmltools_0.5.7  IRdisplay_1.1   \n[13] IRkernel_1.3.2   fansi_1.0.6      grid_4.3.2       tibble_3.2.1    \n[17] evaluate_0.23    MASS_7.3-60.0.1  fastmap_1.1.1    base64enc_0.1-3 \n[21] lifecycle_1.0.4  compiler_4.3.2   dplyr_1.1.4      pkgconfig_2.0.3 \n[25] Rcpp_1.0.12      pbdZMQ_0.3-11    lattice_0.22-5   digest_0.6.34   \n[29] R6_2.5.1         nloptr_2.0.3     tidyselect_1.2.0 repr_1.1.6      \n[33] utf8_1.2.4       pillar_1.9.0     splines_4.3.2    magrittr_2.0.3  \n[37] uuid_1.2-0       tools_4.3.2      boot_1.3-29",
    "crumbs": [
      "Teoria della generalizzabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Teoria della generalizzabilità</span>"
    ]
  },
  {
    "objectID": "chapters/fa/01_intro_fa.html",
    "href": "chapters/fa/01_intro_fa.html",
    "title": "14  Introduzione all’analisi fattoriale",
    "section": "",
    "text": "14.1 Caratteristiche dell’analisi fattoriale\nL’analisi fattoriale è una tecnica statistica utilizzata per identificare la struttura latente sottostante a un insieme di variabili osservate, con lo scopo di ridurre la complessità del dato e individuare costrutti latenti che spiegano le relazioni tra le variabili. Le due principali forme di analisi fattoriale sono l’analisi fattoriale esplorativa (EFA) e l’analisi fattoriale confermativa (CFA), che differiscono nel loro scopo e nel grado di definizione a priori della struttura da parte del ricercatore.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Introduzione all'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/01_intro_fa.html#caratteristiche-dellanalisi-fattoriale",
    "href": "chapters/fa/01_intro_fa.html#caratteristiche-dellanalisi-fattoriale",
    "title": "14  Introduzione all’analisi fattoriale",
    "section": "",
    "text": "14.1.1 Analisi Fattoriale Esplorativa (EFA)\nL’EFA viene utilizzata quando il ricercatore non ha ipotesi a priori su come un gruppo di variabili si strutturi. Il suo scopo è identificare empiricamente il modello che meglio si adatta ai dati, bilanciando precisione e semplicità. Questa tecnica esplora la struttura sottostante ai dati, permettendo di individuare fattori latenti che spiegano la varianza comune tra le variabili osservate. È particolarmente utile nei primi stadi di sviluppo di test psicometrici, quando si desidera identificare le dimensioni latenti sottostanti a un nuovo insieme di item. Tuttavia, la scelta di parametri e metodi di estrazione influisce pesantemente sul risultato finale.\n\n\n14.1.2 Analisi Fattoriale Confermativa (CFA)\nL’CFA è un approccio utilizzato quando il ricercatore ha un modello teorico ben definito e desidera valutare quanto questo modello ipotizzato si adatti ai dati osservati. La CFA consente di confrontare modelli teorici alternativi e valutare quale meglio spiega i dati, tenendo conto di vari fattori come i carichi fattoriali, gli errori e le covarianze. In psicometria, viene comunemente utilizzata per verificare la validità strutturale di un test o questionario, valutando se i dati empirici supportano il modello teorico ipotizzato.\n\n\n14.1.3 Struttura e Componenti dell’Analisi Fattoriale\nIndipendentemente dal tipo di analisi, l’analisi fattoriale si basa sulla distinzione tra variabili osservate (o manifest) e variabili latenti (o fattori). Le variabili latenti rappresentano costrutti teorici non direttamente osservabili, mentre le variabili osservate sono i punteggi effettivi ottenuti da misure dirette. Un modello fattoriale può includere carichi fattoriali, errori, covarianze e percorsi di regressione.\nUn carico fattoriale rappresenta la forza della relazione tra una variabile osservata e il fattore latente, mentre il residuo o errore rappresenta la varianza non spiegata dal fattore latente. Le covarianze esprimono le relazioni tra le variabili o tra i fattori latenti. L’equazione generale di un indicatore osservato \\(X\\) in relazione a un fattore latente \\(F\\) può essere espressa come:\n\\[\nX = \\lambda \\cdot F + \\text{Intercept} + \\text{Errore}\n\\]\ndove:\n\n\\(X\\) è il valore osservato dell’indicatore;\n\\(\\lambda\\) è il carico fattoriale;\n\\(F\\) è il valore del fattore latente;\nIntercept è il valore atteso dell’indicatore quando il fattore latente è zero;\nErrore è la parte di varianza non spiegata dal fattore latente.\n\n\n\n14.1.4 Modelli Fattoriali Gerarchici e Bifattoriali\nEsistono varianti più avanzate dell’analisi fattoriale, come i modelli gerarchici e i modelli bifattoriali, che permettono di rappresentare strutture latenti più complesse. In particolare, i modelli bifattoriali sono utili quando si ritiene che un insieme di variabili possa essere spiegato sia da un fattore generale che da fattori specifici. Ad esempio, nel contesto della misurazione dell’intelligenza, un modello bifattoriale potrebbe includere un fattore generale (g) che spiega la varianza comune tra tutte le variabili, e fattori specifici che spiegano varianze più circoscritte a singoli domini cognitivi.\n\n\n14.1.5 Sviluppo Storico dell’Analisi Fattoriale\nL’analisi fattoriale è stata sviluppata all’inizio del XX secolo da Charles Spearman per studiare la struttura dell’intelligenza. Spearman introdusse il concetto di fattore generale (g), che rappresentava la dimensione comune che spiegava la covarianza tra diverse abilità cognitive. Successivamente, psicologi come Thurstone criticarono il modello unifattoriale di Spearman e proposero un modello multifattoriale, che permetteva di individuare più fattori specifici, ciascuno dei quali spiegava una dimensione distinta dell’intelligenza.\nNegli anni ’60 e ’70, l’analisi fattoriale subì una trasformazione con lo sviluppo dei modelli di equazioni strutturali (SEM), che combinavano l’analisi fattoriale con la path analysis per rappresentare relazioni più complesse tra variabili osservate e latenti. Questo sviluppo permise ai ricercatori di verificare ipotesi teoriche più articolate riguardanti la struttura di costrutti psicologici complessi.\n\n\n14.1.6 Applicazioni dell’Analisi Fattoriale\nL’analisi fattoriale è ampiamente utilizzata nello sviluppo di strumenti psicometrici, come i test di intelligenza, le scale di personalità e i questionari di auto-valutazione. Viene utilizzata per valutare la validità di costrutto, ovvero la capacità di uno strumento di misurare effettivamente il costrutto teorico che si propone di valutare. Inoltre, l’analisi fattoriale può essere impiegata per esaminare la validità discriminante, ovvero la capacità di uno strumento di distinguere tra costrutti correlati ma distinti.\nInfine, l’analisi fattoriale è uno strumento fondamentale per individuare variabili latenti sottostanti e semplificare i dati complessi, consentendo ai ricercatori di ridurre grandi set di variabili osservate a un insieme più ristretto di fattori interpretabili. La sua applicazione, tuttavia, richiede attenzione nella scelta dei parametri e delle assunzioni, poiché le decisioni prese nel processo di analisi possono influenzare significativamente i risultati finali.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Introduzione all'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html",
    "href": "chapters/fa/02_analisi_fattoriale_1.html",
    "title": "15  Il modello unifattoriale",
    "section": "",
    "text": "15.1 Introduzione\nQuesto capitolo presenta le nozioni fondamentali dell’analisi fattoriale, un modello statistico che consente di spiegare le correlazioni tra variabili osservate mediante la loro saturazione in uno o più fattori generali. In questo modello, le \\(p\\) variabili osservate (item) sono considerate condizionalmente indipendenti rispetto a \\(m\\) variabili latenti chiamate fattori. L’obiettivo dell’analisi fattoriale è di interpretare questi fattori come costrutti teorici inosservabili. Ad esempio, l’analisi fattoriale può essere utilizzata per spiegare le correlazioni tra le prestazioni di un gruppo di individui in una serie di compiti mediante il concetto di intelligenza. In questo modo, l’analisi fattoriale aiuta a identificare i costrutti cui gli item si riferiscono e a stabilire in che misura ciascun item rappresenta il costrutto. Il modello può essere unifattoriale (\\(m = 1\\)) o multifattoriale (\\(m &gt; 1\\)), e in questo capitolo si introdurrà il modello unifattoriale che assume l’esistenza di un unico fattore comune latente.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#modello-monofattoriale",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#modello-monofattoriale",
    "title": "15  Il modello unifattoriale",
    "section": "15.3 Modello monofattoriale",
    "text": "15.3 Modello monofattoriale\nCon \\(p\\) variabili manifeste \\(y_i\\), il caso più semplice è quello di un solo fattore comune:\n\\[\n\\begin{equation}\ny_i = \\mu_i + \\lambda_{i} \\xi +  1 \\cdot \\delta_i \\qquad i=1, \\dots, p,\n\\end{equation}\n\\tag{15.1}\\]\ndove \\(\\xi\\) rappresenta il fattore comune a tutte le \\(y_i\\), \\(\\delta_i\\) sono i fattori specifici o unici di ogni variabile osservata e \\(\\lambda_i\\) sono le saturazioni (o pesi) fattoriali le quali stabiliscono il peso del fattore latente su ciascuna variabile osservata.\nIl modello di analisi fattoriale e il modello di regressione possono sembrare simili, ma presentano alcune differenze importanti. In primo luogo, sia il fattore comune \\(\\xi\\) sia i fattori specifici \\(\\delta_i\\) sono inosservabili, il che rende tutto ciò che si trova a destra dell’uguaglianza incognito. In secondo luogo, l’analisi di regressione e l’analisi fattoriale hanno obiettivi diversi. L’analisi di regressione mira a individuare le variabili esplicative, osservabili direttamente, che sono in grado di spiegare la maggior parte della varianza della variabile dipendente. Al contrario, il problema dell’analisi unifattoriale consiste nell’identificare la variabile esplicativa inosservabile che è in grado di spiegare la maggior parte della covarianza tra le variabili osservate.\nSolitamente, per comodità, si assume che la media delle variabili osservate \\(y_i\\) sia zero, ovvero \\(\\mu_i=0\\). Ciò equivale a considerare gli scarti delle variabili rispetto alle rispettive medie. Il modello unifattoriale assume che le variabili osservate siano il risultato della combinazione lineare di un fattore comune \\(\\xi\\) e dei fattori specifici \\(\\delta_i\\), ovvero:\n\\[\n\\begin{equation}\ny_i -\\mu_i = \\lambda_i \\xi + 1 \\cdot \\delta_i,\n\\end{equation}\n\\tag{15.2}\\]\ndove \\(\\lambda_i\\) è la saturazione o il peso della variabile \\(i\\)-esima sul fattore comune e \\(\\delta_i\\) rappresenta il fattore specifico della variabile \\(i\\)-esima. Si assume che il fattore comune abbia media zero e varianza unitaria, mentre i fattori specifici abbiano media zero, varianza \\(\\psi_{i}\\) e siano incorrelati tra loro e con il fattore comune. Nel modello unifattoriale, l’interdipendenza tra le variabili è completamente spiegata dal fattore comune.\nLe ipotesi precedenti consentono di ricavare la covarianza tra la variabile osservata \\(y_i\\) e il fattore comune, la varianza della variabile osservata \\(y_i\\) e la covarianza tra due variabili osservate \\(y_i\\) e \\(y_k\\). L’obiettivo della discussione in questo capitolo è appunto quello di analizzare tali grandezze statistiche.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#correlazione-parziale",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#correlazione-parziale",
    "title": "15  Il modello unifattoriale",
    "section": "15.4 Correlazione parziale",
    "text": "15.4 Correlazione parziale\nPrima di entrare nel dettaglio del modello statistico dell’analisi fattoriale, è importante chiarire il concetto di correlazione parziale. Si attribuisce spesso a Charles Spearman la nascita dell’analisi fattoriale. Nel 1904, Spearman pubblicò un articolo intitolato “General Intelligence, Objectively Determined and Measured” in cui propose la Teoria dei Due Fattori. In questo articolo, dimostrò come fosse possibile identificare un fattore inosservabile a partire da una matrice di correlazioni, utilizzando il metodo dell’annullamento della tetrade (tetrad differences). L’annullamento della tetrade è un’applicazione della teoria della correlazione parziale che mira a stabilire se, controllando un insieme di variabili inosservabili chiamate fattori \\(\\xi_j\\), le correlazioni tra le variabili osservabili \\(Y_i\\), al netto degli effetti lineari delle \\(\\xi_j\\), diventino statisticamente nulle.\nPossiamo considerare un esempio con tre variabili: \\(Y_1\\), \\(Y_2\\) e \\(F\\). La correlazione tra \\(Y_1\\) e \\(Y_2\\), \\(r_{1,2}\\), può essere influenzata dalla presenza di \\(F\\). Per calcolare la correlazione parziale tra \\(Y_1\\) e \\(Y_2\\) al netto dell’effetto lineare di \\(F\\), dobbiamo trovare le componenti di \\(Y_1\\) e \\(Y_2\\) che sono linearmente indipendenti da \\(F\\).\nPer fare ciò, dobbiamo trovare la componente di \\(Y_1\\) che è ortogonale a \\(F\\). Possiamo calcolare i residui \\(E_1\\) del modello:\n\\[\nY_1 = b_{01} + b_{11}F + E_1.\n\\]\nLa componente di \\(Y_1\\) linearmente indipendente da \\(F\\) è quindi data dai residui \\(E_1\\). Possiamo eseguire un’operazione analoga per \\(Y_2\\) per trovare la sua componente ortogonale a \\(F\\). Calcolando la correlazione tra le due componenti così ottenute si ottiene la correlazione parziale tra \\(Y_1\\) e \\(Y_2\\) al netto dell’effetto lineare di \\(F\\).\nL’Equazione 15.3 consente di calcolare la correlazione parziale tra \\(Y_1\\) e \\(Y_2\\) al netto dell’effetto di \\(F\\) a partire dalle correlazioni semplici tra le tre variabili \\(Y_1\\), \\(Y_2\\) e \\(F\\).\n\\[\n\\begin{equation}\nr_{1,2 \\mid F} = \\frac{r_{12} - r_{1F}r_{2F}}{\\sqrt{(1-r_{1F}^2)(1-r_{2F}^2)}}.\n\\end{equation}\n\\tag{15.3}\\]\nIn particolare, la correlazione parziale \\(r_{1,2 \\mid F}\\) è data dalla differenza tra la correlazione \\(r_{12}\\) tra \\(Y_1\\) e \\(Y_2\\) e il prodotto tra le correlazioni \\(r_{1F}\\) e \\(r_{2F}\\) tra ciascuna delle due variabili e \\(F\\), il tutto diviso per la radice quadrata del prodotto delle differenze tra 1 e i quadrati delle correlazioni tra \\(Y_1\\) e \\(F\\) e tra \\(Y_2\\) e \\(F\\). In altre parole, la formula tiene conto dell’effetto di \\(F\\) sulle correlazioni tra \\(Y_1\\) e \\(Y_2\\) per ottenere una stima della relazione diretta tra le due variabili, eliminando l’effetto del fattore comune.\nConsideriamo un esempio numerico. Sia \\(f\\) una variabile su cui misuriamo \\(n\\) valori\n\nset.seed(123)\nn &lt;- 1000\nf &lt;- rnorm(n, 24, 12)\n\nSiano \\(y_1\\) e \\(y_2\\) funzioni lineari di \\(f\\), a cui viene aggiunta una componente d’errore gaussiano:\n\ny1 &lt;- 10 + 7 * f + rnorm(n, 0, 50)\ny2 &lt;- 3  + 2 * f + rnorm(n, 0, 50)\n\nLa correlazione tra \\(y_1\\) e \\(y_2\\) (\\(r_{12}= 0.355\\)) deriva dal fatto che \\(\\hat{y}_1\\) e \\(\\hat{y}_2\\) sono entrambe funzioni lineari di \\(f\\):\n\nY &lt;- cbind(y1, y2, f)\nR &lt;- cor(Y)\nround(R, 3)\n\n\nA matrix: 3 x 3 of type dbl\n\n\n\ny1\ny2\nf\n\n\n\n\ny1\n1.000\n0.380\n0.867\n\n\ny2\n0.380\n1.000\n0.423\n\n\nf\n0.867\n0.423\n1.000\n\n\n\n\n\nEseguiamo le regressioni di \\(y_1\\) su \\(f\\) e di \\(y_2\\) su \\(F\\):\n\nfm1 &lt;- lm(y1 ~ f)\nfm2 &lt;- lm(y2 ~ f)\n\nNella regressione, ciascuna osservazione \\(y_{i1}\\) viene scomposta in due componenti linearmente indipendenti, i valori adattati \\(\\hat{y}_{i}\\) e i residui, \\(e_{i}\\): \\(y_i = \\hat{y}_i + e_1\\). Nel caso di \\(y_1\\) abbiamo\n\nround(head(cbind(y1, y1.hat=fm1$fit, e=fm1$res, fm1$fit+fm1$res)), 3)\n\n\nA matrix: 6 x 4 of type dbl\n\n\n\ny1\ny1.hat\ne\n\n\n\n\n\n1\n81.130\n130.505\n-49.375\n81.130\n\n\n2\n106.667\n159.704\n-53.037\n106.667\n\n\n3\n308.032\n317.846\n-9.813\n308.032\n\n\n4\n177.314\n186.285\n-8.971\n177.314\n\n\n5\n61.393\n191.482\n-130.089\n61.393\n\n\n6\n374.094\n331.668\n42.426\n374.094\n\n\n\n\n\nLo stesso può dirsi di \\(y_2\\). La correlazione parziale \\(r_{12 \\mid f}\\) tra \\(y_1\\) e \\(y_2\\) dato \\(f\\) è uguale alla correlazione di Pearson tra i residui \\(e_1\\) e \\(e_2\\) calcolati mediante i due modelli di regressione descritti sopra:\n\ncor(fm1$res, fm2$res)\n\n0.0282861771586006\n\n\nLa correlazione parziale tra \\(y_1\\) e \\(y_2\\) al netto di \\(f\\) è .02829.\nPer i dati esaminati sopra, dunque, la correlazione parziale tra le variabili \\(y_1\\) e \\(y_2\\) diventa uguale a zero se la variabile \\(f\\) viene controllata (ovvero, se escludiamo da \\(y_1\\) e da \\(y_2\\) l’effetto lineare di \\(f\\)). Il fatto che la correlazione parziale sia zero significa che la correlazione che abbiamo osservato tra \\(y_1\\) e \\(y_2\\) (\\(r = 0.355\\)) non dipendeva dall’effetto che una variabile \\(y\\) esercitava sull’altra, ma bensì dal fatto che c’era una terza variabile, \\(f\\), che influenzava sia \\(y_1\\) sia \\(y_2\\). In altre parole, le variabili \\(y_1\\) e \\(y_2\\) sono condizionalmente indipendenti dato \\(f\\). Ciò significa, come abbiamo visto sopra, che la componente di \\(y_1\\) linearmente indipendente da \\(f\\) è incorrelata con la componente di \\(y_2\\) linearmente indipendente da \\(f\\).\nLa correlazione che abbiamo calcolato tra i residui di due modelli di regressione è identica alla correlazione che viene calcolata applicando l’Equazione 15.3:\n\n(R[1, 2] - R[1, 3] * R[2, 3]) / \n  sqrt((1 - R[1, 3]^2) * (1- R[2, 3]^2)) %&gt;% \n  round(3)\n\n0.0282751285315664",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#principio-base-dellanalisi-fattoriale",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#principio-base-dellanalisi-fattoriale",
    "title": "15  Il modello unifattoriale",
    "section": "15.5 Principio base dell’analisi fattoriale",
    "text": "15.5 Principio base dell’analisi fattoriale\nAttualmente, l’inferenza statistica nell’analisi fattoriale spesso si svolge mediante il calcolo di stime della massima verosimiglianza ottenute mediante procedure iterative. All’inizio dell’analisi fattoriale, tuttavia, la procedura di estrazione dei fattori faceva leva sulle relazioni invarianti che il modello fattoriale impone agli elementi della matrice di covarianza delle variabili osservate. Il più conosciuto tra tali invarianti è la tetrade che si presenta nei modelli ad un fattore.\nLa tetrade è una combinazione di quattro correlazioni. Se l’associazione osservata tra le variabili dipende effettivamente dal fatto che le variabili in questione sono state causalmente generate da un fattore comune inosservabile, allora è possibile generare una combinazione delle correlazioni tra le variabili che porta all’annullamento della tetrade. In altre parole, l’analisi fattoriale si chiede se esiste un insieme esiguo di \\(m&lt;p\\) variabili inosservabili che rendono significativamente nulle tutte le correlazioni parziali tra le \\(p\\) variabili osservate al netto dei fattori comuni. Se il metodo della correlazione parziale consente di identificare \\(m\\) variabili latenti, allora lo psicologo conclude che tali fattori corrispondono agli \\(m\\) costrutti che intende misurare.\nPer chiarire il metodo dell’annullamento della tetrade consideriamo la matrice di correlazioni riportata nella Tabella successiva. Nella tabella, la correlazione parziale tra ciascuna coppia di variabili \\(y_i\\), \\(y_j\\) (con \\(i \\neq j\\)) dato \\(\\xi\\) è sempre uguale a zero. Ad esempio, la correlazione parziale tra \\(y_3\\) e \\(y_5\\) dato \\(\\xi\\) è:\n\\[\n\\begin{align}\n  r_{35 \\mid \\xi} &= \\frac{r_{35} - r_{3\\xi}r_{5\\xi}}\n  {\\sqrt{(1-r_{3\\xi}^2)(1-r_{5\\xi}^2)}} \\notag \\\\[12pt]\n  &= \\frac{0.35 - 0.7 \\times 0.5}\n  {\\sqrt{(1-0.7^2)(1-0.5^2)}} = 0. \\notag\n\\end{align}\n\\]\nLo stesso risultato si trova per qualunque altra coppia di variabili \\(y_i\\) e \\(y_j\\), ovvero \\(r_{ij \\mid \\xi} = 0\\).\n\n\n\n\n\\(\\xi\\)\n\\(y_1\\)\n\\(y_2\\)\n\\(y_3\\)\n\\(y_4\\)\n\\(y_5\\)\n\n\n\n\n\\(\\xi\\)\n1.00\n\n\n\n\n\n\n\n\\(y_1\\)\n0.90\n1.00\n\n\n\n\n\n\n\\(y_2\\)\n0.80\n0.72\n1.00\n\n\n\n\n\n\\(y_3\\)\n0.70\n0.63\n0.56\n1.00\n\n\n\n\n\\(y_4\\)\n0.60\n0.54\n0.48\n0.42\n1.00\n\n\n\n\\(y_5\\)\n0.50\n0.45\n0.40\n0.35\n0.30\n1.00\n\n\n\nPossiamo dunque dire che, per la matrice di correlazioni della Tabella, esiste un’unica variabile \\(\\xi\\) la quale, quando viene controllata, spiega tutte le\n\\[p(p-1)/2 = 5(5-1)/2=10\\]\ncorrelazioni tra le variabili \\(y\\). Questo risultato non è sorprendente, in quanto la matrice di correlazioni della Tabella è stata costruita in modo tale da possedere tale proprietà.\nMa supponiamo di essere in una situazione diversa, ovvero di avere osservato soltanto le variabili \\(y_i\\) e di non conoscere \\(\\xi\\). In tali circostanze ci possiamo porre la seguente domanda: Esiste una variabile inosservabile \\(\\xi\\) la quale, se venisse controllata, renderebbe uguali a zero tutte le correlazioni parziali tra le variabili \\(y\\)? Se una tale variabile inosservabile esiste, ed è in grado di spiegare tutte le correlazioni tra le variabili osservate \\(y\\), allora essa viene chiamata fattore. Arriviamo dunque alla seguente definizione:\nUn fattore è una variabile inosservabile in grado di rendere significativamente nulle tutte le correlazioni parziali tra le variabili manifeste.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#vincoli-sulle-correlazioni",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#vincoli-sulle-correlazioni",
    "title": "15  Il modello unifattoriale",
    "section": "15.6 Vincoli sulle correlazioni",
    "text": "15.6 Vincoli sulle correlazioni\nCome si può stabilire se esiste una variabile inosservabile in grado di rendere nulle tutte le correlazioni parziali tra le variabili osservate? Riscriviamo l’Equazione 15.3 per specificare la correlazione parziale tra le variabili \\(y_i\\) e \\(y_j\\) dato \\(\\xi\\):\n\\[\n\\begin{align}\n  r_{ij \\mid \\xi} &= \\frac{r_{ij} - r_{i\\xi}r_{j\\xi}}\n  {\\sqrt{(1-r_{i\\xi}^2)(1-r_{j\\xi}^2)}}\n\\end{align}\n\\]\nAffinché \\(r_{ij \\mid \\xi}\\) sia uguale a zero è necessario che\n\\[\nr_{ij} - r_{i\\xi}r_{j\\xi}=0\n\\]\novvero\n\\[\n\\begin{equation}\nr_{ij} = r_{i\\xi}r_{j\\xi}.\n\\end{equation}\n\\]\nIn altri termini, se esiste un fattore non osservato \\(\\xi\\) in grado di rendere uguali a zero tutte le correlazioni parziali \\(r_{ih \\mid \\xi}\\), allora la correlazione tra ciascuna coppia di variabili \\(y\\) deve essere uguale al prodotto delle correlazioni tra ciascuna \\(y\\) e il fattore latente \\(\\xi\\). Questo è il principio base dell’analisi fattoriale.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#teoria-dei-due-fattori",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#teoria-dei-due-fattori",
    "title": "15  Il modello unifattoriale",
    "section": "15.7 Teoria dei Due Fattori",
    "text": "15.7 Teoria dei Due Fattori\nPer fare un esempio concreto relativo al metodo dell’annullamento della tetrade, esaminiamo la matrice di correlazioni originariamente analizzata da Spearman. Spearman (1904) raccolse alcune misure di capacità intellettuale su un piccolo numero di studenti di una scuola superiore. Nello specifico, esaminò i voti di tali studenti nelle seguenti materie: studio dei classici (\\(c\\)), letteratura inglese (\\(e\\)) e abilità matematiche (\\(m\\)). Considerò anche la prestazione in un compito di discriminazione dell’altezza di suoni (“pitch discrimination”) (\\(p\\)), ovvero un’abilità diversa da quelle richieste nei test scolastici.\nSecondo la Teoria dei Due Fattori, le prestazioni relative ad un determinato compito intellettuale possiedono una componente comune (detta fattore ‘g’) con le prestazioni in un qualunque altro compito intellettuale e una componente specifica a quel determinato compito. Il modello dell’intelligenza di Spearman prevede dunque due fattori, uno generale e uno specifico (detto fattore ‘s’). Il fattore ‘g’ costituisce la componente invariante dell’abilità intellettiva, mente il fattore ‘s’ è una componente che varia da condizione a condizione.\nCome è possibile stabilire se esiste una variabile latente in grado di spiegare le correlazioni tra le variabili osservate da Spearman? Lo strumento proposto da Spearman per rispondere a questa domanda è l’annullamento della tetrade. L’annullamento della tetrade utilizza i vincoli sulle correlazioni che derivano dalla definizione di correlazione parziale. In precedenza abbiamo visto che la correlazione parziale tra le variabili \\(y\\) indicizzate da \\(i\\) e \\(j\\), al netto dell’effetto di \\(\\xi\\), è nulla se\n\\[\nr_{ij} = r_{i\\xi}r_{j\\xi}.\n\\]\nNel caso dei dati di Spearman, dunque, le correlazioni parziali sono nulle se la correlazione tra ‘’studi classici’’ e ‘’letteratura inglese’’ è uguale al prodotto della correlazione tra ‘’studi classici’’ e il fattore \\(\\xi\\) e della correlazione tra ‘’letteratura inglese’’ e il fattore \\(\\xi\\). Inoltre, la correlazione tra ‘’studi classici’’ e ‘’abilità matematica’’ deve essere uguale al prodotto della correlazione tra ‘’studi classici’’ e il fattore \\(\\xi\\) e della correlazione tra ‘’abilità matematica’’ e il fattore \\(\\xi\\); e così via.\nLe correlazioni tra le variabili manifeste e il fattore latente sono dette e vengono denotate con la lettera \\(\\lambda\\). Se il modello di Spearman è corretto, avremo che\n\\[r_{ec}=\\lambda_e \\times \\lambda_{c},\\]\ndove \\(r_{ec}\\) è la correlazione tra ‘’letteratura inglese’’ (e) e ‘’studi classici’’ (c), \\(\\lambda_e\\) è la correlazione tra ‘’letteratura inglese’’ e \\(\\xi\\), e \\(\\lambda_{c}\\) è la correlazione tra ‘’studi classici’’ e \\(\\xi\\).\nAllo stesso modo, la correlazione tra ‘’studi classici’’ e ‘’matematica’’ (m) dovrà essere uguale a\n\\[\\lambda_c \\times \\lambda_m,\\]\neccetera.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#annullamento-della-tetrade",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#annullamento-della-tetrade",
    "title": "15  Il modello unifattoriale",
    "section": "15.8 Annullamento della tetrade",
    "text": "15.8 Annullamento della tetrade\nDate le correlazioni tra tre coppie di variabili manifeste, il metodo dell’annullamento della tetrade\n\nin una matrice di correlazione, si selezionino quattro coefficienti nelle posizioni che marcano gli angoli di un rettangolo. La differenza tra i prodotti dei coefficienti che giacciono sulle due diagonali di tale rettangolo costituisce la differenza delle tetradi e deve essere uguale a zero.\n\nrende possibile stimare i valori delle saturazioni fattoriali \\(\\lambda\\). Ad esempio, per le variabili \\(c\\), \\(m\\) ed \\(e\\), possiamo scrivere le seguenti tre equazioni in tre incognite:\n\\[\n\\begin{align}\n  r_{cm} &= \\lambda_c \\times \\lambda_m, \\notag \\\\\n  r_{em} &= \\lambda_e \\times \\lambda_m,  \\\\\n  r_{ce} &= \\lambda_c \\times \\lambda_e. \\notag\n\\end{align}\n\\]\nRisolvendo il precedente sistema di equazioni lineari, il coefficiente di saturazione \\(\\lambda_m\\) della variabile \\(y_m\\) nel fattore comune \\(\\xi\\), ad esempio, pu{`o} essere calcolato a partire dalle correlazioni tra le variabili manifeste \\(c\\), \\(m\\), ed \\(e\\) nel modo seguente\\footnote{ La terza delle equazioni del sistema lineare può essere riscritta come \\(\\lambda_c = \\frac{r_{ce}}{\\lambda_e}\\).\nUtilizzando tale risultato, la prima equazione diventa \\(r_{cm} = \\frac{r_{ce}}{\\lambda_e}\\lambda_m\\). Dalla seconda equazione otteniamo \\(\\lambda_e = \\frac{r_{em}}{\\lambda_m}\\). Sostituendo questo risultato nell’equazione precedente otteniamo \\(r_{cm} = \\frac{r_{ce}}{r_{em}}\\lambda_m^2\\), quindi \\(\\lambda_m^2 = \\frac{r_{cm} r_{em} }{r_{ce}}\\).\nVerifichiamo: \\(\\frac{r_{cm} r_{em}}{r_{ce}} = \\frac{\\lambda_c \\lambda_m \\lambda_e \\lambda_m}{\\lambda_c \\lambda_e} = \\lambda_m^2\\).\n\\[\n\\begin{align}\n  \\lambda_m &= \\sqrt{\n    \\frac{r_{cm} r_{em}}{r_{ce}}\n    }.\n\\end{align}\n\\tag{15.4}\\]\nLo stesso vale per le altre due saturazioni \\(\\lambda_c\\) e \\(\\lambda_e\\).\nNel suo articolo del 1904, Spearman osservò le seguenti correlazioni tra le variabili \\(Y_c\\), \\(Y_e\\), \\(Y_m\\) e \\(Y_p\\):\n\\[\n\\begin{array}{ccccc}\n  \\hline\n    & Y_C & Y_E & Y_M & Y_P \\\\\n  \\hline\n  Y_C & 1.00 & 0.78 & 0.70 & 0.66 \\\\\n  Y_E &   & 1.00 & 0.64 & 0.54 \\\\\n  Y_M &   &   & 1.00 & 0.45 \\\\\n  Y_P &   &   &   & 1.00 \\\\\n  \\hline\n\\end{array}\n\\]\nUtilizzando l’Equazione 15.4, mediante le correlazioni \\(r_{cm}\\), \\(r_{em}\\), e \\(r_{ce}\\) fornite dalla tabella precedente, la saturazione \\(\\lambda_m\\) diventa uguale a:\n\\[\n\\begin{align}\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{r_{cm} r_{em}}{r_{ce}} } = \\sqrt{\n    \\frac{0.70 \\times 0.64}{0.78} } = 0.76. \\notag\n\\end{align}\n\\]\nÈ importante notare che il metodo dell’annullamento della tetrade produce risultati falsificabili. Infatti, ci sono modi diversi per calcolare la stessa saturazione fattoriale. Se il modello fattoriale è corretto si deve ottenere lo stesso risultato in tutti i casi.\nNel caso presente, la saturazione fattoriale \\(\\lambda_m\\) può essere calcolata in altri due modi:\n\\[\n\\begin{align}\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{r_{cm} r_{mp}}{r_{cp}} } = \\sqrt{ \\frac{0.78 \\times 0.45}{0.66} } = 0.69, \\notag \\\\\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{r_{em} r_{mp}}{r_{ep}} } = \\sqrt{\n    \\frac{0.64 \\times 0.45}{0.54} } = 0.73. \\notag\n\\end{align}\n\\]\nI tre valori che sono stati ottenuti sono molto simili. Qual è allora la stima migliore di \\(\\lambda_m\\)?",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#metodo-del-centroide",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#metodo-del-centroide",
    "title": "15  Il modello unifattoriale",
    "section": "15.9 Metodo del centroide",
    "text": "15.9 Metodo del centroide\nLa soluzione più semplice è quella di fare la media di questi tre valori (\\(\\bar{\\lambda}_m = 0.73\\)). Un metodo migliore (meno vulnerabile ai valori anomali) è dato dal rapporto tra la somma dei numeratori e dei denominatori:\n\\[\n\\begin{align}\n  \\hat{\\lambda}_m &= \\sqrt{ \\frac{0.70 \\times 0.64 + 0.78 \\times 0.45 + 0.64\n      \\times 0.45}{0.78+0.66+0.54} } = 0.73 \\notag\n\\end{align}\n\\]\nIn questo caso, i due metodi danno lo stesso risultato. Le altre tre saturazioni fattoriali trovate mediante il metodo del centroide sono:\n\\[\\hat{\\lambda}_c = 0.97, \\quad \\hat{\\lambda}_e = 0.84, \\quad \\hat{\\lambda}_p = 0.65.\\]\nIn conclusione,\n\\[\n\\boldsymbol{\\hat{\\Lambda}}'=\n(\\hat{\\lambda}_c, \\hat{\\lambda}_e, \\hat{\\lambda}_m, \\hat{\\lambda}_p) = (0.97, 0.84, 0.73, 0.65).\n\\]\nQuesto risultato è la soluzione proposta da Spearman nel suo articolo del 1904 per risolvere il problema di determinare le saturazioni fattoriali di un modello con un fattore comune latente.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#introduzione-a-lavaan",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#introduzione-a-lavaan",
    "title": "15  Il modello unifattoriale",
    "section": "15.10 Introduzione a lavaan",
    "text": "15.10 Introduzione a lavaan\nAttualmente, l’analisi fattoriale viene svolta mediante software. Il pacchetto R più ampiamente utilizzato per condurre l’analisi fattoriale è lavaan.\n\n15.10.1 Sintassi del modello\nAl cuore del pacchetto lavaan si trova la “sintassi del modello”. La sintassi del modello è una descrizione del modello da stimare. In questa sezione, spieghiamo brevemente gli elementi della sintassi del modello lavaan.\nNell’ambiente R, una formula di regressione ha la seguente forma:\ny ~ x1 + x2 + x3 + x4\nIn questa formula, la tilde (“~”) è l’operatore di regressione. Sul lato sinistro dell’operatore, abbiamo la variabile dipendente (y), e sul lato destro abbiamo le variabili indipendenti, separate dall’operatore “+” . In lavaan, un modello tipico è semplicemente un insieme (o sistema) di formule di regressione, in cui alcune variabili (che iniziano con una ‘f’ qui sotto) possono essere latenti. Ad esempio:\ny ~ f1 + f2 + x1 + x2\nf1 ~ f2 + f3\nf2 ~ f3 + x1 + x2\nSe abbiamo variabili latenti in una qualsiasi delle formule di regressione, dobbiamo “definirle” elencando i loro indicatori (manifesti o latenti). Lo facciamo utilizzando l’operatore speciale “=~”, che può essere letto come “è misurato da”. Ad esempio, per definire le tre variabili latenti f1, f2 e f3, possiamo usare la sintassi seguente:\nf1 =~ y1 + y2 + y3\nf2 =~ y4 + y5 + y6\nf3 =~ y7 + y8 + y9 + y10\nInoltre, le varianze e le covarianze sono specificate utilizzando un operatore “doppia tilde”, ad esempio:\ny1 ~~ y1 # varianza\ny1 ~~ y2 # covarianza\nf1 ~~ f2 # covarianza\nE infine, le intercette per le variabili osservate e latenti sono semplici formule di regressione con solo una intercetta (esplicitamente indicato dal numero “1”) come unico predittore:\ny1 ~ 1\nf1 ~ 1\nUtilizzando questi quattro tipi di formule, è possibile descrivere una vasta gamma di modelli di variabili latenti. L’attuale insieme di tipi di formula è riassunto nella tabella sottostante.\n\n\n\ntipo di formula\noperatore\nmnemonic\n\n\n\n\ndefinizione variabile latente\n=~\nè misurato da\n\n\nregressione\n~\nviene regredito su\n\n\n(co)varianza (residuale)\n~~\nè correlato con\n\n\nintercetta\n~ 1\nintercetta\n\n\n\nUna sintassi completa del modello lavaan è semplicemente una combinazione di questi tipi di formule, racchiusi tra virgolette singole. Ad esempio:\nmy_model &lt;- ' \n  # regressions\n  y1 + y2 ~ f1 + f2 + x1 + x2\n  f1 ~ f2 + f3\n  f2 ~ f3 + x1 + x2\n\n  # latent variable definitions \n  f1 =~ y1 + y2 + y3 \n  f2 =~ y4 + y5 + y6 \n  f3 =~ y7 + y8 + y9\n  \n  # variances and covariances \n  y1 ~~ y1 \n  y1 ~~ y2 \n  f1 ~~ f2\n\n  # intercepts \n  y1 ~ 1 \n  f1 ~ 1\n'\nPer adattare il modello ai dati usiamo la seguente sintassi.\nfit &lt;- cfa(model = my_model, data = my_data)\n\n\n15.10.2 Un esempio concreto\nAnalizziamo nuovamente i dati di Spearman che abbiamo esaminato in precedenza usando lavaan. La matrice completa dei dati di Spearman è messa a disposizione da Kan, Maas, e Levine (2019).\nSpecifichiamo il nome delle variabili manifeste\n\nvarnames &lt;- c(\n  \"Classics\", \"French\", \"English\", \"Math\", \"Pitch\", \"Music\"\n)\n\ne il loro numero\n\nny &lt;- length(varnames)\n\nCreiamo la matrice di correlazione:\n\nspearman_cor_mat &lt;- matrix(\n  c(\n    1.00,  .83,  .78,  .70,  .66,  .63,\n     .83, 1.00,  .67,  .67,  .65,  .57,\n     .78,  .67, 1.00,  .64,  .54,  .51,\n     .70,  .67,  .64, 1.00,  .45,  .51,\n     .66,  .65,  .54,  .45, 1.00,  .40,\n     .63,  .57,  .51,  .51,  .40, 1.00\n  ),\n  ny, ny,\n  byrow = TRUE,\n  dimnames = list(varnames, varnames)\n)\n\nSpecifichiamo l’ampiezza campionaria:\n\nn &lt;- 33\n\nDefiniamo il modello unifattoriale in lavaan. L’operatore =~ si può leggere dicendo che la variabile latente a sinistra dell’operatore viene identificata dalle variabili manifeste elencate a destra dell’operatore e separate dal segno +. Per il caso presente, il modello dei due fattori di Spearman può essere specificato come segue.\n\nspearman_mod &lt;- \"\n  g =~ Classics + French + English + Math + Pitch + Music\n\"\n\nAdattiamo il modello ai dati con la funzione cfa():\n\nfit1 &lt;- lavaan::cfa(\n  spearman_mod,\n  sample.cov = spearman_cor_mat,\n  sample.nobs = n,\n  std.lv = TRUE\n)\n\nLa funzione cfa() è una funzione dedicata per adattare modelli di analisi fattoriale confermativa. Il primo argomento è il modello specificato dall’utente. Il secondo argomento è il dataset che contiene le variabili osservate. L’argomento std.lv = TRUE specifica che imponiamo una varianza pari a 1 a tutte le variabili latenti comuni (nel caso presente, solo una). Ciò consente di stimare le saturazioni fattoriali.\nUna volta adattato il modello, la funzione summary() ci consente di esaminare la soluzione ottenuta:\n\nout = summary(\n  fit1, \n  fit.measures = TRUE, \n  standardized = TRUE\n)\nprint(out)\n\nlavaan 0.6-18 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                            33\n\nModel Test User Model:\n                                                      \n  Test statistic                                 2.913\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.968\n\nModel Test Baseline Model:\n\n  Test statistic                               133.625\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.086\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -212.547\n  Loglikelihood unrestricted model (H1)       -211.091\n                                                      \n  Akaike (AIC)                                 449.094\n  Bayesian (BIC)                               467.052\n  Sample-size adjusted Bayesian (SABIC)        429.622\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                    0.976\n  P-value H_0: RMSEA &gt;= 0.080                    0.016\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.025\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  g =~                                                                  \n    Classics          0.942    0.129    7.314    0.000    0.942    0.956\n    French            0.857    0.137    6.239    0.000    0.857    0.871\n    English           0.795    0.143    5.545    0.000    0.795    0.807\n    Math              0.732    0.149    4.923    0.000    0.732    0.743\n    Pitch             0.678    0.153    4.438    0.000    0.678    0.689\n    Music             0.643    0.155    4.142    0.000    0.643    0.653\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Classics          0.083    0.051    1.629    0.103    0.083    0.086\n   .French            0.234    0.072    3.244    0.001    0.234    0.242\n   .English           0.338    0.094    3.610    0.000    0.338    0.349\n   .Math              0.434    0.115    3.773    0.000    0.434    0.447\n   .Pitch             0.510    0.132    3.855    0.000    0.510    0.526\n   .Music             0.556    0.143    3.893    0.000    0.556    0.573\n    g                 1.000                               1.000    1.000\n\n\n\nL’output consiste in tre parti. Le prime nove righe sono chiamate intestazione. L’intestazione contiene le seguenti informazioni:\n\nil numero di versione di lavaan\nse l’ottimizzazione è terminata normalmente o meno e quante iterazioni sono state necessarie\nlo stimatore utilizzato (qui: ML, per la massima verosimiglianza)\nl’ottimizzatore utilizzato per trovare i valori dei parametri di adattamento migliori per questo stimatore (qui: NLMINB)\nil numero di parametri del modello (qui: 12)\nil numero di osservazioni che sono state effettivamente utilizzate nell’analisi (qui: 33)\nuna sezione chiamata “Model Test User Model”: che fornisce una statistica di test, i gradi di libertà e un valore p per il modello specificato dall’utente.\n\nLa sezione successiva contiene ulteriori misure di adattamento e viene mostrata solo se si utilizza l’argomento opzionale fit.measures = TRUE. Inizia con la riga Model Test Baseline Model: e termina con il valore per l’SRMR. L’ultima sezione contiene le stime dei parametri. Inizia con informazioni (tecniche) sul metodo utilizzato per calcolare gli errori standard. Quindi, vengono elencati tutti i parametri liberi (e fissati) inclusi nel modello. Di solito, prima vengono mostrate le variabili latenti, seguite dalle covarianze e dalle varianze (residui). La prima colonna (Stima) contiene il valore del parametro (stimato o fisso) per ogni parametro del modello; la seconda colonna (Std.err) contiene l’errore standard per ogni parametro stimato; la terza colonna (Z-value) contiene la statistica di Wald (che viene semplicemente ottenuta dividendo il valore del parametro per il suo errore standard), e l’ultima colonna (P(&gt;|z|)) contiene il valore p per testare l’ipotesi nulla che il valore del parametro sia uguale a zero nella popolazione.\n\nEstimate: Questo valore rappresenta lo stimatore di massima verosimiglianza per i pesi dei percorsi tra il costrutto latente (nel caso presente, il costrutto g) e le variabili osservate (le variabili manifeste: Classics, French, English, Math, Pitch, Music). In sostanza, è il peso del collegamento tra il costrutto latente e ciascuna delle variabili osservate nel modello.\nStd.lv: Questi valori rappresentano le stime dei coefficienti standardizzate rispetto alle variabili latenti. La standardizzazione avviene dividendo la stima del coefficiente non standardizzato per la deviazione standard della variabile latente. Ciò rende possibile confrontare direttamente i coefficienti all’interno del modello perché rimuove le unità di misura, facendo in modo che i coefficienti siano espressi in termini di deviazioni standard. Tuttavia, questa standardizzazione è parziale perché considera solo la varianza della variabile latente.\nStd.all: Questi valori rappresentano le stime dei coefficienti completamente standardizzate, cioè standardizzate sia rispetto alle variabili latenti che a quelle osservate. Ciò significa che sia la variabile dipendente (latente) sia le variabili indipendenti (osservate) sono state standardizzate prima di calcolare i coefficienti. Questo processo di standardizzazione completa permette un confronto diretto dei coefficienti all’interno del modello indipendentemente dalle unità di misura originali, rendendoli espressi in termini di quanti deviazioni standard la variabile dipendente cambia per ogni deviazione standard di cambiamento nella variabile indipendente.\n\nSi noti che nella sezione Varianze: c’è un punto prima dei nomi delle variabili osservate. Ciò perché sono variabili dipendenti (o endogene) (predette dalle variabili latenti) e quindi il valore della varianza stampato in output è una stima della varianza residua: la varianza rimanente che non è spiegata dal/i predittore/i. Al contrario, non c’è un punto prima dei nomi delle variabili latenti, perché in questo modello sono variabili esogene. I valori delle varianze qui sono le varianze totali stimate delle variabili latenti.\nÈ possibile semplificare l’output dalla funzione summary() in maniera tale da stampare solo la tabella completa delle stime dei parametri e degli errori standard. Qui usiamo coef(fit1).\n\nprint(round(coef(fit1), 2))\n\n       g=~Classics          g=~French         g=~English            g=~Math \n              0.94               0.86               0.79               0.73 \n          g=~Pitch           g=~Music Classics~~Classics     French~~French \n              0.68               0.64               0.08               0.23 \n  English~~English         Math~~Math       Pitch~~Pitch       Music~~Music \n              0.34               0.43               0.51               0.56 \n\n\nUsando parameterEstimates, l’output diventa il seguente.\n\nout = parameterEstimates(fit1, standardized = TRUE)\nprint(out)\n\n        lhs op      rhs   est    se     z pvalue ci.lower ci.upper std.lv\n1         g =~ Classics 0.942 0.129 7.314  0.000    0.689    1.194  0.942\n2         g =~   French 0.857 0.137 6.239  0.000    0.588    1.127  0.857\n3         g =~  English 0.795 0.143 5.545  0.000    0.514    1.076  0.795\n4         g =~     Math 0.732 0.149 4.923  0.000    0.441    1.024  0.732\n5         g =~    Pitch 0.678 0.153 4.438  0.000    0.379    0.978  0.678\n6         g =~    Music 0.643 0.155 4.142  0.000    0.339    0.948  0.643\n7  Classics ~~ Classics 0.083 0.051 1.629  0.103   -0.017    0.183  0.083\n8    French ~~   French 0.234 0.072 3.244  0.001    0.093    0.376  0.234\n9   English ~~  English 0.338 0.094 3.610  0.000    0.154    0.522  0.338\n10     Math ~~     Math 0.434 0.115 3.773  0.000    0.208    0.659  0.434\n11    Pitch ~~    Pitch 0.510 0.132 3.855  0.000    0.251    0.769  0.510\n12    Music ~~    Music 0.556 0.143 3.893  0.000    0.276    0.836  0.556\n13        g ~~        g 1.000 0.000    NA     NA    1.000    1.000  1.000\n   std.all\n1    0.956\n2    0.871\n3    0.807\n4    0.743\n5    0.689\n6    0.653\n7    0.086\n8    0.242\n9    0.349\n10   0.447\n11   0.526\n12   0.573\n13   1.000\n\n\nCon opportuni parametri possiamo semplificare l’output nel modo seguente.\n\nout = parameterEstimates(fit1, standardized = TRUE) %&gt;%\n  dplyr::filter(op == \"=~\") %&gt;%\n  dplyr::select(\n    \"Latent Factor\" = lhs,\n    Indicator = rhs,\n    B = est,\n    SE = se,\n    Z = z,\n    \"p-value\" = pvalue,\n    Beta = std.all\n  )\nprint(out)\n\n  Latent.Factor Indicator     B    SE     Z p.value  Beta\n1             g  Classics 0.942 0.129 7.314       0 0.956\n2             g    French 0.857 0.137 6.239       0 0.871\n3             g   English 0.795 0.143 5.545       0 0.807\n4             g      Math 0.732 0.149 4.923       0 0.743\n5             g     Pitch 0.678 0.153 4.438       0 0.689\n6             g     Music 0.643 0.155 4.142       0 0.653\n\n\nEsaminiamo la matrice delle correlazioni residue:\n\ncor_table &lt;- residuals(fit1, type = \"cor\")$cov\nprint(cor_table)\n\n         Clsscs French Englsh   Math  Pitch  Music\nClassics  0.000                                   \nFrench   -0.003  0.000                            \nEnglish   0.008 -0.033  0.000                     \nMath     -0.011  0.023  0.040  0.000              \nPitch     0.001  0.050 -0.016 -0.062  0.000       \nMusic     0.005  0.001 -0.017  0.024 -0.050  0.000\n\n\nCreiamo un qq-plot dei residui:\n\nres1 &lt;- residuals(fit1, type = \"cor\")$cov\nres1[upper.tri(res1, diag = TRUE)] &lt;- NA\nv1 &lt;- as.vector(res1)\nv2 &lt;- v1[!is.na(v1)]\n\ntibble(v2) %&gt;% \n  ggplot(aes(sample = v2)) + \n  stat_qq() + \n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\n15.10.3 Diagrammi di percorso\nIl pacchetto semPlot consente di disegnare diagrammi di percorso per vari modelli SEM. La funzione semPaths prende in input un oggetto creato da lavaan e disegna il diagramma, con diverse opzioni disponibili. Il diagramma prodotto controlla le dimensioni dei caratteri/etichette, la visualizzazione dei residui e il colore dei percorsi/coefficienti. Sono disponibili queste e molte altre opzioni di controllo.\n\nsemPaths(\n    fit1,\n    \"std\",\n    posCol = c(\"black\"),\n    edge.label.cex = 1.2,\n    sizeMan = 7\n)\n\n\n\n\n\n\n\n\nIl calcolo delle saturazioni fattoriali con il metodo del centroide aveva prodotto il seguente risultato:\n\nclassici (Cls): 0.97\ninglese (Eng): 0.84\nmatematica (Mth): 0.73\npitch discrimination (Ptc): 0.65\n\nSi noti la somiglianza con i valori ottenuti mediante il metodo di massima verosimiglianza riportati nella figura.\n\n\n15.10.4 Analisi fattoriale esplorativa\nQuando abbiamo un’unica variabile latente, l’analisi fattoriale confermativa si riduce al caso dell’analisi fattoriale esplorativa. Esaminiamo qui sotto la sintassi per l’analisi fattoriale esplorativa in lavaan.\nSpecifichiamo il modello.\n\nefa_model &lt;- '\n    efa(\"efa\")*g =~ Classics + French + English + Math + Pitch + Music\n'\n\nAdattiamo il modello ai dati.\n\nfit2 &lt;- lavaan::cfa(\n  efa_model,\n  sample.cov = spearman_cor_mat,\n  sample.nobs = n,\n  std.lv = TRUE\n)\n\nEsaminiamo la soluzione ottenuta.\n\nout = summary(fit2, standardized = TRUE)\nprint(out)\n\nlavaan 0.6.17 ended normally after 3 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Rotation method                       GEOMIN OBLIQUE\n  Geomin epsilon                                 0.001\n  Rotation algorithm (rstarts)                GPA (30)\n  Standardized metric                             TRUE\n  Row weights                                     None\n\n  Number of observations                            33\n\nModel Test User Model:\n                                                      \n  Test statistic                                 2.913\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.968\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  g =~ efa                                                              \n    Classics          0.942    0.129    7.314    0.000    0.942    0.956\n    French            0.857    0.137    6.239    0.000    0.857    0.871\n    English           0.795    0.143    5.545    0.000    0.795    0.807\n    Math              0.732    0.149    4.923    0.000    0.732    0.743\n    Pitch             0.678    0.153    4.438    0.000    0.678    0.689\n    Music             0.643    0.155    4.142    0.000    0.643    0.653\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Classics          0.083    0.051    1.629    0.103    0.083    0.086\n   .French            0.234    0.072    3.244    0.001    0.234    0.242\n   .English           0.338    0.094    3.610    0.000    0.338    0.349\n   .Math              0.434    0.115    3.773    0.000    0.434    0.447\n   .Pitch             0.510    0.132    3.855    0.000    0.510    0.526\n   .Music             0.556    0.143    3.893    0.000    0.556    0.573\n    g                 1.000                               1.000    1.000\n\n\n\n\nsemPaths(\n    fit2,\n    \"std\",\n    posCol = c(\"black\"),\n    edge.label.cex = 1.2,\n    sizeMan = 7\n)",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#conclusioni",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#conclusioni",
    "title": "15  Il modello unifattoriale",
    "section": "15.11 Conclusioni",
    "text": "15.11 Conclusioni\nNel presente capitolo abbiamo introdotto il metodo dell’annullamento della tetrade che consente di stimare le saturazioni di un modello monofattoriale. Abbiamo anche visto che il metodo dell’annullamento della tetrade non è altro che un’applicazione della correlazione parziale.\nPossiamo dire che un tema cruciale nella costruzione dei test psicologici è quello di stabilire il numero di fattori/tratti che sono soggiacenti all’insieme degli indicatori che vengono considerati. La teoria classica dei test richiede che il test sia monofattoriale, ovvero che gli indicatori considerati siano l’espressione di un unico tratto latente. La violazione della monodimensionalità rende problematica l’applicazione dei principi della teoria classica dei test ai punteggi di un test che non possiede tale proprietà. L’esame della dimensionalità di un gruppo di indicatori rappresenta dunque una fase cruciale nel processo di costruzione di un test e, solitamente, questo esame è affrontato mediante l’analisi fattoriale. In questo capitolo abbiamo presentato le proprietà di base del modello unifattoriale.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#session-info",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#session-info",
    "title": "15  Il modello unifattoriale",
    "section": "15.12 Session Info",
    "text": "15.12 Session Info\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 15.0\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] corrplot_0.94     kableExtra_1.4.0  lavaanExtra_0.2.1 lavaanPlot_0.8.1 \n [5] ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n [9] ggExtra_0.10.1    bayesplot_1.11.1  gridExtra_2.3     patchwork_1.3.0  \n[13] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-18     psych_2.4.6.26   \n[17] scales_1.3.0      markdown_1.13     knitr_1.48        lubridate_1.9.3  \n[21] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[25] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n[29] tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3  rstudioapi_0.16.0   jsonlite_1.8.9     \n  [4] magrittr_2.0.3      TH.data_1.1-2       estimability_1.5.1 \n  [7] farver_2.1.2        nloptr_2.1.1        rmarkdown_2.28     \n [10] vctrs_0.6.5         minqa_1.2.8         base64enc_0.1-3    \n [13] rstatix_0.7.2       htmltools_0.5.8.1   broom_1.0.6        \n [16] Formula_1.2-5       htmlwidgets_1.6.4   plyr_1.8.9         \n [19] sandwich_3.1-1      emmeans_1.10.4      zoo_1.8-12         \n [22] uuid_1.2-1          igraph_2.0.3        mime_0.12          \n [25] lifecycle_1.0.4     pkgconfig_2.0.3     Matrix_1.7-0       \n [28] R6_2.5.1            fastmap_1.2.0       shiny_1.9.1        \n [31] numDeriv_2016.8-1.1 digest_0.6.37       OpenMx_2.21.12     \n [34] fdrtool_1.2.18      colorspace_2.1-1    rprojroot_2.0.4    \n [37] Hmisc_5.1-3         labeling_0.4.3      fansi_1.0.6        \n [40] timechange_0.3.0    abind_1.4-8         compiler_4.4.1     \n [43] withr_3.0.1         glasso_1.11         htmlTable_2.4.3    \n [46] backports_1.5.0     carData_3.0-5       ggsignif_0.6.4     \n [49] MASS_7.3-61         corpcor_1.6.10      gtools_3.9.5       \n [52] tools_4.4.1         pbivnorm_0.6.0      foreign_0.8-87     \n [55] zip_2.3.1           httpuv_1.6.15       nnet_7.3-19        \n [58] glue_1.7.0          quadprog_1.5-8      DiagrammeR_1.0.11  \n [61] promises_1.3.0      nlme_3.1-166        lisrelToR_0.3      \n [64] grid_4.4.1          pbdZMQ_0.3-13       checkmate_2.3.2    \n [67] cluster_2.1.6       reshape2_1.4.4      generics_0.1.3     \n [70] gtable_0.3.5        tzdb_0.4.0          data.table_1.16.0  \n [73] hms_1.1.3           xml2_1.3.6          car_3.1-2          \n [76] utf8_1.2.4          sem_3.1-16          pillar_1.9.0       \n [79] IRdisplay_1.1       rockchalk_1.8.157   later_1.3.2        \n [82] splines_4.4.1       lattice_0.22-6      survival_3.7-0     \n [85] kutils_1.73         tidyselect_1.2.1    miniUI_0.1.1.1     \n [88] pbapply_1.7-2       svglite_2.1.3       stats4_4.4.1       \n [91] xfun_0.47           qgraph_1.9.8        arm_1.14-4         \n [94] visNetwork_2.1.2    stringi_1.8.4       boot_1.3-31        \n [97] evaluate_1.0.0      codetools_0.2-20    mi_1.1             \n[100] cli_3.6.3           RcppParallel_5.1.9  IRkernel_1.3.2     \n[103] rpart_4.1.23        systemfonts_1.1.0   xtable_1.8-4       \n[106] repr_1.1.7          munsell_0.5.1       Rcpp_1.0.13        \n[109] coda_0.19-4.1       png_0.1-8           XML_3.99-0.17      \n[112] parallel_4.4.1      jpeg_0.1-10         lme4_1.1-35.5      \n[115] mvtnorm_1.3-1       openxlsx_4.2.7.1    crayon_1.5.3       \n[118] rlang_1.1.4         multcomp_1.4-26     mnormt_2.1.1       \n\n\n\n\n\n\nKan, Kees-Jan, Han LJ van der Maas, e Stephen Z Levine. 2019. «Extending psychometric network analysis: Empirical evidence against g in favor of mutualism?» Intelligence 73: 52–62.\n\n\nPetersen, Isaac T. 2024. Principles of psychological assessment: With applied examples in R. CRC Press.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html",
    "href": "chapters/fa/03_analisi_fattoriale_2.html",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "",
    "text": "16.1 Modello monofattoriale\nIl punto di partenza dell’analisi fattoriale esplorativa è rappresentato da una marice di dimensioni \\(p \\times p\\) (dove \\(p\\) è il numero di variabili osservate) che contiene i coefficienti di correlazione (o di covarianza) tra le variabili. Il punto di arrivo è rappresentato da una matrice di dimensioni \\(p \\times k\\) (dove \\(k\\)) è il numero di fattori comuni che contiene i coefficienti (le saturazioni) che esprimono la relazione tra i fattori e le variabili osservate. Considereremo ora il modello matematico dell’analisi fattoriale esplorativa, con un solo fattore comune, che rappresenta il caso più semplice.\nCon \\(p\\) variabili manifeste \\(Y_i\\), il modello ad un fattore comune può essere espresso algebricamente nel modo seguente:\n\\[\nY_i = \\mu_i + \\lambda_{i} \\xi + \\delta_i \\qquad i=1, \\dots, p\n\\]\ndove \\(\\xi\\) rappresenta il fattore latente, chiamato anche fattore comune, poiché è comune a tutte le \\(Y_i\\), i \\(\\delta_i\\) sono invece specifici di ogni variabile osservata e per tale ragione vengono chiamati fattori specifici o unici, e infine i \\(\\lambda_i\\) sono detti saturazioni (o pesi) fattoriali poiché consentono di valutare il peso del fattore latente su ciascuna variabile osservata. Si suole assumere per comodità che \\(\\mu=0\\), il che corrisponde a considerare le variabili \\(Y_i\\) come ottenute dagli scarti dalle medie \\(\\mu_i\\) per \\(i = 1, \\dots, p\\):\n\\[\nY_i -\\mu_i = \\lambda_i \\xi + \\delta_i.\n\\]\nSi assume che il fattore comune abbia media zero, \\(\\mathbb{E}(\\xi)=0\\), e varianza unitaria, \\(\\mathbb{V}(\\xi)=1\\), che i fattori specifici abbiano media zero, \\(\\mathbb{E}(\\delta_j)=0\\), e varianza \\(\\mathbb{V}(\\delta_j)=\\psi_{i}\\), che i fattori specifici siano incorrelati tra loro, \\(\\mathbb{E}(\\delta_i \\delta_k)=0\\), e che i fattori specifici siano incorrelati con il fattore comune, \\(\\mathbb{E}(\\delta_i \\xi)=0\\).\nIn questo modello, poiché i fattori specifici sono tra loro incorrelati, l’interdipendenza tra le variabili manifeste è completamente spiegata dal fattore comune. Dalle ipotesi precedenti è possibile ricavare la covarianza tra \\(Y_i\\) e il fattore comune, la varianza della \\(i\\)-esima variabile manifesta \\(Y_i\\) e la covarianza tra due variabili manifeste \\(Y_i\\) e \\(Y_k\\).",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#covarianza-tra-un-indicatore-e-il-fattore-comune",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#covarianza-tra-un-indicatore-e-il-fattore-comune",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.2 Covarianza tra un indicatore e il fattore comune",
    "text": "16.2 Covarianza tra un indicatore e il fattore comune\nDal modello monofattoriale è possibile determinare l’espressione della covarianza teorica tra una variabile manifesta \\(Y_i\\) e il fattore comune \\(\\xi\\):\n\\[\nCov(Y_i,\\xi)=\\mathbb{E}(Y_i \\xi)-\\mathbb{E}(Y_i)\\mathbb{E}(\\xi).\n\\]\nDato che \\(\\mathbb{E}(\\xi)=0\\), possiamo scrivere\n\\[\n\\begin{equation}\n\\begin{aligned}\n  Cov(Y_i,\\xi) &= \\mathbb{E}(Y_i \\xi)=\\mathbb{E}[(\\lambda_i \\xi + \\delta_i) \\xi]\\notag\\\\\n  &=\\mathbb{E}(\\lambda_i \\xi^2 + \\delta_i \\xi)\\notag\\\\\n  &=\\lambda_i\\underbrace{\\mathbb{E}(\\xi^2)}_{\\mathbb{V}(\\xi)=1} + \\underbrace{\\mathbb{E}(\\delta_i \\xi)}_{Cov(\\delta_i, \\xi)=0}\\notag\\\\\n  &= \\lambda_i.\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nNel modello a un solo fattore, dunque, la saturazione \\(\\lambda_j\\) rappresenta la covarianza la variabile manifesta \\(Y_i\\) e il fattore comune \\(\\xi\\) e indica l’importanza del fattore nel determinare il punteggio osservato. Se le variabili \\(Y_i\\) sono standardizzate, la saturazione fattoriale \\(\\lambda_i\\) corrisponde alla correlazione tra \\(Y_i\\) e \\(\\xi\\).",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#espressione-fattoriale-della-varianza",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#espressione-fattoriale-della-varianza",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.3 Espressione fattoriale della varianza",
    "text": "16.3 Espressione fattoriale della varianza\nNell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la varianza di \\(Y_i\\)\n\\[\n\\begin{equation}\n  \\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) -[\\mathbb{E}(Y_i)]^2 = \\mathbb{E}(Y_i^2)\\notag\n\\end{equation}\n\\]\nè data da\n\\[\n\\begin{equation}\n\\begin{aligned}\n  \\mathbb{V}(Y_i) &= \\mathbb{E}[(\\lambda_i \\xi + \\delta_i)^2 ]\\notag\\\\\n  &=\\lambda_i^2 \\underbrace{\\mathbb{E}(\\xi^2) }_{\\mathbb{V}(\\xi)=1} + \\underbrace{\\mathbb{E}(\\delta_i^2) }_{\\mathbb{V}(\\delta_i)=\\psi_{i}} + 2\\lambda_i \\underbrace{\\mathbb{E}(\\xi \\delta_i) }_{Cov(\\xi, \\delta_{i})=0}\\notag\\\\\n  &=\\lambda^2_i + \\psi_{i}.\n\\end{aligned}\n\\end{equation}\n\\]\nLa quantità \\(\\lambda^2_i\\) è denominata comunalità della \\(i\\)-esima variabile manifesta e corrisponde alla quota della varianza della \\(Y_i\\) spiegata dal fattore comune. Di conseguenza \\(\\psi_{i}\\) è la parte residua della varianza di \\(Y_i\\) non spiegata dal fattore comune ed è denominata unicità di \\(Y_i\\). Nel caso di variabili standardizzate, l’unicità diventa uguale a\n\\[\n\\psi_{i}=1-\\lambda^2_i.\n\\]\nIn definitiva, la varianza totale di una variabile osservata può essere divisa in una quota che ciascuna variabile condivide con le altre variabili ed è spiegata dal fattore comune (questa quota è chiamata comunalità ed è uguale uguale al quadrato della saturazione della variabile osservata nel fattore comune, ovvero \\(h^2_i = \\lambda_i^2\\)), e in una quota che è spiegata dal fattore specifico (questa parte è chiamata unicità ed è uguale a \\(u_i = \\psi_{i}\\)).\nEsempio. Riprendiamo l’analisi della matrice di correlazioni di Spearman. Nell’output prodotto dalla funzione factanal() viene riportata la quantità denominata SS loadings. Tale quantità indica la porzione della varianza totale delle 4 variabili manifeste che viene spiegata dal fattore comune. Ciascuna variabile standardizzata contribuisce con un’unità di varianza; nel caso presente, dunque la varianza totale è uguale a 4. Si ricordi che, nella statistica multivariata, per varianza totale si intende la somma delle varianze delle variabili manifeste (nel linguaggio dell’algebra matriciale questa quantità corrisponde alla traccia della matrice di covarianze). La quota della varianza totale spiegata dal modello, invece, è data dalla somma delle comunalità delle quattro variabili, ovvero dalla somma delle saturazioni fattoriali innalzate al quadrato.\n\nSpearman &lt;- matrix(c(\n  1.0, .78, .70, .66,\n  .78, 1.0, .64, .54,\n  .70, .64, 1.0, .45,\n  .66, .54, .45, 1.0\n),\nbyrow = TRUE, ncol = 4\n)\nrownames(Spearman) &lt;- c(\"C\", \"E\", \"M\", \"P\")\ncolnames(Spearman) &lt;- c(\"C\", \"E\", \"M\", \"P\")\nSpearman |&gt;\n  print()\n\n     C    E    M    P\nC 1.00 0.78 0.70 0.66\nE 0.78 1.00 0.64 0.54\nM 0.70 0.64 1.00 0.45\nP 0.66 0.54 0.45 1.00\n\n\nEseguiamo l’analisi fattoriale:\n\nfm &lt;- factanal(covmat = Spearman, factors = 1)\nfm |&gt;\n    print()\n\n\nCall:\nfactanal(factors = 1, covmat = Spearman)\n\nUniquenesses:\n    C     E     M     P \n0.086 0.329 0.460 0.539 \n\nLoadings:\n  Factor1\nC 0.956  \nE 0.819  \nM 0.735  \nP 0.679  \n\n               Factor1\nSS loadings      2.587\nProportion Var   0.647\n\nThe degrees of freedom for the model is 2 and the fit was 0.023 \n\n\nLe saturazioni fattoriali sono:\n\nL &lt;- c(fm$load[1], fm$load[2], fm$load[3], fm$load[4])\nprint(L)\n\n[1] 0.9562592 0.8193902 0.7350316 0.6790212\n\n\nFacendo il prodotto interno otteniamo:\n\nt(L) %*% L \n\n\nA matrix: 1 x 1 of type dbl\n\n\n2.587173\n\n\n\n\n\nIn termini proporzionali, la quota della varianza totale delle variabile manifeste che viene spiegata dal modello ad un fattore comune è dunque uguale a \\(2.587 / 4 = 0.647\\). Questa quantità è indicata nell’output con la denominazione Proportion Var.\nSi dice unicità (uniqueness) la quota della varianza della variabile considerata che non viene spiegata dalla soluzione fattoriale:\n\nround(fm$uniqueness, 3) |&gt;\n    print()\n\n    C     E     M     P \n0.086 0.329 0.460 0.539 \n\n\nLa comunalità (ovvero, la quota di varianza di ciascuna variabile manifesta che viene spiegata dal fattore comune) può essere trovata come:\n\nround(1 - fm$uniqueness, 3) |&gt;\n    print()\n\n    C     E     M     P \n0.914 0.671 0.540 0.461 \n\n\noppure con\n\nL^2 |&gt;\n    print()\n\n[1] 0.9144316 0.6714003 0.5402714 0.4610697",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#covarianza-tra-due-variabili-manifeste",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#covarianza-tra-due-variabili-manifeste",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.4 Covarianza tra due variabili manifeste",
    "text": "16.4 Covarianza tra due variabili manifeste\nNell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la covarianza tra \\(Y_i\\) e \\(Y_k\\)\n\\[\nCov(Y_i, Y_k)=\\mathbb{E}(Y_i Y_k) -\n\\mathbb{E}(Y_i)\\mathbb{E}(Y_k)=\\mathbb{E}(Y_i Y_k)\n\\]\nè uguale al prodotto delle corrispondenti saturazioni fattoriali:\n\\[\n\\begin{equation}\n\\begin{aligned}\nCov(Y_i, Y_k) &= \\mathbb{E}(Y_i Y_k) \\notag\\\\\n  & =\\mathbb{E}[(\\lambda_i \\xi + \\delta_i)(\\lambda_k \\xi +  \\delta_k)]\\notag\\\\\n  &=\\mathbb{E}(\\lambda_i\\lambda_k\\xi^2 + \\lambda_i  \\xi \\delta_k + \\lambda_k \\delta_i \\xi + \\delta_i \\delta_k)\\notag\\\\\n  &=\\lambda_i\\lambda_k\\underbrace{\\mathbb{E}(\\xi^2)}_{\\mathbb{V}(\\xi)=1}+\\lambda_i\\underbrace{\\mathbb{E}(\\xi \\delta_k)}_{Cov(\\xi, \\delta_k) =0}+\\notag\\\\ \\;&+\\lambda_k\\underbrace{\\mathbb{E}(\\delta_i \\xi)}_{Cov(\\delta_i, \\xi) =0} +\\underbrace{\\mathbb{E}(\\delta_i \\delta_k)}_{Cov(\\delta_i, \\delta_k)=0}\\notag\\\\\n  &=\\lambda_i\\lambda_k.\n\\end{aligned}\n\\end{equation}\n\\]",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#correlazioni-osservate-e-correlazioni-riprodotte-dal-modello",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#correlazioni-osservate-e-correlazioni-riprodotte-dal-modello",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.5 Correlazioni osservate e correlazioni riprodotte dal modello",
    "text": "16.5 Correlazioni osservate e correlazioni riprodotte dal modello\nIn generale possiamo affermare che il modello monofattoriale è adeguato se si verifica che \\(Cov(Y_i, Y_k \\mid \\xi) = 0\\) (\\(i, k = 1, \\dots,p; \\; i\\neq k\\)), ossia se il fattore comune spiega tutta la covarianza tra le variabili osservate. La matrice di correlazioni riprodotte dal modello è chiamata \\(\\boldsymbol{\\Sigma}\\) e può essere espressa come:\n\\[\n\\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^\\prime + \\boldsymbol{\\Psi}\n\\]\nIn altri termini, il modello monofattoriale è adeguato se è nulla la differenza tra la matrice di correlazioni osservate e la matrice di correlazioni riprodotte dal modello. Per i dati di Spearman, le correlazioni riprodotte dal modello ad un fattore sono\n\nround( L %*% t(L) + diag(fm$uniq), 3) |&gt;\n    print()\n\n      [,1]  [,2]  [,3]  [,4]\n[1,] 1.000 0.784 0.703 0.649\n[2,] 0.784 1.000 0.602 0.556\n[3,] 0.703 0.602 1.000 0.499\n[4,] 0.649 0.556 0.499 1.000\n\n\nLa matrice delle differenze tra le correlazioni campionarie e quelle riprodotte è\n\nround(Spearman - (L %*% t(L) + diag(fm$uniq)), 3) |&gt;\n    print()\n\n       C      E      M      P\nC  0.000 -0.004 -0.003  0.011\nE -0.004  0.000  0.038 -0.016\nM -0.003  0.038  0.000 -0.049\nP  0.011 -0.016 -0.049  0.000\n\n\nLo scarto maggiore tra le correlazioni campionarie e quelle riprodotte è uguale a 0.049. Si può dunque concludere che il modello monofattoriale spiega in maniera ragionevole i dati di Spearman.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#bontà-di-adattamento-del-modello-ai-dati",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#bontà-di-adattamento-del-modello-ai-dati",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.6 Bontà di adattamento del modello ai dati",
    "text": "16.6 Bontà di adattamento del modello ai dati\nLa verifica della bontà di adattamento del modello ai dati si determina mediante un test statistico che valuta la differenza tra la matrice di correlazioni (o di covarianze) osservata e la matrice di correlazioni (o covarianze) predetta dal modello fattoriale. L’ipotesi nulla che viene valutata è che la matrice delle correlazioni residue sia dovuta semplicemente agli errori di campionamento, ovvero che la matrice di correlazioni predetta dal modello \\(\\boldsymbol{\\Sigma}(\\theta)\\) sia uguale alla matrice di correlazioni \\(\\boldsymbol{\\Sigma}\\) nella popolazione.\nLa statistica test \\(v\\) è una funzione della differenza tra la matrice riprodotta \\(\\boldsymbol{S}(\\theta)\\) e quella osservata \\(\\boldsymbol{S}\\)\n\\[\nv = f\\left[\\boldsymbol{S}(\\theta) - \\boldsymbol{S}\\right]\n\\]\ne si distribuisce come una \\(\\chi^2\\) con \\(\\nu\\) gradi di libertà\n\\[\n\\nu = p(p+1)/ 2 - q,\n\\]\ndove \\(p\\) è il numero di variabili manifeste e \\(q\\) è il numero di parametri stimati dal modello fattoriale (ovvero, \\(\\lambda\\) e \\(\\psi\\)).\nLa statistica \\(v\\) assume valore 0 se i parametri del modello riproducono esattamente la matrice di correlazioni tra le variabili nella popolazione. Tanto maggiore è la statistica \\(v\\) tanto maggiore è la discrepanza tra le correlazioni osservate e quelle predette dal modello fattoriale.\nUn risultato statisticamente significativo (es., \\(p\\) &lt; .05) – il quale suggerisce che una tale differenza non è uguale a zero – rivela dunque una discrepanza tra il modello e i dati. Il test del modello fattoriale mediante la statistica \\(\\chi^2\\) segue dunque una logica diversa da quella utilizzata nei normali test di ipotesi statistiche: un risultato statisticamente significativo indica una mancanza di adattamento del modello ai dati.\nL’applicazione del test \\(\\chi^2\\) per valutare la bontà di adattamento del modello ai dati richiede che ciascuna variabile manifesta sia distribuita normalmente – più precisamente, richiede che le variabili manifeste siano un campione casuale che deriva da una normale multivariata. Questo requisito non è facile da rispettare in pratica.\nTuttavia, il limite principale della statistica \\(\\chi^2\\) è che essa dipende fortemente dalle dimensioni del campione: al crescere delle dimensioni campionarie è più facile ottenere un risultato statisticamente significativo (ovvero, concludere che vi è un cattivo adattamento del modello ai dati). Per questa ragione, la bontà di adattamento del modello ai dati viene valutata da molteplici indici, non soltanto dalla statistica \\(\\chi^2\\). Più comune è calcolare il rapporto \\(\\chi^2 / \\nu\\) e usare tale rapporto per valutare la bontà dell’adattamento. Valori minori di 3 o 4 suggeriscono che il modello ben si adatta ai dati.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#lerrore-standard-della-misurazione-e-il-modello-fattoriale",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#lerrore-standard-della-misurazione-e-il-modello-fattoriale",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.7 L’errore standard della misurazione e il modello fattoriale",
    "text": "16.7 L’errore standard della misurazione e il modello fattoriale\nIn questa sezione, approfondiamo la connessione tra l’errore standard di misurazione, un concetto fondamentale della Classical Test Theory (CTT), e l’applicazione del modello fattoriale. Questa connessione ci permette di reinterpretare l’errore standard di misurazione attraverso il prisma dell’analisi fattoriale. Procediamo con un’esposizione dettagliata.\nAll’interno della CTT, si afferma che il punteggio ottenuto (\\(X\\)) in un test corrisponde alla somma del valore vero (\\(T\\)) e dell’errore di misurazione (\\(E\\)), dove \\(E\\) è considerato una variabile casuale indipendente da \\(T\\). Se focalizziamo l’attenzione sul soggetto \\(i\\)-esimo, la formula diventa \\(X_i = T_i + E_i\\), con \\(T_i\\) rappresentante il valore vero e \\(E_i\\) l’errore di misurazione, quest’ultimo avente media zero.\nTrasformiamo questa relazione nel contesto di un modello fattoriale monofattoriale che coinvolge \\(p\\) variabili osservate (o item). Per ogni item, la relazione è espressa come:\n\\[\n\\begin{equation}\n\\begin{aligned}\nY_{1i} &=  \\lambda_1 \\xi_i + \\delta_{1i} \\notag\\\\\nY_{2i} &=  \\lambda_2 \\xi_i + \\delta_{2i} \\notag\\\\\n  \\dots\\notag\\\\\nY_{pi} &=  \\lambda_p \\xi_i + \\delta_{pi}, \\notag\n\\end{aligned}\n\\end{equation}\n\\]\ndove \\(Y_{ji}\\) rappresenta il punteggio osservato per l’item \\(j\\) del soggetto \\(i\\), \\(\\lambda_j\\) è il carico fattoriale dell’item \\(j\\) sul fattore comune \\(\\xi_i\\), e \\(\\delta_{ji}\\) è l’errore unico associato all’item \\(j\\) per il soggetto \\(i\\).\nIl punteggio totale \\(X_i\\) per il soggetto \\(i\\)-esimo deriva dalla somma dei punteggi di ciascun item, il che si traduce in:\n\\[\n\\begin{equation}\n\\begin{aligned}\nX_i &= \\sum_{j=1}^p Y_{ji} = \\sum_{j=1}^p \\lambda_j \\xi_i + \\sum_{j=1}^p \\delta_{ji}\\notag\\\\[12pt]\n  &=  \\left( \\sum_{j=1}^p \\lambda_j \\right) \\xi_i  +  \\sum_{j=1}^p \\delta_{ji} \\notag\\\\[12pt]\n  &= T_i + E_i\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nRispettando la struttura della CTT, la varianza del punteggio osservato \\(X_i\\) si decompone in due componenti fondamentali: la varianza del valore vero \\(\\sigma^2_{T_i}\\) e la varianza dell’errore \\(\\sigma^2_{E_i}\\). Nel contesto dell’analisi fattoriale, \\(\\sigma^2_{T_i}\\) corrisponde al quadrato della somma dei carichi fattoriali:\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\sigma^2_{T_i} &= \\mathbb{V}\\left[ \\left( \\sum_{j=1}^p \\lambda_j \\right) \\xi_i \\right]\\notag\\\\\n&= \\left( \\sum_{j=1}^p \\lambda_j \\right)^2 \\mathbb{V}(\\xi_i)\\notag\\\\\n&= \\left( \\sum_{j=1}^p \\lambda_j \\right)^2 \\notag\n\\end{aligned}\n\\end{equation}\n\\]\nInoltre, considerando la varianza dell’errore di misurazione \\(\\sigma^2_{E_i}\\) nel contesto fattoriale, questa è equivalente alla somma delle varianze degli errori unici (\\(\\delta_{ji}\\)), ovvero le unicità:\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\sigma^2_{E_i} &= \\mathbb{V}\\left( \\sum_{j=1}^p \\delta_{ji} \\right)\\notag\\\\\n&= \\sum_{j=1}^p \\mathbb{V}\\left( \\delta_{ji} \\right)\\notag\\\\\n&= \\sum_{j=1}^p \\Psi_j\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nPertanto, nel contesto dell’analisi fattoriale, l’errore standard di misurazione per il punteggio totale del test è quantificabile come la radice quadrata della somma delle unicità:\n\\[\n\\begin{equation}\n\\sigma_{E} = \\sqrt{\\sum_{j=1}^p \\Psi_j}\n\\end{equation}\n\\](eq-err-stnd-meas-FA)\nQuesto collegamento tra la CTT e l’analisi fattoriale offre una prospettiva rinnovata sull’errore standard di misurazione, arricchendo la nostra comprensione della precisione dei test psicometrici.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#un-esempio-concreto",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#un-esempio-concreto",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.8 Un esempio concreto",
    "text": "16.8 Un esempio concreto\nApplichiamo ora il risultato precedente ad un caso concreto. Consideriamo i dati utilizzati nella validazione italiana del Cognitive Style Questionnaire - Short Form (CSQ-SF, Meins et al. 2012). Il CSQ-SF viene utilizzato per misurare la vulnerabilità all’ansia e alla depressione. È costituito da cinque sottoscale: Internality, Globality, Stability, Negative consequences e Self-worth.\nLeggiamo i dati in \\(\\textsf{R}\\):\n\ncsq &lt;- rio::import(here::here(\"data\", \"csq540.csv\"))\n\nIl numero di partecipanti è\n\nn &lt;- nrow(csq)\nn\n\n540\n\n\nLe statistiche descrittive si ottengono con la seguente istruzione:\n\npsych::describe(csq, type = 2) |&gt;\n    print()\n\n  vars   n  mean    sd median trimmed   mad min max range  skew kurtosis   se\nI    1 540 47.76  5.78     48   47.87  4.45  21  64    43 -0.31     1.07 0.25\nG    2 540 45.00 11.94     42   44.55 11.86  16  78    62  0.34    -0.70 0.51\nS    3 540 44.60 12.18     42   44.24 13.34  16  77    61  0.27    -0.77 0.52\nN    4 540 22.01  6.92     21   21.86  7.41   8  39    31  0.21    -0.74 0.30\nW    5 540 44.05 13.10     43   43.66 13.34  16  79    63  0.31    -0.53 0.56\n\n\nEsaminiamo la matrice di correlazione:\n\npsych::pairs.panels(csq) |&gt;\n    print()\n\nNULL\n\n\n\n\n\n\n\n\n\nLa sottoscala di Internality è problematica, come messo anche in evidenza dall’autore del test. La consideriamo comunque in questa analisi statistica.\nSpecifichiamo il modello unifattoriale nella sintassi di lavaan:\n\nmod_csq &lt;- \"\n   F =~ NA*I + G + S + N + W\n   F ~~ 1*F\n\" \n\nAdattiamo il modello ai dati:\n\nfit &lt;- lavaan:::cfa(\n  mod_csq,\n  data = csq\n)\n\nEsaminiamo i risultati:\n\nsummary(\n  fit, \n  standardized = TRUE,\n  fit.measures = TRUE\n) |&gt;\n    print()\n\nlavaan 0.6.17 ended normally after 26 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           540\n\nModel Test User Model:\n                                                      \n  Test statistic                                46.716\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              2361.816\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.982\n  Tucker-Lewis Index (TLI)                       0.965\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -8741.781\n  Loglikelihood unrestricted model (H1)      -8718.423\n                                                      \n  Akaike (AIC)                               17503.562\n  Bayesian (BIC)                             17546.478\n  Sample-size adjusted Bayesian (SABIC)      17514.734\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.124\n  90 Percent confidence interval - lower         0.093\n  90 Percent confidence interval - upper         0.158\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.989\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  F =~                                                                  \n    I                 0.725    0.253    2.867    0.004    0.725    0.126\n    G               -11.322    0.384  -29.481    0.000  -11.322   -0.949\n    S               -11.342    0.398  -28.513    0.000  -11.342   -0.932\n    N                -6.163    0.233  -26.398    0.000   -6.163   -0.891\n    W               -11.598    0.444  -26.137    0.000  -11.598   -0.886\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    F                 1.000                               1.000    1.000\n   .I                32.840    2.000   16.420    0.000   32.840    0.984\n   .G                14.038    1.473    9.532    0.000   14.038    0.099\n   .S                19.508    1.718   11.353    0.000   19.508    0.132\n   .N                 9.847    0.725   13.573    0.000    9.847    0.206\n   .W                36.892    2.685   13.737    0.000   36.892    0.215\n\n\n\nEsaminiamo solo le stime dei parametri del modello:\n\nparameterEstimates(fit) |&gt;\n    print()\n\n   lhs op rhs     est    se       z pvalue ci.lower ci.upper\n1    F =~   I   0.725 0.253   2.867  0.004    0.229    1.220\n2    F =~   G -11.322 0.384 -29.481  0.000  -12.075  -10.569\n3    F =~   S -11.342 0.398 -28.513  0.000  -12.122  -10.563\n4    F =~   N  -6.163 0.233 -26.398  0.000   -6.621   -5.705\n5    F =~   W -11.598 0.444 -26.137  0.000  -12.467  -10.728\n6    F ~~   F   1.000 0.000      NA     NA    1.000    1.000\n7    I ~~   I  32.840 2.000  16.420  0.000   28.920   36.759\n8    G ~~   G  14.038 1.473   9.532  0.000   11.151   16.924\n9    S ~~   S  19.508 1.718  11.353  0.000   16.140   22.876\n10   N ~~   N   9.847 0.725  13.573  0.000    8.425   11.269\n11   W ~~   W  36.892 2.685  13.737  0.000   31.628   42.155\n\n\nRecuperiamo le specificità:\n\npsi &lt;- parameterEstimates(fit)$est[7:11]\npsi |&gt;\n    print()\n\n[1] 32.839665 14.037578 19.508119  9.846927 36.891617\n\n\nStimiamo l’errore standard della misurazione con la @ref(eq:err-stnd-meas-FA):\n\nsqrt(sum(psi)) |&gt;\n    print()\n\n[1] 10.63597\n\n\nApplichiamo ora la formula della TCT:\n\\[\n\\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}}.\n\\]\nPer trovare \\(\\sigma\\) calcoliamo prima il punteggio totale:\n\ntot_score &lt;- rowSums(csq)\n\nLa deviazione standard di tot_score ci fornisce una stima di \\(\\sigma_X\\):\n\nsigma &lt;- sd(tot_score)\nsigma |&gt;\n    print()\n\n[1] 41.26414\n\n\nPer applicare la formula della TCT abbiamo bisogno dell’attendibilità. La stimiamo usando la funzione reliability del pacchetto semTools dall’oggetto creato da lavaan:::cfa():\n\nrel &lt;- semTools::reliability(fit)\nrel |&gt;\n    print()\n\n               F\nalpha  0.8506572\nomega  0.9330313\nomega2 0.9330313\nomega3 0.9273385\navevar 0.7916575\n\n\nUtilizzando \\(\\Omega\\) otteniamo:\n\nsigma * sqrt(1- rel[2]) |&gt;\n    print()\n\n[1] 0.2587831\n\n\n10.67846074554\n\n\nSi noti come il risultato sia molto simile a quello trovato con la formula della TCT.\n\n16.8.1 Correlazioni osservate e riprodotte\nLe correlazioni riprodotte dal modello si ottengono nel modo seguente dall’oggetto fit.\n\ncor_mat &lt;- lavInspect(fit, \"cor.ov\")\ncor_mat |&gt;\n    print()\n\n       I      G      S      N      W\nI  1.000                            \nG -0.119  1.000                     \nS -0.117  0.885  1.000              \nN -0.112  0.846  0.830  1.000       \nW -0.111  0.841  0.825  0.789  1.000\n\n\nAbbiamo visto come il modello unifattoriale predice che la correlazione tra due variabili manifeste sia il prodotto delle rispettive correlazioni fattoriali. Estraiamo le saturazioni fattoriali.\n\nl &lt;- inspect(fit, what=\"std\")$lambda\nl |&gt;\n    print()\n\n       F\nI  0.126\nG -0.949\nS -0.932\nN -0.891\nW -0.886\n\n\nPer esempio, se consideriamo I e G, la correlazione predetta dal modello fattoriale tra queste due sottoscale è data dal prodotto delle rispettive saturazioni fattoriali.\n\nl[1] * l[2] |&gt;\n    print()\n\n[1] -0.9493687\n\n\n-0.11915121205349\n\n\nLa matrice di correlazioni riprodotte riportata sopra mostra il risultato di questo prodotto per ciascuna coppia di variabili manifeste.\n\nl %*% t(l) |&gt; round(3) |&gt;\n    print()\n\n       I      G      S      N      W\nI  0.016 -0.119 -0.117 -0.112 -0.111\nG -0.119  0.901  0.885  0.846  0.841\nS -0.117  0.885  0.868  0.830  0.825\nN -0.112  0.846  0.830  0.794  0.789\nW -0.111  0.841  0.825  0.789  0.785\n\n\n\n\n16.8.2 Scomposizione della varianza\nConsideriamo la variabile manifesta W. Calcoliamo la varianza.\n\nvar(csq$W) |&gt; print()\n\n[1] 171.714\n\n\nLa varianza riprodotta di questa variabile, secondo il modello fattoriale, dovrebbe esere uguale alla somma di due componenti: la varianza predetta dall’effetto causale del fattore latente e la varianza residua. La varianza predetta dall’effetto causale del fattore latente è uguale alla saturazione elevata al quadrato:\n\n(-11.598)^2 \n\n134.513604\n\n\nCalcolo ora la proporzione di varianza residua normalizzando rispetto alla varianza osservata (non a quella riprodotta dal modello):\n\n1 - (-11.598)^2 / var(csq$W) \n\n0.216641572893455\n\n\nIl valore così ottenuto è molto simile al valore della varianza residua di W.\nRipeto i calcoli per la variabile G\n\n1 - (-11.322)^2 / var(csq$G) \n\n0.1003728851332\n\n\ne per la variabile I\n\n1 - (0.725)^2 / var(csq$I) \n\n0.984275494822392\n\n\nIn tutti i casi, i valori ottenuti sono molto simili alle varianze residue ipotizzate dal modello unifattoriale.\n\n\n16.8.3 Correlazione tra variabili manifeste e fattore comune\nUn modo per verificare il fatto che, nel modello unifattoriale, la saturazione fattoriale della \\(i\\)-esima variabile manifesta è uguale alla correlazione tra i punteggi osservati sulla i$-esima variabile manifesta e il fattore latente è quella di calcolare le correlazioni tra le variabili manifeste e i punteggi fattoriali. I punteggi fattoriali rappresentano una stima del punteggio “vero”, ovvero del punteggio che ciascun rispondente otterrebbe in assenza di errori di misurazione. Vedremo in seguito come si possono stimare i punteggi fattoriali. Per ora ci limitiamo a calcolarli usando lavaan.\n\nhead(lavPredict(fit)) |&gt;\n    print()\n\n              F\n[1,]  0.2693790\n[2,] -0.9110820\n[3,]  0.1871406\n[4,] -0.3315541\n[5,]  0.8306627\n[6,]  1.1534515\n\n\nAbbiamo un punteggio diverso per ciascuno dei 540 individui che appartengono al campione di dati esaminato.\n\ndim(lavPredict(fit))\n\n\n5401\n\n\nCalcoliamo ora le correlazioni tra i valori osservati su ciascuna delle cinque scale del CSQ e le stime dei punteggi veri.\n\nc(\n  cor(csq$I, lavPredict(fit)),\n  cor(csq$G, lavPredict(fit)),\n  cor(csq$S, lavPredict(fit)),\n  cor(csq$N, lavPredict(fit)),\n  cor(csq$W, lavPredict(fit))\n) |&gt; \n  round(3) |&gt;\n    print()\n\n[1]  0.128 -0.970 -0.952 -0.910 -0.905\n\n\nSi noti che i valori ottenui sono molto simili ai valori delle saturazioni fattoriali. La piccola differenza tra le correlazioni ottenute e i valori delle saturazioni fattoriali dipende dal fatto che abbiamo stimato i punteggi fattoriali.\n\ninspect(fit, what=\"std\")$lambda |&gt;\n    print()\n\n       F\nI  0.126\nG -0.949\nS -0.932\nN -0.891\nW -0.886",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/03_analisi_fattoriale_2.html#session-info",
    "href": "chapters/fa/03_analisi_fattoriale_2.html#session-info",
    "title": "16  Il modello statistico dell’analisi fattoriale",
    "section": "16.9 Session Info",
    "text": "16.9 Session Info\n\nsessionInfo()",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Il modello statistico dell'analisi fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/04_analisi_fattoriale_3.html",
    "href": "chapters/fa/04_analisi_fattoriale_3.html",
    "title": "17  Il modello multifattoriale",
    "section": "",
    "text": "17.1 Modello multifattoriale: fattori ortogonali\nLa teoria dei due fattori ha orientato per diversi anni le ricerche sull’intelligenza, finché Thurstone (1945) non propose una sua modifica, conosciuta come teoria multifattoriale. Secondo Thurstone la covariazione tra le variabili manifeste non può essere spiegata da un unico fattore generale. Invece è necessario ipotizzare l’azione causale di diversi fattori, definiti comuni, i quali si riferiscono solo ad alcune delle variabili considerate.\nIl modello plurifattoriale assume che ciascuna variabile manifesta sia espressa come funzione lineare di un certo numero \\(m\\) di fattori comuni, \\(\\xi_1, \\xi_2, \\dots, \\xi_m\\), responsabili della correlazione con le altre variabili, e di un solo fattore specifico (termine d’errore), responsabile della variabilità della variabile stessa. Per \\(p\\) variabili manifeste, \\(Y_1, Y_2, \\dots, Y_p\\), il modello fattoriale diventa quello indicato dal sistema di equazioni lineari descritto di seguito. Idealmente, \\(m\\) dovrebbe essere molto più piccolo di \\(p\\) così da consentire una descrizione parsimoniosa delle variabili manifeste in funzione di pochi fattori soggiacenti.\nLe variabili manifeste \\(Y\\) sono indicizzate da \\(i = 1, \\dots, p.\\) Le variabili latenti \\(\\xi\\) (fattori) sono indicizzate da \\(j = 1, \\dots, m.\\) I fattori specifici \\(\\delta\\) sono indicizzati da \\(i = 1, \\dots, p.\\) Le saturazioni fattoriali si distinguono dunque tramite due indici, \\(i\\) e \\(j\\): il primo indice si riferisce alle variabili manifeste, il secondo si riferisce ai fattori latenti.\nIndichiamo con \\(\\mu_i\\), con \\(i=1, \\dots, p\\) le medie delle \\(p\\) variabili manifeste \\(Y_1, Y_2, \\dots, Y_p\\). Se non vi è alcun effetto delle variabili comuni latenti, allora la variabile \\(Y_{ijk}\\), dove \\(k\\) è l’indice usato per i soggetti, sarà uguale a:\n\\[\n\\begin{equation}\n\\begin{cases}\n  Y_{1k}    &= \\mu_1 + \\delta_{1k} \\\\\n&\\vdots\\\\\nY_{ik}   &= \\mu_i + \\delta_{ik}\\\\\n&\\vdots\\\\\nY_{pk}   &= \\mu_p + \\delta_{pk} \\notag\n\\end{cases}\n\\end{equation}\n\\]\nSe invece le variabili manifeste rappresentano la somma dell’effetto causale di \\(m\\) fattori comuni e di \\(p\\) fattori specifici, allora possiamo scrivere:\n\\[\n\\begin{equation}\n\\begin{cases}\n  Y_1  - \\mu_1  &= \\lambda_{11}\\xi_1 + \\dots + \\lambda_{1k}\\xi_k \\dots +\\lambda_{1m}\\xi_m + \\delta_1 \\\\\n&\\vdots\\\\\nY_i -  \\mu_i  &= \\lambda_{i1}\\xi_1 + \\dots +  \\lambda_{ik}\\xi_k \\dots +\\lambda_{im}\\xi_m + \\delta_i\\\\\n&\\vdots\\\\\nY_p - \\mu_p  &= \\lambda_{p1}\\xi_1 + \\dots +  \\lambda_{pk}\\xi_k \\dots +\\lambda_{pm}\\xi_m + \\delta_p \\notag\n\\end{cases}\n\\end{equation}\n\\]\nNel precedente sistema di equazioni lineari,\nIn conclusione, secondo il modello multifattoriale, le variabili manifeste \\(Y_i\\), con \\(i=1, \\dots, p\\), sono il risultato di una combinazione lineare di \\(m &lt; p\\) fattori inosservabili ad esse comuni \\(\\xi_j\\), con \\(j=1, \\dots, m\\), e di \\(p\\) fattori specifici \\(\\delta_i\\), con \\(i=1, \\dots, p\\), anch’essi inosservabili e di natura residua.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Il modello multifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/04_analisi_fattoriale_3.html#modello-multifattoriale-fattori-ortogonali",
    "href": "chapters/fa/04_analisi_fattoriale_3.html#modello-multifattoriale-fattori-ortogonali",
    "title": "17  Il modello multifattoriale",
    "section": "",
    "text": "\\(\\xi_j\\), con \\(j=1, \\dots, m\\), rappresenta la \\(j\\)-esima variabile inosservabile a fattore comune (ossia il \\(j\\)-esimo fattore comune a tutte le variabili \\(Y_i\\));\n\\(\\lambda_{ij}\\) rappresenta il parametro, detto saturazione o peso fattoriale, che riflette l’importanza del \\(j\\)-esimo fattore comune nella composizione della \\(i\\)-esima variabile osservabile;\n\\(\\delta_i\\) rappresenta il fattore specifico (o unico) di ogni variabile manifesta \\(Y_i\\).\n\n\n\n17.1.1 Assunzioni del modello multifattoriale\nLe variabili inosservabili a fattore comune \\(\\xi_j\\), con \\(j=1, \\dots, m\\), in quanto latenti, non possiedono unità di misura. Pertanto, per semplicità si assume che abbiano media zero, \\(\\mathbb{E}(\\xi_j)=0\\), abbiano varianza unitaria, \\(\\mathbb{V} (\\xi_j)= \\mathbb{E}(\\xi_j^2) - [\\mathbb{E}(\\xi_j)]^2=1\\), e siano incorrelate tra loro, \\(Cov(\\xi_j, \\xi_h)=0\\), con \\(j, h = 1, \\dots, m; \\;j \\neq h\\). Si assume inoltre che le variabili a fattore specifico \\(\\delta_i\\) siano tra loro incorrelate, \\(Cov(\\delta_i,\\delta_k)=0\\), con \\(i, k = 1, \\dots, p, \\; i \\neq k\\), abbiano media zero, \\(\\mathbb{E}(\\delta_i)=0\\), e varianza uguale a \\(\\mathbb{V} (\\delta_i) = \\psi_{ii}\\). La varianza \\(\\psi_{ii}\\) è detta varianza specifica o unicità della \\(i\\)-esima variabile manifesta \\(Y_i\\). Si assume infine che i fattori specifici siano linearmente incorrelati con i fattori comuni, ovvero \\(Cov(\\xi_j, \\delta_i)=0\\) per ogni \\(j=1, \\dots, m\\) e per ogni \\(i=1\\dots,p\\).\n\n\n17.1.2 Interpretazione dei parametri del modello\n\n17.1.2.1 Covarianza tra variabili e fattori\nNell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la covarianza tra \\(Y_i\\) e \\(\\xi_j\\) è uguale alla saturazione fattoriale \\(\\lambda_{ij}\\):\n\\[\n\\begin{equation}\n\\begin{aligned}\n  Cov(Y_i, \\xi_j) &= \\mathbb{E}(Y_i \\xi_j)\\notag\\\\\n  &=\\mathbb{E}\\left[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)\\xi_j \\right]\\notag\\\\\n  &= \\lambda_{i1}\\underbrace{\\mathbb{E}(\\xi_1\\xi_j)}_{=0} + \\dots +\n\\lambda_{ij}\\underbrace{\\mathbb{E}(\\xi_j^2)}_{=1} + \\dots \\notag\\\\\n& \\; + \\lambda_{im}\\underbrace{\\mathbb{E}(\\xi_m\\xi_j)}_{=0} +\n  \\underbrace{\\mathbb{E}(\\delta_i \\xi_j)}_{=0}\\notag\\\\\n  &= \\lambda_{ij}.\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nAnche nel modello multifattoriale, dunque, le saturazioni fattoriali rappresentano le covarianze tra le variabili e i fattori:\n\\[\nCov(Y_i, \\xi_j) = \\lambda_{ij} \\qquad i=1, \\dots, p; \\quad j= 1, \\dots, m.\n\\]\nNaturalmente, se le variabili sono standardizzate, le saturazioni fattoriali diventano correlazioni:\n\\[\nr_{ij} = \\lambda_{ij}.\n\\]\n\n\n17.1.2.2 Espressione fattoriale della varianza\nCome nel modello monofattoriale, la varianza delle variabili manifeste si decompone in una componente dovuta ai fattori comuni, chiamata comunalità, e in una componente specifica alle \\(Y_i\\), chiamata unicità. Nell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la varianza di \\(Y_i\\) è uguale a\n\\[\n\\begin{equation}\n\\begin{aligned}\n  \\mathbb{V} (Y_i)\n  &=\\mathbb{E}\\left[ (\\lambda_{i1} \\xi_1 + \\dots +\n    \\lambda_{im} \\xi_m + \\delta_i)^2 \\right].\n\\end{aligned}\n\\end{equation}\n\\](eq-eq-var-multifatt)\nCome si sviluppa il polinomio precedente? Il quadrato di un polinomio è uguale alla somma dei quadrati di tutti i termini più il doppio prodotto di ogni termine per ciascuno di quelli che lo seguono. Il valore atteso del quadrato del primo termine è uguale a \\(\\lambda_{i1}^2\\mathbb{E}(\\xi_1^2)\\) ma, essendo la varianza di \\(\\xi_1\\) uguale a \\(1\\), otteniamo semplicemente \\(\\lambda_{i1}^2\\). Lo stesso vale per i quadrati di tutti i termini seguenti tranne l’ultimo. Infatti, \\(\\mathbb{E}(\\delta_i^2)=\\psi_{ii}\\). Per quel che riguarda i doppi prodotti, sono tutti nulli. In primo luogo perché, nel caso di fattori ortogonali, la covarianza tra i fattori comuni è nulla, \\(\\mathbb{E}(\\xi_j \\xi_h)=0\\), con \\(j \\neq h\\). In secondo luogo perché il fattori comuni cono incorrelati con i fattori specifici, quindi \\(\\mathbb{E}(\\delta_i \\xi_j)=0\\).\nIn conclusione,\n\\[\n\\begin{equation}\n\\begin{aligned}\n  \\mathbb{V}(Y_i) &= \\lambda_{i1}^2 + \\lambda_{i2}^2 + \\dots + \\lambda_{im}^2 + \\psi_{ii} \\notag\\\\\n  &= \\sum_{j=1}^m \\lambda_{ij}^2 + \\psi_{ii}\\notag\\\\\n  &= h_i^2 + \\psi_{ii}\\notag\\\\\n  &=\\text{communalità} + \\text{unicità},\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nla varianza della variabile manifesta \\(Y_i\\) è suddivisa in due parti: il primo addendo è definito comunalità poiché rappresenta la parte di variabilità della \\(Y_i\\) spiegata dai fattori comuni; il secondo addendo è invece definito varianza specifica (o unicità) poiché esprime la parte di variabilità della \\(Y_i\\) non spiegata dai fattori comuni.\n\n\n17.1.2.3 Espressione fattoriale della covarianza\nQuale esempio, consideriamo il caso di \\(p=5\\) variabili osservabili e \\(m=2\\) fattori ortogonali. Se le variabili manifeste sono ‘centrate’ (ovvero, se a ciascuna di esse sottraiamo la rispettiva media), allora il modello multifattoriale diventa\n\\[\n\\begin{equation}\n\\begin{aligned}\n  Y_1 &= \\lambda_{11} \\xi_1 + \\lambda_{12} \\xi_2 + \\delta_1,\\notag\\\\\n  Y_2 &= \\lambda_{21} \\xi_1 + \\lambda_{22} \\xi_2 + \\delta_2,\\notag\\\\\n  Y_3 &= \\lambda_{31} \\xi_1 + \\lambda_{32} \\xi_2 + \\delta_3,\\notag\\\\\n  Y_4 &= \\lambda_{41} \\xi_1 + \\lambda_{42} \\xi_2 + \\delta_4,\\notag\\\\\n  Y_5 &= \\lambda_{51} \\xi_1 + \\lambda_{52} \\xi_2 + \\delta_5.\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nNell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la covarianza tra \\(Y_1\\) e \\(Y_2\\), ad esempio, è uguale a:\n$$ \\[\\begin{equation}\n\\begin{aligned}\n  Cov(Y_1, Y_2) &= \\mathbb{E}\\left( Y_1 Y_2\\right) \\notag\\\\\n  &= \\mathbb{E}\\left[\n  (\\lambda_{11} \\xi_1 + \\lambda_{12} \\xi_2 + \\delta_1)\n   (\\lambda_{21} \\xi_1 + \\lambda_{22} \\xi_2 +  \\delta_2)\n  \\right]\\notag\\\\\n  &= \\lambda_{11} \\lambda_{21} \\mathbb{E}(\\xi_1^2) +\n      \\lambda_{11} \\lambda_{22} \\mathbb{E}(\\xi_1 \\xi_2) +\\notag\n      \\lambda_{11} \\mathbb{E}(\\xi_1 \\delta_2) +\\notag\\\\\n    &\\quad \\lambda_{12} \\lambda_{21}\\mathbb{E}(\\xi_1 \\xi_2)\\, +\n      \\lambda_{12} \\lambda_{22}\\mathbb{E}(\\xi^2_2)\\, +\n      \\lambda_{12} \\mathbb{E}(\\xi_2\\delta_2) +\\notag\\\\\n    &\\quad \\lambda_{21} \\mathbb{E}(\\xi_1\\delta_1) +\\notag\n     \\lambda_{22} \\mathbb{E}(\\xi_2\\delta_1) + \\mathbb{E}(\\delta_1 \\delta_2)\\notag\\\\\n   &= \\lambda_{11} \\lambda_{21} + \\lambda_{12} \\lambda_{22}.\\notag\n\\end{aligned}\n\\end{equation}\\]\n$$ In conclusione, la covarianza tra le variabili manifeste \\(Y_l\\) e \\(Y_m\\) riprodotta dal modello è data dalla somma dei prodotti delle saturazioni \\(\\lambda_l \\lambda_m\\) nei due fattori.\nEsempio. Consideriamo i dati riportati da {cite:t}brown2015confirmatory, ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti:\n\nanxiety (N1),\nhostility (N2),\ndepression (N3),\nself-consciousness (N4),\nwarmth (E1),\ngregariousness (E2),\nassertiveness (E3),\npositive emotions (E4).\n\n\nvarnames &lt;- c(\"N1\", \"N2\", \"N3\", \"N4\", \"E1\", \"E2\", \"E3\", \"E4\")\nsds &lt;- '5.7  5.6  6.4  5.7  6.0  6.2  5.7  5.6'\n\ncors &lt;- '\n 1.000\n 0.767  1.000 \n 0.731  0.709  1.000 \n 0.778  0.738  0.762  1.000 \n-0.351  -0.302  -0.356  -0.318  1.000 \n-0.316  -0.280  -0.300  -0.267  0.675  1.000 \n-0.296  -0.289  -0.297  -0.296  0.634  0.651  1.000 \n-0.282  -0.254  -0.292  -0.245  0.534  0.593  0.566  1.000'\n\npsychot_cor_mat &lt;- getCov(cors, names = varnames)\nn &lt;- 250\n\nEseguiamo l’analisi fattoriale esplorativa con il metodo della massima verosimiglianza ipotizzando due fattori comuni incorrelati:\n\nn_facs &lt;- 2\nfit_efa &lt;- factanal(\n  covmat = psychot_cor_mat,\n  factors = n_facs,\n  rotation = \"varimax\",\n  n.obs = n\n)\n\nEsaminiamo le saturazioni fattoriali:\n\nlambda &lt;- fit_efa$loadings\nprint(lambda)\n\n\nLoadings:\n   Factor1 Factor2\nN1  0.854  -0.228 \nN2  0.826  -0.194 \nN3  0.811  -0.233 \nN4  0.865  -0.186 \nE1 -0.202   0.773 \nE2 -0.139   0.829 \nE3 -0.158   0.771 \nE4 -0.147   0.684 \n\n               Factor1 Factor2\nSS loadings      2.923   2.526\nProportion Var   0.365   0.316\nCumulative Var   0.365   0.681\n\n\nLa soluzione fattoriale conferma la presenza di due fattori: il primo fattore satura sulle scale di neutoricismo, il secono sulle scale di estroversione.\nLa correlazione riprodotta \\(r_{12}\\) è uguale a \\(\\lambda_{11}\\lambda_{21} + \\lambda_{12}\\lambda_{22}\\)\n\nlambda[1, 1] * lambda[2, 1] + lambda[1, 2] * lambda[2, 2]\n\n0.74928439937518\n\n\ne corrisponde da vicino alla correlazione osservata 0.767.\nL’intera matrice di correlazioni riprodotte è \\(\\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\psi}\\):\n\nRr &lt;- lambda %*% t(lambda) + diag(fit_efa$uniq)\nRr %&gt;% \n  round(3)\n\n\nA matrix: 8 × 8 of type dbl\n\n\n\nN1\nN2\nN3\nN4\nE1\nE2\nE3\nE4\n\n\n\n\nN1\n1.000\n0.749\n0.745\n0.781\n-0.348\n-0.307\n-0.311\n-0.281\n\n\nN2\n0.749\n1.000\n0.715\n0.751\n-0.317\n-0.276\n-0.281\n-0.254\n\n\nN3\n0.745\n0.715\n1.000\n0.745\n-0.344\n-0.306\n-0.308\n-0.279\n\n\nN4\n0.781\n0.751\n0.745\n1.000\n-0.318\n-0.274\n-0.280\n-0.254\n\n\nE1\n-0.348\n-0.317\n-0.344\n-0.318\n1.000\n0.669\n0.628\n0.558\n\n\nE2\n-0.307\n-0.276\n-0.306\n-0.274\n0.669\n1.000\n0.661\n0.587\n\n\nE3\n-0.311\n-0.281\n-0.308\n-0.280\n0.628\n0.661\n1.000\n0.550\n\n\nE4\n-0.281\n-0.254\n-0.279\n-0.254\n0.558\n0.587\n0.550\n1.000\n\n\n\n\n\nLa differenza tra la matrice di correlazioni riprodotte e la matrice di correlazioni osservate è uguale a:\n\n(psychot_cor_mat - Rr) %&gt;% \n  round(3)\n\n\nA matrix: 8 × 8 of type dbl\n\n\n\nN1\nN2\nN3\nN4\nE1\nE2\nE3\nE4\n\n\n\n\nN1\n0.000\n0.018\n-0.014\n-0.003\n-0.003\n-0.009\n0.015\n-0.001\n\n\nN2\n0.018\n0.000\n-0.006\n-0.013\n0.015\n-0.004\n-0.008\n0.000\n\n\nN3\n-0.014\n-0.006\n0.000\n0.017\n-0.012\n0.006\n0.011\n-0.013\n\n\nN4\n-0.003\n-0.013\n0.017\n0.000\n0.000\n0.007\n-0.016\n0.009\n\n\nE1\n-0.003\n0.015\n-0.012\n0.000\n0.000\n0.006\n0.006\n-0.024\n\n\nE2\n-0.009\n-0.004\n0.006\n0.007\n0.006\n0.000\n-0.010\n0.006\n\n\nE3\n0.015\n-0.008\n0.011\n-0.016\n0.006\n-0.010\n0.000\n0.016\n\n\nE4\n-0.001\n0.000\n-0.013\n0.009\n-0.024\n0.006\n0.016\n0.000",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Il modello multifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/04_analisi_fattoriale_3.html#modello-fattoriale-fattori-obliqui",
    "href": "chapters/fa/04_analisi_fattoriale_3.html#modello-fattoriale-fattori-obliqui",
    "title": "17  Il modello multifattoriale",
    "section": "17.2 Modello fattoriale: Fattori obliqui",
    "text": "17.2 Modello fattoriale: Fattori obliqui\nAnche nel caso di fattori comuni correlati è possibile esprimere nei termini dei parametri del modello la covarianza teorica tra una variabile manifesta \\(Y_i\\) e uno dei fattori comuni, la covarianza teorica tra due variabili manifeste, e la comunalità di ciascuna variabile manifesta. Dato però che i fattori comuni risultano correlati, l’espressione fattoriale di tali quantità è più complessa che nel caso di fattori comuni ortogonali.\n\n17.2.1 Covarianza teorica tra variabili e fattori\nIn base al modello multifattoriale con \\(m\\) fattori comuni la variabile \\(Y_i\\) è\n\\[\nY_i = \\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i.\n(\\#eq:mod-multifact)\n\\]\nPoniamoci il problema di trovare la covarianza teorica tra la variabile manifesta \\(Y_i\\) e il fattore comune \\(\\xi_j\\). Come in precedenza, il problema si riduce a quello di trovare \\(\\mathbb{E}(Y_i \\xi_j)\\). Ne segue che\n\\[\n\\begin{equation}\n\\begin{aligned}\n  Cov(Y_i, \\xi_j) &= \\mathbb{E}(Y_i \\xi_j)\\notag\\\\\n  &=\\mathbb{E}\\left[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{ij} \\xi_j + \\dots + \\lambda_{im} \\xi_m + \\delta_i)\\xi_j \\right]\\notag\\\\\n  &= \\lambda_{i1}\\underbrace{\\mathbb{E}(\\xi_1\\xi_j)}_{\\neq 0} + \\dots + \\lambda_{ij}\\underbrace{\\mathbb{E}(\\xi_j^2)}_{=1} + \\dots \\notag\\\\\n& \\quad + \\lambda_{im}\\underbrace{\\mathbb{E}(\\xi_m\\xi_j)}_{\\neq 0} + \\underbrace{\\mathbb{E}(\\delta_i \\xi_j)}_{=0}\\notag\\\\\n  &= \\lambda_{ij} + \\lambda_{i1} Cov(\\xi_1, \\xi_j) + \\dots + \\lambda_{im} Cov(\\xi_m, \\xi_j).\n\\end{aligned}\n\\end{equation}\n\\]\nAd esempio, nel caso di tre fattori comuni \\(\\xi_1, \\xi_2, \\xi_3\\), la covarianza tra \\(Y_1\\) e \\(\\xi_{1}\\) diventa\n\\[\n\\lambda_{11} + \\lambda_{12}Cov(\\xi_1, \\xi_2) + \\lambda_{13}Cov(\\xi_1, \\xi_3).\n\\]\n\n\n17.2.2 Espressione fattoriale della varianza\nPoniamoci ora il problema di trovare la varianza teorica della variabile manifesta \\(Y_i\\). In base al modello fattoriale, la variabile \\(Y_i\\) è specificata come nella @ref(eq:mod-multifact). La varianza di \\(Y_i\\) è \\(\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) -[\\mathbb{E}(Y_i)]^2\\). Però, avendo espresso \\(Y_i\\) nei termini della differenza dalla sua media, l’espressione della varianza si riduce a \\(\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2)\\). Dobbiamo dunque sviluppare l’espressione\n\\[\n\\mathbb{E}(Y_i^2) = \\mathbb{E}[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)^2].\n\\]\nIn conclusione, la varianza teorica di \\(Y_i\\) è uguale a\n\\[\n\\begin{equation}\n\\begin{split}\n\\mathbb{V}(Y_i) &= \\lambda_{i1}^2 + \\lambda_{i2}^2 + \\dots + \\lambda_{im}^2  + \\\\\n&\\quad 2 \\lambda_{i1} \\lambda_{i2} Cov(\\xi_1, \\xi_2) + \\dots + 2 \\lambda_{i,m-1} \\lambda_{im} Cov(\\xi_{m-1}, \\xi_m) + \\\\\n&\\quad \\psi_{ii}.\\notag\n\\end{split}\n\\end{equation}\n\\]\nAd esempio, nel caso di tre fattori comuni, \\(\\xi_1, \\xi_2, \\xi_3\\), la varianza di \\(Y_1\\) è\n\\[\n\\begin{equation}\n\\begin{split}\n\\mathbb{V}(Y_1) = &\\lambda_{11}^2 + \\lambda_{12}^2 + \\lambda_{13}^2 +\\\\\n&\\quad 2 \\lambda_{11} \\lambda_{12} Cov(\\xi_1, \\xi_2) + \\\\\n&\\quad 2 \\lambda_{11} \\lambda_{13} Cov(\\xi_1, \\xi_3) + \\\\\n&\\quad 2 \\lambda_{12} \\lambda_{13} Cov(\\xi_2, \\xi_3) + \\\\\n&\\quad \\psi_{11}. \\notag\n\\end{split}\n\\end{equation}\n\\]\n\n\n17.2.3 Covarianza teorica tra due variabili\nConsideriamo ora il caso più semplice di due soli fattori comuni correlati e calcoliamo la covarianza tra \\(Y_1\\) e \\(Y_2\\):\n\\[\n\\begin{equation}\n\\begin{aligned}\n\\mathbb{E}(Y_1 Y_2) =\\mathbb{E}[(&\\lambda_{11}\\xi_1 + \\lambda_{12}\\xi_2+\\delta_1) (\\lambda_{21}\\xi_1 + \\lambda_{22}\\xi_2+\\delta_2)]\\notag\\\\\n=\\mathbb{E}(\n&\\lambda_{11}\\lambda_{21}\\xi_1^2 +\n\\lambda_{11}\\lambda_{22}\\xi_1\\xi_2 +\n\\lambda_{11}\\xi_1\\delta_2 +\\notag\\\\\n+&\\lambda_{12}\\lambda_{21}\\xi_1\\xi_2 +\n\\lambda_{12}\\lambda_{22}\\xi_2^2 +\n\\lambda_{12}\\xi_2\\delta_2 +\\notag\\\\\n+&\\lambda_{21}\\xi_1\\delta_1 +\n\\lambda_{22}\\xi_2\\delta_1 +\n\\delta_1\\delta_2).\\notag\n\\end{aligned}\n\\end{equation}\n\\]\nDistribuendo l’operatore di valore atteso, dato che \\(\\mathbb{E}(\\xi^2)=1\\) e \\(\\mathbb{E}(\\xi \\delta)=0\\), otteniamo\n\\[\nCov(Y_1, Y_2) = \\lambda_{11} \\lambda_{21} + \\lambda_{12} \\lambda_{22} +\n\\lambda_{12} \\lambda_{21}Cov(\\xi_1, \\xi_2) +\\lambda_{11} \\lambda_{22}Cov(\\xi_1, \\xi_2).\n\\]\nIn termini matriciali si scrive\n\\[\n\\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi},\n\\]\ndove \\(\\boldsymbol{\\Phi}\\) è la matrice di ordine \\(m \\times m\\) di varianze e covarianze tra i fattori comuni e \\(\\boldsymbol{\\Psi}\\) è una matrice diagonale di ordine \\(p\\) con le unicità delle variabili.\nEsempio. Consideriamo nuovamente i dati esaminati negli esercizi precedenti, ma questa volta il modello consente una correlazione tra i due fattori comuni:\n\nefa_result &lt;- fa(psychot_cor_mat, nfactors = 2, n.obs = n, rotate = \"oblimin\")\nprint(efa_result)\n\nLoading required namespace: GPArotation\n\n\n\nFactor Analysis using method =  minres\nCall: fa(r = psychot_cor_mat, nfactors = 2, n.obs = n, rotate = \"oblimin\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n     MR1   MR2   h2   u2 com\nN1  0.88 -0.02 0.78 0.22   1\nN2  0.85  0.01 0.72 0.28   1\nN3  0.83 -0.04 0.71 0.29   1\nN4  0.90  0.03 0.78 0.22   1\nE1 -0.05  0.77 0.63 0.37   1\nE2  0.03  0.86 0.71 0.29   1\nE3  0.00  0.79 0.63 0.37   1\nE4 -0.01  0.70 0.49 0.51   1\n\n                       MR1  MR2\nSS loadings           3.00 2.45\nProportion Var        0.37 0.31\nCumulative Var        0.37 0.68\nProportion Explained  0.55 0.45\nCumulative Proportion 0.55 1.00\n\n With factor correlations of \n      MR1   MR2\nMR1  1.00 -0.43\nMR2 -0.43  1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  28  with the objective function =  5.02 with Chi Square =  1231.22\ndf of  the model are 13  and the objective function was  0.04 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  250 with the empirical chi square  1.73  with prob &lt;  1 \nThe total n.obs was  250  with Likelihood Chi Square =  9.65  with prob &lt;  0.72 \n\nTucker Lewis Index of factoring reliability =  1.006\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.047\nBIC =  -62.12\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   MR1  MR2\nCorrelation of (regression) scores with factors   0.96 0.94\nMultiple R square of scores with factors          0.93 0.87\nMinimum correlation of possible factor scores     0.85 0.75\n\n\n\nfa.diagram(efa_result)\n\n\n\n\n\n\n\n\nEsaminiamo la matrice delle correlazioni residue:\n\nresiduals &lt;- residuals(efa_result)\nprint(residuals)\n\n   N1    N2    N3    N4    E1    E2    E3    E4   \nN1  0.22                                          \nN2  0.02  0.28                                    \nN3 -0.01  0.00  0.29                              \nN4  0.00 -0.01  0.02  0.22                        \nE1  0.00  0.01 -0.01  0.00  0.37                  \nE2 -0.01  0.00  0.01  0.01  0.01  0.29            \nE3  0.01 -0.01  0.01 -0.02  0.01 -0.01  0.37      \nE4  0.00  0.00 -0.01  0.01 -0.02  0.01  0.01  0.51\n\n\nEsaminiamo più da vicino la matrice di correlazioni riprodotta dal modello, nel caso di fattori obliqui. Le saturazioni fattoriali sono:\n\n# Estrai i carichi fattoriali (saturazioni fattoriali)\nlambda &lt;- efa_result$loadings\n\n# Converti i carichi in una matrice 8 x 2 (assumendo 2 fattori)\n# e assegna i nomi appropriati alle righe e alle colonne\nlambda &lt;- matrix(lambda[, 1:2], nrow = 8, ncol = 2)\nrownames(lambda) &lt;- c(\"N1\", \"N2\", \"N3\", \"N4\", \"E1\", \"E2\", \"E3\", \"E4\")\ncolnames(lambda) &lt;- c(\"Factor1\", \"Factor2\")\n\n# Stampa la matrice dei carichi\nprint(lambda)\n\n        Factor1     Factor2\nN1  0.877075569 -0.01577815\nN2  0.852280802  0.01128419\nN3  0.826584447 -0.03684789\nN4  0.898762806  0.03121279\nE1 -0.048589010  0.77186847\nE2  0.034700239  0.85566012\nE3  0.002815265  0.79291602\nE4 -0.007884591  0.69545191\n\n\nLa matrice di intercorrelazoni fattoriali è\n\n# Estrai la matrice delle intercorrelazioni fattoriali\nPhi &lt;- efa_result$Phi\n\n# Stampa la matrice delle intercorrelazioni\nprint(Phi)\n\n           MR1        MR2\nMR1  1.0000000 -0.4313609\nMR2 -0.4313609  1.0000000\n\n\nLe varianze residue sono:\n\n# Estrai le varianze residue\nPsi &lt;- diag(efa_result$uniquenesses)\n\n# Stampa le varianze residue\nprint(Psi)\n\n          [,1]      [,2]      [,3]     [,4]      [,5]      [,6]      [,7]\n[1,] 0.2185506 0.0000000 0.0000000 0.000000 0.0000000 0.0000000 0.0000000\n[2,] 0.0000000 0.2817872 0.0000000 0.000000 0.0000000 0.0000000 0.0000000\n[3,] 0.0000000 0.0000000 0.2891237 0.000000 0.0000000 0.0000000 0.0000000\n[4,] 0.0000000 0.0000000 0.0000000 0.215453 0.0000000 0.0000000 0.0000000\n[5,] 0.0000000 0.0000000 0.0000000 0.000000 0.3695024 0.0000000 0.0000000\n[6,] 0.0000000 0.0000000 0.0000000 0.000000 0.0000000 0.2922572 0.0000000\n[7,] 0.0000000 0.0000000 0.0000000 0.000000 0.0000000 0.0000000 0.3732021\n[8,] 0.0000000 0.0000000 0.0000000 0.000000 0.0000000 0.0000000 0.0000000\n          [,8]\n[1,] 0.0000000\n[2,] 0.0000000\n[3,] 0.0000000\n[4,] 0.0000000\n[5,] 0.0000000\n[6,] 0.0000000\n[7,] 0.0000000\n[8,] 0.5115539\n\n\nMediante i parametri del modello la matrice di correlazione si riproduce nel modo seguente:\n\\[\n\\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi}.\n\\]\nIn \\(\\textsf{R}\\) scriviamo:\n\nR_hat &lt;- lambda %*% Phi %*% t(lambda) + Psi\nR_hat %&gt;% \n  round(3)\n\n\nA matrix: 8 x 8 of type dbl\n\n\n\nN1\nN2\nN3\nN4\nE1\nE2\nE3\nE4\n\n\n\n\nN1\n1.000\n0.749\n0.745\n0.782\n-0.347\n-0.307\n-0.310\n-0.281\n\n\nN2\n0.749\n1.000\n0.714\n0.751\n-0.316\n-0.276\n-0.280\n-0.255\n\n\nN3\n0.745\n0.714\n1.000\n0.745\n-0.345\n-0.307\n-0.310\n-0.280\n\n\nN4\n0.782\n0.751\n0.745\n1.000\n-0.318\n-0.274\n-0.280\n-0.255\n\n\nE1\n-0.347\n-0.316\n-0.345\n-0.318\n1.000\n0.665\n0.628\n0.554\n\n\nE2\n-0.307\n-0.276\n-0.307\n-0.274\n0.665\n1.000\n0.666\n0.587\n\n\nE3\n-0.310\n-0.280\n-0.310\n-0.280\n0.628\n0.666\n1.000\n0.553\n\n\nE4\n-0.281\n-0.255\n-0.280\n-0.255\n0.554\n0.587\n0.553\n1.000\n\n\n\n\n\nLe correlazioni residue sono:\n\n(psychot_cor_mat - R_hat) %&gt;% \n  round(3)\n\n\nA matrix: 8 x 8 of type dbl\n\n\n\nN1\nN2\nN3\nN4\nE1\nE2\nE3\nE4\n\n\n\n\nN1\n0.000\n0.018\n-0.014\n-0.004\n-0.004\n-0.009\n0.014\n-0.001\n\n\nN2\n0.018\n0.000\n-0.005\n-0.013\n0.014\n-0.004\n-0.009\n0.001\n\n\nN3\n-0.014\n-0.005\n0.000\n0.017\n-0.011\n0.007\n0.013\n-0.012\n\n\nN4\n-0.004\n-0.013\n0.017\n0.000\n0.000\n0.007\n-0.016\n0.010\n\n\nE1\n-0.004\n0.014\n-0.011\n0.000\n0.000\n0.010\n0.006\n-0.020\n\n\nE2\n-0.009\n-0.004\n0.007\n0.007\n0.010\n0.000\n-0.015\n0.006\n\n\nE3\n0.014\n-0.009\n0.013\n-0.016\n0.006\n-0.015\n0.000\n0.013\n\n\nE4\n-0.001\n0.001\n-0.012\n0.010\n-0.020\n0.006\n0.013\n0.000\n\n\n\n\n\nPer fare un esempio relativo alla correlazione tra due indicatori, calcoliamo la correlazione predetta dal modello tra le variabili \\(Y_1\\) e \\(Y_2\\):\n\nlambda[1, 1] * lambda[2, 1] + lambda[1, 2] * lambda[2, 2] +\n  lambda[1, 1] * lambda[2, 2] * Phi[1, 2] + \n  lambda[1, 2] * lambda[2, 1] * Phi[1, 2]\n\n0.748868098259331\n\n\nQuesto valore si avvicina al valore contenuto dell’elemento (1, 2) della matrice di correlazioni osservate:\n\npsychot_cor_mat[1, 2]\n\n0.767\n\n\nUsando questa procedura possiamo riprodurre tutti gli elementi della matrice di correlazione osservata tramite i parametri stimati dal modello EFA replicando così il risultato che si trova con $ = ^{} + . $",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Il modello multifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/04_analisi_fattoriale_3.html#session-info",
    "href": "chapters/fa/04_analisi_fattoriale_3.html#session-info",
    "title": "17  Il modello multifattoriale",
    "section": "17.3 Session Info",
    "text": "17.3 Session Info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.34   IRdisplay_1.1   utf8_1.2.4      base64enc_0.1-3\n [5] fastmap_1.1.1   glue_1.7.0      htmltools_0.5.7 repr_1.1.6     \n [9] lifecycle_1.0.4 cli_3.6.2       fansi_1.0.6     vctrs_0.6.5    \n[13] pbdZMQ_0.3-11   compiler_4.3.2  tools_4.3.2     evaluate_0.23  \n[17] pillar_1.9.0    crayon_1.5.2    rlang_1.1.3     jsonlite_1.8.8 \n[21] IRkernel_1.3.2  uuid_1.2-0",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Il modello multifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/04_analisi_fattoriale_3.html#session-info-1",
    "href": "chapters/fa/04_analisi_fattoriale_3.html#session-info-1",
    "title": "17  Il modello multifattoriale",
    "section": "17.4 Session Info",
    "text": "17.4 Session Info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidySEM_0.2.4      OpenMx_2.21.8      corrplot_0.92      kableExtra_1.3.4  \n [5] ggokabeito_0.1.0   viridis_0.6.4      viridisLite_0.4.2  ggpubr_0.6.0      \n [9] ggExtra_0.10.1     bayesplot_1.10.0   gridExtra_2.3      patchwork_1.1.3   \n[13] semTools_0.5-6.920 semPlot_1.1.6      lavaan_0.6-16      psych_2.3.6       \n[17] scales_1.2.1       markdown_1.8       knitr_1.44         lubridate_1.9.2   \n[21] forcats_1.0.0      stringr_1.5.0      dplyr_1.1.3        purrr_1.0.2       \n[25] readr_2.1.4        tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.3     \n[29] tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] splines_4.3.1         later_1.3.1           pbdZMQ_0.3-10        \n  [4] XML_3.99-0.14         rpart_4.1.19          fastDummies_1.7.3    \n  [7] lifecycle_1.0.3       rstatix_0.7.2         StanHeaders_2.26.28  \n [10] rprojroot_2.0.3       globals_0.16.2        processx_3.8.2       \n [13] lattice_0.21-8        MASS_7.3-60           rockchalk_1.8.157    \n [16] backports_1.4.1       magrittr_2.0.3        openxlsx_4.2.5.2     \n [19] Hmisc_5.1-1           rmarkdown_2.24        httpuv_1.6.11        \n [22] tmvnsim_1.0-2         qgraph_1.9.5          zip_2.3.0            \n [25] pkgbuild_1.4.2        pbapply_1.7-2         minqa_1.2.6          \n [28] multcomp_1.4-25       abind_1.4-5           rvest_1.0.3          \n [31] quadprog_1.5-8        nnet_7.3-19           TH.data_1.1-2        \n [34] sandwich_3.0-2        inline_0.3.19         listenv_0.9.0        \n [37] arm_1.13-1            proto_1.0.0           parallelly_1.36.0    \n [40] texreg_1.38.6         svglite_2.1.1         codetools_0.2-19     \n [43] xml2_1.3.5            tidyselect_1.2.0      lme4_1.1-34          \n [46] matrixStats_1.0.0     stats4_4.3.1          base64enc_0.1-3      \n [49] webshot_0.5.5         jsonlite_1.8.7        progressr_0.14.0     \n [52] ellipsis_0.3.2        Formula_1.2-5         survival_3.5-7       \n [55] emmeans_1.8.8         systemfonts_1.0.4     dbscan_1.1-11        \n [58] tools_4.3.1           Rcpp_1.0.11           glue_1.6.2           \n [61] mnormt_2.1.1          xfun_0.40             MplusAutomation_1.1.0\n [64] IRdisplay_1.1         loo_2.6.0             withr_2.5.0          \n [67] fastmap_1.1.1         boot_1.3-28.1         fansi_1.0.4          \n [70] callr_3.7.3           digest_0.6.33         mi_1.1               \n [73] timechange_0.2.0      R6_2.5.1              mime_0.12            \n [76] estimability_1.4.1    colorspace_2.1-0      gtools_3.9.4         \n [79] jpeg_0.1-10           utf8_1.2.3            generics_0.1.3       \n [82] data.table_1.14.8     corpcor_1.6.10        prettyunits_1.1.1    \n [85] httr_1.4.7            htmlwidgets_1.6.2     pkgconfig_2.0.3      \n [88] sem_3.1-15            gtable_0.3.4          bain_0.2.9           \n [91] htmltools_0.5.6       carData_3.0-5         blavaan_0.5-1        \n [94] png_0.1-8             rstudioapi_0.15.0     tzdb_0.4.0           \n [97] reshape2_1.4.4        uuid_1.1-1            coda_0.19-4          \n[100] checkmate_2.2.0       nlme_3.1-163          nloptr_2.0.3         \n[103] repr_1.1.6            zoo_1.8-12            parallel_4.3.1       \n[106] miniUI_0.1.1.1        nonnest2_0.5-6        foreign_0.8-85       \n[109] pillar_1.9.0          grid_4.3.1            vctrs_0.6.3          \n[112] RANN_2.6.1            promises_1.2.1        car_3.1-2            \n[115] xtable_1.8-4          cluster_2.1.4         GPArotation_2023.8-1 \n[118] htmlTable_2.4.1       evaluate_0.21         pbivnorm_0.6.0       \n[121] gsubfn_0.7            mvtnorm_1.2-3         cli_3.6.1            \n[124] kutils_1.72           compiler_4.3.1        rlang_1.1.1          \n[127] crayon_1.5.2          rstantools_2.3.1.1    future.apply_1.11.0  \n[130] ggsignif_0.6.4        fdrtool_1.2.17        ps_1.7.5             \n[133] plyr_1.8.8            rstan_2.26.23         stringi_1.7.12       \n[136] pander_0.6.5          QuickJSR_1.0.6        munsell_0.5.0        \n[139] CompQuadForm_1.4.3    lisrelToR_0.1.5       Matrix_1.6-1         \n[142] IRkernel_1.3.2        hms_1.1.3             glasso_1.11          \n[145] future_1.33.0         shiny_1.7.5           igraph_1.5.1         \n[148] broom_1.0.5           RcppParallel_5.1.7",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Il modello multifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/05_factor_scores.html",
    "href": "chapters/fa/05_factor_scores.html",
    "title": "18  I punteggi fattoriali",
    "section": "",
    "text": "18.0.1 Esempio di interpretazione\nIl WISC-III (Wechsler Intelligence Scale For Children - III) valuta l’abilità intellettiva di soggetti dai 6 ai 16 anni e 11 mesi. I subtest sono stati selezionati per valutare diverse abilità mentali, che tutte insieme indicano l’abilità intellettiva generale del bambino. Alcuni gli richiedono un ragionamento astratto, altri si focalizzano sulla memoria, altri ancora richiedono certe abilità percettive e così via.\nSi consideri la matrice di correlazione tra i subtest della scala WISC-III riportata dal manuale.\nlower &lt;- '\n1\n.66      1\n.57 .55      1\n.70 .69 .54       1\n.56 .59 .47 .64      1\n.34 .34 .43 .35 .29      1\n.47 .45 .39 .45 .38 .25      1\n.21 .20 .27 .26 .25 .23 .18      1\n.40 .39 .35 .40 .35 .20 .37 .28      1\n.48 .49 .52 .46 .40 .32 .52 .27 .41      1\n.41 .42 .39 .41 .34 .26 .49 .24 .37 .61      1\n.35 .35 .41 .35 .34 .28 .33 .53 .36 .45 .38      1\n.18 .18 .22 .17 .17 .14 .24 .15 .23 .31 .29 .24     1\n'\nwisc_III_cov &lt;- getCov(\n  lower,\n  names = c(\n    \"INFO\", \"SIM\", \"ARITH\", \"VOC\", \"COMP\", \"DIGIT\", \"PICTCOM\",\n    \"CODING\", \"PICTARG\", \"BLOCK\", \"OBJECT\", \"SYMBOL\", \"MAZES\"\n  )\n)\nEseguiamo l’analisi fattoriale con il metodo delle componenti principali e una rotazione Varimax:\nf_pc &lt;- psych::principal(wisc_III_cov, nfactors = 3, rotate = \"varimax\")\nprint(f_pc)\n\nPrincipal Components Analysis\nCall: psych::principal(r = wisc_III_cov, nfactors = 3, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n          RC1  RC3  RC2   h2   u2 com\nINFO     0.80 0.25 0.09 0.72 0.28 1.2\nSIM      0.81 0.25 0.08 0.72 0.28 1.2\nARITH    0.65 0.26 0.28 0.57 0.43 1.7\nVOC      0.83 0.19 0.13 0.75 0.25 1.2\nCOMP     0.75 0.14 0.16 0.60 0.40 1.2\nDIGIT    0.45 0.06 0.36 0.34 0.66 2.0\nPICTCOM  0.43 0.61 0.02 0.56 0.44 1.8\nCODING   0.10 0.09 0.88 0.79 0.21 1.0\nPICTARG  0.34 0.45 0.27 0.39 0.61 2.6\nBLOCK    0.41 0.66 0.22 0.66 0.34 1.9\nOBJECT   0.31 0.71 0.14 0.62 0.38 1.5\nSYMBOL   0.23 0.32 0.74 0.70 0.30 1.6\nMAZES   -0.06 0.71 0.11 0.51 0.49 1.1\n\n                       RC1  RC3  RC2\nSS loadings           3.80 2.37 1.74\nProportion Var        0.29 0.18 0.13\nCumulative Var        0.29 0.47 0.61\nProportion Explained  0.48 0.30 0.22\nCumulative Proportion 0.48 0.78 1.00\n\nMean item complexity =  1.5\nTest of the hypothesis that 3 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.07 \n\nFit based upon off diagonal values = 0.97\nSi noti che i primi cinque subtest possiedono saturazioni maggiori di \\(0.6\\) sul primo fattore. Dato che questi test sono tutti presentati verbalmente e richiedono delle risposte verbali, tale fattore può essere denominato Comprensione Verbale.\nI subtest “Cifrario” e “Ricerca di simboli” saturano sul secondo fattore. Entrambi i subtest misurano la velocità dei processi di codifica o ricerca. Questo fattore, dunque, può essere denominato Velocità di elaborazione.\nInfine, i subtest “Completamento di figure,” “Disegno con i cubi,” “Riordinamento di storie figurate” e “Labirinti” saturano sul terzo fattore. Tutti questi test condividono una componente geometrica o configurazionale: misurano infatti le abilità necessarie per la manipolazione o la disposizione di immagini, oggetti, blocchi. Questo fattore, dunque, può essere denominato Organizzazione percettiva.\nNel caso di una rotazione ortogonale, la comunalità di ciascuna sottoscala è uguale alla somma dei coefficienti di impatto al quadrato della sottoscala nei fattori. Per le 13 sottoscale del WISC-III abbiamo dunque\nh2 &lt;- rep(0,13)\nfor (i in 1:13) {\n  h2[i] &lt;- sum(f_pc$loadings[i, ]^2)\n}\nround(h2, 2)\n\n\n0.720.720.570.750.60.340.560.790.390.660.620.70.51\nQuesti risultati replicano quelli riportati nel manuale del test WISC-III.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>I punteggi fattoriali</span>"
    ]
  },
  {
    "objectID": "chapters/fa/05_factor_scores.html#punteggi-fattoriali",
    "href": "chapters/fa/05_factor_scores.html#punteggi-fattoriali",
    "title": "18  I punteggi fattoriali",
    "section": "18.1 Punteggi fattoriali",
    "text": "18.1 Punteggi fattoriali\nFino ad ora abbiamo considerato le strategie di costruzione del modello basate sulla stima e sull’interpretazione delle saturazioni fattoriali e delle comunalità. Questo è il primo passo nella costruzione del modello fattoriale. È però possibile compiere un passo ulteriore, ovvero quello della stima dei punteggi fattoriali (factor scores) i quali risultano utili sia per interpretare i risultati dell’analisi fattoriale che per fare diagnostica. I punteggi fattoriali forniscono le previsioni dei livelli dei fattori latenti per ogni rispondente. Esistono vari metodi di stima dei punteggi fattoriali. Tra questi troviamo il metodo di Thomson basato sulla regressione e il metodo di Bartlett basato sulla massima verosimiglianza. Entrambi questi metodi sono implementati nel software .\n\n18.1.1 Stima dei punteggi fattoriali\nSi definiscono punteggi fattoriali i valori assunti dai fattori comuni (inosservabili) in corrispondenza delle osservazioni campionarie. Il metodo di Thomson stima i punteggi fattoriali in base all’approccio della regressione multipla, ovvero, impiegando la matrice delle correlazioni tra le variabili e la matrice di struttura (ovvero, la matrice delle correlazioni delle variabili con i fattori). Per ottenere le stime dei punteggi fattoriali con il metodo di Thomson è necessario specificare nella funzione factanal() l’opzione scores = \"regression\".\n\n\n18.1.2 Dimostrazione di Thurstone\nPrima di descrivere il metodo della regressione, esaminiamo la dimostrazione che Thurstone (1947) ha fornito per illustrare il significato dei punteggi fattoriali (si veda Loehlin, 1987). L’idea è quella di esaminare la stima dei punteggi fattoriali in una situazione in cui i tali punteggi sono conosciuti, in maniera tale da potere controllare il risultato dell’analisi.\nSi consideri un insieme di 1000 scatole di cui conosciamo le dimensioni \\(x, y, z\\):\n\nset.seed(123)\nn &lt;- 1e3\nx &lt;- rnorm(n, 100, 1.5)\ny &lt;- rnorm(n, 200, 1.5)\nz &lt;- rnorm(n, 300, 1.5)\n\nIl problema è quello di stimare le dimensioni delle scatole disponendo soltanto di una serie di misure indirette, corrotte dal rumore di misura. Thurstone (1947) utilizzò le seguenti trasformazioni delle dimensioni delle scatole (si veda Jennrich, 2007).\n\ns &lt;- 40\ny1 &lt;- rnorm(n, mean(x), s)\ny2 &lt;- rnorm(n, mean(y), s)\ny3 &lt;- rnorm(n, mean(z), s)\ny4 &lt;- x * y + rnorm(n, 0, s)\ny5 &lt;- x * z + rnorm(n, 0, s)\ny6 &lt;- y * z + rnorm(n, 0, s)\ny7 &lt;- x^2 * y + rnorm(n, 0, s)\ny8 &lt;- x * y^2 + rnorm(n, 0, s)\ny9 &lt;- x^2 * z + rnorm(n, 0, s)\ny10 &lt;- x * z^2 + rnorm(n, 0, s)\ny11 &lt;- y^2 * z + rnorm(n, 0, s)\ny12 &lt;- y * z^2 + rnorm(n, 0, s)\ny13 &lt;- y^2 * z + rnorm(n, 0, s)\ny14 &lt;- y * z^2 + rnorm(n, 0, s)\ny15 &lt;- x / y + rnorm(n, 0, s)\ny16 &lt;- y / x + rnorm(n, 0, s)\ny17 &lt;- x / z + rnorm(n, 0, s)\ny18 &lt;- z / x + rnorm(n, 0, s)\ny19 &lt;- y / z + rnorm(n, 0, s)\ny20 &lt;- z / y + rnorm(n, 0, s)\ny21 &lt;- 2 * x + 2*y + rnorm(n, 0, s)\ny22 &lt;- 2 * x + 2*z + rnorm(n, 0, s)\ny23 &lt;- 2 * y + 2*z + rnorm(n, 0, s)\n\nEseguiamo l’analisi fattoriale con una soluzione a tre fattori sui dati così creati.\n\nY &lt;- cbind(\n  y1, y2, y3, y4, y5, y6, y7, y8, y9, \n  y10, y11, y12, y13, y14, y15, y16, \n  y17, y18, y19, y20, y21, y22, y23\n)\n\nfa &lt;- factanal(\n  Y, \n  factors = 3, \n  scores = \"regression\",\n  lower = 0.01\n)\n\nL’opzione scores = \"regression\" richiede il calcolo dei punteggi fattoriali con il metodo della regressione. Nel caso di una rotazione Varimax (default della funzione factanal()), i punteggi fattoriali risultano ovviamente incorrelati:\n\ncor(\n  cbind(fa$scores[, 1], fa$scores[, 2], fa$scores[, 3])\n  ) %&gt;% \n  round(3)\n\n\nA matrix: 3 x 3 of type dbl\n\n\n1.000\n0.002\n-0.001\n\n\n0.002\n1.000\n0.005\n\n\n-0.001\n0.005\n1.000\n\n\n\n\n\nGeneriamo ora i diagrammi di dispersione che mettono in relazione le dimensioni originarie delle scatole (\\(x, y, z\\)) con i punteggi fattoriali sui tre fattori. Se l’analisi ha successo, ci aspettiamo un’alta correlazione tra i punteggi fattoriali di ogni fattore e una sola delle dimensioni delle scatole \\(x\\), \\(y\\), \\(z\\).\n\np1 &lt;- tibble(x, fs1 = fa$scores[, 1]) %&gt;% \n  ggplot(aes(x, fs1)) +\n  geom_point(alpha = 0.2)\np2 &lt;- tibble(y, fs1 = fa$scores[, 1]) %&gt;% \n  ggplot(aes(y, fs1)) +\n  geom_point(alpha = 0.2)\np3 &lt;- tibble(z, fs1 = fa$scores[, 1]) %&gt;% \n  ggplot(aes(z, fs1)) +\n  geom_point(alpha = 0.2)\n\np4 &lt;- tibble(x, fs2 = fa$scores[, 2]) %&gt;% \n  ggplot(aes(x, fs2)) +\n  geom_point(alpha = 0.2)\np5 &lt;- tibble(y, fs2 = fa$scores[, 2]) %&gt;% \n  ggplot(aes(y, fs2)) +\n  geom_point(alpha = 0.2)\np6 &lt;- tibble(z, fs2 = fa$scores[, 2]) %&gt;% \n  ggplot(aes(z, fs2)) +\n  geom_point(alpha = 0.2)\n\np7 &lt;- tibble(x, fs3 = fa$scores[, 3]) %&gt;% \n  ggplot(aes(x, fs3)) +\n  geom_point(alpha = 0.2)\np8 &lt;- tibble(y, fs3 = fa$scores[, 3]) %&gt;% \n  ggplot(aes(y, fs3)) +\n  geom_point(alpha = 0.2)\np9 &lt;- tibble(z, fs3 = fa$scores[, 3]) %&gt;% \n  ggplot(aes(z, fs3)) +\n  geom_point(alpha = 0.2)\n\n\n(p1 | p2 | p3) /\n(p4 | p5 | p6) /\n(p7 | p8 | p9) \n\n\n\n\n\n\n\n\nI risultati riportati nella figura confermano le aspettative.\nIl metodo della regressione pone il problema della stima dei punteggi fattoriali nei termini di una ideale regressione di ogni fattore rispetto a tutte le variabili osservate. Per il fattore \\(j\\)-esimo, si può scrivere la seguente equazione:\n\\[\n\\begin{aligned}\nF_j =& \\beta_{1j}y_1 + \\dots + \\beta_{pm}y_p + \\varepsilon_j\n\\end{aligned}\n\\]\ndove \\(F_j\\) sono i punteggi fattoriali e \\(y\\) sono le variabili osservate standardizzate \\((Y-\\bar{Y})/s\\). In forma matriciale, il modello diventa\n\\[\n\\textbf{F} = \\textbf{y} \\textbf{B} +\n\\boldsymbol{\\varepsilon}\n\\]\nI coefficienti parziali di regressione B sono ignoti. Tuttavia, possono essere calcolati utilizzando i metodi della regressione lineare. Nel modello di regressione, infatti, i coefficienti dei minimi quadrati possono essere calcolati utilizzando due matrici di correlazioni: la matrice \\(\\textbf{R}_{xx}\\) (le correlazioni tra le variabili \\(X\\)) e la matrice \\(\\textbf{R}_{xy}\\) (le correlazioni tra le variabili \\(X\\) e la variabile \\(Y\\):\n\\[\n\\hat{\\textbf{B}} = \\textbf{R}_{xx}^{-1}\\textbf{R}_{xy}\n\\]\nNel caso dell’analisi fattoriale, \\(\\textbf{R}_{xx}\\) corrisponde alla matrice delle correlazioni tra le variabili osservate e \\(\\textbf{R}_{xy}\\) corrisponde alla matrice di struttura (la matrice delle correlazioni tra le variabili osservate e i fattori). Se i fattori sono ortogonali, la matrice di struttura coincide con la matrice dei pesi fattoriali \\(\\hat{\\boldsymbol{\\Lambda}}\\).\nI coefficienti B dell’equazione precedente possono dunque essere trovati nel modo seguente:\n\\[\n\\begin{equation}\n\\hat{\\textbf{B}} = \\textbf{R}_{yy}^{-1}\\textbf{R}_{xf}=\n\\textbf{R}^{-1}\\hat{\\boldsymbol{\\Lambda}}\n\\end{equation}\n\\]\nUna volta stimati i coefficienti \\(\\hat{\\textbf{B}}\\), i punteggi fattoriali si calcolano allo stesso modo dei punteggi teorici del modello di regressione:\n\\[\n\\begin{equation}\n\\hat{\\textbf{F}} = \\textbf{y} \\hat{\\textbf{B}} = \\textbf{y}\n\\textbf{R}^{-1}\\hat{\\boldsymbol{\\Lambda}},\n\\end{equation}\n\\]\ndove \\(\\textbf{y}\\) è la matrice delle variabili osservate standardizzate \\((Y-\\bar{Y})/s\\).\nEsercizio. Si utilizzino i dati dass21.txt che corrispondono alla somministrazione del test DASS-21 a 334 partecipanti. Lo schema di codifica si può trovare seguendo questo link. Ci si focalizzi sulla sottoscala Stress del DASS-21. Si trovino i punteggi fattoriali usando la funzione factanal() e si replichi il risultato seguendo la procedura delineata sopra.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>I punteggi fattoriali</span>"
    ]
  },
  {
    "objectID": "chapters/fa/05_factor_scores.html#session-info",
    "href": "chapters/fa/05_factor_scores.html#session-info",
    "title": "18  I punteggi fattoriali",
    "section": "18.2 Session Info",
    "text": "18.2 Session Info\n\nsessionInfo()",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>I punteggi fattoriali</span>"
    ]
  },
  {
    "objectID": "chapters/fa/06_constraints_on_parms.html",
    "href": "chapters/fa/06_constraints_on_parms.html",
    "title": "19  Attendibilità e modello fattoriale",
    "section": "",
    "text": "19.1 Teoria classica dei test e analisi fattoriale\n{cite:t}mcdonald2013test illustra come la teoria classica dei test possa essere correlata al modello dell’analisi fattoriale. La figura rappresenta, attraverso i termini del modello fattoriale, la relazione che sussiste tra i punteggi \\(Y\\), derivanti dalla somministrazione di un test composto da cinque item, e i punteggi veri.\nDiagramma di percorso del modello monofattoriale.\n:::\nÈ necessario ricodificare due item.\nbfi$O2r &lt;- 7 - bfi$O2\nbfi$O5r &lt;- 7 - bfi$O5\ncor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\") |&gt;\n    round(2)\n\n\nA matrix: 5 x 5 of type dbl\n\n\n\nO1\nO2r\nO3\nO4\nO5r\n\n\n\n\nO1\n1.00\n0.21\n0.40\n0.18\n0.24\n\n\nO2r\n0.21\n1.00\n0.26\n0.07\n0.32\n\n\nO3\n0.40\n0.26\n1.00\n0.19\n0.31\n\n\nO4\n0.18\n0.07\n0.19\n1.00\n0.18\n\n\nO5r\n0.24\n0.32\n0.31\n0.18\n1.00\nEseguiamo l’analisi fattoriale confermativa con lavaan.\nmod &lt;- \"\n    f =~ NA*O1 + O2r + O3 + O4 + O5r\n    f ~~ 1*f\n\"\n\nfit &lt;- cfa(mod, data = bfi, std.ov = TRUE, std.lv = TRUE)\nEstraiamo le saturazioni fattoriali e le specificità dall’oggetto fit.\nlambda &lt;- inspect(fit, what = \"std\")$lambda\npsy &lt;- diag(inspect(fit, what = \"est\")$theta)\nCalcoliamo il coefficiente \\(\\omega\\)\n\\[\n\\omega = \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2  + \\sum_{i=1}^p \\psi_{ii}}\n\\]\nusando i parametri del modello fattoriale.\nsum(lambda)^2 / (sum(lambda)^2 + sum(psy))\n\n0.618064541281708\nRipetiamo i calcoli usando la funzione compRelSEM del pacchetto semTools.\nsemTools::compRelSEM(fit, tau.eq = FALSE)\n\nf: 0.618110889806653\nIl coefficiente \\(\\omega=0.62\\) può essere interpretato dicendo che il 62% della varianza del punteggio totale \\(Y\\) della sottoscala Openness viene spiegato dal fattore comune latente.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Attendibilità e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/06_constraints_on_parms.html#teoria-classica-dei-test-e-analisi-fattoriale",
    "href": "chapters/fa/06_constraints_on_parms.html#teoria-classica-dei-test-e-analisi-fattoriale",
    "title": "19  Attendibilità e modello fattoriale",
    "section": "",
    "text": "```xbgpsojw ../images/factmod1.png\n\n\n\n\nheight: 300px\n\n\nname: lcsm1-fig\n\n\n\n\n\nEsistono diverse strategie per stimare l'attendibilità in situazioni in cui viene somministrato un unico test. In questo contesto, analizzeremo tre metodologie che possono essere implementate attraverso l'analisi fattoriale: l'$\\alpha$ di Cronbach, l'$\\omega$ di McDonald e il metodo di Spearman-Brown.\n\nIl coefficiente $\\alpha$ rappresenta il principale indice utilizzato per quantificare l'attendibilità come misura di coerenza interna o omogeneità. Approfondiremo come questo indice rappresenti il limite inferiore dell'attendibilità di un test, a condizione che siano soddisfatte alcune ipotesi. Tuttavia, se queste assunzioni non vengono rispettate, l'$\\alpha$ si rivela un stimatore distorto dell'attendibilità.\n\nPrima di esaminare le diverse metodologie per stimare l'attendibilità in termini di coerenza interna, è essenziale distinguere tra le tre diverse forme che il modello unifattoriale può assumere. Queste tre forme corrispondono al modello con indicatori congenerici, al modello $\\tau$-equivalente e al modello parallelo.\n\n## Modello fattoriale e CTT\n\nConsiderando un insieme di item osservati $X_1, X_2, \\dots, X_p$, con $p&gt;2$, i punteggi ottenuti da questi item sono composti da due elementi distinti: una componente di punteggio vero e una componente di errore.\n\n$$\n\\begin{equation}\n\\begin{aligned}\nX_1 &=T_1+E_1,\\notag\\\\ \nX_2 &=T_2+E_2,\\notag\\\\ \n&\\dots\\notag\\\\ \nX_p &=T_p+E_p.\\notag\n\\end{aligned}\n\\end{equation}\n$$\n\nIn linea con l'approccio delineato da {cite:t}`mcdonald2013test`, questa decomposizione tra la componente vera e quella di errore può essere formalizzata mediante l'utilizzo dei parametri del modello fattoriale. L'equazione $X_i = T_i + E_i$ può quindi essere riformulata come segue:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i, \\quad{i=1, \\dots, p},\n$$ \n\nIn questa equazione, $X_i$ rappresenta il punteggio osservato per l'item $i$-esimo (espresso in termini di scarti dalla media), $\\lambda_i$ è il carico fattoriale associato all'item $i$-esimo, $\\xi$ costituisce il fattore comune e $\\delta_i$ è la componente residuale del punteggio osservato per l'item $i$-esimo. Tale formulazione si basa sulle assunzioni del modello monofattoriale. Nello specifico, si ipotizza che $\\xi$ e $\\delta_i$ siano incorrelati per ogni item $i$, e che $\\delta_i$ e $\\delta_k$ siano incorrelati per ogni coppia $i \\neq k$.\n\n## Classi di modelli\n\nNell'ambito dei modelli monofattoriali, possiamo distinguere tre scenari principali:\n\n1. **Modello con indicatori congenerici:** Questo modello rappresenta il caso più generale, in cui non vi sono restrizioni imposte sulla struttura degli indicatori. Gli indicatori sono correlati in quanto riflettono un fattore comune, ma possono avere carichi fattoriali diversi e specificità uniche.\n\n2. **Modello con indicatori $\\tau$-equivalenti:** In questo scenario, tutti gli indicatori hanno lo stesso carico fattoriale, il che implica che misurano il fattore comune con la stessa forza. Tuttavia, possono differire per quanto riguarda la loro varianza e specificità.\n\n3. **Modello con indicatori paralleli:** Qui, gli indicatori non solo condividono lo stesso carico fattoriale, ma presentano anche identica varianza degli errori. Questo indica una completa equivalenza tra gli indicatori, mostrando una struttura molto più rigida rispetto al modello $\\tau$-equivalente.\n\nIl modello con indicatori congenerici funge da base più flessibile, mentre i modelli con indicatori $\\tau$-equivalenti e paralleli introducono vincoli crescenti che specificano relazioni sempre più strette tra gli indicatori.\n\n### Indicatori congenerici\n\nGli indicatori *congenerici* rappresentano misure di uno stesso costrutto, ma non è necessario che riflettano tale costrutto con la medesima intensità. Nel contesto degli indicatori congenerici all'interno del modello monofattoriale, non vengono introdotte limitazioni né sulle saturazioni fattoriali né sulle specificità:\n\n$$\n\\lambda_1\\neq \\lambda_2 \\neq \\dots\\neq \\lambda_p,\n$$\n\n$$\n\\psi_{11}\\neq \\psi_{22} \\neq \\dots\\neq \\psi_{pp}.\n$$ \n\nIl modello mono-fattoriale con indicatori congenerici è dunque\n\n$$\n\\begin{equation}\nX_i = \\lambda_i \\xi + \\delta_i.\n\\end{equation}\n$$(eq-mod-tau-eq)\n\nDalle assunzioni precedenti possiamo derivare la matrice $\\boldsymbol{\\Sigma}$ riprodotta in base al modello congenerico la quale risulta essere uguale a\n\n$$\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{11} & \\sigma_{12} & \\dots & \\sigma_{1p}, \\\\\n        \\sigma_{21} & \\sigma_{22} & \\dots & \\sigma_{2p}. \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{p1} & \\sigma_{p2} & \\dots & \\sigma_{pp} \n      \\end{array} \n    \\right].\n$$ \n    \nSi noti come tutte le varianze e tutte le covarianze siano tra loro diverse.\n\n### Indicatori tau-equivalenti\n\nNel caso di indicatori $\\tau$-equivalenti, si ha che\n\n$$\n\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda,\n$$\n\n$$\n\\psi_{11}\\neq \\psi_{22} \\neq \\dots\\neq \\psi_{pp}.\n$$ \n\nIl modello monofattoriale con indicatori $\\tau$-equivalenti diventa dunque\n\n$$\n\\begin{equation}\nX_i = \\lambda \\xi + \\delta_i, \n\\end{equation}\n$$(eq-mod-tau-eq)\n\novvero \n\n$$\n\\begin{equation}\nX_i = \\tau + \\delta_i,\n\\end{equation}\n$$(eq-mod-tau-eq-b)\n\ndove $\\tau=\\lambda \\xi$ è l'attributo comune scalato nell'unità di misura dell'indicatore. Secondo il modello {eq}`eq-mod-tau-eq`, tutte le $p(p-1)$ covarianze tra gli item\ndel test devono essere uguali, ovvero\n\n$$\n\\begin{equation}\n\\sigma_{ik} = \\lambda^2=\\sigma^2_T,\n\\end{equation}\n$$(eq-cov-tau-eq)\n\nper $i\\neq k$. Gli elementi sulla diagonale principale della matrice di varianze e covarianze saranno invece\n\n$$\n\\begin{equation}\n\\sigma_{ii} = \\lambda^2 + \\psi_{ii} =\\sigma^2_T + \\psi_{ii}.\n\\end{equation}\n$$(eq-var-tau)\n\nLa matrice $\\boldsymbol{\\Sigma}$ riprodotta in base al modello $\\tau$-equivalente è dunque uguale a\n\n$$\n\\begin{equation}\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{T}^2 + \\psi_{11} & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 + \\psi_{22} & \\dots & \\sigma_{T}^2 \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 + \\psi_{pp} \n      \\end{array} \n    \\right].\n\\end{equation}\n$$(eq-sigma-tau-eq)\n    \nTutte le covarianze sono uguali, mentre le varianze sono tra loro diverse.\n\n### Indicatori paralleli\n\nNel caso di indicatori paralleli si ha che\n\n$$\n\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda,\n$$\n\n$$\n\\psi_{11}=\\psi_{22}=\\dots=\\psi_{pp}=\\psi.\n$$ \n\nIl modello costituito da indicatori paralleli impone dunque un'ulteriore restrizione che riguarda le varianze degli item, ovvero:\n\n$$\n\\sigma_{ii} = \\lambda^2 + \\psi =\\sigma^2_T + \\sigma^2.\n$$ \n\nLa struttura di varianze e covarianze imposta dal modello per indicatori paralleli è\ndunque tale da richiedere l'uguaglianza tra tutte le covarianze tra gli\nitem e l'uguaglianza tra tutte le varianze degli item. La matrice\n$\\boldsymbol{\\Sigma}$ riprodotta in base al modello con indicatori\nparalleli è dunque uguale a \n\n$$\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{T}^2 + \\sigma^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 + \\sigma^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 +\\sigma^2 \\notag\n      \\end{array} \n    \\right].\n$$\n\n\n## Metodo dei minimi quadrati non pesati\n\nNel contesto del modello unifattoriale, la varianza di ciascun indicatore è decomposta in due componenti: la componente $\\sigma^2_T$, attribuibile all'effetto del fattore latente comune, e la componente $\\psi$, riferita all'influenza del fattore specifico. {cite:t}`mcdonald2013test` dimostra come sia possibile ottenere stime di tali componenti dai dati osservati. Queste stime vengono successivamente impiegate per calcolare l'affidabilità interna del test mediante le formule degli indici $\\alpha$ di Cronbach e $\\omega$ di McDonald.\n\nIn precedenza, abbiamo esaminato come la varianza del punteggio vero possa essere equivalente alla covarianza tra due forme parallele dello stesso test: $\\sigma^2_T = \\sigma_{XX^\\prime}$. Nel caso di indicatori $\\tau$-equivalenti, la matrice $\\boldsymbol{\\Sigma}$ prevista dal modello risulta essere:\n\n$$\n\\boldsymbol{\\Sigma}=\\left[\n      \\begin{array}{ c c c c }\n        \\sigma_{T}^2 + \\psi_{11} & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 \\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 + \\psi_{22} & \\dots & \\sigma_{T}^2 \\\\\n        \\vdots & \\vdots & & \\vdots\\\\\n        \\sigma_{T}^2 & \\sigma_{T}^2 & \\dots & \\sigma_{T}^2 + \\psi_{pp} \\notag\n      \\end{array}\n    \\right],\n$$\n\nossia, tutte le covarianze sono equivalenti tra loro. Nel caso degli indicatori $\\tau$-equivalenti, dunque, una stima $\\hat{\\sigma}^2_T$ di $\\sigma^2_T$ si ottiene calcolando la media delle covarianze della matrice **S**:\n\n$$\n\\begin{equation}\n\\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} {\\sum \\sum}_{i \\neq k} s_{ik}.\n\\end{equation}\n$$ (eq-sigma-t)\n\nQuesto metodo di stima di $\\sigma^2_T$ è noto come \"metodo dei minimi quadrati non pesati\" {cite:p}`mcdonald2013test`.\n\nInoltre, nel caso di indicatori $\\tau$-equivalenti, la stima di $\\psi_{ii}$ nell'eq. {eq}`eq-var-tau` è calcolata come:\n\n$$\n\\hat{\\psi}_{ii }= s_{ii} - \\hat{\\sigma}_T^2,\n$$\n\nper ogni item $i$.\n\nPer quanto riguarda gli *indicatori paralleli*, la stima di $\\sigma^2_T$ è ancora basata sull'eq. {eq}`eq-sigma-t`, ovvero sulla media delle covarianze della matrice $\\boldsymbol{\\Sigma}$. Tuttavia, la stima del valore costante $\\psi$ è ottenuta tramite l'equazione:\n\n$$\n\\begin{equation}\n\\hat{\\psi} = \\frac{1}{p} \\sum_i (s_{ii} - \\hat{\\sigma}_T^2)\n\\end{equation}\n$$(eq-psi-par-st)\n\n## Varianza del punteggio totale di un test\n\nConsideriamo un test omogeneo costituito da $p$ item, il cui punteggio totale $Y$ è dato dalla somma dei punteggi individuali degli item, espressi come $Y = \\sum_{i=1}^p X_i$. Analizziamo la varianza di $Y$ utilizzando un modello unifattoriale.\n\nIn un modello congenerico con un singolo fattore comune, il punteggio di ciascun item $i$, $X_i$, può essere rappresentato dalla seguente equazione:\n\n$$\nX_i = \\lambda_i \\xi + \\delta_i,\n$$\n\ndove $\\lambda_i$ rappresenta la carica fattoriale dell'item $i$ sul fattore comune $\\xi$, e $\\delta_i$ è l'errore specifico associato all'item. Questa formulazione è analoga all'equazione $X_i = T_i + E_i$ della teoria classica dei test, dove $T_i$ è il vero punteggio e $E_i$ l'errore di misurazione.\n\nIl punteggio totale, essendo la somma di tutti gli item, si esprime come $\\sum_i (\\lambda_i \\xi + \\delta_i)$. La varianza del punteggio totale può quindi essere calcolata come segue:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n  \\mathbb{V}(Y) &= \\mathbb{V}\\left[ \\sum_i  (\\lambda_i \\xi + \\delta_i)  \\right] \\\\\n  &= \\mathbb{V}\\left[ \\left( \\sum_i \\lambda_i\\right) \\xi + \\sum_i \\delta_i\\right] \\\\\n  &=  \\left(\\sum_i \\lambda_i\\right)^2 \\mathbb{V}(\\xi) +  \\sum_i  \\mathbb{V}(\\delta_i) \\\\\n  &= \\left(\\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii},\n\\end{aligned}\n\\end{equation}\n$$ (eq-var-y)\n\ndove $\\mathbb{V}(\\xi) = 1$ per ipotesi. La varianza di $Y$ si decompone in due parti principali: la prima parte, $(\\sum_i \\lambda_i)^2$, rappresenta la varianza attribuibile al fattore comune, riflettendo la variazione legata all'attributo misurato dagli item; la seconda parte, $\\sum_i \\psi_{ii}$, corrisponde alla somma delle varianze degli errori specifici di ciascun item, rappresentando la variazione dovuta agli errori di misurazione.\n\n## Stima dell'attendibilità\n\n### Coefficiente Omega\n\nDopo aver analizzato la varianza del punteggio totale di un test come indicato nella precedente equazione:\n\n$$\n\\mathbb{V}(Y) = \\left( \\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii},\n$$\n\nsi introduce il coefficiente di affidabilità $\\omega$. {cite:t}`mcdonald2013test` definisce $\\omega$ come il rapporto tra la varianza attribuibile al fattore comune e la varianza totale del punteggio. Basandosi sui parametri del modello monofattoriale, il coefficiente $\\omega$ può essere formulato come segue:\n\n$$\n\\begin{equation}\n\\begin{aligned}\n\\omega &= \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\mathbb{V}(Y)} \\\\\n&= \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2  + \\sum_{i=1}^p \\psi_{ii}}\n\\end{aligned}\n\\end{equation}\n$$ (eq-omega)\n\nQuesto coefficiente $\\omega$ offre una stima quantitativa dell'affidabilità di un test, basata sui parametri del modello congenerico e utilizzando i dati raccolti da una singola somministrazione del test. La sua utilità risiede nel quantificare quanto della varianza osservata nel punteggio totale è effettivamente spiegata dal fattore comune misurato dal test.\n\n#### Un esempio concreto\n\nConsideriamo nuovamente la scala *Openness* del dataframe `bfi` discussi nel capitolo {ref}`ctt-3-notebook`. Leggiamo i dati in R.\n\n::: {#d3363486 .cell vscode='{\"languageId\":\"r\"}' execution_count=2}\n``` {.r .cell-code}\ndata(bfi, package = \"psych\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n19.1.0.1 Coefficiente \\(\\omega\\) e assunzioni della teoria classica dei test\nIl calcolo del coefficiente \\(\\omega\\) si appoggia su un’assunzione fondamentale della teoria classica dei test: che non esistano covarianze tra gli errori specifici degli item, ossia \\(\\psi_{ik}=0\\) per ogni \\(i \\neq k\\). Tuttavia, questa ipotesi potrebbe non reggere in contesti di dati empirici. Bollen (1980) sottolinea che, qualora le covarianze tra errori specifici non siano trascurabili, l’equazione per \\(\\omega\\) dovrebbe essere modificata come segue:\n\\[\n\\begin{equation}\n\\omega = \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2  + \\sum_{i=1}^p \\psi_{ii} + \\sum_{i, k, i\\neq k}^p \\psi_{ik}}.\n\\end{equation}\n\\]\nPer verificare la validità dell’assunzione di indipendenza tra gli errori specifici, si può ricorrere a un’analisi fattoriale confermativa. Se l’analisi rivela correlazioni significative tra molti errori specifici, potrebbe essere necessario incorporare ulteriori fattori nel modello per accomodare queste covarianze. Questo può suggerire una struttura non più unidimensionale, indicando la presenza di diverse sottoscale all’interno del test. Tuttavia, anche con l’identificazione di tali sottoscale, le covarianze tra i fattori specifici possono rimanere inesplicate. In tali casi, l’uso dell’equazione modificata per \\(\\omega\\) diventa indispensabile.\n\n\n19.1.0.2 Interpretazione del Coefficiente \\(\\omega\\)\n{cite:t}mcdonald2013test propone diverse interpretazioni del coefficiente \\(\\omega\\) che aiutano a comprenderne il significato nel contesto della teoria dei test: - \\(\\omega\\) può essere visto come il quadrato della correlazione tra il punteggio totale \\(Y\\) e il fattore comune \\(\\xi\\), che rappresenta anche la correlazione tra \\(Y\\) e il punteggio vero. Questo si allinea alla definizione classica di affidabilità, espressa come \\(\\rho_{XT}^2 = \\sigma^2_{\\tau}/\\sigma^2_X\\), dove \\(\\sigma^2_{\\tau}\\) è la varianza del punteggio vero e \\(\\sigma^2_X\\) quella del punteggio osservato. - \\(\\omega\\) descrive anche la correlazione tra due applicazioni ipotetiche del test, \\(Y\\) e \\(Y'\\), che condividono le stesse somme (o medie) delle cariche fattoriali e delle varianze specifiche nel contesto di un modello a singolo fattore. - \\(\\omega\\) rappresenta il quadrato della correlazione tra il punteggio totale di \\(p\\) item e il punteggio medio di un insieme infinito di item all’interno di un dominio omogeneo, dove i \\(p\\) item analizzati sono un sottoinsieme rappresentativo.\nIn sintesi, il coefficiente \\(\\omega\\) fornisce una misura di quanto il punteggio totale di un test sia rappresentativo del fattore latente che il test intende misurare. Attraverso la correlazione, l’omogeneità e la consistenza osservata tra diverse somministrazioni o versioni di un test, \\(\\omega\\) aiuta a interpretare la qualità e l’affidabilità del test stesso.\n\n\n19.1.1 Coefficienti \\(\\alpha\\) e \\(\\omega\\) nel modello \\(\\tau\\)-equivalente\nNel contesto dei modelli monofattoriali, i coefficienti \\(\\omega\\) e \\(\\alpha\\) offrono stime dell’attendibilità, ma in contesti distinti. Il coefficiente \\(\\omega\\) è utile per i modelli con indicatori congenerici, mentre il coefficiente \\(\\alpha\\) è specifico per i modelli con indicatori \\(\\tau\\)-equivalenti.\nIn un modello \\(\\tau\\)-equivalente, dove ciascun item ha la stessa carica fattoriale \\(\\lambda\\), la varianza di ogni item si scompone in una parte dovuta al punteggio vero e una parte d’errore, espressa come \\(\\sigma_{ii} = \\lambda^2 + \\psi_{ii} = \\sigma^2_T + \\sigma^2_i\\). In questo scenario, la formula per il coefficiente \\(\\omega\\) si semplifica nel seguente modo:\n\\[\n\\omega = \\frac{\\left( \\sum_i \\lambda_i \\right)^2}{\\left( \\sum_i \\lambda_i \\right)^2  + \\sum_i \\psi_{ii}} = \\frac{p^2 \\lambda^2}{\\sigma^2_Y} = \\frac{p^2 \\sigma_T^2}{\\sigma_Y^2},\n\\]\ndove \\(Y\\) rappresenta il punteggio totale del test.\nApplicando il metodo dei minimi quadrati non pesati, possiamo derivare la stima seguente per \\(\\omega\\):\n\\[\n\\hat{\\omega} = \\frac{p^2 \\hat{\\sigma}_T^2}{s_Y^2},\n\\]\ndove \\(\\hat{\\sigma}_T^2\\) è stimato come:\n\\[\n\\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} \\sum \\sum_{i \\neq k} s_{ik}.\n\\]\nIntegrando questa stima nella formula precedente, otteniamo:\n\\[\n\\hat{\\omega} = \\frac{p}{p-1}\\frac{\\sum \\sum_{i \\neq k} s_{ik}}{s_Y^2}.\n\\]\nPer gli indicatori \\(\\tau\\)-equivalenti, quindi, \\(\\omega\\) può essere stimato da:\n\\[\n\\hat{\\omega} = \\frac{p}{p-1}\\left(1-\\frac{\\sum_i s_{ii}}{s_Y^2}\\right).\n\\] (eq-alpha-camp)\nQuesta stima di \\(\\omega\\) ha un parallelo nei valori di popolazione definiti da \\(\\alpha\\), che si esprime come:\n\\[\n\\alpha = \\frac{p}{p-1}\\left(1-\\frac{\\sum_{i=1}^p \\sigma_{ii}}{\\sigma_Y^2}\\right) = \\frac{p}{p-1}\\frac{\\sum_{i \\neq k}^p \\text{Cov}(X_i, X_k)}{\\mathbb{V}(Y)}.\n\\] (eq-alpha-pop)\nIn condizioni ideali del modello \\(\\tau\\)-equivalente, i valori di \\(\\alpha\\) e \\(\\omega\\) convergono. Tuttavia, \\(\\alpha\\) tende a sottostimare \\(\\omega\\), posizionandosi come un limite inferiore per \\(\\omega\\). Data questa natura conservativa di \\(\\alpha\\), alcuni ricercatori lo preferiscono a \\(\\omega\\), sebbene questa proprietà valga solamente quando le assunzioni del modello \\(\\tau\\)-equivalente sono rigorosamente rispettate.\n\n19.1.1.1 Un esempio concreto\nConsideriamo la matrice di varianze e covarianze della sottoscala Openness.\n\nC &lt;- cov(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nC |&gt; round(2)\n\n\nA matrix: 5 x 5 of type dbl\n\n\n\nO1\nO2r\nO3\nO4\nO5r\n\n\n\n\nO1\n1.28\n0.38\n0.54\n0.25\n0.36\n\n\nO2r\n0.38\n2.45\n0.50\n0.13\n0.67\n\n\nO3\n0.54\n0.50\n1.49\n0.29\n0.50\n\n\nO4\n0.25\n0.13\n0.29\n1.49\n0.29\n\n\nO5r\n0.36\n0.67\n0.50\n0.29\n1.76\n\n\n\n\n\nCalcoliamo il coefficiente \\(\\alpha\\) usando l’eq. {eq}eq-alpha-camp:\n\np &lt;- 5\nalpha &lt;- (p / (p - 1)) * (1 - tr(C) / sum(C))\nalpha\n\n0.600172514820215\n\n\n\n\n\n19.1.2 La formula “profetica” di Spearman-Brown\nLa formula profetica di Spearman-Brown è impiegata per calcolare l’affidabilità nei modelli di misurazione che utilizzano indicatori paralleli. Supponiamo di avere un test composto da \\(p\\) item paralleli, in cui ogni item ha la stessa carica fattoriale \\(\\lambda\\) e la stessa varianza dell’errore specifico \\(\\psi\\), ovvero \\(\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda\\) e \\(\\psi_{11}=\\psi_{22}=\\dots=\\psi_{pp}=\\psi\\).\nLa proporzione di varianza nel punteggio totale del test spiegata dalla variabile latente è quindi:\n\\[\n\\left(\\sum_i \\lambda_i \\right)^2 = (p \\lambda)^2 = p^2 \\lambda^2.\n\\]\nDefinendo l’affidabilità di un singolo item, \\(\\rho_1\\), come\n\\[\n\\rho_1 = \\frac{\\lambda^2}{\\lambda^2 + \\psi},\n\\]\nper \\(p\\) item paralleli, l’affidabilità del test, \\(\\rho_p\\), diventa:\n\\[\n\\begin{equation}\n\\begin{aligned}\n  \\rho_p &= \\frac{p^2 \\lambda^2}{p^2 \\lambda^2 + p \\psi} \\\\\n         &= \\frac{p \\lambda^2}{ p \\lambda^2 + \\psi} \\\\\n         &= \\frac{p \\lambda^2}{(p-1) \\lambda^2 + (\\lambda^2 + \\psi)}.\n\\end{aligned}\n\\end{equation}\n\\]\nSfruttando l’affidabilità di un singolo item \\(\\rho_1\\), possiamo riformulare \\(\\rho_p\\) come:\n\\[\n\\begin{equation}\n\\begin{aligned}\n  \\rho_p &= \\frac{p \\rho_1}{(p-1)\\rho_1 + 1}.\n\\end{aligned}\n\\end{equation}\n\\] (eq-spearman-brown-der)\nQuesta espressione, derivata qui sopra, mostra come l’affidabilità \\(\\rho_p\\) di un test composto da \\(p\\) item paralleli possa essere calcolata a partire dall’affidabilità di un singolo item. Tale formula è nota come “formula di predizione” di Spearman-Brown (Spearman-Brown prophecy formula).\nIn contesti con item paralleli, è importante notare che le misure di affidabilità \\(\\omega\\), \\(\\alpha\\), e \\(\\rho_p\\) risultano equivalenti.\n\n19.1.2.1 Un esempio concreto\nPoniamoci il problema di calcolare l’attendibilità della sottoscala Openness utilizzando la formula di Spearman-Brown. Ipotizziamo dunque che gli item della scala Openness siano paralleli. La matrice di correlazione è:\n\nR &lt;- cor(bfi[c(\"O1\", \"O2r\", \"O3\", \"O4\", \"O5r\")], use = \"pairwise.complete.obs\")\nprint(R)\n\n           O1       O2r        O3        O4       O5r\nO1  1.0000000 0.2137348 0.3953359 0.1783758 0.2389921\nO2r 0.2137348 1.0000000 0.2615580 0.0683203 0.3248698\nO3  0.3953359 0.2615580 1.0000000 0.1945048 0.3106404\nO4  0.1783758 0.0683203 0.1945048 1.0000000 0.1790512\nO5r 0.2389921 0.3248698 0.3106404 0.1790512 1.0000000\n\n\nSeguendo {cite:t}mcdonald2013test, supponiamo di calcolare l’attendibilità di un singolo item (\\(\\rho_1\\)) come la correlazione media tra gli item:\n\nrr &lt;- NULL\np &lt;- 5\nk &lt;- 1\nfor (i in 1:p) {\n  for (j in 1:p) {\n    if (j != i) {\n      rr[k] &lt;- R[i, j]\n    }\n    k &lt;- k + 1\n  }\n}\nro_1 &lt;- mean(rr, na.rm = TRUE)\nro_1\n\n0.236538319550858\n\n\nApplicando la formula di Spearman-Brown, la stima dell’attendibilità del test diventa pari a\n\n(p * ro_1) / ((p - 1) * ro_1 + 1)\n\n0.607707322439719",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Attendibilità e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/06_constraints_on_parms.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/fa/06_constraints_on_parms.html#commenti-e-considerazioni-conclusive",
    "title": "19  Attendibilità e modello fattoriale",
    "section": "19.2 Commenti e considerazioni conclusive",
    "text": "19.2 Commenti e considerazioni conclusive\nIl coefficiente \\(\\alpha\\) di Cronbach è uno degli indici di affidabilità più diffusi in psicometria. Tuttavia, la sua efficacia dipende strettamente dalla \\(\\tau\\)-equivalenza degli item, che presuppongono un tratto latente unidimensionale. Nella pratica, questa condizione è spesso violata: molti test misurano più di un fattore, e le comunalità degli item non sono uniformi, mettendo in discussione la validità dell’ipotesi di \\(\\tau\\)-equivalenza. Se gli errori sono incorrelati, il coefficiente \\(\\alpha\\) può sottostimare l’affidabilità; se invece gli errori sono correlati, può sovrastimarla.\nData questa limitazione, l’utilizzo del coefficiente \\(\\omega\\) di McDonald è generalmente più consigliabile. Il coefficiente \\(\\omega\\) fornisce una stima più robusta dell’affidabilità in vari contesti, inclusi quelli con assunzioni meno restrittive rispetto alla \\(\\tau\\)-equivalenza. Altri indici come il \\(glb\\) (Greatest Lower Bound), discusso da Ten Berge e Sočan (2004), e l’indice \\(\\beta\\) di Revelle (1979), rappresentano alternative valide al coefficiente \\(\\alpha\\), offrendo diversi vantaggi metodologici a seconda delle specifiche esigenze di misurazione e delle caratteristiche dei dati analizzati.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Attendibilità e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/06_constraints_on_parms.html#session-info",
    "href": "chapters/fa/06_constraints_on_parms.html#session-info",
    "title": "19  Attendibilità e modello fattoriale",
    "section": "19.3 Session Info",
    "text": "19.3 Session Info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] modelsummary_1.4.5 ggokabeito_0.1.0   viridis_0.6.5      viridisLite_0.4.2 \n [5] ggpubr_0.6.0       ggExtra_0.10.1     bayesplot_1.11.1   gridExtra_2.3     \n [9] patchwork_1.2.0    semTools_0.5-6     semPlot_1.1.6      lavaan_0.6-17     \n[13] psych_2.4.1        scales_1.3.0       markdown_1.12      knitr_1.45        \n[17] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[21] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[25] ggplot2_3.4.4      tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5   nloptr_2.0.3      \n  [7] rmarkdown_2.25     vctrs_0.6.5        minqa_1.2.6       \n [10] base64enc_0.1-3    rstatix_0.7.2      htmltools_0.5.7   \n [13] broom_1.0.5        Formula_1.2-5      htmlwidgets_1.6.4 \n [16] plyr_1.8.9         sandwich_3.1-0     emmeans_1.10.0    \n [19] zoo_1.8-12         uuid_1.2-0         igraph_2.0.2      \n [22] mime_0.12          lifecycle_1.0.4    pkgconfig_2.0.3   \n [25] Matrix_1.6-5       R6_2.5.1           fastmap_1.1.1     \n [28] shiny_1.8.0        digest_0.6.34      OpenMx_2.21.11    \n [31] fdrtool_1.2.17     colorspace_2.1-0   rprojroot_2.0.4   \n [34] Hmisc_5.1-1        fansi_1.0.6        timechange_0.3.0  \n [37] abind_1.4-5        compiler_4.3.2     withr_3.0.0       \n [40] glasso_1.11        htmlTable_2.4.2    backports_1.4.1   \n [43] carData_3.0-5      ggsignif_0.6.4     MASS_7.3-60.0.1   \n [46] corpcor_1.6.10     gtools_3.9.5       tools_4.3.2       \n [49] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [52] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [55] quadprog_1.5-8     nlme_3.1-164       promises_1.2.1    \n [58] lisrelToR_0.3      grid_4.3.2         pbdZMQ_0.3-11     \n [61] checkmate_2.3.1    cluster_2.1.6      reshape2_1.4.4    \n [64] generics_0.1.3     gtable_0.3.4       tzdb_0.4.0        \n [67] data.table_1.15.0  hms_1.1.3          car_3.1-2         \n [70] utf8_1.2.4         tables_0.9.17      sem_3.1-15        \n [73] pillar_1.9.0       IRdisplay_1.1      rockchalk_1.8.157 \n [76] later_1.3.2        splines_4.3.2      lattice_0.22-5    \n [79] survival_3.5-8     kutils_1.73        tidyselect_1.2.0  \n [82] miniUI_0.1.1.1     pbapply_1.7-2      stats4_4.3.2      \n [85] xfun_0.42          qgraph_1.9.8       arm_1.13-1        \n [88] stringi_1.8.3      boot_1.3-29        evaluate_0.23     \n [91] codetools_0.2-19   mi_1.1             cli_3.6.2         \n [94] RcppParallel_5.1.7 IRkernel_1.3.2     rpart_4.1.23      \n [97] xtable_1.8-4       repr_1.1.6         munsell_0.5.0     \n[100] Rcpp_1.0.12        coda_0.19-4.1      png_0.1-8         \n[103] XML_3.99-0.16.1    parallel_4.3.2     ellipsis_0.3.2    \n[106] jpeg_0.1-10        lme4_1.1-35.1      mvtnorm_1.2-4     \n[109] insight_0.19.8     openxlsx_4.2.5.2   crayon_1.5.2      \n[112] rlang_1.1.3        multcomp_1.4-25    mnormt_2.1.1",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Attendibilità e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/07_total_score.html",
    "href": "chapters/fa/07_total_score.html",
    "title": "20  Punteggio totale e modello fattoriale",
    "section": "",
    "text": "20.1 Punteggio totale e modello fattoriale parallelo\nMcNeish e Wolf (2020) richiamano l’attenzione sul fatto che usare il punteggio totale quale misura di un costrutto è possibile solo quando i dati soddisfano i vincoli di un modello fattoriale parallelo.\nConsideriamo l’esempio seguente, nel quale McNeish e Wolf (2020) esaminano i dati “classici” di Holzinger and Swineford (1939), i quali si riferiscono ai seguenti item:\nLeggiamo i dati in R.\nd &lt;- rio::import(\n  \"../data/1_Factor_Parallel.csv\"\n)\nMcNeish e Wolf (2020) sottolineano il fatto che il punteggio totale\n\\[\n\\text{Punteggio totale} = \\text{Item 1 + Item 2 + Item 3 + Item 4 + Item 5 + Item 6}\n\\]\nrappresenta l’idea che ciasun item fornisca la stessa quantità di informazione relativamente alla misura del costrutto. Ciò può essere specificato da un modello fattoriale nel quale le saturazioni fattoriali degli item sono tutte uguali a 1. Questo corrisponde al modello parallelo che abbiamo discusso in precedenza. In tali circostanze, i punteggi fattoriali del test risultano perfettamente associati al punteggio totale (correlazione uguale a 1). Dunque, se tale modello fattoriale è giustificato dai dati, questo giustifica l’uso del punteggio totale del test quale misura del costrutto.\nÈ facile verificare tali affermazioni. Implementiamo il modello parallelo.\nm_parallel &lt;-\n  \"\n  # all loadings are fixed to one\n  f1 =~ 1*X4 + 1*X5 + 1*X6 + 1*X7 + 1*X8 + 1*X9\n  \n  # all residual variances constrained to same value\n  X4 ~~ theta*X4\n  X5 ~~ theta*X5\n  X6 ~~ theta*X6\n  X7 ~~ theta*X7\n  X8 ~~ theta*X8\n  X9 ~~ theta*X9\n\"\nAdattiamo il modello parallelo ai dati forniti dagli autori.\nfit_parallel &lt;- sem(m_parallel, data=d)\nCalcoliamo il punteggio totale.\nd$ts &lt;- with(\n  d,\n  X4 + X5 + X6 + X7 + X8 + X9\n)\nCalcoliamo i punteggi fattoriali.\nscores &lt;- lavPredict(fit_parallel, method=\"regression\")\nd$scores &lt;- as.numeric(scores)\nUn diagramma a dispersione tra il punteggio totale e i punteggi fattoriali conferma che i due sono perfettamente associati. Quindi, usare il punteggio totale o i punteggi fattoriali è equivalente.\nd |&gt; \n  ggplot(aes(x=ts, y=scores)) + \n  geom_point()\nTuttavia, questa conclusione è valida solo se il modello parallelo è giustificato per i dati. Se esaminiamo l’output di lavaan vediamo che, nel caso presente, questo non è vero.\n# report output with fit measures and standardized estimates\nout = summary(fit_parallel, fit.measures = TRUE, standardized = TRUE)\nprint(out)\n\nlavaan 0.6.17 ended normally after 13 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n  Number of equality constraints                     5\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                               325.899\n  Degrees of freedom                                19\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               568.519\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.446\n  Tucker-Lewis Index (TLI)                       0.562\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2680.931\n  Loglikelihood unrestricted model (H1)      -2517.981\n                                                      \n  Akaike (AIC)                                5365.862\n  Bayesian (BIC)                              5373.276\n  Sample-size adjusted Bayesian (SABIC)       5366.933\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.232\n  90 Percent confidence interval - lower         0.210\n  90 Percent confidence interval - upper         0.254\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.206\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    X4                1.000                               0.633    0.551\n    X5                1.000                               0.633    0.551\n    X6                1.000                               0.633    0.551\n    X7                1.000                               0.633    0.551\n    X8                1.000                               0.633    0.551\n    X9                1.000                               0.633    0.551\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .X4      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n   .X5      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n   .X6      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n   .X7      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n   .X8      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n   .X9      (thet)    0.920    0.034   27.432    0.000    0.920    0.697\n    f1                0.400    0.045    8.803    0.000    1.000    1.000\nDunque, per questi dati, il punteggio totale può ovviamente essere calcolato. Ma non fornisce una misura adeguata del costrutto. Dunque, il punteggio totale non dovrebbe essere usato nel caso dei dati ottenuti con questo test.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Punteggio totale e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/07_total_score.html#punteggio-totale-e-modello-fattoriale-parallelo",
    "href": "chapters/fa/07_total_score.html#punteggio-totale-e-modello-fattoriale-parallelo",
    "title": "20  Punteggio totale e modello fattoriale",
    "section": "",
    "text": "Paragraph comprehension\nSentence completion\nWord definitions\nSpeeded addition\nSpeeded dot counting\nDiscrimination between curved and straight letters",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Punteggio totale e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/07_total_score.html#punteggio-totale-e-modello-fattoriale-congenerico",
    "href": "chapters/fa/07_total_score.html#punteggio-totale-e-modello-fattoriale-congenerico",
    "title": "20  Punteggio totale e modello fattoriale",
    "section": "20.2 Punteggio totale e modello fattoriale congenerico",
    "text": "20.2 Punteggio totale e modello fattoriale congenerico\nGli autori adattano ai dati un modello congenerico.\n\nm_congeneric &lt;- \n'\n  #all loadings are uniquely estimated\n  f1 =~ NA*X4 + X5 + X6 + X7 + X8 + X9\n  #constrain factor variance to 1\n  f1 ~~ 1*f1\n'\n\n\n# Fit above model\nfit_congeneric &lt;- sem(m_congeneric, data=d)\n\n\nparameterEstimates(fit_congeneric, standardized = TRUE) %&gt;%\n  dplyr::filter(op == \"=~\") %&gt;%\n  dplyr::select(\n    \"Latent Factor\" = lhs,\n    Indicator = rhs,\n    B = est,\n    SE = se,\n    Z = z,\n    \"p-value\" = pvalue,\n    Beta = std.all\n  ) %&gt;%\n  knitr::kable(\n    digits = 3, booktabs = TRUE, format = \"markdown\",\n    caption = \"Factor Loadings\"\n  )\n\n\n\nTable: Factor Loadings\n\n|Latent Factor |Indicator |     B|    SE|      Z| p-value|  Beta|\n|:-------------|:---------|-----:|-----:|------:|-------:|-----:|\n|f1            |X4        | 0.963| 0.059| 16.274|   0.000| 0.824|\n|f1            |X5        | 1.121| 0.067| 16.835|   0.000| 0.846|\n|f1            |X6        | 0.894| 0.058| 15.450|   0.000| 0.792|\n|f1            |X7        | 0.195| 0.071|  2.767|   0.006| 0.170|\n|f1            |X8        | 0.185| 0.063|  2.938|   0.003| 0.180|\n|f1            |X9        | 0.278| 0.065|  4.245|   0.000| 0.258|\n\n\nSi noti che le saturazioni fattoriali sono molto diverse tra loro, suggerendo che il punteggio del costrutto si relaziona in modo diverso con ciascun item e che sarebbe inappropriato stimare il punteggio del costrutto assegnando un peso unitario agli item.\nMcNeish e Wolf (2020) calcolano poi i punteggi fattoriali del modello congenerico.\n\nscores_cong &lt;- lavPredict(fit_congeneric, method=\"regression\")\nd$scores_cong &lt;- as.numeric(scores_cong)\n\nIl grafico seguente mostra la relazione tra i punteggi fattoriali e il punteggio totale.\n\nd |&gt; \n  ggplot(aes(x=ts, y=scores_cong)) + \n  geom_point()\n\n\n\n\n\n\n\n\nNel caso presente, il coefficiente di determinazione tra punteggio totale e punteggi fattoriali è 0.77.\n\ncor(d$ts, d$scores_cong)^2\n\n0.765992021080728\n\n\nSecondo gli autori, ciò significa che due persone con un punteggio totale identico potrebbero avere punteggi di modello congenerico potenzialmente diversi perché hanno raggiunto il loro particolare punteggio totale approvando item diversi. Poiché il modello congenerico assegna pesi diversi agli item, ciascun item contribuisce in modo diverso al punteggio fattoriale del modello congenerico, il che non è vero per il punteggio totale.\nSi noti che, per i dati di Holzinger and Swineford (1939), neppure un modello congenerico ad un fattore si dimostra adeguato.\n\nout = summary(fit_congeneric, fit.measures = TRUE, standardized = TRUE)\nprint(out)\n\nlavaan 0.6.17 ended normally after 16 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                               115.366\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               568.519\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.808\n  Tucker-Lewis Index (TLI)                       0.680\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2575.664\n  Loglikelihood unrestricted model (H1)      -2517.981\n                                                      \n  Akaike (AIC)                                5175.328\n  Bayesian (BIC)                              5219.813\n  Sample-size adjusted Bayesian (SABIC)       5181.756\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.198\n  90 Percent confidence interval - lower         0.167\n  90 Percent confidence interval - upper         0.231\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.129\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    X4                0.963    0.059   16.274    0.000    0.963    0.824\n    X5                1.121    0.067   16.835    0.000    1.121    0.846\n    X6                0.894    0.058   15.450    0.000    0.894    0.792\n    X7                0.195    0.071    2.767    0.006    0.195    0.170\n    X8                0.185    0.063    2.938    0.003    0.185    0.180\n    X9                0.278    0.065    4.245    0.000    0.278    0.258\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    f1                1.000                               1.000    1.000\n   .X4                0.437    0.056    7.775    0.000    0.437    0.320\n   .X5                0.500    0.071    6.998    0.000    0.500    0.285\n   .X6                0.474    0.054    8.777    0.000    0.474    0.372\n   .X7                1.278    0.105   12.211    0.000    1.278    0.971\n   .X8                1.023    0.084   12.204    0.000    1.023    0.967\n   .X9                1.080    0.089   12.132    0.000    1.080    0.933\n\n\n\nSe trascuriamo le considerazioni sulla struttura fattoriale e esaminiamo (per esempio) unicamente il coefficiente omega, finiamo per trovare una risposta accettabile, ma sbagliata.\n\npsych::omega(d[, 1:6])\n\nCaricamento dei namespace richiesti: GPArotation\n\n\n\nOmega \nCall: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n    digits = digits, title = title, sl = sl, labels = labels, \n    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n    covar = covar)\nAlpha:                 0.72 \nG.6:                   0.76 \nOmega Hierarchical:    0.55 \nOmega H asymptotic:    0.65 \nOmega Total            0.84 \n\nSchmid Leiman Factor loadings greater than  0.2 \n      g  F1*  F2*   F3*   h2   u2   p2\nX4 0.73            0.68 1.00 0.00 0.53\nX5 0.96                 0.92 0.08 1.00\nX6 0.69            0.22 0.54 0.46 0.90\nX7           0.56       0.33 0.67 0.03\nX8           0.75       0.59 0.41 0.05\nX9 0.22      0.49       0.29 0.71 0.16\n\nWith Sums of squares  of:\n   g  F1*  F2*  F3* \n2.02 0.00 1.11 0.54 \n\ngeneral/max  1.82   max/min =   257.39\nmean percent general =  0.44    with sd =  0.43 and cv of  0.97 \nExplained Common Variance of the general factor =  0.55 \n\nThe degrees of freedom are 0  and the fit is  0 \nThe number of observations was  301  with Chi Square =  0.03  with prob &lt;  NA\nThe root mean square of the residuals is  0 \nThe df corrected root mean square of the residuals is  NA\n\nCompare this with the adequacy of just a general factor and no group factors\nThe degrees of freedom for just the general factor are 9  and the fit is  0.48 \nThe number of observations was  301  with Chi Square =  142.26  with prob &lt;  3.5e-26\nThe root mean square of the residuals is  0.17 \nThe df corrected root mean square of the residuals is  0.21 \n\nRMSEA index =  0.222  and the 10 % confidence intervals are  0.191 0.255\nBIC =  90.9 \n\nMeasures of factor score adequacy             \n                                                 g   F1*  F2*  F3*\nCorrelation of scores with factors            0.96  0.08 0.83 0.96\nMultiple R square of scores with factors      0.93  0.01 0.68 0.91\nMinimum correlation of factor score estimates 0.86 -0.99 0.36 0.83\n\n Total, General and Subset omega for each subset\n                                                 g  F1*  F2*  F3*\nOmega total for total scores and subscales    0.84 0.92 0.66 0.86\nOmega general for total scores and subscales  0.55 0.92 0.04 0.61\nOmega group for total scores and subscales    0.27 0.00 0.61 0.25\n\n\n\n\n\n\n\n\n\nÈ invece necessario ipotizzare un modello congenerico a due fattori.\n\nm2f_cong &lt;- '\n  # all loadings are uniquely estimated on each factor\n  f1 =~ NA*X4 + X5 + X6\n  f2 =~ NA*X7 + X8 + X9\n  \n  # constrain factor variancse to 1\n  f1 ~~ 1*f1\n  f2 ~~ 1*f2\n  \n  # estimate factor covariance\n  f1 ~~ f2\n'\n\n\n# Fit above model\nfit_2f_congeneric &lt;- sem(m2f_cong, data=d)\n\nSolo questo modello fornisce un adattamento adeguato ai dati.\n\nout = summary(fit_2f_congeneric, fit.measures = TRUE, standardized = TRUE)\nprint(out)\n\nlavaan 0.6.17 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                                14.736\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.064\n\nModel Test Baseline Model:\n\n  Test statistic                               568.519\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.988\n  Tucker-Lewis Index (TLI)                       0.977\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2525.349\n  Loglikelihood unrestricted model (H1)      -2517.981\n                                                      \n  Akaike (AIC)                                5076.698\n  Bayesian (BIC)                              5124.891\n  Sample-size adjusted Bayesian (SABIC)       5083.662\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.053\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.095\n  P-value H_0: RMSEA &lt;= 0.050                    0.402\n  P-value H_0: RMSEA &gt;= 0.080                    0.159\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.035\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    X4                0.965    0.059   16.296    0.000    0.965    0.826\n    X5                1.123    0.067   16.845    0.000    1.123    0.847\n    X6                0.895    0.058   15.465    0.000    0.895    0.793\n  f2 =~                                                                 \n    X7                0.659    0.080    8.218    0.000    0.659    0.575\n    X8                0.733    0.077    9.532    0.000    0.733    0.712\n    X9                0.599    0.075    8.025    0.000    0.599    0.557\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2                0.275    0.072    3.813    0.000    0.275    0.275\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    f1                1.000                               1.000    1.000\n    f2                1.000                               1.000    1.000\n   .X4                0.433    0.056    7.679    0.000    0.433    0.318\n   .X5                0.496    0.072    6.892    0.000    0.496    0.282\n   .X6                0.472    0.054    8.732    0.000    0.472    0.371\n   .X7                0.881    0.100    8.807    0.000    0.881    0.670\n   .X8                0.521    0.094    5.534    0.000    0.521    0.492\n   .X9                0.798    0.087    9.162    0.000    0.798    0.689\n\n\n\nNel contesto di questi dati, l’utilizzo di un modello congenerico non è sufficiente a giustificare l’impiego del punteggio totale, che rappresenta la somma dei punteggi degli item. Questo perché, nel caso specifico, sommando i punteggi di tutti gli item, finiremmo per includere misurazioni di due costrutti distinti.",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Punteggio totale e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/fa/07_total_score.html#session-info",
    "href": "chapters/fa/07_total_score.html#session-info",
    "title": "20  Punteggio totale e modello fattoriale",
    "section": "20.3 Session Info",
    "text": "20.3 Session Info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] modelsummary_1.4.5 ggokabeito_0.1.0   viridis_0.6.5      viridisLite_0.4.2 \n [5] ggpubr_0.6.0       ggExtra_0.10.1     bayesplot_1.11.1   gridExtra_2.3     \n [9] patchwork_1.2.0    semTools_0.5-6     semPlot_1.1.6      lavaan_0.6-17     \n[13] psych_2.4.1        scales_1.3.0       markdown_1.12      knitr_1.45        \n[17] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[21] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[25] ggplot2_3.4.4      tidyverse_2.0.0    here_1.0.1        \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5   nloptr_2.0.3      \n  [7] rmarkdown_2.25     vctrs_0.6.5        minqa_1.2.6       \n [10] base64enc_0.1-3    rstatix_0.7.2      htmltools_0.5.7   \n [13] broom_1.0.5        Formula_1.2-5      htmlwidgets_1.6.4 \n [16] plyr_1.8.9         sandwich_3.1-0     emmeans_1.10.0    \n [19] zoo_1.8-12         uuid_1.2-0         igraph_2.0.2      \n [22] mime_0.12          lifecycle_1.0.4    pkgconfig_2.0.3   \n [25] Matrix_1.6-5       R6_2.5.1           fastmap_1.1.1     \n [28] shiny_1.8.0        digest_0.6.34      OpenMx_2.21.11    \n [31] fdrtool_1.2.17     colorspace_2.1-0   rprojroot_2.0.4   \n [34] Hmisc_5.1-1        fansi_1.0.6        timechange_0.3.0  \n [37] abind_1.4-5        compiler_4.3.2     withr_3.0.0       \n [40] glasso_1.11        htmlTable_2.4.2    backports_1.4.1   \n [43] carData_3.0-5      ggsignif_0.6.4     MASS_7.3-60.0.1   \n [46] corpcor_1.6.10     gtools_3.9.5       tools_4.3.2       \n [49] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [52] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [55] quadprog_1.5-8     nlme_3.1-164       promises_1.2.1    \n [58] lisrelToR_0.3      grid_4.3.2         pbdZMQ_0.3-11     \n [61] checkmate_2.3.1    cluster_2.1.6      reshape2_1.4.4    \n [64] generics_0.1.3     gtable_0.3.4       tzdb_0.4.0        \n [67] data.table_1.15.0  hms_1.1.3          car_3.1-2         \n [70] utf8_1.2.4         tables_0.9.17      sem_3.1-15        \n [73] pillar_1.9.0       IRdisplay_1.1      rockchalk_1.8.157 \n [76] later_1.3.2        splines_4.3.2      lattice_0.22-5    \n [79] survival_3.5-8     kutils_1.73        tidyselect_1.2.0  \n [82] miniUI_0.1.1.1     pbapply_1.7-2      stats4_4.3.2      \n [85] xfun_0.42          qgraph_1.9.8       arm_1.13-1        \n [88] stringi_1.8.3      boot_1.3-29        evaluate_0.23     \n [91] codetools_0.2-19   mi_1.1             cli_3.6.2         \n [94] RcppParallel_5.1.7 IRkernel_1.3.2     rpart_4.1.23      \n [97] xtable_1.8-4       repr_1.1.6         munsell_0.5.0     \n[100] Rcpp_1.0.12        coda_0.19-4.1      png_0.1-8         \n[103] XML_3.99-0.16.1    parallel_4.3.2     ellipsis_0.3.2    \n[106] jpeg_0.1-10        lme4_1.1-35.1      mvtnorm_1.2-4     \n[109] insight_0.19.8     openxlsx_4.2.5.2   crayon_1.5.2      \n[112] rlang_1.1.3        multcomp_1.4-25    mnormt_2.1.1",
    "crumbs": [
      "Analisi fattoriale",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Punteggio totale e modello fattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice A — Sommatorie",
    "section": "",
    "text": "A.1 Manipolazione di somme\nÈ conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l’operatore della sommatoria.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice A — Sommatorie",
    "section": "",
    "text": "A.1.1 Proprietà 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\nA.1.2 Proprietà 2 (proprietà distributiva)\nNel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\nè possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nA.1.3 Proprietà 3 (proprietà associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nÈ dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nA.1.4 Proprietà 4\nSe deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nA.1.5 Proprietà 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice A — Sommatorie",
    "section": "A.2 Doppia sommatoria",
    "text": "A.2 Doppia sommatoria\nÈ possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria è il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria in \\(j\\) non dipende dall’indice \\(i\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n} x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_probability.html",
    "href": "chapters/appendix/solutions_probability.html",
    "title": "Appendice B — Probabilità",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nimport math\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\n?sec-prob-on-general-spaces\n?exr-prob-on-general-spaces-1\nPer calcolare questa probabilità in maniera analitica, utilizziamo la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dal gruppo di 20 è dato da:\n\\[\n\\binom{20}{5} = \\frac{20!}{5!(15!)} = 15,504.\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione (ovvero, selezionare solo psicologi del lavoro) è:\n\\[\n\\binom{10}{0} \\times \\binom{10}{5} = 1 \\times 252 = 252.\n\\]\nQuindi, la probabilità di avere nessun psicologo clinico è:\n\\[\nP(\\text{nessun psicologo clinico}) = \\frac{252}{15,504} \\approx 0.016.\n\\]\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione è:\n\\[\n\\binom{10}{1} \\times \\binom{10}{4} = 10 \\times 210 = 2,100.\n\\]\nQuindi, la probabilità di avere esattamente 1 psicologo clinico è:\n\\[\nP(\\text{1 psicologo clinico}) = \\frac{2,100}{15,504} \\approx 0.135.\n\\]\nLa probabilità di avere almeno 2 psicologi clinici nella commissione è quindi:\n\\[\n\\begin{align}\nP(\\text{almeno 2 psicologi clinici}) &= 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}) \\notag\\\\\n&= 1 - 0.016 - 0.135 \\notag\\\\\n&= 0.848.\\notag\n\\end{align}\n\\]\nQuindi, la probabilità che almeno 2 psicologi clinici siano nella commissione è circa 0.848.\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n\n# Calcolo delle probabilità per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilità di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilità di almeno 2 psicologi clinici: 0.848\n\n\nIn maniera più intuitiva, possiamo risolvere il problema con una simulazione Monte Carlo.\n\nimport random\n\n# Numero di simulazioni\nsimulations = 1000000\n\n# Numero di successi (almeno 2 psicologi clinici nella commissione)\nsuccess_count = 0\n\n# Creiamo una lista che rappresenta il gruppo di 20 persone\n# 1 rappresenta un psicologo clinico, 0 rappresenta un psicologo del lavoro\ngroup = [1] * 10 + [0] * 10\n\n# Simulazione Monte Carlo\nfor _ in range(simulations):\n    # Estrai casualmente 5 persone dal gruppo\n    committee = random.sample(group, 5)\n\n    # Conta quanti psicologi clinici ci sono nella commissione\n    num_clinical_psychologists = sum(committee)\n\n    # Verifica se ci sono almeno 2 psicologi clinici\n    if num_clinical_psychologists &gt;= 2:\n        success_count += 1\n\n# Calcola la probabilità\nprobability = success_count / simulations\n\n# Mostra il risultato\nprint(\n    f\"La probabilità che almeno 2 psicologi clinici siano nella commissione è: {probability:.4f}\"\n)\n\nLa probabilità che almeno 2 psicologi clinici siano nella commissione è: 0.8482\n\n\n\n\n?sec-simulations\n?exr-prob-simulation-1\nPer calcolare le deviazioni standard delle distribuzioni gaussiane date le percentuali di studenti che ottengono meno di 18, possiamo utilizzare le proprietà della distribuzione normale e i quantili della distribuzione normale standard (distribuzione normale con media 0 e deviazione standard 1).\nLe distribuzioni normali hanno la proprietà che possiamo trasformare qualsiasi valore \\(X\\) della distribuzione \\(N(\\mu, \\sigma)\\) nella distribuzione normale standard \\(N(0, 1)\\) tramite la formula:\n\\[ Z = \\frac{X - \\mu}{\\sigma}, \\]\ndove \\(Z\\) è il quantile standardizzato.\nPer trovare il valore di \\(\\sigma\\) dato un certo percentile, utilizziamo l’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale standard. Per un dato percentile \\(p\\), \\(z_p\\) è tale che:\n\\[ p = P(Z \\leq z_p) \\]\nQuindi possiamo trovare \\(\\sigma\\) risolvendo per \\(\\sigma\\) nella formula:\n\\[ z_p = \\frac{X - \\mu}{\\sigma}, \\]\n\\[ \\sigma = \\frac{X - \\mu}{z_p}, \\]\ndove:\n\n\\(X\\) è il punteggio di soglia (18 in questo caso).\n\\(\\mu\\) è la media della distribuzione.\n\\(z_p\\) è il quantile della distribuzione normale standard per il percentile \\(p\\).\n\nI quantili della distribuzione normale standard per i percentili desiderati sono:\n\nPer il 15%, il quantile è \\(z_{0.15} \\approx -1.036\\).\nPer il 10%, il quantile è \\(z_{0.10} \\approx -1.281\\).\nPer il 5%, il quantile è \\(z_{0.05} \\approx -1.645\\).\n\nPrima Prova\n\nMedia: \\(\\mu = 24\\)\nPercentuale che ottiene meno di 18: 15%\nQuantile: \\(z_{0.15} = -1.036\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_1 = \\frac{24 - 18}{1.036} \\approx 5.79 \\]\nSeconda Prova\n\nMedia: \\(\\mu = 25\\)\nPercentuale che ottiene meno di 18: 10%\nQuantile: \\(z_{0.10} = -1.281\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_2 = \\frac{25 - 18}{1.281} \\approx 5.46 \\]\nTerza Prova\n\nMedia: \\(\\mu = 26\\)\nPercentuale che ottiene meno di 18: 5%\nQuantile: \\(z_{0.05} = -1.645\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_3 = \\frac{26 - 18}{1.645} \\approx 4.86 \\]\n\n# Funzione per calcolare la deviazione standard data la media, la soglia e il quantile\ndef calculate_std(mean, threshold, quantile):\n    return abs((mean - threshold) / quantile)\n\n\n# Parametri delle distribuzioni gaussiane per le tre prove\nmean_test1 = 24\nstd_test1 = calculate_std(mean_test1, 18, -1.036)\nmean_test2 = 25\nstd_test2 = calculate_std(mean_test2, 18, -1.281)\nmean_test3 = 26\nstd_test3 = calculate_std(mean_test3, 18, -1.645)\n\n# Numero di studenti\nn_students = 220\n\n# Percentuale di studenti che non fa le prove\ndrop_test1 = 0.10\ndrop_test2 = 0.05\n\n# Seed per il generatore di numeri casuali basato sulla stringa \"simulation\"\nseed = sum(map(ord, \"simulation\"))\nrng = np.random.default_rng(seed=seed)\n\n# Generazione dei voti per le tre prove\n# Genera i voti solo per gli studenti che partecipano alla prova\ntest1_scores = np.where(\n    rng.random(n_students) &gt; drop_test1,\n    rng.normal(mean_test1, std_test1, n_students),\n    np.nan,\n)\ntest2_scores = np.where(\n    rng.random(n_students) &gt; drop_test2,\n    rng.normal(mean_test2, std_test2, n_students),\n    np.nan,\n)\ntest3_scores = rng.normal(mean_test3, std_test3, n_students)\n\n# Calcola il voto finale solo per gli studenti che hanno partecipato a tutte e tre le prove\nfinal_scores = np.nanmean(\n    np.column_stack((test1_scores, test2_scores, test3_scores)), axis=1\n)\n\n# Filtra gli studenti che non hanno partecipato a tutte e tre le prove\nvalid_final_scores = final_scores[~np.isnan(final_scores)]\n\n# Visualizzazione della distribuzione finale dei voti\nplt.hist(valid_final_scores, bins=30, edgecolor=\"black\")\nplt.title(\"Distribuzione dei voti finali\")\nplt.xlabel(\"Voto finale\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n# Statistiche descrittive dei voti finali\nmean_final_score = np.mean(valid_final_scores)\nmedian_final_score = np.median(valid_final_scores)\nstd_final_score = np.std(valid_final_scores)\n\nprint(f\"Media dei voti finali: {mean_final_score:.2f}\")\nprint(f\"Mediana dei voti finali: {median_final_score:.2f}\")\nprint(f\"Deviazione standard dei voti finali: {std_final_score:.2f}\")",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Probabilità</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Testing Psicologico",
    "section": "",
    "text": "Benvenuti\nQuesto sito web è dedicato al materiale didattico dell’insegnamento di Testing Psicologico (A.A. 2024/2025), rivolto agli studenti del primo anno del Corso di Laurea Magistrale PSICOLOGIA CLINICA E DELLA SALUTE E NEUROPSICOLOGIA dell’Università degli Studi di Firenze.\nL’insegnamento si propone quale stimolo e guida per l’apprendimento delle basi dell’assessment psicologico.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#informazioni-sullinsegnamento",
    "href": "index.html#informazioni-sullinsegnamento",
    "title": "Testing Psicologico",
    "section": "Informazioni sull’insegnamento",
    "text": "Informazioni sull’insegnamento\n\n\nCodice: B033288 - TESTING PSICOLOGICO \n\nModulo: B033288 - TESTING PSICOLOGICO (Cognomi L-Z) \n\nCorso di laurea: Laurea Magistrale: PSICOLOGIA CLINICA E DELLA SALUTE E NEUROPSICOLOGIA \n\nAnno Accademico: 2024-2025 \n\nCalendario: Il corso si terrà dal 3 marzo al 31 maggio 2025.\n\nOrario delle lezioni: Le lezioni si svolgeranno il lunedì e il martedì dalle 8:30 alle 10:30 e il giovedì dalle 11:30 alle 13:30.\n\nLuogo: Le lezioni si terranno presso il Plesso didattico La Torretta.\n\nModalità di svolgimento della didattica: Le lezioni ed esercitazioni saranno svolte in modalità frontale.\n\n\n\n\n\n\n\nIl presente sito web costituisce l’unica fonte ufficiale da consultare per ottenere informazioni sul programma dell’insegnamento B033288 - TESTING PSICOLOGICO (Cognomi A-K) A.A. 2024-2025 e sulle modalità d’esame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Testing Psicologico",
    "section": "Syllabus",
    "text": "Syllabus\nIl Syllabus può essere scaricato utilizzando questo link.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Definizione di misurazione\nLa misurazione psicologica è un pilastro fondamentale nella comprensione e nell’analisi del comportamento umano, fornendo un mezzo quantitativo per esplorare le dinamiche della mente e della personalità. La definizione di misurazione proposta da Stevens (1951), uno dei pionieri della teoria della misurazione, stabilisce che essa consiste nell’assegnare numeri a oggetti o eventi secondo regole definite. Tuttavia, è ormai ampiamente accettato che questa visione sia troppo semplicistica e che la misurazione richieda un approccio più sofisticato. Si concorda comunemente sul fatto che la misurazione debba essere considerata come un processo di creazione di modelli che rappresentano i fenomeni di interesse, principalmente in forma quantitativa.\nDi conseguenza, la misurazione si basa su regole che attribuiscono scale o valori alle entità che rappresentano i costrutti di interesse. Come avviene per tutti i modelli, quelli di misurazione, come i test, le scale o le variabili, devono semplificare la realtà per risultare utili. Pertanto, è fondamentale specificare chiaramente i modelli di misurazione per poterli valutare, confutare e migliorare.\nInoltre, anziché chiedersi se un modello sia vero o corretto, è più utile sviluppare diversi modelli alternativi plausibili e porre domande del tipo: quale modello è meno inaccurato? Questo approccio al confronto dei modelli rappresenta la strategia migliore per valutare e perfezionare le procedure di misurazione, consentendo un’analisi più approfondita e accurata delle variabili coinvolte.\nPer illustrare l’approccio alla misurazione come descritto, prendiamo in considerazione un esempio concreto: la valutazione dell’intelligenza attraverso il test del quoziente intellettivo (QI).\nIniziamo definendo il concetto di interesse, ovvero l’intelligenza, che può essere concepita come la capacità di apprendere, comprendere e applicare conoscenze, risolvere problemi e adattarsi a nuove situazioni. Tuttavia, trattandosi di un concetto astratto, è necessario operazionalizzarlo in modo misurabile.\nPer misurare l’intelligenza, si crea un test di QI che comprende una serie di compiti e domande progettati per valutare diverse dimensioni della capacità cognitiva, quali la memoria, il ragionamento logico e la comprensione verbale.\nCiascun compito nel test di QI è associato a un punteggio. I risultati individuali vengono quindi calcolati e confrontati con una norma statistica per attribuire un punteggio di QI.\nSuccessivamente, il test di QI viene sottoposto a diverse analisi per verificare la sua validità (ovvero se misura effettivamente l’intelligenza) e affidabilità (se fornisce risultati consistenti nel tempo).\nTuttavia, esistono diverse teorie dell’intelligenza, come ad esempio quella delle intelligenze multiple di Gardner, che suggeriscono modelli alternativi di misurazione. Confrontando il modello del QI con questi approcci alternativi, gli psicologi possono valutare quale modello è meno distorto o più adatto per specifici scopi.\nIn risposta alle critiche, alle nuove scoperte e ai cambiamenti culturali e sociali, il modello del QI viene regolarmente rivisto e adattato per assicurare che continui a essere uno strumento utile di misurazione.\nQuesto esempio mostra come la misurazione in psicologia non sia semplicemente un atto di assegnare numeri a un costrutto, ma piuttosto un processo complesso che implica la creazione, la valutazione e il continuo perfezionamento di modelli teorici.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#temi-centrali-nellapproccio-psicometrico",
    "href": "prefazione.html#temi-centrali-nellapproccio-psicometrico",
    "title": "Prefazione",
    "section": "Temi Centrali nell’Approccio Psicometrico",
    "text": "Temi Centrali nell’Approccio Psicometrico\n\nAffidabilità: Questo concetto si riferisce alla capacità di un test di produrre risultati consistenti nel tempo e in contesti diversi, costituendo una base fondamentale per la misurazione psicologica.\nValidazione del Costrutto e Test dei Modelli: L’evoluzione della psicometria ha portato a una sempre maggiore enfasi sulla validazione dei costrutti e sull’importanza dei test di modelli, utilizzando tecniche come i modelli a equazioni strutturali (SEM) per verificare la coerenza e la validità dei costrutti psicologici.\nDimensionalità e Validità Strutturale: La dimensionalità viene considerata un elemento fondamentale nella valutazione della validità strutturale, poiché permette di esplorare come i diversi aspetti di un costrutto si manifestano e interagiscono all’interno del modello di misurazione.\nCostruzione dei Questionari: La progettazione e la formulazione degli item dei questionari rivestono un ruolo cruciale, in quanto influenzano direttamente l’affidabilità e la validità dei risultati ottenuti. La scelta degli item, il loro ordine e la chiarezza della formulazione sono tutti aspetti che contribuiscono alla qualità e all’efficacia della misurazione psicologica.\n\nAttraverso questi approcci, la misurazione psicologica si adatta alle sfide uniche poste dalla natura astratta e complessa dei costrutti psicologici, cercando di fornire strumenti validi e affidabili per la loro esplorazione e comprensione.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#affidabilità-e-generalizzabilità-nelle-misure-psicologiche",
    "href": "prefazione.html#affidabilità-e-generalizzabilità-nelle-misure-psicologiche",
    "title": "Prefazione",
    "section": "Affidabilità e Generalizzabilità nelle Misure Psicologiche",
    "text": "Affidabilità e Generalizzabilità nelle Misure Psicologiche\nNel contesto della misurazione psicologica, così come in altre discipline, è cruciale considerare le variabili che possono influenzare la precisione delle misure. L’affidabilità di uno strumento di misurazione psicologica si riferisce alla sua consistenza nel produrre risultati replicabili nel tempo e in contesti diversi. Gli indici di affidabilità sono utilizzati per quantificare il grado di riproducibilità e l’assenza di errori casuali nelle misurazioni.\n\nTeoria Classica dei Test\nL’approccio più ampiamente utilizzato nello studio dell’affidabilità delle misure psicologiche è rappresentato dalla teoria classica dei test, come descritto da Lord e Novick (1968). Secondo questa teoria, ogni misurazione (\\(X\\)) è composta da due componenti distintive: un punteggio “vero” (\\(T\\)) e un errore di misurazione (\\(e\\)). Il concetto di misurazione accurata, o “vera”, può essere rappresentato come \\(X - e\\), evidenziando il fatto che ogni misurazione può essere decomposta in tali elementi distinti.\nLa teoria classica dei test enfatizza l’importanza di condurre misurazioni ripetute per valutare l’affidabilità. Un concetto fondamentale è quello dei test paralleli, che consistono in due test con medie, varianze e distribuzioni identiche, e che mostrano una correlazione simile con variabili esterne. In questa prospettiva, il punteggio vero e l’errore di misurazione sono considerati indipendenti. Di conseguenza, la varianza dei punteggi osservati (Varianza \\(X\\)) è la somma della varianza dei punteggi veri (Varianza \\(T\\)) e della varianza dell’errore di misurazione (Varianza \\(e\\)).\nL’affidabilità è quindi definita come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato:\n\\[\n\\text{Affidabilità} = \\frac{\\text{Varianza}(T)}{\\text{Varianza}(X)}.\n\\]\nIn termini pratici, un’affidabilità di 1 indicherebbe l’assenza di errori, mentre un’affidabilità di 0 implicherebbe che i punteggi derivano esclusivamente dall’errore. La correlazione tra il punteggio osservato e il punteggio vero è la radice quadrata dell’affidabilità, fornendo una stima della precisione della misurazione.\nQuesto framework fornisce una solida base per comprendere e quantificare l’affidabilità nelle misure psicologiche, sottolineando l’importanza di considerare sia i punteggi veri sia gli errori di misurazione per ottenere misurazioni precise e affidabili.\n\n\nEvidenze Multiple di Affidabilità\nNonostante la teoria classica dei test fornisca una definizione matematica dei test paralleli, non fornisce dettagliate linee guida sulle procedure specifiche per costruirli. Tuttavia, a partire dagli anni ’50, sono stati sviluppati diversi metodi che consentono di valutare empiricamente l’affidabilità delle misurazioni:\n\nTest-Retest: Questo approccio implica la somministrazione dello stesso test ai partecipanti in due momenti diversi. L’obiettivo è valutare la stabilità dei punteggi nel tempo. Una correlazione elevata tra i punteggi ottenuti nei due momenti indica una buona affidabilità del test-retest.\nEquivalenza di Forme Parallele: Questo metodo prevede l’utilizzo di due versioni diverse del test, ma che coprono lo stesso contenuto, somministrate simultaneamente ai partecipanti. Una forte correlazione tra i punteggi ottenuti dalle due versioni suggerisce che entrambe misurano il medesimo costrutto in modo affidabile.\nSplit-Half e Coerenza Interna:\n\nSplit-Half: I partecipanti completano una sola versione del test, la quale è divisa in due parti equivalenti. Si calcola poi la correlazione tra i punteggi delle due metà. Questo metodo valuta la coerenza interna del test.\nCoerenza Interna (ad esempio, Omega di McDonals): Valuta la correlazione tra tutti gli elementi del test. Un alto valore di coerenza interna indica che tutti gli elementi del test misurano aspetti simili del costrutto.\n\nValutazione da Giudici Multipli: In questo caso, i partecipanti sono valutati da più giudici in un’unica occasione. Un alto grado di accordo tra i giudici fornisce un’indicazione dell’affidabilità delle valutazioni.\n\nCiascuno di questi approcci fornisce indicazioni sull’affidabilità di un test, ma è fondamentale considerare che alcuni potrebbero essere più appropriati di altri in base alla natura del test e del costrutto misurato. L’affidabilità è pertanto un concetto multidimensionale che richiede l’impiego di diversi approcci per una valutazione completa delle misurazioni psicologiche.\n\n\nIl Ruolo del Coefficiente Alpha nella Misurazione Psicologica\nIl coefficiente alpha, introdotto da Cronbach nel 1951, è diventato un importante indicatore di coerenza interna nella letteratura psicologica, principalmente grazie alla sua facilità di calcolo. A differenza dell’affidabilità test-retest, che richiede dati raccolti in due momenti diversi, o dell’affidabilità delle forme parallele, che richiede la costruzione di due versioni alternative di un test, il coefficiente alpha può essere calcolato utilizzando un unico set di dati, rendendolo estremamente pratico come indice di affidabilità.\nTuttavia, è importante correggere un comune malinteso riguardo al coefficiente alpha: esso non misura direttamente l’omogeneità delle intercorrelazioni tra gli elementi o conferma la unidimensionalità di una scala. In realtà, il coefficiente alpha non fornisce informazioni dirette su questi aspetti strutturali della scala.\nPer affrontare la questione della unidimensionalità, è necessario ricorrere a approcci più sofisticati come l’analisi fattoriale confermativa e i modelli di equazioni strutturali (SEM). Questi metodi consentono di testare quanto bene la struttura di correlazione degli elementi si adatti a un modello con un singolo fattore rispetto a modelli multifattoriali, valutando se le correlazioni tra gli elementi possono essere meglio spiegate da un singolo costrutto sottostante.\nNel contesto delle analisi SEM, le saturazioni degli item indicano quanto della varianza di un item sia condivisa con gli altri (e quindi generalizzabile), mentre la varianza residua dell’item cattura l’errore unico associato a quell’item. La presenza di multidimensionalità emerge dalla capacità di un modello multifattoriale di adattarsi meglio ai dati rispetto a un modello a singolo fattore.\nQuando un test è considerato multidimensionale, è ancora appropriato utilizzare il coefficiente alpha come indice di affidabilità? La risposta è negativa. In presenza di multidimensionalità, il coefficiente alpha tende a sottostimare l’affidabilità. Pertanto, è consigliabile, in tali casi, utilizzare altri metodi per valutare l’affidabilità, anziché basarsi esclusivamente sul coefficiente alpha.\n\n\nIl Fenomeno dell’Attenuazione in Relazione all’Affidabilità\nAll’interno del contesto della teoria classica dei test, come delineato da Lord e Novick (1968), l’affidabilità svolge un ruolo cruciale poiché influisce sulla forza della correlazione che una misura può mostrare con altre variabili, come un criterio esterno. Secondo questa teoria, se l’errore nelle misurazioni è genuinamente casuale, il massimo teorico della correlazione tra una misura e un’altra variabile non è 1.0, ma piuttosto la radice quadrata dell’affidabilità di quella misura.\nCiò implica che, in presenza di un’affidabilità meno che ottimale, la correlazione effettiva tra una misura e qualsiasi altra variabile viene sistematicamente sottostimata, fenomeno noto come attenuazione. Questa attenuazione è direttamente proporzionale all’inadeguatezza dell’affidabilità: più bassa è l’affidabilità di una misura, maggiore sarà la sottostima della sua correlazione con altre variabili. Pertanto, per ottenere stime accurate delle correlazioni e comprendere veramente le relazioni tra diverse variabili, è fondamentale garantire che le misure utilizzate siano il più affidabili possibile. Questa considerazione enfatizza l’importanza dell’accuratezza e della precisione nelle procedure di misurazione psicologica.\n\n\nLa Teoria della Generalizzabilità\nLa Teoria della Generalizzabilità propone un approccio più completo e flessibile per comprendere l’affidabilità delle misure psicologiche rispetto alla classificazione tradizionale delle tipologie di affidabilità. Invece di limitarsi a categorizzare le misure in base a criteri specifici come test-retest, affidabilità interna o inter-valutatori, la Teoria della Generalizzabilità considera una serie di dimensioni che possono influenzare l’affidabilità in contesti diversi.\nUna delle principali criticità della teoria classica dei test è la sua presunzione di uniformità e parallelismo delle misurazioni e degli errori casuali. La Teoria della Generalizzabilità, al contrario, riconosce che l’affidabilità dipende dalla specifica dimensione di generalizzazione considerata. Ad esempio, un test potrebbe essere affidabile per misurare una certa caratteristica in un contesto, ma non altrettanto affidabile in un contesto diverso o per una caratteristica correlata ma non identica.\nPer superare le limitazioni della teoria classica dei test, l’American Psychological Association ha proposto l’adozione della Teoria della Generalizzabilità. Tuttavia, nonostante questa proposta, la pratica nei campi di ricerca non si è adeguatamente evoluta e la teoria della generalizzabilità non ha ancora completamente sostituito le nozioni più semplicistiche popolari in psicologia.\nLa Teoria della Generalizzabilità esamina diverse dimensioni che influenzano l’affidabilità, tra cui la dimensione temporale, delle forme, degli item e dei giudici o osservatori. Questa teoria enfatizza l’importanza di estendere le osservazioni a un’ampia varietà di situazioni e identificare l’impatto specifico delle fonti di varianza nei punteggi dei test in contesti particolari.\nInvece dei tradizionali coefficienti di affidabilità come il coefficiente di stabilità o il coefficiente alfa, la Teoria della Generalizzabilità suggerisce l’uso di misure più ampie di affidabilità, come il coefficiente di correlazione intraclasse, per esaminare specifici aspetti dell’affidabilità. Questo approccio è particolarmente utile in ricerche con dati strutturati in maniera nidificata e dove diverse dimensioni possono influenzare l’affidabilità, come nei metodi di valutazione ecologica momentanea.### La Teoria della Risposta agli Item\nLa Teoria della Risposta agli Item (IRT) rappresenta un avanzamento rispetto alla teoria classica dei test, offrendo un approccio più sofisticato per analizzare le risposte degli individui agli item e la loro relazione con un costrutto latente. Questa teoria stabilisce un collegamento tra le risposte degli individui a un particolare item e il costrutto latente utilizzando una funzione chiamata “curva caratteristica dell’item”.\nLa curva caratteristica dell’item mostra la probabilità che individui con differenti livelli del costrutto latente rispondano correttamente all’item, fornendo inoltre informazioni sulla capacità dell’item di distinguere tra individui con livelli elevati e bassi del tratto latente, oltre a misurare la sua difficoltà. Queste informazioni sono cruciali per identificare eventuali distorsioni negli item, noto come bias. Secondo la IRT, un item è privo di bias nel misurare un costrutto se individui con lo stesso livello del tratto ottengono punteggi attesi simili sull’item, indipendentemente da caratteristiche non rilevanti come genere, etnia o background culturale.\nLa Teoria della Risposta agli Item offre diversi vantaggi nel processo di creazione e valutazione di scale psicometriche:\n\nSelezione degli Item: Permette di selezionare gli item in base alla loro difficoltà e alla capacità di discriminazione, superando così la limitazione della teoria classica che si basa esclusivamente sulle correlazioni tra gli item e il punteggio totale.\nTesting Adattivo Computerizzato: La IRT facilita la valutazione della posizione di un individuo su un costrutto latente senza la necessità di somministrare l’intero test, grazie a tecniche come il testing adattivo computerizzato.\n\nIn conclusione, la Teoria della Risposta agli Item fornisce strumenti quantitativi per esaminare approfonditamente la relazione tra un item specifico e il costrutto latente, attraverso parametri di difficoltà e discriminazione.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#evoluzione-e-comprensione-della-validità-nelle-misure-psicologiche",
    "href": "prefazione.html#evoluzione-e-comprensione-della-validità-nelle-misure-psicologiche",
    "title": "Prefazione",
    "section": "Evoluzione e Comprensione della Validità nelle Misure Psicologiche",
    "text": "Evoluzione e Comprensione della Validità nelle Misure Psicologiche\nLa nostra comprensione della validità nelle misure psicologiche ha subito un notevole sviluppo nel corso del tempo, passando da una visione iniziale più frammentata a un approccio più olistico e dinamico. Inizialmente, la validità veniva suddivisa in diversi tipi, tra cui la validità di contenuto, di facciata, orientata al criterio e di costrutto.\nLa validità di contenuto si riferisce alla rappresentatività degli item di un test rispetto al costrutto che si intende misurare, mentre la validità di facciata valuta se superficialmente gli item sembrano idonei a misurare il costrutto, sebbene questa non sia considerata un indice rigoroso di validità. La validità orientata al criterio si divide ulteriormente in predittiva e concorrente, che valutano la capacità del test di prevedere comportamenti futuri o di correlare con criteri esterni contemporaneamente misurati. Infine, la validità di costrutto indaga se il test misura effettivamente il costrutto in questione, richiedendo una comprensione approfondita sia del costrutto sia della metodologia del test.\nTuttavia, queste distinzioni sono state gradualmente considerate limitate e frammentarie. Un punto di svolta è stato rappresentato dall’approccio olistico di Samuel Messick, che ha enfatizzato che la validità va oltre la misura stessa, coinvolgendo l’interpretazione e l’uso dei punteggi del test. Messick ha sottolineato l’importanza di considerare le evidenze di validità da molteplici fonti e di assicurare la coerenza delle interpretazioni dei punteggi del test con le teorie psicologiche sottostanti.\nUn’importante correzione concettuale è stata l’idea che la validità non sia un attributo statico dei test, ma piuttosto un processo continuo di accumulo di evidenze e giustificazioni teoriche. Questo processo di validazione riflette l’evoluzione delle teorie psicologiche e delle metodologie di misurazione, sottolineando che la validità è dinamica e contestuale.\nIn sintesi, l’evoluzione della concezione di validità nelle misure psicologiche sottolinea l’importanza di un approccio comprensivo, teoricamente informato e basato sull’evidenza per valutare, interpretare e utilizzare i punteggi dei test. Questo approccio moderno incoraggia i ricercatori e i praticanti a considerare la validità come un concetto ampio che incorpora molteplici aspetti della progettazione, dell’implementazione e dell’interpretazione dei test psicologici.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#approfondimento-su-tecniche-di-validazione-di-costrutto-e-costruzione-di-scale",
    "href": "prefazione.html#approfondimento-su-tecniche-di-validazione-di-costrutto-e-costruzione-di-scale",
    "title": "Prefazione",
    "section": "Approfondimento su Tecniche di Validazione di Costrutto e Costruzione di Scale",
    "text": "Approfondimento su Tecniche di Validazione di Costrutto e Costruzione di Scale\nLa discussione sulla evoluzione della validità nelle misure psicologiche può proseguire con l’esame delle tecniche che vengono usate per la validazione di costrutto e per la costruzione di scale. In particolare, gli strumenti maggiormente usati dagli psicometristi sono l’Analisi Fattoriale Confermativa (CFA) e i Modelli di Equazioni Strutturali (SEM).\nL’Analisi Fattoriale Confermativa (CFA) rappresenta un approccio metodologico rigoroso, basato sull’ipotesi che un insieme di osservazioni possa essere spiegato da pochi costrutti latenti. A differenza dell’Analisi Fattoriale Esplorativa, che non prevede ipotesi a priori sui fattori, la CFA richiede che i ricercatori definiscano anticipatamente un modello teorico. Questo specifica le relazioni tra le variabili osservabili e i costrutti latenti, permettendo di testare l’adeguatezza del modello ai dati. La capacità della CFA di confrontare diversi modelli offre un mezzo potente per identificare la struttura che meglio rappresenta i dati.\nNel contesto della valutazione della coerenza interna di una scala, l’utilizzo della CFA supera i limiti dei metodi basati sulla teoria classica dei test, fornendo una valutazione più dettagliata e strutturata delle relazioni tra item e costrutti latenti.\nI Modelli di Equazioni Strutturali (SEM) estendono le possibilità offerte dalla CFA, abilitando l’analisi delle relazioni di regressione non solo tra variabili manifeste e latenti, ma anche tra i costrutti latenti stessi. Questa caratteristica rende i SEM strumenti eccezionalmente potenti per esplorare le interazioni complesse tra variabili in uno studio psicometrico.\nL’esame della dimensionalità di un costrutto attraverso la CFA e i SEM consente di testare con precisione le ipotesi sulla struttura dimensionale dei costrutti, verificando se l’organizzazione teorizzata degli item in fattori latenti corrisponde ai dati. Questi strumenti sono quindi fondamentali per confermare la struttura di un costrutto come ipotizzato dalla teoria sottostante.\nIn aggiunta, l’approccio Multitrait-Multimethod (MTMM) per esaminare la validità esterna, incorporando la validità convergente e discriminante, arricchisce ulteriormente la comprensione della misura. L’uso del disegno MTMM permette di distinguere efficacemente tra costrutti correlati ma distinti, assicurando che le misure non solo riflettano accuratamente il costrutto target, ma siano anche discriminanti rispetto ad altri costrutti.\nIn sintesi, l’integrazione di CFA e SEM nel processo di validazione di costrutti e nella costruzione di scale psicometriche rappresenta un avanzamento metodologico significativo. Questi approcci non solo migliorano la precisione e la comprensione delle relazioni tra variabili osservabili e latenti, ma contribuiscono anche a elevare la qualità e l’affidabilità delle misure psicologiche. Attraverso un uso attento e informato di queste tecniche, i ricercatori possono arricchire la validità e l’utilità delle scale psicometriche. Chi volesse approfondire ulteriormente questi argomenti, può fare riferimento al testo di John e Benet-Martinez (2014).\n\n\n\n\nJohn, Oliver P., e Veronica Benet-Martinez. 2014. «Measurement: Reliability, construct validation, and scale construction». In Handbook of research methods in social and personality psychology, a cura di Harry T. Reis e Charles M. Judd, 2nd ed., 473–503. Cambridge University Press.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Allen, Mary J, and Wendy M Yen. 2001. Introduction to Measurement\nTheory. Waveland Press.\n\n\nBollen, Kenneth, and Richard Lennox. 1991. “Conventional Wisdom on\nMeasurement: A Structural Equation Perspective.”\nPsychological Bulletin 110 (2): 305–14.\n\n\nJohn, Oliver P., and Veronica Benet-Martinez. 2014. “Measurement:\nReliability, Construct Validation, and Scale Construction.” In\nHandbook of Research Methods in Social and Personality\nPsychology, edited by Harry T. Reis and Charles M. Judd, 2nd ed.,\n473–503. Cambridge University Press.\n\n\nKan, Kees-Jan, Han LJ van der Maas, and Stephen Z Levine. 2019.\n“Extending Psychometric Network Analysis: Empirical Evidence\nAgainst g in Favor of Mutualism?” Intelligence 73:\n52–62.\n\n\nKline, Paul. 2013. Handbook of Psychological Testing.\nRoutledge.\n\n\nLord, Frederic M, and Melvin R Novick. 1968. Statistical Theories of\nMental Test Scores. Addison-Wesley.\n\n\nMcDonald, Roderick P. 2013. Test Theory: A Unified Treatment.\nPsychology Press.\n\n\nNunnally, Jum C. 1994. Psychometric Theory. McGraw-Hill.\n\n\nPetersen, Isaac T. 2024. Principles of Psychological Assessment:\nWith Applied Examples in r. CRC Press.\n\n\nSpearman, C. 1904. “General Intelligence Objectively Determined\nand Measured.” American Journal of Psychology 15:\n201–93.",
    "crumbs": [
      "Bibliografia"
    ]
  },
  {
    "objectID": "chapters/fa/02_analisi_fattoriale_1.html#errore-di-misura",
    "href": "chapters/fa/02_analisi_fattoriale_1.html#errore-di-misura",
    "title": "15  Il modello unifattoriale",
    "section": "15.2 Errore di misura",
    "text": "15.2 Errore di misura\nL’analisi fattoriale concettualizza ogni misura osservabile \\(y\\) come risultante dalla combinazione lineare del punteggio reale associato al costrutto latente \\(\\xi\\), e di un elemento di errore di misura non osservato \\(\\delta\\). In questo contesto, il valore misurato di \\(y\\) è interpretato come il prodotto del punteggio reale latente, ponderato da un coefficiente di carico fattoriale \\(\\lambda\\), a cui si aggiunge un termine di errore specifico di misura \\(\\delta_y\\). Per illustrare con un esempio pratico, nel caso di una bilancia non completamente affidabile, ogni lettura del peso corporeo riflette sia il peso effettivo che un errore di misura intrinseco alla bilancia, che si manifesta con variazioni aleatorie da una lettura all’altra. In questa situazione, il modello fattoriale può essere formalizzato attraverso l’equazione:\n\\[\ny = \\lambda\\xi + \\delta_{y}.\n\\]\nQuando si analizzano multiple misure osservabili \\(y\\) che rappresentano lo stesso costrutto latente \\(\\xi\\), diventa fattibile la stima del punteggio reale latente \\(\\xi\\) insieme alla componente di errore di misura \\(\\delta\\), migliorando così la comprensione e l’accuratezza dell’interpretazione dei dati.",
    "crumbs": [
      "Il modello del'analisi fattoriale",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Il modello unifattoriale</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html",
    "href": "chapters/cfa/01_cfa.html",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "",
    "text": "21.1 Introduzione\nIn questo capitolo esamineremo la CFA per l’analisi dei modelli di misurazione con fattori comuni e indicatori continui. A differenza dell’analisi fattoriale esplorativa (EFA), nella CFA vengono analizzati modelli di misurazione vincolati. Ciò significa che il ricercatore specifica (1) il numero esatto di fattori; (2) il pattern dei carichi fattoriali, ossia la corrispondenza specifica tra i fattori e gli indicatori; e (3) la presenza di errori correlati, se presenti.\nLa seconda caratteristica menzionata sopra implica che un indicatore satura solo sui fattori specificati dal ricercatore, e tutte le saturazioni incrociate di quell’indicatore su altri fattori sono fissate a zero. Sebbene sia possibile specificare un numero esatto di fattori nella EFA, la tecnica analizza modelli di misurazione non restrittivi, in cui ciascun indicatore satura su tutti i fattori (ossia tutte le saturazioni incrociate sono liberamente stimate).\nUn’altra differenza è che i modelli EFA con più fattori sono identificati solo dopo aver specificato un metodo di rotazione dei fattori, come obliqua (i fattori possono covariare) oppure ortogonale (i fattori sono non correlati). Poiché la CFA richiede un modello identificato, non c’è una fase di rotazione e di solito è permesso ai fattori di covariare.\nNell’ambito dei requisiti per l’identificazione, è possibile stimare errori correlati nella CFA, ma è più difficile ottenere questo risultato nella EFA. Pertanto, la tecnica della CFA supporta meglio l’analisi delle strutture di covarianza degli errori rispetto alla EFA.\nsource(\"../../code/_common.R\")\nsuppressPackageStartupMessages({\n    library(\"lavaan\")\n    library(\"semTools\")\n})",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#efa-vs.-cfa-confronto-tra-analisi-fattoriale-esplorativa-e-confermativa",
    "href": "chapters/cfa/01_cfa.html#efa-vs.-cfa-confronto-tra-analisi-fattoriale-esplorativa-e-confermativa",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.3 EFA vs. CFA: Confronto tra Analisi Fattoriale Esplorativa e Confermativa",
    "text": "21.3 EFA vs. CFA: Confronto tra Analisi Fattoriale Esplorativa e Confermativa\n\n21.3.1 Fondamenti Comuni e Differenze\nSia l’Analisi Fattoriale Esplorativa (EFA) che quella Confermativa (CFA) si basano sul modello dei fattori comuni. Entrambe le tecniche presuppongono che la varianza degli indicatori osservati possa essere suddivisa in varianza comune e varianza unica. La varianza comune è quella condivisa tra gli indicatori e sottende le covarianze osservate, mentre la varianza unica comprende sia la varianza specifica delle variabili che l’errore di misurazione. I fattori estratti, detti fattori comuni, rappresentano le variabili latenti costruite da questa varianza comune.\nNell’EFA, la struttura dei fattori è indeterminata e viene esplorata senza ipotesi a priori riguardo al numero o alla natura dei fattori. L’EFA è quindi particolarmente utile nelle fasi iniziali di ricerca, quando la teoria è poco sviluppata o si sospetta la presenza di fattori inaspettati.\nAl contrario, la CFA si basa su un modello di fattori predefinito, che specifica a priori quali indicatori sono associati a ciascun fattore, rendendola idonea per confermare teorie esistenti o per validare strutture fattoriali precedentemente esplorate. In CFA, i carichi incrociati (indicatori che caricano su più di un fattore) sono generalmente vincolati a zero, stabilendo una relazione diretta e specifica tra fattori e indicatori.\n\n\n21.3.2 Indeterminatezza Fattoriale\nUn problema ricorrente in entrambe le tecniche è l’indeterminatezza fattoriale, dove i fattori comuni non possono essere definiti in modo univoco dai loro indicatori a causa della natura approssimativa delle stime. Questo si manifesta sia in EFA, con l’indeterminatezza della rotazione, che in CFA, dove l’analisi potrebbe non replicarsi in nuovi campioni a causa dell’uso dei medesimi dati per verificare il modello.\n\n\n21.3.3 Indeterminatezza dei Punteggi Fattoriali\nUn’altra complicazione è l’indeterminatezza dei punteggi fattoriali, che si verifica quando esistono infinite soluzioni valide per i punteggi fattoriali a partire dagli indicatori. Questo comporta che diversi metodi possono produrre ordinamenti differenti dei casi, un problema noto come indeterminatezza dei punteggi fattoriali (Grice, 2001).\n\n\n21.3.4 Rotazione e Specificazione del Modello\nLa EFA può presentare ambiguità a causa dell’infinita quantità di configurazioni dei carichi fattoriali che potrebbero adattarsi ai dati, un fenomeno meno pronunciato nella CFA dove la specifica del modello è più rigida.\n\n\n21.3.5 Applicazioni Pratiche\nL’EFA è spesso preferita in nuovi ambiti di ricerca, dove i fattori potrebbero non essere ben definiti, mentre la CFA è utilizzata per confermare le strutture fattoriali in studi di validazione o in seguito a revisioni di test esistenti.\n\n\n21.3.6 Problemi con l’Uso Combinato di EFA e CFA\nSi noti che l’applicazione della CFA immediatamente dopo la EFA nello stesso campione può essere problematica. Talvolta, l’uso congiunto non verifica né conferma i risultati dell’EFA. La restrittività dei modelli CFA, con i carichi incrociati impostati a zero, può portare a risultati che non sono coerenti con i dati analizzati nell’EFA.\n\n\n21.3.7 Nuove Approcci Intermedi\nMetodi come l’Analisi Strutturale Esplorativa (ESEM) offrono un approccio ibrido che combina la flessibilità dell’EFA con alcuni degli aspetti confirmatori della CFA. Questo permette una maggiore precisione nel testare l’adattamento del modello, pur mantenendo la capacità di esplorare nuove strutture fattoriali.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#raccomandazioni-per-la-selezione-degli-indicatori-nellanalisi-fattoriale",
    "href": "chapters/cfa/01_cfa.html#raccomandazioni-per-la-selezione-degli-indicatori-nellanalisi-fattoriale",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.4 Raccomandazioni per la Selezione degli Indicatori nell’Analisi Fattoriale",
    "text": "21.4 Raccomandazioni per la Selezione degli Indicatori nell’Analisi Fattoriale\nLa selezione accurata degli indicatori è cruciale per il successo dell’analisi fattoriale, sia essa Esplorativa (EFA) o Confermativa (CFA). Le linee guida suggerite da Fabrigar e Wegener (2012) e Little et al. (1999), come riassunto in Kline (2023), enfatizzano i seguenti punti chiave:\n\nDefinizione dei Concetti Teorici: È essenziale articolare i concetti teorici in modo dettagliato per delineare chiaramente ogni dominio di interesse. Ad esempio, se lo studio riguarda le dimensioni dell’ansia, è importante riferirsi a letteratura teorica ed empirica che discute vari aspetti come ansia di stato, ansia di tratto e ansia sociale.\nScelta degli Indicatori: Gli indicatori selezionati dovrebbero coprire adeguatamente i domini d’interesse senza affidarsi esclusivamente allo stesso metodo di misurazione, come i questionari di autovalutazione, per ridurre la varianza dovuta a metodi comuni. L’impiego di modelli CFA specializzati può aiutare a stimare questi effetti del metodo.\nGuida Teorica o Empirica Forte: Se esiste una solida base teorica o empirica, gli indicatori omogenei sono preferibili poiché forniscono stime più precise e meno distorte, specialmente in analisi di tipo più confermativo.\nAnalisi di Indicatori Meno Omogenei: Se la guida teorica è debole, può essere vantaggioso esaminare un insieme di indicatori meno omogenei che coprono un’ampia gamma del dominio d’interesse. Ciò evita di basarsi su approssimazioni che potrebbero non riflettere pienamente i concetti chiave.\nUso di Indicatori di Qualità Psicometrica Inferiore: Anche gli indicatori con minore qualità psicometrica possono essere utili se coprono ampiamente il costrutto, generano punteggi che riflettono ampie differenze individuali e sono analizzati attraverso metodi più confermativi.\nProblemi Tecnici: L’analisi potrebbe incontrare problemi come i casi Heywood o la mancata convergenza se alcuni fattori hanno un numero insufficiente di indicatori, specialmente in campioni piccoli. Un numero sicuro minimo di indicatori per ogni fattore previsto è di circa 3-5. Tuttavia, in alcuni casi, potrebbe essere vantaggioso utilizzare meno indicatori per fattore se questi sono psicometricamente solidi.\n\nHayduk e Littvay (2012) hanno sottolineato che non è sempre preferibile avere più indicatori per fattore; in certi contesti, un singolo indicatore ben scelto può essere sufficiente. Se gli indicatori sono altamente ridondanti, non aggiungono informazioni significative. L’idea di una “regola d’oro” di 3-5 indicatori per fattore è una guida generale, ma la scelta dovrebbe essere basata sulle ipotesi specifiche di ricerca piuttosto che su una regola arbitraria.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#fondamenti-dei-modelli-di-base-nella-cfa",
    "href": "chapters/cfa/01_cfa.html#fondamenti-dei-modelli-di-base-nella-cfa",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.5 Fondamenti dei Modelli di Base nella CFA",
    "text": "21.5 Fondamenti dei Modelli di Base nella CFA\nI modelli di base nella Confermative Factor Analysis (CFA) con più fattori sono caratterizzati da specifiche fondamentali che garantiscono una misurazione precisa delle variabili latenti. Ecco una sintesi delle caratteristiche principali di tali modelli:\n\nRelazione tra Indicatori e Fattori: Ogni indicatore è una variabile continua influenzata da due principali componenti: un fattore comune, che rappresenta la variabile latente che l’indicatore è inteso a misurare, e la varianza unica. Quest’ultima include sia l’errore di misurazione casuale sia la varianza specifica non spiegata dal fattore, entrambi rappresentati dal termine di errore.\nIndipendenza dei Termini di Errore: I termini di errore sono assunti come indipendenti l’uno dall’altro e dai fattori. Ciò implica l’assenza di confondenti non misurati per qualsiasi coppia di indicatori e l’indipendenza delle cause omesse dai fattori.\nLinearità e Covarianza: Le relazioni all’interno del modello sono lineari e i fattori possono covariare, il che significa che non esistono effetti causali diretti tra i fattori.\n\nQueste caratteristiche definiscono la misurazione unidimensionale, sottolineando che ciascun indicatore è pensato per misurare una sola dimensione e non condivide varianza con altri indicatori una volta controllati i fattori comuni. Tuttavia, è anche possibile specificare modelli CFA multidimensionali, dove alcuni indicatori possono caricare su più di un fattore o dove coppie di termini di errore possono essere correlati.\nInoltre, esistono metodi specializzati per analizzare relazioni non lineari tra fattori e indicatori continui, o tra i fattori stessi, come descritto da Amemiya e Yalcin (2001). Le relazioni tra indicatori categorici e fattori sono intrinsecamente non lineari, e questi scenari sono trattati nel CFA categorico.\nUn esempio di modello CFA di base con due fattori e sei indicatori viene presentato di seguito, dove tutti i carichi incrociati sono fissati a zero (kline-14-1-fig?). Per esempio, il fattore B non ha un effetto causale diretto sull’indicatore X1, il quale è misurato da un altro fattore (A). Tuttavia, ciò non significa che X1 e il fattore B siano completamente scorrelati. La struttura del modello permette a X1 di covariare con B poiché B è correlato con A, che è una causa di X1 (l’altra causa è E1, il termine di errore di X1). In modo simile, si prevede che gli indicatori X1 e X4 covarino poiché sono influenzati dai fattori A e B, rispettivamente, i quali sono correlati.\nLe costanti di scala, indicate come (1) nel modello, definiscono le metriche per le variabili non misurate, inclusi i fattori comuni e i termini di errore degli indicatori, stabilendo così una base uniforme per la misurazione nel modello CFA.\n\n\n\n\n\n\nFigura 21.1: Modello di analisi fattoriali confermativa con due fattori comuni e sei indicatori. (Figura tratta da Kline (2023))",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#oltre-i-requisiti-minimi-di-identificazione",
    "href": "chapters/cfa/01_cfa.html#oltre-i-requisiti-minimi-di-identificazione",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.7 Oltre i Requisiti Minimi di Identificazione",
    "text": "21.7 Oltre i Requisiti Minimi di Identificazione\nNel contesto della Confermative Factor Analysis (CFA), i requisiti di identificazione sono considerati necessari ma non sufficienti. Questo significa che, anche se il loro soddisfacimento è cruciale per una corretta stima dei parametri del modello, essi non garantiscono da soli che il modello sia il migliore possibile o pienamente identificato in termini di struttura e fondamenti teorici. Questa distinzione sottolinea l’importanza di andare oltre i criteri minimi per esplorare l’adeguatezza complessiva e la validità del modello all’interno del suo contesto teorico e applicativo.\n\n21.7.1 Perché sono Necessari\n\nGradi di Libertà (dfM) Maggiori o Uguali a Zero: Avere gradi di libertà non negativi è essenziale per assicurare che ci siano abbastanza dati per stimare i parametri del modello. Se i gradi di libertà sono negativi, indica che ci sono troppi parametri da stimare rispetto alle informazioni disponibili, il che rende il modello inidentificabile.\nScalatura Corretta di Ogni Variabile Non Misurata: La scalatura delle variabili latenti consente di stabilire un’unità di misura chiara, rendendo possibile l’interpretazione dei parametri come i carichi fattoriali. Senza una scalatura appropriata, i parametri del modello rimarrebbero indeterminati e potrebbero condurre a conclusioni ambigue.\n\n\n\n21.7.2 Perché Non Sono Sufficienti\nNonostante la soddisfazione di questi requisiti renda il modello tecnicamente identificabile e stima i parametri, ci sono altre considerazioni che possono influenzare l’adeguatezza del modello:\n\nAdeguamento del Modello: Anche se un modello ha gradi di libertà positivi e le variabili sono correttamente scalate, potrebbe non adattarsi bene ai dati. L’adeguatezza del modello è valutata attraverso statistiche di fit come il Chi-quadrato, RMSEA, CFI, e altri. Un modello può soddisfare i requisiti di identificazione ma avere un cattivo fit.\nValidità Teorica: Un modello può essere tecnicamente corretto ma non catturare accuratamente le relazioni teoriche tra le variabili. La costruzione del modello deve essere guidata da una solida base teorica che giustifica le relazioni tra i fattori e gli indicatori.\n\n\n\n21.7.3 Esempio Pratico\nImmaginiamo un modello CFA per misurare due concetti psicologici, come l’ansia e la depressione, con tre indicatori per ciascun fattore. Anche se il modello potrebbe avere gradi di libertà sufficienti e ogni fattore è correttamente scalato con un indicatore con carico fissato a 1.0, potrebbero sorgere problemi:\n\nCross-loadings: Gli indicatori per l’ansia potrebbero anche avere carichi significativi sulla depressione, il che non è catturato nel modello perché ogni indicatore è supposto misurare un solo fattore. Questo problema di validità del modello non è rilevato dai semplici criteri di identificazione.\nAdattamento del Modello: Il modello potrebbe mostrare un cattivo adattamento ai dati, suggerendo che la struttura ipotizzata dei fattori e degli indicatori non riflette accuratamente le relazioni tra le variabili osservate.\n\nIn conclusione, mentre i requisiti di identificazione sono critici per la fattibilità tecnica di un modello CFA, non garantiscono di per sé che il modello sia il migliore possibile o che rifletta accuratamente le dinamiche sottostanti. Ulteriori analisi e valutazioni sono necessarie per assicurare che il modello sia sia identificabile che valido.\n\n21.7.3.1 Altri Metodi per la Scalatura dei Fattori nei Modelli di CFA\nLa scalatura dei fattori è fondamentale per garantire una corretta identificazione e interpretazione dei fattori in un modello di Confermative Factor Analysis (CFA). Oltre al comune metodo della variabile di riferimento, esistono altri due approcci principali:\n\nMetodo di Standardizzazione della Varianza (Variance Standardization Method):\n\nDescrizione: Questo metodo fissa la varianza di ciascun fattore a 1.0, un approccio noto come unit variance identification (UVI).\nImplicazioni: La standardizzazione dei fattori implica che le loro varianze non sono stimate come parametri liberi. Invece, le covarianze tra i fattori sono liberamente stimate e interpretate come correlazioni di Pearson.\nCarichi degli Indicatori: Tutti i carichi degli indicatori sono considerati parametri liberi, il che permette di testarne la significatività statistica attraverso i loro errori standard.\nVantaggi e Limitazioni: Il principale vantaggio di questo metodo è la sua semplicità e l’assenza di necessità di selezionare una variabile di riferimento. Tuttavia, è generalmente più adatto per modellare fattori esogeni.\n\nMetodo di Codifica degli Effetti (Effects Coding Method):\n\nFunzionamento: A differenza dei metodi precedenti, questo non richiede la selezione di una variabile di riferimento e non implica la standardizzazione dei fattori.\nVincolo di Codifica degli Effetti (ECI): Si impone che la media dei carichi fattoriali per gli indicatori di un dato fattore sia uguale a 1.0. Questo obbliga il software SEM a trovare una combinazione ottimale di carichi che, in media, risultino in 1.0.\nStima della Varianza del Fattore: La varianza del fattore viene stimata come la varianza comune media calcolata attraverso tutti gli indicatori, considerando il loro contributo individuale alla misurazione del fattore.\nVantaggi: Questo metodo consente che tutti gli indicatori contribuiscano equamente alla scalatura del loro fattore comune. È particolarmente utile in studi longitudinali o quando si confrontano gruppi diversi, dato che le varianze dei fattori possono fornire informazioni preziose.\n\n\nOgni metodo di scalatura presenta vantaggi specifici e limitazioni, che devono essere considerati in base agli obiettivi della ricerca e alle caratteristiche del modello CFA:\n\nIl Metodo di Standardizzazione della Varianza offre una soluzione semplice e diretta, ma potrebbe non essere sempre il più appropriato, specialmente in contesti dove i fattori sono endogeni.\nIl Metodo di Codifica degli Effetti è vantaggioso per stabilire una scalatura equilibrata e stabile dei fattori, utile soprattutto in studi comparativi o longitudinali.\n\nLa scelta del metodo di scalatura dovrebbe essere guidata dalle necessità specifiche della ricerca, dalla struttura dei dati e dalle ipotesi teoriche del modello di CFA utilizzato.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#esempio-di-cfa-per-un-modello-di-abilità-cognitive-la-kaufman-assessment-battery-for-children",
    "href": "chapters/cfa/01_cfa.html#esempio-di-cfa-per-un-modello-di-abilità-cognitive-la-kaufman-assessment-battery-for-children",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.8 Esempio di CFA per un Modello di Abilità Cognitive: La Kaufman Assessment Battery for Children",
    "text": "21.8 Esempio di CFA per un Modello di Abilità Cognitive: La Kaufman Assessment Battery for Children\nLa Kaufman Assessment Battery for Children (KABC-I) è un test di valutazione delle abilità cognitive, somministrato individualmente a bambini dagli 2 anni e mezzo ai 12 anni e mezzo (Kaufman & Kaufman, 1983). Questo strumento è stato progettato per misurare due distinti fattori cognitivi attraverso otto indicatori.\nI primi tre compiti del test sono orientati all’elaborazione sequenziale e richiedono ai bambini di ricordare e ripetere stimoli uditivi (come nel Richiamo Numerico e nell’Ordine delle Parole) o visivi (come nei Movimenti della Mano) in un ordine specifico. Questi compiti sono pensati per riflettere la capacità di memoria a breve termine e di sequenziamento delle informazioni.\nGli altri cinque compiti, che includono la Chiusura Gestaltica e la Serie Fotografica, sono ritenuti misurare un tipo di ragionamento più olistico e meno sequenziale, associato all’elaborazione simultanea. Questi compiti valutano la capacità di integrare e sintetizzare le informazioni visuo-spaziali in un contesto più ampio, spesso indipendentemente dall’ordine in cui le informazioni sono presentate.\nKeith (1985) ha proposto delle denominazioni alternative per i fattori misurati dalla KABC-I, suggerendo i termini “memoria a breve termine” per sostituire “elaborazione sequenziale” e “ragionamento visuo-spaziale” per “elaborazione simultanea”. Queste etichette alternative riflettono una prospettiva leggermente diversa sui tipi di competenze cognitive che i due fattori intendono misurare.\nQuesto modello di CFA, utilizzando i compiti della KABC-I come indicatori, fornisce una struttura utile per comprendere come diversi tipi di elaborazione cognitiva possano essere categorizzati e valutati nei contesti educativi e diagnostici.\n\n# input the correlations in lower diagnonal form\nkabcLower.cor &lt;- \"\n 1.00\n .39 1.00\n .35  .67 1.00\n .21  .11  .16 1.00\n .32  .27  .29  .38 1.00\n .40  .29  .28  .30  .47 1.00\n .39  .32  .30  .31  .42  .41 1.00\n .39  .29  .37  .42  .58  .51  .42 1.00 \"\n\n# name the variables and convert to full correlation matrix\n# hm, hand movements; nr, number recall; wo, word order; gc, gestalt closure;\n# tr, triangles; sm, spatial memory; ma, matrix analogies; ps, photo series\nkabc.cor &lt;- lavaan::getCov(kabcLower.cor, names = c(\n    \"hm\", \"nr\", \"wo\",\n    \"gc\", \"tr\", \"sm\", \"ma\", \"ps\"\n))\n# display correlations\nkabc.cor\n\n\nA matrix: 8 x 8 of type dbl\n\n\n\nhm\nnr\nwo\ngc\ntr\nsm\nma\nps\n\n\n\n\nhm\n1.00\n0.39\n0.35\n0.21\n0.32\n0.40\n0.39\n0.39\n\n\nnr\n0.39\n1.00\n0.67\n0.11\n0.27\n0.29\n0.32\n0.29\n\n\nwo\n0.35\n0.67\n1.00\n0.16\n0.29\n0.28\n0.30\n0.37\n\n\ngc\n0.21\n0.11\n0.16\n1.00\n0.38\n0.30\n0.31\n0.42\n\n\ntr\n0.32\n0.27\n0.29\n0.38\n1.00\n0.47\n0.42\n0.58\n\n\nsm\n0.40\n0.29\n0.28\n0.30\n0.47\n1.00\n0.41\n0.51\n\n\nma\n0.39\n0.32\n0.30\n0.31\n0.42\n0.41\n1.00\n0.42\n\n\nps\n0.39\n0.29\n0.37\n0.42\n0.58\n0.51\n0.42\n1.00\n\n\n\n\n\n\n# add the standard deviations and convert to covariances\nkabc.cov &lt;- lavaan::cor2cov(kabc.cor, sds = c(3.40, 2.40, 2.90, 2.70, 2.70, 4.20, 2.80, 3.00))\n\n# display covariances\nkabc.cov\n\n\nA matrix: 8 x 8 of type dbl\n\n\n\nhm\nnr\nwo\ngc\ntr\nsm\nma\nps\n\n\n\n\nhm\n11.5600\n3.1824\n3.4510\n1.9278\n2.9376\n5.7120\n3.7128\n3.978\n\n\nnr\n3.1824\n5.7600\n4.6632\n0.7128\n1.7496\n2.9232\n2.1504\n2.088\n\n\nwo\n3.4510\n4.6632\n8.4100\n1.2528\n2.2707\n3.4104\n2.4360\n3.219\n\n\ngc\n1.9278\n0.7128\n1.2528\n7.2900\n2.7702\n3.4020\n2.3436\n3.402\n\n\ntr\n2.9376\n1.7496\n2.2707\n2.7702\n7.2900\n5.3298\n3.1752\n4.698\n\n\nsm\n5.7120\n2.9232\n3.4104\n3.4020\n5.3298\n17.6400\n4.8216\n6.426\n\n\nma\n3.7128\n2.1504\n2.4360\n2.3436\n3.1752\n4.8216\n7.8400\n3.528\n\n\nps\n3.9780\n2.0880\n3.2190\n3.4020\n4.6980\n6.4260\n3.5280\n9.000\n\n\n\n\n\n\n\n\n\n\n\nFigura 21.3: Modello CFA per la Kaufman Assessment Battery for Children. (Figura tratta da Kline (2023))\n\n\n\n\n21.8.0.1 Modello a Fattore Singolo\nNell’ambito della CFA, se il modello bersaglio ha due o più fattori, spesso il primo modello analizzato è un modello a fattore singolo. Se non si può rigettare un modello a fattore singolo, non ha molto senso valutare modelli con più fattori.\nSpecifichiamo il modello ad un fattore comune nella sintassi di lavaan.\n\n# single factor (general ability)\n# indicator hm automatically specified as reference variable\nkabc1.model &lt;- \"\n    General =~ hm + nr + wo + gc + tr + sm + ma + ps \n\"\n\nAdattiamo il modello ai dati.\n\n# variances calculated with N in the denominator, not N - 1\nkabc1 &lt;- lavaan::sem(kabc1.model, sample.cov = kabc.cov, sample.nobs = 200)\n\nGeneriamo un modello di percorso.\n\nsemPlot::semPaths(kabc1,\n    what = \"col\", whatLabels = \"par\", style = \"mx\", \n    layout = \"tree2\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 8, sizeMan2 = 5\n)\n\n\n\n\n\n\n\n\nEsaminiamo la soluzione non standardizzata.\n\nlavaan::parameterEstimates(kabc1) |&gt; \n    print()\n\n       lhs op     rhs   est    se     z pvalue ci.lower ci.upper\n1  General =~      hm 1.000 0.000    NA     NA    1.000    1.000\n2  General =~      nr 0.636 0.111 5.708      0    0.418    0.854\n3  General =~      wo 0.805 0.136 5.910      0    0.538    1.072\n4  General =~      gc 0.659 0.123 5.361      0    0.418    0.900\n5  General =~      tr 0.963 0.138 6.984      0    0.693    1.233\n6  General =~      sm 1.433 0.211 6.796      0    1.019    1.846\n7  General =~      ma 0.883 0.137 6.459      0    0.615    1.151\n8  General =~      ps 1.166 0.159 7.324      0    0.854    1.478\n9       hm ~~      hm 7.812 0.863 9.049      0    6.120    9.504\n10      nr ~~      nr 4.240 0.456 9.294      0    3.345    5.134\n11      wo ~~      wo 5.975 0.650 9.195      0    4.702    7.249\n12      gc ~~      gc 5.652 0.599 9.432      0    4.478    6.827\n13      tr ~~      tr 3.831 0.468 8.186      0    2.914    4.748\n14      sm ~~      sm 9.979 1.179 8.463      0    7.668   12.290\n15      ma ~~      ma 4.925 0.558 8.822      0    3.831    6.020\n16      ps ~~      ps 3.936 0.531 7.410      0    2.895    4.977\n17 General ~~ General 3.690 0.921 4.008      0    1.885    5.494\n\n\nLa saturazione non standardizzata per il compito “Movimenti della Mano” è stato fissato automaticamente a 1.0 per scalare il singolo fattore comune. Le istruzioni seguenti consentono di estrarre dall’output di sem() solo le informazioni relative alle saturazioni fattoriali.\n\nparameterEstimates(kabc1, standardized = TRUE) %&gt;%\n    dplyr::filter(op == \"=~\") %&gt;%\n    dplyr::select(\n        \"Latent Factor\" = lhs,\n        Indicator = rhs,\n        B = est,\n        SE = se,\n        Z = z,\n        \"p-value\" = pvalue,\n        Beta = std.all\n    ) %&gt;%\n    knitr::kable(\n        digits = 3, booktabs = TRUE, format = \"markdown\",\n        caption = \"Factor Loadings\"\n    )\n\n\n\nTable: Factor Loadings\n\n|Latent Factor |Indicator |     B|    SE|     Z| p-value|  Beta|\n|:-------------|:---------|-----:|-----:|-----:|-------:|-----:|\n|General       |hm        | 1.000| 0.000|    NA|      NA| 0.566|\n|General       |nr        | 0.636| 0.111| 5.708|       0| 0.510|\n|General       |wo        | 0.805| 0.136| 5.910|       0| 0.535|\n|General       |gc        | 0.659| 0.123| 5.361|       0| 0.470|\n|General       |tr        | 0.963| 0.138| 6.984|       0| 0.687|\n|General       |sm        | 1.433| 0.211| 6.796|       0| 0.657|\n|General       |ma        | 0.883| 0.137| 6.459|       0| 0.607|\n|General       |ps        | 1.166| 0.159| 7.324|       0| 0.749|\n\n\nEsaminiamo le misure di bontà di adattamento.\n\nfitMeasures(kabc1, c(\"chisq\", \"df\", \"cfi\", \"tli\", \"rmsea\", \"srmr\")) |&gt;\n    print()\n\n  chisq      df     cfi     tli   rmsea    srmr \n105.427  20.000   0.818   0.746   0.146   0.084 \n\n\nTroviamo i residui grezzi, ovvero la differenza tra la matrice di covarianza osservata e quella predetta dal modello.\n\nlavaan::residuals(kabc1, type = \"raw\") |&gt;\n    print()\n\n$type\n[1] \"raw\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.820  0.000                                          \nwo  0.462  2.751  0.000                                   \ngc -0.513 -0.836 -0.711  0.000                            \ntr -0.631 -0.519 -0.602  0.415  0.000                     \nsm  0.397 -0.452 -0.863 -0.097  0.212  0.000              \nma  0.437  0.069 -0.199  0.186  0.022  0.131  0.000       \nps -0.345 -0.659 -0.263  0.550  0.530  0.229 -0.289  0.000\n\n\n\nSpecificando type = \"cor.bollen\" o type = \"cor\" otteniamo la differenza tra la matrice di correlazione osservata e quella predetta dal modello.\n\nlavaan::residuals(kabc1, type = \"cor.bollen\") |&gt;\n    print()\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.101  0.000                                          \nwo  0.047  0.397  0.000                                   \ngc -0.056 -0.130 -0.091  0.000                            \ntr -0.069 -0.080 -0.077  0.057  0.000                     \nsm  0.028 -0.045 -0.071 -0.009  0.019  0.000              \nma  0.046  0.010 -0.025  0.025  0.003  0.011  0.000       \nps -0.034 -0.092 -0.030  0.068  0.066  0.018 -0.035  0.000\n\n\n\nIn alternativa, possiamo ottenere i residui standardizzati alla maniera di Mplus (standardized.mplus), che vengono calcolati utilizzando la seguente formula:\n\\[\n    \\text{Residuo Standardizzato} = \\frac{\\text{Cov. Osservata} - \\text{Cov. Stimata}}{\\sqrt{\\text{Var. dell'Errore per X} \\times \\text{Var. dell'Errore per Y}}},\n\\]\ndove: - La covarianza osservata è il valore della covarianza tra due variabili nel set di dati. - La covarianza stimata è la covarianza tra le stesse due variabili, come previsto dal modello SEM. - La varianza dell’errore per la variabile X e Y sono le varianze degli errori per le due variabili in questione.\nI residui standardizzati misurano quanto la relazione osservata tra due variabili si discosta da quella prevista dal modello, in unità standardizzate. Un valore vicino a zero indica che il modello si adatta bene ai dati per quella specifica relazione. Valori più grandi in valore assoluto suggeriscono un cattivo adattamento in quella specifica parte del modello.\n\nlavaan::residuals(kabc1, type = \"standardized.mplus\") |&gt;\n    print()\n\n$type\n[1] \"standardized.mplus\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  2.062  0.000                                          \nwo  1.026  6.218  0.000                                   \ngc -1.231 -2.727 -1.952  0.000                            \ntr -2.200 -2.364 -2.355  1.379  0.000                     \nsm  0.723 -1.188 -1.995 -0.210  0.596  0.000              \nma  1.086  0.237 -0.601  0.544  0.089  0.313  0.000       \nps -1.241 -3.422 -1.037  1.833  2.178  0.675 -1.375  0.000\n\n\n\nIl modello a fattore singolo mostra un rapporto elevato chi-quadro/df. Inoltre, i residui per questa analisi indicano che l’adattamento locale è scadente. Pertanto, il modello a fattore singolo per la KABC-I è rigettato.\n\n\n21.8.0.2 Modello a Due Fattori\nIn una seconda analisi, adattiamo ai dati il modello a due fattori rappresentato nella {numref}kline-14-3-fig.\n\nkabc2_model &lt;- \"\n    Sequent =~ hm + nr + wo\n    Simultan =~ gc + tr + sm + ma + ps \n\"\n\n\nkabc2 &lt;- lavaan::sem(kabc2_model, sample.cov = kabc.cov, sample.nobs = 200)\n\n\nsemPlot::semPaths(kabc2,\n    what = \"col\", whatLabels = \"par\", style = \"mx\", \n    layout = \"tree2\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 8, sizeMan2 = 5\n)\n\n\n\n\n\n\n\n\n\nlavaan::parameterEstimates(kabc2) |&gt;\n    print()\n\n        lhs op      rhs   est    se     z pvalue ci.lower ci.upper\n1   Sequent =~       hm 1.000 0.000    NA     NA    1.000    1.000\n2   Sequent =~       nr 1.147 0.181 6.341  0.000    0.792    1.501\n3   Sequent =~       wo 1.388 0.219 6.340  0.000    0.959    1.817\n4  Simultan =~       gc 1.000 0.000    NA     NA    1.000    1.000\n5  Simultan =~       tr 1.445 0.227 6.352  0.000    0.999    1.890\n6  Simultan =~       sm 2.029 0.335 6.062  0.000    1.373    2.685\n7  Simultan =~       ma 1.212 0.212 5.717  0.000    0.797    1.628\n8  Simultan =~       ps 1.727 0.265 6.521  0.000    1.208    2.246\n9        hm ~~       hm 8.664 0.938 9.237  0.000    6.826   10.502\n10       nr ~~       nr 1.998 0.414 4.831  0.000    1.188    2.809\n11       wo ~~       wo 2.902 0.604 4.801  0.000    1.717    4.087\n12       gc ~~       gc 5.419 0.585 9.261  0.000    4.272    6.566\n13       tr ~~       tr 3.426 0.458 7.479  0.000    2.528    4.323\n14       sm ~~       sm 9.997 1.202 8.320  0.000    7.642   12.353\n15       ma ~~       ma 5.105 0.578 8.838  0.000    3.973    6.237\n16       ps ~~       ps 3.482 0.537 6.482  0.000    2.429    4.535\n17  Sequent ~~  Sequent 2.838 0.838 3.389  0.001    1.197    4.480\n18 Simultan ~~ Simultan 1.834 0.530 3.459  0.001    0.795    2.874\n19  Sequent ~~ Simultan 1.271 0.324 3.918  0.000    0.635    1.907\n\n\n\nstandardizedSolution(kabc2)\n\n\nA lavaan.data.frame: 19 x 9\n\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nSequent\n=~\nhm\n0.4967517\n0.06185190\n8.031309\n8.881784e-16\n0.3755242\n0.6179792\n\n\nSequent\n=~\nnr\n0.8070386\n0.04626958\n17.442098\n0.000000e+00\n0.7163519\n0.8977253\n\n\nSequent\n=~\nwo\n0.8082004\n0.04624070\n17.478118\n0.000000e+00\n0.7175703\n0.8988305\n\n\nSimultan\n=~\ngc\n0.5029005\n0.06088027\n8.260485\n2.220446e-16\n0.3835774\n0.6222236\n\n\nSimultan\n=~\ntr\n0.7264627\n0.04412957\n16.462040\n0.000000e+00\n0.6399703\n0.8129550\n\n\nSimultan\n=~\nsm\n0.6560490\n0.04959951\n13.226925\n0.000000e+00\n0.5588358\n0.7532623\n\n\nSimultan\n=~\nma\n0.5878905\n0.05485948\n10.716298\n0.000000e+00\n0.4803679\n0.6954131\n\n\nSimultan\n=~\nps\n0.7817406\n0.04012341\n19.483401\n0.000000e+00\n0.7031001\n0.8603810\n\n\nhm\n~~\nhm\n0.7532377\n0.06145007\n12.257719\n0.000000e+00\n0.6327978\n0.8736777\n\n\nnr\n~~\nnr\n0.3486887\n0.07468267\n4.668937\n3.027615e-06\n0.2023134\n0.4950641\n\n\nwo\n~~\nwo\n0.3468121\n0.07474351\n4.640030\n3.483594e-06\n0.2003175\n0.4933067\n\n\ngc\n~~\ngc\n0.7470911\n0.06123343\n12.200705\n0.000000e+00\n0.6270758\n0.8671064\n\n\ntr\n~~\ntr\n0.4722520\n0.06411696\n7.365476\n1.765255e-13\n0.3465850\n0.5979189\n\n\nsm\n~~\nsm\n0.5695997\n0.06507943\n8.752377\n0.000000e+00\n0.4420463\n0.6971530\n\n\nma\n~~\nma\n0.6543848\n0.06450273\n10.145071\n0.000000e+00\n0.5279617\n0.7808078\n\n\nps\n~~\nps\n0.3888817\n0.06273220\n6.199076\n5.679559e-10\n0.2659288\n0.5118345\n\n\nSequent\n~~\nSequent\n1.0000000\n0.00000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nSimultan\n~~\nSimultan\n1.0000000\n0.00000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nSequent\n~~\nSimultan\n0.5569247\n0.06673231\n8.345654\n0.000000e+00\n0.4261318\n0.6877176\n\n\n\n\n\n\nfitMeasures(kabc2, c(\"chisq\", \"df\", \"cfi\", \"tli\", \"rmsea\", \"srmr\")) |&gt;\n    print()\n\n chisq     df    cfi    tli  rmsea   srmr \n38.325 19.000  0.959  0.939  0.071  0.072 \n\n\nUn modello di analisi fattoriale confermativa (CFA) che utilizza un singolo fattore può essere visto come un caso specifico o un “sottoinsieme” di modelli CFA più complessi con due o più fattori che impiegano gli stessi indicatori e lo stesso schema di covarianza degli errori, se presente. Questa struttura gerarchica tra i modelli a singolo fattore e quelli multifattoriali implica che i ricercatori possono applicare il test del chi-quadro per confrontare direttamente l’adattamento di un modello CFA a singolo fattore con quello di modelli CFA a più fattori. In pratica, ciò permette di valutare se l’introduzione di fattori aggiuntivi migliora significativamente l’adattamento del modello ai dati rispetto a un modello più semplice a singolo fattore. Questo tipo di analisi è fondamentale per determinare la complessità ottimale del modello in base alla struttura sottostante dei dati. Sebbene questo argomento verrà approfondito successivamente, è importante anticipare qui l’utilizzo del test del rapporto di verosimiglianza, che consente di confrontare i modelli in maniera quantitativa.\n\nlavTestLRT(kabc1, kabc2)\n\n\nA anova: 2 x 8\n\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nRMSEA\nDf diff\nPr(&gt;Chisq)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\nkabc2\n19\n7592.082\n7648.153\n38.32476\nNA\nNA\nNA\nNA\n\n\nkabc1\n20\n7657.183\n7709.956\n105.42664\n67.10188\n0.5748995\n1\n2.578323e-16\n\n\n\n\n\nI risultati del test indicano che l’adattamento del modello con due fattori è statisticamente migliore rispetto a quello del modello a fattore singolo (il modello ad un fattore ha un valore \\(\\chi^2\\) superiore di 67.1 punti, con un grado di libertà).\nAnche se il test del rapporto tra verosimiglianze favorisce il modello a due fattori, possiamo notare che l’esame dei residui mostra un problema con l’indicatore hm.\n\nlavaan::residuals(kabc2, type = \"standardized.mplus\") |&gt;\n    print()\n\n$type\n[1] \"standardized.mplus\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr -0.591  0.000                                          \nwo -3.790  1.539  0.000                                   \ngc  1.126 -2.329 -1.315     NA                            \ntr  2.046 -1.558 -1.001  0.429  0.000                     \nsm  3.464 -0.112 -0.355 -0.784 -0.267  0.000              \nma  3.505  1.129  0.727  0.323 -0.245  0.664  0.008       \nps  2.991 -2.002  0.524  0.910  0.677 -0.144 -1.978  0.000\n\n\n\nPer affrontare questo problema, calcoliamo i modification indices che ci dicono quale parametro del modello ha l’effetto maggiore sulla misura di fit complessivo.\n\nmodindices(kabc2, sort = TRUE, maximum.number = 5)\n\n\nA lavaan.data.frame: 5 x 8\n\n\n\nlhs\nop\nrhs\nmi\nepc\nsepc.lv\nsepc.all\nsepc.nox\n\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n25\nSimultan\n=~\nhm\n20.097078\n1.0539461\n1.4275011\n0.4209070\n0.4209070\n\n\n35\nnr\n~~\nwo\n20.097058\n4.7406831\n4.7406831\n1.9685321\n1.9685321\n\n\n26\nSimultan\n=~\nnr\n7.013048\n-0.5104555\n-0.6913786\n-0.2887972\n-0.2887972\n\n\n29\nhm\n~~\nwo\n7.012988\n-1.7458372\n-1.7458372\n-0.3481696\n-0.3481696\n\n\n32\nhm\n~~\nsm\n4.847027\n1.6094583\n1.6094583\n0.1729329\n0.1729329\n\n\n\n\n\nI risultati degli indici di modifica (MI) indicano che il misfit del modello è principalmente attribuibile alla fissazione a zero del carico tra l’indicatore hm e il fattore comune Simulan, nonché alla fissazione a zero della covarianza tra le componenti residue di nr e wo. Per migliorare l’adattamento del modello, si propone quindi di modificare questi aspetti, iniziando con il primo, ovvero riconsiderando il carico di hm sul fattore Simulan.\n\nkabc3_model &lt;- \"\n    Sequent =~ hm + nr + wo\n    Simultan =~ hm + gc + tr + sm + ma + ps\n\"\n\n\nkabc3 &lt;- lavaan::sem(kabc3_model, sample.cov = kabc.cov, sample.nobs = 200)\n\n\nlavaan::parameterEstimates(kabc3) |&gt;\n    print()\n\n        lhs op      rhs   est    se     z pvalue ci.lower ci.upper\n1   Sequent =~       hm 1.000 0.000    NA     NA    1.000    1.000\n2   Sequent =~       nr 2.285 0.777 2.941  0.003    0.762    3.808\n3   Sequent =~       wo 2.767 0.941 2.939  0.003    0.922    4.612\n4  Simultan =~       hm 1.000 0.000    NA     NA    1.000    1.000\n5  Simultan =~       gc 1.014 0.255 3.979  0.000    0.515    1.514\n6  Simultan =~       tr 1.457 0.329 4.427  0.000    0.812    2.101\n7  Simultan =~       sm 2.103 0.483 4.354  0.000    1.157    3.050\n8  Simultan =~       ma 1.259 0.298 4.229  0.000    0.675    1.842\n9  Simultan =~       ps 1.752 0.391 4.486  0.000    0.987    2.518\n10       hm ~~       hm 7.851 0.845 9.291  0.000    6.195    9.507\n11       nr ~~       nr 1.899 0.487 3.896  0.000    0.944    2.854\n12       wo ~~       wo 2.750 0.713 3.856  0.000    1.352    4.148\n13       gc ~~       gc 5.444 0.585 9.297  0.000    4.296    6.591\n14       tr ~~       tr 3.521 0.457 7.702  0.000    2.625    4.417\n15       sm ~~       sm 9.767 1.179 8.287  0.000    7.457   12.077\n16       ma ~~       ma 5.013 0.569 8.815  0.000    3.898    6.127\n17       ps ~~       ps 3.554 0.529 6.718  0.000    2.517    4.591\n18  Sequent ~~  Sequent 0.734 0.490 1.499  0.134   -0.226    1.693\n19 Simultan ~~ Simultan 1.759 0.760 2.314  0.021    0.269    3.250\n20  Sequent ~~ Simultan 0.579 0.178 3.252  0.001    0.230    0.928\n\n\nIl modello così modificato fornisce un buon adattamento ai dati.\n\nfitMeasures(kabc3, c(\"chisq\", \"df\", \"cfi\", \"tli\", \"rmsea\", \"srmr\")) |&gt;\n    print()\n\n chisq     df    cfi    tli  rmsea   srmr \n18.108 18.000  1.000  1.000  0.005  0.035 \n\n\n\nlavaan::residuals(kabc3, type = \"standardized.mplus\") |&gt;\n    print()\n\n$type\n[1] \"standardized.mplus\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  1.165  0.000                                          \nwo -1.637  0.000  0.000                                   \ngc -1.066 -1.919 -0.939  0.000                            \ntr -1.710 -0.763 -0.247  0.603  0.000                     \nsm  1.325  0.287  0.044 -0.867 -0.304  0.000              \nma  1.730  1.428  1.029  0.258 -0.298  0.338  0.000       \nps -0.512 -1.059  1.285  1.035  1.088 -0.361 -2.181  0.008\n\n\n\nEseguiamo il confronto tra questo terzo modello e il secondo.\n\nlavTestLRT(kabc2, kabc3)\n\n\nA anova: 2 x 8\n\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nRMSEA\nDf diff\nPr(&gt;Chisq)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\nkabc3\n18\n7573.864\n7633.234\n18.10764\nNA\nNA\nNA\nNA\n\n\nkabc2\n19\n7592.082\n7648.153\n38.32476\n20.21711\n0.3099767\n1\n6.913179e-06\n\n\n\n\n\nIl test del rapporto tra verosimiglianze favorisce il modello nel quale hm satura su entrambi i fattori comuni.\n\nstandardizedSolution(kabc3)\n\n\nA lavaan.data.frame: 20 x 9\n\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nSequent\n=~\nhm\n0.2525852\n0.08220770\n3.072524\n2.122564e-03\n0.09146104\n0.4137093\n\n\nSequent\n=~\nnr\n0.8177224\n0.05332037\n15.336023\n0.000000e+00\n0.71321642\n0.9222284\n\n\nSequent\n=~\nwo\n0.8193490\n0.05332364\n15.365586\n0.000000e+00\n0.71483657\n0.9238614\n\n\nSimultan\n=~\nhm\n0.3911086\n0.07920465\n4.937950\n7.894795e-07\n0.23587038\n0.5463469\n\n\nSimultan\n=~\ngc\n0.4995366\n0.06083478\n8.211366\n2.220446e-16\n0.38030263\n0.6187706\n\n\nSimultan\n=~\ntr\n0.7173667\n0.04430392\n16.191948\n0.000000e+00\n0.63053266\n0.8042008\n\n\nSimultan\n=~\nsm\n0.6659828\n0.04841875\n13.754648\n0.000000e+00\n0.57108381\n0.7608818\n\n\nSimultan\n=~\nma\n0.5978172\n0.05378964\n11.113985\n0.000000e+00\n0.49239147\n0.7032430\n\n\nSimultan\n=~\nps\n0.7766255\n0.03976264\n19.531536\n0.000000e+00\n0.69869211\n0.8545588\n\n\nhm\n~~\nhm\n0.6825459\n0.06079286\n11.227403\n0.000000e+00\n0.56339406\n0.8016977\n\n\nnr\n~~\nnr\n0.3313300\n0.08720253\n3.799546\n1.449613e-04\n0.16041622\n0.5022438\n\n\nwo\n~~\nwo\n0.3286672\n0.08738134\n3.761298\n1.690341e-04\n0.15740296\n0.4999315\n\n\ngc\n~~\ngc\n0.7504632\n0.06077839\n12.347532\n0.000000e+00\n0.63133972\n0.8695867\n\n\ntr\n~~\ntr\n0.4853850\n0.06356431\n7.636123\n2.242651e-14\n0.36080119\n0.6099687\n\n\nsm\n~~\nsm\n0.5564669\n0.06449211\n8.628450\n0.000000e+00\n0.43006469\n0.6828691\n\n\nma\n~~\nma\n0.6426146\n0.06431274\n9.992026\n0.000000e+00\n0.51656392\n0.7686652\n\n\nps\n~~\nps\n0.3968529\n0.06176136\n6.425586\n1.313629e-10\n0.27580286\n0.5179029\n\n\nSequent\n~~\nSequent\n1.0000000\n0.00000000\nNA\nNA\n1.00000000\n1.0000000\n\n\nSimultan\n~~\nSimultan\n1.0000000\n0.00000000\nNA\nNA\n1.00000000\n1.0000000\n\n\nSequent\n~~\nSimultan\n0.5096198\n0.07025684\n7.253668\n4.056755e-13\n0.37191892\n0.6473207\n\n\n\n\n\n\nsemPlot::semPaths(kabc3,\n    what = \"col\", whatLabels = \"std\", style = \"mx\",\n    layout = \"tree2\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 8, sizeMan2 = 5\n)\n\n\n\n\n\n\n\n\nNei modelli precedenti, abbiamo adottato un metodo di scalatura dei fattori comuni che fissava la saturazione fattoriale di uno degli indicatori per ciascun fattore comune a 1.0 come riferimento. Ora, esploreremo un diverso approccio di scalatura che prevede la standardizzazione della varianza delle variabili latenti.\nPer attuare questa procedura nel software lavaan, è necessario modificare la configurazione predefinita in cui la saturazione fattoriale del primo indicatore di ogni fattore comune è fissata a 1.0. Per fare ciò, useremo la sintassi NA* per indicare che la saturazione fattoriale del primo indicatore deve essere stimata. Questo si realizza inserendo NA* nell’istruzione che definisce la relazione tra le variabili latenti e gli indicatori (espresso tramite =~). Inoltre, è fondamentale specificare che la varianza delle variabili latenti sia fissata a 1.0, il che si attua mediante la sintassi 1* nell’istruzione che stabilisce la varianza di ciascun fattore comune (~~).\n\nkabc3alt_model &lt;- \"\n    Sequent =~ NA*hm + nr + wo\n    Simultan =~ NA*hm + gc + tr + sm + ma + ps\n\n    Sequent ~~ 1*Sequent\n    Simultan ~~ 1*Simultan\n\"\n\nAdattiamo il modello così parametrizzato ai dati.\n\nkabc3alt &lt;- lavaan::sem(\n    kabc3alt_model, sample.cov = kabc.cov, sample.nobs = 200, std.lv = TRUE\n)\n\nEsaminiamo la soluzione non standardizzata.\n\nsemPlot::semPaths(kabc3alt,\n    what = \"col\", whatLabels = \"par\", style = \"mx\", \n    layout = \"tree2\", nCharNodes = 7,\n    shapeMan = \"rectangle\", sizeMan = 8, sizeMan2 = 5\n)\n\n\n\n\n\n\n\n\nEsaminiamo la soluzione stanardizzata.\n\nloadings &lt;- standardizedSolution(kabc3alt)\nloadings\n\n\nA lavaan.data.frame: 20 x 9\n\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nSequent\n=~\nhm\n0.2525843\n0.08220772\n3.072513\n2.122649e-03\n0.09146008\n0.4137084\n\n\nSequent\n=~\nnr\n0.8177223\n0.05332042\n15.336006\n0.000000e+00\n0.71321623\n0.9222284\n\n\nSequent\n=~\nwo\n0.8193488\n0.05332369\n15.365569\n0.000000e+00\n0.71483633\n0.9238614\n\n\nSimultan\n=~\nhm\n0.3911092\n0.07920463\n4.937959\n7.894445e-07\n0.23587098\n0.5463474\n\n\nSimultan\n=~\ngc\n0.4995384\n0.06083464\n8.211414\n2.220446e-16\n0.38030467\n0.6187721\n\n\nSimultan\n=~\ntr\n0.7173674\n0.04430383\n16.191995\n0.000000e+00\n0.63053351\n0.8042013\n\n\nSimultan\n=~\nsm\n0.6659822\n0.04841876\n13.754631\n0.000000e+00\n0.57108320\n0.7608813\n\n\nSimultan\n=~\nma\n0.5978175\n0.05378959\n11.114002\n0.000000e+00\n0.49239189\n0.7032432\n\n\nSimultan\n=~\nps\n0.7766261\n0.03976255\n19.531596\n0.000000e+00\n0.69869292\n0.8545593\n\n\nSequent\n~~\nSequent\n1.0000000\n0.00000000\nNA\nNA\n1.00000000\n1.0000000\n\n\nSimultan\n~~\nSimultan\n1.0000000\n0.00000000\nNA\nNA\n1.00000000\n1.0000000\n\n\nhm\n~~\nhm\n0.6825461\n0.06079284\n11.227409\n0.000000e+00\n0.56339433\n0.8016979\n\n\nnr\n~~\nnr\n0.3313302\n0.08720260\n3.799545\n1.449621e-04\n0.16041623\n0.5022441\n\n\nwo\n~~\nwo\n0.3286675\n0.08738141\n3.761297\n1.690344e-04\n0.15740304\n0.4999319\n\n\ngc\n~~\ngc\n0.7504614\n0.06077847\n12.347487\n0.000000e+00\n0.63133780\n0.8695850\n\n\ntr\n~~\ntr\n0.4853840\n0.06356425\n7.636116\n2.242651e-14\n0.36080034\n0.6099676\n\n\nsm\n~~\nsm\n0.5564677\n0.06449207\n8.628466\n0.000000e+00\n0.43006551\n0.6828698\n\n\nma\n~~\nma\n0.6426142\n0.06431272\n9.992024\n0.000000e+00\n0.51656358\n0.7686648\n\n\nps\n~~\nps\n0.3968519\n0.06176127\n6.425579\n1.313689e-10\n0.27580204\n0.5179018\n\n\nSequent\n~~\nSimultan\n0.5096198\n0.07025682\n7.253670\n4.056755e-13\n0.37191898\n0.6473207\n\n\n\n\n\n\nrelevant_loadings &lt;- loadings[loadings$op == \"=~\", c(\"lhs\", \"rhs\", \"est.std\")]\nrelevant_loadings\n\n\nA lavaan.data.frame: 9 x 3\n\n\n\nlhs\nrhs\nest.std\n\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n\n\n\n\n1\nSequent\nhm\n0.2525843\n\n\n2\nSequent\nnr\n0.8177223\n\n\n3\nSequent\nwo\n0.8193488\n\n\n4\nSimultan\nhm\n0.3911092\n\n\n5\nSimultan\ngc\n0.4995384\n\n\n6\nSimultan\ntr\n0.7173674\n\n\n7\nSimultan\nsm\n0.6659822\n\n\n8\nSimultan\nma\n0.5978175\n\n\n9\nSimultan\nps\n0.7766261\n\n\n\n\n\nIdealmente, per sostenere l’ipotesi di validità convergente, un fattore dovrebbe spiegare almeno il 50% della varianza in ciascuno dei suoi indicatori continui, come sostengono Bagozzi e Yi (2012). Ciò implica che, per essere considerato adeguatamente rappresentativo del costrutto che intende misurare, tutti gli indicatori di un fattore dovrebbero mostrare che la maggior parte della loro varianza è spiegata dal fattore stesso. Un modo meno rigoroso ma ancora informativo per valutare la validità convergente è attraverso l’uso della Varianza Media Estratta (AVE), calcolata come la media dei quadrati dei carichi fattoriali standardizzati di tutti gli indicatori associati a un particolare fattore. Un valore AVE superiore a 0.50 indica che, in media, il fattore spiega più della metà della varianza degli indicatori rispetto alla varianza residua attribuibile agli errori di misurazione, come indicato da Hair et al. (2022).\nNell’ambito di un modello a due fattori, i risultati ottenuti dall’esempio in esame evidenziano alcune criticità in relazione al criterio più stringente: il modello non riesce a spiegare una variazione significativa (R^2 &gt; 0.50) per quattro dei otto indicatori, ossia la metà di essi. Tuttavia, se consideriamo l’AVE, i risultati migliorano leggermente per il fattore sequenziale, che spiega in media circa il 52% della varianza dei suoi tre indicatori (AVE = 0.517).\nNella pratica analitica reale, valori di R^2 inferiori a 0.50 sono spesso considerati accettabili. Comrey e Lee (1992) hanno proposto una scala di valutazione gradiente in cui un R^2 superiore a 0.50 è classificato come eccellente, mentre valori approssimativamente pari a 0.40, 0.30, 0.20 e 0.10 sono considerati molto buoni, buoni, sufficienti e scarsi, rispettivamente. Secondo queste linee guida più flessibili, i risultati per gli indicatori del modello CFA a due fattori della KABC-I sono classificati come “eccellenti” (R^2 &gt; 0.50) per tre degli otto indicatori, nessuno è giudicato “scarso” (R^2 circa 0.10), e i rimanenti cinque indicatori presentano valori intermedi. È essenziale sottolineare che queste linee guida non dovrebbero essere applicate in modo indiscriminato in tutti i contesti di CFA o con tutti i tipi di indicatori. Gli indicatori continui, come i punteggi totali nell’esempio citato, tendono a mostrare carichi fattoriali più elevati rispetto agli indicatori ordinali, come quelli basati su scale di risposta tipo Likert.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#considerazioni-finali",
    "href": "chapters/cfa/01_cfa.html#considerazioni-finali",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.9 Considerazioni Finali",
    "text": "21.9 Considerazioni Finali\nL’analisi fattoriale confermativa (CFA) rappresenta uno strumento cruciale nell’ambito delle ricerche psicologiche e sociali, in quanto consente di esaminare modelli di misurazione riflessiva. In questi modelli, i fattori comuni agiscono come proxy per le variabili teoriche. La CFA richiede che il ricercatore definisca preventivamente aspetti critici del modello, come il numero di fattori, l’assegnazione degli indicatori ai fattori e gli schemi di covarianza degli errori.\nNei modelli CFA base, ciascun indicatore continuo è associato a un unico fattore e si presume che gli errori siano indipendenti, formando così una struttura unidimensionale. L’analisi di modelli con più fattori permette di verificare le ipotesi di validità convergente e discriminante.\nÈ anche possibile esplorare modelli CFA che includono covarianze di errore o indicatori correlati a più fattori. Tuttavia, gestire tali modelli è più complesso, specialmente in termini di identificazione del modello. Problemi tecnici come la non convergenza delle soluzioni o risultati inammissibili sono più comuni nei campioni di dimensioni ridotte o quando i fattori sono definiti da soli due indicatori. L’aggiustamento del modello può diventare una sfida, considerata l’ampia varietà di modifiche potenziali.\nUn’altra questione critica è rappresentata dai modelli CFA equivalenti, i quali possono produrre risultati simili nonostante le loro differenze strutturali. Per affrontare queste sfide efficacemente, è essenziale fondare l’analisi più su basi teoriche che su meri calcoli statistici. L’efficacia della CFA, quindi, dipende notevolmente dal contesto teorico e dalla competenza metodologica del ricercatore, essendo cruciale un’approfondita comprensione del dominio di studio per guidare l’analisi.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#session-info",
    "href": "chapters/cfa/01_cfa.html#session-info",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.10 Session Info",
    "text": "21.10 Session Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggokabeito_0.1.0  viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n [5] ggExtra_0.10.1    bayesplot_1.11.1  gridExtra_2.3     patchwork_1.2.0  \n [9] semTools_0.5-6    semPlot_1.1.6     lavaan_0.6-17     psych_2.4.3      \n[13] scales_1.3.0      markdown_1.12     knitr_1.45        lubridate_1.9.3  \n[17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.0    \n[25] tidyverse_2.0.0   here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] rstudioapi_0.15.0  jsonlite_1.8.8     magrittr_2.0.3    \n  [4] TH.data_1.1-2      estimability_1.5   nloptr_2.0.3      \n  [7] rmarkdown_2.26     vctrs_0.6.5        minqa_1.2.6       \n [10] base64enc_0.1-3    rstatix_0.7.2      htmltools_0.5.7   \n [13] broom_1.0.5        Formula_1.2-5      htmlwidgets_1.6.4 \n [16] plyr_1.8.9         sandwich_3.1-0     emmeans_1.10.0    \n [19] zoo_1.8-12         uuid_1.2-0         igraph_2.0.2      \n [22] mime_0.12          lifecycle_1.0.4    pkgconfig_2.0.3   \n [25] Matrix_1.6-5       R6_2.5.1           fastmap_1.1.1     \n [28] shiny_1.8.0        digest_0.6.35      OpenMx_2.21.11    \n [31] fdrtool_1.2.17     colorspace_2.1-0   rprojroot_2.0.4   \n [34] Hmisc_5.1-1        fansi_1.0.6        timechange_0.3.0  \n [37] abind_1.4-5        compiler_4.3.3     withr_3.0.0       \n [40] glasso_1.11        htmlTable_2.4.2    backports_1.4.1   \n [43] carData_3.0-5      ggsignif_0.6.4     MASS_7.3-60.0.1   \n [46] corpcor_1.6.10     gtools_3.9.5       tools_4.3.3       \n [49] pbivnorm_0.6.0     foreign_0.8-86     zip_2.3.1         \n [52] httpuv_1.6.14      nnet_7.3-19        glue_1.7.0        \n [55] quadprog_1.5-8     nlme_3.1-164       promises_1.2.1    \n [58] lisrelToR_0.3      grid_4.3.3         pbdZMQ_0.3-11     \n [61] checkmate_2.3.1    cluster_2.1.6      reshape2_1.4.4    \n [64] generics_0.1.3     gtable_0.3.4       tzdb_0.4.0        \n [67] data.table_1.15.2  hms_1.1.3          car_3.1-2         \n [70] utf8_1.2.4         sem_3.1-15         pillar_1.9.0      \n [73] IRdisplay_1.1      rockchalk_1.8.157  later_1.3.2       \n [76] splines_4.3.3      lattice_0.22-5     survival_3.5-8    \n [79] kutils_1.73        tidyselect_1.2.0   miniUI_0.1.1.1    \n [82] pbapply_1.7-2      stats4_4.3.3       xfun_0.42         \n [85] qgraph_1.9.8       arm_1.13-1         stringi_1.8.3     \n [88] boot_1.3-29        evaluate_0.23      codetools_0.2-19  \n [91] mi_1.1             cli_3.6.2          RcppParallel_5.1.7\n [94] IRkernel_1.3.2     rpart_4.1.23       xtable_1.8-4      \n [97] repr_1.1.6         munsell_0.5.0      Rcpp_1.0.12       \n[100] coda_0.19-4.1      png_0.1-8          XML_3.99-0.16.1   \n[103] parallel_4.3.3     ellipsis_0.3.2     jpeg_0.1-10       \n[106] lme4_1.1-35.1      mvtnorm_1.2-4      openxlsx_4.2.5.2  \n[109] crayon_1.5.2       rlang_1.1.3        multcomp_1.4-25   \n[112] mnormt_2.1.1      \n\n\n\n\n\n\nKline, Rex B. 2023. Principles and practice of structural equation modeling. Guilford publications.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#limitazioni-dellapproccio-fattoriale",
    "href": "chapters/cfa/01_cfa.html#limitazioni-dellapproccio-fattoriale",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.2 Limitazioni dell’approccio fattoriale",
    "text": "21.2 Limitazioni dell’approccio fattoriale\nL’approccio classico dell’analisi fattoriale (EFA più rotazione fattoriale) ha rivelato avere diversi limiti. Nella ricerca iniziale, dibattiti teorici importanti, come il numero di fattori dell’intelligenza o della personalità, erano basati sui risultati di diverse rotazioni fattoriali. Questi dibattiti si sono rivelati essere semplici speculazioni, poiché conclusioni diverse potevano essere supportate a seconda dell’interpretazione dei dati. Per esempio, il dibattito tra Eysenck e Cattell sul numero di fattori della personalità (due o sedici) dipendeva dall’uso di rotazioni ortogonali o oblique sugli stessi dati.\nNella seconda metà del XX secolo, c’era una generale insoddisfazione verso l’analisi fattoriale a causa della sua apparente capacità di adattarsi a quasi qualsiasi soluzione. Furono raccomandati criteri rigorosi per il suo uso, come la necessità di grandi campioni, che spesso rendevano l’analisi impraticabile a quei tempi. Inoltre, furono introdotti vincoli relativi alle ipotesi del modello e al requisito che le variabili nella matrice di correlazione avessero varianze equivalenti, creando problemi pratici significativi, specialmente con dati binari spesso usati nei test psicometrici.\nSolo con l’introduzione di metodi psicometrici moderni, come l’analisi fattoriale confermativa (CFA) discussa in questo capitolo e la Teoria di Risposta all’Item (discussa in una sezione successiva), questi problemi sono stati risolti.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  },
  {
    "objectID": "chapters/cfa/01_cfa.html#scalatura-dei-fattori-e-inclusione-delle-covariate-nei-modelli-cfa-di-base",
    "href": "chapters/cfa/01_cfa.html#scalatura-dei-fattori-e-inclusione-delle-covariate-nei-modelli-cfa-di-base",
    "title": "21  Analisti Fattoriale Confermativa",
    "section": "21.6 Scalatura dei Fattori e Inclusione delle Covariate nei Modelli CFA di Base",
    "text": "21.6 Scalatura dei Fattori e Inclusione delle Covariate nei Modelli CFA di Base\nNella rappresentazione di base dei modelli Confermative Factor Analysis (CFA), la scalatura dei fattori viene spesso eseguita utilizzando il metodo della variabile di riferimento, conosciuto anche come metodo della variabile marker o approccio di identificazione del carico di riferimento (Newsom, 2015). In questo approccio, un vincolo di Unit Loading Identification (ULI) è applicato al carico di un indicatore per ciascun fattore. Per esempio, nel modello illustrato, il carico di \\(X1\\) sul fattore \\(A\\) è fissato a 1.0, stabilendo così la varianza del fattore \\(A\\) sulla base della varianza comune dell’indicatore \\(X1\\), che funge da variabile di riferimento per \\(A\\). Analogamente, la varianza del fattore \\(B\\) è calibrata utilizzando \\(X4\\) come variabile marker.\nQuando più indicatori per lo stesso fattore presentano precisione equivalente e nessuno di essi è considerato particolarmente rappresentativo del concetto sottostante, la scelta dell’indicatore come variabile di riferimento diventa generalmente arbitraria. Questa selezione non influisce solitamente sull’adattamento globale del modello, sulla soluzione standardizzata, o sulle stime delle varianze di errore dell’indicatore nelle soluzioni non standardizzate. Le saturazioni fisse a 1.0 per le variabili di riferimento rimangono invariate nelle soluzioni non standardizzate e non sono soggette a test di significatività, poiché sono considerate costanti.\nUn potenziale svantaggio di questo metodo è l’assenza di test di significatività per le saturazioni fisse, il che può essere limitante se si desidera valutare la significatività di tutte le saturazioni. Metodi alternativi per scalare i fattori, che non richiedono la selezione di variabili di riferimento, saranno discussi nelle sezioni successive.\nNei modelli CFA di base, tutti i fattori sono considerati variabili esogene, il che significa che sono liberi di variare e covariare indipendentemente l’uno dall’altro. Tuttavia, è possibile includere variabili esterne, dette covariate, che si presume possano influenzare i fattori comuni. Ad esempio, l’età dei partecipanti potrebbe essere vista come una covariata che influisce sui fattori comuni in un modello CFA.\nL’inclusione di covariate trasforma i fattori comuni da variabili esogene a endogene, implicando che non sono più completamente liberi di variare in modo indipendente, ma possono essere direttamente influenzati dalle covariate. Questo richiede l’aggiunta di termini di disturbo nei fattori comuni per rappresentare l’effetto diretto delle covariate su di essi, integrando così l’effetto delle variabili esterne nel modello CFA.\n\n21.6.1 Parametri del Modello nella CFA\nIn un modello CFA con indicatori continui, quando le medie delle variabili non sono considerate, i parametri liberi includono varianze, covarianze di variabili esogene e gli effetti diretti (carichi) sulle variabili endogene. Ad esempio, analizzando il modello di base illustrato in figura, i parametri liberi possono essere suddivisi come segue:\n\nVarianze: Comprendono le varianze di due fattori e sei termini di errore associati agli indicatori, per un totale di otto varianze.\nCovarianza: È presente una covarianza tra i due fattori.\nEffetti Diretti (Carichi): Quattro carichi fattoriali rappresentano gli effetti diretti dei fattori sugli indicatori, specificamente per gli indicatori X2, X3, X5 e X6. Questi carichi non sono fissati, a differenza di quelli usati per scalare i fattori.\n\nSommando questi parametri, il totale dei parametri liberi nel modello è 13. Con \\(v = 6\\) variabili osservate, il numero totale di osservazioni statisticamente indipendenti, calcolato come \\(6(7)/2\\), è 21. Di conseguenza, i gradi di libertà per il modello presentato sono calcolati sottraendo i parametri liberi dalle osservazioni indipendenti, risultando in \\(21 - 13 = 8\\) gradi di libertà.\n\n21.6.1.1 Requisiti di Identificazione: Necessari ma Non Sufficienti per i Modelli di CFA\nPer assicurare che un modello di Confermative Factor Analysis (CFA) sia correttamente specificato e possa essere utilizzato per trarre conclusioni valide, è fondamentale soddisfare alcuni requisiti di identificazione essenziali. Questi requisiti sono necessari ma non sempre sufficienti; cioè, la loro soddisfazione non garantisce automaticamente l’identificazione completa del modello.\n\nGradi di Libertà (dfM) Maggiori o Uguali a Zero:\n\nCalcolo: I gradi di libertà di un modello CFA si determinano sottraendo il numero di parametri liberi (come varianze, covarianze, e carichi fattoriali) dal numero totale di osservazioni indipendenti disponibili, solitamente le varianze e covarianze degli indicatori.\nSignificato: Avere gradi di libertà positivi indica che ci sono sufficienti dati per stimare i parametri del modello e verificare il suo adattamento. Un modello con zero gradi di libertà è “saturato” e si adatterà perfettamente ai dati, ma non fornirà validazione ulteriore.\nImportanza: Mantenere dfM ≥ 0 è cruciale per evitare la sottospecificazione del modello, che potrebbe condurre a stime inaccurate e conclusioni fuorvianti.\n\nScalatura Corretta di Ogni Variabile Non Misurata:\n\nNecessità: È essenziale scalare ogni variabile latente, come i fattori, per definirne l’unità di misura. Senza una scalatura adeguata, parametri come i carichi fattoriali rimarrebbero indeterminati.\nMetodi: La scalatura può essere effettuata in vari modi, come fissando il carico di un indicatore per fattore a 1.0 (metodo della variabile di riferimento), fissando la varianza del fattore a un valore preciso, tipicamente 1.0 (metodo della standardizzazione della varianza), o applicando vincoli alle stime delle saturazioni fattoriali (metodo di codifica degli effetti).\n\n\nIn sintesi, pur essendo fondamentale soddisfare questi requisiti per stabilire una base identificabile e interpretabile per un modello CFA, l’identificazione completa del modello può richiedere considerazioni aggiuntive legate alla struttura specifica e alle ipotesi teoriche che sottendono al modello.\n\n\n\n\n\n\nFigura 21.2: Scalatura dei fattori nel metodo della variabile di riferimento con vincoli di identificazione del carico unitario (ULI) (a), metodo di standardizzazione della variabile con vincoli di identificazione della varianza unitaria (UVI) (b) e metodo di codifica degli effetti con vincoli di identificazione della codifica degli effetti (ECI) (a + b + c)/3 = (d + e + f)/3 = 1.0 (c). (Figura tratta da Kline (2023))\n\n\n\n\n\n21.6.1.2 Requisiti Sufficienti Aggiuntivi per l’Identificazione nei Modelli CFA\nOltre ai criteri base, esistono requisiti addizionali che favoriscono l’identificazione adeguata nei modelli di Confermative Factor Analysis (CFA):\n\nRegola dei Tre Indicatori per i Modelli a Singolo Fattore: Affinché un modello CFA con un solo fattore sia pienamente identificabile, è necessario che disponga di almeno tre indicatori. Questo è dovuto al fatto che con solamente due indicatori non si dispone di sufficiente informazione per separare accuratamente la varianza del fattore e i suoi carichi specifici dagli errori di misurazione. Un modello con esattamente tre indicatori ha zero gradi di libertà, il che significa che si adatterà perfettamente ai dati ma non permetterà ulteriori test o validazioni. Per garantire gradi di libertà positivi (dfM &gt; 0) e consentire un’efficace validazione del modello, è consigliabile utilizzare almeno quattro indicatori.\nRegola dei Due Indicatori per i Modelli con Più Fattori: Nei modelli CFA che coinvolgono più di un fattore, è essenziale che ogni fattore sia rappresentato da almeno due indicatori. Questa disposizione aiuta a definire chiaramente ogni fattore e a distinguerlo dagli altri fattori presenti nel modello. Tuttavia, i modelli che si limitano a due indicatori per fattore possono presentare problematiche, specialmente in campioni di dimensioni ridotte, poiché possono emergere instabilità nelle stime e complessità nell’interpretazione dei risultati.\n\nQuesti requisiti aggiuntivi sono fondamentali non solo per garantire che un modello CFA sia teoricamente valido (attraverso una corretta scalatura e definizione delle variabili latenti), ma anche per assicurare la sua utilità pratica, fornendo sufficienti gradi di libertà per consentire validazioni affidabili e interpretazioni significative del modello.",
    "crumbs": [
      "Analisi fattoriale confermativa",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Analisti Fattoriale Confermativa</span>"
    ]
  }
]
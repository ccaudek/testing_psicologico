# Valutazione della matrice di correlazione {#sec-extraction-cor-matrix}

::: callout-important
## In questo capitolo imparerai a:

- esaminare la matrice di correlazione tra le variabili come passo preliminare di un'analisi fattoriale.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Factor Analysis and Principal Component Analysis* del testo di @petersen2024principles.
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(lavaan, corrr, psych)
```
:::

## Introduzione

Prima di eseguire un'analisi fattoriale esplorativa (EFA), √® fondamentale valutare se i dati soddisfano i presupposti minimi richiesti. Il primo passo consiste nell'esaminare la **matrice di correlazione** tra le variabili. Se il **determinante** di questa matrice √® pari a zero, significa che esiste **collinearit√† perfetta** tra alcune variabili: in questo caso, l‚Äôanalisi fattoriale non pu√≤ essere effettuata perch√© non sarebbe possibile distinguere contributi distinti dei fattori latenti.

Tuttavia, anche se il determinante √® diverso da zero, non √® detto che i dati siano adatti all‚ÄôEFA. √à necessario che le variabili mostrino **correlazioni sufficientemente elevate** tra loro, altrimenti l‚Äôanalisi potrebbe produrre **soluzioni instabili o difficili da interpretare**. Correlazioni troppo deboli indicano che non esistono dimensioni comuni sottostanti e quindi non ha senso estrarre dei fattori.

Per valutare l‚Äôadeguatezza dei dati, possiamo:

- **ispezionare visivamente** la matrice di correlazione,
- calcolare il **test di sfericit√† di Bartlett**,
- calcolare l‚Äô**indice di adeguatezza campionaria KMO** (Kaiser-Meyer-Olkin).

Questi strumenti forniscono informazioni complementari sull'opportunit√† di procedere con un‚Äôanalisi fattoriale.


## Analisi Preliminari

Per illustrare il procedimento, utilizziamo il dataset `HolzingerSwineford1939`, che contiene **301 osservazioni** relative a **punteggi di abilit√† mentale** su diverse prove cognitive. In questa analisi considereremo le variabili `x1`‚Äì`x9`.

Cominciamo con l'importazione del dataset e la verifica dell‚Äôintegrit√† dei dati.

```{r}
# Caricamento del dataset e visualizzazione iniziale
data(HolzingerSwineford1939)
glimpse(HolzingerSwineford1939)

# Selezione delle variabili di interesse
hz <- HolzingerSwineford1939 |>
  dplyr::select(x1:x9)

# Visualizzazione delle prime 5 righe
hz |> slice(1:5)
```

### Valutazione dei Dati Mancanti

Prima di esaminare le correlazioni, √® importante verificare **l‚Äôeventuale presenza di dati mancanti**, poich√© anche pochi valori mancanti possono alterare significativamente la matrice di correlazione.

```{r}
# Controllo dei dati mancanti
hz |> summarise(across(everything(), ~ sum(is.na(.))))
```

In questo caso, **non sono presenti dati mancanti**. In presenza di dati mancanti, sar√† necessario adottare strategie appropriate (es. imputazione, listwise deletion, ecc.) prima di procedere.

> üîç *Nota didattica:* In genere, per l‚Äôanalisi fattoriale √® preferibile utilizzare una matrice di correlazione calcolata su dati completi, perch√© la presenza di dati mancanti pu√≤ distorcere le relazioni tra le variabili.

### Esplorazione delle Distribuzioni

Un controllo preliminare utile √® l‚Äôesame della **forma delle distribuzioni** delle variabili, in particolare **asimmetria** (skewness) e **curtosi** (kurtosis), che possono indicare violazioni di normalit√†.

```{r}
describe(hz)
```

In questo caso, i valori di asimmetria e curtosi sono **sufficientemente contenuti**, quindi non √® necessario trasformare le variabili. Tuttavia, se ci fossero valori molto estremi, una trasformazione (log, z-score, Box-Cox) potrebbe essere utile.


### Ispezione della Matrice di Correlazione

Una **matrice di correlazione** √® la base concettuale dell'analisi fattoriale: essa mostra quanto ogni variabile √® associata con le altre. In presenza di **gruppi di variabili altamente correlate tra loro e poco correlate con le altre**, √® plausibile che esistano **fattori comuni sottostanti**.

Visualizziamo la matrice utilizzando il pacchetto `corrr`:

```{r}
#| fig-asp: 1
#| fig-width: 6
#| fig-height: 6
#| 
cor_tb <- correlate(hz)

cor_tb |>
  rearrange() |>
  rplot(colors = c("red", "white", "blue"))
```

Il grafico mostra tre blocchi distinti:

- **x4‚Äìx6**: un primo gruppo fortemente correlato tra loro,
- **x1‚Äìx3**: un secondo gruppo coeso,
- **x7‚Äìx9**: un terzo gruppo distinto.

Questa struttura √® coerente con l‚Äôidea che i punteggi derivino da **tre fattori latenti** diversi.


## Test di Sfericit√† di Bartlett

Il **test di sfericit√† di Bartlett** verifica se la matrice di correlazione differisce significativamente da una matrice identit√† (cio√® una matrice in cui tutte le variabili sono incorrelate).

**Ipotesi nulla**: le variabili non sono correlate tra loro.  
**Ipotesi alternativa**: esistono correlazioni significative tra le variabili.

La formula del test √®:

$$
\chi^2 = -\left[n - 1 - \frac{1}{6}(2p + 5)\right] \ln |\boldsymbol{R}|,
$$

dove:

- $n$ = numerosit√† campionaria,
- $p$ = numero di variabili,
- $|\boldsymbol{R}|$ = determinante della matrice di correlazione.

Il test restituisce una **statistica $\chi^2$** con $p(p - 1)/2$ gradi di libert√†.

```{r}
cor_mat <- cor(hz)

out = cortest.bartlett(R = cor_mat, n = 301)
print(out)
```

Risultato: la statistica √® altamente significativa ‚Üí **possiamo rifiutare l‚Äôipotesi nulla**. Le variabili sono sufficientemente correlate per proseguire con l‚Äôanalisi fattoriale.

> üìå *Nota:* Il test di Bartlett √® molto sensibile alla numerosit√† campionaria: con campioni ampi, anche correlazioni deboli possono risultare statisticamente ‚Äúsignificative‚Äù. √à quindi opportuno integrare il test con altri indici, come il KMO.


## Indice KMO (Kaiser-Meyer-Olkin)

L‚Äôindice **KMO** misura quanto le correlazioni osservate siano spiegabili da **fattori latenti comuni**, piuttosto che da correlazioni parziali tra le variabili (che rappresentano associazioni "spuriate").

La formula √®:

$$
\text{KMO} = \frac{\sum_i \sum_j r^2_{ij}}{\sum_i \sum_j r^2_{ij} + \sum_i \sum_j p^2_{ij}},
$$

dove $r_{ij}$ sono le correlazioni osservate, e $p_{ij}$ le correlazioni parziali.

Valori possibili:

- **0.90‚Äì1.00**: eccellente (*meravigliosa*)
- **0.80‚Äì0.89**: molto buona (*meritevole*)
- **0.70‚Äì0.79**: buona (*media*)
- **0.60‚Äì0.69**: discreta (*mediocre*)
- **0.50‚Äì0.59**: scarsa (*miserabile*)
- **< 0.50**: inadeguata (*inaccettabile*)

```{r}
out = KMO(cor_mat)
print(out)
```

Nel nostro caso, il valore KMO √® **attorno a 0.70**, quindi l‚Äôadeguatezza √® **buona**, ma non eccellente. Possiamo proseguire con l‚Äôanalisi, pur restando consapevoli che la qualit√† dei dati potrebbe essere migliorata (es. con la revisione degli item).


## Riflessioni conclusive

Le analisi preliminari condotte sul dataset `HolzingerSwineford1939` indicano che:

- le **correlazioni tra variabili** sono presenti e coerenti con una struttura a pi√π fattori,
- il **test di Bartlett** conferma che la matrice di correlazione √® diversa da una matrice identit√†,
- l‚Äô**indice KMO** suggerisce un‚Äôadeguatezza campionaria soddisfacente, anche se non ottimale.

Questi risultati ci consentono di procedere con l‚Äôanalisi fattoriale esplorativa, ma evidenziano anche la necessit√† di **valutazioni critiche** in fase interpretativa. L‚Äôuso combinato di pi√π strumenti diagnostici consente di fondare l‚Äôanalisi su basi solide e di trarre conclusioni pi√π affidabili riguardo alla struttura latente dei dati.

## Session Info

```{r}
#| vscode: {languageId: r}
sessionInfo()
```


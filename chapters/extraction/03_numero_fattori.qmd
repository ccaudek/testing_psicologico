# Determinare il numero dei fattori {#sec-extraction-number-factors}

::: callout-important
## In questo capitolo imparerai:

- 
:::

::: callout-tip
## Prerequisiti

- Leggere l'articolo *How many factors to retain in exploratory factor analysis? A critical overview of factor retention methods* [@goretzko2025many].
:::

::: callout-caution
## Preparazione del Notebook

```{r}
# library(devtools)
# install_github("jmbh/fspe")
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(
  lavaan, psych, paran, fspe, nFactors, semTools, EFAtools, MASS,
  EFAfactors, EGAnet, latentFactoR, REFA
)
```
:::


## Introduzione

L‚ÄôAnalisi Fattoriale Esplorativa (EFA) √® uno strumento fondamentale nella costruzione e valutazione di test psicologici. Essa consente di esplorare la struttura latente sottostante a un insieme di variabili osservate. Uno degli aspetti pi√π delicati dell'EFA √® la **determinazione del numero di fattori da estrarre**, nota anche come *factor retention*. Una scelta errata pu√≤ compromettere l‚Äôintera analisi, portando a:

- **Sottofattorizzazione**: sottostimare il numero di fattori, rischiando di distorcere la struttura latente e generare caricamenti spurii (cross-loadings);
- **Sovrafattorizzazione**: estrarre pi√π fattori del necessario, introducendo elementi poco interpretabili. Questo errore √® meno grave, purch√© venga riconosciuto e gestito opportunamente.

### Tre domande fondamentali sulla dimensionalit√† di un test

1. **Quante dimensioni?** Alcuni test misurano un solo costrutto latente, altri ne misurano diversi.
2. **Le dimensioni sono correlate?** Se s√¨, √® opportuno utilizzare metodi di rotazione obliqua.
3. **Cosa significano le dimensioni?** L‚Äôinterpretazione teorica dei fattori √® cruciale per l‚Äôapplicazione pratica del test.

Questo capitolo presenta e confronta i principali approcci proposti per determinare il numero ottimale di fattori, illustrandone i presupposti, i punti di forza e le limitazioni.

## Metodi basati sugli autovalori

### Kaiser-Guttman Rule

Retiene i fattori con autovalore > 1 (solo per matrici di correlazione). Anche se molto diffuso, √® fortemente sconsigliato: ha una tendenza sistematica alla **sovrafattorizzazione**. √à inappropriato per dati non standardizzati o con bassa comunalit√†.

### Scree Test (Cattell)

Grafico degli autovalori decrescenti: il numero di fattori corrisponde al punto prima del "gomito". Soggettivo e a bassa affidabilit√†.

### Valore medio degli autovalori

Retiene i fattori con autovalore maggiore della media degli autovalori. Alternativa alla regola di Kaiser, ma ancora euristica.

### Metodi Avanzati

- **Empirical Kaiser Criterion (EKC)**: corregge per numerosit√† campionaria e varianza cumulata. Buona performance solo in strutture semplici e unidimensionali.
- **STOC** e **STAF**: automatizzano lo scree test via algoritmi (es. accelerazione della pendenza) -- implementate in `nFactors`.

## Metodi Basati sulla Simulazione

### Parallel Analysis (PA)

Considerata lo "standard aureo". Confronta gli autovalori empirici con quelli derivati da dati casuali:

- variante standard: usa la media degli autovalori simulati;
- variante di Glorfeld: usa il 95¬∞ percentile per essere pi√π conservativa;
- funzioni: `fa.parallel()` del pacchetto `psych`.

### Comparison Data (CD)

Usa bootstrap e riproduce la matrice di correlazione. Confronta soluzioni adiacenti con un test di Mann-Whitney sugli RMSE. Utile con fattori correlati, ma tende a sovrafattorizzare se non ben calibrato. Implementato in `EFAtools`.

## Approcci basati sul confronto tra modelli

### Criteri Informativi: AIC, BIC

Utilizzano la verosimiglianza e penalizzano la complessit√† del modello.

- AIC: tende a selezionare modelli pi√π complessi;
- BIC: pi√π conservativo.

### Indici di Fit: 

Gli indicici di fit come RMSEA, CFI, SRMR, ecc. sono usati pi√π comunemente in CFA, ma sono meno affidabili in EFA a causa della dipendenza da dimensione campionaria e altri fattori.

### Metodo Hull

Il **metodo Hull** (Lorenzo-Seva, Timmerman, & Kiers, 2011) √® un approccio grafico per la determinazione del numero ottimale di fattori. L‚Äôidea di base √® bilanciare **bont√† dell‚Äôadattamento** e **parsimonia del modello** (cio√® la semplicit√†).

Come funziona:

1. si adattano diversi modelli fattoriali con un numero crescente di fattori;
2. per ciascun modello, si registra un indice di fit (es. CFI) e i **gradi di libert√†**;
3. si costruisce il **"convex hull"**, ovvero il contorno convesso che racchiude i punti CFI ~ gradi di libert√†;
4. si identifica il punto sul contorno del hull che rappresenta il miglior compromesso tra **fit accettabile** e **modello semplice** (cio√® con pi√π gradi di libert√†).

Vantaggi:

- tende a evitare la **sovrafattorizzazione**, comune in altri metodi;
- ha buone prestazioni quando il modello √® **ben sovradeterminato** (cio√® ogni fattore √® misurato da molte variabili);
- √® adatto anche in presenza di **fattori correlati**.

## Minimum Average Partial (MAP)

Test che valuta la media delle correlazioni parziali residue dopo estrazione di i componenti. Retiene il numero di componenti che minimizza questa media. √à implementato in `vss()` del pacchetto `psych`.

## Approcci moderni

### Analisi Esplorativa della Rete (EGA)

L‚Äô**Exploratory Graph Analysis (EGA)** √® un metodo alternativo all‚Äôanalisi fattoriale esplorativa (EFA), che non si basa sull‚Äôipotesi di **fattori latenti comuni**, ma sull‚Äôidentificazione di **comunit√† di variabili** all‚Äôinterno di un **modello a rete**.

- In EGA, le **variabili osservate** (es. item di un test) sono rappresentate come **nodi** di una rete.
- Le **connessioni** (archi) tra i nodi riflettono **correlazioni parziali** standardizzate, cio√® relazioni tra due variabili controllando per tutte le altre.
- Il modello statistico di base √® il **Gaussian Graphical Model (GGM)**, stimato con un metodo di **massima verosimiglianza penalizzata** (regularization), che tende ad annullare le correlazioni pi√π deboli, producendo reti **sparse** (con pochi collegamenti).
- All‚Äôinterno di questa rete, le variabili **fortemente collegate tra loro** tendono a raggrupparsi in **comunit√†** (clusters), che vengono interpretate come **fattori**.

Vantaggi dell‚ÄôEGA:

- √® particolarmente utile in condizioni in cui:
  - le **comunalit√† sono basse** (cio√® le variabili condividono poca varianza comune),
  - i dati sono **ordinali** o non normalmente distribuiti.
- rispetto all‚ÄôEFA tradizionale, EGA √® pi√π robusto a **strutture complesse o deboli**.

Come viene determinato il numero di fattori?

Il numero di comunit√† (e quindi di fattori) viene identificato attraverso **algoritmi di rilevamento delle comunit√†**, come il **walktrap algorithm**, che cerca sottogruppi fortemente interconnessi all‚Äôinterno della rete.

In sintesi, EGA fornisce una rappresentazione grafica e interpretabile della struttura fattoriale dei dati, e pu√≤ essere usato per **decidere quanti fattori estrarre** in un‚Äôanalisi esplorativa.

## Metodi Basati su Machine Learning

### Factor Forest (ML)

Approccio machine learning addestrato su dati simulati. Molto preciso, ma dipende da modelli preaddestrati. Implementato in `latentFactoR`.

### Comparison Data Forest (CDF)

Versione pi√π leggera del Factor Forest basata su CD + Random Forest. Meno accurata ma pi√π accessibile. Implementazione disponibile su OSF.

### Regularized EFA (REFA)

Utilizza penalizzazioni (LASSO, Ridge, MC+) per ottenere strutture sparse. Pu√≤ essere utile per l‚Äôidentificazione automatica dei fattori. Implementazioni: `fanc`, `regsem`, `lslx`.


## Implementazione in R

Per confrontare i metodi discussi per la scelta del numero $m$ di fattori usiamo una matrice di correlazioni calcolata sulle sottoscale della WAIS. Le 11 sottoscale del test sono le seguenti:

- X1 = Information
- X2 = Comprehension
- X3 = Arithmetic
- X4 = Similarities
- X5 = Digit.span
- X6 = Vocabulary
- X7 = Digit.symbol
- X8 = Picture.completion
- X9 = Block.design
- X10 = Picture.arrangement
- X11 = Object.

I dati sono stati ottenuti dal manuale della III edizione.

```{r}
varnames <- c(
    "IN", "CO", "AR", "SI", "DS", "VO", "SY", "PC",
    "BD", "PA", "OA", "AG", "ED"
)
temp <- matrix(c(
    1, 0.67, 0.62, 0.66, 0.47, 0.81, 0.47, 0.60, 0.49, 0.51, 0.41,
    -0.07, 0.66, .67, 1, 0.54, 0.60, 0.39, 0.72, 0.40, 0.54, 0.45,
    0.49, 0.38, -0.08, 0.52, .62, .54, 1, 0.51, 0.51, 0.58, 0.41,
    0.46, 0.48, 0.43, 0.37, -0.08, 0.49, .66, .60, .51, 1, 0.41,
    0.68, 0.49, 0.56, 0.50, 0.50, 0.41, -0.19, 0.55, .47, .39, .51,
    .41, 1, 0.45, 0.45, 0.42, 0.39, 0.42, 0.31, -0.19, 0.43,
    .81, .72, .58, .68, .45, 1, 0.49, 0.57, 0.46, 0.52, 0.40, -0.02,
    0.62, .47, .40, .41, .49, .45, .49, 1, 0.50, 0.50, 0.52, 0.46,
    -0.46, 0.57, .60, .54, .46, .56, .42, .57, .50, 1, 0.61, 0.59,
    0.51, -0.28, 0.48, .49, .45, .48, .50, .39, .46, .50, .61, 1,
    0.54, 0.59, -0.32, 0.44, .51, .49, .43, .50, .42, .52, .52, .59,
    .54, 1, 0.46, -0.37, 0.49, .41, .38, .37, .41, .31, .40, .46, .51,
    .59, .46, 1, -0.28, 0.40, -.07, -.08, -.08, -.19, -.19, -.02,
    -.46, -.28, -.32, -.37, -.28, 1, -0.29, .66, .52, .49, .55, .43,
    .62, .57, .48, .44, .49, .40, -.29, 1
), nrow = 13, ncol = 13, byrow = TRUE)

colnames(temp) <- varnames
rownames(temp) <- varnames

wais_cor <- temp[1:11, 1:11]
wais_cor
```

##  Metodi basati sugli autovalori

```{r}
# Calcola gli autovalori della matrice di correlazione WAIS
wais_eigen <- eigen(wais_cor)
eigenvalues <- wais_eigen$values
print(eigenvalues)
```

### Kaiser-Guttman Rule

```{r}
kaiser_rule <- sum(eigenvalues > 1)
cat("Numero di fattori secondo la regola di Kaiser:", kaiser_rule, "\n")
```

**Spiegazione**: la regola di Kaiser suggerisce di mantenere i fattori con autovalori maggiori di 1.  
*Problema*: √® noto che **sovrastima** il numero di fattori, specialmente in campioni piccoli o quando le comunalit√† sono basse.

### Scree Plot (Cattell)

```{r}
# Scree plot
plot(eigenvalues, type = "b", pch = 19, main = "Scree plot (Cattell)", 
     xlab = "Numero di fattori", ylab = "Autovalore")
abline(h = 1, col = "red", lty = 2)
```

**Spiegazione**: Il numero ottimale di fattori corrisponde al punto **prima del "gomito"** nella curva degli autovalori decrescenti.  
*Problema*: il metodo √® **visivo e soggettivo**, quindi ha bassa affidabilit√†.

### Regola del valore medio degli autovalori

```{r}
mean_val <- mean(eigenvalues)
mean_rule <- sum(eigenvalues > mean_val)
cat("Numero di fattori secondo la regola del valore medio:", mean_rule, "\n")
```

**Spiegazione**: mantiene solo i fattori con autovalori superiori alla media.  
Questa √® una **variante della regola di Kaiser**, meno estrema, ma comunque euristica.

### Metodi avanzati con il pacchetto `nFactors`

```{r}
# Metodo EKC (Empirical Kaiser Criterion)
ekc_result <- efa.ekc(sample.cov = wais_cor, sample.nobs = 300)  # Specificare N = numerosit√† stimata
ekc_result
```

**Spiegazione**: EKC √® una versione empiricamente corretta della regola di Kaiser, che **tiene conto del campione**, della **forma della distribuzione**, e della **varianza spiegata cumulativa**.  
√à pi√π affidabile, soprattutto in strutture semplici.

### STOC e STAF (versioni automatizzate dello Scree Test)

```{r}
# Calcola autovalori simulati
nfac <- nFactors::nScree(x = eigenvalues)
summary(nfac)

# Plot per confronto
plotnScree(nfac)
```

**Spiegazione**:

- **STOC** = Optimal Coordinate
- **STAF** = Acceleration Factor  
Sono versioni **statistiche** dello scree test, che usano variazioni nella pendenza degli autovalori.


## Metodi basati sulla simulazione

### Parallel Analysis (PA)

```{r}
# Variante standard: confronto con media degli autovalori simulati
set.seed(123)  # Per replicabilit√†
fa.parallel(wais_cor, n.obs = 300, fa = "fa", fm = "ml", 
            main = "Parallel Analysis (media simulata)")
```


### Spiegazione

- Confronta gli **autovalori osservati** con quelli ottenuti da **dati casuali**.
- Se l‚Äôautovalore osservato > simulato ‚Üí **mantieni** il fattore.
- Il metodo √® **molto affidabile**, specie se il numero di soggetti (`n.obs`) √® corretto.
- La **variante di Glorfeld** (non mostrata) √® pi√π **conservativa** (riduce il rischio di sovrafattorizzare).


### Comparison Data (CD)

```{r}
# Metodo Comparison Data
# Richiede che i dati siano in formato "raw" (non solo matrice di correlazione)
# Quindi, simuliamo dati coerenti con la matrice di correlazione per scopi didattici:

set.seed(123)
N <- 300  # ipotetica numerosit√† campionaria
wais_sim <- mvrnorm(N, mu = rep(0, 11), Sigma = wais_cor)
colnames(wais_sim) <- colnames(wais_cor)

# Applica il metodo Comparison Data
cd_result <- EFAtools::CD(
  x = wais_sim,
  n_factors_max = 6,        # Numero massimo di fattori da testare
  N_pop = 10000,             # Dimensione della popolazione simulata
  N_samples = 500,           # Numero di campioni bootstrap
  alpha = 0.3,               # Soglia per il test di Mann-Whitney
  use = "pairwise.complete.obs",  # Gestione dei dati mancanti
  cor_method = "pearson",    # Metodo di correlazione
  max_iter = 50              # Iterazioni massime
)

# Mostra il riepilogo dei risultati
cd_result
```

### Spiegazione

- Il metodo **Comparison Data (CD)** simula set di dati "riprodotti" con un certo numero di fattori.
- Confronta il **RMSE** delle soluzioni successive con un **test di Mann-Whitney**.
- Il numero ottimale di fattori √® quello **oltre il quale non si osserva un miglioramento significativo**.
- *Attenzione*: pu√≤ **sovrafattorizzare** se `max_factors` √® troppo alto o se i dati sono rumorosi.
- Molto utile con **fattori correlati** e **strutture complesse**.

**In sintesi**:

- **PA (Parallel Analysis)** √® il metodo di riferimento, raccomandato dalla maggior parte delle linee guida (es. Fabrigar et al., 1999).
- **CD (Comparison Data)** √® utile in presenza di **fattori obliqui** o **bassa comunalit√†**, ma pu√≤ richiedere **parametri aggiustati** per una stima pi√π accurata.
-  Evita di usare **un solo criterio**: combina i risultati con quelli basati sugli **autovalori** e sulle **analisi di bont√† di adattamento** (RMSEA, BIC, ecc.).

## Indici di informazione

Consideriamo ora un'implementazione in R per determinare il numero di fattori da estrarre dalla matrice di correlazione WAIS utilizzando metodi basati sugli indici di informazione.

```{r}
dim(wais_cor)  # Dovrebbe essere 11x11
```

1. **Criteri Informativi AIC e BIC**:

   - Calcolo di AIC e BIC per modelli con 1-5 fattori.
   - Visualizzazione grafica per identificare il punto di minimo.

```{r}
# Calcolo il numero di fattori usando AIC e BIC
fa_fit <- function(nfactors, x, n.obs = 100) {
  fit <- fa(x, nfactors = nfactors, fm = "ml", n.obs = n.obs)
  chi <- fit$STATISTIC
  df <- fit$dof
  pval <- fit$PVAL
  aic <- chi - 2 * df
  bic <- chi - df * log(n.obs)
  list(nfactors = nfactors, chi = chi, df = df, pval = pval, aic = aic, bic = bic)
}
```

```{r}
# Assumiamo una dimensione campionaria di 100 
n.obs <- 100

# Calcoliamo AIC e BIC per diversi numeri di fattori
results <- data.frame()
for (i in 1:5) {
  res <- fa_fit(i, wais_cor, n.obs)
  results <- rbind(results, data.frame(
    nfactors = i,
    chi_square = res$chi,
    df = res$df,
    p_value = res$pval,
    aic = res$aic,
    bic = res$bic
  ))
}
```

```{r}
# Visualizziamo i risultati
print(results)
```

```{r}
# Grafici per AIC e BIC
par(mfrow = c(1, 2))
plot(results$nfactors, results$aic, type = "b", main = "AIC per numero di fattori", 
     xlab = "Numero di fattori", ylab = "AIC", xaxt = "n")
axis(1, at = 1:5)
abline(v = which.min(results$aic), col = "red", lty = 2)

plot(results$nfactors, results$bic, type = "b", main = "BIC per numero di fattori", 
     xlab = "Numero di fattori", ylab = "BIC", xaxt = "n")
axis(1, at = 1:5)
abline(v = which.min(results$bic), col = "red", lty = 2)
par(mfrow = c(1, 1))
```

2. **Indici di Fit da CFA**:

   - Implementazione di CFI, TLI, RMSEA e SRMR.
   - Grafici per valutare quando questi indici raggiungono valori accettabili.
   - Criteri di riferimento: CFI > 0.95, RMSEA < 0.05.

```{r}
# Definiamo i modelli CFA per diversi numeri di fattori
fit_indices <- data.frame()

for (i in 1:5) {
  # Estraiamo prima i fattori con analisi fattoriale esplorativa
  fa_result <- fa(wais_cor, nfactors = i, fm = "ml", rotate = "varimax")
  
  # Creiamo il modello CFA basato sui loadings pi√π alti
  model_syntax <- ""
  for (j in 1:i) {
    # Seleziona le variabili con i loadings pi√π alti per ciascun fattore
    vars <- names(sort(abs(fa_result$loadings[, j]), decreasing = TRUE)[1:ceiling(11/i)])
    model_syntax <- paste0(model_syntax, "F", j, " =~ ", paste(vars, collapse = " + "), "\n")
  }
  
  # Eseguiamo la CFA
  try({
    fit <- cfa(model_syntax, sample.cov = wais_cor, sample.nobs = n.obs)
    indices <- fitMeasures(fit, c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr", "aic", "bic"))
    
    fit_indices <- rbind(fit_indices, data.frame(
      nfactors = i, 
      chisq = indices["chisq"], 
      df = indices["df"], 
      pvalue = indices["pvalue"],
      cfi = indices["cfi"], 
      tli = indices["tli"], 
      rmsea = indices["rmsea"], 
      srmr = indices["srmr"],
      aic = indices["aic"], 
      bic = indices["bic"]
    ))
  }, silent = TRUE)
}
```

```{r}
# Visualizziamo gli indici di fit
print(fit_indices)
```

```{r}
# Visualizziamo graficamente gli indici di fit
if (nrow(fit_indices) > 0) {
  par(mfrow = c(2, 2))
  plot(fit_indices$nfactors, fit_indices$cfi, type = "b", main = "CFI per numero di fattori", 
       xlab = "Numero di fattori", ylab = "CFI", xaxt = "n")
  axis(1, at = 1:5)
  abline(h = 0.95, col = "red", lty = 2)
  
  plot(fit_indices$nfactors, fit_indices$rmsea, type = "b", main = "RMSEA per numero di fattori", 
       xlab = "Numero di fattori", ylab = "RMSEA", xaxt = "n")
  axis(1, at = 1:5)
  abline(h = 0.05, col = "red", lty = 2)
  
  plot(fit_indices$nfactors, fit_indices$aic, type = "b", main = "AIC (CFA) per numero di fattori", 
       xlab = "Numero di fattori", ylab = "AIC", xaxt = "n")
  axis(1, at = 1:5)
  
  plot(fit_indices$nfactors, fit_indices$bic, type = "b", main = "BIC (CFA) per numero di fattori", 
       xlab = "Numero di fattori", ylab = "BIC", xaxt = "n")
  axis(1, at = 1:5)
  par(mfrow = c(1, 1))
}
```

3. **Test del Chi-Quadrato**:

   - Confronto incrementale tra modelli con diverso numero di fattori.
   - Test della significativit√† della differenza di fit.

```{r}
# Calcoliamo la differenza di chi-quadrato tra modelli consecutivi
if (nrow(results) > 1) {
  chi_diff <- data.frame(
    comparison = character(),
    chi_diff = numeric(),
    df_diff = numeric(),
    p_value = numeric()
  )
  
  for (i in 2:nrow(results)) {
    chi_diff_val <- results$chi_square[i-1] - results$chi_square[i]
    df_diff_val <- results$df[i-1] - results$df[i]
    p_val <- 1 - pchisq(chi_diff_val, df_diff_val)
    
    chi_diff <- rbind(chi_diff, data.frame(
      comparison = paste(i-1, "vs", i),
      chi_diff = chi_diff_val,
      df_diff = df_diff_val,
      p_value = p_val
    ))
  }
  
  print("Test del chi-quadrato per confronto di modelli:")
  print(chi_diff)
}
```

4. **Sintesi dei Risultati**:

   - Riepilogo delle indicazioni dai vari indici.
   - Raccomandazione sul numero ottimale di fattori.

```{r}
cat("\nSintesi dei risultati:\n")
cat("Numero di fattori suggerito da AIC:", which.min(results$aic), "\n")
cat("Numero di fattori suggerito da BIC:", which.min(results$bic), "\n")

if (nrow(fit_indices) > 0) {
  # Per CFI vogliamo valori > 0.95
  good_cfi <- which(fit_indices$cfi > 0.95)
  if (length(good_cfi) > 0) {
    cat("Numero minimo di fattori con CFI > 0.95:", min(good_cfi), "\n")
  }
  
  # Per RMSEA vogliamo valori < 0.05
  good_rmsea <- which(fit_indices$rmsea < 0.05)
  if (length(good_rmsea) > 0) {
    cat("Numero minimo di fattori con RMSEA < 0.05:", min(good_rmsea), "\n")
  }
}

if (nrow(chi_diff) > 0) {
  # Per il test chi-quadrato, cerchiamo il primo confronto non significativo
  non_sig <- which(chi_diff$p_value > 0.05)
  if (length(non_sig) > 0) {
    cat("Basato sul test del chi-quadrato, il numero ottimale di fattori √®:", as.numeric(substr(chi_diff$comparison[min(non_sig)], 1, 1)), "\n")
  }
}
```

## Metodo Hull

Il metodo √® implementato nel pacchetto [`EFAtools`](https://cran.r-project.org/web/packages/EFAtools/index.html) in R (Steiner & Gruber, 2020).

Nel grafico risultante, si osserva la curva dei valori di CFI in funzione dei gradi di libert√†. Il metodo Hull seleziona il punto "di gomito", dove il modello ha ancora un buon fit ma con la massima parsimonia. In alcuni casi, il metodo pu√≤ suggerire ad esempio che **una soluzione a un fattore √® preferibile**, se l‚Äôaggiunta di ulteriori fattori non migliora significativamente l‚Äôadattamento.

```{r}
Hull(
  wais_sim,
  fa = "fa",
  nfact = 6,
  cor.type = "pearson",
  use = "pairwise.complete.obs",
  vis = TRUE,
  plot = TRUE
)
```

## Metodo MAP 

Il **MAP test** valuta, per ogni possibile numero di componenti estratti, quanto rimane di correlazione "spuria" nei residui. Il numero ottimale √® quello che **minimizza la media delle correlazioni parziali residue**, cio√® quello che riesce a "pulire" meglio la matrice di correlazione iniziale.

```{r}
# Applica il metodo MAP con la funzione vss()
vss_map <- vss(
  x = wais_cor,
  n = 6,          # numero massimo di fattori/componenti da testare
  n.obs = 100,     # numero di osservazioni
  rotate = "none", # nessuna rotazione per mantenere interpretabilit√†
  plot = FALSE     # non mostrare il grafico automaticamente
)
vss_map
```


### Sintesi dei principali risultati

| Metodo                           | Numero ottimale di fattori | Valore ottimale |
|----------------------------------|-----------------------------|------------------|
| **MAP (Velicer)**                | **2**                       | 0.03 (minimo)    |
| **BIC**                          | **2**                       | -140.3 (minimo)  |
| **BIC corretto per n (SABIC)**   | **2**                       | -32.93 (minimo)  |
| **VSS complessit√† 1**            | 2                           | 0.92 (massimo)   |
| **VSS complessit√† 2**            | 5                           | 0.95 (massimo)   |


### Velicer MAP

- Valuta la **media delle correlazioni parziali residue**.
- L‚Äôobiettivo √® minimizzare la varianza residua non spiegata dai fattori.
- **Risultato**: minimo a **2 fattori**, con valore 0.03 ‚Üí suggerisce **2 fattori**.

### BIC e SABIC

- Criteri informativi che bilanciano bont√† del fit e parsimonia.
- Pi√π basso √® il valore, meglio √®.
- Entrambi i criteri (sia BIC classico che SABIC) raggiungono il **minimo a 2 fattori**.

### SS (Very Simple Structure)

- Misura quanto bene una struttura semplice (con pochi caricamenti per variabile) si adatta ai dati.
- Due versioni:
  - **Complessit√† 1**: solo il caricamento maggiore per ogni variabile.
  - **Complessit√† 2**: primi due caricamenti per variabile.
- Complessit√† 1 ‚Üí massimo a **2 fattori** (0.92)
- Complessit√† 2 ‚Üí massimo a **5 fattori** (0.95)

üîé *Nota*: VSS complessit√† 2 √® pi√π permissiva e tende a favorire strutture pi√π complesse.

**Interpretazione complessiva.**

Tutti i criteri **basati su residui o penalizzazione della complessit√†** (MAP, BIC, SABIC, VSS-1) **concordano nel suggerire una soluzione a 2 fattori**.

Solo VSS-2 (pi√π permissivo) suggerisce **5 fattori**, ma questa soluzione √® meno parsimoniosa e pi√π soggetta a sovrafattorizzazione.

In sintesi, sulla base di criteri oggettivi e parsimoniosi come **MAP**, **BIC**, **SABIC**, e **VSS a complessit√† 1**, una soluzione a **2 fattori** sembra ottimale per questi dati WAIS. L‚Äôadozione di criteri informativi e basati sui residui, come MAP e BIC, √® fortemente raccomandata rispetto a metodi pi√π soggettivi o sovraestimanti come Kaiser o Scree test.


## Exploratory Graph Analysis (EGA)

L‚Äô**Exploratory Graph Analysis (EGA)** √® un metodo innovativo per identificare la struttura latente dei dati basato su modelli a rete, piuttosto che sui tradizionali modelli fattoriali. √à implementato nel pacchetto [`EGAnet`](https://cran.r-project.org/package=EGAnet), sviluppato da Golino e colleghi. Il metodo √® stato introdotto da **Golino & Epskamp (2017)** e perfezionato in studi successivi (Christensen, Golino & Silvia, 2020; Golino et al., 2020).

### Caratteristiche principali di EGA:

- Utilizza il **graphical lasso** per stimare le correlazioni parziali tra variabili, costruendo cos√¨ una rete sparsa (solo le relazioni pi√π forti restano).
- Identifica **comunit√† di variabili** all‚Äôinterno della rete, che corrispondono a **fattori latenti**.
- √à particolarmente utile quando:
  - le **comunalit√† sono basse**,
  - la **struttura fattoriale non √® ben definita**,
  - si lavora con **dati ordinali o non normali**.

Applichiamo l‚ÄôEGA alla matrice di correlazione delle **11 sottoscale della WAIS**.

```{r}
# Applica l'EGA alla matrice di correlazione WAIS
ega_result <- EGA(
  data = wais_cor,        # Matrice di correlazione tra le 11 sottoscale
  n = 300,                # Numero di soggetti nel campione
  model = "glasso",       # Metodo di stima: graphical lasso
  type = "correlation",   # Specifica che stiamo passando una matrice di correlazione
  plot.EGA = TRUE         # Visualizza il grafo delle comunit√† (dimensioni)
)
```

- **`model = "glasso"`**: applica una penalizzazione (lasso) per ridurre il numero di connessioni deboli tra variabili.
- **`plot.EGA = TRUE`**: mostra un grafo con le sottoscale collegate in base alla loro correlazione condizionale.
- **`ega_result$wc`**: contiene l‚Äôassegnazione di ciascuna variabile a una **comunit√†**, interpretata come un **fattore latente**.

**Interpretazione dei risultati**:

```{r}
# Riepilogo generale
summary(ega_result)
```

```{r}
# Numero di dimensioni individuate (cio√® di comunit√†)
length(unique(ega_result$wc))
```

**Vantaggi:**

- **non richiede ipotesi forti sulla distribuzione dei dati**;
- **pi√π robusto** dei metodi classici (EFA, PA) in presenza di **comunalit√† basse**;
- offre una **visualizzazione intuitiva** delle relazioni tra variabili.

> üí° *EGA pu√≤ essere utilizzato sia per esplorare la dimensionalit√† di un set di item sia per decidere quanti fattori mantenere prima di una conferma con CFA.*


## Riflessioni Conclusive

Determinare il numero di fattori da estrarre in un'Analisi Fattoriale Esplorativa (EFA) rappresenta una delle sfide metodologiche pi√π complesse nella costruzione di strumenti psicometrici. Nessun metodo √® infallibile o universalmente valido: ogni tecnica presenta vantaggi, limiti e assunzioni specifiche. Per questo motivo, la **triangolazione** di pi√π metodi e la riflessione teorica guidano le scelte pi√π solide.

### 1. La scelta del numero di fattori: tra tecniche classiche e moderne

Le tecniche tradizionali, come la regola di Kaiser e lo scree test, sono state largamente impiegate per la loro semplicit√†, ma risultano oggi superate per via della loro tendenza sistematica alla **sovra- o sotto-fattorizzazione**. In particolare:

- La **Parallel Analysis (PA)** si conferma il metodo pi√π raccomandato, grazie alla sua capacit√† di distinguere fattori reali da quelli generati dal rumore;
- Il metodo **Comparison Data (CD)** si dimostra utile con strutture complesse o fattori correlati, ma va calibrato attentamente;
- I criteri **informativi** (AIC, BIC) e gli **indici di adattamento del modello** (RMSEA, CFI) aggiungono elementi preziosi per valutare la bont√† della soluzione, specialmente quando integrati con la CFA;
- Metodi recenti come **MAP**, **Hull**, **EGA** o **Factor Forest** offrono soluzioni promettenti, soprattutto in contesti con comunalit√† basse, dati non normali o ordinali.

### 2. Replicabilit√†: validare ci√≤ che si scopre

Identificare una struttura fattoriale coerente √® solo il primo passo. Per attribuire **validit√† e generalizzabilit√†** a una soluzione esplorativa, occorre valutarne la **replicabilit√†**:

- **Replicazione in campioni indipendenti** e **validazione incrociata** servono a testare la stabilit√† della struttura in sottogruppi differenti;
- La **CFA** permette di verificare, in modo formale, se una struttura fattoriale individuata in EFA √® confermata da nuovi dati;
- Tecniche di **ricampionamento** (come il bootstrap) offrono ulteriori strumenti per stimare l‚Äôincertezza legata alla soluzione ottenuta.

Una struttura replicabile √® pi√π probabilmente una rappresentazione fedele dei costrutti latenti piuttosto che un artefatto del campione specifico.

### 3. Cosa fare con i fattori: applicazioni e criticit√†

Dopo aver identificato i fattori, √® cruciale decidere **come utilizzarli**:

- Nei **Modelli di Equazioni Strutturali (SEM)**, i fattori possono essere usati come predittori, mediatori, moderatori o esiti, con il vantaggio di modellare esplicitamente l‚Äôerrore di misura;
- Al di fuori dei SEM, l‚Äôuso di **punteggi fattoriali** (calcolati come media, somma o compositi ponderati) va considerato con cautela, poich√© pu√≤ trascurare errori di misura o differenze di importanza tra variabili;
- In certi casi, **compositi a pesi unitari** possono essere preferibili a quelli ponderati, specialmente per garantire maggiore generalizzabilit√† e robustezza cross-campione.

La scelta operativa su come rappresentare e usare i fattori dovrebbe sempre essere coerente con le finalit√† della ricerca e con le caratteristiche dei dati.

### 4. Una visione integrata

In definitiva, la **determinazione del numero di fattori**, la **replicabilit√†** della soluzione e il **modo in cui i fattori vengono utilizzati** sono aspetti interdipendenti di un processo rigoroso e cumulativo. Una buona pratica psicometrica non si limita a identificare la struttura che ‚Äúfunziona meglio‚Äù nel proprio campione, ma valuta la stabilit√† della soluzione, il suo significato teorico e la sua applicazione pratica.

> ‚úèÔ∏è *La validit√† di uno strumento psicologico non si esaurisce nella bont√† del suo adattamento al campione corrente, ma nella sua capacit√† di riflettere stabilmente e in modo interpretabile i costrutti che intende misurare.*


## Session Info

```{r}
#| vscode: {languageId: r}
sessionInfo()
```


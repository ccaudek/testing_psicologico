# L'affidabilità del test {#sec-ctt-reliability}

**Prerequisiti**

- Leggere il capitolo 3, *Reliability*, del testo *Principles of psychological assessment* di @petersen2024principles. 

**Preparazione del Notebook**

```{r}
# Carica il file _common.R per impostazioni di pacchetti e opzioni
here::here("code", "_common.R") |> source()

# Carica pacchetti aggiuntivi
pacman::p_load(modelsummary, MASS)
```


## Introduzione

L'affidabilità (o attendibilità) rappresenta un principio fondamentale nella teoria della misurazione ed è essenziale per garantire che le misure siano coerenti, stabili e precise nei diversi contesti applicativi. Nel testing psicologico, una buona affidabilità implica che i punteggi ottenuti siano sufficientemente consistenti e non eccessivamente influenzati da errori casuali. Questa caratteristica è di estrema importanza perché i punteggi osservati possono variare non solo in funzione delle differenze tra individui, ma anche a causa di fattori esterni e condizioni di misurazione non perfettamente controllabili.

La Teoria della Misurazione Classica (CTT, Classical Test Theory) fornisce una cornice teorica chiara per affrontare e quantificare il problema della misurazione affidabile. Secondo la CTT, ogni punteggio osservato (X) può essere scomposto in due componenti: il punteggio vero (T) e l'errore di misurazione (E). Uno degli obiettivi fondamentali della CTT consiste proprio nel suddividere la varianza complessiva dei punteggi osservati in due parti distinte:

1. **Varianza del punteggio vero ($\sigma_T^2$)**, che riflette la differenza reale tra gli individui rispetto alla caratteristica misurata.
2. **Varianza dell'errore ($\sigma_E^2$)**, che rappresenta le variazioni casuali e indesiderate derivanti da imperfezioni nel processo di misurazione.

Per poter ottenere questa suddivisione e definire formalmente l'affidabilità, la CTT si basa su alcune assunzioni fondamentali:

- **Errore medio nullo**: Si assume che gli errori di misurazione abbiano una media uguale a zero, cioè $E(e) = 0$. Questo implica che gli errori siano casuali e distribuiti simmetricamente attorno al punteggio vero, senza alcun bias sistematico.
- **Indipendenza tra punteggio vero e errore**: L'errore di misurazione non deve essere correlato con il punteggio vero, cioè la correlazione $\rho_{T,E} = 0$. Questo significa che l'errore non dipende dal valore della caratteristica misurata.
- **Indipendenza degli errori nel tempo**: L'errore di misurazione in un'occasione deve essere indipendente dall'errore in un'altra occasione ($\rho_{e_1, e_2} = 0$).

## Varianza del punteggio osservato

Secondo la CTT, la varianza del punteggio osservato ($\sigma^2_X$) è la somma della varianza del punteggio vero e della varianza dell'errore:

$$
\sigma^2_X = \sigma_T^2 + \sigma_E^2.
$$ {#eq-var-sum}

La validità di questa relazione può essere dimostrata facilmente considerando l'assunzione di indipendenza tra errore e punteggio vero ($\rho_{T,E} = 0$), che implica $\sigma_{TE} = 0$.

$$
\sigma^2_X =  \mathbb{V}(T+E) =  \sigma_T^2 + \sigma_E^2 + 2 \sigma_{TE}.
$$ {#eq-3-2-4}

Dato che $\sigma_{TE}=\rho_{TE}\sigma_T \sigma_E=0$, in quanto $\rho_{TE}=0$, ne segue che

$$
\sigma^2_X =   \sigma_T^2 + \sigma_E^2.
$$

Ad esempio, utilizzando dati simulati:

```{r}
set.seed(8394)

n <- 100
Sigma <- matrix(c(6, 0, 0, 3), byrow = TRUE, ncol = 2)
mu <- c(12, 0)
dat <- MASS::mvrnorm(n, mu, Sigma, empirical = TRUE)
T <- dat[, 1]
E <- dat[, 2]
X <- T + E

var(X)
var(T) + var(E)
```

## Covarianza tra punteggio osservato e punteggio vero

La covarianza tra il punteggio osservato e il punteggio vero è pari alla varianza del punteggio vero:

$$
\sigma_{X T} = \sigma_T^2.
$$ {#eq-cov-obs-true}

Questa relazione è dimostrata considerando l'indipendenza tra punteggio vero e errore e il fatto che $E(E) = 0$:

$$
\begin{aligned}
\sigma_{X T} &= \mathbb{E}(XT) - \mathbb{E}(X)\mathbb{E}(T)\notag\\
&=  \mathbb{E}[(T+E)T] - \mathbb{E}(T+E)\mathbb{E}(T)\notag\\
&=  \mathbb{E}(T^2) + \underbrace{\mathbb{E}(ET)}_{=0} - [\mathbb{E}(T)]^2 -  \underbrace{\mathbb{E}(E)}_{=0} \mathbb{E}(T)\notag\\
&=\mathbb{E}(T^2) - [\mathbb{E}(T)]^2\notag \\
&= \sigma_T^2.
\end{aligned}
$$

Verifica empirica:

```{r}
cov(X, T)
var(T)
```

## Correlazione tra punteggio osservato e punteggio vero

La correlazione tra punteggio osservato e punteggio vero è data dal rapporto tra la deviazione standard del punteggio vero e quella del punteggio osservato:

$$
\rho_{X T} = \frac{\sigma_T}{\sigma_X}.
$$ {#eq-sd-ratio}

Esaminiamo la dimostrazione. Per definizione, la correlazione tra due variabili $X$ e $T$ è data dal rapporto tra la loro covarianza e il prodotto delle rispettive deviazioni standard:

$$
\rho_{XT} = \frac{\sigma_{XT}}{\sigma_X \sigma_T}.
$$

Dalla teoria classica della misurazione sappiamo che il punteggio osservato $X$ è la somma del punteggio vero $T$ e dell'errore $E$: $X = T + E$. Pertanto, la covarianza tra punteggio osservato e punteggio vero è:

$$
\sigma_{XT} = \text{Cov}(X, T) = \text{Cov}(T + E, T).
$$

Applicando la proprietà della linearità della covarianza, 

$$\text{Cov}(A+B,C)=\text{Cov}(A,C)+\text{Cov}(B,C) ,$$ 

per il caso presente, poiché per assunzione della CTT vale che la covarianza tra errore e punteggio vero sia nulla ($\sigma_{ET} = 0$), otteniamo:

$$
\sigma_{XT} = \text{Cov}(T + E, T) = \text{Cov}(T,T) + \text{Cov}(E,T) = \sigma^2_T + 0 = \sigma^2_T.
$$

Inserendo questo risultato nell'equazione iniziale otteniamo:

$$
\rho_{XT} = \frac{\sigma_{XT}}{\sigma_X \sigma_T} = \frac{\sigma^2_T}{\sigma_X \sigma_T}.
$$

A questo punto semplifichiamo l'espressione, dividendo numeratore e denominatore per $\sigma_T$:

$$
\rho_{XT} = \frac{\sigma^2_T}{\sigma_X \sigma_T} = \frac{\sigma_T}{\sigma_X}.
$$

Quindi, abbiamo dimostrato che la correlazione tra il punteggio osservato e il punteggio vero è data dal rapporto tra la deviazione standard del punteggio vero e quella del punteggio osservato. Questo risultato è importante perché evidenzia che la correlazione tra punteggio vero e osservato dipende dalla proporzione di varianza vera rispetto alla varianza totale (osservata). Questa relazione mostra che l'affidabilità aumenta quanto più la varianza vera prevale sulla varianza totale osservata.

Verifica empirica:

```{r}
cor(X, T)
sd(T) / sd(X)
```

## Definizione e interpretazione dell'affidabilità

Il quadrato della correlazione tra punteggio osservato e punteggio vero, $\rho_{XT}^2$, corrisponde all'attendibilità del test. Quindi, la **CTT definisce formalmente l'affidabilità** di un test come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato:

$$
\rho_{X T}^2 = \frac{\sigma_T^2}{\sigma_X^2}.
$$ {#eq-reliability-1}

Questa relazione implica anche che l'affidabilità è uguale al quadrato della correlazione tra il punteggio osservato e il punteggio vero. L'affidabilità può quindi essere interpretata come la proporzione della varianza osservata che riflette la reale differenza tra individui rispetto alla caratteristica misurata.

Questa formula è il concetto fondamentale della CTT e misura il livello di variazione del punteggio vero rispetto alla variazione del punteggio osservato.

Verifica empirica:

```{r}
cor(X, T)^2
var(T) / var(X)
```

Infine, considerando che $\sigma_X^2 = \sigma_T^2 + \sigma_E^2$, possiamo anche esprimere l'affidabilità in termini di errore:

$$
\begin{equation}
\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2} =\frac{\sigma_{X}^2 - \sigma^2_E}{\sigma_X^2} = 1-\frac{\sigma_{E}^2}{\sigma_{X}^2}.
\end{equation}
$$ {#eq-3-2-6}


Dall'@eq-3-2-6, possiamo dedurre che il coefficiente di affidabilità assume il valore di $1$ quando la varianza degli errori $\sigma_{E}^2$ è nulla, e assume il valore di $0$ quando la varianza degli errori è uguale alla varianza del punteggio osservato. Quindi, il coefficiente di affidabilità è un valore assoluto situato nell'intervallo tra $0$ e $1$ che indica il grado in cui un test misura stabilmente una caratteristica psicologica senza interferenze casuali.

In relazione ai dati dell'esempio, otteniamo:

```{r}
1 - (var(E) / var(X))
```


## Attendibilità e modello di regressione lineare

La CTT può essere chiaramente compresa attraverso il parallelo con il modello di regressione lineare semplice. Infatti, nella CTT il punteggio osservato (variabile dipendente) viene espresso come funzione lineare del punteggio vero (variabile indipendente). In altre parole, il punteggio osservato può essere considerato come il risultato di una regressione lineare del punteggio vero, con un'intercetta uguale a 0 e una pendenza uguale a 1, a cui si aggiunge un errore casuale.

In termini più formali, questo modello può essere espresso come:

$$
X = a + b T + E.
$$

dove:

 - $X$ rappresenta il punteggio osservato,
 - $T$ il punteggio vero,
 - $E$ è l'errore di misurazione.
 
Il coefficiente di attendibilità definito dalla CTT (ovvero il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato) coincide esattamente con il coefficiente di determinazione $R^2$ del modello di regressione lineare così definito. Il coefficiente di determinazione $R^2$ misura infatti la proporzione di varianza della variabile dipendente spiegata dal modello, che in questo caso corrisponde alla varianza del punteggio vero.
 
Per chiarire ulteriormente il concetto, riprendiamo l'esempio con i dati simulati:

```{r}
fm <- lm(X ~ T)
summary(fm)
```

Come possiamo osservare dall'output, la regressione ha intercetta prossima a 0 e pendenza prossima a 1. Questo risultato è coerente con le assunzioni della CTT secondo cui i punteggi osservati dovrebbero riflettere direttamente i punteggi veri, $\mathbb{E}(X) = \mathbb{E}(T)$.

Inoltre, il coefficiente di determinazione  fornito dal modello di regressione corrisponde precisamente al coefficiente di attendibilità calcolato tramite la formula della CTT:

$$
\rho_{X T}^2 = \frac{\sigma_T^2}{\sigma_X^2}.
$$

Verifica empirica:

```{r}
var(T) / var(X)
```

Pertanto, il coefficiente di attendibilità può essere interpretato come il coefficiente di determinazione di una regressione lineare che descrive quanto della variabilità totale nei punteggi osservati possa essere spiegata dai punteggi veri.

Inoltre, l'errore standard della regressione corrisponde esattamente all'errore standard di misurazione definito dalla CTT. Questo valore rappresenta la variabilità media degli errori intorno alla retta di regressione, ovvero la dispersione dei punteggi osservati intorno ai punteggi veri:

```{r}
sqrt(var(E) * 99 / 98)
```

**Nota importante:** il fattore correttivo utilizzato nella formula precedente deriva dal fatto che, nella stima della varianza tramite regressione lineare, si usa $n-2$ al denominatore (dove $n$ è il numero di osservazioni), mentre la funzione `var()` di R usa $n-1$. Da qui la necessità della correzione:

$$
\text{Errore standard} = \sqrt{\frac{(n-1)}{(n-2)} \cdot \sigma_E^2}.
$$

Questa equivalenza chiarisce ulteriormente come il modello di regressione lineare e la CTT siano strettamente connessi, offrendo una prospettiva intuitiva per comprendere il significato e l'importanza del concetto di affidabilità.

<!-- ## Misurazioni parallele e affidabilità -->

<!-- L'equazione $\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}$ definisce il coefficiente di affidabilità, ma non ci fornisce gli strumenti pratici per calcolarlo direttamente. Questo perché la varianza del punteggio reale $\sigma_{T}^2$ rappresenta un valore sconosciuto. Il metodo utilizzato dalla CTT per ottenere una stima empirica dell'attendibilità è quello delle *forme parallele* del -->
<!-- test. In pratica, se è possibile creare versioni alternative del test che siano equivalenti in termini di contenuto, modalità di risposta e caratteristiche statistiche, allora diventa possibile ottenere una stima empirica del coefficiente di affidabilità. -->

<!-- Secondo la CTT, due test $X=T+E$ e $X^\prime=T^\prime+E^\prime$ sono considerati misurazioni parallele della stessa abilità latente quando: -->

<!-- - $T = T^\prime$, -->
<!-- - $\mathbb{V}(E) = \mathbb{V}(E^\prime)$. -->

<!-- Queste premesse implicano che $\mathbb{E}(X) = \mathbb{E}(X^\prime)$. -->

<!-- La dimostrazione procede come segue. Considerando che $\mathbb{E}(X) = T$ e $\mathbb{E}(X^\prime) = T$, è evidente che $\mathbb{E}(X) =\mathbb{E}(X^\prime)$ poiché $\mathbb{E}(E) = \mathbb{E}(E^\prime) = 0$. -->

<!-- In modo analogo, l'uguaglianza delle varianze nei punteggi osservati delle due misurazioni parallele deve essere verificata, cioè $\mathbb{V}(X) = \mathbb{V}(X^\prime)$. -->

<!-- Questa dimostrazione si sviluppa come segue. Per $X$, possiamo scrivere  -->

<!-- $$\mathbb{V}(X) = \mathbb{V}(T + E) = \mathbb{V}(T) + \mathbb{V}(E);$$ -->

<!-- mentre per $X^\prime$ possiamo scrivere  -->

<!-- $$\mathbb{V}(X^\prime) = \mathbb{V}(T^\prime + E^\prime) = \mathbb{V}(T^\prime) + \mathbb{V}(E^\prime).$$  -->

<!-- Poiché sappiamo che $\mathbb{V}(E) = \mathbb{V}(E^\prime)$ e che $T = T^\prime$, possiamo dedurre che $\mathbb{V}(X) = \mathbb{V}(X^\prime)$. -->

<!-- In aggiunta, è importante notare che per costruzione gli errori $E$ e $E^\prime$ sono incorrelati sia con $T$ che tra di loro. -->

## Misurazioni parallele e affidabilità

La definizione formale del coefficiente di affidabilità è data dall'equazione:

$$
\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}
$$

Tuttavia, questa formula presenta una difficoltà pratica fondamentale: la varianza del punteggio vero $\sigma_{T}^2$ non è direttamente osservabile, essendo una quantità teorica sconosciuta. La Teoria Classica dei Test (CTT) risolve questo problema attraverso il metodo delle *forme parallele* del test, che permette di ottenere una stima empirica della sua attendibilità.

Due test $X = T + E$ e $X' = T' + E'$ sono definiti paralleli quando misurano la stessa abilità latente e soddisfano le seguenti condizioni:

- uguaglianza dei punteggi veri: $T = T'$,
- uguaglianza delle varianze degli errori: $\mathbb{V}(E) = \mathbb{V}(E')$.

Da queste condizioni deriva logicamente l'uguaglianza dei valori attesi dei punteggi osservati:

$$
\mathbb{E}(X) = \mathbb{E}(T + E) = \mathbb{E}(T) + \mathbb{E}(E) = T
$$
$$
\mathbb{E}(X') = \mathbb{E}(T' + E') = \mathbb{E}(T') + \mathbb{E}(E') = T'
$$

Dato che per definizione $T = T'$ e $\mathbb{E}(E) = \mathbb{E}(E') = 0$, segue direttamente:

$$
\mathbb{E}(X) = \mathbb{E}(X') .
$$

Analogamente, per i test paralleli deve valere anche l'uguaglianza delle varianze dei punteggi osservati:

$$
\mathbb{V}(X) = \mathbb{V}(X') .
$$

La dimostrazione si articola chiaramente:

$$
\mathbb{V}(X) = \mathbb{V}(T + E) = \mathbb{V}(T) + \mathbb{V}(E)
$$

$$
\mathbb{V}(X') = \mathbb{V}(T' + E') = \mathbb{V}(T') + \mathbb{V}(E')
$$

Considerando che $T = T'$ e $\mathbb{V}(E) = \mathbb{V}(E')$, si conferma immediatamente che:

$$
\mathbb{V}(X) = \mathbb{V}(X').
$$

Infine, per costruzione, la CTT assume che gli errori di misurazione $E$ ed $E'$ siano indipendenti dal punteggio vero $T$ e siano incorrelati tra loro:

$$
\text{Cov}(E, T) = \text{Cov}(E', T') = \text{Cov}(E, E') = 0 .
$$

Queste proprietà costituiscono i requisiti essenziali per la validità pratica ed empirica del metodo delle forme parallele, permettendo di stimare in modo affidabile il coefficiente di attendibilità del test tramite la correlazione tra le due misurazioni parallele.



<!-- ## La correlazione tra due forme parallele del test -->

<!-- Ora procediamo a dimostrare che, secondo le ipotesi della Teoria della CTT, la correlazione tra due versioni parallele di un test è effettivamente equivalente al rapporto tra la varianza del punteggio reale e la varianza del punteggio osservato. Come discusso nel capitolo precedente, le misurazioni parallele rappresentano il grado più elevato di somiglianza tra due diverse versioni di un test. -->

<!-- La dimostrazione è la seguente. Consideriamo, senza perdita di generalità, che $\mathbb{E}(X) = \mathbb{E}(X') = \mathbb{E}(T) = 0$. Questa scelta ci consente di scrivere: -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!-- \rho_{X X^\prime} &= \frac{\sigma(X, X^\prime)}{\sigma(X) \sigma(X^\prime)} \\ -->
<!-- &= \frac{\mathbb{E}(XX^\prime)}{\sigma(X) \sigma(X^\prime)} \\ -->
<!-- &= \frac{\mathbb{E}[(T+E)(T+E^\prime)]}{\sigma(X) \sigma(X^\prime)} \\ -->
<!-- &= \frac{\mathbb{E}(T^2) + \mathbb{E}(TE^\prime) + \mathbb{E}(TE) + \mathbb{E}(EE^\prime)}{\sigma(X) \sigma(X^\prime)}. -->
<!-- \end{aligned} -->
<!-- $$ -->

<!-- Tuttavia, sappiamo che $\mathbb{E}(TE) = \mathbb{E}(TE^\prime) = \mathbb{E}(EE^\prime) = 0$. Inoltre, $\sigma(X) = \sigma(X^\prime) = \sigma_X$. Pertanto, giungiamo a: -->

<!-- $$ -->
<!-- \rho_{X X^\prime} = \frac{\mathbb{E}(T^2)}{\sigma_X \sigma_X} = \frac{\sigma^2_T}{\sigma^2_X}. -->
<!-- $$ {#eq:3-3-5} -->

<!-- Notiamo che il risultato ottenuto, insieme all'equazione che definisce il coefficiente di affidabilità $\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}$, presentano entrambi la stessa espressione a destra del segno di uguale. Questo conduce a un risultato cruciale: il coefficiente di affidabilità, ossia il quadrato della correlazione tra il punteggio osservato e il punteggio reale, è identico alla correlazione tra i punteggi osservati di due versioni parallele del test: -->

<!-- $$ -->
<!-- \rho^2_{XT} =  \rho_{XX^\prime}. -->
<!-- $$ {#eq-rho2xt-rhoxx} -->

<!-- Questa conclusione è di notevole importanza in quanto consente di esprimere la variabile inosservabile $\rho^2_{XT}$ in termini della variabile osservabile $\rho_{XX^\prime}$, la quale può essere calcolata in base ai punteggi osservati delle due forme parallele del test. Fondamentalmente, la stima di $\rho^2_{XT}$ si semplifica nella stima di $\rho^2_{XX^\prime}$. Questo spiega l'importanza dell'equazione {eq}`eq-rho2xt-rhoxx` nella CTT. Inoltre, è da sottolineare che l'equazione {ref}`eq:rho2xt-rhoxx` fornisce una giustificazione per l'utilizzo della correlazione split-half come misura di affidabilità. -->

<!-- ## La correlazione tra punteggio osservato e punteggio vero -->

<!-- Esaminiamo adesso la correlazione tra il punteggio osservato e il punteggio reale. L'@eq-rho2xt-rhoxx può essere riformulata come segue: -->

<!-- $$ -->
<!-- \rho_{XT} = \sqrt{\rho_{XX^\prime}}. -->
<!-- $$  -->

<!-- In altre parole, la radice quadrata del coefficiente di affidabilità equivale alla correlazione tra il punteggio osservato e il punteggio reale. -->

<!-- Procediamo ora a verificare questa relazione utilizzando i dati dell'esempio. -->

<!-- ```{r} -->
<!-- #| vscode: {languageId: r} -->
<!-- sqrt(var(T) / var(X)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| vscode: {languageId: r} -->
<!-- cor(X, T) -->
<!-- ``` -->

<!-- ## I fattori che influenzano l'attendibilità -->

<!-- Considerando le tre equazioni: -->

<!-- $$ -->
<!-- \rho^2_{XT} = \rho_{XX'},\quad -->
<!-- \rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}, \quad -->
<!-- \rho_{XT}^2 = 1-\frac{\sigma_{E}^2}{\sigma_X^2}, -->
<!-- $$  -->

<!-- possiamo affermare che esistono tre modi equivalenti per giungere alla conclusione che l'attendibilità di un test è elevata. L'attendibilità di un test è considerata alta quando si verificano le seguenti condizioni: -->

<!-- - La correlazione tra le forme parallele del test è elevata. -->
<!-- - La varianza del punteggio vero è ampia rispetto alla varianza del punteggio osservato. -->
<!-- - La varianza dell'errore di misurazione è ridotta rispetto alla varianza del punteggio osservato. -->

<!-- Queste considerazioni rivestono un'importanza fondamentale nella progettazione di un test. In particolare, l'equazione $\rho^2_{XT} = \rho_{XX'}$ fornisce un criterio per la selezione degli item da includere nel test. Se interpretiamo $\rho_{XX'}$ come la correlazione tra due item, allora gli item che presentano la correlazione più elevata tra di loro dovrebbero essere inclusi nel test. In questo modo, l'attendibilità del test aumenta, poiché gli item selezionati risultano fortemente correlati con il punteggio vero. -->


## La correlazione tra due forme parallele del test

Vediamo ora come dimostrare formalmente che, sotto le ipotesi della CTT, la correlazione tra due versioni parallele del test coincide esattamente con il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato.

Supponiamo, per semplicità e senza perdita di generalità, che $\mathbb{E}(X) = \mathbb{E}(X') = \mathbb{E}(T) = 0$. Questa scelta semplifica i calcoli e porta alla seguente formulazione:

$$
\begin{aligned}
\rho_{X X^\prime} &= \frac{\sigma(X, X^\prime)}{\sigma(X) \sigma(X^\prime)} \\
&= \frac{\mathbb{E}(XX^\prime)}{\sigma(X) \sigma(X^\prime)} \\
&= \frac{\mathbb{E}[(T+E)(T+E^\prime)]}{\sigma(X) \sigma(X^\prime)} \\
&= \frac{\mathbb{E}(T^2) + \mathbb{E}(TE^\prime) + \mathbb{E}(TE) + \mathbb{E}(EE^\prime)}{\sigma(X) \sigma(X^\prime)}.
\end{aligned}
$$

Poiché gli errori $E$ ed $E'$ sono incorrelati con $T$ e tra loro, abbiamo $\mathbb{E}(TE) = \mathbb{E}(TE^\prime) = \mathbb{E}(EE^\prime) = 0$. Inoltre, per ipotesi di parallelismo, $\sigma(X) = \sigma(X^\prime) = \sigma_X$. Quindi, otteniamo il risultato finale:

$$
\rho_{X X^\prime} = \frac{\mathbb{E}(T^2)}{\sigma_X \sigma_X} = \frac{\sigma^2_T}{\sigma^2_X}.
$$ {#eq-3-3-5}

Questo risultato è estremamente rilevante poiché permette di collegare la correlazione osservabile tra due forme parallele $\rho_{X X'}$ con la correlazione teorica (non direttamente osservabile) tra il punteggio osservato e quello vero:

$$
\rho^2_{XT} = \rho_{XX^\prime}.
$$ {#eq-rho2xt-rhoxx}

Questa equazione giustifica l'uso empirico della correlazione tra forme parallele (ad esempio, tramite metodo split-half) per stimare l'affidabilità del test. 

## La correlazione tra punteggio osservato e punteggio vero

L'equazione @eq-rho2xt-rhoxx può essere riscritta per esprimere direttamente la correlazione tra punteggio osservato e punteggio vero:

$$
\rho_{XT} = \sqrt{\rho_{XX^\prime}}.
$$

Quindi, la radice quadrata della correlazione tra due forme parallele del test fornisce la correlazione tra il punteggio osservato e il punteggio reale.

Verifica empirica:

```{r}
sqrt(var(T) / var(X))
```

```{r}
cor(X, T)
```

## I fattori che influenzano l'attendibilità

Le seguenti tre equazioni riassumono concisamente i criteri fondamentali per valutare l'affidabilità di un test:

$$
\rho^2_{XT} = \rho_{XX'},\quad
\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}, \quad
\rho_{XT}^2 = 1 - \frac{\sigma_{E}^2}{\sigma_X^2}.
$$

Da queste espressioni possiamo identificare tre condizioni equivalenti che descrivono un test altamente attendibile:

- una correlazione elevata tra le due forme parallele del test;
- una varianza del punteggio vero significativamente più ampia rispetto alla varianza del punteggio osservato;
- una varianza dell'errore di misurazione ridotta rispetto alla varianza complessiva del punteggio osservato.

Questi fattori svolgono un ruolo cruciale nella progettazione e nello sviluppo di strumenti psicometrici. In particolare, la selezione di item strettamente correlati tra loro aumenta l'affidabilità, perché contribuisce direttamente a incrementare la proporzione di varianza del punteggio vero rispetto alla varianza totale osservata.


## Riflessioni conclusive

L'affidabilità costituisce un concetto fondamentale all'interno della teoria della misurazione, poiché si riferisce alla coerenza dei punteggi in varie situazioni, come diverse configurazioni di item, versioni del test o momenti di somministrazione. Nel corso di questo capitolo, abbiamo esplorato le basi teoriche dell'affidabilità. All'interno della CTT, l'affidabilità è definita come la correlazione tra il punteggio vero e il punteggio osservato, oppure, equivalentemente, come uno meno la correlazione tra il punteggio di errore e il punteggio osservato. Dal momento che il punteggio vero non è direttamente osservabile, è necessario ricorrere a metodi alternativi per stimare l'affidabilità. Il metodo proposto dalla CTT per ottenere tale stima è quello della correlazione dei punteggi ottenuti da due test paralleli.

## Session Info

```{r}
#| vscode: {languageId: r}
sessionInfo()
```

<!-- [^2]: Vedremo in seguito -->
<!--     (§ [$$ch:err_stnd_stima$$](#ch:err_stnd_stima){reference-type="ref" -->
<!--     reference="ch:err_stnd_stima"}) come il livello di abilità latente -->
<!--     (il punteggio vero) possa essere stimato con la formula di Kelley -->
<!--     (1923), ovvero $$\begin{aligned} -->
<!--     \hat{T}_i &= \rho_{XT} x_i + (1 - \rho_{XT})\mu_x\notag\\ -->
<!--     &= \mu_x + \rho_{XT} (x_i - \mu_x),\notag\end{aligned}$$ dove -->
<!--     $\mu_x$ è la media dei punteggio osservato e $\hat{T}_i$ è la stima -->
<!--     del punteggio vero per l'$i$-esimo rispondente. -->

<!-- [^3]:  -->


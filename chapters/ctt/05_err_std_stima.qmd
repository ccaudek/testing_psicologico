# La stima del punteggio vero {#sec-ctt-true-score-estimate}

**Preparazione del Notebook**

```{r}
here::here("code", "_common.R") |> source()
pacman::p_load(psychometric)
```

## Introduzione
  
Nella Teoria Classica dei Test, la *stima del punteggio vero* con il metodo della *regressione di Kelley* offre una correzione del punteggio osservato basata sull’affidabilità del test, al fine di ottenere una valutazione più precisa del “vero” punteggio di un individuo. L’idea è di ridurre l’errore di misurazione compensando gli estremi: punteggi molto alti o molto bassi tendono infatti a convergere verso la media. Nella formula di Kelley, il punteggio stimato risulta da una media ponderata tra il punteggio osservato e la media dei punteggi (del campione o della popolazione), con pesi determinati dall’affidabilità del test.

Un obiettivo essenziale della valutazione psicologica è proprio quello di stimare il punteggio vero del soggetto. Poiché il punteggio osservato $X$ differisce dal punteggio vero $T$ a causa dell’errore di misurazione $(X = T + E)$, la teoria classica ci fornisce gli strumenti per correggere $X$ tenendo conto dell’affidabilità del test. Questa correzione è particolarmente utile quando si desidera costruire un intervallo di confidenza per il punteggio vero del soggetto.

Per costruire tale intervallo di confidenza, servono due ingredienti:
  
1. Una stima puntuale del punteggio vero ($\hat{T}$).
2. L’errore standard della stima ($\sigma_{\hat{T}}$), che rappresenta la deviazione standard della distribuzione delle possibili stime di $T$ (qualora si ripetesse il test un numero infinito di volte nelle stesse condizioni).

Di seguito, illustreremo prima come ottenere $\hat{T}$ con la formula di Kelley e, in seguito, come calcolare il corrispondente errore standard della stima per costruire un intervallo di confidenza.


## Il paradosso di Kelley

Negli anni ’20, **Kelley** ha mostrato che il punteggio vero di un rispondente può essere stimato mediante un modello di regressione lineare che lega i punteggi osservati a quelli veri. Tale relazione si basa sul concetto che l’affidabilità ($\rho$) di un test coincide con il quadrato della correlazione tra punteggi osservati e punteggi veri. La **formula di Kelley** per la stima $\hat{T}$ del punteggio vero risulta:
  
$$
\begin{equation}
\hat{T} = \mu_x + \rho  (X - \mu_x),
\end{equation}
$$ {#eq-kelly}

dove:

- $X$ è il punteggio osservato,
- $\mu_x$ è la media dei punteggi nel campione (o nella popolazione di riferimento),
- $\rho$ è l’affidabilità del test (coefficiente di correlazione tra $X$ e $T$).

Quando $\rho = 1$, il test è perfettamente affidabile e il punteggio vero coincide con il punteggio osservato. Se invece $\rho = 0$, l’intera varianza è attribuibile all’errore e la stima più “sicura” del punteggio vero è la semplice media dei punteggi ($\mu_x$). Per valori compresi tra 0 e 1, $\hat{T}$ si avvicina alla media campionaria in misura proporzionale al grado di affidabilità del test, dando luogo a quella che viene definita *regressione verso la media*.

Questo comportamento rispecchia quello che Kelley definì un “paradosso”: intuitivamente, si sarebbe tentati di considerare $X$ (il punteggio osservato) come la migliore stima del punteggio vero. In realtà, quando l’affidabilità del test non è perfetta, la formula di Kelley mostra che conviene correggere il punteggio osservato spostandolo (più o meno) verso la media.

> “This is an interesting equation in that it expresses the estimate of true ability as the weighted sum of two separate estimates, one based upon the individual’s observed score, $X_1$, and the other based upon the mean of the group to which he belongs, $M_1$. If the test is highly reliable, much weight is given to the test score and little to the group mean, and vice versa.”  
> *(Kelley, 1947)*


## Derivazione 

**1. Partenza: un modello di regressione lineare.**

Per chiarire l'@eq-kelly e la sua derivazione in termini di predizione del punteggio vero a partire dal punteggio osservato, partiamo da un modello di regressione lineare. Questo modello stabilisce che il punteggio osservato $X$ sia legato al punteggio vero $T$ da una relazione lineare del tipo $X = 0 + 1 \cdot T + E$, dove $E$ rappresenta l’errore di misura (o rumore), con media zero. Il nostro interesse qui, però, si sposta verso la predizione del punteggio vero $T$ utilizzando il punteggio osservato $X$, attraverso un modello di regressione. La formula per questa predizione assume la forma:

$$
T = \alpha + \beta X + \varepsilon ,
$$

in cui $\alpha$ è l’intercetta, $\beta$ è la pendenza (slope) e $\varepsilon$ è il nuovo errore di regressione (che non va confuso con l’errore di misura precedentemente indicato con $E$).

**2. Passaggio a variabili centrate.**

Per semplificare l’analisi, si introducono le variabili come scostamenti dalla loro media:

$$
x = X - \bar{X}, \quad \tau = T - \mathbb{E}(T) ,
$$

dove $\bar{X}$ è la media campionaria (o popolazionale, a seconda dei casi) di $X$, mentre $\mathbb{E}(T)$ è la media teorica di $T$.

Se consideriamo le variabili centrate, la media di $x$ e di $\tau$ è per definizione zero. Questo fa sì che l’intercetta $\alpha$ nel modello centrato sia 0. Di conseguenza, il modello di regressione si scrive come:

$$\hat{\tau} = \beta x ,$$

Qui $\hat{\tau}$ è la stima di $\tau$ (quindi, una volta “decentrata”, è la stima di $T$).

**3. Calcolo della pendenza $\beta$.**

Nel modello di regressione lineare semplice, la pendenza $\beta$ è data dal rapporto fra la covarianza di $\tau$ $x$ e la varianza di $x$:

$$
\beta = \frac{\sigma_{\tau x}}{\sigma^2_x}.
$$ 

Spesso conviene passare dalla covarianza $\sigma_{\tau x}$ alla correlazione $\rho_{\tau x}$. La correlazione tra $\tau$ e $x$ è definita come:
  
$$
\rho_{\tau x} = \frac{\sigma_{\tau x}}{\sigma_\tau \sigma_x} .
$$

Da qui otteniamo:

$$
\sigma_{\tau x} = \rho_{\tau x} \, \sigma_\tau \, \sigma_x.
$$

Sostituendo $\sigma_{\tau x}$ nella formula di $\beta$, si ha:

$$
\beta = \frac{\rho_{\tau x} \, \sigma_\tau \, \sigma_x}{\sigma_x^2} 
    = \rho_{\tau x} \frac{\sigma_\tau}{\sigma_x}.
$$

Sostituendo $\beta$ nel modello $\hat{\tau} = \beta x$, otteniamo:

$$
\hat{\tau} = \left(\rho_{\tau x} \frac{\sigma_\tau}{\sigma_x}\right) x.
$$

**4. Collegamento con il concetto di attendibilità.**

L’attendibilità $\rho_{xx^\prime}$ (o talvolta $r_{xx'}$ in ambito campionario) si basa sull’idea che $\sigma^2_{\tau}$, la varianza del punteggio vero, si può esprimere come:

$$
\sigma^2_{\tau} = \sigma^2_x \rho_{xx^\prime} .
$$

Si dimostra (in psicometria classica) che $\rho_{\tau x}^2 = \rho_{xx^\prime}$. Da ciò segue che:

$$
\rho_{\tau x} = \sqrt{\rho_{xx^\prime}}.
$$

Quindi, sostituendo nella formula precedente per $\hat{\tau}$:

$$
\hat{\tau} 
= \left(\rho_{\tau x} \frac{\sigma_\tau}{\sigma_x}\right) x
= \left(\sqrt{\rho_{xx^\prime}} \, \frac{\sigma_\tau}{\sigma_x}\right) x.
$$

E, ricordando che $\sigma_\tau^2 = \sigma_x^2 \rho_{xx^\prime}$, si ha $\sigma_\tau = \sqrt{\rho_{xx^\prime}}\,\sigma_x$. Pertanto:

$$
\hat{\tau} = \sqrt{\rho_{xx^\prime}} \, \frac{\sqrt{\rho_{xx^\prime}}\, \sigma_x}{\sigma_x} \, x
= \rho_{xx^\prime} \, x.
$$

Ovvero:

$$
\boxed{\hat{\tau} = \rho_{xx^\prime} \, x.}
$$

Questa è la formula finale in termini di variabili centrate: la stima $\hat{\tau}$ (ovvero la stima del punteggio vero rispetto alla media) è uguale a $\rho_{xx^\prime}$ (il coefficiente di attendibilità) moltiplicato per $x$ (lo scostamento del punteggio osservato dalla sua media).

**5. Ritorno ai punteggi “grezzi”.**

Se vogliamo la stima del punteggio vero in forma “grezza”, cioè $\hat{T}$, dobbiamo “riportare” la stima $\hat{\tau}$ al livello di $T$. Ricordiamo che $\tau = T - \mathbb{E}(T)$. A livello operativo (in versione campionaria), si aggiunge $\bar{X}$ per compensare lo scostamento dalla media di $X$. 

Poiché $\hat{\tau} = \hat{T} - \bar{T}$, e nel caso più semplice assumiamo $\bar{T} \approx \bar{X}$ (ciò accade quando, in media, $\mathbb{E}(T)$ coincide con $\bar{X}$), otteniamo:

$$
\hat{T} = \bar{X} + \rho_{xx^\prime} (X - \bar{X}).
$$

Espandendo e riordinando, la formula rimane:

$$
\boxed{\hat{T} = \bar{X} + \rho_{xx^\prime} \bigl(X - \bar{X}\bigr).}
$$

Questa rappresenta la **formula di Kelly** (o **formula di regressione per la stima del punteggio vero**).

**6. Dal coefficiente di attendibilità teorico a quello stimato.**
  
In pratica, non si conosce quasi mai $\rho_{xx^\prime}$ (attendibilità vera della popolazione). Perciò, si usa la stima campionaria $r_{xx^\prime}$, calcolata dai dati. La formula finale per stimare il punteggio vero di un individuo partendo dal punteggio osservato diventa:

$$
\boxed{
  \hat{T} = \bar{X} + r_{xx^\prime} \bigl(X - \bar{X}\bigr) 
}
$$
    
dove:

- $r_{xx^\prime}$ è la stima dell’attendibilità ricavata dai dati.
- $\bar{X}$ è la media dei punteggi osservati nel campione.
- $X$ è il punteggio osservato dell’individuo.

**Significato intuitivo.**  

- Se $r_{xx^\prime}$ è elevato, significa che il test è molto affidabile, e quindi la stima $\hat{T}$ sarà vicina a $X$.  
- Se $r_{xx^\prime}$ è basso, significa che c’è molta incertezza nella misura; la stima $\hat{T}$ tende allora ad avvicinarsi maggiormente alla media $\bar{X}$.

In conclusione, la derivazione qui mostrata spiega, passo per passo, come si passi dal concetto di regressione lineare al risultato finale che mette in relazione il punteggio osservato (centrato e non) con la stima del punteggio vero, tenendo conto del coefficiente di attendibilità. Il risultato finale:
  
$$
\hat{T} = \bar{X} + \rho_{xx^\prime} (X - \bar{X}),
$$

(o la sua controparte campionaria con $r_{xx^\prime}$) fornisce un modo intuitivo ed efficace per “correggere” il punteggio osservato $X$ in base alla sua attendibilità, restituendo una stima del punteggio vero di un individuo.

::: {#exm-}
Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a $\bar{X} = 100$, si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a $X$ = 115.

La stima del punteggio vero $\hat{T}$ è uguale a 

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X})\notag\\
&= 100 + 0.80 \cdot (115 - 100) = 112.
\end{aligned}
\end{equation}
$$

In alternativa, possiamo usare la funzione `Est.true` del pacchetto `psychometric`.

```{r}
Est.true(115, 100, .8)
```
:::


## Errore Standard della Stima

Nel contesto del modello di regressione di Kelley, un indice fondamentale per valutare la precisione con cui i punteggi veri vengono stimati a partire dai punteggi osservati è l’**errore standard della stima** (indicato con $\sigma_{\hat{T}}$). Questo parametro descrive quanto le **stime del punteggio vero** ($\hat{T}$) potrebbero variare se ripetessimo la misurazione (o il test) più volte nelle stesse condizioni:

- Se $\sigma_{\hat{T}}$ è **piccolo**, la stima del punteggio vero è più “stabile” (varia poco).
- Se $\sigma_{\hat{T}}$ è **grande**, c’è più incertezza nella stima del punteggio vero.

La formula generale per l’errore standard della stima, sotto le ipotesi classiche di normalità e linearità, è:

$$
\sigma_{\hat{T}} 
= \sigma_X \,\sqrt{\rho_{XX^\prime} \,\bigl(1 - \rho_{XX^\prime}\bigr)},
$$ {#eq-std-err-estimate}

dove:

- $\sigma_X$ è la deviazione standard dei punteggi osservati $X$,
- $\rho_{XX^\prime}$ è il coefficiente di affidabilità (o correlazione) fra il punteggio osservato $X$ e il punteggio vero $T$.

Nel caso di **dati campionari**, si usano i corrispettivi $s_X$ e $r_{XX^\prime}$:

$$
s_{\hat{T}} 
= s_X \,\sqrt{r_{XX^\prime} \,\bigl(1 - r_{XX^\prime}\bigr)}.
$$ {#eq-std-err-estimate-camp}

## Derivazione dell’Errore Standard della Stima

**1. Stima di Kelley: forma “grezza” e forma “centrata”.**

**Forma grezza.**  
Nel modello di Kelley, la stima del punteggio vero (in termini grezzi) è:

$$
\hat{T}
= \bar{X} \;+\; \rho_{XX^\prime}\,\bigl(X - \bar{X}\bigr).
$$

Qui $\bar{X}$ è la media dei punteggi osservati nel campione (o popolazione, a seconda del contesto).

**Forma centrata.**  
Talvolta, per semplificare gli aspetti algebrici, si introduce una versione centrata. Definiamo:

$$
\tau = T - \bar{T}, 
\quad
x = X - \bar{X},
$$

dove $\bar{T}$ è la media teorica (o campionaria) dei punteggi veri. In questa forma:

$$
\hat{\tau}
= \rho_{XX^\prime}\, x
\;\;\Longrightarrow\;\;
\hat{T}
= \bar{T} + \rho_{XX^\prime}\,\bigl(X - \bar{X}\bigr).
$$

Se si assume $\bar{T}\approx \bar{X}$, le due scritture coincidono. **In ogni caso**, il passaggio dalla forma centrata a quella grezza comporta solo l’aggiunta (o sottrazione) di costanti, che non incide sul calcolo della varianza.  

**2. Definizione dell’errore di stima $\varepsilon$.**

L’**errore di stima** $\varepsilon$ è la discrepanza fra il punteggio vero $T$ e la sua stima $\hat{T}$:

$$
\varepsilon
= T - \hat{T}.
$$

> **Attenzione**: $\varepsilon$ **non** è l’errore di misura $E = X - T$.  
> - $E$ riflette la differenza fra $X$ (punteggio osservato) e $T$ (punteggio vero).  
> - $\varepsilon$ riflette la differenza fra $T$ e $\hat{T}$ (ossia: quanto la stima “azzecca” il vero valore).

**3. Calcolo della varianza dell’errore di stima $\sigma_{\varepsilon}^2$.**

Il nostro obiettivo è derivare:

$$
\sigma_{\varepsilon}^2
= \mathbb{V}(\varepsilon) 
= \mathbb{V}(T - \hat{T}).
$$

**3.1 Passaggio dal modello “grezzo” alla forma semplificata.**

Da $\hat{T} = \bar{X} + \rho_{XX^\prime}\,(X - \bar{X})$, se togliamo la costante $\bar{X}$, non alteriamo la varianza. Quindi, ai fini del calcolo di $\mathbb{V}(T - \hat{T})$, possiamo scrivere:

$$
\hat{T} \;\approx\; \rho_{XX^\prime}\,X 
\quad(\text{ignorando le costanti}).
$$

Perciò,

$$
\varepsilon 
= T - \hat{T} 
\;\approx\; T - \rho_{XX^\prime}\,X.
$$

**3.2 Varianza di $\varepsilon$.**

Calcoliamo la varianza:

$$
\mathbb{V}(\varepsilon)
= \mathbb{V}(T - \rho_{XX^\prime} X).
$$

Usando le proprietà della varianza:

$$
\mathbb{V}(T - \rho_{XX^\prime} X)
= \mathbb{V}(T)
+ \rho_{XX^\prime}^2\,\mathbb{V}(X)
- 2\,\rho_{XX^\prime}\,\mathrm{Cov}(T,X).
$$

Da **psicometria classica** sappiamo che:

- $\mathbb{V}(T) = \sigma_T^2$,
- $\mathbb{V}(X) = \sigma_X^2$,
- $\mathrm{Cov}(T, X) = \sigma_T^2$, poiché $X = T + E$ e $\mathrm{Cov}(T, E) = 0$.

Sostituiamo:

$$
\sigma_{\varepsilon}^2
= \sigma_T^2 
\;+\; \rho_{XX^\prime}^2 \,\sigma_X^2
\;-\; 2\,\rho_{XX^\prime}\,\sigma_T^2.
$$

**3.3 Rapporto tra $\rho_{XX^\prime}$ e $\sigma_T^2, \sigma_X^2$.**

Per definizione di **affidabilità** nel modello classico:

$$
\rho_{XX^\prime}
= \frac{\sigma_T^2}{\sigma_X^2}.
$$

Pertanto:

- $\rho_{XX^\prime}^2 \,\sigma_X^2 = \Bigl(\tfrac{\sigma_T^2}{\sigma_X^2}\Bigr)^2 \sigma_X^2 = \tfrac{\sigma_T^4}{\sigma_X^4}\,\sigma_X^2 = \tfrac{\sigma_T^4}{\sigma_X^2}.$
- $-\,2\,\rho_{XX^\prime}\,\sigma_T^2 = -\,2\,\tfrac{\sigma_T^2}{\sigma_X^2}\,\sigma_T^2 = -\,2\,\tfrac{\sigma_T^4}{\sigma_X^2}.$

Sostituendo:

$$
\sigma_{\varepsilon}^2
= \sigma_T^2
+ \frac{\sigma_T^4}{\sigma_X^2}
- 2\,\frac{\sigma_T^4}{\sigma_X^2}
= \sigma_T^2 \;-\; \frac{\sigma_T^4}{\sigma_X^2}.
$$

Fattorizzando $\sigma_T^2$:

$$
\sigma_{\varepsilon}^2
= \sigma_T^2\Bigl(1 - \frac{\sigma_T^2}{\sigma_X^2}\Bigr).
$$

Dal momento che $\tfrac{\sigma_T^2}{\sigma_X^2} = \rho_{XX^\prime}$,

$$
\sigma_{\varepsilon}^2
= \sigma_T^2 \,\bigl(1 - \rho_{XX^\prime}\bigr).
$$

Prendendo la radice quadrata:

$$
\sigma_{\varepsilon}
= \sigma_T\,\sqrt{1 - \rho_{XX^\prime}}.
$$

**3.4 Da $\sigma_T$ a $\sigma_X$.**

Ricordiamo anche che $\sigma_T^2 = \rho_{XX^\prime}\,\sigma_X^2$. Quindi:

$$
\sigma_T
= \sqrt{\rho_{XX^\prime}}\;\,\sigma_X.
$$

Sostituendo in $\sigma_{\varepsilon} = \sigma_T \,\sqrt{1 - \rho_{XX^\prime}}$:

$$
\sigma_{\varepsilon}
= \bigl(\sqrt{\rho_{XX^\prime}}\,\sigma_X\bigr)\,\sqrt{1 - \rho_{XX^\prime}}
= \sigma_X \,\sqrt{\rho_{XX^\prime}\,\bigl(1 - \rho_{XX^\prime}\bigr)}.
$$

Ma $\sigma_{\varepsilon}$ è, per definizione, la deviazione standard di $T - \hat{T}$. In questo modello, coincide con **l’errore standard della stima**, $\sigma_{\hat{T}}$. Da qui la formula finale:

$$
\boxed{
\sigma_{\hat{T}}
= \sigma_X\,\sqrt{\rho_{XX^\prime}\,\bigl(1 - \rho_{XX^\prime}\bigr)},
}
$$

che è esattamente l'@eq-std-err-estimate.

## Intervallo di Confidenza per il Punteggio Vero

Una volta noto l’errore standard della stima $\sigma_{\hat{T}}$, possiamo costruire un **intervallo di confidenza** (IC) per il punteggio vero. L’idea è simile alla statistica classica:

$$
\hat{T} \;\pm\; z \,\sigma_{\hat{T}},
$$

dove:

- $\hat{T}$ è la stima puntuale del punteggio vero (e.g., $\bar{X} + \rho_{XX^\prime}(X - \bar{X})$),
- $z$ è il quantile della distribuzione normale standard (per esempio, $z = 1{,}96$ per un IC al 95\%),
- $\sigma_{\hat{T}}$ è l’errore standard della stima.

Se il campione è **molto piccolo** (meno di 30 soggetti), si sostituisce $z$ con $t$ (la distribuzione di Student).

**Interpretazione**  

- L’ampiezza dell’intervallo di confidenza dipende sia dal livello di confidenza (tramite $z$ o $t$) sia dalla precisione della stima (tramite $\sigma_{\hat{T}}$).  
- Quando $\rho_{XX^\prime}$ è bassa, il fattore $\sqrt{\rho_{XX^\prime}(1 - \rho_{XX^\prime})}$ può aumentare considerevolmente, allargando l’intervallo di confidenza. 
- Un **intervallo più ampio** indica maggiore incertezza nella stima del punteggio vero.

In sintesi, **l’errore standard della stima** $\sigma_{\hat{T}}$ fornisce un modo diretto per quantificare l’incertezza della stima di Kelley: se conosco $\sigma_{\hat{T}}$, posso immediatamente costruire intervalli di confidenza e capire “quanto fidarmi” dei punteggi veri stimati da un test.


::: {#exm-1}
@charter1996revisiting ha esaminato l'effetto della variazione dell'attendibilità del test sull'ampiezza dell'intervallo di confidenza per il punteggio vero. Utilizzando come esempio i punteggi di QI ($\mu$ = 100, $\sigma$ = 15), Charter ha immaginato di variare il coefficiente di attendibilità del test utilizzato per la misurazione del QI. I valori presi in considerazione sono 0.55, 0.65, 0.75, 0.85 e 0.95. Ad esempio, supponiamo di avere un punteggio osservato pari a QI = 120 e un coefficiente di attendibilità del test $\rho_{xx^\prime}$ pari a 0.65. In tali circostanze, la stima del punteggio vero è pari a

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X}) \notag\\
&= 100 + 0.65 (120 - 100)\notag\\
&= 113.\notag
\end{aligned}
\end{equation}
$$

L'errore standard della stima è uguale a

$$
\begin{equation}
\begin{aligned}
\sigma_{\hat{T}} &= \sigma_{X} \sqrt{r_{XX^\prime} (1 - r_{XX^\prime})} \notag\\
&= 15 \sqrt{0.65 (1 - 0.65)}\notag\\
&= 7.15.\notag
\end{aligned}
\end{equation}
$$

L'intervallo di confidenza al 95% per la stima del punteggio vero diventa pertanto uguale a 

$$
113 \pm 1.96 \cdot 7.15 = [98.98, 127.02].
$$ 

Si noti che si può calcolare l'errore standard della stima con la funzione `SE.Est()` del pacchetto `psychometric`.

```{r}
SE.Est(15, .65)
```

\
Inoltre, la funzione `CI.tscore()` restituisce sia la stima del punteggio vero sia l'intervallo di fiducia al livello desiderato di significatività. 

```{r}
CI.tscore(120, 100, 15, 0.65, level = 0.95)
```
:::


## Cut-off

Una delle applicazioni pratiche degli **intervalli di confidenza** sul punteggio vero è il confronto con un cut-off (o soglia). L’idea di base è semplice: se l’intero intervallo di confidenza risulta superiore (o inferiore) al cut-off, si può concludere – con il grado di certezza desiderato $(1 - \alpha)$ – che il **punteggio vero** del rispondente superi (o non raggiunga) tale soglia. Se invece il cut-off cade all’interno dell’intervallo di confidenza, allora non si può prendere una decisione netta: i dati non sono sufficienti a stabilire se il valore vero sia al di sopra o al di sotto del cut-off.

::: {#exm-1}
Consideriamo i punteggi del QI, con media campionaria $\bar{X} = 100$ e deviazione standard $s_X = 15$. Supponiamo inoltre che l’attendibilità del test sia $\rho_{XX^\prime} = 0{,}95$. Se un individuo ottiene un QI osservato $X = 130$ e vogliamo sapere se il suo punteggio vero supera un cut-off di 120, possiamo costruire l’intervallo di confidenza al 95%.

Nel frammento di codice (in R) seguente si riportano i passaggi per calcolare la stima del punteggio vero $\hat{T}$ e il relativo errore standard $\sigma_{\hat{T}}$, e per costruire l’intervallo di confidenza al 95%:

```{r}
xm <- 100        # media dei punteggi
sx <- 15         # dev. standard dei punteggi
rho <- 0.95      # affidabilità
x <- 130         # punteggio osservato

# Stima del punteggio vero 
t.hat <- xm + rho * (x - xm)
t.hat

# Errore standard della stima
se.t <- sx * sqrt(rho * (1 - rho))
se.t

# Intervallo di confidenza al 95%
t.hat + c(-1, 1) * qnorm(0.975) * se.t
```

Se il limite inferiore di questo intervallo risulta superiore a 120, possiamo concludere con un livello di confidenza del 95% che il punteggio vero dell’individuo superi il cut-off. Di conseguenza, lo psicologo potrebbe raccomandare l’ammissione dell’individuo a un corso avanzato (nell’esempio, è quanto accade con $\rho_{XX^\prime} = 0{,}95$).

Continuando, supponiamo che l’attendibilità del test sia $0{,}80$, un valore empiricamente più frequente. In questo caso, la diminuzione di $\rho_{XX^\prime}$ aumenta l’errore standard della stima, allargando l’intervallo di confidenza. Di fatto, con $\rho_{XX^\prime} = 0{,}80$, l’intervallo 95% per il punteggio vero del medesimo QI osservato (130) potrebbe includere il cut-off di 120, rendendo impossibile concludere che il valore vero sia effettivamente al di sopra della soglia. In sintesi, **minore è l’affidabilità**, maggiore è l’ampiezza dell’intervallo di confidenza, e dunque **minore la certezza** di superare (o non superare) un dato cut-off.
:::

## Riflessioni Conclusive

La teoria classica del punteggio vero (CTT) si basa su un modello additivo, nel quale il **punteggio osservato** $X$ è la somma di due componenti:

$$
X = T + E,
$$

dove $T$ è il punteggio vero (concettualmente stabile) ed $E$ è il punteggio di errore (inteso come variabilità casuale). Nel quadro della CTT, si assume che l’errore $E$ non sia correlato né con il punteggio vero $T$ del test in questione, né con altri test (composti dal loro punteggio vero e da un proprio errore). I **test paralleli** condividono gli stessi punteggi veri e la stessa varianza di errore, mentre i **test $\tau$-equivalenti** differiscono tra loro solo per una costante additiva dei punteggi veri. Tuttavia, nella pratica, le condizioni richieste da questi modelli possono essere violate in vari modi (per esempio, con item eterogenei, con campioni molto diversi, oppure quando il “vero attributo” non è stabilmente misurabile in condizioni ripetute).

È importante ricordare che né $T$ né $E$ sono **direttamente osservabili**: si tratta di concetti teorici, mentre i dati empirici a nostra disposizione sono unicamente i punteggi $X$. Parlare di “punteggio vero” significa riferirsi a una media ipotetica su infinite ripetizioni del test, ma ciò non garantisce che il costrutto misurato coincida esattamente con la “realtà” psicologica o educativa sottostante. Infatti, qualunque test, per quanto affidabile, ha sempre un certo margine di errore e può non cogliere del tutto l’attributo di interesse.

**Vantaggi della CTT.**

- **Semplicità concettuale**: la CTT è ampiamente diffusa e relativamente facile da comprendere.  
- **Calcoli accessibili**: statistiche descrittive e analisi degli item (difficoltà, discriminazione) possono essere implementate agevolmente.  
- **Adattabilità in contesti vari**: specialmente nei test di competenza, valutazioni di collocamento e decisioni di ammissione, la CTT offre soluzioni adeguate e immediate.  
- **Interpretazioni intuitive**: punteggi e difficoltà item sono espressi in range (0–100% e 0.0–1.0), con significati diretti e “reali”.

**Limiti della CTT.**

- **Test lunghi e omogenei**: per ottenere affidabilità elevata, la CTT tende a richiedere un maggior numero di item simili.  
- **Item inadatti a individui estremi**: un test concepito per la “media” può rivelarsi troppo facile o troppo difficile per un dato esaminando.  
- **Dipendenza dal campione**: le stime di difficoltà e discriminazione degli item (e di validità/affidabilità) valgono specificamente per il campione analizzato o per campioni molto simili.  
- **Riferimento a una selezione di item**: spostando o cambiando gli item, si alterano i risultati di validità e affidabilità.  
- **Applicabilità “normativa”**: la CTT è più adatta a costruire test normativi (assumendo distribuzioni tendenzialmente normali).  
- **Sensibilità agli estremi**: le correlazioni tra discriminazione degli item, affidabilità e validità possono variare in modo rilevante per punteggi molto alti o molto bassi.  
- **Errore di misurazione costante**: benché nella realtà l’errore possa variare lungo il continuum dei punteggi (spesso minore intorno alla media e maggiore agli estremi), la CTT fornisce una stima “media” dell’errore di misurazione, senza distinguere i differenti livelli di abilità.

**Conclusioni.**

L’esempio del cut-off mostra come gli **intervalli di confidenza** possano supportare decisioni pratiche, ma anche come tali decisioni siano influenzate dall’**affidabilità** del test. Una singola stima puntuale ($\hat{T}$) può apparire “sicura”, ma occorre valutarne la variabilità tramite l’**errore standard della stima**. In parallelo, le riflessioni sul modello CTT ricordano che i “punteggi veri” e gli “errori” sono costrutti teorici, e che la loro adeguatezza dipende dall’aderenza delle ipotesi di base. Sebbene la CTT sia uno strumento largamente utilizzato (per la sua semplicità e immediatezza), in contesti più complessi o in cui la personalizzazione del test è necessaria (ad esempio, per adattare gli item al livello del rispondente), modelli più recenti come la **teoria della risposta all’item** (IRT) possono offrire maggior flessibilità e precisione.

In definitiva, scegliere la **CTT** o altri modelli di misura dipende dagli obiettivi del test, dal contesto di utilizzo e dalla disponibilità di risorse analitiche e di campioni adeguati. La comprensione dei limiti e delle potenzialità di ciascun approccio risulta fondamentale per ogni psicologo che si occupi di sviluppo e interpretazione di test.

## Session Info

```{r}
sessionInfo()
```


# La stima del punteggio vero {#sec-ctt-true-score-estimate}

**Preparazione del Notebook**

```{r}
here::here("code", "_common.R") |> source()
pacman::p_load(psychometric)
```

## Introduzione
  
Nella CTT, la **stima del punteggio vero** con il metodo della **regressione di Kelley** offre una correzione del punteggio osservato basata sull’affidabilità del test, al fine di ottenere una valutazione più precisa del “vero” punteggio di un individuo. L’idea è di ridurre l’errore di misurazione compensando gli estremi: punteggi molto alti o molto bassi tendono infatti a convergere verso la media. Nella formula di Kelley, il punteggio stimato risulta da una media ponderata tra il punteggio osservato e la media dei punteggi (del campione o della popolazione), con pesi determinati dall’affidabilità del test.

Un obiettivo essenziale della valutazione psicologica è proprio quello di stimare il punteggio vero del soggetto. Poiché il punteggio osservato $X$ differisce dal punteggio vero $T$ a causa dell’errore di misurazione $(X = T + E)$, la CTT ci fornisce gli strumenti per correggere $X$ tenendo conto dell’affidabilità del test. Questa correzione è particolarmente utile quando si desidera costruire un intervallo di confidenza per il punteggio vero del **singolo soggetto**.

Per costruire tale intervallo di confidenza, servono due ingredienti:
  
1. una stima puntuale del punteggio vero ($\hat{T}$);
2. l’errore standard della stima ($\sigma_{\hat{T}}$), che rappresenta la deviazione standard della distribuzione delle possibili stime di $T$ (qualora si somministrasse il test un numero infinito di volte nelle stesse condizioni).

Di seguito, illustreremo prima come ottenere $\hat{T}$ con la formula di Kelley e, in seguito, come calcolare il corrispondente errore standard della stima per costruire un intervallo di confidenza.


## Il paradosso di Kelley

@kelley1921reliability dimostrò che il punteggio vero di un rispondente può essere stimato mediante un modello di regressione lineare che lega i punteggi osservati a quelli veri. Tale relazione si basa sul concetto che l’affidabilità ($\rho$) di un test coincide con il quadrato della correlazione tra punteggi osservati e punteggi veri. La **formula di Kelley** per la stima $\hat{T}$ del punteggio vero risulta:
  
$$
\begin{equation}
\hat{T} = \mu_x + \rho  (X - \mu_x),
\end{equation}
$$ {#eq-kelly}

dove:

- $X$ è il punteggio osservato (espresso come scarti dalla media),
- $\mu_x$ è la media dei punteggi $X$ nel campione (o nella popolazione di riferimento),
- $\rho$ è l’affidabilità del test (coefficiente di correlazione tra $X$ e $T$).

::: {.callout-tip title="Nota" collapse="true"}
Si noti che, nell'@eq-kelly, il ruolo di $T$ e $X$ è invertito rispetto all'equazione di regressione precedentemente considerata. Inizialmente, ci interessava comprendere in che modo i punteggi osservati $X$ fossero determinati dai punteggi veri $T$. Ora, invece, il nostro obiettivo è **stimare** i punteggi veri a partire da quelli osservati.
:::

Quando $\rho = 1$, il test è perfettamente affidabile e il punteggio vero coincide con il punteggio osservato. Se invece $\rho = 0$, l’intera varianza è attribuibile all’errore e la stima più “sicura” del punteggio vero è la semplice media dei punteggi ($\mu_x$). Per valori compresi tra 0 e 1, $\hat{T}$ si avvicina alla media campionaria in misura proporzionale al grado di affidabilità del test, dando luogo a quella che viene definita *regressione verso la media*.

Questo comportamento rispecchia quello che Kelley definì un “paradosso”: intuitivamente, si sarebbe tentati di considerare $X$ (il punteggio osservato) come la migliore stima del punteggio vero. In realtà, quando l’affidabilità del test non è perfetta, la formula di Kelley mostra che conviene correggere il punteggio osservato spostandolo (più o meno) verso la media.

> “This is an interesting equation in that it expresses the estimate of true ability as the weighted sum of two separate estimates, one based upon the individual’s observed score, $X_1$, and the other based upon the mean of the group to which he belongs, $M_1$. If the test is highly reliable, much weight is given to the test score and little to the group mean, and vice versa.”  
> *(Kelley, 1947)*


## Derivazione 

**1. Partenza: un modello di regressione lineare.**

Per chiarire l'@eq-kelly, partiamo da un modello di regressione lineare. Questo modello stabilisce che il punteggio osservato $X$ sia legato al punteggio vero $T$ da una relazione lineare del tipo $X = 0 + 1 \cdot T + E$, dove $E$ rappresenta l’errore di misura (o rumore), con media zero (come abbiamo visto in precedenza).

Il nostro interesse qui, però, si sposta verso la predizione del punteggio vero $T$ utilizzando il punteggio osservato $X$, attraverso un modello di regressione. La formula per questa predizione assume la forma:

$$
T = \alpha + \beta X + \varepsilon ,
$$

in cui $\alpha$ è l’intercetta, $\beta$ è la pendenza (slope) e $\varepsilon$ è il nuovo errore di regressione (che non va confuso con l’errore di misura precedentemente indicato con $E$).

**2. Passaggio a variabili centrate.**

Per semplificare l’analisi, si introducono le variabili come scostamenti dalla loro media:

$$
x = X - \bar{X}, \quad \tau = T - \mathbb{E}(T) ,
$$

dove $\bar{X}$ è la media campionaria (o popolazionale, a seconda dei casi) di $X$, mentre $\mathbb{E}(T)$ è la media teorica di $T$.

Se consideriamo le variabili centrate, la media di $x$ e di $\tau$ è per definizione zero. Questo fa sì che l’intercetta $\alpha$ nel modello centrato sia 0. Di conseguenza, il modello di regressione si scrive come:

$$\hat{\tau} = \beta x ,$$

Qui $\hat{\tau}$ è la stima di $\tau$ (quindi, una volta “decentrata”, è la stima di $T$).

**3. Calcolo della pendenza $\beta$.**

Nel modello di regressione lineare semplice, la pendenza $\beta$ è data dal rapporto fra la covarianza tra $\tau$ e $x$, e la varianza di $x$:

$$
\beta = \frac{\sigma_{\tau x}}{\sigma^2_x}.
$$ 

Esprimiamo la covarianza $\sigma_{\tau x}$ in termini della correlazione $\rho_{\tau x}$. La correlazione tra $\tau$ e $x$ è definita come:
  
$$
\rho_{\tau x} = \frac{\sigma_{\tau x}}{\sigma_\tau \sigma_x} .
$$

Da qui otteniamo:

$$
\sigma_{\tau x} = \rho_{\tau x} \, \sigma_\tau \, \sigma_x.
$$

Sostituendo $\sigma_{\tau x}$ nella formula di $\beta$, si ha:

$$
\beta = \frac{\rho_{\tau x} \, \sigma_\tau \, \sigma_x}{\sigma_x^2} 
    = \rho_{\tau x} \frac{\sigma_\tau}{\sigma_x}.
$$

Sostituendo $\beta$ nel modello $\hat{\tau} = \beta x$, otteniamo:

$$
\hat{\tau} = \left(\rho_{\tau x} \frac{\sigma_\tau}{\sigma_x}\right) x.
$$

**4. Collegamento con il concetto di attendibilità.**

L’attendibilità $\rho_{xx^\prime}$ si basa sull’idea che $\sigma^2_{\tau}$, la varianza del punteggio vero, si può esprimere come:

$$
\sigma^2_{\tau} = \sigma^2_x \rho_{xx^\prime} .
$$

Si dimostra altresì che $\rho_{\tau x}^2 = \rho_{xx^\prime}$. Da ciò segue che:

$$
\rho_{\tau x} = \sqrt{\rho_{xx^\prime}}.
$$

Quindi, sostituendo nella formula precedente per $\hat{\tau}$:

$$
\hat{\tau} 
= \left(\rho_{\tau x} \frac{\sigma_\tau}{\sigma_x}\right) x
= \left(\sqrt{\rho_{xx^\prime}} \, \frac{\sigma_\tau}{\sigma_x}\right) x.
$$

E, ricordando che $\sigma_\tau^2 = \sigma_x^2 \rho_{xx^\prime}$, si ha $\sigma_\tau = \sqrt{\rho_{xx^\prime}}\,\sigma_x$. Pertanto:

$$
\hat{\tau} = \sqrt{\rho_{xx^\prime}} \, \frac{\sqrt{\rho_{xx^\prime}}\, \sigma_x}{\sigma_x} \, x
= \rho_{xx^\prime} \, x.
$$

Ovvero:

$$
\boxed{\hat{\tau} = \rho_{xx^\prime} \, x.}
$$

Questa è la formula finale in termini di variabili centrate: la stima $\hat{\tau}$ (ovvero la stima del punteggio vero rispetto alla media) è uguale a $\rho_{xx^\prime}$ (il coefficiente di attendibilità) moltiplicato per $x$ (lo scostamento del punteggio osservato dalla sua media).

**5. Ritorno ai punteggi “grezzi”.**

Se vogliamo la stima del punteggio vero in forma “grezza”, cioè $\hat{T}$, dobbiamo “riportare” la stima $\hat{\tau}$ al livello di $T$. Poiché $\hat{\tau} = \hat{T} - \bar{T}$, e nel caso più semplice assumiamo $\bar{T} \approx \bar{X}$, otteniamo:

$$
\hat{T} = \bar{X} + \rho_{xx^\prime} (X - \bar{X}).
$$

Espandendo e riordinando, la formula rimane:

$$
\hat{T} = \bar{X} + \rho_{xx^\prime} \bigl(X - \bar{X}\bigr).
$$ {#eq-kelley-raw}

L'@eq-kelley-raw rappresenta la **formula di Kelly** (o **formula di regressione per la stima del punteggio vero**).

**6. Dal coefficiente di attendibilità teorico a quello stimato.**
  
In pratica, non si conosce $\rho_{xx^\prime}$ (attendibilità vera della popolazione). Perciò, si usa la stima campionaria $r_{xx^\prime}$, calcolata dai dati. La formula finale per stimare il punteggio vero di un individuo partendo dal punteggio osservato diventa:

$$
\hat{T} = \bar{X} + r_{xx^\prime} \bigl(X - \bar{X}\bigr) ,
$$ {#eq-kelley-raw-sample}
    
dove:

- $r_{xx^\prime}$ è la stima dell’attendibilità ricavata dai dati,
- $\bar{X}$ è la media dei punteggi osservati nel campione,
- $X$ è il punteggio osservato dell’individuo.

### Significato intuitivo

- Quando $r_{xx^\prime}$ è elevato, il test è altamente affidabile e la stima $\hat{T}$ risulterà prossima a $X$.  
- Al contrario, se $r_{xx^\prime}$ è basso, la misura è più incerta e la stima $\hat{T}$ tenderà ad avvicinarsi maggiormente alla media $\bar{X}$.  

In sintesi, l'@eq-kelley-raw-sample offre un metodo per **correggere** il punteggio osservato $X$ tenendo conto dell'affidabilità del test, fornendo così una stima più accurata del punteggio vero di un individuo.

::: {#exm-}
Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a $\bar{X} = 100$, si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a $X$ = 115.

La stima del punteggio vero $\hat{T}$ è uguale a 

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X})\notag\\
&= 100 + 0.80 \cdot (115 - 100) = 112.
\end{aligned}
\end{equation}
$$

In alternativa, possiamo usare la funzione `Est.true` del pacchetto `psychometric`.

```{r}
Est.true(115, 100, .8)
```
:::


## Errore Standard della Stima

Nel contesto del modello di regressione di Kelley, un indice fondamentale per valutare la precisione con cui i punteggi veri vengono stimati a partire dai punteggi osservati è l’**errore standard della stima** (indicato con $\sigma_{\hat{T}}$). Questo parametro descrive quanto le **stime del punteggio vero** ($\hat{T}$) potrebbero variare se ripetessimo la misurazione (o il test) più volte nelle stesse condizioni:

- se $\sigma_{\hat{T}}$ è **piccolo**, la stima del punteggio vero è più “stabile” (varia poco);
- se $\sigma_{\hat{T}}$ è **grande**, c’è più incertezza nella stima del punteggio vero.

La formula generale per l’errore standard della stima, sotto le ipotesi classiche di normalità e linearità, è:

$$
\sigma_{\hat{T}} 
= \sigma_X \,\sqrt{\rho_{XX^\prime} \,\bigl(1 - \rho_{XX^\prime}\bigr)} ,
$$ {#eq-std-err-estimate}

dove:

- $\sigma_X$ è la deviazione standard dei punteggi osservati $X$,
- $\rho_{XX^\prime}$ è il coefficiente di affidabilità.

Nel caso di **dati campionari**, si usano i corrispettivi $s_X$ e $r_{XX^\prime}$:

$$
s_{\hat{T}} 
= s_X \,\sqrt{r_{XX^\prime} \,\bigl(1 - r_{XX^\prime}\bigr)}.
$$ {#eq-std-err-estimate-camp}

## Derivazione dell’Errore Standard della Stima

**1. Stima di Kelley: forma “grezza” e forma “centrata”.**

Nel modello di Kelley, la stima del punteggio vero (in termini grezzi) è:

$$
\hat{T}
= \bar{X} \;+\; \rho_{XX^\prime}\,\bigl(X - \bar{X}\bigr).
$$

Qui $\bar{X}$ è la media dei punteggi osservati nel campione (o popolazione, a seconda del contesto).

Per semplificare gli aspetti algebrici, si introduce una versione centrata. Definiamo:

$$
\tau = T - \bar{T}, 
\quad
x = X - \bar{X},
$$

dove $\bar{T}$ è la media teorica (o campionaria) dei punteggi veri. In questa forma:

$$
\hat{\tau}
= \rho_{XX^\prime}\, x
\;\;\Longrightarrow\;\;
\hat{T}
= \bar{T} + \rho_{XX^\prime}\,\bigl(X - \bar{X}\bigr).
$$

Se si assume $\bar{T}\approx \bar{X}$, le due scritture coincidono. **In ogni caso**, il passaggio dalla forma centrata a quella grezza comporta solo l’aggiunta (o sottrazione) di costanti, che non incide sul calcolo della varianza.  

**2. Definizione dell’errore di stima $\varepsilon$.**

L’**errore di stima** $\varepsilon$ è la discrepanza fra il punteggio vero $T$ e la sua stima $\hat{T}$:

$$
\varepsilon
= T - \hat{T}.
$$

::: {.callout-important title="Nota"}
È fondamentale non confondere l'errore di stima $\varepsilon$ con l'errore di misura $E = X - T$:  

- $E$ rappresenta la differenza tra il punteggio osservato $X$ e il punteggio vero $T$, riflettendo l'imprecisione della misurazione;   
- $\varepsilon$ rappresenta la differenza tra il punteggio vero $T$ e la sua stima $\hat{T}$, indicando quanto accuratamente la stima riesce a catturare il valore reale.
:::

**3. Calcolo della varianza dell’errore di stima $\sigma_{\varepsilon}^2$.**

Il nostro obiettivo è derivare:

$$
\sigma_{\varepsilon}^2
= \mathbb{V}(\varepsilon) 
= \mathbb{V}(T - \hat{T}).
$$

**3.1 Passaggio dal modello “grezzo” alla forma semplificata.**

Da $\hat{T} = \bar{X} + \rho_{XX^\prime}\,(X - \bar{X})$, se togliamo la costante $\bar{X}$, non alteriamo la varianza. Quindi, ai fini del calcolo di $\mathbb{V}(T - \hat{T})$, possiamo scrivere:

$$
\hat{T} \;=\; \rho_{XX^\prime}\,X 
\quad(\text{ignorando le costanti}).
$$

Perciò,

$$
\varepsilon 
= T - \hat{T} 
\;=\; T - \rho_{XX^\prime}\,X.
$$

**3.2 Varianza di $\varepsilon$.**

Calcoliamo la varianza:

$$
\mathbb{V}(\varepsilon)
= \mathbb{V}(T - \rho_{XX^\prime} X).
$$

Usando le proprietà della varianza:

$$
\mathbb{V}(T - \rho_{XX^\prime} X)
= \mathbb{V}(T)
+ \rho_{XX^\prime}^2\,\mathbb{V}(X)
- 2\,\rho_{XX^\prime}\,\mathrm{Cov}(T,X).
$$

Sappiamo che:

- $\mathbb{V}(T) = \sigma_T^2$,
- $\mathbb{V}(X) = \sigma_X^2$,
- $\mathrm{Cov}(T, X) = \sigma_T^2$.

Sostituiamo:

$$
\sigma_{\varepsilon}^2
= \sigma_T^2 
\;+\; \rho_{XX^\prime}^2 \,\sigma_X^2
\;-\; 2\,\rho_{XX^\prime}\,\sigma_T^2.
$$

**3.3 Rapporto tra $\rho_{XX^\prime}$ e $\sigma_T^2, \sigma_X^2$.**

Per definizione di affidabilità:

$$
\rho_{XX^\prime}
= \frac{\sigma_T^2}{\sigma_X^2}.
$$

Pertanto:

- $\rho_{XX^\prime}^2 \,\sigma_X^2 = \Bigl(\tfrac{\sigma_T^2}{\sigma_X^2}\Bigr)^2 \sigma_X^2 = \tfrac{\sigma_T^4}{\sigma_X^4}\,\sigma_X^2 = \tfrac{\sigma_T^4}{\sigma_X^2}.$
- $-\,2\,\rho_{XX^\prime}\,\sigma_T^2 = -\,2\,\tfrac{\sigma_T^2}{\sigma_X^2}\,\sigma_T^2 = -\,2\,\tfrac{\sigma_T^4}{\sigma_X^2}.$

Sostituendo:

$$
\sigma_{\varepsilon}^2
= \sigma_T^2
+ \frac{\sigma_T^4}{\sigma_X^2}
- 2\,\frac{\sigma_T^4}{\sigma_X^2}
= \sigma_T^2 \;-\; \frac{\sigma_T^4}{\sigma_X^2}.
$$

Fattorizzando $\sigma_T^2$:

$$
\sigma_{\varepsilon}^2
= \sigma_T^2\Bigl(1 - \frac{\sigma_T^2}{\sigma_X^2}\Bigr).
$$

Dal momento che $\tfrac{\sigma_T^2}{\sigma_X^2} = \rho_{XX^\prime}$,

$$
\sigma_{\varepsilon}^2
= \sigma_T^2 \,\bigl(1 - \rho_{XX^\prime}\bigr).
$$

Prendendo la radice quadrata:

$$
\sigma_{\varepsilon}
= \sigma_T\,\sqrt{1 - \rho_{XX^\prime}}.
$$

**3.4 Da $\sigma_T$ a $\sigma_X$.**

Ricordiamo anche che $\sigma_T^2 = \rho_{XX^\prime}\,\sigma_X^2$. Quindi: 
$\sigma_T = \sqrt{\rho_{XX^\prime}}\;\,\sigma_X.$

Sostituendo in $\sigma_{\varepsilon} = \sigma_T \,\sqrt{1 - \rho_{XX^\prime}}$:

$$
\sigma_{\varepsilon}
= \bigl(\sqrt{\rho_{XX^\prime}}\,\sigma_X\bigr)\,\sqrt{1 - \rho_{XX^\prime}}
= \sigma_X \,\sqrt{\rho_{XX^\prime}\,\bigl(1 - \rho_{XX^\prime}\bigr)}.
$$

Ma $\sigma_{\varepsilon}$ è, per definizione, la deviazione standard di $T - \hat{T}$, ovvero **l’errore standard della stima**, $\sigma_{\hat{T}}$. Da qui la formula finale:

$$
\sigma_{\hat{T}}
= \sigma_X\,\sqrt{\rho_{XX^\prime}\,\bigl(1 - \rho_{XX^\prime}\bigr)},
$$

che è esattamente l'@eq-std-err-estimate.

## Intervallo di Confidenza per il Punteggio Vero

Una volta noto l’errore standard della stima $\sigma_{\hat{T}}$, possiamo costruire un **intervallo di confidenza** (IC) per il punteggio vero. L’idea è simile alla statistica classica:

$$
\hat{T} \;\pm\; z \,\sigma_{\hat{T}},
$$

dove:

- $\hat{T}$ è la stima puntuale del punteggio vero (e.g., $\bar{X} + \rho_{XX^\prime}(X - \bar{X})$),
- $z$ è il quantile della distribuzione normale standard (per esempio, $z = 1{,}96$ per un IC al 95\%),
- $\sigma_{\hat{T}}$ è l’errore standard della stima.

Se il campione è **molto piccolo** (meno di 30 soggetti), si sostituisce $z$ con $t$ (la distribuzione $t$ di Student).

### Interpretazione  

- L’ampiezza dell’intervallo di confidenza dipende sia dal livello di confidenza scelto (tramite $z$ o $t$) sia dalla precisione della stima (tramite $\sigma_{\hat{T}}$).  
- Quando $\rho_{XX^\prime}$ è basso, il termine $\sqrt{\rho_{XX^\prime}(1 - \rho_{XX^\prime})}$ può crescere notevolmente, determinando un intervallo di confidenza più ampio.  
- Un **intervallo più esteso** riflette una maggiore incertezza nella stima del punteggio vero.  

In sintesi, **l’errore standard della stima** $\sigma_{\hat{T}}$ fornisce una misura diretta dell’incertezza associata alla stima di Kelley. Conoscendo $\sigma_{\hat{T}}$, è possibile costruire intervalli di confidenza e valutare con maggiore consapevolezza l'affidabilità dei punteggi veri stimati da un test.

::: {#exm-1}
@charter1996revisiting ha esaminato l'effetto della variazione dell'attendibilità del test sull'ampiezza dell'intervallo di confidenza per il punteggio vero. Utilizzando come esempio i punteggi di QI ($\mu$ = 100, $\sigma$ = 15), Charter ha immaginato di variare il coefficiente di attendibilità del test utilizzato per la misurazione del QI. I valori presi in considerazione sono 0.55, 0.65, 0.75, 0.85 e 0.95. Ad esempio, supponiamo di avere un punteggio osservato pari a QI = 120 e un coefficiente di attendibilità del test $\rho_{xx^\prime}$ pari a 0.65. In tali circostanze, la stima del punteggio vero è pari a

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X}) \notag\\
&= 100 + 0.65 (120 - 100)\notag\\
&= 113.\notag
\end{aligned}
\end{equation}
$$

L'errore standard della stima è uguale a

$$
\begin{equation}
\begin{aligned}
\sigma_{\hat{T}} &= \sigma_{X} \sqrt{r_{XX^\prime} (1 - r_{XX^\prime})} \notag\\
&= 15 \sqrt{0.65 (1 - 0.65)}\notag\\
&= 7.15.\notag
\end{aligned}
\end{equation}
$$

L'intervallo di confidenza al 95% per la stima del punteggio vero diventa pertanto uguale a 

$$
113 \pm 1.96 \cdot 7.15 = [98.98, 127.02].
$$ 

Si noti che si può calcolare l'errore standard della stima con la funzione `SE.Est()` del pacchetto `psychometric`.

```{r}
SE.Est(15, .65)
```

\
Inoltre, la funzione `CI.tscore()` restituisce sia la stima del punteggio vero sia l'intervallo di fiducia al livello desiderato di significatività. 

```{r}
CI.tscore(120, 100, 15, 0.65, level = 0.95)
```
:::


## Cut-off

Una delle applicazioni pratiche degli **intervalli di confidenza sul punteggio vero** è il confronto con un cut-off (o soglia). L’idea di base è semplice:  

- Se l’intero intervallo di confidenza si trova al di sopra (o al di sotto) del cut-off, allora si può affermare, con il grado di certezza desiderato$(1 - \alpha)$, che il **punteggio vero** del rispondente superi (o non raggiunga) la soglia.  
- Se invece il cut-off cade all’interno dell’intervallo di confidenza, non è possibile trarre una conclusione netta: i dati disponibili non permettono di stabilire con sufficiente certezza se il punteggio vero sia superiore o inferiore alla soglia.

::: {#exm-1}
Consideriamo i punteggi del QI, con media campionaria $\bar{X} = 100$ e deviazione standard $s_X = 15$. Supponiamo inoltre che l’attendibilità del test sia $\rho_{XX^\prime} = 0{,}95$. Se un individuo ottiene un QI osservato $X = 130$ e vogliamo sapere se il suo punteggio vero supera un cut-off di 120, possiamo costruire l’intervallo di confidenza al 95%.

Nel frammento di codice (in R) seguente si riportano i passaggi per calcolare la stima del punteggio vero $\hat{T}$ e il relativo errore standard $\sigma_{\hat{T}}$, e per costruire l’intervallo di confidenza al 95%:

```{r}
xm <- 100 # media dei punteggi
sx <- 15 # dev. standard dei punteggi
rho <- 0.95 # affidabilità
x <- 130 # punteggio osservato

# Stima del punteggio vero
t.hat <- xm + rho * (x - xm)
t.hat

# Errore standard della stima
se.t <- sx * sqrt(rho * (1 - rho))
se.t

# Intervallo di confidenza al 95%
t.hat + c(-1, 1) * qnorm(0.975) * se.t
```

Se il limite inferiore di questo intervallo risulta superiore a 120, possiamo concludere con un livello di confidenza del 95% che il punteggio vero dell’individuo superi il cut-off. Di conseguenza, lo psicologo potrebbe raccomandare l’ammissione dell’individuo a un corso avanzato (nell’esempio, è quanto accade con $\rho_{XX^\prime} = 0{,}95$).

Continuando, supponiamo che l’attendibilità del test sia $0{,}80$, un valore empiricamente più frequente. In questo caso, la diminuzione di $\rho_{XX^\prime}$ aumenta l’errore standard della stima, allargando l’intervallo di confidenza. Di fatto, con $\rho_{XX^\prime} = 0{,}80$, l’intervallo 95% per il punteggio vero del medesimo QI osservato (130) potrebbe includere il cut-off di 120, rendendo impossibile concludere che il valore vero sia effettivamente al di sopra della soglia. In sintesi, **minore è l’affidabilità**, maggiore è l’ampiezza dell’intervallo di confidenza, e dunque **minore la certezza** di superare (o non superare) un dato cut-off.
:::

## Riflessioni Conclusive  

La CTT si basa su un modello additivo, in cui il punteggio osservato $X$ è la somma di due componenti:  

$$
X = T + E ,
$$

dove $T$ rappresenta il punteggio vero (concettualmente stabile) e $E$ l’errore di misura (variabilità casuale). Un presupposto fondamentale della CTT è che l’errore $E$ sia indipendente sia dal punteggio vero $T$ del test, sia dagli errori di misura di altri test. Inoltre, la teoria introduce due categorie di test con proprietà specifiche:  

- **test paralleli**, che condividono gli stessi punteggi veri e la stessa varianza d’errore;  
- **test $\tau$-equivalenti**, che differiscono solo per una costante additiva nei punteggi veri.  

Tuttavia, nella pratica, le ipotesi alla base di questi modelli possono essere facilmente violate, ad esempio in presenza di item eterogenei, campioni molto diversi, o quando il costrutto misurato non è stabilmente riproducibile in condizioni ripetute.  

### Natura teorica della CTT  

Un aspetto cruciale della CTT è che né $T$ né $E$ sono **direttamente osservabili**: i dati empirici a nostra disposizione si limitano ai punteggi$X$. Parlare di “punteggio vero” significa riferirsi a una media ipotetica ottenuta su infinite ripetizioni del test, ma ciò non implica necessariamente che il costrutto misurato corrisponda fedelmente alla realtà psicologica sottostante. Qualunque test, per quanto affidabile, è sempre soggetto a un certo margine di errore e può non catturare pienamente l’attributo di interesse.  

### Vantaggi della CTT  

- **Semplicità concettuale**: modello intuitivo e largamente diffuso.  
- **Calcoli accessibili**: le statistiche di base (affidabilità, difficoltà, discriminazione degli item) sono facilmente calcolabili.  

### Limiti della CTT 

- **Affidabilità dipendente dalla lunghezza del test**: maggiore affidabilità spesso richiede un numero elevato di item simili.  
- **Difficoltà nella misura di individui con punteggi estremi**: i test costruiti per la media tendono a essere meno accurati per soggetti con punteggi molto alti o molto bassi.  
- **Dipendenza dal campione**: la validità e l’affidabilità di un test sono specifiche per il campione su cui è stato calibrato.  
- **Sensibilità alle modifiche del test**: alterare gli item può influenzare la validità e l’affidabilità.  
- **Ipotesi di errore costante**: mentre nella realtà l’errore può variare lungo il continuum dei punteggi (ad esempio, essendo minore intorno alla media e maggiore agli estremi), la CTT assume un errore standard fisso.  

### Conclusioni  

L’esempio del cut-off dimostra come gli **intervalli di confidenza** possano supportare decisioni pratiche e come queste decisioni dipendano dall’**affidabilità** del test. Una singola stima puntuale ($\hat{T}$) può sembrare precisa, ma è fondamentale considerare la sua variabilità attraverso l’**errore standard della stima**.  

Più in generale, la CTT offre un quadro di riferimento utile e largamente adottato per la costruzione e l’interpretazione dei test psicometrici. Tuttavia, le sue ipotesi semplificatrici possono renderla meno adatta a contesti complessi o a test che necessitano di una maggiore personalizzazione. In tali casi, approcci più avanzati, come la **Teoria della Risposta all’Item** (IRT), forniscono strumenti più flessibili e accurati.  

In definitiva, la scelta tra CTT e modelli alternativi dipende dagli obiettivi del test, dal contesto applicativo e dalla disponibilità di risorse analitiche. Per chi si occupa di sviluppo e interpretazione di test, è essenziale comprendere i limiti e le potenzialità di ciascun approccio, adottando il metodo più adeguato alle esigenze della valutazione psicometrica.

## Session Info

```{r}
sessionInfo()
```


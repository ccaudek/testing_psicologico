# Il modello statistico dell'analisi fattoriale {#sec-fa-statistical-model-fa}

::: callout-important
## In questo capitolo imparerai a

- Comprendere il modello statistico monofattoriale.
- Eseguire l'analisi statistica per il modello monofattoriale con `lavaan`.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. 
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(lavaan, semPlot, tidyr, ggdag, dagitty)
```
:::

## Modello monofattoriale

L’analisi fattoriale esplorativa (AFE) parte da una matrice di
dimensioni $p \times p$ (dove $p$ è il numero di variabili
osservate) che contiene i coefficienti di correlazione (o, in alternativa,
di covarianza) fra tali variabili. L’obiettivo dell’AFE è ottenere una
matrice di dimensioni $p \times k$ (dove $k$ è il numero di fattori
comuni) i cui elementi – chiamati *saturazioni fattoriali* – descrivono
la relazione tra ciascun fattore comune e ogni variabile osservata.

Nel caso più semplice, quello *monofattoriale*, si ipotizza
l’esistenza di un unico fattore latente, $\xi$. In presenza di $p$
variabili manifeste $Y_i$, il modello matematico di un solo fattore
comune si può esprimere nel modo seguente:

$$
Y_i = \mu_i + \lambda_{i} \,\xi + \delta_i ,
\quad\text{per}\quad 
i=1, \dots, p,
$$ {#eq-fa-model-1f}

dove:

- $\xi$ è il fattore comune (o *fattore latente*), condiviso da tutte
  le variabili $Y_i$;
- $\delta_i$ è il *fattore specifico* (o *fattore unico*) associato
  alla $i$-esima variabile osservata, cioè una componente di varianza
  che non è condivisa con le altre variabili;
- $\lambda_i$ è la *saturazione fattoriale* (o *peso*) della
  $i$-esima variabile, ossia il coefficiente che quantifica il peso
  esercitato dal fattore comune $\xi$ su $Y_i$.

Per semplificare l’analisi, si assume spesso che $\mu_i = 0$,
considerando le $Y_i$ già centrate (cioè prive della loro media).
Questa convenzione rende possibile riscrivere il modello come:

$$
Y_i = \lambda_i \,\xi + \delta_i.
$$ {#eq-fa-model-1f-noint}

In aggiunta a questa ipotesi di centratura, si stabilisce che:

1. il fattore comune $\xi$ abbia media nulla,
   $\mathbb{E}(\xi) = 0$, e varianza unitaria,
   $\mathbb{V}(\xi) = 1$;
2. i fattori specifici $\delta_i$ abbiano media nulla,
   $\mathbb{E}(\delta_i)=0$, e varianza $\psi_i$,
   cioè $\mathbb{V}(\delta_i) = \psi_i$;
3. i fattori specifici siano tra loro incorrelati:
   $\mathbb{E}(\delta_i \,\delta_k) = 0$ per $i \neq k$;
4. i fattori specifici siano incorrelati con il fattore comune:
   $\mathbb{E}(\delta_i\,\xi) = 0$ per ogni $i$.

Date queste ipotesi, l’interdipendenza (cioè le correlazioni) fra le
variabili osservate $Y_i$ e $Y_k$ è interamente spiegata dal singolo
fattore comune $\xi$. I termini $\delta_i$ riguardano solo la
varianza *non condivisa* di ciascuna variabile.

Sulla base di queste assunzioni, è possibile:

- calcolare la *covarianza* tra $Y_i$ e il fattore comune $\xi$;
- determinare la *varianza* di ciascuna variabile $Y_i$;
- ottenere la *covarianza* tra due variabili manifeste $Y_i$ e
  $Y_k$.

Tali derivazioni consentono di comprendere a fondo come il fattore
latente $\xi$ contribuisca a spiegare le relazioni fra le variabili
osservate e quanta parte della varianza di ciascuna variabile sia invece
imputabile a fattori specifici (non condivisi). Questo concetto è alla
base di tutte le procedure di stima e di interpretazione nell’analisi
fattoriale esplorativa con un solo fattore.

## Covarianza tra un indicatore e il fattore comune

Nel modello monofattoriale, vogliamo determinare la covarianza teorica
tra una variabile manifesta $Y_i$ e il fattore comune $\xi$. La
definizione di covarianza è:

$$
\mathrm{Cov}(Y_i, \xi) 
= \mathbb{E}(Y_i \, \xi) 
  - \mathbb{E}(Y_i)\,\mathbb{E}(\xi).
$$

Poiché per semplicità assumiamo $\mathbb{E}(\xi) = 0$, la formula si
riduce a:

$$
\mathrm{Cov}(Y_i, \xi) 
= \mathbb{E}(Y_i \,\xi).
$$

Usando il modello monofattoriale $Y_i = \lambda_i \xi + \delta_i$, si
ottiene:

$$
\mathrm{Cov}(Y_i, \xi) 
= \mathbb{E}\bigl((\lambda_i \,\xi + \delta_i)\xi\bigr)
= \mathbb{E}(\lambda_i\,\xi^2 + \delta_i\,\xi).
$$

Il termine $\lambda_i$ è una costante (la *saturazione fattoriale*),
perciò si può portare fuori dall’aspettazione:

$$
= \lambda_i \,\mathbb{E}(\xi^2) + \mathbb{E}(\delta_i \,\xi).
$$

A questo punto, valgono due ipotesi fondamentali:

1. $\mathbb{E}(\xi^2) = \mathbb{V}(\xi) = 1$, cioè il fattore comune ha
   varianza unitaria.
2. $\mathrm{Cov}(\delta_i,\xi) = \mathbb{E}(\delta_i \,\xi) = 0$, poiché
   il fattore specifico $\delta_i$ è incorrelato con il fattore comune
   $\xi$.

Applicando queste ipotesi si ha:

$$
\mathrm{Cov}(Y_i, \xi) 
= \lambda_i \cdot 1 + 0 
= \lambda_i.
$$

**In sintesi**: in un modello a singolo fattore, la *saturazione*
$\lambda_i$ coincide con la covarianza tra la variabile manifesta
$Y_i$ e il fattore comune $\xi$. Inoltre, se ogni variabile $Y_i$
è stata *standardizzata*, ossia ha varianza pari a 1, allora
$\lambda_i = \mathrm{Corr}(Y_i,\xi)$. In tal caso, $\lambda_i$
esprime direttamente la *correlazione* tra la variabile $Y_i$ e il
fattore comune $\xi$.


## Espressione fattoriale della varianza

Sotto l’ipotesi che $\mathbb{E}(Y_i) = 0$, la varianza di $Y_i$ è:

$$
\mathbb{V}(Y_i) = \mathbb{E}(Y_i^2) - [\mathbb{E}(Y_i)]^2 
                = \mathbb{E}(Y_i^2).
$$

Usando di nuovo il modello monofattoriale $Y_i = \lambda_i \xi + \delta_i$:

$$
\mathbb{V}(Y_i) 
= \mathbb{E}\bigl((\lambda_i \,\xi + \delta_i)^2\bigr).
$$

Sviluppando il quadrato:

$$
= \mathbb{E}\bigl(\lambda_i^2 \,\xi^2 
                  + 2\,\lambda_i\,\xi\,\delta_i
                  + \delta_i^2\bigr).
$$

Distinguiamo i tre termini all’interno dell’aspettazione:

1. $\mathbb{E}(\lambda_i^2 \,\xi^2) = \lambda_i^2 \,\mathbb{E}(\xi^2)$
   poiché $\lambda_i^2$ è costante e
   $\mathbb{E}(\xi^2) = \mathbb{V}(\xi) = 1$. Pertanto questo termine
   diventa $\lambda_i^2$.
2. $\mathbb{E}(2\,\lambda_i\,\xi\,\delta_i) = 2\,\lambda_i\,\mathbb{E}(\xi\,\delta_i)$.
   Ma $\mathrm{Cov}(\xi, \delta_i) = 0$, dunque
   $\mathbb{E}(\xi\,\delta_i) = 0$. Di conseguenza questo termine è
   nullo.
3. $\mathbb{E}(\delta_i^2) = \mathbb{V}(\delta_i) = \psi_i$, dato che
   il fattore specifico $\delta_i$ ha varianza $\psi_i$.

Mettendo insieme questi risultati, otteniamo:

$$
\mathbb{V}(Y_i) 
= \lambda_i^2 + \psi_i.
$$

- $\lambda_i^2$ è detta *comunalità* della variabile $Y_i$ e indica
  la parte di varianza spiegata dal fattore comune $\xi$.
- $\psi_i$ rappresenta la parte di varianza non spiegata dal fattore
  comune, detta *unicità* di $Y_i$.

Nel caso in cui le $Y_i$ siano state *standardizzate* (quindi abbiano
$\mathbb{V}(Y_i) = 1$), si ottiene:

$$
1 = \lambda_i^2 + \psi_i,
$$

da cui

$$
\psi_i = 1 - \lambda_i^2.
$$

In questo scenario, la comunalità $\lambda_i^2$ indica esattamente la
percentuale di varianza di $Y_i$ spiegata dal fattore comune, mentre
$\psi_i$ indica la percentuale rimanente, legata a fattori specifici
o ad altri errori di misura.


**In sintesi**, la varianza di una variabile osservata $Y_i$ può
essere scomposta in:

- $\lambda_i^2$, la parte *comune* che la variabile condivide con
  tutte le altre (ossia la porzione di varianza attribuibile al fattore
  comune $\xi$, chiamata *comunalità*);
- $\psi_i$, la parte *specifica* o *residua*, non spiegata dal fattore
  comune (chiamata *unicità*).

Nei modelli fattoriali, l’obiettivo principale è proprio stimare
correttamente $\lambda_i$ e $\psi_i$ per capire in che misura un
fattore latente unico ($\xi$) spiega le relazioni tra le diverse
variabili manifeste $Y_1, Y_2, \dots, Y_p$.

::: {#exm-}
Riprendiamo l’analisi della matrice di correlazioni di Spearman. 

```{r}
Spearman <- matrix(c(
  1.0, .78, .70, .66,
  .78, 1.0, .64, .54,
  .70, .64, 1.0, .45,
  .66, .54, .45, 1.0
),
byrow = TRUE, ncol = 4
)
rownames(Spearman) <- c("C", "E", "M", "P")
colnames(Spearman) <- c("C", "E", "M", "P")
Spearman |>
  print()
```

Quando eseguiamo una *analisi fattoriale* con la funzione `factanal()`, nello
stesso output compare la quantità denominata `SS loadings`. 

```{r}
fm <- factanal(covmat = Spearman, factors = 1)
fm
```

Questa quantità indica quanta parte della *varianza totale* delle quattro
variabili manifeste è spiegata dal fattore comune.

Ricordiamo che, per *varianza totale* in statistica multivariata, si
intende la somma delle varianze delle variabili osservate (cioè la
*traccia* della matrice di covarianza). Se le variabili sono
standardizzate, ciascuna contribuisce con 1 alla varianza complessiva,
quindi, con quattro variabili, la varianza totale risulta 4.

La *quota* della varianza totale spiegata dal modello fattoriale a un
fattore è data dalla somma delle comunalità di ogni variabile, ossia
dalle saturazioni fattoriali (loadings) *al quadrato*, sommate tra loro.
Nell’esempio, il valore ottenuto è 2.587; perciò la proporzione di
varianza spiegata è

$$
\frac{2.587}{4} \approx 0.647,
$$

che `factanal()` riporta come `Proportion Var`. 

La parte di varianza di ciascuna variabile *non* spiegata dal fattore
comune prende il nome di *unicità* (in inglese *uniqueness*). Nel
risultato di `factanal()`, l’unicità di ogni variabile si ottiene con
`fm$uniqueness`. La *comunalità* (ovvero la quota di varianza spiegata
dal fattore comune) si ricava da `1 - fm$uniqueness`, oppure calcolando
direttamente il quadrato di ogni saturazione fattoriale. 

```{r}
L <- c(fm$load[1], fm$load[2], fm$load[3], fm$load[4])
print(L)
```

Eseguendo il prodotto interno `t(L) %*% L`, infatti, si ottiene la somma dei quadrati delle saturazioni (le cosiddette *squared loadings*), che fornisce la
comunalità totale spiegata dal fattore per l’insieme delle variabili.

```{r}
t(L) %*% L 
```
:::

## Covarianza tra due variabili manifeste

Consideriamo due variabili manifeste $Y_i$ e $Y_k$ con media nulla,
ossia $\mathbb{E}(Y_i) = \mathbb{E}(Y_k) = 0$. In questa ipotesi, la
loro covarianza è data da:

$$
\mathrm{Cov}(Y_i, Y_k) 
= \mathbb{E}(Y_i \, Y_k) 
  - \mathbb{E}(Y_i)\,\mathbb{E}(Y_k) 
= \mathbb{E}(Y_i \, Y_k).
$$

Nel *modello monofattoriale*, ogni variabile si esprime come
$Y_i = \lambda_i \,\xi + \delta_i$, dove $\xi$ è il fattore comune e
$\delta_i$ è il fattore specifico. Sostituendo queste espressioni
nella formula della covarianza, otteniamo:

$$
\mathrm{Cov}(Y_i, Y_k) 
= \mathbb{E}\bigl((\lambda_i \,\xi + \delta_i)
                  (\lambda_k \,\xi + \delta_k)\bigr).
$$

Espandendo il prodotto dentro l’aspettazione:

$$
= \mathbb{E}\bigl(\lambda_i\,\lambda_k \,\xi^2 
                + \lambda_i\,\xi\,\delta_k 
                + \lambda_k\,\delta_i\,\xi 
                + \delta_i\,\delta_k\bigr).
$$

A questo punto, si applicano le ipotesi del modello:

1. $\mathbb{E}(\xi^2) = \mathbb{V}(\xi) = 1$.
2. $\mathrm{Cov}(\xi, \delta_i) = 0$, dunque
   $\mathbb{E}(\xi \,\delta_i) = 0$.
3. $\mathrm{Cov}(\delta_i, \delta_k) = 0$, cioè
   $\mathbb{E}(\delta_i \,\delta_k) = 0$.

Applicandole ai termini sopra, abbiamo:

$$
\mathrm{Cov}(Y_i, Y_k)
= \lambda_i\,\lambda_k\,\underbrace{\mathbb{E}(\xi^2)}_{=1}
  + \lambda_i \,\underbrace{\mathbb{E}(\xi\,\delta_k)}_{=0}
  + \lambda_k \,\underbrace{\mathbb{E}(\delta_i\,\xi)}_{=0}
  + \underbrace{\mathbb{E}(\delta_i\,\delta_k)}_{=0}
= \lambda_i \,\lambda_k.
$$

**In sintesi**, in un modello a singolo fattore, la covarianza tra due
variabili manifeste $Y_i$ e $Y_k$ è interamente spiegata dal
fattore comune $\xi$ e risulta pari al prodotto delle rispettive
saturazioni fattoriali $\lambda_i$ e $\lambda_k$.

## Correlazioni osservate e correlazioni riprodotte dal modello

Nel modello monofattoriale, l’ipotesi di base è che il *fattore comune*
spieghi *tutta* la covarianza tra le variabili osservate. In altre
parole, ci aspettiamo che, una volta noto il valore del fattore comune
$\xi$, ogni variabile $Y_i$ sia incorrelata con le altre
$(Y_k)$. Formalmente, ciò si traduce nell’uguaglianza:

$$
\mathrm{Cov}(Y_i, Y_k \,\mid\, \xi) = 0
\quad\text{per}\quad 
i \neq k.
$$

Se questa condizione risulta soddisfatta, il modello monofattoriale
riproduce correttamente le *correlazioni* osservate fra le variabili.
Con il termine $\boldsymbol{\Sigma}$ si indica la *matrice di
correlazioni riprodotte* dal modello, che in forma matriciale si esprime
come:

$$
\boldsymbol{\Sigma} 
= \boldsymbol{\Lambda}\,\boldsymbol{\Lambda}^{\prime} 
  + \boldsymbol{\Psi},
$$

dove $\boldsymbol{\Lambda}$ è la matrice delle *saturazioni
fattoriali* (loadings) e $\boldsymbol{\Psi}$ è la matrice delle
*unicità* (cioè le varianze specifiche non spiegate dal fattore
comune). 

Il modello monofattoriale si considera *adeguato* se la differenza tra
la matrice di correlazioni empiricamente osservate e la matrice
$\boldsymbol{\Sigma}$ prodotta dal modello risulta trascurabile.
Quando tale differenza (chiamata spesso *misura di scostamento* o
*misfit*) è prossima allo zero, possiamo concludere che il fattore
comune riesce a spiegare in modo soddisfacente i rapporti di
correlazione tra le variabili del nostro insieme di dati.

::: {#exm-}
Per i dati di Spearman, le correlazioni riprodotte dal modello ad un fattore sono

```{r}
round(L %*% t(L) + diag(fm$uniq), 3)
```

La matrice delle differenze tra le correlazioni campionarie e quelle
riprodotte è

```{r}
round(Spearman - (L %*% t(L) + diag(fm$uniq)), 3) 
```

Lo scarto maggiore tra le correlazioni campionarie e quelle riprodotte è
uguale a 0.049. Si può dunque concludere che il modello monofattoriale
spiega in maniera ragionevole i dati di Spearman.
:::

## Bontà di adattamento del modello ai dati

Un aspetto fondamentale nell’analisi fattoriale è valutare se la
*matrice di correlazioni* (o *covarianze*) prevista dal modello
rispecchia adeguatamente i dati empirici. A tal scopo, si conduce un
test statistico che confronta la matrice di correlazioni/covarianze
*osservata* con quella *predetta* dal modello fattoriale.

### L’ipotesi nulla del test

L’ipotesi nulla ($H_0$) afferma che le differenze tra le correlazioni
osservate e quelle riprodotte dal modello siano dovute soltanto agli
errori di campionamento. In altre parole, il modello è considerato
“corretto” a livello di popolazione, ossia
$\boldsymbol{\Sigma}(\theta) = \boldsymbol{\Sigma}$, dove:

- $\boldsymbol{\Sigma}$ è la matrice di correlazioni (o covarianze)
  nella *popolazione*;
- $\boldsymbol{\Sigma}(\theta)$ è la matrice di correlazioni (o
  covarianze) riprodotta dal modello in base ai parametri $\theta$.

### La statistica $\chi^2$

La statistica usata per il test, indicata come $v$ (o più
comunemente $\chi^2$), è funzione della differenza tra
$\boldsymbol{S}$ (la matrice osservata) e
$\boldsymbol{S}(\theta)$ (la matrice riprodotta dal modello):

$$
v = f\bigl[\boldsymbol{S}(\theta) - \boldsymbol{S}\bigr].
$$ {#eq-chisq-gof}

Quando l’ipotesi nulla è vera (cioè la *discrepanza* tra le due matrici
è solo casuale), $v$ si distribuisce approssimativamente come una
$\chi^2$ con $\nu$ gradi di libertà, dove

$$
\nu = \frac{p(p+1)}{2} \;-\; q.
$$ {#eq-chisq-gof-nu}

- $p$ è il numero di variabili manifeste;
- $q$ è il numero di parametri stimati dal modello (ad esempio,
  $\lambda$ e $\psi$ nel modello monofattoriale).

Il valore di $v$ è *tanto maggiore quanto più le correlazioni/covarianze
previste dal modello differiscono da quelle effettivamente osservate*.
Se $v=0$, i parametri del modello ricostruiscono *esattamente* la
matrice di correlazioni della popolazione.

### Interpretazione del test

Il test $\chi^2$ di adattamento del modello fattoriale segue la logica
inversa rispetto ai test più comuni (dove un risultato significativo
indica evidenza per l’ipotesi alternativa):

- se il test *non* è significativo (es., $p\geq 0{,}05$), non si può
  escludere che la discrepanza tra matrice osservata e matrice stimata
  sia dovuta al caso: in tal caso, il modello è considerato adeguato;
- al contrario, un risultato *significativo* (es., $p < 0{,}05$)
  indica che la differenza non si spiega solo con l’errore di
  campionamento e che il modello presenta *carenze di adattamento* ai
  dati.

### Assunzioni e limiti

1. **Normalità multivariata**: il test $\chi^2$ richiede che le
   variabili siano distribuite (almeno approssimativamente) come un
   campione casuale tratto da una distribuzione normale multivariata.
   Nella pratica, non sempre questa condizione è soddisfatta.
2. **Dimensioni campionarie**: la statistica $\chi^2$ è *sensibile* al
   numero di osservazioni. Con campioni di grandi dimensioni, anche
   piccole discrepanze tra il modello e i dati tendono a produrre
   risultati statisticamente significativi, suggerendo un *falso* cattivo
   adattamento.

Per questi motivi, la bontà di adattamento del modello non si giudica
solo in base alla significatività del test $\chi^2$. Un criterio
alternativo è ad esempio valutare il **rapporto $\chi^2/\nu$**, dove
$\nu$ sono i gradi di libertà del test. Valori di
$\chi^2/\nu \leq 3$ (o talvolta $\leq 4$) sono spesso considerati
indicativi di un adattamento accettabile. Inoltre, in letteratura
esistono molti altri indici (*fit indices*) che completano la valutazione
della bontà di adattamento del modello fattoriale.

## L’errore standard della misurazione nel modello fattoriale

In questa sezione, mostriamo come il *concetto di errore standard di misurazione*, tipico della CTT, possa essere reinterpretato tramite il *modello fattoriale*.

### Collegamento tra CTT e analisi fattoriale

Secondo la CTT, il punteggio osservato $X$ di un test si scompone in
due parti:

$$
X = T + E,
$$

dove:

- $T$ è il *valore vero* del soggetto,
- $E$ è l’*errore di misurazione*, considerato una variabile casuale
  con media zero, indipendente da $T$.

Se consideriamo un modello fattoriale *monofattoriale* con $p$ item
(variabili osservate), la relazione che descrive ciascun item $j$ per
il soggetto $i$ è:

$$
Y_{ji} = \lambda_j \,\xi_i + \delta_{ji},
$$

dove:

- $Y_{ji}$ è il punteggio osservato nell’item $j$,
- $\xi_i$ è il fattore comune (latente) per il soggetto $i$,
- $\lambda_j$ è il *carico fattoriale* dell’item $j$ sul fattore
  $\xi$,
- $\delta_{ji}$ è l’errore unico (o fattore specifico) relativo
  all’item $j$.

Il **punteggio totale** $X_i$ del soggetto $i$ si ottiene sommando i
punteggi dei singoli item:

$$
X_i 
= \sum_{j=1}^p Y_{ji}
= \sum_{j=1}^p (\lambda_j \,\xi_i + \delta_{ji})
= \biggl(\sum_{j=1}^p \lambda_j\biggr)\,\xi_i 
  + \sum_{j=1}^p \delta_{ji}.
$$

Notiamo che questa formula rispecchia la struttura della CTT [@mcdonald2013test]:

$$
X_i = T_i + E_i,
$$

dove il *valore vero* $T_i$ è
$\bigl(\sum_{j=1}^p \lambda_j\bigr)\,\xi_i$ (la parte del punteggio
dovuta al fattore comune) e l’*errore* $E_i$ è
$\sum_{j=1}^p \delta_{ji}$ (la somma degli errori unici).

### Decomposizione della varianza

Nella CTT, la varianza del punteggio osservato $\sigma^2_{X_i}$ si
scompone nella varianza del valore vero ($\sigma^2_{T_i}$) e nella
varianza dell’errore ($\sigma^2_{E_i}$):

$$
\sigma^2_{X_i} 
= \sigma^2_{T_i} + \sigma^2_{E_i}.
$$

All’interno del modello fattoriale, la *varianza del valore vero*
($\sigma^2_{T_i}$) corrisponde alla varianza del termine
$\bigl(\sum_{j=1}^p \lambda_j\bigr)\,\xi_i$. Poiché $\xi_i$ ha
varianza unitaria ($\mathbb{V}(\xi_i)=1$), si ha:

$$
\sigma^2_{T_i}
= \mathbb{V}\Biggl[\biggl(\sum_{j=1}^p \lambda_j\biggr)\,\xi_i\Biggr]
= \biggl(\sum_{j=1}^p \lambda_j\biggr)^2 \,\mathbb{V}(\xi_i)
= \biggl(\sum_{j=1}^p \lambda_j\biggr)^2.
$$

La *varianza dell’errore* ($\sigma^2_{E_i}$), invece, è la varianza
della somma degli errori unici $\sum_{j=1}^p \delta_{ji}$. Nel
modello fattoriale, si assume che gli errori $\delta_{ji}$ siano
incorrelati tra loro, per cui:

$$
\sigma^2_{E_i}
= \mathbb{V}\Biggl(\sum_{j=1}^p \delta_{ji}\Biggr)
= \sum_{j=1}^p \mathbb{V}(\delta_{ji})
= \sum_{j=1}^p \Psi_j,
$$

dove $\Psi_j$ è la varianza (unicità) associata all’errore dell’item
$j$. 

### Errore standard di misurazione

Nella CTT, *l’errore standard di misurazione* di un test quantifica, in
media, quanto il punteggio osservato può differire dal valore vero
$T_i$. Nel modello fattoriale, **l’errore standard di misurazione del
punteggio totale** è la radice quadrata della somma delle varianze degli
errori unici:

$$
\sigma_E 
= \sqrt{\sigma^2_{E_i}}
= \sqrt{\sum_{j=1}^p \Psi_j}.
$$

Questo fornisce una visione fattoriale dell’errore di misurazione: la
precisione di un test (intesa come minore ampiezza dell’errore) aumenta
al diminuire della somma delle unicità dei singoli item.

**In sintesi**, il modello fattoriale arricchisce il tradizionale concetto di errore standard di misurazione della CTT, mostrando che l’errore
(*specifico* o *unico*) di ciascun item influisce cumulativamente sulla
precisione del punteggio totale. In altre parole, **gli item che
presentano carichi fattoriali elevati** contribuiscono a ridurre
l’errore complessivo di misurazione, mentre **le loro corrispettive
unicità** (varianze specifiche non spiegate dal fattore comune)
aumentano l’incertezza del punteggio totale. Questo legame tra CTT e
analisi fattoriale offre *un’ottica ulteriore* per comprendere e
quantificare la precisione dei test psicometrici.


## Un esempio concreto

Vediamo ora come applicare i concetti del modello monofattoriale e
dell’errore standard di misurazione a un caso reale. Utilizzeremo i dati
raccolti per la validazione italiana del *Cognitive Style Questionnaire
– Short Form* (CSQ-SF, Meins et al. 2012). Questo questionario, volto a
misurare la vulnerabilità all’ansia e alla depressione, comprende cinque
sottoscale: *Internality* (`I`), *Globality* (`G`), *Stability* (`S`),
*Negative consequences* (`N`) e *Self-worth* (`W`). Sebbene la
sottoscala di *Internality* risulti problematica, la includiamo
nell’analisi per illustrare la procedura completa.


### Lettura e ispezione preliminare dei dati

In $\textsf{R}$, carichiamo il dataset e ne verifichiamo la dimensione
($n$, numero di partecipanti). Per una prima esplorazione, calcoliamo
le statistiche descrittive (`psych::describe(...)`) e visualizziamo la
matrice di correlazione con `psych::pairs.panels(...)`.

```{r}
csq <- rio::import(here::here("data", "csq540.csv"))
n <- nrow(csq)                 # Numero di partecipanti
psych::describe(csq, type = 2) # Statistiche descrittive
```

```{r}
#| fig-asp: 1
psych::pairs.panels(csq)       # Matrice di correlazione
```


Ne emerge che la sottoscala *Internality* (`I`) presenta alcune criticità
— aspetto già segnalato in letteratura.

### Specifica e stima di un modello unifattoriale

Per analizzare i dati secondo un modello fattoriale a un solo fattore,
usiamo la sintassi del pacchetto `lavaan`:

```{r}
mod_csq <- "
  F =~ NA*I + G + S + N + W
  F ~~ 1*F
"
fit <- lavaan:::cfa(mod_csq, data = csq)
```

- Nella prima riga, `F =~ NA*I + G + S + N + W` indichiamo che il fattore
  `F` è definito dai cinque item/sottoscale (`I, G, S, N, W`), con
  parametro `NA` per lasciare libera la stima della prima saturazione.
- Nella seconda riga, `F ~~ 1*F` impone varianza unitaria per il fattore
  `F`.

Otteniamo il resoconto completo con:

```{r}
summary(fit, standardized = TRUE, fit.measures = TRUE)
```

e le stime dei parametri con:

```{r}
parameterEstimates(fit)
```

In particolare, ci soffermiamo sulle *unicità* (varianze specifiche di
ciascuna sottoscala), accessibili da:

```{r}
psi <- parameterEstimates(fit)$est[7:11]
psi
```


### Stima dell’errore standard di misurazione tramite il modello fattoriale

Nel modello fattoriale monofattoriale, *l’errore standard di
misurazione* di un punteggio totale è la radice quadrata della somma
delle varianze specifiche (unicità). Con le stime ottenute da lavaan,
basta sommare i valori $\psi_j$ e prenderne la radice quadrata:

```{r}
sqrt(sum(psi))
```

Questo valore rappresenta l’errore standard complessivo del *punteggio
totale* calcolato sui cinque item (sottoscale).


### Confronto con la formula della CTT

Ricordiamo la *formula classica* per l’errore standard di misurazione
nella **Classical Test Theory (CTT)**:

$$
\sigma_E = \sigma_X \sqrt{1 - \rho_{XX'}},
$$

dove $\sigma_X$ è la *deviazione standard del punteggio totale* e
$\rho_{XX'}$ è l’*attendibilità* (affidabilità) del test.

1. Calcoliamo il **punteggio totale** come somma delle sottoscale:

   ```{r}
   tot_score <- rowSums(csq)
   ```

2. Otteniamo la **deviazione standard** di `tot_score`:

   ```{r}
   sigma <- sd(tot_score)
   sigma
   ```

3. Stimiamo l’**attendibilità** $\rho_{XX'}$ (qui indicata da
   $\Omega$) con la funzione `semTools::reliability()` applicata
   all’oggetto `fit` prodotto da `lavaan`:

   ```{r}
   rel <- semTools::reliability(fit)
   rel
   ```

   Il valore di $\Omega$ è tipicamente riportato nella seconda riga di
   `rel`.

4. Applichiamo la formula:

   ```{r}
   sigma * sqrt(1 - rel[2])
   ```

Il valore ottenuto risulta molto simile all’errore standard di
misurazione calcolato con la formula di derivazione fattoriale
$\sqrt{\sum_{j=1}^p \Psi_j}$, a conferma della coerenza tra il
modello fattoriale e la CTT.


### Correlazioni riprodotte dal modello

Per ispezionare *come* il modello unifattoriale “ricostruisce” le
correlazioni tra le variabili, possiamo estrarre:

- La **matrice di correlazione riprodotta**:

  ```{r}
  cor_mat <- lavInspect(fit, "cor.ov")
  cor_mat
  ```

- Le **saturazioni fattoriali standardizzate** (loadings):

  ```{r}
  l <- inspect(fit, what="std")$lambda
  l
  ```

Nel modello monofattoriale, la **correlazione predetta** tra due
variabili manifeste (ad esempio `I` e `G`) è data dal *prodotto* delle
loro saturazioni. Se `l[1]` è la saturazione di `I` e `l[2]` quella di
`G`, allora:

```{r}
l[1] * l[2]
```

restituisce la correlazione stimata per queste due sottoscale. Per
visualizzare la *matrice completa* delle correlazioni riprodotte dal
modello, calcoliamo:

```{r}
l %*% t(l) |> round(3)
```


### Varianza riprodotta di una variabile

Prendiamo a esempio la variabile $`W`$ e confrontiamo:

- La **varianza osservata**:  

  ```{r}
  var(csq$W)
  ```
  
- La **varianza riprodotta** dal modello: somma della varianza spiegata
  dal fattore e della varianza residua. Poiché il caricamento fattoriale
  standardizzato per `W` (ad esempio `-11.598` nel caso di non
  standardizzazione, o un valore $\lambda_W$ in quello standardizzato)
  misura l’effetto di `F` su `W`, la parte spiegata è $\lambda_W^2$.
  Sommando poi la specificità (residuo), ricostruiamo la varianza
  totale. Se prendiamo la proporzione di varianza residua rispetto a
  quella osservata:

  ```{r}
  1 - (l^2 / var(csq$W))
  ```

  otteniamo un valore simile all’unicità stimata per `W`.

Procedendo nello stesso modo per le altre sottoscale (`G`, `I`, ecc.)
possiamo verificare la corrispondenza fra la varianza empirica e la
varianza spiegata dal modello unifattoriale.

**In sintesi**, questo esempio illustra come, in un modello unifattoriale, sia possibile
collegare:

1. **errori standard di misurazione** (CTT) e **somme di unicità** degli
   item (analisi fattoriale);
2. **correlazioni osservate** e **correlazioni riprodotte** dal modello
   mediante il prodotto dei carichi fattoriali;
3. **varianza osservata** e **varianza ricostruita** come somma di
   varianza comune (fattore) e varianza residua (unicità).

La coerenza dei risultati fra CTT e analisi fattoriale ribadisce la loro
stretta complementarità nello studio dell’affidabilità e della struttura
latente di un test psicometrico.


## Correlazione tra variabili manifeste e fattore comune

Nel *modello unifattoriale*, la *saturazione fattoriale* $\lambda_i$
della variabile manifesta $Y_i$ corrisponde teoricamente alla
*correlazione* tra $Y_i$ e il *fattore comune* $\xi$. Tuttavia,
perché ciò risulti evidente in un’applicazione reale, è necessario poter
disporre di una *stima* dei punteggi fattoriali per ciascun
partecipante, cioè i valori (stimati) del fattore comune $\xi_i$. In
$\textsf{R}$, con `lavaan` possiamo ricavare i **punteggi fattoriali**
usando la funzione `lavPredict(fit)`.

```{r}
head(lavPredict(fit)) |> print()
dim(lavPredict(fit))
```

- `head(lavPredict(fit))` mostra le prime righe dei punteggi fattoriali
  stimati per i soggetti.
- `dim(lavPredict(fit))` conferma che abbiamo un punteggio per ognuno
  dei 540 soggetti nel dataset.

Per verificare in concreto la relazione tra $\lambda_i$ e la
correlazione di $Y_i$ con il fattore comune, calcoliamo la
*correlazione* tra i valori osservati su ciascuna sottoscala del CSQ e
le stime dei punteggi fattoriali (ossia $\hat{\xi}$):

```{r}
c(
  cor(csq$I, lavPredict(fit)),
  cor(csq$G, lavPredict(fit)),
  cor(csq$S, lavPredict(fit)),
  cor(csq$N, lavPredict(fit)),
  cor(csq$W, lavPredict(fit))
) |> 
  round(3)
```

I risultati ottenuti sono molto *simili* (ma non necessariamente
identici) alle saturazioni fattoriali riportate in:

```{r}
inspect(fit, what="std")$lambda
```

La piccola differenza riscontrata è dovuta al fatto che i punteggi
fattoriali $\hat{\xi}_i$ sono *stime* e non i valori reali del fattore
latente, quindi non coincidono esattamente con $\xi_i$. Ciò nonostante,
se il modello è ben specificato e i dati si adattano in modo
soddisfacente, le correlazioni tra punteggi osservati e fattore stimato
risulteranno prossime alle saturazioni fattoriali teoriche.

## Session Info

```{r}
sessionInfo()
```


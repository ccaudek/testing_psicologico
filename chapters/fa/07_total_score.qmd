# Punteggio totale e modello fattoriale {#sec-fa-total-score}

::: callout-important
## In questo capitolo imparerai a

- comprendere le condizioni che giustificano l'uso del punteggio totale del test.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo 6, *Factor Analysis and Principal Component Analysis*, del testo *Principles of psychological assessment* di @petersen2024principles. 
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(lavaan, modelsummary)
```
:::


## Introduzione

In questo capitolo affrontiamo una questione centrale nella costruzione e interpretazione dei test psicometrici: **è corretto utilizzare il punteggio totale come misura del costrutto latente che il test intende rilevare?**

L’uso del punteggio totale (cioè la semplice somma dei punteggi degli item) è una pratica diffusissima nella ricerca psicologica e nelle applicazioni cliniche. Tuttavia, tale uso è **giustificabile solo in circostanze ben precise**. Come mostrano @mcneish2020thinking, è necessario verificare che i dati raccolti rispettino determinate assunzioni. In caso contrario, il punteggio totale può essere **una misura fuorviante del costrutto**.

Per comprendere quando il punteggio totale può essere considerato una misura adeguata del costrutto latente, dobbiamo considerare il legame tra il punteggio totale e i modelli di misura fattoriali, in particolare il modello parallelo e il modello congenerico.

## Punteggio totale e modello fattoriale parallelo

### Il modello parallelo

Secondo @mcneish2020thinking, il punteggio totale può essere considerato una misura valida del costrutto solo se gli item soddisfano i requisiti del **modello fattoriale parallelo**. Questo modello implica:

- **saturazioni fattoriali uguali per tutti gli item** (ad esempio, tutte uguali a 1);
- **varianze residue uguali tra gli item**.

In termini psicometrici, questo significa assumere che **ogni item contribuisce nella stessa misura alla valutazione del costrutto**, e che ha lo stesso livello di "rumore" o errore.

### Esempio: Dati di Holzinger e Swineford (1939)

@mcneish2020thinking illustrano il problema usando i dati classici di Holzinger e Swineford. Gli item considerati sono:

- Paragraph comprehension  
- Sentence completion  
- Word definitions  
- Speeded addition  
- Speeded dot counting  
- Discrimination between curved and straight letters

Importiamo i dati in R:

```{r}
d <- rio::import(here::here("data", "1_Factor_Parallel.csv"))
```

Supponiamo ora di voler stimare il costrutto sottostante utilizzando il punteggio totale:

$$
\text{Punteggio totale} = \text{Item 1 + Item 2 + Item 3 + Item 4 + Item 5 + Item 6}
$$

Questo equivale ad assumere che **ogni item fornisca esattamente la stessa quantità di informazione** sul costrutto. Formalmente, ciò può essere espresso da un modello parallelo nel quale tutte le saturazioni fattoriali sono fissate a 1 e tutte le varianze residue sono uguali.

```{r}
m_parallel <- "
  f1 =~ 1*X4 + 1*X5 + 1*X6 + 1*X7 + 1*X8 + 1*X9
  X4 ~~ theta*X4
  X5 ~~ theta*X5
  X6 ~~ theta*X6
  X7 ~~ theta*X7
  X8 ~~ theta*X8
  X9 ~~ theta*X9
"
```

```{r}
fit_parallel <- sem(m_parallel, data = d)
```


### Confronto tra punteggio totale e punteggio fattoriale

Calcoliamo ora il punteggio totale e i punteggi fattoriali stimati dal modello:

```{r}
d$ts <- with(d, X4 + X5 + X6 + X7 + X8 + X9)
d$scores <- as.numeric(lavPredict(fit_parallel, method="regression"))
```

Visualizziamo la relazione tra i due:

```{r}
ggplot(d, aes(x = ts, y = scores)) + geom_point()
```

Se il modello parallelo fosse corretto, il punteggio totale e il punteggio fattoriale dovrebbero essere **perfettamente correlati**. Tuttavia, l’output di `lavaan` mostra che il modello parallelo **non si adatta bene ai dati**:

```{r}
summary(fit_parallel, fit.measures = TRUE, standardized = TRUE)
```

In questo caso, **l’uso del punteggio totale non è giustificato**: gli item non contribuiscono in modo uniforme alla misura del costrutto, e le ipotesi del modello parallelo non sono rispettate.

## Punteggio totale e modello congenerico

### Il modello congenerico

Il modello congenerico è una generalizzazione del modello parallelo. Qui si **ammette che gli item possano avere saturazioni fattoriali differenti** e varianze residue differenti. In pratica, si riconosce che alcuni item sono più informativi di altri.

```{r}
m_congeneric <- "
  f1 =~ NA*X4 + X5 + X6 + X7 + X8 + X9
  f1 ~~ 1*f1
"
```

```{r}
fit_congeneric <- sem(m_congeneric, data = d)
```

Analizziamo le saturazioni fattoriali:

```{r}
parameterEstimates(fit_congeneric, standardized = TRUE) %>%
  dplyr::filter(op == "=~") %>%
  dplyr::select(
    "Latent Factor" = lhs,
    Indicator = rhs,
    B = est,
    SE = se,
    Z = z,
    "p-value" = pvalue,
    Beta = std.all
  ) %>%
  knitr::kable(
    digits = 3, booktabs = TRUE, format = "markdown",
    caption = "Factor Loadings"
  )
```

Come si osserva, le saturazioni sono eterogenee. Ciò significa che **il costrutto latente si riflette diversamente nei vari item**. In tali casi, il punteggio totale—che attribuisce lo stesso peso a ciascun item—**è una misura distorta del costrutto**.

### Confronto con i punteggi fattoriali del modello congenerico

Esaminiamo la relazione tra i punteggi fattoriali del modello congenerico e il punteggio totale del test.

```{r}
d$scores_cong <- as.numeric(lavPredict(fit_congeneric, method="regression"))

d |> 
  ggplot(aes(x = ts, y = scores_cong)) + 
  geom_point()

cor(d$ts, d$scores_cong)^2
```

Qui il coefficiente di determinazione è circa 0.77, il che implica che **due persone con lo stesso punteggio totale possono avere punteggi fattoriali molto diversi**, a seconda degli item approvati. Questo è un limite importante del punteggio totale, che non tiene conto del contributo specifico di ciascun item.

Se ignoriamo le assunzioni del modello e guardiamo solo a un indice globale come l'**omega**, possiamo essere tratti in inganno:

```{r}
psych::omega(d[, 1:6])
```

L’omega può risultare “accettabile” (`Omega Total  0.84`), ma ciò **non garantisce che il punteggio totale sia una misura valida del costrutto**.

## Necessità di un modello a due fattori

I dati suggeriscono invece la presenza di **due costrutti distinti**. Adattiamo quindi un **modello congenerico a due fattori**:

```{r}
m2f_cong <- "
  f1 =~ NA*X4 + X5 + X6
  f2 =~ NA*X7 + X8 + X9
  f1 ~~ 1*f1
  f2 ~~ 1*f2
  f1 ~~ f2
"
fit_2f_congeneric <- sem(m2f_cong, data = d)
summary(fit_2f_congeneric, fit.measures = TRUE, standardized = TRUE)
```

Il modello mostra un buon adattamento. In questo scenario, **il punteggio totale aggrega item che misurano costrutti diversi**, perdendo così validità come indicatore di un singolo costrutto.

## Conclusione

L’uso del punteggio totale come stima del costrutto latente è una semplificazione che **deve essere giustificata empiricamente**: 

- é giustificato **solo se il modello parallelo è supportato dai dati**;
- nel caso in cui gli item abbiano saturazioni diverse (modello congenerico), il punteggio totale **perde validità**;
- se esistono **più costrutti latenti**, l’uso del punteggio totale può **introdurre errori sistematici**.

**In sintesi:** prima di usare o interpretare un punteggio totale, è essenziale testare il modello fattoriale sottostante. I punteggi totali, per quanto comodi, possono essere ingannevoli [@mcneish2020thinking].


## Session Info

```{r}
#| vscode: {languageId: r}
sessionInfo()
```


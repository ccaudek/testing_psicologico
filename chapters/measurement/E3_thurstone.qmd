# ✏ Esercizi

```{r}
source("../../code/_common.R")
library("rio")
library("psych")
```

## Il Modello Thurstoniano

Il modello Thurstoniano fornisce un quadro statistico per analizzare e interpretare preferenze o ranking di oggetti (o stimoli) da parte di singoli individui. L’idea di base è che, dietro i ranking osservati, esista una scala latente continua, non direttamente misurabile, dove ogni individuo assegna un punteggio personale a ciascun oggetto. Tali punteggi individuali, sebbene soggettivi, possono essere descritti complessivamente su una dimensione unica, grazie a ipotesi specifiche sulle distribuzioni di questi punteggi.

Più in dettaglio, il modello ipotizza che:

- Le utilità (o punteggi) latenti siano distribuite normalmente.
Ogni oggetto possiede una distribuzione gaussiana dei propri punteggi latenti nella popolazione.
- Le distribuzioni differiscano nelle medie, ma abbiano la stessa varianza.
Nel Caso V di Thurstone, tutte le distribuzioni hanno una varianza comune, mentre le medie possono variare da un oggetto all’altro (alcuni oggetti sono mediamente più apprezzati di altri).

Sulla base di questi presupposti, si procede così:

- Si calcola, per ciascuna coppia di oggetti, la proporzione di individui che preferisce un oggetto all’altro.
- Tali proporzioni vengono convertite in z-score (percentili della distribuzione normale cumulativa) per stimare quanto un oggetto supera un altro in termini di deviazioni standard.
- Sommando o mediando opportunamente questi z-score, si ottiene una stima dell’utilità media (ovvero la media della distribuzione normale latente) di ogni oggetto.
Di solito, per identificare il modello, si fissa a zero la media di un oggetto (ad esempio, quello meno desiderato).

Questa procedura consente di trasformare i dati di ranking discreti in stime numeriche di utilità psicologica, evidenziando le differenze relative di importanza fra gli oggetti analizzati.


## Tutorial

Nel seguente esercizio vedremo come eseguire uno scaling thurstoniano su dati di preferenze (o scelte) e ottenere delle stime delle *utilità* psicologiche di una serie di oggetti o caratteristiche confrontate fra loro. In altre parole, date le classifiche (rank) osservate, vogliamo inferire quali possano essere le distribuzioni di “valore psicologico” che hanno generato tali preferenze. Per stimare le utilità non osservate a partire dalle preferenze osservate, si ipotizza che le utilità siano distribuite normalmente con la stessa varianza (ipotesi del “Caso V” di Thurstone).

### Studio delle preferenze per alcune caratteristiche lavorative

I dati di questo esempio provengono (in forma semplificata) da uno studio sulla motivazione al lavoro, condotto su $N=1100$ partecipanti. A ogni partecipante è stato chiesto di ordinare in base all’importanza nove possibili caratteristiche di un lavoro ideale (assegnando il rank 1 alla più importante e il rank 9 alla meno importante). Le nove caratteristiche, qui elencate con i nomi delle colonne corrispondenti, sono:

1.  **Ambiente di Sostegno (Support)**
2.  **Lavoro Stimolante (Challenge)**
3.  **Prospettive di Carriera (Career)**
4.  **Integrità Etica (Ethics)**
5.  **Autonomia e Impatto Personale (Autonomy)**
6.  **Opportunità di Crescita (Development)**
7.  **Interazione Sociale (Interaction)**
8.  **Competizione (Competition)**
9.  **Ambiente e Sicurezza (Safety)**


Di seguito, illustriamo passo dopo passo l’analisi con il pacchetto **psych** di R.

### Passo 1. Lettura e ispezione dei dati

Il file di dati (ad esempio, `JobFeatures.txt`) contiene le classifiche di 1100 partecipanti, ciascuno con i ranghi per le 9 caratteristiche. Per leggere il file in RStudio si può usare la funzione `read.delim()`:

```{r}
JobFeatures <- rio::import("../../data/JobFeatures.txt")
glimpse(JobFeatures)
```

Possiamo controllare i nomi delle variabili con:

```{r}
names(JobFeatures)
```

La funzione `head(JobFeatures)` mostra le prime righe del data frame:

```{r}
head(JobFeatures)
```

### Passo 2. Esecuzione dello scaling thurstoniano

Per poter eseguire l’analisi, caricando il pacchetto **psych**. La funzione che ci interessa è `thurstone()`. Se cerchiamo informazioni:

```r
help("thurstone")
```

scopriamo che la funzione ha la forma generale:

```r
thurstone(x, ranks = FALSE, digits = 2)
```

- **x**: il set di dati su cui eseguire lo scaling.
- **ranks**: se `TRUE`, i dati forniti sono ranghi raw; se `FALSE`, ci si aspetta una matrice di proporzioni di scelta (di default è `FALSE`).
- **digits**: numero di cifre decimali per l’indice di bontà di adattamento (default 2).

Dal momento che abbiamo dati grezzi di ranking, impostiamo `ranks = TRUE`. Il comando:

```{r}
thurstone(JobFeatures, ranks = TRUE)
```

restituirà in Console un output simile al seguente:

```
Thurstonian scale (case 5) scale values 
Call: thurstone(x = JobFeatures, ranks = TRUE)
[1] 0.97 0.93 0.91 0.92 0.60 1.04 0.63 0.00 0.23

Goodness of fit of model   1
```

- I valori dopo la riga `Call:` sono le **medie** stimate delle utilità psicologiche.  
- Sono ordinate nello stesso modo in cui le caratteristiche compaiono nel data frame.  
- Una di queste medie è fissata a 0 (tipicamente, la caratteristica meno preferita viene posta a 0 per identificare il modello).  


### Passo 3. Calcolo delle proporzioni di preferenza a coppie

Se assegniamo i risultati della funzione a un oggetto, ad esempio:

```{r}
scaling <- thurstone(JobFeatures, ranks = TRUE)
```

non vediamo nulla stampato in Console, ma l’analisi è stata eseguita. Ora `ls(scaling)` mostra i componenti:

```{r}
ls(scaling)
```

- `scaling$scale` contiene i valori medi di utilità, già visti.  
- `scaling$choice` contiene la **matrice delle proporzioni di scelta** (9×9). Ogni cella $(i, j)$ indica la proporzione di partecipanti che preferiscono la caratteristica j rispetto alla caratteristica i.  

```{r}
scaling$choice |> 
  round(2)
```

Se, per esempio, la cella $(8,6)$ vale 0.853, significa che l’**8ª caratteristica** è preferita alla **6ª** dall’85.3% del campione (o dei ranghi aggregati).

### Passo 4. Valutazione dell’adattamento del modello

Possiamo esaminare gli scarti (residui) confrontando le proporzioni osservate con quelle predette dal modello:

```{r}
scaling$residual |> 
  round(3)
```

- Residui vicini a zero indicano che il modello di Thurstone (utilità normali) riproduce bene i dati osservati.  

Infine, con:

```{r}
scaling$GF
```

otteniamo un indice di bontà di adattamento prossimo a 1, segno che il modello fornisce una buona descrizione dei dati (più il valore è vicino a 1, meglio il modello si adatta).

**In sintesi**  
- **Thurstonian scaling (Caso V)**: presuppone che le utilità latenti degli oggetti abbiano distribuzioni normali con varianza uguale.  
- **Procedura**:  
  1. Lettura dei ranking e ispezione dei dati.  
  2. Calcolo dello scaling con la funzione `thurstone()`.  
  3. Interpretazione delle *scale* (medie di utilità).  
  4. Analisi delle proporzioni di preferenza a coppie.  
  5. Verifica dei residui e dell’indice *Goodness of Fit* (GF).  
- **Conclusione interpretativa**:  
  - Un oggetto con media più alta risulta, in media, più desiderato.  
  - L’oggetto con media zero (fissata) è quello meno preferito o funge da riferimento.  
  - Residui bassi e un GF vicino a 1 indicano che il modello spiega bene i dati.


## Scaling Fechneriano

Un altro esempio di scaling psicologico riguarda lo scaling fechneriano. Faccio qui riferimento ad uno studio condotto un po' di tempo fa nell'ambito delle Vision Sciences. 

Nello studio di @domini2009intrinsic, abbiamo utilizzato il modello *Intrinsic Constraints* per correlare la **profondità visiva percepita** di un oggetto tridimensionale con i principi teorici dello **scaling sensoriale Fechneriano**. Quest’ultimo, basato sulle teorie psicofisiche di Fechner, prevede la costruzione di una scala psicofisica per attributi sensoriali mediante l’**integrazione cumulativa di incrementi psicometrici**, in particolare delle *Just Noticeable Differences* (JNDs). L’obiettivo della ricerca era progettare stimoli visivi caratterizzati da diversi indizi di profondità (stereopsi, parallasse di movimento, ecc.) in modo da indurre una **percezione soggettiva equivalente della profondità 3D**. Secondo questa logica, oggetti definiti da cue visivi distinti dovrebbero risultare percettivamente equiparabili in termini di profondità qualora fossero associati a un **numero identico di JNDs**. In altre parole, l’uniformità percettiva emerge quando gli stimoli, pur differendo negli indizi di profondità, raggiungono la stessa soglia di discriminabilità psicofisica.

## Riflessioni Conclusive

Lo **scaling thurstoniano (Caso V)** trasforma i ranking discreti in stime continue di utilità, consentendo di evidenziare differenze relative fra le caratteristiche analizzate e di quantificare la “distanza” tra gli oggetti su una scala latente comune. Quando il numero di oggetti è elevato, si procede al calcolo di tutte le proporzioni di preferenza pairwise, applicando la stessa logica, eventualmente integrata con metodi di stima più sofisticati.

Questa metodologia, introdotta da **Louis Leon Thurstone** negli anni Venti, è una delle prime forme di *scaling* psicologico. Con il termine *scaling* si indica il processo di collocare stimoli (o concetti) su un continuum, in base al grado in cui essi possiedono una certa proprietà psicologica. Nel *Caso V*, si assume che tutte le distribuzioni di punteggi latenti abbiano la stessa varianza, ipotesi che semplifica il modello ma può risultare limitante nella pratica, poiché la coerenza dei giudizi e la natura degli stimoli possono variare notevolmente.

Prima di Thurstone, **Gustav Theodor Fechner** (1801-1887) pose le basi della psicofisica proponendo l’idea che la relazione fra l’intensità fisica di uno stimolo e la sua percezione psicologica seguisse una legge logaritmica. Al centro del metodo di Fechner vi è il concetto di *JND* (Just Noticeable Difference, o “differenza appena percepibile”): la più piccola variazione dello stimolo che un individuo è in grado di distinguere da un riferimento. Accumulando queste *unità di percezione* – le JND – Fechner ipotizzò che si potesse costruire una scala psicologica che misurasse l’intensità soggettiva delle sensazioni in funzione dello stimolo fisico.

Dal punto di vista concettuale, lo scaling di Fechner precede e ispira quello di Thurstone in quanto entrambi i metodi assumono l’esistenza di **variabili latenti** alla base dei giudizi individuali. Nel caso di Fechner, l’obiettivo principale era correlare la misura fisica di uno stimolo (ad esempio, il peso o la luminosità) alla sensazione percepita dal soggetto, segmentando la scala fisica in unità psicologicamente equipollenti (le JND). Thurstone, invece, ha esteso questo paradigma al contesto dei giudizi di preferenza e classificazione, introducendo la nozione di distribuzioni normali per i punteggi latenti e di varianza costante tra gli oggetti.

### Limiti e prospettive

Una criticità rilevante nello scaling thurstoniano è la **mancanza di procedure consolidate per la falsificazione interna** del modello: a differenza, ad esempio, di quanto avviene nello *scaling di Mokken*, dove si può testare la monotonicità delle risposte. Se i dati violano l’assunzione di varianza costante o di un unico continuum psicologico condiviso, il modello di Thurstone non fornisce criteri immediati per identificare o risolvere tali problemi.

Nel panorama odierno, molti studiosi preferiscono approcci basati sulla **Teoria della Risposta all’Item (IRT)**, che offre una rappresentazione più flessibile: la probabilità di risposta a un item dipende sia dalle sue caratteristiche, sia dal livello latente dell’individuo. L’IRT permette di testare in modo più rigoroso le assunzioni del modello (p. es. la monotonicità e l’indipendenza locale) e di stimare con maggiore precisione sia le proprietà degli item, sia i parametri delle persone.

**In conclusione**, lo scaling thurstoniano è stato un passo fondamentale nello sviluppo degli strumenti di misurazione in psicologia, ereditando la tensione di Fechner nel voler “misurare l’immisurabile”. Nonostante la sua eleganza e semplicità introduttiva, diverse questioni tecniche (come l’ipotesi di varianza costante) e l’assenza di metodi di falsificazione robusti hanno portato, nel tempo, allo sviluppo di approcci più potenti e flessibili, tra cui la **Teoria della Risposta all’Item**. Rimane comunque un importante riferimento storico e didattico per comprendere la logica dello scaling psicologico e il percorso che ha condotto agli strumenti sofisticati oggi disponibili.

## Sesssion Info

```{r}
sessionInfo()
```


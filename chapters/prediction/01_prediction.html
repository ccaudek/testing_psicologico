<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Corrado Caudek">

<title>80&nbsp; Predizione – Testing Psicologico</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/networks/01_networks.html" rel="next">
<link href="../../chapters/lgm/11_lgm_wais.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-6d55ea969593a3483f4613a548523a33.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-24dbbe1c26930d58e213c8ea2157398f.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-62e4b2809dfb41b5160f340e7c383cce.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d5b1b7f210f9f8712579e048ed54cd39.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/prediction/01_prediction.html">Predizione</a></li><li class="breadcrumb-item"><a href="../../chapters/prediction/01_prediction.html"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Predizione</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Testing Psicologico</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/testing_psicologico/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalità oscura"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Programmazione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../cal_testing_psic_2025.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Calendario delle lezioni</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Punteggi e scale</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/measurement/01_scores_scales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Punteggi e scale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/measurement/E1_likert.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/measurement/E2_optimal_scoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/measurement/E3_thurstone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/measurement/02_development.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Sviluppo dello strumento</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/measurement/03_equating.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Equating nei Test Psicologici</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">CTT</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ctt/01_ctt_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Fondamenti teorici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ctt/02_ctt_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">L’affidabilità del test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ctt/03_ctt_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Metodi di stima dell’affidabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ctt/04_err_std_mis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">L’errore standard della misurazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ctt/05_err_std_stima.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La stima del punteggio vero</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ctt/06_ctt_applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Applicazioni della CTT</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Giudici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/raters/01_multilevel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Modelli multilivello</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/raters/02_interrater_reliability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">L’affidabilità tra giudici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/raters/E1_irr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Validità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/validity/01_validity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">La validità del test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/validity/02_other_variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Relazioni test-criterio</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Generalizzabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/gtheory/01_gtheory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Teoria della generalizzabilità</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Items</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/items/01_item_development.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Lo sviluppo degli item</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/items/02_item_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Analisi degli item</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Analisi dei percorsi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/path_analysis/01_path_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Analisi dei percorsi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/path_analysis/02_clement_2022.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Riparazione affettiva post-infedeltà</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">FA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/01_intro_fa.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Introduzione all’analisi fattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/02_analisi_fattoriale_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Il modello unifattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/03_analisi_fattoriale_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Il modello statistico dell’analisi fattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/04_analisi_fattoriale_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Il modello multifattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/05_factor_scores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">I punteggi fattoriali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/06_constraints_on_parms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Attendibilità e modello fattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/fa/07_total_score.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Punteggio totale e modello fattoriale</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Costruzione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/extraction/01_val_matrici.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Valutazione della matrice di correlazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/extraction/02_estrazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">L’estrazione dei fattori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/extraction/03_numero_fattori.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Il numero dei fattori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/extraction/04_rotazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">La rotazione fattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/extraction/05_val_soluzione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Valutare e rifinire la soluzione fattoriale</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">CFA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/01_cfa.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Analisti Fattoriale Confermativa</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/02_meanstructure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">La struttura delle medie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/03_cat_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Dati non gaussiani e categoriali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/04_mmm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">CFA per matrici multi-tratto multi-metodo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/05_bifactor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Modello bifattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/06_efa_lavaan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Exploratory Structural Equation Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/07_fa_in_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Strategia Integrata per un’Analisi Fattoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/E_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cfa/E_02_bifactor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">SEM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/01_sem_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Introduzione ai Modelli SEM</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/02_data_preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Preparazione dei Dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/03_gof.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Test del Modello e Indicizzazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/04_mod_comp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Confronto tra modelli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/05_cfa_mod_comp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">CFA: confronto tra modelli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/06_refine_solution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">La revisione del modello</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/07_group_invariance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Invarianza di misura</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/08_multilevel_sem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Modelli di Equazioni Strutturali Multilivello</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/09_structural_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modelli di Regressione Strutturale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/10_missing_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/11_small_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Modellizzazione SEM in Piccoli Campioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/12_temp_reliability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Affidabilità longitudinale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/13_esem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Exploratory structural equation modelling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/14_sem_power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Dimensione Campionaria e Analisi della Potenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/E_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/sem/15_prior_pred_mod_check.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Prior Predictive Model Checking</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Mokken</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mokken/01_core_issues.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Analisi della Scala di Mokken</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mokken/02_applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Applicazione Pratica</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">IRT</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/01_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Modello di Regressione Logistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/E_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">✏️ Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/02_rasch_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Modello di Rasch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/03_assumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Assunzioni e Proprietà del Modello di Rasch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/04_estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Stima</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/05_1pl_2pl_3pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Modelli 1PL, 2PL e 3PL</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/irt/06_implementation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Implementazione</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">LGM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/01_lgm_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Curve di crescita latente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/02_lgm_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Considerazioni Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/06_lgm_mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">LGM e modelli misti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/03_time_effects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Dati longitudinali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/05_intro_panel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Specificare e Interpretare un Modello Longitudinale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/07_growth_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Curve di crescita latente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/08_growth_cont.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Il tempo su una metrica continua</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/09_time_inv_cov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Covariate indipendenti dal tempo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/10_growth_groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Modelli di crescita latenti a gruppi multipli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/lgm/11_lgm_wais.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Lo Sviluppo dell’Intelligenza</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">Predizione</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/prediction/01_prediction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Predizione</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/networks/01_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Network psicologici</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a1_intro_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Linguaggio R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a2_sums.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Simbolo di somma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a3_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a4_linear_alg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Elementi di algebra lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false">
 <span class="menu-text">Soluzioni degli esercizi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Probabilità</span></span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">80.1</span> Introduzione</a></li>
  <li><a href="#calcolo-della-probabilità-di-hiv-dato-un-test-positivo" id="toc-calcolo-della-probabilità-di-hiv-dato-un-test-positivo" class="nav-link" data-scroll-target="#calcolo-della-probabilità-di-hiv-dato-un-test-positivo"><span class="header-section-number">80.2</span> Calcolo della probabilità di HIV dato un test positivo</a></li>
  <li><a href="#calcolo-della-probabilità-di-un-secondo-test-positivo" id="toc-calcolo-della-probabilità-di-un-secondo-test-positivo" class="nav-link" data-scroll-target="#calcolo-della-probabilità-di-un-secondo-test-positivo"><span class="header-section-number">80.3</span> Calcolo della probabilità di un secondo test positivo</a></li>
  <li><a href="#accuratezza-delle-predizioni" id="toc-accuratezza-delle-predizioni" class="nav-link" data-scroll-target="#accuratezza-delle-predizioni"><span class="header-section-number">80.4</span> Accuratezza delle Predizioni</a>
  <ul>
  <li><a href="#calcolo-dei-tassi-marginali" id="toc-calcolo-dei-tassi-marginali" class="nav-link" data-scroll-target="#calcolo-dei-tassi-marginali"><span class="header-section-number">80.4.1</span> Calcolo dei Tassi Marginali</a></li>
  <li><a href="#percentuale-di-accuratezza" id="toc-percentuale-di-accuratezza" class="nav-link" data-scroll-target="#percentuale-di-accuratezza"><span class="header-section-number">80.4.2</span> Percentuale di Accuratezza</a></li>
  <li><a href="#accuratezza-per-caso" id="toc-accuratezza-per-caso" class="nav-link" data-scroll-target="#accuratezza-per-caso"><span class="header-section-number">80.4.3</span> Accuratezza per Caso</a></li>
  <li><a href="#predire-dal-tasso-di-base" id="toc-predire-dal-tasso-di-base" class="nav-link" data-scroll-target="#predire-dal-tasso-di-base"><span class="header-section-number">80.4.4</span> Predire dal Tasso di Base</a></li>
  <li><a href="#diversi-tipi-di-errori-e-i-loro-costi" id="toc-diversi-tipi-di-errori-e-i-loro-costi" class="nav-link" data-scroll-target="#diversi-tipi-di-errori-e-i-loro-costi"><span class="header-section-number">80.4.5</span> Diversi Tipi di Errori e i loro Costi</a></li>
  <li><a href="#importanza-del-rapporto-di-selezione-e-del-tasso-di-base" id="toc-importanza-del-rapporto-di-selezione-e-del-tasso-di-base" class="nav-link" data-scroll-target="#importanza-del-rapporto-di-selezione-e-del-tasso-di-base"><span class="header-section-number">80.4.6</span> Importanza del Rapporto di Selezione e del Tasso di Base</a></li>
  <li><a href="#predizioni-e-affidabilità-in-condizioni-di-basso-tasso-di-base" id="toc-predizioni-e-affidabilità-in-condizioni-di-basso-tasso-di-base" class="nav-link" data-scroll-target="#predizioni-e-affidabilità-in-condizioni-di-basso-tasso-di-base"><span class="header-section-number">80.4.7</span> Predizioni e Affidabilità in Condizioni di Basso Tasso di Base</a></li>
  <li><a href="#sensibilità-specificità-ppv-e-npv" id="toc-sensibilità-specificità-ppv-e-npv" class="nav-link" data-scroll-target="#sensibilità-specificità-ppv-e-npv"><span class="header-section-number">80.4.8</span> Sensibilità, Specificità, PPV e NPV</a></li>
  <li><a href="#interpretazione-delle-metriche" id="toc-interpretazione-delle-metriche" class="nav-link" data-scroll-target="#interpretazione-delle-metriche"><span class="header-section-number">80.4.9</span> Interpretazione delle Metriche</a></li>
  </ul></li>
  <li><a href="#alcune-stime-di-accuratezza-dipendono-dal-cutoff" id="toc-alcune-stime-di-accuratezza-dipendono-dal-cutoff" class="nav-link" data-scroll-target="#alcune-stime-di-accuratezza-dipendono-dal-cutoff"><span class="header-section-number">80.5</span> Alcune Stime di Accuratezza Dipendono dal Cutoff</a></li>
  <li><a href="#teoria-della-detezione-del-segnale" id="toc-teoria-della-detezione-del-segnale" class="nav-link" data-scroll-target="#teoria-della-detezione-del-segnale"><span class="header-section-number">80.6</span> Teoria della Detezione del Segnale</a>
  <ul>
  <li><a href="#curva-roc-receiver-operating-characteristic" id="toc-curva-roc-receiver-operating-characteristic" class="nav-link" data-scroll-target="#curva-roc-receiver-operating-characteristic"><span class="header-section-number">80.6.1</span> Curva ROC (Receiver Operating Characteristic)</a></li>
  <li><a href="#area-sotto-la-curva-roc-auc" id="toc-area-sotto-la-curva-roc-auc" class="nav-link" data-scroll-target="#area-sotto-la-curva-roc-auc"><span class="header-section-number">80.6.2</span> Area Sotto la Curva ROC (AUC)</a></li>
  </ul></li>
  <li><a href="#predictionAccuracy" id="toc-predictionAccuracy" class="nav-link" data-scroll-target="#predictionAccuracy"><span class="header-section-number">80.7</span> Accuratezza della Predizione attraverso i Cutoff</a></li>
  <li><a href="#calibration" id="toc-calibration" class="nav-link" data-scroll-target="#calibration"><span class="header-section-number">80.8</span> Calibrazione</a>
  <ul>
  <li><a href="#calibrationPlot" id="toc-calibrationPlot" class="nav-link" data-scroll-target="#calibrationPlot"><span class="header-section-number">80.8.1</span> Calibration Plot</a>
  <ul>
  <li><a href="#brierScores" id="toc-brierScores" class="nav-link" data-scroll-target="#brierScores"><span class="header-section-number">80.8.1.1</span> Brier Scores</a></li>
  <li><a href="#brierScores" id="toc-brierScores" class="nav-link" data-scroll-target="#brierScores"><span class="header-section-number">80.8.1.2</span> Brier Scores</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#matrice-di-confusione" id="toc-matrice-di-confusione" class="nav-link" data-scroll-target="#matrice-di-confusione"><span class="header-section-number">80.9</span> Matrice di Confusione</a>
  <ul>
  <li><a href="#truePositive" id="toc-truePositive" class="nav-link" data-scroll-target="#truePositive"><span class="header-section-number">80.9.1</span> True Positives (TP)</a></li>
  <li><a href="#trueNegative" id="toc-trueNegative" class="nav-link" data-scroll-target="#trueNegative"><span class="header-section-number">80.9.2</span> True Negatives (TN)</a></li>
  <li><a href="#falsePositive" id="toc-falsePositive" class="nav-link" data-scroll-target="#falsePositive"><span class="header-section-number">80.9.3</span> False Positives (FP)</a></li>
  <li><a href="#falseNegative" id="toc-falseNegative" class="nav-link" data-scroll-target="#falseNegative"><span class="header-section-number">80.9.4</span> False Negatives (FN)</a></li>
  <li><a href="#sampleSize-prediction" id="toc-sampleSize-prediction" class="nav-link" data-scroll-target="#sampleSize-prediction"><span class="header-section-number">80.9.5</span> Dimensione del Campione (<em>N</em>)</a></li>
  <li><a href="#selectionRatio" id="toc-selectionRatio" class="nav-link" data-scroll-target="#selectionRatio"><span class="header-section-number">80.9.6</span> Selection Ratio (SR)</a></li>
  <li><a href="#pretestProbability" id="toc-pretestProbability" class="nav-link" data-scroll-target="#pretestProbability"><span class="header-section-number">80.9.7</span> Base Rate (BR)</a></li>
  <li><a href="#pretestOdds" id="toc-pretestOdds" class="nav-link" data-scroll-target="#pretestOdds"><span class="header-section-number">80.9.8</span> Pretest Odds</a></li>
  <li><a href="#percentAccuracy" id="toc-percentAccuracy" class="nav-link" data-scroll-target="#percentAccuracy"><span class="header-section-number">80.9.9</span> Percent Accuracy</a></li>
  <li><a href="#percentAccuracyByChance" id="toc-percentAccuracyByChance" class="nav-link" data-scroll-target="#percentAccuracyByChance"><span class="header-section-number">80.9.10</span> Percent Accuracy by Chance</a></li>
  <li><a href="#percentAccuracyPredictingFromBaseRate" id="toc-percentAccuracyPredictingFromBaseRate" class="nav-link" data-scroll-target="#percentAccuracyPredictingFromBaseRate"><span class="header-section-number">80.9.11</span> Percent Accuracy Predicting from the Base Rate</a></li>
  <li><a href="#relativeImprovementOverChance" id="toc-relativeImprovementOverChance" class="nav-link" data-scroll-target="#relativeImprovementOverChance"><span class="header-section-number">80.9.12</span> Relative Improvement Over Chance (RIOC)</a></li>
  <li><a href="#relativeImprovementOverPredictingFromBaseRate" id="toc-relativeImprovementOverPredictingFromBaseRate" class="nav-link" data-scroll-target="#relativeImprovementOverPredictingFromBaseRate"><span class="header-section-number">80.9.13</span> Relative Improvement Over Predicting from the Base Rate</a></li>
  <li><a href="#sensitivity" id="toc-sensitivity" class="nav-link" data-scroll-target="#sensitivity"><span class="header-section-number">80.9.14</span> Sensitivity (SN)</a></li>
  <li><a href="#specificity" id="toc-specificity" class="nav-link" data-scroll-target="#specificity"><span class="header-section-number">80.9.15</span> Specificity (SP)</a></li>
  <li><a href="#falseNegativeRate" id="toc-falseNegativeRate" class="nav-link" data-scroll-target="#falseNegativeRate"><span class="header-section-number">80.9.16</span> False Negative Rate (FNR)</a></li>
  <li><a href="#falsePositiveRate" id="toc-falsePositiveRate" class="nav-link" data-scroll-target="#falsePositiveRate"><span class="header-section-number">80.9.17</span> False Positive Rate (FPR)</a></li>
  <li><a href="#ppv" id="toc-ppv" class="nav-link" data-scroll-target="#ppv"><span class="header-section-number">80.9.18</span> Positive Predictive Value (PPV)</a></li>
  <li><a href="#npv" id="toc-npv" class="nav-link" data-scroll-target="#npv"><span class="header-section-number">80.9.19</span> Negative Predictive Value (NPV)</a></li>
  <li><a href="#falseDiscoveryRate" id="toc-falseDiscoveryRate" class="nav-link" data-scroll-target="#falseDiscoveryRate"><span class="header-section-number">80.9.20</span> False Discovery Rate (FDR)</a></li>
  <li><a href="#falseOmissionRate" id="toc-falseOmissionRate" class="nav-link" data-scroll-target="#falseOmissionRate"><span class="header-section-number">80.9.21</span> False Omission Rate (FOR)</a></li>
  <li><a href="#youdenJ-example" id="toc-youdenJ-example" class="nav-link" data-scroll-target="#youdenJ-example"><span class="header-section-number">80.9.22</span> Youden’s J Statistic</a></li>
  <li><a href="#balancedAccuracy" id="toc-balancedAccuracy" class="nav-link" data-scroll-target="#balancedAccuracy"><span class="header-section-number">80.9.23</span> Balanced Accuracy</a></li>
  <li><a href="#fScore" id="toc-fScore" class="nav-link" data-scroll-target="#fScore"><span class="header-section-number">80.9.24</span> F-Score</a></li>
  <li><a href="#matthewsCorrelationCoefficient" id="toc-matthewsCorrelationCoefficient" class="nav-link" data-scroll-target="#matthewsCorrelationCoefficient"><span class="header-section-number">80.9.25</span> Matthews Correlation Coefficient (MCC)</a></li>
  <li><a href="#diagnosticOddsRatio" id="toc-diagnosticOddsRatio" class="nav-link" data-scroll-target="#diagnosticOddsRatio"><span class="header-section-number">80.9.26</span> Diagnostic Odds Ratio</a></li>
  <li><a href="#diagnosticLikelihoodRatio" id="toc-diagnosticLikelihoodRatio" class="nav-link" data-scroll-target="#diagnosticLikelihoodRatio"><span class="header-section-number">80.9.27</span> Diagnostic Likelihood Ratio</a>
  <ul>
  <li><a href="#positiveLikelihoodRatio" id="toc-positiveLikelihoodRatio" class="nav-link" data-scroll-target="#positiveLikelihoodRatio"><span class="header-section-number">80.9.27.1</span> Positive Likelihood Ratio (LR+)</a></li>
  <li><a href="#negativeLikelihoodRatio" id="toc-negativeLikelihoodRatio" class="nav-link" data-scroll-target="#negativeLikelihoodRatio"><span class="header-section-number">80.9.27.2</span> Negative Likelihood Ratio (LR−)</a></li>
  </ul></li>
  <li><a href="#posttestOdds" id="toc-posttestOdds" class="nav-link" data-scroll-target="#posttestOdds"><span class="header-section-number">80.9.28</span> Posttest Odds</a></li>
  <li><a href="#posttestProbability" id="toc-posttestProbability" class="nav-link" data-scroll-target="#posttestProbability"><span class="header-section-number">80.9.29</span> Posttest Probability</a></li>
  <li><a href="#nomogram" id="toc-nomogram" class="nav-link" data-scroll-target="#nomogram"><span class="header-section-number">80.9.30</span> Probability Nomogram</a></li>
  <li><a href="#dPrimeSDT" id="toc-dPrimeSDT" class="nav-link" data-scroll-target="#dPrimeSDT"><span class="header-section-number">80.9.31</span> <span class="math inline">\(d'\)</span> Sensitivity from Signal Detection Theory</a></li>
  <li><a href="#aSDT" id="toc-aSDT" class="nav-link" data-scroll-target="#aSDT"><span class="header-section-number">80.9.32</span> <span class="math inline">\(A\)</span> (Non-Parametric) Sensitivity from Signal Detection Theory</a></li>
  <li><a href="#betaSDT" id="toc-betaSDT" class="nav-link" data-scroll-target="#betaSDT"><span class="header-section-number">80.9.33</span> <span class="math inline">\(\beta\)</span> Bias from Signal Detection Theory</a></li>
  <li><a href="#cSDT" id="toc-cSDT" class="nav-link" data-scroll-target="#cSDT"><span class="header-section-number">80.9.34</span> <span class="math inline">\(c\)</span> Bias from Signal Detection Theory</a></li>
  <li><a href="#bSDT" id="toc-bSDT" class="nav-link" data-scroll-target="#bSDT"><span class="header-section-number">80.9.35</span> <span class="math inline">\(b\)</span> (Non-Parametric) Bias from Signal Detection Theory</a></li>
  <li><a href="#miscalibration" id="toc-miscalibration" class="nav-link" data-scroll-target="#miscalibration"><span class="header-section-number">80.9.36</span> Mean Difference between Predicted Versus Observed Values (Miscalibration)</a></li>
  </ul></li>
  <li><a href="#optimalCutoff" id="toc-optimalCutoff" class="nav-link" data-scroll-target="#optimalCutoff"><span class="header-section-number">80.10</span> Optimal Cutoff Specification</a>
  <ul>
  <li><a href="#decisionTheory" id="toc-decisionTheory" class="nav-link" data-scroll-target="#decisionTheory"><span class="header-section-number">80.10.1</span> Decision Theory</a>
  <ul>
  <li><a href="#overallUtilityCutoff" id="toc-overallUtilityCutoff" class="nav-link" data-scroll-target="#overallUtilityCutoff"><span class="header-section-number">80.10.1.1</span> Overall utility of a specific cutoff value</a></li>
  <li><a href="#utilityRatio" id="toc-utilityRatio" class="nav-link" data-scroll-target="#utilityRatio"><span class="header-section-number">80.10.1.2</span> Utility ratio</a></li>
  </ul></li>
  <li><a href="#informationTheory" id="toc-informationTheory" class="nav-link" data-scroll-target="#informationTheory"><span class="header-section-number">80.10.2</span> Information Theory</a>
  <ul>
  <li><a href="#informationGain" id="toc-informationGain" class="nav-link" data-scroll-target="#informationGain"><span class="header-section-number">80.10.2.1</span> Information Gain</a>
  <ul class="collapse">
  <li><a href="#IgainTreat2023" id="toc-IgainTreat2023" class="nav-link" data-scroll-target="#IgainTreat2023"><span class="header-section-number">80.10.2.1.1</span> Formula from <span class="citation" data-cites="Treat2023">(<strong>Treat2023?</strong>)</span></a></li>
  <li><a href="#IgainMetz1973" id="toc-IgainMetz1973" class="nav-link" data-scroll-target="#IgainMetz1973"><span class="header-section-number">80.10.2.1.2</span> Alternative formula from <span class="citation" data-cites="Metz1973">(<strong>Metz1973?</strong>)</span></a></li>
  <li><a href="#IgainSomoza1989" id="toc-IgainSomoza1989" class="nav-link" data-scroll-target="#IgainSomoza1989"><span class="header-section-number">80.10.2.1.3</span> Alternative formula from <span class="citation" data-cites="Somoza1989">(<strong>Somoza1989?</strong>)</span></a></li>
  <li><a href="#IgainExamples" id="toc-IgainExamples" class="nav-link" data-scroll-target="#IgainExamples"><span class="header-section-number">80.10.2.1.4</span> Examples</a></li>
  <li><a href="#baseRateEffectsIgain" id="toc-baseRateEffectsIgain" class="nav-link" data-scroll-target="#baseRateEffectsIgain"><span class="header-section-number">80.10.2.1.5</span> Effect of Base Rate</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#calculateAccuracyAtEveryPossibleCutoff" id="toc-calculateAccuracyAtEveryPossibleCutoff" class="nav-link" data-scroll-target="#calculateAccuracyAtEveryPossibleCutoff"><span class="header-section-number">80.10.3</span> Calculate Accuracy</a></li>
  <li><a href="#allAccuracyStatistics-youdenJ" id="toc-allAccuracyStatistics-youdenJ" class="nav-link" data-scroll-target="#allAccuracyStatistics-youdenJ"><span class="header-section-number">80.10.4</span> Youden’s J Statistic</a>
  <ul>
  <li><a href="#allAccuracyStatistics-youdenJthreshold" id="toc-allAccuracyStatistics-youdenJthreshold" class="nav-link" data-scroll-target="#allAccuracyStatistics-youdenJthreshold"><span class="header-section-number">80.10.4.1</span> Threshold</a></li>
  <li><a href="#allAccuracyStatistics-youdenJaccuracy" id="toc-allAccuracyStatistics-youdenJaccuracy" class="nav-link" data-scroll-target="#allAccuracyStatistics-youdenJaccuracy"><span class="header-section-number">80.10.4.2</span> Accuracy statistics at cutoff of Youden’s J Statistic</a></li>
  </ul></li>
  <li><a href="#allAccuracyStatistics-topLeftROC" id="toc-allAccuracyStatistics-topLeftROC" class="nav-link" data-scroll-target="#allAccuracyStatistics-topLeftROC"><span class="header-section-number">80.10.5</span> Closest to the Top Left of the ROC Curve</a>
  <ul>
  <li><a href="#allAccuracyStatistics-topLeftROCthreshold" id="toc-allAccuracyStatistics-topLeftROCthreshold" class="nav-link" data-scroll-target="#allAccuracyStatistics-topLeftROCthreshold"><span class="header-section-number">80.10.5.1</span> Threshold</a></li>
  <li><a href="#allAccuracyStatistics-topLeftROCaccuracy" id="toc-allAccuracyStatistics-topLeftROCaccuracy" class="nav-link" data-scroll-target="#allAccuracyStatistics-topLeftROCaccuracy"><span class="header-section-number">80.10.5.2</span> Accuracy stats at cutoff where the ROC plot is closest to the Top Left</a></li>
  </ul></li>
  <li><a href="#allAccuracyStatistics-cutoff" id="toc-allAccuracyStatistics-cutoff" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoff"><span class="header-section-number">80.10.6</span> Cutoff that optimizes each of the following criteria:</a>
  <ul>
  <li><a href="#allAccuracyStatistics-cutoffPercentAccuracy" id="toc-allAccuracyStatistics-cutoffPercentAccuracy" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffPercentAccuracy"><span class="header-section-number">80.10.6.1</span> Percent Accuracy</a></li>
  <li><a href="#allAccuracyStatistics-cutoffPercentAccuracyByChance" id="toc-allAccuracyStatistics-cutoffPercentAccuracyByChance" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffPercentAccuracyByChance"><span class="header-section-number">80.10.6.2</span> Percent Accuracy by Chance</a></li>
  <li><a href="#allAccuracyStatistics-cutoffROIC" id="toc-allAccuracyStatistics-cutoffROIC" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffROIC"><span class="header-section-number">80.10.6.3</span> Relative Improvement Over Chance (ROIC)</a></li>
  <li><a href="#allAccuracyStatistics-cutoffRelativeImprovementOverPredictingFromBaseRate" id="toc-allAccuracyStatistics-cutoffRelativeImprovementOverPredictingFromBaseRate" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffRelativeImprovementOverPredictingFromBaseRate"><span class="header-section-number">80.10.6.4</span> Relative Improvement Over Predicting from the Base Rate</a></li>
  <li><a href="#allAccuracyStatistics-cutoffSensitivity" id="toc-allAccuracyStatistics-cutoffSensitivity" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffSensitivity"><span class="header-section-number">80.10.6.5</span> Sensitivity</a></li>
  <li><a href="#allAccuracyStatistics-cutoffSpecificity" id="toc-allAccuracyStatistics-cutoffSpecificity" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffSpecificity"><span class="header-section-number">80.10.6.6</span> Specificity</a></li>
  <li><a href="#allAccuracyStatistics-cutoffPPV" id="toc-allAccuracyStatistics-cutoffPPV" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffPPV"><span class="header-section-number">80.10.6.7</span> Positive Predictive Value</a></li>
  <li><a href="#allAccuracyStatistics-cutoffNPV" id="toc-allAccuracyStatistics-cutoffNPV" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffNPV"><span class="header-section-number">80.10.6.8</span> Negative Predictive Value</a></li>
  <li><a href="#allAccuracyStatistics-cutoffYoudenJ" id="toc-allAccuracyStatistics-cutoffYoudenJ" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffYoudenJ"><span class="header-section-number">80.10.6.9</span> Youden’s J Statistic</a></li>
  <li><a href="#allAccuracyStatistics-cutoffBalancedAccuracy" id="toc-allAccuracyStatistics-cutoffBalancedAccuracy" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffBalancedAccuracy"><span class="header-section-number">80.10.6.10</span> Balanced Accuracy</a></li>
  <li><a href="#allAccuracyStatistics-cutoffF1" id="toc-allAccuracyStatistics-cutoffF1" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffF1"><span class="header-section-number">80.10.6.11</span> F1 Score</a></li>
  <li><a href="#allAccuracyStatistics-cutoffMCC" id="toc-allAccuracyStatistics-cutoffMCC" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffMCC"><span class="header-section-number">80.10.6.12</span> Matthews Correlation Coefficient</a></li>
  <li><a href="#allAccuracyStatistics-cutoffDOR" id="toc-allAccuracyStatistics-cutoffDOR" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffDOR"><span class="header-section-number">80.10.6.13</span> Diagnostic Odds Ratio</a></li>
  <li><a href="#allAccuracyStatistics-cutoffPLR" id="toc-allAccuracyStatistics-cutoffPLR" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffPLR"><span class="header-section-number">80.10.6.14</span> Positive Likelihood Ratio</a></li>
  <li><a href="#allAccuracyStatistics-cutoffNLR" id="toc-allAccuracyStatistics-cutoffNLR" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffNLR"><span class="header-section-number">80.10.6.15</span> Negative Likelihood Ratio</a></li>
  <li><a href="#allAccuracyStatistics-cutoffDprime" id="toc-allAccuracyStatistics-cutoffDprime" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffDprime"><span class="header-section-number">80.10.6.16</span> <span class="math inline">\(d'\)</span> Sensitivity</a></li>
  <li><a href="#allAccuracyStatistics-cutoffAsensitivity" id="toc-allAccuracyStatistics-cutoffAsensitivity" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffAsensitivity"><span class="header-section-number">80.10.6.17</span> <span class="math inline">\(A\)</span> (Non-Parametric) Sensitivity</a></li>
  <li><a href="#allAccuracyStatistics-cutoffBetaBias" id="toc-allAccuracyStatistics-cutoffBetaBias" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffBetaBias"><span class="header-section-number">80.10.6.18</span> <span class="math inline">\(\beta\)</span> Bias</a></li>
  <li><a href="#allAccuracyStatistics-cutoffCbias" id="toc-allAccuracyStatistics-cutoffCbias" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffCbias"><span class="header-section-number">80.10.6.19</span> <span class="math inline">\(c\)</span> Bias</a></li>
  <li><a href="#allAccuracyStatistics-cutoffBbias" id="toc-allAccuracyStatistics-cutoffBbias" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffBbias"><span class="header-section-number">80.10.6.20</span> <span class="math inline">\(b\)</span> (Non-Parametric) Bias</a></li>
  <li><a href="#allAccuracyStatistics-cutoffMiscalibration" id="toc-allAccuracyStatistics-cutoffMiscalibration" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffMiscalibration"><span class="header-section-number">80.10.6.21</span> Mean difference between predicted and observed values (Miscalibration)</a></li>
  <li><a href="#allAccuracyStatistics-cutoffOverallUtility" id="toc-allAccuracyStatistics-cutoffOverallUtility" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffOverallUtility"><span class="header-section-number">80.10.6.22</span> Overall Utility</a></li>
  <li><a href="#allAccuracyStatistics-cutoffIgain" id="toc-allAccuracyStatistics-cutoffIgain" class="nav-link" data-scroll-target="#allAccuracyStatistics-cutoffIgain"><span class="header-section-number">80.10.6.23</span> Information Gain</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#regression-prediction" id="toc-regression-prediction" class="nav-link" data-scroll-target="#regression-prediction"><span class="header-section-number">80.11</span> Regression for Prediction of Continuous Outcomes</a>
  <ul>
  <li><a href="#multiCollinearity" id="toc-multiCollinearity" class="nav-link" data-scroll-target="#multiCollinearity"><span class="header-section-number">80.11.1</span> Multicollinearity</a></li>
  </ul></li>
  <li><a href="#waysToImprovePredictionAccuracy" id="toc-waysToImprovePredictionAccuracy" class="nav-link" data-scroll-target="#waysToImprovePredictionAccuracy"><span class="header-section-number">80.12</span> Ways to Improve Prediction Accuracy</a></li>
  <li><a href="#conclusion-prediction" id="toc-conclusion-prediction" class="nav-link" data-scroll-target="#conclusion-prediction"><span class="header-section-number">80.13</span> Conclusion</a></li>
  <li><a href="#readings-prediction" id="toc-readings-prediction" class="nav-link" data-scroll-target="#readings-prediction"><span class="header-section-number">80.14</span> Suggested Readings</a></li>
  <li><a href="#exercises-prediction" id="toc-exercises-prediction" class="nav-link" data-scroll-target="#exercises-prediction"><span class="header-section-number">80.15</span> Exercises</a>
  <ul>
  <li><a href="#exercisesQuestions-prediction" id="toc-exercisesQuestions-prediction" class="nav-link" data-scroll-target="#exercisesQuestions-prediction"><span class="header-section-number">80.15.1</span> Questions</a></li>
  <li><a href="#exercisesAnswers-prediction" id="toc-exercisesAnswers-prediction" class="nav-link" data-scroll-target="#exercisesAnswers-prediction"><span class="header-section-number">80.15.2</span> Answers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/prediction/01_prediction.html">Predizione</a></li><li class="breadcrumb-item"><a href="../../chapters/prediction/01_prediction.html"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Predizione</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-prediction" class="quarto-section-identifier"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Predizione</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<ul>
<li>Leggere il capitolo 9 <em>Prediction</em> del testo di <span class="citation" data-cites="petersen2024principles">Petersen (<a href="../../99-references.html#ref-petersen2024principles" role="doc-biblioref">2024</a>)</span>.</li>
</ul>
<p><strong>Concetti e Competenze Chiave</strong></p>
<p><strong>Preparazione del Notebook</strong></p>
<div id="cell-2" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"code"</span>, <span class="st">"_common.R"</span>) <span class="sc">|&gt;</span> <span class="fu">source</span>()</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">"pacman"</span>)) <span class="fu">install.packages</span>(<span class="st">"pacman"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    petersenlab, magrittr, viridis, pROC, ROCR, rms, ResourceSelection,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    PredictABEL, gridExtra, grid, ggpubr, msir, car, ggrepel, MOTE,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    tinytex</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2" data-number="80.1">
<h2 data-number="80.1" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">80.1</span> Introduzione</h2>
<p>Le predizioni possono essere di vario tipo. Alcune riguardano dati categoriali, mentre altre si basano su dati continui. Per i dati categoriali, possiamo valutare le predizioni utilizzando una tabella 2x2, nota come matrice di confusione, o con modelli di regressione logistica. Invece, per i dati continui, possiamo utilizzare la regressione multipla o varianti come il modello a equazioni strutturali o i modelli misti.</p>
<p>Consideriamo un esempio pratico di predizione della probabilità di contrarre l’HIV, utilizzando le seguenti informazioni <span class="citation" data-cites="petersen2024principles">(<a href="../../99-references.html#ref-petersen2024principles" role="doc-biblioref">Petersen, 2024</a>)</span>:</p>
<ul>
<li><strong>Tasso di base dell’HIV (P(HIV))</strong>: 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l’HIV.</li>
<li><strong>Sensibilità del test (P(Test+ HIV))</strong>: 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l’HIV.</li>
<li><strong>Specificità del test (P(Test- ¬HIV))</strong>: 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l’HIV.</li>
</ul>
</section>
<section id="calcolo-della-probabilità-di-hiv-dato-un-test-positivo" class="level2" data-number="80.2">
<h2 data-number="80.2" class="anchored" data-anchor-id="calcolo-della-probabilità-di-hiv-dato-un-test-positivo"><span class="header-section-number">80.2</span> Calcolo della probabilità di HIV dato un test positivo</h2>
<p>Per calcolare la probabilità di avere l’HIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:</p>
<p><span class="math display">\[
P(HIV \mid Test+) = \frac{P(Test+ \mid HIV) \times P(HIV)}{P(Test+)}.
\]</span></p>
<p>Abbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:</p>
<p><span class="math display">\[
P(Test+) = P(Test+ \mid HIV) \times P(HIV) + P(Test+ \mid \neg HIV) \times P(\neg HIV),
\]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(P(Test+ \mid \neg HIV) = 1 - P(Test- \mid \neg HIV) = 1 - 0.9928 = 0.0072\)</span> (tasso di falsi positivi),</li>
<li><span class="math inline">\(P(\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\)</span>.</li>
</ul>
<p>Calcoliamo <span class="math inline">\(P(Test+)\)</span>:</p>
<p><span class="math display">\[
P(Test+) = (0.95 \times 0.003) + (0.0072 \times 0.997) \approx 0.010027.
\]</span></p>
<p>Ora possiamo calcolare <span class="math inline">\(P(HIV \mid Test+)\)</span>:</p>
<p><span class="math display">\[
P(HIV \mid Test+) = \frac{0.95 \times 0.003}{0.010027} \approx 0.2844 \text{ o 28.44\%}.
\]</span></p>
<p>Quindi, se il test risulta positivo, la probabilità di avere l’HIV è circa il 28.44%.</p>
</section>
<section id="calcolo-della-probabilità-di-un-secondo-test-positivo" class="level2" data-number="80.3">
<h2 data-number="80.3" class="anchored" data-anchor-id="calcolo-della-probabilità-di-un-secondo-test-positivo"><span class="header-section-number">80.3</span> Calcolo della probabilità di un secondo test positivo</h2>
<p>Dopo un primo test positivo, la probabilità di avere l’HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l’HIV dopo due test positivi consecutivi.</p>
<p>Per calcolare <span class="math inline">\(P(\text{Secondo Test+})\)</span>, consideriamo due scenari:</p>
<ol type="1">
<li>La persona ha effettivamente l’HIV:
<ul>
<li>Probabilità: <span class="math inline">\(P(HIV \mid Test+) = 0.2844\)</span>.</li>
<li>Probabilità di un test positivo: <span class="math inline">\(P(\text{Test+} \mid HIV) = 0.95\)</span> (sensibilità del test).</li>
</ul></li>
<li>La persona non ha l’HIV:
<ul>
<li>Probabilità: <span class="math inline">\(P(\neg HIV \mid Test+) = 1 - P(HIV \mid Test+) = 0.7156\)</span>.</li>
<li>Probabilità di un test positivo: <span class="math inline">\(P(\text{Test+} \mid \neg HIV) = 0.0072\)</span> (tasso di falsi positivi).</li>
</ul></li>
</ol>
<p>Utilizziamo la formula della probabilità totale:</p>
<p><span class="math display">\[
\begin{aligned}
P(\text{Secondo Test+}) &amp;= P(\text{Test+} \mid HIV) \times P(HIV \mid Test+) + \\
&amp;\quad P(\text{Test+} \mid \neg HIV) \times P(\neg HIV \mid Test+).
\end{aligned}
\]</span></p>
<p>Sostituendo i valori:</p>
<p><span class="math display">\[
P(\text{Secondo Test+}) = (0.95 \times 0.2844) + (0.0072 \times 0.7156) \approx 0.2753.
\]</span></p>
<p>Applichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l’HIV dopo un secondo test positivo:</p>
<p><span class="math display">\[
P(HIV \mid \text{Secondo Test+}) = \frac{P(\text{Secondo Test+} \mid HIV) \times P(HIV \mid Test+)}{P(\text{Secondo Test+})}.
\]</span></p>
<p>Sostituendo i valori:</p>
<p><span class="math display">\[
P(HIV \mid \text{Secondo Test+}) = \frac{0.95 \times 0.2844}{0.2753} \approx 0.981.
\]</span></p>
<p>In conclusione, dopo un secondo test positivo, la probabilità di avere l’HIV aumenta notevolmente, passando dal 28.44% al 98.1%. Questo drastico aumento dimostra l’importanza di:</p>
<ol type="1">
<li>considerare il tasso di base (prevalenza) nella popolazione;</li>
<li>aggiornare progressivamente le probabilità con nuove evidenze;</li>
<li>interpretare i risultati di test diagnostici multipli in modo bayesiano.</li>
</ol>
<p>L’analisi evidenzia come l’accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo sostanzialmente l’incertezza iniziale.</p>
</section>
<section id="accuratezza-delle-predizioni" class="level2" data-number="80.4">
<h2 data-number="80.4" class="anchored" data-anchor-id="accuratezza-delle-predizioni"><span class="header-section-number">80.4</span> Accuratezza delle Predizioni</h2>
<p>Per valutare l’accuratezza delle predizioni, <span class="citation" data-cites="petersen2024principles">Petersen (<a href="../../99-references.html#ref-petersen2024principles" role="doc-biblioref">2024</a>)</span> considera un esempio adattato da Meehl &amp; Rosen (1955). L’esercito americano esegue un test sui candidati per escludere quelli che hanno basse probabilità di superare l’addestramento di base. Per analizzare l’accuratezza di queste predizioni, possiamo utilizzare una <em>matrice di confusione</em>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 23%">
<col style="width: 24%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Decision (Prediction)</th>
<th>Actual Adjustment (Poor)</th>
<th>Actual Adjustment (Good)</th>
<th>Total Predicted</th>
<th>Selection Ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Reject</strong></td>
<td>TP = 86 (.043)</td>
<td>FP = 422 (.211)</td>
<td>508</td>
<td>SR = 0.254</td>
</tr>
<tr class="even">
<td><strong>Retain</strong></td>
<td>FN = 14 (.007)</td>
<td>TN = 1,478 (.739)</td>
<td>1,492</td>
<td>1 - SR = 0.746</td>
</tr>
<tr class="odd">
<td><strong>Total Actual</strong></td>
<td>100</td>
<td>1,900</td>
<td>N = 2,000</td>
<td></td>
</tr>
<tr class="even">
<td><strong>Base Rate</strong></td>
<td>BR = 0.05</td>
<td>1 - BR = 0.95</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Una <em>matrice di confusione</em> è una tabella che mette a confronto le predizioni fatte da un modello con gli esiti reali. Quando si tratta di una predizione dicotomica (ad esempio, sì/no o positivo/negativo), la matrice di confusione è organizzata in una tabella 2x2 che descrive le seguenti combinazioni.</p>
<ul>
<li><strong>Vero positivo (TP)</strong>: La predizione indica che la persona possiede la caratteristica, e ciò risulta corretto perché la persona effettivamente la possiede.</li>
<li><strong>Vero negativo (TN)</strong>: La predizione indica che la persona non possiede la caratteristica, e ciò risulta corretto perché la persona effettivamente non la possiede.</li>
<li><strong>Falso positivo (FP)</strong>: La predizione indica che la persona possiede la caratteristica, ma in realtà la persona non la possiede.</li>
<li><strong>Falso negativo (FN)</strong>: La predizione indica che la persona non possiede la caratteristica, ma in realtà la persona la possiede.</li>
</ul>
<p>Questi quattro risultati sono alla base dell’analisi dell’accuratezza di un modello predittivo. Il termine “vero” indica una predizione corretta, mentre “falso” rappresenta un errore. “Positivo” e “negativo” si riferiscono rispettivamente al fatto che la predizione indichi la presenza o l’assenza di una determinata caratteristica.</p>
<section id="calcolo-dei-tassi-marginali" class="level3" data-number="80.4.1">
<h3 data-number="80.4.1" class="anchored" data-anchor-id="calcolo-dei-tassi-marginali"><span class="header-section-number">80.4.1</span> Calcolo dei Tassi Marginali</h3>
<p>Con le informazioni presenti nella matrice di confusione, possiamo calcolare i <em>tassi marginali</em>, ovvero le probabilità globali che una persona presenti una certa caratteristica o sia classificata in un determinato modo.</p>
<ol type="1">
<li><p><strong>Tasso di base (BR)</strong>: Questo rappresenta la probabilità marginale che una persona abbia la caratteristica di interesse. Ad esempio, se 100 persone su 2.000 mostrano un cattivo adattamento, il tasso di base è:</p>
<p><span class="math display">\[
BR = \frac{FN + TP}{N} = \frac{100}{2000} = 0.05
\]</span></p>
<p>Ciò significa che il 5% dei candidati ha un cattivo adattamento.</p></li>
<li><p><strong>Rapporto di selezione (SR)</strong>: Questo indica la probabilità marginale che una persona venga esclusa dal test. Se 508 persone vengono escluse, il rapporto di selezione è:</p>
<p><span class="math display">\[
SR = \frac{TP + FP}{N} = \frac{508}{2000} = 0.254
\]</span></p>
<p>Il 25.4% dei candidati è stato escluso.</p></li>
</ol>
<p>Il <em>rapporto di selezione</em> può dipendere dal punteggio di cutoff del test o da fattori esterni, come il numero di candidati che possono essere trattati o inclusi nel programma.</p>
</section>
<section id="percentuale-di-accuratezza" class="level3" data-number="80.4.2">
<h3 data-number="80.4.2" class="anchored" data-anchor-id="percentuale-di-accuratezza"><span class="header-section-number">80.4.2</span> Percentuale di Accuratezza</h3>
<p>La <em>percentuale di accuratezza</em> è un indicatore generale di quante predizioni sono corrette. Si calcola dividendo il numero di predizioni corrette (TP + TN) per il numero totale di predizioni (N), e moltiplicando per 100:</p>
<p><span class="math display">\[
\text{Percentuale di accuratezza} = 100 \times \frac{TP + TN}{N}.
\]</span></p>
<p>Nel nostro esempio, il 78% delle predizioni è corretto, il che indica che il modello ha una buona accuratezza complessiva.</p>
</section>
<section id="accuratezza-per-caso" class="level3" data-number="80.4.3">
<h3 data-number="80.4.3" class="anchored" data-anchor-id="accuratezza-per-caso"><span class="header-section-number">80.4.3</span> Accuratezza per Caso</h3>
<p>Sebbene il 78% di accuratezza possa sembrare un buon risultato, è essenziale confrontare questo valore con quello che si otterrebbe semplicemente per puro caso. Questo confronto ci aiuta a capire se il modello apporta un reale valore aggiunto rispetto a una previsione casuale.</p>
<p>Ad esempio, consideriamo un tasso di base (BR) del 5% e un rapporto di selezione (SR) del 25,4%. La probabilità di ottenere un vero positivo per caso è data da:</p>
<p><span class="math display">\[
P(TP) = BR \times SR = 0.05 \times 0.254 = 0.0127.
\]</span></p>
<p>Qui, il tasso di base BR = 0,05 rappresenta la probabilità che un individuo appartenga al gruppo con la caratteristica di interesse, mentre il rapporto di selezione SR = 0,254 indica la probabilità che l’individuo venga classificato come positivo. Moltiplicando queste due probabilità marginali, otteniamo la probabilità congiunta di ottenere un vero positivo per caso, pari a 0,0127.</p>
<p>Analogamente, la probabilità di ottenere un vero negativo per caso è data da:</p>
<p><span class="math display">\[
P(TN) = (1 - BR) \times (1 - SR) = 0.95 \times 0.746 = 0.7087.
\]</span></p>
<p>Pertanto, la <em>percentuale di accuratezza per caso</em>, ossia l’accuratezza attesa basandosi esclusivamente sulle probabilità marginali (BR e SR) senza informazioni specifiche del modello, è:</p>
<p><span class="math display">\[
P(\text{Accuratezza per caso}) = P(TP) + P(TN) = 0.0127 + 0.7087 = 0.7214.
\]</span></p>
<p>In questo esempio, il 72,14% di accuratezza potrebbe essere raggiunto anche senza l’uso del modello, semplicemente per caso. Dato che il nostro modello raggiunge un’accuratezza del 78%, il reale incremento di accuratezza rispetto al caso è solo del 6%. Questo evidenzia l’importanza di confrontare l’accuratezza del modello con quella ottenibile per puro caso per valutare il suo valore aggiunto.</p>
<p>Confrontando le aspettative casuali con l’accuratezza effettiva del modello, possiamo quindi misurare il reale beneficio del modello. Se l’accuratezza effettiva supera di poco quella ottenibile per caso, significa che il modello offre un miglioramento limitato rispetto a una semplice scelta casuale.</p>
</section>
<section id="predire-dal-tasso-di-base" class="level3" data-number="80.4.4">
<h3 data-number="80.4.4" class="anchored" data-anchor-id="predire-dal-tasso-di-base"><span class="header-section-number">80.4.4</span> Predire dal Tasso di Base</h3>
<p>Chiediamoci ora cosa accadrebbe se facessimo una previsione basata solo sulla probabilità generale degli esiti (tasso di base), senza considerare alcun modello predittivo.</p>
<p>Con un tasso di base basso (BR = 0.05) di un insufficiente adattamento alla vita militare, possiamo massimizzare l’accuratezza complessiva scegliendo di non “escludere” nessuno. Questo equivale a un <em>rapporto di selezione</em> (SR) pari a zero, indicando che non classifichiamo alcun caso come “Reject”. In questo scenario, tutti i casi sarebbero previsti come “Retain”, aumentando l’accuratezza totale ma rinunciando completamente alla possibilità di identificare casi positivi.</p>
<p>Se applichiamo questa logica alla matrice di confusione dei dati:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 27%">
<col style="width: 29%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Decision (Prediction)</th>
<th>Actual Adjustment (Poor)</th>
<th>Actual Adjustment (Good)</th>
<th>Total Predicted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Reject</strong></td>
<td>TP = 0</td>
<td>FP = 0</td>
<td>0</td>
</tr>
<tr class="even">
<td><strong>Retain</strong></td>
<td>FN = 100</td>
<td>TN = 1,900</td>
<td>2,000</td>
</tr>
<tr class="odd">
<td><strong>Total Actual</strong></td>
<td>100</td>
<td>1,900</td>
<td>N = 2,000</td>
</tr>
</tbody>
</table>
<ul>
<li>Con <strong>SR = 0</strong> (nessun caso viene classificato come “Reject”), otterremo:
<ul>
<li><strong>TN</strong> (Vero Negativo) = 1,900 (tutti i casi corretti di “Retain”)</li>
<li><strong>FN</strong> (Falso Negativo) = 100 (tutti i casi di “Poor” classificati erroneamente come “Retain”).</li>
</ul></li>
</ul>
<p>L’accuratezza complessiva in questo caso sarà quindi:</p>
<p><span class="math display">\[
P(\text{Accuratezza}) = \frac{\text{TP} + \text{TN}}{N} = \frac{0 + 1,900}{2,000} = 0.95
\]</span></p>
<p>In sintesi:</p>
<ul>
<li>“Predire dal Tasso di Base” implica usare l’esito prevalente per ogni predizione senza cercare di individuare i casi positivi;</li>
<li>nei dati forniti, impostando SR = 0 otteniamo un’accuratezza del 95%, che è superiore all’accuratezza del 78% del modello originale;</li>
<li>questo approccio aumenta l’accuratezza complessiva ma non offre alcuna informazione discriminativa.</li>
</ul>
<p>In conclusione, optare per l’esito più probabile in ogni predizione (cioè, predire sempre in base al tasso di base) può portare a un’elevata accuratezza, come osservato da Meehl e Rosen (1955), soprattutto quando il tasso di base è molto basso o molto alto. Questo effetto ci mostra quanto sia importante confrontare l’accuratezza del nostro modello con l’accuratezza che potremmo ottenere (1) per puro caso e (2) utilizzando solo il tasso di base. Questo confronto è cruciale, poiché l’accuratezza di un modello può cambiare notevolmente a seconda del contesto in cui viene applicato. Infatti, in alcuni contesti, dove il tasso di base si discosta molto dal 50%, l’uso del modello può addirittura ridurre la sua capacità di predizione accurata.</p>
<p>Inoltre, è importante considerare che la <em>percentuale di accuratezza</em> tratta tutti i tipi di errore allo stesso modo, senza fare distinzioni. Tuttavia, nella pratica, non tutti gli errori hanno lo stesso peso o importanza. Il costo di un falso positivo può essere molto diverso da quello di un falso negativo, e questa differenza può variare a seconda del contesto specifico, come verrà discusso nel prossimo paragrafo.</p>
</section>
<section id="diversi-tipi-di-errori-e-i-loro-costi" class="level3" data-number="80.4.5">
<h3 data-number="80.4.5" class="anchored" data-anchor-id="diversi-tipi-di-errori-e-i-loro-costi"><span class="header-section-number">80.4.5</span> Diversi Tipi di Errori e i loro Costi</h3>
<p>In un processo di classificazione, non tutti gli errori hanno lo stesso costo. Esistono due tipi principali di errori: i <em>falsi positivi</em> e i <em>falsi negativi</em>, ciascuno con implicazioni diverse che dipendono dal contesto della predizione.</p>
<p>Spesso, l’accuratezza complessiva può essere aumentata affidandosi semplicemente al <em>tasso di base</em>, ma in molte situazioni può essere preferibile utilizzare uno strumento di screening, anche a costo di una minore <em>accuratezza complessiva</em>, se ciò consente di minimizzare errori specifici che hanno costi elevati. Ad esempio:</p>
<ol type="1">
<li><p><strong>Screening medico</strong>: Consideriamo uno strumento di screening per l’HIV. I <em>falsi positivi</em> (classificare erroneamente una persona come a rischio) comportano costi come la necessità di test di conferma e, talvolta, ansia temporanea per l’individuo. Tuttavia, un <em>falso negativo</em> (non identificare una persona effettivamente a rischio) ha costi molto più alti, poiché potrebbe portare a un mancato intervento precoce, con conseguenze gravi per la salute. In questo caso, i costi associati ai falsi negativi superano di gran lunga quelli dei falsi positivi, rendendo lo screening preferibile nonostante una diminuzione dell’accuratezza complessiva.</p></li>
<li><p><strong>Selezione del personale in situazioni di rischio</strong>: La CIA, ad esempio, ha utilizzato strumenti di selezione per identificare potenziali spie durante periodi di guerra. Un <em>falso positivo</em> in questo contesto (considerare erroneamente una persona come una spia) potrebbe risultare nell’esclusione di un candidato innocente. Un <em>falso negativo</em> (assumere una persona che è effettivamente una spia) comporta rischi molto più gravi, rendendo cruciale l’identificazione corretta delle spie, anche a costo di più <em>falsi positivi</em>.</p></li>
</ol>
<p>Il modo in cui i costi degli errori vengono valutati dipende fortemente dal contesto. Alcuni potenziali costi dei <em>falsi positivi</em> includono trattamenti medici non necessari o il rischio di incarcerare una persona innocente. Al contrario, i <em>falsi negativi</em> possono portare al rilascio di una persona pericolosa, alla mancata individuazione di una malattia grave, o al mancato riconoscimento di un rischio imminente.</p>
</section>
<section id="importanza-del-rapporto-di-selezione-e-del-tasso-di-base" class="level3" data-number="80.4.6">
<h3 data-number="80.4.6" class="anchored" data-anchor-id="importanza-del-rapporto-di-selezione-e-del-tasso-di-base"><span class="header-section-number">80.4.6</span> Importanza del Rapporto di Selezione e del Tasso di Base</h3>
<p>Il costo degli errori può variare a seconda di come si imposta il <em>rapporto di selezione</em> (cioè, quanto rigorosamente si applica il criterio per accettare o escludere un individuo). La scelta di un rapporto di selezione meno restrittivo o più restrittivo influisce sulla probabilità di incorrere in <em>falsi positivi</em> e <em>falsi negativi</em> e può dipendere dal contesto e dai costi associati agli errori.</p>
<ul>
<li><strong>Criterio meno rigido</strong>: Se escludere candidati è costoso, ad esempio quando si ha la necessità di assumere molte persone, potrebbe essere più utile un criterio di selezione permissivo, che accetta anche persone con un rischio potenziale.</li>
<li><strong>Criterio più rigido</strong>: In contesti in cui non è necessario accettare molti individui, si può adottare un criterio di selezione più rigido per ridurre i rischi, scartando un numero maggiore di candidati sospetti.</li>
</ul>
<p>Quando il <em>rapporto di selezione</em> differisce dal <em>tasso di base</em> degli esiti negativi effettivi, inevitabilmente si generano errori:</p>
<ul>
<li>Se, ad esempio, il rapporto di selezione prevede di escludere il 25% dei candidati, ma solo il 5% risulta effettivamente “non idoneo,” il risultato sarà un numero elevato di <em>falsi positivi</em>.</li>
<li>D’altro canto, se si esclude solo l’1% dei candidati mentre il tasso di non idoneità è del 5%, si finirà per includere molti <em>falsi negativi</em>.</li>
</ul>
</section>
<section id="predizioni-e-affidabilità-in-condizioni-di-basso-tasso-di-base" class="level3" data-number="80.4.7">
<h3 data-number="80.4.7" class="anchored" data-anchor-id="predizioni-e-affidabilità-in-condizioni-di-basso-tasso-di-base"><span class="header-section-number">80.4.7</span> Predizioni e Affidabilità in Condizioni di Basso Tasso di Base</h3>
<p>Fare predizioni accurate diventa particolarmente complesso quando il tasso di base è basso, come nel caso di eventi rari (ad esempio, il suicidio). In questi casi, il numero di casi positivi reali è molto ridotto, rendendo difficile identificare correttamente i pochi eventi positivi senza generare numerosi falsi positivi o falsi negativi.</p>
<p>Questa difficoltà può essere compresa in relazione alla teoria classica dei test, che definisce l’affidabilità come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato. Con un tasso di base molto basso, la varianza del punteggio vero è ridotta, il che abbassa l’affidabilità della misura e rende più complessa una predizione accurata.</p>
</section>
<section id="sensibilità-specificità-ppv-e-npv" class="level3" data-number="80.4.8">
<h3 data-number="80.4.8" class="anchored" data-anchor-id="sensibilità-specificità-ppv-e-npv"><span class="header-section-number">80.4.8</span> Sensibilità, Specificità, PPV e NPV</h3>
<p>Come abbiamo visto, la <em>percentuale di accuratezza</em> da sola non è sufficiente per valutare l’efficacia di un modello, poiché è molto influenzata dai <em>tassi di base</em>. Ad esempio, se il tasso di base è basso, potremmo ottenere un’alta percentuale di accuratezza semplicemente affermando che nessuno ha la condizione; se è alto, affermando che tutti ce l’hanno. Perciò, è essenziale considerare altre metriche di accuratezza, come <em>sensibilità</em> (SN), <em>specificità</em> (SP), <em>valore predittivo positivo</em> (PPV) e <em>valore predittivo negativo</em> (NPV).</p>
<p>Queste metriche, che si possono calcolare dalla <em>matrice di confusione</em>, ci aiutano a valutare se il modello è efficace nel rilevare la condizione senza includere erroneamente i casi negativi. Analizziamole in dettaglio:</p>
<ul>
<li><p><strong>Sensibilità</strong> (SN): indica la capacità del test di identificare correttamente i veri positivi, cioè le persone con la condizione. Si calcola come la proporzione di veri positivi (<span class="math inline">\(\text{TP}\)</span>) rispetto al totale di persone con la condizione (<span class="math inline">\(\text{TP} + \text{FN}\)</span>):</p>
<p><span class="math display">\[
\frac{\text{TP}}{\text{TP} + \text{FN}} = \frac{86}{86 + 14} = 0.86
\]</span></p></li>
<li><p><strong>Specificità</strong> (SP): misura la capacità del test di identificare correttamente i veri negativi, ossia le persone senza la condizione. Si calcola come la proporzione di veri negativi (<span class="math inline">\(\text{TN}\)</span>) rispetto al totale di persone senza la condizione (<span class="math inline">\(\text{TN} + \text{FP}\)</span>):</p>
<p><span class="math display">\[
\frac{\text{TN}}{\text{TN} + \text{FP}} = \frac{1,478}{1,478 + 422} = 0.78
\]</span></p></li>
<li><p><strong>Valore Predittivo Positivo</strong> (PPV): indica la probabilità che una persona classificata come positiva abbia effettivamente la condizione. Si calcola come la proporzione di veri positivi (<span class="math inline">\(\text{TP}\)</span>) sul totale dei positivi stimati (<span class="math inline">\(\text{TP} + \text{FP}\)</span>):</p>
<p><span class="math display">\[
\frac{\text{TP}}{\text{TP} + \text{FP}} = \frac{86}{86 + 422} = 0.17
\]</span></p></li>
<li><p><strong>Valore Predittivo Negativo</strong> (NPV): rappresenta la probabilità che una persona classificata come negativa non abbia effettivamente la condizione. Si calcola come la proporzione di veri negativi (<span class="math inline">\(\text{TN}\)</span>) sul totale dei negativi stimati (<span class="math inline">\(\text{TN} + \text{FN}\)</span>):</p>
<p><span class="math display">\[
\frac{\text{TN}}{\text{TN} + \text{FN}} = \frac{1,478}{1,478 + 14} = 0.99
\]</span></p></li>
</ul>
<p>Ogni misura è espressa come una proporzione, variando da 0 a 1, dove valori più alti indicano una maggiore accuratezza per ciascun aspetto specifico. Usando queste metriche otteniamo un quadro dettagliato dell’efficacia dello strumento a un determinato cutoff.</p>
</section>
<section id="interpretazione-delle-metriche" class="level3" data-number="80.4.9">
<h3 data-number="80.4.9" class="anchored" data-anchor-id="interpretazione-delle-metriche"><span class="header-section-number">80.4.9</span> Interpretazione delle Metriche</h3>
<p>In questo caso, il nostro strumento mostra: - <strong>Alta sensibilità</strong> (0,86): è efficace nel rilevare chi ha la condizione. - <strong>Bassa specificità</strong> (0,78): classifica erroneamente come positivi molti casi che non hanno la condizione. - <strong>Basso PPV</strong> (0,17): la maggior parte dei casi classificati come positivi sono in realtà negativi, indicando una frequenza elevata di falsi positivi. - <strong>Alto NPV</strong> (0,99): quasi tutti i casi classificati come negativi non hanno la condizione.</p>
<p>Quindi, pur avendo una buona capacità di rilevare i positivi (alta sensibilità), il modello è meno efficace nel limitare i falsi positivi (basso PPV). Questo potrebbe essere accettabile se l’obiettivo è identificare tutti i potenziali casi positivi, anche a costo di includere molti falsi positivi, ma potrebbe non essere ideale se il costo degli errori di falsa positività è elevato.</p>
</section>
</section>
<section id="alcune-stime-di-accuratezza-dipendono-dal-cutoff" class="level2" data-number="80.5">
<h2 data-number="80.5" class="anchored" data-anchor-id="alcune-stime-di-accuratezza-dipendono-dal-cutoff"><span class="header-section-number">80.5</span> Alcune Stime di Accuratezza Dipendono dal Cutoff</h2>
<p>Sensibilità, specificità, PPV e NPV variano in base al cutoff (ovvero, la soglia) per la classificazione. Consideriamo il seguente esempio. Degli alieni visitano la Terra e sviluppano un test per determinare se una bacca è commestibile o non commestibile.</p>
<div id="cell-5" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>sampleSize <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>edibleScores <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(sampleSize, <span class="dv">50</span>, <span class="dv">15</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>inedibleScores <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(sampleSize, <span class="dv">100</span>, <span class="dv">15</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>edibleData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">score =</span> <span class="fu">c</span>(edibleScores, inedibleScores), <span class="at">type =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"edible"</span>, sampleSize), <span class="fu">rep</span>(<span class="st">"inedible"</span>, sampleSize)))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>cutoff <span class="ot">&lt;-</span> <span class="dv">75</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>hist_edible <span class="ot">&lt;-</span> <span class="fu">density</span>(edibleScores, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">150</span>) <span class="sc">%$%</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y) <span class="sc">%&gt;%</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">area =</span> x <span class="sc">&gt;=</span> cutoff)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>hist_edible<span class="sc">$</span>type[hist_edible<span class="sc">$</span>area <span class="sc">==</span> <span class="cn">TRUE</span>] <span class="ot">&lt;-</span> <span class="st">"edible_FP"</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>hist_edible<span class="sc">$</span>type[hist_edible<span class="sc">$</span>area <span class="sc">==</span> <span class="cn">FALSE</span>] <span class="ot">&lt;-</span> <span class="st">"edible_TN"</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>hist_inedible <span class="ot">&lt;-</span> <span class="fu">density</span>(inedibleScores, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">150</span>) <span class="sc">%$%</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y) <span class="sc">%&gt;%</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">area =</span> x <span class="sc">&lt;</span> cutoff)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>hist_inedible<span class="sc">$</span>type[hist_inedible<span class="sc">$</span>area <span class="sc">==</span> <span class="cn">TRUE</span>] <span class="ot">&lt;-</span> <span class="st">"inedible_FN"</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>hist_inedible<span class="sc">$</span>type[hist_inedible<span class="sc">$</span>area <span class="sc">==</span> <span class="cn">FALSE</span>] <span class="ot">&lt;-</span> <span class="st">"inedible_TP"</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>density_data <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(hist_edible, hist_inedible)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>density_data<span class="sc">$</span>type <span class="ot">&lt;-</span> <span class="fu">factor</span>(density_data<span class="sc">$</span>type, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"edible_TN"</span>, <span class="st">"inedible_TP"</span>, <span class="st">"edible_FP"</span>, <span class="st">"inedible_FN"</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La Figura successiva mostra le distribuzioni dei punteggi in base al tipo di bacca. Si può notare come ci sono due distribuzioni distinte, ma con una certa sovrapposizione. Pertanto, qualsiasi cutoff selezionato comporterà almeno alcune classificazioni errate. L’entità della sovrapposizione delle distribuzioni riflette la quantità di errore di misurazione dello strumento rispetto alla caratteristica di interesse.</p>
<div id="cell-7" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> edibleData, <span class="fu">aes</span>(<span class="at">x =</span> score, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">fill =</span> type)) <span class="sc">+</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_density</span>(<span class="at">alpha =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(<span class="at">name =</span> <span class="st">"Tipo di Bacca"</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="fu">viridis</span>(<span class="dv">2</span>)[<span class="dv">1</span>], <span class="fu">viridis</span>(<span class="dv">2</span>)[<span class="dv">2</span>])) <span class="sc">+</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">name =</span> <span class="st">"Frequenza"</span>) </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-4-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>La Figura successiva mostra le distribuzioni dei punteggi in base al tipo di bacca con un cutoff. La linea rossa indica il cutoff: il livello al di sopra del quale le bacche vengono classificate come non commestibili. Ci sono errori su entrambi i lati del cutoff. Sotto il cutoff, ci sono dei falsi negativi (blu): bacche non commestibili erroneamente classificate come commestibili. Sopra il cutoff, ci sono dei falsi positivi (verde): bacche commestibili erroneamente classificate come non commestibili. I costi dei falsi negativi potrebbero includere malattia o morte derivanti dal consumo di bacche non commestibili, mentre i costi dei falsi positivi potrebbero includere maggiore tempo per trovare cibo, insufficienza di cibo e fame.</p>
<div id="cell-9" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> density_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> y, <span class="at">fill =</span> type)) <span class="sc">+</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_ribbon</span>(<span class="at">alpha =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">"Tipo di Bacca"</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">values =</span> <span class="fu">c</span>(<span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">4</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">1</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">3</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">2</span>]),</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">breaks =</span> <span class="fu">c</span>(<span class="st">"edible_TN"</span>, <span class="st">"inedible_TP"</span>, <span class="st">"edible_FP"</span>, <span class="st">"inedible_FN"</span>),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Commestibile: TN"</span>, <span class="st">"Non Commestibile: TP"</span>, <span class="st">"Commestibile: FP"</span>, <span class="st">"Non Commestibile: FN"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> cutoff, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">"Punteggio"</span>) <span class="sc">+</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">name =</span> <span class="st">"Frequenza"</span>) </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-5-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>A seconda dei nostri obiettivi di valutazione, potremmo voler usare un diverso rapporto di selezione modificando il cutoff. La Figura mostra le distribuzioni dei punteggi quando si aumenta il cutoff. Ora ci sono più falsi negativi (blu) e meno falsi positivi (verde). Se alziamo il cutoff per essere più conservativi, il numero di falsi negativi aumenta, mentre il numero di falsi positivi diminuisce. Di conseguenza, aumentando il cutoff, la sensibilità e il valore predittivo negativo (NPV) diminuiscono, mentre la specificità e il valore predittivo positivo (PPV) aumentano. Un cutoff più alto potrebbe essere ottimale se i costi dei falsi positivi sono considerati superiori a quelli dei falsi negativi. Ad esempio, se gli alieni non possono rischiare di mangiare bacche non commestibili perché sono fatali, e ci sono abbastanza bacche commestibili per nutrire la colonia aliena.</p>
<div id="cell-11" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Raise the cutoff</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>cutoff <span class="ot">&lt;-</span> <span class="dv">85</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> density_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> y, <span class="at">fill =</span> type)) <span class="sc">+</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_ribbon</span>(<span class="at">alpha =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">"Tipo di Bacca"</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">values =</span> <span class="fu">c</span>(<span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">4</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">1</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">3</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">2</span>]),</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">breaks =</span> <span class="fu">c</span>(<span class="st">"edible_TN"</span>, <span class="st">"inedible_TP"</span>, <span class="st">"edible_FP"</span>, <span class="st">"inedible_FN"</span>),</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Commestibile: TN"</span>, <span class="st">"Non Commestibile: TP"</span>, <span class="st">"Commestibile: FP"</span>, <span class="st">"Non Commestibile: FN"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> cutoff, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">"Punteggio"</span>) <span class="sc">+</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">name =</span> <span class="st">"Frequenza"</span>) <span class="sc">+</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-6-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In alternativa, possiamo abbassare il cutoff per essere più liberali. La Figura seguente mostra le distribuzioni dei punteggi quando abbassiamo il cutoff. Ora ci sono meno falsi negativi (blu) e più falsi positivi (verde). Abbassando il cutoff, la sensibilità e il NPV aumentano, mentre la specificità e il PPV diminuiscono. Un cutoff più basso potrebbe essere ottimale se i costi dei falsi negativi sono considerati superiori a quelli dei falsi positivi. Ad esempio, se gli alieni non possono rischiare di perdere bacche commestibili perché sono scarse, e mangiare bacche non commestibili comporta solo disagi temporanei.</p>
<div id="cell-13" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lower the cutoff</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>cutoff <span class="ot">&lt;-</span> <span class="dv">65</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> density_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> y, <span class="at">fill =</span> type)) <span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_ribbon</span>(<span class="at">alpha =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">"Tipo di Bacca"</span>,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">values =</span> <span class="fu">c</span>(<span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">4</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">1</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">3</span>], <span class="fu">viridis</span>(<span class="dv">4</span>)[<span class="dv">2</span>]),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">breaks =</span> <span class="fu">c</span>(<span class="st">"edible_TN"</span>, <span class="st">"inedible_TP"</span>, <span class="st">"edible_FP"</span>, <span class="st">"inedible_FN"</span>),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Commestibile: TN"</span>, <span class="st">"Non Commestibile: TP"</span>, <span class="st">"Commestibile: FP"</span>, <span class="st">"Non Commestibile: FN"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> cutoff, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">"Punteggio"</span>) <span class="sc">+</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">name =</span> <span class="st">"Frequenza"</span>) <span class="sc">+</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-7-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In sintesi, sensibilità e specificità variano in base al cutoff utilizzato per la classificazione. Se aumentiamo il cutoff, la specificità e il PPV aumentano, mentre la sensibilità e il NPV diminuiscono. Se abbassiamo il cutoff, la sensibilità e il NPV aumentano, mentre la specificità e il PPV diminuiscono. Pertanto, il cutoff ottimale dipende dai costi associati ai falsi negativi e ai falsi positivi. Se i falsi negativi sono più costosi, dovremmo impostare un cutoff basso; se i falsi positivi sono più costosi, dovremmo impostare un cutoff alto.</p>
</section>
<section id="teoria-della-detezione-del-segnale" class="level2" data-number="80.6">
<h2 data-number="80.6" class="anchored" data-anchor-id="teoria-della-detezione-del-segnale"><span class="header-section-number">80.6</span> Teoria della Detezione del Segnale</h2>
<p>La <em>teoria della detezione del segnale</em> (Signal Detection Theory, SDT) è una teoria probabilistica utilizzata per il rilevamento di uno stimolo (segnale) all’interno di un insieme di stimoli che include anche stimoli non target (rumore). La SDT è nata durante lo sviluppo del radar (<strong>RA</strong>dio <strong>D</strong>etection <strong>A</strong>nd <strong>R</strong>anging) e del sonar (<strong>SO</strong>und <strong>N</strong>avigation <strong>A</strong>nd <strong>R</strong>anging) durante la Seconda Guerra Mondiale, basandosi su ricerche in ambito sensoriale-percettivo. Il settore militare desiderava determinare quali oggetti rilevati da radar/sonar fossero effettivamente aerei o sottomarini nemici, e quali fossero solo rumore (ad esempio, oggetti diversi nell’ambiente).</p>
<p>La SDT ha permesso di valutare il numero di errori commessi dagli operatori (cioè, quanto fossero precisi) e di scomporre tali errori in diverse categorie. La teoria distingue tra <em>sensibilità</em> e <em>bias</em>. Nella SDT, la <em>sensibilità</em> (o discriminabilità) è la capacità di un test di distinguere tra uno stimolo target e stimoli non target, ossia quanto bene il test riesca a rilevare il segnale tra i rumori. Il <em>bias</em> rappresenta invece la tendenza del test a sovrastimare o sottostimare la probabilità di un evento target rispetto al tasso reale di occorrenza di tale evento.</p>
<p>Alcuni operatori radar/sonar non erano molto sensibili alla differenza tra segnale e rumore, a causa di fattori come l’età o la capacità di distinguere sottili variazioni di segnale. Gli individui con bassa sensibilità, che quindi non riuscivano a distinguere efficacemente tra segnale e rumore, venivano esclusi, poiché la sensibilità era considerata una competenza che difficilmente si può insegnare. Altri operatori, pur avendo una buona sensibilità, mostravano bias sistematici o scarsa <em>calibrazione</em>, cioè commettevano errori sistematici nel giudicare i segnali, ad esempio sovra-rifiutando o sotto-rifiutando il target.</p>
<p>Sovra-rifiutare significa produrre molti <em>falsi negativi</em> (cioè, giudicare un segnale sicuro quando in realtà non lo è), mentre sotto-rifiutare genera molti <em>falsi positivi</em> (cioè, giudicare un segnale come pericoloso quando in realtà non lo è). Un operatore con buona sensibilità ma bias sistematico veniva considerato più facile da addestrare rispetto a chi aveva una bassa sensibilità. Gli operatori radar e sonar venivano quindi selezionati in base alla loro sensibilità nel distinguere tra segnale e rumore, e poi addestrati per migliorare la calibrazione e ridurre il bias sistematico, evitando così di sovra- o sotto-rifiutare gli stimoli.</p>
<p>Anche se la SDT è stata sviluppata inizialmente durante la Seconda Guerra Mondiale, oggi ha un ruolo importante in molti ambiti della scienza e della medicina. Un esempio in medicina è il rilevamento di tumori nella radiologia. La SDT è fondamentale anche in psicologia, specialmente nella psicologia cognitiva. Ad esempio, ricerche sulla percezione sociale hanno dimostrato che gli uomini tendono a mostrare una scarsa sensibilità nel distinguere le manifestazioni di interesse sessuale nelle donne, confondendo la cordialità con l’interesse sessuale. Inoltre, gli uomini tendono ad avere un bias sistematico, sovrastimando l’interesse sessuale delle donne nei loro confronti, mostrando così una soglia troppo bassa nel giudicare tali segnali.</p>
<p>Le metriche SDT di sensibilità includono <a href="#dPrimeSDT"><span class="math inline">\(d'\)</span></a> (d-prime), <a href="#aSDT"><span class="math inline">\(A\)</span></a> (o <span class="math inline">\(A'\)</span>), e l’area sotto la curva ROC (Receiver Operating Characteristic). Le metriche di bias includono <a href="#betaSDT"><span class="math inline">\(\beta\)</span></a>, <a href="#cSDT"><span class="math inline">\(c\)</span></a> e <a href="#bSDT"><span class="math inline">\(b\)</span></a>.</p>
<section id="curva-roc-receiver-operating-characteristic" class="level3" data-number="80.6.1">
<h3 data-number="80.6.1" class="anchored" data-anchor-id="curva-roc-receiver-operating-characteristic"><span class="header-section-number">80.6.1</span> Curva ROC (Receiver Operating Characteristic)</h3>
<p>L’asse delle x della curva ROC rappresenta il tasso di falsi allarmi o tasso di falsi positivi (<span class="math inline">\(1 -\)</span> specificità). L’asse delle y rappresenta il tasso di successi o tasso di veri positivi (sensibilità). La curva ROC traccia la combinazione tra sensibilità e specificità per ogni possibile valore di cutoff.</p>
<p>Iniziamo con un cutoff pari a zero (in alto a destra sulla curva ROC). In questo caso, la sensibilità è pari a 1.0 e la specificità è 0, e il punto corrispondente viene tracciato sulla curva. Con un cutoff di zero, il test decide di agire su ogni stimolo (quindi il test è estremamente liberale). Aumentiamo progressivamente il cutoff e tracciamo la sensibilità e la specificità a ogni valore di cutoff. All’aumentare del cutoff, la sensibilità diminuisce e la specificità aumenta.</p>
<p>Terminiamo con il valore di cutoff più alto possibile, dove la sensibilità è pari a 0 e la specificità è 1.0 (in altre parole, il test non agisce mai; quindi è il massimo della conservatività). Ogni punto sulla curva ROC corrisponde a una coppia di tasso di successi (sensibilità) e tasso di falsi allarmi (falsi positivi) risultante da uno specifico valore di cutoff. Dopodiché, possiamo collegare i punti con delle linee o curve per ottenere la curva ROC.</p>
<p>La Figura seguente mostra un esempio empirico di curva ROC, dove le linee connettono i tassi di successi e di falsi allarmi.</p>
<div id="cell-16" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(aSAH<span class="sc">$</span>outcome, aSAH<span class="sc">$</span>s100b), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-8-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Creiamo ora una curva ROC lisciata, dove viene tracciata una curva continua e adattata per connettere i tassi di successi e di falsi allarmi.</p>
<div id="cell-18" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(aSAH<span class="sc">$</span>outcome, aSAH<span class="sc">$</span>s100b, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-9-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="area-sotto-la-curva-roc-auc" class="level3" data-number="80.6.2">
<h3 data-number="80.6.2" class="anchored" data-anchor-id="area-sotto-la-curva-roc-auc"><span class="header-section-number">80.6.2</span> Area Sotto la Curva ROC (AUC)</h3>
<p>Le metodologie ROC possono essere utilizzate per confrontare e calcolare il potere discriminativo degli strumenti di misurazione, senza essere influenzati da fattori come il <em>selection ratio</em>, il <em>base rate</em> e i costi e benefici associati. L’analisi ROC fornisce un indice quantitativo di quanto bene uno strumento possa prevedere un segnale di interesse o discriminare tra segnali diversi. Questo approccio ci aiuta a capire con quale frequenza la nostra valutazione è corretta.</p>
<p>Se scegliamo casualmente due osservazioni, e una è corretta mentre l’altra è sbagliata, la precisione sarebbe del 50%, ma questo rifletterebbe una risposta casuale, quindi inutile. L’area geometrica sotto la curva ROC riflette l’accuratezza discriminativa della misura. Questo indice è noto come AUC (Area Under the Curve) della curva ROC. AUC quantifica il potere discriminativo di un test. Più precisamente, AUC rappresenta la probabilità che, selezionando casualmente un target e un non-target, il test classifichi correttamente il target come tale. I valori dell’AUC variano da 0.0 a 1.0, dove 0.5 rappresenta la precisione casuale, come indicato dalla linea diagonale nella curva ROC. Un test è utile nella misura in cui la sua curva ROC si trova sopra la linea diagonale, indicando che la sua accuratezza discriminativa è superiore al caso.</p>
<div id="cell-20" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(aSAH<span class="sc">$</span>outcome, aSAH<span class="sc">$</span>s100b, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">auc.polygon =</span> <span class="cn">TRUE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-10-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-21" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulazione dei dati per AUC</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>simulateDataFromAUC <span class="ot">&lt;-</span> <span class="cf">function</span>(auc, n) {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    t <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">log</span>(<span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> auc)<span class="sc">**</span><span class="dv">2</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> t <span class="sc">-</span> ((<span class="fl">2.515517</span> <span class="sc">+</span> <span class="fl">0.802853</span> <span class="sc">*</span> t <span class="sc">+</span> <span class="fl">0.0103328</span> <span class="sc">*</span> t<span class="sc">**</span><span class="dv">2</span>) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fl">1.432788</span> <span class="sc">*</span> t <span class="sc">+</span> <span class="fl">0.189269</span> <span class="sc">*</span> t<span class="sc">**</span><span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.001308</span> <span class="sc">*</span> t<span class="sc">**</span><span class="dv">3</span>))</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    d <span class="ot">&lt;-</span> z <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="dv">2</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(n <span class="sc">/</span> <span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">0</span>), <span class="fu">rnorm</span>(n <span class="sc">/</span> <span class="dv">2</span>, <span class="at">mean =</span> d))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, n <span class="sc">/</span> <span class="dv">2</span>), <span class="fu">rep</span>(<span class="dv">1</span>, n <span class="sc">/</span> <span class="dv">2</span>))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(data)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">52242</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>auc60 <span class="ot">&lt;-</span> <span class="fu">simulateDataFromAUC</span>(.<span class="dv">60</span>, <span class="dv">50000</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>auc70 <span class="ot">&lt;-</span> <span class="fu">simulateDataFromAUC</span>(.<span class="dv">70</span>, <span class="dv">50000</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>auc80 <span class="ot">&lt;-</span> <span class="fu">simulateDataFromAUC</span>(.<span class="dv">80</span>, <span class="dv">50000</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>auc90 <span class="ot">&lt;-</span> <span class="fu">simulateDataFromAUC</span>(.<span class="dv">90</span>, <span class="dv">50000</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>auc95 <span class="ot">&lt;-</span> <span class="fu">simulateDataFromAUC</span>(.<span class="dv">95</span>, <span class="dv">50000</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>auc99 <span class="ot">&lt;-</span> <span class="fu">simulateDataFromAUC</span>(.<span class="dv">99</span>, <span class="dv">50000</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(y <span class="sc">~</span> x, auc60, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">print.auc.x =</span> .<span class="dv">52</span>, <span class="at">print.auc.y =</span> .<span class="dv">61</span>, <span class="at">print.auc.pattern =</span> <span class="st">"%.2f"</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(y <span class="sc">~</span> x, auc70, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">print.auc.x =</span> .<span class="dv">6</span>, <span class="at">print.auc.y =</span> .<span class="dv">67</span>, <span class="at">print.auc.pattern =</span> <span class="st">"%.2f"</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(y <span class="sc">~</span> x, auc80, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">print.auc.x =</span> .<span class="dv">695</span>, <span class="at">print.auc.y =</span> .<span class="dv">735</span>, <span class="at">print.auc.pattern =</span> <span class="st">"%.2f"</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(y <span class="sc">~</span> x, auc90, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">print.auc.x =</span> .<span class="dv">805</span>, <span class="at">print.auc.y =</span> .<span class="dv">815</span>, <span class="at">print.auc.pattern =</span> <span class="st">"%.2f"</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(y <span class="sc">~</span> x, auc95, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">print.auc.x =</span> .<span class="dv">875</span>, <span class="at">print.auc.y =</span> .<span class="dv">865</span>, <span class="at">print.auc.pattern =</span> <span class="st">"%.2f"</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(y <span class="sc">~</span> x, auc99, <span class="at">smooth =</span> <span class="cn">TRUE</span>), <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>, <span class="at">print.auc.x =</span> .<span class="dv">94</span>, <span class="at">print.auc.y =</span> .<span class="dv">94</span>, <span class="at">print.auc.pattern =</span> <span class="st">"%.2f"</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-11-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Ad esempio, se l’AUC è pari a 0.75, ciò significa che il punteggio complessivo di un individuo che possiede la caratteristica in questione sarà più alto nel 75% dei casi rispetto a quello di un individuo che non la possiede. In termini più semplici, l’AUC fornisce la probabilità che lo strumento classifichi correttamente, se scegliamo casualmente un esito positivo e uno negativo.</p>
<p>L’AUC è un indice più robusto rispetto alla percentuale di accuratezza perché la percentuale di accuratezza può essere influenzata da fattori come il base rate. L’AUC misura quanto un test è migliore del caso nel discriminare tra esiti diversi. Inoltre, è utile come indicatore generale di accuratezza discriminativa, poiché mostra quanto un test sia accurato su tutti i possibili cutoff.</p>
<p>Anche se conoscere l’accuratezza del test a ogni cutoff può essere utile per selezionare il cutoff ottimale, nella realtà non siamo interessati a tutti i possibili cutoff, poiché non tutti gli errori hanno lo stesso costo.</p>
<p>Iniziare {#gettingStarted-prediction}</p>
<p>Caricare le Librerie {#loadLibraries-prediction}</p>
<p>Preparare i Dati {#prepareData-prediction} Caricamento dei Dati {#loadData-prediction}</p>
<p>Il dataset aSAH del pacchetto pROC contiene i punteggi dei test (s100b) e gli esiti clinici (outcome) di pazienti.</p>
<div id="cell-25" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(aSAH)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>mydataSDT <span class="ot">&lt;-</span> aSAH</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per garantire la riproducibilità, imposto il seed qui sotto. L’utilizzo dello stesso seed garantirà gli stessi risultati ogni volta. Non c’è nulla di speciale in questo seed specifico.</p>
<div id="cell-27" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">52242</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>testScore <span class="ot">&lt;-</span> mydataSDT<span class="sc">$</span>s100b</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>mydataSDT <span class="ot">&lt;-</span> mydataSDT <span class="sc">%&gt;%</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">testScoreSimple =</span> <span class="fu">ntile</span>(testScore, <span class="dv">10</span>))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>predictedProbability <span class="ot">&lt;-</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    (mydataSDT<span class="sc">$</span>s100b <span class="sc">-</span> <span class="fu">min</span>(mydataSDT<span class="sc">$</span>s100b, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)) <span class="sc">/</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        (<span class="fu">max</span>(mydataSDT<span class="sc">$</span>s100b, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="sc">-</span> <span class="fu">min</span>(mydataSDT<span class="sc">$</span>s100b, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>continuousOutcome <span class="ot">&lt;-</span> mydataSDT<span class="sc">$</span>testScore <span class="sc">+</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rnorm</span>(<span class="fu">nrow</span>(mydataSDT), <span class="at">mean =</span> <span class="fl">0.20</span>, <span class="at">sd =</span> <span class="fl">0.20</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorder <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorder[mydataSDT<span class="sc">$</span>outcome <span class="sc">==</span> <span class="st">"Good"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorder[mydataSDT<span class="sc">$</span>outcome <span class="sc">==</span> <span class="st">"Poor"</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La curva ROC (Receiver Operating Characteristic) mostra la combinazione tra il tasso di successo (o sensibilità) e il tasso di falsi allarmi (<span class="math inline">\(1 - \text{specificità}\)</span>) per ogni possibile soglia di cutoff. La curva dimostra come, all’aumentare della soglia (diventando più conservativa), la sensibilità diminuisce e la specificità aumenta, e viceversa.</p>
<p>Le curve ROC possono essere generate utilizzando il pacchetto pROC, e gli esempi mostrano che la misura ha un’accuratezza moderata—è più accurata del caso, ma c’è margine di miglioramento.</p>
<p>Curva ROC Empirica {#empiricalROC} Il codice per generare una curva ROC empirica è mostrato qui sotto, e il grafico è visibile in Figura <span class="citation" data-cites="ref">(<a href="../../99-references.html#ref-ref" role="doc-biblioref"><strong>ref?</strong></a>)</span>(fig</p>
<div id="cell-29" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>rocCurve <span class="ot">&lt;-</span> <span class="fu">roc</span>(<span class="at">data =</span> mydataSDT, <span class="at">response =</span> disorder, <span class="at">predictor =</span> testScore, <span class="at">smooth =</span> <span class="cn">FALSE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-30" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rocCurve, <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-15-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Una curva ROC empirica con i cutoff sovrapposti è mostrata</p>
<div id="cell-32" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">prediction</span>(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">na.omit</span>(mydataSDT[, <span class="fu">c</span>(<span class="st">"testScoreSimple"</span>, <span class="st">"disorder"</span>)])<span class="sc">$</span>testScoreSimple,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">na.omit</span>(mydataSDT[, <span class="fu">c</span>(<span class="st">"testScoreSimple"</span>, <span class="st">"disorder"</span>)])<span class="sc">$</span>disorder</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf, <span class="at">print.cutoffs.at =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">11</span>, <span class="at">text.adj =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.05</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-16-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Curva ROC Liscia si ottiene nel modo seguente.</p>
<div id="cell-34" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>rocCurveSmooth <span class="ot">&lt;-</span> <span class="fu">roc</span>(<span class="at">data =</span> mydataSDT, <span class="at">response =</span> disorder, <span class="at">predictor =</span> testScore, <span class="at">smooth =</span> <span class="cn">TRUE</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rocCurveSmooth, <span class="at">legacy.axes =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-17-output-1.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Statistica di Youden J {#youdenJ} La soglia della statistica di Youden J è il punto in cui il test ha la massima combinazione (somma) di sensibilità e specificità: <span class="math inline">\(\text{max}(\text{sensitivity} + \text{specificity} - 1)\)</span>.</p>
<div id="cell-36" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>youdenJ <span class="ot">&lt;-</span> <span class="fu">coords</span>(rocCurve, <span class="at">x =</span> <span class="st">"best"</span>, <span class="at">best.method =</span> <span class="st">"youden"</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>youdenJthreshold <span class="ot">&lt;-</span> youdenJ<span class="sc">$</span>threshold</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>youdenJspecificity <span class="ot">&lt;-</span> youdenJ<span class="sc">$</span>specificity</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>youdenJsensitivity <span class="ot">&lt;-</span> youdenJ<span class="sc">$</span>sensitivity</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>youdenJ</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A data.frame: 1 x 3</caption>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th" scope="col">threshold</th>
<th data-quarto-table-cell-role="th" scope="col">specificity</th>
<th data-quarto-table-cell-role="th" scope="col">sensitivity</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th" scope="col">&lt;dbl&gt;</th>
<th data-quarto-table-cell-role="th" scope="col">&lt;dbl&gt;</th>
<th data-quarto-table-cell-role="th" scope="col">&lt;dbl&gt;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.205</td>
<td>0.8055556</td>
<td>0.6341463</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Per questo test, la soglia ottimale secondo la statistica di Youden J è <span class="math inline">\(r youdenJthreshold\)</span>, con una sensibilità di <span class="math inline">\(r youdenJsensitivity\)</span> e una specificità di <span class="math inline">\(r youdenJspecificity\)</span>.</p>
<p>Punto più vicino alla parte in alto a sinistra della curva ROC {#topLeftROC} Il punto più vicino alla parte superiore sinistra della curva ROC, dove sensibilità e specificità sono perfette, è dato da: <span class="math inline">\(\text{min}[(1 - \text{sensitivity})^2 + (1 - \text{specificity})^2]\)</span>.</p>
<div id="cell-39" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>closestTopLeft <span class="ot">&lt;-</span> <span class="fu">coords</span>(rocCurve, <span class="at">x =</span> <span class="st">"best"</span>, <span class="at">best.method =</span> <span class="st">"closest.topleft"</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>closestTopLeftthreshold <span class="ot">&lt;-</span> closestTopLeft<span class="sc">$</span>threshold</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>closestTopLeftspecificity <span class="ot">&lt;-</span> closestTopLeft<span class="sc">$</span>specificity</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>closestTopLeftsensitivity <span class="ot">&lt;-</span> closestTopLeft<span class="sc">$</span>sensitivity</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>closestTopLeft</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A data.frame: 1 x 3</caption>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th" scope="col">threshold</th>
<th data-quarto-table-cell-role="th" scope="col">specificity</th>
<th data-quarto-table-cell-role="th" scope="col">sensitivity</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th" scope="col">&lt;dbl&gt;</th>
<th data-quarto-table-cell-role="th" scope="col">&lt;dbl&gt;</th>
<th data-quarto-table-cell-role="th" scope="col">&lt;dbl&gt;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.205</td>
<td>0.8055556</td>
<td>0.6341463</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Per questo test, la combinazione di sensibilità e specificità è ottimale alla soglia di <span class="math inline">\(r closestTopLeftthreshold\)</span>, con una sensibilità di <span class="math inline">\(r closestTopLeftsensitivity\)</span> e una specificità di <span class="math inline">\(r closestTopLeftspecificity\)</span>.</p>
</section>
</section>
<section id="predictionAccuracy" class="level2" data-number="80.7">
<h2 data-number="80.7" class="anchored" data-anchor-id="predictionAccuracy"><span class="header-section-number">80.7</span> Accuratezza della Predizione attraverso i Cutoff</h2>
<p>Esistono due dimensioni principali dell’accuratezza: (1) la <em>discriminazione</em> (ad esempio, <a href="#sensitivity">sensibilità</a>, <a href="#specificity">specificità</a>, <a href="#auc">area sotto la curva ROC</a>) e (2) la <em>calibrazione</em>. Alcuni indici generali di accuratezza combinano la discriminazione e la calibrazione.</p>
<p>Il pacchetto <a href="https://github.com/DevPsyLab/petersenlab"><code>petersenlab</code></a> include la funzione <code>accuracyOverall()</code>, che stima l’accuratezza della predizione su tutti i cutoff.</p>
<p>Ecco un esempio di codice che utilizza questa funzione:</p>
<div id="cell-41" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="20">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracyOverall</span>(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">predicted =</span> mydataSDT<span class="sc">$</span>testScore,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">actual =</span> mydataSDT<span class="sc">$</span>disorder</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">t</span>() <span class="sc">%&gt;%</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(., <span class="dv">2</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracyOverall</span>(</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">predicted =</span> mydataSDT<span class="sc">$</span>testScore,</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">actual =</span> mydataSDT<span class="sc">$</span>disorder,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">dropUndefined =</span> <span class="cn">TRUE</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">t</span>() <span class="sc">%&gt;%</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(., <span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A matrix: 12 x 1 of type dbl</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">ME</td>
<td>-0.12</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">MAE</td>
<td>0.34</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">MSE</td>
<td>0.21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">RMSE</td>
<td>0.46</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">MPE</td>
<td>-Inf</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">MAPE</td>
<td>Inf</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">sMAPE</td>
<td>82.72</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">MASE</td>
<td>0.74</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">RMSLE</td>
<td>0.30</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">rsquared</td>
<td>0.17</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">rsquaredAdj</td>
<td>0.17</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">rsquaredPredictive</td>
<td>0.12</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A matrix: 12 x 1 of type dbl</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">ME</td>
<td>-0.12</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">MAE</td>
<td>0.34</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">MSE</td>
<td>0.21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">RMSE</td>
<td>0.46</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">MPE</td>
<td>60.29</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">MAPE</td>
<td>65.51</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">sMAPE</td>
<td>82.72</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">MASE</td>
<td>0.74</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">RMSLE</td>
<td>0.30</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">rsquared</td>
<td>0.17</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">rsquaredAdj</td>
<td>0.17</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">rsquaredPredictive</td>
<td>0.12</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>In questo esempio, la funzione <code>accuracyOverall()</code> calcola l’accuratezza complessiva della predizione su tutta la gamma di cutoff disponibili, fornendo una sintesi del grado di accuratezza globale del modello.</p>
</section>
<section id="calibration" class="level2" data-number="80.8">
<h2 data-number="80.8" class="anchored" data-anchor-id="calibration"><span class="header-section-number">80.8</span> Calibrazione</h2>
<p>Quando si tratta di un risultato categorico, la calibrazione è il grado in cui una stima probabilistica di un evento riflette la reale probabilità sottostante di quell’evento.<br>
Quando si tratta di un risultato continuo, la calibrazione indica quanto i valori previsti siano vicini ai valori effettivi osservati.<br>
L’importanza di esaminare la calibrazione, oltre alla <em>discriminazione</em>, è descritta da Lindhiem (2020).</p>
<p>La calibrazione è diventata centrale nella valutazione dell’accuratezza delle previsioni meteorologiche.<br>
Ad esempio, nei giorni in cui un meteorologo prevede il 60% di possibilità di pioggia, dovrebbe effettivamente piovere circa il 60% delle volte.<br>
Grazie ai progressi nella comprensione scientifica dei sistemi meteorologici, le previsioni della pioggia sono diventate più accurate.<br>
Le previsioni della National Weather Service, per esempio, sono ben calibrate.<br>
Tuttavia, le previsioni di pioggia fatte da meteorologi televisivi locali possono essere esagerate per aumentare l’audience (Silver, 2012).<br>
Curiosamente, alcune previsioni di pioggia di The Weather Channel risultano miscalibrate in certe condizioni (Bickel, 2008).<br>
Ad esempio, nei giorni in cui viene prevista una probabilità di pioggia del 20%, la probabilità reale è in realtà intorno al 5%.<br>
Questa miscalibrazione è deliberata, poiché le persone tendono a essere più arrabbiate se viene detto loro che non pioverà e invece piove (falsi negativi) rispetto al contrario (falsi positivi).<br>
Come osserva Silver (2012), “Se piove quando non dovrebbe, le persone si arrabbiano con il meteorologo, mentre una giornata inaspettatamente soleggiata è vista come un bonus fortuito.”</p>
<p>La calibrazione non è importante solo per le previsioni meteorologiche, ma anche per la valutazione psicologica.<br>
Esistono diversi metodi per esaminare la calibrazione, come i <em>Brier Scores</em>, il test di Hosmer-Lemeshow, lo <em>z</em> di Spiegelhalter e la differenza media tra i valori previsti e osservati a diversi intervalli di soglie, rappresentata graficamente tramite un <em>calibration plot</em>.</p>
<section id="calibrationPlot" class="level3" data-number="80.8.1">
<h3 data-number="80.8.1" class="anchored" data-anchor-id="calibrationPlot"><span class="header-section-number">80.8.1</span> Calibration Plot</h3>
<p>Un <em>calibration plot</em> può aiutare a individuare la miscalibrazione.<br>
Questo grafico rappresenta la probabilità prevista di un evento sull’asse x e la probabilità effettiva osservata sull’asse y.<br>
Le previsioni sono suddivise in gruppi (spesso 10).<br>
La linea diagonale rappresenta previsioni perfettamente calibrate.<br>
Quando le previsioni si discostano da questa linea, indicano miscalibrazione.<br>
Esistono quattro pattern generali di miscalibrazione: <em>overextremity</em>, <em>underextremity</em>, <em>overprediction</em>, e <em>underprediction</em>.</p>
<ul>
<li><em>Overextremity</em> si verifica quando le probabilità previste sono troppo vicine agli estremi (zero o uno).<br>
</li>
<li><em>Underextremity</em> accade quando le probabilità previste sono troppo lontane dagli estremi.<br>
</li>
<li><em>Overprediction</em> si ha quando le probabilità previste sono costantemente maggiori di quelle osservate.<br>
</li>
<li><em>Underprediction</em> si ha quando le probabilità previste sono costantemente minori di quelle osservate.</li>
</ul>
<p>Per generare un <em>calibration plot</em>, possiamo utilizzare il pacchetto <code>PredictABEL</code>. Di seguito è riportato un esempio di codice in R per creare questo grafico:</p>
<div id="cell-44" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="21">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(aSAH)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>mydataSDT <span class="ot">&lt;-</span> aSAH</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">52242</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>testScore <span class="ot">&lt;-</span> mydataSDT<span class="sc">$</span>s100b</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>mydataSDT <span class="ot">&lt;-</span> mydataSDT <span class="sc">%&gt;%</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">testScoreSimple =</span> <span class="fu">ntile</span>(testScore, <span class="dv">10</span>))</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>predictedProbability <span class="ot">&lt;-</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    (mydataSDT<span class="sc">$</span>s100b <span class="sc">-</span> <span class="fu">min</span>(mydataSDT<span class="sc">$</span>s100b, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)) <span class="sc">/</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        (<span class="fu">max</span>(mydataSDT<span class="sc">$</span>s100b, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="sc">-</span> <span class="fu">min</span>(mydataSDT<span class="sc">$</span>s100b, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>continuousOutcome <span class="ot">&lt;-</span> mydataSDT<span class="sc">$</span>testScore <span class="sc">+</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rnorm</span>(<span class="fu">nrow</span>(mydataSDT), <span class="at">mean =</span> <span class="fl">0.20</span>, <span class="at">sd =</span> <span class="fl">0.20</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorder <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorder[mydataSDT<span class="sc">$</span>outcome <span class="sc">==</span> <span class="st">"Good"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorder[mydataSDT<span class="sc">$</span>outcome <span class="sc">==</span> <span class="st">"Poor"</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>colNumberOutcome <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">names</span>(mydataSDT) <span class="sc">==</span> <span class="st">"disorder"</span>)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>myDataNoMissing <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(mydataSDT)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-45" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="22">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotCalibration</span>(</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> <span class="fu">na.omit</span>(myDataNoMissing),</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">cOutcome =</span> colNumberOutcome,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">predRisk =</span> myDataNoMissing<span class="sc">$</span>predictedProbability,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">groups =</span> <span class="dv">10</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<dl>
    <dt>$Table_HLtest</dt>
        <dd>
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A matrix: 10 x 5 of type dbl</caption>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th" scope="col">total</th>
<th data-quarto-table-cell-role="th" scope="col">meanpred</th>
<th data-quarto-table-cell-role="th" scope="col">meanobs</th>
<th data-quarto-table-cell-role="th" scope="col">predicted</th>
<th data-quarto-table-cell-role="th" scope="col">observed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">[0.0000,0.0245)</td>
<td>20</td>
<td>0.013</td>
<td>0.200</td>
<td>0.26</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">0.0245</td>
<td>7</td>
<td>0.025</td>
<td>0.143</td>
<td>0.17</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">0.0294</td>
<td>8</td>
<td>0.029</td>
<td>0.250</td>
<td>0.24</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">[0.0343,0.0441)</td>
<td>14</td>
<td>0.036</td>
<td>0.214</td>
<td>0.50</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">[0.0441,0.0588)</td>
<td>11</td>
<td>0.051</td>
<td>0.364</td>
<td>0.56</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">[0.0588,0.0686)</td>
<td>8</td>
<td>0.061</td>
<td>0.125</td>
<td>0.49</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">[0.0686,0.1324)</td>
<td>12</td>
<td>0.094</td>
<td>0.417</td>
<td>1.12</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">[0.1324,0.2059)</td>
<td>12</td>
<td>0.165</td>
<td>0.583</td>
<td>1.98</td>
<td>7</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">[0.2059,0.2598)</td>
<td>10</td>
<td>0.222</td>
<td>0.300</td>
<td>2.22</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">[0.2598,1.0000]</td>
<td>11</td>
<td>0.408</td>
<td>1.000</td>
<td>4.49</td>
<td>11</td>
</tr>
</tbody>
</table>

</dd>
    <dt>$Chi_square</dt>
        <dd>154.23</dd>
    <dt>$df</dt>
        <dd>8</dd>
    <dt>$p_value</dt>
        <dd>0</dd>
</dl>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_prediction_files/figure-html/cell-22-output-2.png" width="720" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Questo <em>calibration plot</em> mostra che le probabilità previste erano consistentemente inferiori a quelle effettive osservate, suggerendo un problema di <em>underprediction</em>. Per correggere questa miscalibrazione, le probabilità previste dovrebbero essere aumentate affinché risultino coerenti con quelle osservate.</p>
<section id="brierScores" class="level4" data-number="80.8.1.1">
<h4 data-number="80.8.1.1" class="anchored" data-anchor-id="brierScores"><span class="header-section-number">80.8.1.1</span> Brier Scores</h4>
</section>
<section id="brierScores" class="level4" data-number="80.8.1.2">
<h4 data-number="80.8.1.2" class="anchored" data-anchor-id="brierScores"><span class="header-section-number">80.8.1.2</span> Brier Scores</h4>
<p>I punteggi di Brier (<em>Brier scores</em>) offrono una misura di accuratezza per le previsioni probabilistiche, valutando quanto le probabilità previste si avvicinino ai risultati reali. Questo punteggio è calcolato come la media dei quadrati delle differenze tra le probabilità previste e i risultati osservati, permettendo di valutare la qualità delle previsioni considerando sia errori di sovrastima che di sottostima.</p>
<p>Un punteggio di Brier basso indica una migliore calibrazione delle previsioni, con un valore di 0 che rappresenta una previsione perfettamente calibrata (cioè, le probabilità previste coincidono esattamente con i risultati osservati). Valori più vicini a 1 indicano invece una calibrazione peggiore, suggerendo che le previsioni si discostano ampiamente dai risultati effettivi.</p>
<p>Il pacchetto <code>rms</code> di R può essere utilizzato per calcolare i punteggi di Brier, come mostrato nell’esempio seguente:</p>
<div id="cell-48" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="46">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">val.prob</span>(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>predictedProbability,</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>disorder,</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">pl =</span> <span class="cn">FALSE</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>)[<span class="st">"Brier"</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<strong>Brier:</strong> 0.261212926954575
</div>
</div>
<p>In sintesi, il punteggio di Brier rappresenta una misura sintetica della precisione e della calibrazione di un modello predittivo: quanto più è basso, tanto maggiore è la capacità del modello di riflettere accuratamente le probabilità reali.</p>
</section>
</section>
</section>
<section id="matrice-di-confusione" class="level2" data-number="80.9">
<h2 data-number="80.9" class="anchored" data-anchor-id="matrice-di-confusione"><span class="header-section-number">80.9</span> Matrice di Confusione</h2>
<p>Una matrice di confusione (detta anche tabella 2x2 di accuratezza, tabella di cross-tabulation o tabella di contingenza) è una matrice utilizzata per i dati categoriali che mostra l’esito predetto su una dimensione e l’esito reale (la verità) sull’altra. Se le predizioni e gli esiti sono dicotomici, la matrice di confusione è una matrice 2x2 con due righe e due colonne che rappresentano le quattro possibili combinazioni previste-reali (i cosiddetti outcome decisionali). In questo caso, la matrice di confusione fornisce un conteggio tabellare dei casi corretti (true positives e true negatives) rispetto agli errori (false positives e false negatives).</p>
<p>Conteggio Assoluto {#confusionMatrix-number}</p>
<p>È possibile visualizzare i dati di una matrice di confusione utilizzando il seguente codice:</p>
<div id="cell-51" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="33">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>cutoff <span class="ot">&lt;-</span> <span class="fl">0.205</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>diagnosis <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>diagnosis[mydataSDT<span class="sc">$</span>testScore <span class="sc">&lt;</span> cutoff] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>diagnosis[mydataSDT<span class="sc">$</span>testScore <span class="sc">&gt;=</span> cutoff] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>diagnosisFactor <span class="ot">&lt;-</span> <span class="fu">factor</span>(</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>diagnosis,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Decision: Diagnosis"</span>, <span class="st">"Decision: No Diagnosis"</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>mydataSDT<span class="sc">$</span>disorderFactor <span class="ot">&lt;-</span> <span class="fu">factor</span>(</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>disorder,</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Truth: Disorder"</span>, <span class="st">"Truth: No Disorder"</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(mydataSDT<span class="sc">$</span>diagnosisFactor, mydataSDT<span class="sc">$</span>disorderFactor)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>                        
                         Truth: Disorder Truth: No Disorder
  Decision: Diagnosis                 26                 14
  Decision: No Diagnosis              15                 58</code></pre>
</div>
</div>
<p>Conteggio con Margini Aggiunti {#confusionMatrix-numberMargins}</p>
<p>Per aggiungere i margini ai conteggi assoluti:</p>
<div id="cell-53" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="34">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">addmargins</span>(<span class="fu">table</span>(mydataSDT<span class="sc">$</span>diagnosisFactor, mydataSDT<span class="sc">$</span>disorderFactor))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A table: 3 x 3 of type dbl</caption>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th" scope="col">Truth: Disorder</th>
<th data-quarto-table-cell-role="th" scope="col">Truth: No Disorder</th>
<th data-quarto-table-cell-role="th" scope="col">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">Decision: Diagnosis</td>
<td>26</td>
<td>14</td>
<td>40</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">Decision: No Diagnosis</td>
<td>15</td>
<td>58</td>
<td>73</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">Sum</td>
<td>41</td>
<td>72</td>
<td>113</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Per calcolare le proporzioni:</p>
<div id="cell-55" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="35">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(mydataSDT<span class="sc">$</span>diagnosisFactor, mydataSDT<span class="sc">$</span>disorderFactor))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>                        
                         Truth: Disorder Truth: No Disorder
  Decision: Diagnosis          0.2300885          0.1238938
  Decision: No Diagnosis       0.1327434          0.5132743</code></pre>
</div>
</div>
<p>Aggiungi i margini alle proporzioni:</p>
<div id="cell-57" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="36">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">addmargins</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(mydataSDT<span class="sc">$</span>diagnosisFactor, mydataSDT<span class="sc">$</span>disorderFactor)))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>A table: 3 x 3 of type dbl</caption>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th" scope="col">Truth: Disorder</th>
<th data-quarto-table-cell-role="th" scope="col">Truth: No Disorder</th>
<th data-quarto-table-cell-role="th" scope="col">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">Decision: Diagnosis</td>
<td>0.2300885</td>
<td>0.1238938</td>
<td>0.3539823</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th" scope="row">Decision: No Diagnosis</td>
<td>0.1327434</td>
<td>0.5132743</td>
<td>0.6460177</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th" scope="row">Sum</td>
<td>0.3628319</td>
<td>0.6371681</td>
<td>1.0000000</td>
</tr>
</tbody>
</table>
</div>
</div>
<section id="truePositive" class="level3" data-number="80.9.1">
<h3 data-number="80.9.1" class="anchored" data-anchor-id="truePositive"><span class="header-section-number">80.9.1</span> True Positives (TP)</h3>
<p>I <em>true positives</em> (TP) sono i casi in cui una classificazione positiva (ad esempio, la presenza di un disturbo) è corretta, ovvero il test indica che la classificazione è presente, e lo è davvero. Più alto è il numero di <em>true positives</em> rispetto alla dimensione del campione, maggiore è l’accuratezza. La formula per calcolare i <em>true positives</em> è:</p>
<p><span class="math display">\[
TP = BR \times SR \times N
\]</span></p>
<p>Ecco come calcolare i true positives in R:</p>
<div id="cell-59" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="37">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>TPvalue <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>diagnosis <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> mydataSDT<span class="sc">$</span>disorder <span class="sc">==</span> <span class="dv">1</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>TPvalue</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
26
</div>
</div>
</section>
<section id="trueNegative" class="level3" data-number="80.9.2">
<h3 data-number="80.9.2" class="anchored" data-anchor-id="trueNegative"><span class="header-section-number">80.9.2</span> True Negatives (TN)</h3>
<p>I <em>true negatives</em> (TN) sono i casi in cui una classificazione negativa (assenza di disturbo) è corretta, ovvero il test indica che la classificazione non è presente e questa effettivamente non è presente. La formula per calcolare i <em>true negatives</em> è:</p>
<p><span class="math display">\[
TN = (1 - BR) \times (1 - SR) \times N
\]</span></p>
<p>Per calcolare i true negatives in R:</p>
<div id="cell-61" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="38">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>TNvalue <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>diagnosis <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> mydataSDT<span class="sc">$</span>disorder <span class="sc">==</span> <span class="dv">0</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>TNvalue</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
58
</div>
</div>
</section>
<section id="falsePositive" class="level3" data-number="80.9.3">
<h3 data-number="80.9.3" class="anchored" data-anchor-id="falsePositive"><span class="header-section-number">80.9.3</span> False Positives (FP)</h3>
<p>I <em>false positives</em> (FP) sono i casi in cui una classificazione positiva è errata, ovvero il test indica la presenza di un disturbo che in realtà non è presente. Valori più bassi di <em>false positives</em> riflettono una maggiore accuratezza. La formula per calcolare i <em>false positives</em> è:</p>
<p><span class="math display">\[
FP = (1 - BR) \times SR \times N
\]</span></p>
<p>Ecco come calcolare i false positives in R:</p>
<div id="cell-63" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="39">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>FPvalue <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>diagnosis <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> mydataSDT<span class="sc">$</span>disorder <span class="sc">==</span> <span class="dv">0</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>FPvalue</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
14
</div>
</div>
</section>
<section id="falseNegative" class="level3" data-number="80.9.4">
<h3 data-number="80.9.4" class="anchored" data-anchor-id="falseNegative"><span class="header-section-number">80.9.4</span> False Negatives (FN)</h3>
<p>I <em>false negatives</em> (FN) sono i casi in cui una classificazione negativa è errata, ovvero il test indica l’assenza di un disturbo che in realtà è presente. Valori più bassi di <em>false negatives</em> riflettono una maggiore accuratezza. La formula per calcolare i <em>false negatives</em> è:</p>
<p><span class="math display">\[
FN = BR \times (1 - SR) \times N
\]</span></p>
<p>Per calcolare i false negatives in R:</p>
<div id="cell-65" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="40">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>FNvalue <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    mydataSDT<span class="sc">$</span>diagnosis <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> mydataSDT<span class="sc">$</span>disorder <span class="sc">==</span> <span class="dv">1</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>FNvalue</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
15
</div>
</div>
</section>
<section id="sampleSize-prediction" class="level3" data-number="80.9.5">
<h3 data-number="80.9.5" class="anchored" data-anchor-id="sampleSize-prediction"><span class="header-section-number">80.9.5</span> Dimensione del Campione (<em>N</em>)</h3>
<p>La dimensione del campione può essere calcolata sommando il numero di TP, TN, FP e FN:</p>
<div id="cell-67" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="41">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>sampleSize <span class="ot">&lt;-</span> <span class="cf">function</span>(TP, TN, FP, FN) {</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    value <span class="ot">&lt;-</span> TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(value)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="fu">sampleSize</span>(</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">TP =</span> TPvalue,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">TN =</span> TNvalue,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">FP =</span> FPvalue,</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">FN =</span> FNvalue</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
113
</div>
</div>
</section>
<section id="selectionRatio" class="level3" data-number="80.9.6">
<h3 data-number="80.9.6" class="anchored" data-anchor-id="selectionRatio"><span class="header-section-number">80.9.6</span> Selection Ratio (SR)</h3>
<p>The selection ratio (SR) is the marginal probability of selection, independent of other things: <span class="math inline">\(P(R_i)\)</span>. In clinical psychology, the selection ratio is the proportion of people who test positive for the disorder, as in Equation @ref(eq:selectionRatio):</p>
<p><span class="math display">\[
\begin{aligned}
  \text{SR} &amp;= P(R_i) \\
  &amp;= \frac{\text{TP} + \text{FP}}{N}
\end{aligned}
(\#eq:selectionRatio)
\]</span></p>
<div id="cell-69" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="42">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>selectionRatio <span class="ot">&lt;-</span> <span class="cf">function</span>(TP, TN, FP, FN){</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  value <span class="ot">&lt;-</span> (TP <span class="sc">+</span> FP)<span class="sc">/</span>N</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(value)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="fu">selectionRatio</span>(</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">TP =</span> TPvalue,</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">TN =</span> TNvalue,</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">FP =</span> FPvalue,</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">FN =</span> FNvalue</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>selectionRatioValue <span class="ot">&lt;-</span> <span class="fu">selectionRatio</span>(<span class="at">TP =</span> TPvalue, <span class="at">TN =</span> TNvalue, <span class="at">FP =</span> FPvalue, <span class="at">FN =</span> FNvalue)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
0.353982300884956
</div>
</div>
</section>
<section id="pretestProbability" class="level3" data-number="80.9.7">
<h3 data-number="80.9.7" class="anchored" data-anchor-id="pretestProbability"><span class="header-section-number">80.9.7</span> Base Rate (BR)</h3>
<p>The <a href="#baseRate">base rate</a> (BR) of a classification is its <a href="#baseRate">marginal probability</a>, independent of other things: <span class="math inline">\(P(C_i)\)</span>. In clinical psychology, the base rate of a disorder is its prevalence in the population, as in Equation @ref(eq:baseRate). Without additional information, the <a href="#baseRate">base rate</a> is used as the initial <em>pretest probability</em>.</p>
<p><span class="math display">\[
\begin{aligned}
  \text{BR} &amp;= P(C_i) \\
  &amp;= \frac{\text{TP} + \text{FN}}{N}
\end{aligned}
(\#eq:baseRate)
\]</span></p>
<div id="cell-71" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="43">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>baseRate <span class="ot">&lt;-</span> <span class="cf">function</span>(TP, TN, FP, FN){</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  value <span class="ot">&lt;-</span> (TP <span class="sc">+</span> FN)<span class="sc">/</span>N</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(value)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="fu">baseRate</span>(</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">TP =</span> TPvalue,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">TN =</span> TNvalue,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">FP =</span> FPvalue,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">FN =</span> FNvalue)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>baseRateValue <span class="ot">&lt;-</span> <span class="fu">baseRate</span>(<span class="at">TP =</span> TPvalue, <span class="at">TN =</span> TNvalue, <span class="at">FP =</span> FPvalue, <span class="at">FN =</span> FNvalue)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
0.36283185840708
</div>
</div>
</section>
<section id="pretestOdds" class="level3" data-number="80.9.8">
<h3 data-number="80.9.8" class="anchored" data-anchor-id="pretestOdds"><span class="header-section-number">80.9.8</span> Pretest Odds</h3>
<p>The pretest odds of a classification can be estimated using the pretest probability (i.e., <a href="#baseRate">base rate</a>). To convert a probability to odds, divide the probability by one minus that probability, as in Equation @ref(eq:pretestOdds).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{pretest odds} &amp;= \frac{\text{pretest probability}}{1 - \text{pretest probability}} \\
\end{aligned}
(\#eq:pretestOdds)
\]</span></p>
<div id="cell-73" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="44">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>pretestOdds <span class="ot">&lt;-</span> <span class="cf">function</span>(TP, TN, FP, FN, <span class="at">pretestProb =</span> <span class="cn">NULL</span>){</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(pretestProb)){</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    pretestProbability <span class="ot">&lt;-</span> pretestProb</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    N <span class="ot">&lt;-</span> TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    pretestProbability <span class="ot">&lt;-</span> (TP <span class="sc">+</span> FN)<span class="sc">/</span>N</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>  value <span class="ot">&lt;-</span> pretestProbability <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> pretestProbability)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(value)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="fu">pretestOdds</span>(</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">TP =</span> TPvalue,</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">TN =</span> TNvalue,</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">FP =</span> FPvalue,</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">FN =</span> FNvalue)</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a><span class="fu">pretestOdds</span>(<span class="at">pretestProb =</span> <span class="fu">baseRate</span>(</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">TP =</span> TPvalue,</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">TN =</span> TNvalue,</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">FP =</span> FPvalue,</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">FN =</span> FNvalue))</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>pretestOddsValue <span class="ot">&lt;-</span> <span class="fu">pretestOdds</span>(<span class="at">TP =</span> TPvalue,</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>                                <span class="at">TN =</span> TNvalue,</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>                                <span class="at">FP =</span> FPvalue,</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>                                <span class="at">FN =</span> FNvalue)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
0.569444444444444
</div>
<div class="cell-output cell-output-display">
0.569444444444444
</div>
</div>
</section>
<section id="percentAccuracy" class="level3" data-number="80.9.9">
<h3 data-number="80.9.9" class="anchored" data-anchor-id="percentAccuracy"><span class="header-section-number">80.9.9</span> Percent Accuracy</h3>
<p>Percent Accuracy is also called overall accuracy. Higher values reflect greater accuracy. The formula for percent accuracy is in Equation @ref(eq:percentAccuracy). Percent accuracy has several problems. First, it treats all errors (<a href="#falsePositive">FP</a> and <a href="#falseNegative">FN</a>) as equally important. However, in practice, it is rarely the case that <a href="#falsePositive">false positives</a> and <a href="#falseNegative">false negatives</a> are equally important. Second, percent accuracy can be misleading because it is highly influenced by <a href="#baseRate">base rates</a>. You can have a high percent accuracy by predicting from the <a href="#baseRate">base rate</a> and saying that no one has the characteristic (if the <a href="#baseRate">base rate</a> is low) or that everyone has the characteristic (if the <a href="#baseRate">base rate</a> is high). Thus, it is also important to consider other aspects of accuracy.</p>
<p><span class="math display">\[\begin{equation}
\text{Percent Accuracy} = 100\% \times \frac{\text{TP} + \text{TN}}{N}
(\#eq:percentAccuracy)
\end{equation}\]</span></p>
<div id="cell-75" class="cell" data-vscode="{&quot;languageId&quot;:&quot;r&quot;}" data-execution_count="45">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>percentAccuracy <span class="ot">&lt;-</span> <span class="cf">function</span>(TP, TN, FP, FN){</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  value <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="sc">*</span> ((TP <span class="sc">+</span> TN)<span class="sc">/</span>N)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(value)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="fu">percentAccuracy</span>(</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">TP =</span> TPvalue,</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">TN =</span> TNvalue,</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">FP =</span> FPvalue,</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">FN =</span> FNvalue)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>percentAccuracyValue <span class="ot">&lt;-</span> <span class="fu">percentAccuracy</span>(<span class="at">TP =</span> TPvalue,</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">TN =</span> TNvalue,</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">FP =</span> FPvalue,</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">FN =</span> FNvalue)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
74.3362831858407
</div>
</div>
</section>
<section id="percentAccuracyByChance" class="level3" data-number="80.9.10">
<h3 data-number="80.9.10" class="anchored" data-anchor-id="percentAccuracyByChance"><span class="header-section-number">80.9.10</span> Percent Accuracy by Chance</h3>
<p>The formula for calculating percent accuracy by chance is in Equation @ref(eq:PercentAccuracyByChance).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{Percent Accuracy by Chance} &amp;= 100\% \times [P(\text{TP}) + P(\text{TN})] \\
  &amp;= 100\% \times \{(\text{BR} \times {\text{SR}}) + [(1 - \text{BR}) \times (1 - \text{SR})]\}
\end{aligned}
(\#eq:PercentAccuracyByChance)
\]</span></p>
<p>```{r, class.source = “fold-hide”} percentAccuracyByChance &lt;- function(TP, TN, FP, FN){ N &lt;- TP + TN + FP + FN BR &lt;- (TP + FN)/N SR &lt;- (TP + FP)/N value &lt;- 100 * ((BR * SR) + ((1 - BR) * (1 - SR)))</p>
<p>return(value) }</p>
<pre><code>
```{r}
percentAccuracyByChance(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} percentAccuracyByChanceValue &lt;- percentAccuracyByChance(TP = TPvalue,                                                         TN = TNvalue,                                                         FP = FPvalue,                                                         FN = FNvalue)</code></p>
</section>
<section id="percentAccuracyPredictingFromBaseRate" class="level3" data-number="80.9.11">
<h3 data-number="80.9.11" class="anchored" data-anchor-id="percentAccuracyPredictingFromBaseRate"><span class="header-section-number">80.9.11</span> Percent Accuracy Predicting from the Base Rate</h3>
<p><a href="#predictingFromBaseRate"><em>Predicting from the base rate</em></a> is going with the most likely outcome in every prediction. It is also called “betting from the base rate”. If the <a href="#baseRate">base rate</a> is less than .50, it would involve predicting that the condition is absent for every case. If the <a href="#baseRate">base rate</a> is .50 or above, it would involve predicting that the condition is present for every case. <a href="#predictingFromBaseRate">Predicting from the base rate</a> is a special case of <a href="#percentAccuracyByChance">percent accuracy by chance</a> when the <a href="#selectionRatio">selection ratio</a> is set to either one (if the <a href="#baseRate">base rate</a> <span class="math inline">\(\geq\)</span> .5) or zero (if the <a href="#baseRate">base rate</a> &lt; .5).</p>
<p>```{r, class.source = “fold-hide”} percentAccuracyPredictingFromBaseRate &lt;- function(TP, TN, FP, FN){ N &lt;- TP + TN + FP + FN BR &lt;- (TP + FN)/N</p>
<p>ifelse(BR &gt;= .5, SR &lt;- 1, NA) ifelse(BR &lt; .5, SR &lt;- 0, NA)</p>
<p>value &lt;- 100 * ((BR * SR) + ((1 - BR) * (1 - SR)))</p>
<p>return(value) }</p>
<pre><code>
```{r}
percentAccuracyPredictingFromBaseRate(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} percentAccuracyPredictingFromBaseRateValue &lt;- percentAccuracyPredictingFromBaseRate(TP = TPvalue,                                                                                     TN = TNvalue,                                                                                     FP = FPvalue,                                                                                     FN = FNvalue)</code></p>
</section>
<section id="relativeImprovementOverChance" class="level3" data-number="80.9.12">
<h3 data-number="80.9.12" class="anchored" data-anchor-id="relativeImprovementOverChance"><span class="header-section-number">80.9.12</span> Relative Improvement Over Chance (RIOC)</h3>
<p>Relative improvement over chance (RIOC) is a prediction’s improvement over chance as a proportion of the maximum possible improvement over chance, as described by <span class="citation" data-cites="Farrington1989">(<a href="../../99-references.html#ref-Farrington1989" role="doc-biblioref"><strong>Farrington1989?</strong></a>)</span>. Higher values reflect greater accuracy. The formula for calculating RIOC is in Equation @ref(eq:relativeImprovementOverChance).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{relative improvement over chance (RIOC)} &amp;= \frac{\text{total correct} - \text{chance correct}}{\text{maximum correct} - \text{chance correct}} \\
\end{aligned}
(\#eq:relativeImprovementOverChance)
\]</span></p>
<p>```{r, class.source = “fold-hide”} relativeImprovementOverChance &lt;- function(TP, TN, FP, FN){ N &lt;- TP + TN + FP + FN actualYes &lt;- TP + FN predictedYes &lt;- TP + FP value &lt;- ((N * (TP + TN)) - (actualYes * predictedYes + (N - predictedYes) * (N - actualYes))) / ((N * (actualYes + N - predictedYes)) - (actualYes * predictedYes + (N - predictedYes) * (N - actualYes)))</p>
<p>return(value) }</p>
<pre><code>
```{r}
relativeImprovementOverChance(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} relativeImprovementOverChanceValue &lt;- relativeImprovementOverChance(TP = TPvalue,                                                                     TN = TNvalue,                                                                     FP = FPvalue,                                                                     FN = FNvalue)</code></p>
</section>
<section id="relativeImprovementOverPredictingFromBaseRate" class="level3" data-number="80.9.13">
<h3 data-number="80.9.13" class="anchored" data-anchor-id="relativeImprovementOverPredictingFromBaseRate"><span class="header-section-number">80.9.13</span> Relative Improvement Over Predicting from the Base Rate</h3>
<p>Relative improvement over <a href="#predictingFromBaseRate">predicting from the base rate</a> is a prediction’s improvement over <a href="#predictingFromBaseRate">predicting from the base rate</a> as a proportion of the maximum possible improvement over <a href="#predictingFromBaseRate">predicting from the base rate</a>. Higher values reflect greater accuracy. The formula for calculating relative improvement over predicting from the base rate is in Equation @ref(eq:relativeImprovementOverPredictingFromBaseRate).</p>
<p><span class="math display">\[
\scriptsize
\begin{aligned}
  \text{relative improvement over predicting from base rate} &amp;= \frac{\text{total correct} - \text{correct by predicting from base rate}}{\text{maximum correct} - \text{correct by predicting from base rate}} \\
\end{aligned}
(\#eq:relativeImprovementOverPredictingFromBaseRate)
\]</span></p>
<p>```{r, class.source = “fold-hide”} relativeImprovementOverPredictingFromBaseRate &lt;- function(TP, TN, FP, FN){ N &lt;- TP + TN + FP + FN BR &lt;- (TP + FN)/N</p>
<p>ifelse(BR &gt;= .5, SR &lt;- 1, NA) ifelse(BR &lt; .5, SR &lt;- 0, NA)</p>
<p>actualYes &lt;- TP + FN predictedYes &lt;- SR * N value &lt;- ((N * (TP + TN)) - (actualYes * predictedYes + (N - predictedYes) * (N - actualYes))) / ((N * (actualYes + N - predictedYes)) - (actualYes * predictedYes + (N - predictedYes) * (N - actualYes)))</p>
<p>return(value) }</p>
<pre><code>
```{r}
relativeImprovementOverPredictingFromBaseRate(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} relativeImprovementOverPredictingFromBaseRateValue &lt;- relativeImprovementOverPredictingFromBaseRate(   TP = TPvalue,   TN = TNvalue,   FP = FPvalue,   FN = FNvalue)</code></p>
</section>
<section id="sensitivity" class="level3" data-number="80.9.14">
<h3 data-number="80.9.14" class="anchored" data-anchor-id="sensitivity"><span class="header-section-number">80.9.14</span> Sensitivity (SN)</h3>
<p>Sensitivity (SN) is also called true positive rate (TPR), hit rate (HR), or recall. Sensitivity is the <a href="#conditionalProbability">conditional probability</a> of a positive test given that the person has the condition: <span class="math inline">\(P(R \mid C)\)</span>. Higher values reflect greater accuracy. The formula for calculating sensitivity is in Equation @ref(eq:sensitivity). As described in Section @ref(accuracyCutoff) and as depicted in Figure @ref(fig:sensitivitySpecificity), as the cutoff increases (becomes more conservative), sensitivity decreases. As the cutoff decreases, sensitivity increases.</p>
<p><span class="math display">\[
\begin{aligned}
  \text{sensitivity (SN)} &amp;= P(R \mid C) \\
  &amp;= \frac{\text{TP}}{\text{TP} + \text{FN}} = \frac{\text{TP}}{N \times \text{BR}} = 1 - \text{FNR}
\end{aligned}
(\#eq:sensitivity)
\]</span></p>
<p>```{r, class.source = “fold-hide”} sensitivity &lt;- function(TP, TN, FP, FN){ value &lt;- TP/(TP + FN)</p>
<p>return(value) }</p>
<pre><code>
```{r}
sensitivity(
  TP = TPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} sensitivityValue &lt;- sensitivity(TP = TPvalue, FN = FNvalue)</code></p>
<p>Below I compute sensitivity and <a href="#specificity">specificity</a> at every possible cutoff.</p>
<p>```{r, class.source = “fold-hide”} possibleCutoffs &lt;- unique(na.omit(mydataSDT$testScore)) possibleCutoffs &lt;- possibleCutoffs[order(possibleCutoffs)] possibleCutoffs &lt;- c( possibleCutoffs, max(possibleCutoffs, na.rm = TRUE) + 0.01)</p>
<p>specificity &lt;- function(TP, TN, FP, FN){ value &lt;- TN/(TN + FP)</p>
<p>return(value) }</p>
<p>accuracyVariables &lt;- c(“cutoff”, “TP”, “TN”, “FP”, “FN”)</p>
<p>accuracyStats &lt;- data.frame(matrix( nrow = length(possibleCutoffs), ncol = length(accuracyVariables)))</p>
<p>names(accuracyStats) &lt;- accuracyVariables</p>
<p>for(i in 1:length(possibleCutoffs)){ newCutoff &lt;- possibleCutoffs[i]</p>
<p>mydataSDT<span class="math inline">\(diagnosis &lt;- NA
  mydataSDT\)</span>diagnosis[mydataSDT<span class="math inline">\(testScore &lt; newCutoff] &lt;- 0
  mydataSDT\)</span>diagnosis[mydataSDT$testScore &gt;= newCutoff] &lt;- 1</p>
<p>accuracyStats[i, “cutoff”] &lt;- newCutoff accuracyStats[i, “TP”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 1 &amp; mydataSDT\)</span>disorder == 1)) accuracyStats[i, “TN”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 0 &amp; mydataSDT\)</span>disorder == 0)) accuracyStats[i, “FP”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 1 &amp; mydataSDT\)</span>disorder == 0)) accuracyStats[i, “FN”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 0 &amp; mydataSDT\)</span>disorder == 1)) }</p>
<p>accuracyStats<span class="math inline">\(sensitivity &lt;- accuracyStats\)</span>TPrate &lt;- sensitivity( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN)</p>
<p>accuracyStats<span class="math inline">\(specificity &lt;- accuracyStats\)</span>TNrate &lt;- specificity( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN)</p>
<p>sensitivitySpecificityData &lt;- pivot_longer( accuracyStats, cols = all_of(c(“sensitivity”,“specificity”)))</p>
<pre><code>
```{r sensitivitySpecificity, echo = FALSE, results = "hide", out.width = "100%", fig.align = "center", fig.cap = "Sensitivity and Specificity as a Function of the Cutoff."}
ggplot(
  sensitivitySpecificityData,
  aes(
    x = cutoff,
    y = value,
    color = name)) +
  geom_line(linewidth = 2) +
  scale_x_continuous(name = "cutoff (liberal to conservative)") +
  scale_color_viridis_d(name = "") +
  theme_bw()</code></pre>
</section>
<section id="specificity" class="level3" data-number="80.9.15">
<h3 data-number="80.9.15" class="anchored" data-anchor-id="specificity"><span class="header-section-number">80.9.15</span> Specificity (SP)</h3>
<p>Specificity (SP) is also called true negative rate (TNR) or selectivity. Specificity is the <a href="#conditionalProbability">conditional probability</a> of a negative test given that the person does not have the condition: <span class="math inline">\(P(\text{not } R \mid \text{not } C)\)</span>. Higher values reflect greater accuracy. The formula for calculating specificity is in Equation @ref(eq:specificity). As described in Section @ref(accuracyCutoff) and as depicted in Figure @ref(fig:sensitivitySpecificity), as the cutoff increases (becomes more conservative), specificity increases. As the cutoff decreases, specificity decreases.</p>
<p><span class="math display">\[
\begin{aligned}
  \text{specificity (SP)} &amp;= P(\text{not } R \mid \text{not } C) \\
  &amp;= \frac{\text{TN}}{\text{TN} + \text{FP}} = \frac{\text{TN}}{N (1 - \text{BR})} = 1 - \text{FPR}
\end{aligned}
(\#eq:specificity)
\]</span></p>
<p>```{r, class.source = “fold-hide”} specificity &lt;- function(TP, TN, FP, FN){ value &lt;- TN/(TN + FP)</p>
<p>return(value) }</p>
<pre><code>
```{r}
specificity(TN = TNvalue, FP = FPvalue)</code></pre>
<p><code>{r, include = FALSE} specificityValue &lt;- specificity(   TN = TNvalue,   FP = FPvalue)</code></p>
</section>
<section id="falseNegativeRate" class="level3" data-number="80.9.16">
<h3 data-number="80.9.16" class="anchored" data-anchor-id="falseNegativeRate"><span class="header-section-number">80.9.16</span> False Negative Rate (FNR)</h3>
<p>The false negative rate (FNR) is also called the miss rate. The false negative rate is the <a href="#conditionalProbability">conditional probability</a> of a negative test given that the person has the condition: <span class="math inline">\(P(\text{not } R \mid C)\)</span>. Lower values reflect greater accuracy. The formula for calculating false negative rate is in Equation @ref(eq:falseNegativeRate).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{false negative rate (FNR)} &amp;= P(\text{not } R \mid C) \\
  &amp;= \frac{\text{FN}}{\text{FN} + \text{TP}} = \frac{\text{FN}}{N \times \text{BR}} = 1 - \text{TPR}
\end{aligned}
(\#eq:falseNegativeRate)
\]</span></p>
<p>```{r, class.source = “fold-hide”} falseNegativeRate &lt;- function(TP, TN, FP, FN){ value &lt;- FN/(FN + TP)</p>
<p>return(value) }</p>
<pre><code>
```{r}
falseNegativeRate(
  TP = TPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} falseNegativeRate(TP = TPvalue, FN = FNvalue)</code></p>
</section>
<section id="falsePositiveRate" class="level3" data-number="80.9.17">
<h3 data-number="80.9.17" class="anchored" data-anchor-id="falsePositiveRate"><span class="header-section-number">80.9.17</span> False Positive Rate (FPR)</h3>
<p>The false positive rate (FPR) is also called the false alarm rate (FAR) or fall-out. The false positive rate is the <a href="#conditionalProbability">conditional probability</a> of a positive test given that the person does not have the condition: <span class="math inline">\(P(R \mid \text{not } C)\)</span>. Lower values reflect greater accuracy. The formula for calculating false positive rate is in Equation @ref(eq:falsePositiveRate).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{false positive rate (FPR)} &amp;= P(R \mid \text{not } C) \\
  &amp;= \frac{\text{FP}}{\text{FP} + \text{TN}} = \frac{\text{FP}}{N (1 - \text{BR})} = 1 - \text{TNR}
\end{aligned}
(\#eq:falsePositiveRate)
\]</span></p>
<p>```{r, class.source = “fold-hide”} falsePositiveRate &lt;- function(TP, TN, FP, FN){ value &lt;- FP/(FP + TN)</p>
<p>return(value) }</p>
<pre><code>
```{r}
falsePositiveRate(
  TN = TNvalue,
  FP = FPvalue)</code></pre>
<p><code>{r, include = FALSE} falsePositiveRateValue &lt;- falsePositiveRate(TN = TNvalue, FP = FPvalue)</code></p>
</section>
<section id="ppv" class="level3" data-number="80.9.18">
<h3 data-number="80.9.18" class="anchored" data-anchor-id="ppv"><span class="header-section-number">80.9.18</span> Positive Predictive Value (PPV)</h3>
<p>The positive predictive value (PPV) is also called the positive predictive power (PPP) or precision. Many people confuse <a href="#sensitivity">sensitivity</a> (<span class="math inline">\(P(R \mid C)\)</span>) with its inverse <a href="#conditionalProbability">conditional probability</a>, PPV (<span class="math inline">\(P(C \mid R)\)</span>). PPV is the <a href="#conditionalProbability">conditional probability</a> of having the condition given a positive test: <span class="math inline">\(P(C \mid R)\)</span>. Higher values reflect greater accuracy. The formula for calculating positive predictive value is in Equation @ref(eq:positivePredictiveValue).</p>
<p>PPV can be low even when <a href="#sensitivity">sensitivity</a> is high because it depends not only on <a href="#sensitivity">sensitivity</a>, but also on <a href="#specificity">specificity</a> and the <a href="#baseRate">base rate</a>. Because PPV depends on the <a href="#baseRate">base rate</a>, PPV is not an intrinsic property of a measure. The same measure will have a different PPV in different contexts with different <a href="#baseRate">base rates</a> <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>. As described in Section @ref(accuracyCutoff) and as depicted in Figure @ref(fig:ppvNPVbaseRate), as the <a href="#baseRate">base rate</a> increases, PPV increases. As the <a href="#baseRate">base rate</a> decreases, PPV decreases. PPV also differs as a function of the cutoff. As described in Section @ref(accuracyCutoff) and as depicted in Figure @ref(fig:ppvNPVcutoff), as the cutoff increases (becomes more conservative), PPV increases. As the cutoff decreases (becomes more liberal), PPV decreases.</p>
<p><span class="math display">\[
\small
\begin{aligned}
  \text{positive predictive value (PPV)} &amp;= P(C \mid R) \\
  &amp;= \frac{\text{TP}}{\text{TP} + \text{FP}} = \frac{\text{TP}}{N \times \text{SR}}\\
  &amp;= \frac{\text{sensitivity} \times {\text{BR}}}{\text{sensitivity} \times {\text{BR}} + [(1 - \text{specificity}) \times (1 - \text{BR})]}
\end{aligned}
(\#eq:positivePredictiveValue)
\]</span></p>
<p>```{r, class.source = “fold-hide”} positivePredictiveValue &lt;- function(TP, TN, FP, FN, BR = NULL, SN, SP){ if(is.null(BR)){ value &lt;- TP/(TP + FP) } else{ value &lt;- (SN * BR)/(SN * BR + (1 - SP) * (1 - BR)) }</p>
<p>return(value) }</p>
<pre><code>
```{r}
positivePredictiveValue(
  TP = TPvalue,
  FP = FPvalue)

positivePredictiveValue(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  SN = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  SP = specificity(
    TN = TNvalue,
    FP = FPvalue))</code></pre>
<p><code>{r, include = FALSE} positivePredictivevalueValue &lt;- positivePredictiveValue(TP = TPvalue, FP = FPvalue)</code></p>
<p>Below I compute PPV and <a href="#npv">NPV</a> at every possible <a href="#baseRate">base rate</a> given the <a href="#sensitivity">sensitivity</a> and <a href="#specificity">specificity</a> at the current cutoff.</p>
<p>```{r, class.source = “fold-hide”} negativePredictiveValue &lt;- function(TP, TN, FP, FN, BR = NULL, SN, SP){ if(is.null(BR)){ value &lt;- TN/(TN + FN) } else{ value &lt;- (SP * (1 - BR))/(SP * (1 - BR) + (1 - SN) * BR) }</p>
<p>return(value) }</p>
<p>ppvNPVbaseRateData &lt;- data.frame( BR = seq(from = 0, to = 1, by = .01), SN = sensitivity( TP = TPvalue, FN = FNvalue), SP = specificity( TN = TNvalue, FP = FPvalue))</p>
<p>ppvNPVbaseRateData<span class="math inline">\(positivePredictiveValue &lt;- positivePredictiveValue(
  BR = ppvNPVbaseRateData\)</span>BR, SN = ppvNPVbaseRateData<span class="math inline">\(SN,
  SP = ppvNPVbaseRateData\)</span>SP)</p>
<p>ppvNPVbaseRateData<span class="math inline">\(negativePredictiveValue &lt;- negativePredictiveValue(
  BR = ppvNPVbaseRateData\)</span>BR, SN = ppvNPVbaseRateData<span class="math inline">\(SN,
  SP = ppvNPVbaseRateData\)</span>SP)</p>
<p>ppvNPVbaseRateData_long &lt;- pivot_longer( ppvNPVbaseRateData, cols = all_of(c( “positivePredictiveValue”,“negativePredictiveValue”)))</p>
<pre><code>
```{r ppvNPVbaseRate, echo = FALSE, results = "hide", out.width = "100%", fig.align = "center", fig.cap = "Positive Predictive Value and Negative Predictive Value as a Function of the Base Rate."}
ggplot(ppvNPVbaseRateData_long, aes(x = BR, y = value, color = name)) +
  geom_line(linewidth = 2) +
  scale_x_continuous(name = "base rate") +
  scale_y_continuous(name = "predictive value") +
  scale_color_viridis_d(name = "",
                        breaks = c("negativePredictiveValue","positivePredictiveValue"),
                        labels = c("Negative Predictive Value","Positive Predictive Value")) +
  theme_bw()</code></pre>
<p>Below I compute PPV and <a href="#npv">NPV</a> at every possible cutoff.</p>
<p>```{r, class.source = “fold-hide”} accuracyStats<span class="math inline">\(positivePredictiveValue &lt;- positivePredictiveValue(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>accuracyStats<span class="math inline">\(negativePredictiveValue &lt;- negativePredictiveValue(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>ppvNPVcutoffData &lt;- pivot_longer( accuracyStats, cols = all_of(c( “positivePredictiveValue”,“negativePredictiveValue”)))</p>
<pre><code>
```{r ppvNPVcutoff, echo = FALSE, results = "hide", out.width = "100%", fig.align = "center", fig.cap = "Positive Predictive Value and Negative Predictive Value as a Function of the Cutoff."}
ggplot(ppvNPVcutoffData, aes(x = cutoff, y = value, color = name)) +
  geom_line(linewidth = 2) +
  scale_x_continuous(name = "cutoff (liberal to conservative)", limits = c(0.05,2.09)) +
  scale_y_continuous(name = "predictive value") +
  scale_color_viridis_d(name = "", breaks = c("negativePredictiveValue","positivePredictiveValue"), labels = c("Negative Predictive Value","Positive Predictive Value")) +
  theme_bw()</code></pre>
</section>
<section id="npv" class="level3" data-number="80.9.19">
<h3 data-number="80.9.19" class="anchored" data-anchor-id="npv"><span class="header-section-number">80.9.19</span> Negative Predictive Value (NPV)</h3>
<p>The negative predictive value (NPV) is also called the negative predictive power (NPP). Many people confuse <a href="#specificity">specificity</a> (<span class="math inline">\(P(\text{not } R \mid \text{not } C)\)</span>) with its inverse <a href="#conditionalProbability">conditional probability</a>, NPV (<span class="math inline">\(P(\text{not } C \mid  \text{not } R)\)</span>). NPV is the <a href="#conditionalProbability">conditional probability</a> of not having the condition given a negative test: <span class="math inline">\(P(\text{not } C \mid  \text{not } R)\)</span>. Higher values reflect greater accuracy. The formula for calculating negative predictive value is in Equation @ref(eq:negativePredictiveValue).</p>
<p>NPV can be low even when <a href="#specificity">specificity</a> is high because it depends not only on <a href="#specificity">specificity</a>, but also on <a href="#sensitivity">sensitivity</a> and the <a href="#baseRate">base rate</a>. Because NPV depends on the <a href="#baseRate">base rate</a>, NPV is not an intrinsic property of a measure. The same measure will have a different NPV in different contexts with different <a href="#baseRate">base rates</a> <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>. As described in Section @ref(accuracyCutoff) and as depicted in Figure @ref(fig:ppvNPVbaseRate), as the <a href="#baseRate">base rate</a> increases, NPV decreases. As the <a href="#baseRate">base rate</a> decreases, NPV increases. NPV also differs as a function of the cutoff. As described in Section @ref(accuracyCutoff) and as depicted in Figure @ref(fig:ppvNPVcutoff), as the cutoff increases (becomes more conservative), NPV decreases. As the cutoff decreases (becomes more liberal), NPV decreases.</p>
<p><span class="math display">\[
\small
\begin{aligned}
  \text{negative predictive value (NPV)} &amp;= P(\text{not } C \mid \text{not } R) \\
  &amp;= \frac{\text{TN}}{\text{TN} + \text{FN}} = \frac{\text{TN}}{N(\text{1 - SR})}\\
  &amp;= \frac{\text{specificity} \times (1-{\text{BR}})}{\text{specificity} \times (1-{\text{BR}}) + [(1 - \text{sensitivity}) \times \text{BR})]}
\end{aligned}
(\#eq:negativePredictiveValue)
\]</span></p>
<p>```{r, class.source = “fold-hide”} negativePredictiveValue &lt;- function(TP, TN, FP, FN, BR = NULL, SN, SP){ if(is.null(BR)){ value &lt;- TN/(TN + FN) } else{ value &lt;- (SP * (1 - BR))/(SP * (1 - BR) + (1 - SN) * BR) }</p>
<p>return(value) }</p>
<pre><code>
```{r}
negativePredictiveValue(
  TN = TNvalue,
  FN = FNvalue)

negativePredictiveValue(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  SN = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  SP = specificity(
    TN = TNvalue,
    FP = FPvalue))</code></pre>
<p><code>{r, include = FALSE} negativePredictiveValueValue &lt;- negativePredictiveValue(TN = TNvalue,                                                         FN = FNvalue)</code></p>
</section>
<section id="falseDiscoveryRate" class="level3" data-number="80.9.20">
<h3 data-number="80.9.20" class="anchored" data-anchor-id="falseDiscoveryRate"><span class="header-section-number">80.9.20</span> False Discovery Rate (FDR)</h3>
<p>Many people confuse the false positive rate (<span class="math inline">\(P(R \mid \text{not } C)\)</span>) with its inverse <a href="#conditionalProbability">conditional probability</a>, the false discovery rate (<span class="math inline">\(P(\text{not } C \mid  R)\)</span>). The false discovery rate (FDR) is the <a href="#conditionalProbability">conditional probability</a> of not having the condition given a positive test: <span class="math inline">\(P(\text{not } C \mid  R)\)</span>. Lower values reflect greater accuracy. The formula for calculating false discovery rate is in Equation @ref(eq:falseDiscoveryRate).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{false discovery rate (FDR)} &amp;= P(\text{not } C \mid R) \\
  &amp;= \frac{\text{FP}}{\text{FP} + \text{TP}} = 1 - \text{PPV}
\end{aligned}
(\#eq:falseDiscoveryRate)
\]</span></p>
<p>```{r, class.source = “fold-hide”} falseDiscoveryRate &lt;- function(TP, TN, FP, FN){ value &lt;- FP/(FP + TP)</p>
<p>return(value) }</p>
<pre><code>
```{r}
falseDiscoveryRate(
  TP = TPvalue,
  FP = FPvalue)</code></pre>
<p><code>{r, include = FALSE} falseDiscoveryRateValue &lt;- falseDiscoveryRate(TP = TPvalue, FP = FPvalue)</code></p>
</section>
<section id="falseOmissionRate" class="level3" data-number="80.9.21">
<h3 data-number="80.9.21" class="anchored" data-anchor-id="falseOmissionRate"><span class="header-section-number">80.9.21</span> False Omission Rate (FOR)</h3>
<p>Many people confuse the false negative rate (<span class="math inline">\(P(\text{not } R \mid C)\)</span>) with its inverse <a href="#conditionalProbability">conditional probability</a>, the false omission rate (<span class="math inline">\(P(C \mid \text{not } R)\)</span>). The false omission rate (FOR) is the conditional probability of having the condition given a negative test: <span class="math inline">\(P(C \mid \text{not } R)\)</span>. Lower values reflect greater accuracy. The formula for calculating false omission rate is in Equation @ref(eq:falseOmissionRate).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{false omission rate (FOR)} &amp;= P(C \mid \text{not } R) \\
  &amp;= \frac{\text{FN}}{\text{FN} + \text{TN}} = 1 - \text{NPV}
\end{aligned}
(\#eq:falseOmissionRate)
\]</span></p>
<p>```{r, class.source = “fold-hide”} falseOmissionRate &lt;- function(TP, TN, FP, FN){ value &lt;- FN/(FN + TN)</p>
<p>return(value) }</p>
<pre><code>
```{r}
falseOmissionRate(
  TN = TNvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} falseOmissionRateValue &lt;- falseOmissionRate(TN = TNvalue, FN = FNvalue)</code></p>
</section>
<section id="youdenJ-example" class="level3" data-number="80.9.22">
<h3 data-number="80.9.22" class="anchored" data-anchor-id="youdenJ-example"><span class="header-section-number">80.9.22</span> Youden’s J Statistic</h3>
<p>Youden’s J statistic is also called Youden’s Index or informedness. Youden’s J statistic is the sum of <a href="#sensitivity">sensitivity</a> and <a href="#specificity">specificity</a> (and subtracting one). Higher values reflect greater accuracy. The formula for calculating Youden’s J statistic is in Equation @ref(eq:youdenIndex).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{Youden's J statistic} &amp;= \text{sensitivity} + \text{specificity} - 1
\end{aligned}
(\#eq:youdenIndex)
\]</span></p>
<p>```{r, class.source = “fold-hide”} youdenJ &lt;- function(TP, TN, FP, FN){ SN &lt;- TP/(TP + FN) SP &lt;- TN/(TN + FP) value &lt;- SN + SP - 1</p>
<p>return(value) }</p>
<pre><code>
```{r}
youdenJ(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} youdenJValue &lt;- youdenJ(TP = TPvalue, TN = TNvalue, FP = FPvalue, FN = FNvalue)</code></p>
</section>
<section id="balancedAccuracy" class="level3" data-number="80.9.23">
<h3 data-number="80.9.23" class="anchored" data-anchor-id="balancedAccuracy"><span class="header-section-number">80.9.23</span> Balanced Accuracy</h3>
<p>Balanced accuracy is the average of <a href="#sensitivity">sensitivity</a> and <a href="#specificity">specificity</a>. Higher values reflect greater accuracy. The formula for calculating balanced accuracy is in Equation @ref(eq:balancedAccuracy).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{balanced accuracy} &amp;= \frac{\text{sensitivity} + \text{specificity}}{2}
\end{aligned}
(\#eq:balancedAccuracy)
\]</span></p>
<p>```{r, class.source = “fold-hide”} balancedAccuracy &lt;- function(TP, TN, FP, FN){ SN &lt;- TP/(TP + FN) SP &lt;- TN/(TN + FP) value &lt;- (SN + SP) / 2</p>
<p>return(value) }</p>
<pre><code>
```{r}
balancedAccuracy(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} balancedAccuracyValue &lt;- balancedAccuracy(TP = TPvalue,                                           TN = TNvalue,                                           FP = FPvalue,                                           FN = FNvalue)</code></p>
</section>
<section id="fScore" class="level3" data-number="80.9.24">
<h3 data-number="80.9.24" class="anchored" data-anchor-id="fScore"><span class="header-section-number">80.9.24</span> F-Score</h3>
<p>The F-score combines <a href="#ppv">precision</a> (<a href="#ppv">positive predictive value</a>) and <a href="#sensitivity">recall</a> (<a href="#sensitivity">sensitivity</a>), where <span class="math inline">\(\beta\)</span> indicates how many times more important <a href="#sensitivity">sensitivity</a> is than the <a href="#ppv">positive predictive value</a>. If <a href="#sensitivity">sensitivity</a> and the <a href="#ppv">positive predictive value</a> are equally important, <span class="math inline">\(\beta = 1\)</span>, and the F-score is called the <span class="math inline">\(F_1\)</span> score. Higher values reflect greater accuracy. The formula for calculating the F-score is in Equation @ref(eq:FScore).</p>
<p><span class="math display">\[
\begin{aligned}
  F_\beta &amp;= (1 + \beta^2) \cdot \frac{\text{positive predictive value} \cdot \text{sensitivity}}{(\beta^2 \cdot \text{positive predictive value}) + \text{sensitivity}} \\
  &amp;= \frac{(1 + \beta^2) \cdot \text{TP}}{(1 + \beta^2) \cdot \text{TP} + \beta^2 \cdot \text{FN} + \text{FP}}
\end{aligned}
(\#eq:FScore)
\]</span></p>
<p>The <span class="math inline">\(F_1\)</span> score is the harmonic mean of <a href="#sensitivity">sensitivity</a> and <a href="#ppv">positive predictive value</a>. The formula for calculating the <span class="math inline">\(F_1\)</span> score is in Equation @ref(eq:F1Score).</p>
<p><span class="math display">\[
\begin{aligned}
  F_1 &amp;= \frac{2 \cdot \text{positive predictive value} \cdot \text{sensitivity}}{(\text{positive predictive value}) + \text{sensitivity}} \\
  &amp;= \frac{2 \cdot \text{TP}}{2 \cdot \text{TP} + \text{FN} + \text{FP}}
\end{aligned}
(\#eq:F1Score)
\]</span></p>
<p>```{r, class.source = “fold-hide”} fScore &lt;- function(TP, TN, FP, FN, beta = 1){ value &lt;- ((1 + beta^2) * TP) / ((1 + beta^2) * TP + beta^2 * FN + FP)</p>
<p>return(value) }</p>
<pre><code>
```{r}
fScore(
  TP = TPvalue,
  FP = FPvalue,
  FN = FNvalue)

fScore(
  TP = TPvalue,
  FP = FPvalue,
  FN = FNvalue,
  beta = 2)

fScore(
  TP = TPvalue,
  FP = FPvalue,
  FN = FNvalue,
  beta = 0.5)</code></pre>
<p><code>{r, include = FALSE} f1ScoreValue &lt;- fScore(TP = TPvalue, FP = FPvalue, FN = FNvalue)</code></p>
</section>
<section id="matthewsCorrelationCoefficient" class="level3" data-number="80.9.25">
<h3 data-number="80.9.25" class="anchored" data-anchor-id="matthewsCorrelationCoefficient"><span class="header-section-number">80.9.25</span> Matthews Correlation Coefficient (MCC)</h3>
<p>The Matthews correlation coefficient (MCC) is also called the phi coefficient. It is a correlation coefficient between predicted and observed values from a binary classification. Higher values reflect greater accuracy. The formula for calculating the MCC is in Equation @ref(eq:matthewsCorrelationCoefficient).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{MCC} &amp;= \frac{\text{TP} \times \text{TN} - \text{FP} \times \text{FN}}{\sqrt{(\text{TP} + \text{FP})(\text{TP} + \text{FN})(\text{TN} + \text{FP})(\text{TN} + \text{FN})}}
\end{aligned}
(\#eq:matthewsCorrelationCoefficient)
\]</span></p>
<p>```{r, class.source = “fold-hide”} mcc &lt;- function(TP, TN, FP, FN){ TP &lt;- as.double(TP) TN &lt;- as.double(TN) FP &lt;- as.double(FP) FN &lt;- as.double(FN) value &lt;- ((TP * TN) - (FP * FN)) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))</p>
<p>return(value) }</p>
<pre><code>
```{r}
mcc(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} mccValue &lt;- mcc(TP = TPvalue,                 TN = TNvalue,                 FP = FPvalue,                 FN = FNvalue)</code></p>
</section>
<section id="diagnosticOddsRatio" class="level3" data-number="80.9.26">
<h3 data-number="80.9.26" class="anchored" data-anchor-id="diagnosticOddsRatio"><span class="header-section-number">80.9.26</span> Diagnostic Odds Ratio</h3>
<p>The diagnostic odds ratio is the odds of a positive test among people with the condition relative to the odds of a positive test among people without the condition. Higher values reflect greater accuracy. The formula for calculating the diagnostic odds ratio is in Equation @ref(eq:diagnosticOddsRatio). If the predictor is bad, the diagnostic odds ratio could be less than one, and values can go up from there. If the diagnostic odds ratio is greater than 2, we take the odds ratio seriously because we are twice as likely to predict accurately than inaccurately. However, the diagnostic odds ratio ignores/hides <a href="#baseRate">base rates</a>. When interpreting the diagnostic odds ratio, it is important to keep in mind the clinical significance, because otherwise it is not very meaningful. Consider a risk factor that has a diagnostic odds ratio of 3 for tuberculosis, i.e., it puts you at 3 times as likely to develop tuberculosis. The prevalence of tuberculosis is relatively low. Assuming the prevalence of tuberculosis is less than 1/10th of 1%, your risk of developing tuberculosis is still very low even if the risk factor (with a diagnostic odds ratio of 3) is present.</p>
<p><span class="math display">\[
\begin{aligned}
  \text{diagnostic odds ratio} &amp;= \frac{\text{TP} \times \text{TN}}{\text{FP} \times \text{FN}} \\
  &amp;= \frac{\text{sensitivity} \times \text{specificity}}{(1 - \text{sensitivity}) \times (1 - \text{specificity})} \\
  &amp;= \frac{\text{PPV} \times \text{NPV}}{(1 - \text{PPV}) \times (1 - \text{NPV})} \\
  &amp;= \frac{\text{LR+}}{\text{LR}-}
\end{aligned}
(\#eq:diagnosticOddsRatio)
\]</span></p>
<p>```{r, class.source = “fold-hide”} diagnosticOddsRatio &lt;- function(TP, TN, FP, FN){ value &lt;- (TP * TN) / (FP * FN)</p>
<p>return(value) }</p>
<pre><code>
```{r}
diagnosticOddsRatio(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} diagnosticOddsRatioValue &lt;- diagnosticOddsRatio(TP = TPvalue,                                                 TN = TNvalue,                                                 FP = FPvalue,                                                 FN = FNvalue)</code></p>
</section>
<section id="diagnosticLikelihoodRatio" class="level3" data-number="80.9.27">
<h3 data-number="80.9.27" class="anchored" data-anchor-id="diagnosticLikelihoodRatio"><span class="header-section-number">80.9.27</span> Diagnostic Likelihood Ratio</h3>
<p>A likelihood ratio is the ratio of two probabilities. It can be used to compare the likelihood of two possibilities. The diagnostic likelihood ratio is an index of the predictive validity of an instrument: it is the ratio of the probability that a test result is correct to the probability that the test result is incorrect. The diagnostic likelihood ratio is also called the risk ratio. There are two types of diagnostic likelihood ratios: the <a href="#positiveLikelihoodRatio">positive likelihood ratio</a> and the <a href="#negativeLikelihoodRatio">negative likelihood ratio</a>.</p>
<section id="positiveLikelihoodRatio" class="level4" data-number="80.9.27.1">
<h4 data-number="80.9.27.1" class="anchored" data-anchor-id="positiveLikelihoodRatio"><span class="header-section-number">80.9.27.1</span> Positive Likelihood Ratio (LR+)</h4>
<p>The positive likelihood ratio (LR+) compares the <a href="#sensitivity">true positive rate</a> to the <a href="#falsePositiveRate">false positive rate</a>. Positive likelihood ratio values range from 1 to infinity. Higher values reflect greater accuracy, because it indicates the degree to which a <a href="#truePositive">true positive</a> is more likely than a <a href="#falsePositive">false positive</a>. The formula for calculating the positive likelihood ratio is in Equation @ref(eq:positiveLikelihoodRatio).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{positive likelihood ratio (LR+)} &amp;= \frac{\text{TPR}}{\text{FPR}} \\
  &amp;= \frac{P(R \mid C)}{P(R \mid \text{not } C)} \\
  &amp;= \frac{P(R \mid C)}{1 - P(\text{not } R \mid \text{not } C)} \\
  &amp;= \frac{\text{sensitivity}}{1 - \text{specificity}}
\end{aligned}
(\#eq:positiveLikelihoodRatio)
\]</span></p>
<p>```{r, class.source = “fold-hide”} positiveLikelihoodRatio &lt;- function(TP, TN, FP, FN){ SN &lt;- TP/(TP + FN) SP &lt;- TN/(TN + FP)</p>
<p>value &lt;- SN/(1 - SP)</p>
<p>return(value) }</p>
<pre><code>
```{r}
positiveLikelihoodRatio(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} positiveLikelihoodRatioValue &lt;- positiveLikelihoodRatio(TP = TPvalue,                                                         TN = TNvalue,                                                         FP = FPvalue,                                                         FN = FNvalue)</code></p>
</section>
<section id="negativeLikelihoodRatio" class="level4" data-number="80.9.27.2">
<h4 data-number="80.9.27.2" class="anchored" data-anchor-id="negativeLikelihoodRatio"><span class="header-section-number">80.9.27.2</span> Negative Likelihood Ratio (LR−)</h4>
<p>The negative likelihood ratio (LR−) compares the <a href="#falseNegativeRate">false negative rate</a> to the <a href="#specificity">true negative rate</a>. Negative likelihood ratio values range from 0 to 1. Smaller values reflect greater accuracy, because it indicates that a <a href="#falseNegative">false negative</a> is less likely than a <a href="#trueNegative">true negative</a>. The formula for calculating the negative likelihood ratio is in Equation @ref(eq:negativeLikelihoodRatio).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{negative likelihood ratio } (\text{LR}-) &amp;= \frac{\text{FNR}}{\text{TNR}} \\
  &amp;= \frac{P(\text{not } R \mid C)}{P(\text{not } R \mid \text{not } C)} \\
  &amp;= \frac{1 - P(R \mid C)}{P(\text{not } R \mid \text{not } C)} \\
  &amp;= \frac{1 - \text{sensitivity}}{\text{specificity}}
\end{aligned}
(\#eq:negativeLikelihoodRatio)
\]</span></p>
<p>```{r, class.source = “fold-hide”} negativeLikelihoodRatio &lt;- function(TP, TN, FP, FN){ SN &lt;- TP/(TP + FN) SP &lt;- TN/(TN + FP)</p>
<p>value &lt;- (1 - SN)/SP</p>
<p>return(value) }</p>
<pre><code>
```{r}
negativeLikelihoodRatio(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} negativeLikelihoodRatioValue &lt;- negativeLikelihoodRatio(TP = TPvalue,                                                         TN = TNvalue,                                                         FP = FPvalue,                                                         FN = FNvalue)</code></p>
</section>
</section>
<section id="posttestOdds" class="level3" data-number="80.9.28">
<h3 data-number="80.9.28" class="anchored" data-anchor-id="posttestOdds"><span class="header-section-number">80.9.28</span> Posttest Odds</h3>
<p>As presented in Equation @ref(eq:bayes5), the posttest (or posterior) odds are equal to the <a href="#pretestOdds">pretest odds</a> multiplied by the <a href="#diagnosticLikelihoodRatio">likelihood ratio</a>. The posttest odds and <a href="#posttestProbability">posttest probability</a> can be useful to calculate when the <a href="#baseRate">pretest probability</a> is different from the <a href="#baseRate">pretest probability</a> (or prevalence) of the classification. For instance, you might use a different <a href="#baseRate">pretest probability</a> if a test result is already known and you want to know the updated <a href="#posttestProbability">posttest probability</a> after conducting a second test. The formula for calculating posttest odds is in Equation @ref(eq:posttestOdds).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{posttest odds} &amp;= \text{pretest odds} \times \text{likelihood ratio} \\
\end{aligned}
(\#eq:posttestOdds)
\]</span></p>
<p>For calculating the posttest odds of a <a href="#truePositive">true positive</a> compared to a <a href="#falsePositive">false positive</a>, we use the <a href="#positiveLikelihoodRatio">positive likelihood ratio</a>, described later. We would use the <a href="#negativeLikelihoodRatio">negative likelihood ratio</a> if we wanted to calculate the posttest odds of a <a href="#falseNegative">false negative</a> compared to a <a href="#trueNegative">true negative</a>.</p>
<p>```{r, class.source = “fold-hide”} posttestOdds &lt;- function(TP, TN, FP, FN, pretestProb = NULL, SN = NULL, SP = NULL, likelihoodRatio = NULL){ if(!is.null(pretestProb) &amp; !is.null(SN) &amp; !is.null(SP)){ pretestProbability &lt;- pretestProb pretestOdds &lt;- pretestProbability / (1 - pretestProbability)</p>
<pre><code>likelihoodRatio &lt;- SN/(1 - SP)</code></pre>
<p>} else if(!is.null(pretestProb) &amp; !is.null(likelihoodRatio)){ pretestProbability &lt;- pretestProb pretestOdds &lt;- pretestProbability / (1 - pretestProbability)</p>
<pre><code>likelihoodRatio &lt;- likelihoodRatio</code></pre>
<p>} else { N &lt;- TP + TN + FP + FN pretestProbability &lt;- (TP + FN)/N pretestOdds &lt;- pretestProbability / (1 - pretestProbability)</p>
<pre><code>SN &lt;- TP/(TP + FN)
SP &lt;- TN/(TN + FP)
likelihoodRatio &lt;- SN/(1 - SP)</code></pre>
<p>}</p>
<p>value &lt;- pretestOdds * likelihoodRatio</p>
<p>return(value) }</p>
<pre><code>
```{r}
posttestOdds(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)

posttestOdds(
  pretestProb = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  SN = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  SP = specificity(
    TN = TNvalue,
    FP = FPvalue))

posttestOdds(
  pretestProb = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  likelihoodRatio = positiveLikelihoodRatio(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue))</code></pre>
<p><code>{r, include = FALSE} posttestOddsValue &lt;- posttestOdds(TP = TPvalue,                                   TN = TNvalue,                                   FP = FPvalue,                                   FN = FNvalue)</code></p>
</section>
<section id="posttestProbability" class="level3" data-number="80.9.29">
<h3 data-number="80.9.29" class="anchored" data-anchor-id="posttestProbability"><span class="header-section-number">80.9.29</span> Posttest Probability</h3>
<p>The posttest probability is the probability of having the disorder given a test result. When the <a href="#baseRate">base rate</a> is used as the <a href="#baseRate">pretest probability</a>, the posttest probability given a positive test is equal to <a href="#ppv">positive predictive value</a>. To convert odds to a probability, divide the odds by one plus the odds, as is in Equation @ref(eq:posttestProbability).</p>
<p><span class="math display">\[
\begin{aligned}
  \text{posttest probability} &amp;= \frac{\text{posttest odds}}{1 + \text{posttest odds}}
\end{aligned}
(\#eq:posttestProbability)
\]</span></p>
<p>```{r, class.source = “fold-hide”} posttestProbability &lt;- function(TP, TN, FP, FN, pretestProb = NULL, SN = NULL, SP = NULL, likelihoodRatio = NULL){ if(!is.null(pretestProb) &amp; !is.null(SN) &amp; !is.null(SP)){ pretestProbability &lt;- pretestProb pretestOdds &lt;- pretestProbability / (1 - pretestProbability)</p>
<pre><code>likelihoodRatio &lt;- SN/(1 - SP)</code></pre>
<p>} else if(!is.null(pretestProb) &amp; !is.null(likelihoodRatio)){ pretestProbability &lt;- pretestProb pretestOdds &lt;- pretestProbability / (1 - pretestProbability)</p>
<pre><code>likelihoodRatio &lt;- likelihoodRatio</code></pre>
<p>} else { N &lt;- TP + TN + FP + FN pretestProbability &lt;- (TP + FN)/N pretestOdds &lt;- pretestProbability / (1 - pretestProbability)</p>
<pre><code>SN &lt;- TP/(TP + FN)
SP &lt;- TN/(TN + FP)
likelihoodRatio &lt;- SN/(1 - SP)</code></pre>
<p>}</p>
<p>posttestOdds &lt;- pretestOdds * likelihoodRatio value &lt;- posttestOdds / (1 + posttestOdds)</p>
<p>return(value) }</p>
<pre><code>
```{r}
posttestProbability(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)

posttestProbability(
  pretestProb = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  SN = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  SP = specificity(
    TN = TNvalue,
    FP = FPvalue))

posttestProbability(
  pretestProb = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  likelihoodRatio = positiveLikelihoodRatio(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue))</code></pre>
<pre class="{r, include}"><code>posttestProbabilityValue &lt;- posttestProbability(TP = TPvalue,
                                                TN = TNvalue,
                                                FP = FPvalue,
                                                FN = FNvalue)</code></pre>
<p>Consider the following example: Assume the <a href="#baseRate">base rate</a> of the condition is .03%. We have two tests. Test A has a <a href="#sensitivity">sensitivity</a> of .95 and a <a href="#specificity">specificity</a> of .80. Test B has a <a href="#sensitivity">sensitivity</a> of .70 and a <a href="#specificity">specificity</a> of .90. What is the probability of having the condition if a person has a positive test on Test A? Assuming the errors of the two tests are independent, what is the probability of having the condition if the person has a positive test on Test B after having a positive test on Test A?</p>
<pre class="{r}"><code>probGivenTestA &lt;- posttestProbability(
  pretestProb = .003,
  SN = .95,
  SP = .80)

probGivenTestAthenB &lt;- posttestProbability(
  pretestProb = probGivenTestA,
  SN = .70,
  SP = .90)

probGivenTestA
probGivenTestAthenB</code></pre>
<p>The probability of having the condition if a person has a positive test on Test A is <span class="math inline">\(`r apa(probGivenTestA * 100, decimals = 1)`\)</span>%. The probability of having the condition if the person has a positive test on Test B after having a positive test on Test A is <span class="math inline">\(`r apa(probGivenTestAthenB * 100, decimals = 1)`\)</span>%.</p>
</section>
<section id="nomogram" class="level3" data-number="80.9.30">
<h3 data-number="80.9.30" class="anchored" data-anchor-id="nomogram"><span class="header-section-number">80.9.30</span> Probability Nomogram</h3>
<p>The <a href="https://github.com/DevPsyLab/petersenlab"><code>petersenlab</code></a> package <span class="citation" data-cites="R-petersenlab">(<a href="../../99-references.html#ref-R-petersenlab" role="doc-biblioref"><strong>R-petersenlab?</strong></a>)</span> contains the <code>nomogrammer()</code> function that creates a probability nomogram plot, adapted from https://github.com/achekroud/nomogrammer. In Figure @ref(fig:nomogramPlot), the probability nomogram is generated using the number of <a href="#truePositive">true positives</a>, <a href="#trueNegative">true negatives</a>, <a href="#falsePositive">false positives</a>, and <a href="#falseNegative">false negatives</a> at a given cutoff.</p>
<p><code>{r nomogramPlot, fig.align = "center", fig.cap = "Probability Nomogram."} nomogrammer(   TP = TPvalue,   TN = TNvalue,   FP = FPvalue,   FN = FNvalue )</code></p>
<p>The blue line indicates the <a href="#posttestProbability">posterior probability</a> of the condition given a positive test. The pink line indicates the <a href="#posttestProbability">posterior probability</a> of the condition given a negative test. One can also generate the probability nomogram from the <a href="#pretestProbability">base rate</a> and the <a href="#sensitivity">sensitivity</a> and <a href="#specificity">specificity</a> of the test at a given cutoff:</p>
<p><code>{r, eval = FALSE} nomogrammer(   pretestProb = baseRate(TP = TPvalue, TN = TNvalue, FP = FPvalue, FN = FNvalue),   SN = sensitivity(TP = TPvalue, FN = FNvalue),   SP = specificity(TN = TNvalue, FP = FPvalue) )</code></p>
<p>One can also generate the probability nomogram from the <a href="#pretestProbability">base rate</a>, <a href="#positiveLikelihoodRatio">positive likelihood ratio</a>, and <a href="#negativeLikelihoodRatio">negative likelihood ratio</a> at a given cutoff:</p>
<p><code>{r, eval = FALSE} nomogrammer(   pretestProb = baseRate(TP = TPvalue, TN = TNvalue, FP = FPvalue, FN = FNvalue),   PLR = positiveLikelihoodRatio(     TP = TPvalue,     TN = TNvalue,     FP = FPvalue,     FN = FNvalue),   NLR = negativeLikelihoodRatio(     TP = TPvalue,     TN = TNvalue,     FP = FPvalue,     FN = FNvalue) )</code></p>
</section>
<section id="dPrimeSDT" class="level3" data-number="80.9.31">
<h3 data-number="80.9.31" class="anchored" data-anchor-id="dPrimeSDT"><span class="header-section-number">80.9.31</span> <span class="math inline">\(d'\)</span> Sensitivity from Signal Detection Theory</h3>
<p><span class="math inline">\(d'\)</span> (<span class="math inline">\(d\)</span> prime) is an index of sensitivity from <a href="#sdt">signal detection theory</a>, as described by <span class="citation" data-cites="Stanislaw1999">(<a href="../../99-references.html#ref-Stanislaw1999" role="doc-biblioref"><strong>Stanislaw1999?</strong></a>)</span>. Higher values reflect greater accuracy. The formula for calculating <span class="math inline">\(d'\)</span> is in Equation @ref(eq:dPrimeSDT).</p>
<p><span class="math display">\[\begin{equation}
d' = z(\text{hit rate}) - z(\text{false alarm rate})
(\#eq:dPrimeSDT)
\end{equation}\]</span></p>
<p>```{r, class.source = “fold-hide”} dPrimeSDT &lt;- function(TP, TN, FP, FN){ HR &lt;- TP/(TP + FN) FAR &lt;- FP/(FP + TN) value &lt;- qnorm(HR) - qnorm(FAR)</p>
<p>return(value) }</p>
<pre><code>
```{r}
dPrimeSDT(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} dPrimeValue &lt;- dPrimeSDT(TP = TPvalue,                          TN = TNvalue,                          FP = FPvalue,                          FN = FNvalue)</code></p>
</section>
<section id="aSDT" class="level3" data-number="80.9.32">
<h3 data-number="80.9.32" class="anchored" data-anchor-id="aSDT"><span class="header-section-number">80.9.32</span> <span class="math inline">\(A\)</span> (Non-Parametric) Sensitivity from Signal Detection Theory</h3>
<p><span class="math inline">\(A\)</span> is a non-parametric index of sensitivity from <a href="#sdt">signal detection theory</a>, as described by <span class="citation" data-cites="Zhang2005">(<a href="../../99-references.html#ref-Zhang2005" role="doc-biblioref"><strong>Zhang2005?</strong></a>)</span>. Higher values reflect greater accuracy. The formula for calculating <span class="math inline">\(A\)</span> is in Equation @ref(eq:aSDT).</p>
<p>https://sites.google.com/a/mtu.edu/whynotaprime/ (archived at https://perma.cc/W2M2-39TJ)</p>
<p><span class="math display">\[\begin{equation}
A =
\begin{cases}
\frac{3}{4} + \frac{H - F}{4} - F(1 - H) &amp; \text{if } F \leq 0.5 \leq H ; \\
\frac{3}{4} + \frac{H - F}{4} - \frac{F}{4H} &amp; \text{if } F \leq H \leq 0.5 ;\\
\frac{3}{4} + \frac{H - F}{4} - \frac{1 - H}{4(1 - F)} &amp; \text{if } 0.5 \leq F \leq H .
\end{cases}
(\#eq:aSDT)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(H\)</span> is the hit rate and <span class="math inline">\(F\)</span> is the false alarm rate.</p>
<p>```{r, class.source = “fold-hide”} aSDT &lt;- function(TP, TN, FP, FN){ HR &lt;- TP/(TP + FN) FAR &lt;- FP/(FP + TN)</p>
<p>ifelse(FAR &lt;= .5 &amp; HR &gt;= .5, value &lt;- (3/4) + ((HR - FAR)/4) - (FAR * (1 - HR)), NA) ifelse(FAR &lt;= HR &amp; HR &lt;= .5, value &lt;- (3/4) + ((HR - FAR)/4) - (FAR/(4 * HR)), NA) ifelse(FAR &gt;= .5 &amp; FAR &lt;= HR, value &lt;- (3/4) + ((HR - FAR)/4) - ((1 - HR)/(4 * (1 - FAR))), NA)</p>
<p>return(value) }</p>
<pre><code>
```{r, class.source = "fold-hide"}
aSDT(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} Avalue &lt;- aSDT(TP = TPvalue,                TN = TNvalue,                FP = FPvalue,                FN = FNvalue)</code></p>
</section>
<section id="betaSDT" class="level3" data-number="80.9.33">
<h3 data-number="80.9.33" class="anchored" data-anchor-id="betaSDT"><span class="header-section-number">80.9.33</span> <span class="math inline">\(\beta\)</span> Bias from Signal Detection Theory</h3>
<p><span class="math inline">\(\beta\)</span> is an index of bias from <a href="#sdt">signal detection theory</a>, as described by <span class="citation" data-cites="Stanislaw1999">(<a href="../../99-references.html#ref-Stanislaw1999" role="doc-biblioref"><strong>Stanislaw1999?</strong></a>)</span>. Smaller values reflect greater accuracy. The formula for calculating <span class="math inline">\(\beta\)</span> is in Equation @ref(eq:betaSDT).</p>
<p><span class="math display">\[\begin{equation}
\beta = e^{\bigg\{\frac{\big[\phi^{-1}(F)\big]^2 - \big[\phi^{-1}(H)\big]}{2}\bigg\}^2}
(\#eq:betaSDT)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(H\)</span> is the hit rate, <span class="math inline">\(F\)</span> is the false alarm rate, and <span class="math inline">\(\phi\)</span> (phi) is a mathematical function that converts a <em>z</em> score to a probability by determining the portion of the normal distribution that lies to the left of the <em>z</em> score.</p>
<p>```{r, class.source = “fold-hide”} betaSDT &lt;- function(TP, TN, FP, FN){ HR &lt;- TP/(TP + FN) FAR &lt;- FP/(FP + TN) value &lt;- exp(qnorm(FAR)^2/2 - qnorm(HR)^2/2)</p>
<p>return(value) }</p>
<pre><code>
```{r}
betaSDT(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} betaValue &lt;- betaSDT(TP = TPvalue,                      TN = TNvalue,                      FP = FPvalue,                      FN = FNvalue)</code></p>
</section>
<section id="cSDT" class="level3" data-number="80.9.34">
<h3 data-number="80.9.34" class="anchored" data-anchor-id="cSDT"><span class="header-section-number">80.9.34</span> <span class="math inline">\(c\)</span> Bias from Signal Detection Theory</h3>
<p><span class="math inline">\(c\)</span> is an index of bias from <a href="#sdt">signal detection theory</a>, as described by <span class="citation" data-cites="Stanislaw1999">(<a href="../../99-references.html#ref-Stanislaw1999" role="doc-biblioref"><strong>Stanislaw1999?</strong></a>)</span>. Smaller values reflect greater accuracy. The formula for calculating <span class="math inline">\(c\)</span> is in Equation @ref(eq:cSDT).</p>
<p><span class="math display">\[\begin{equation}
c = - \frac{\phi^{-1}(H) + \phi^{-1}(F)}{2}
(\#eq:cSDT)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(H\)</span> is the hit rate, <span class="math inline">\(F\)</span> is the false alarm rate, and <span class="math inline">\(\phi\)</span> (phi) is a mathematical function that converts a <em>z</em> score to a probability by determining the portion of the normal distribution that lies to the left of the <em>z</em> score.</p>
<p>```{r, class.source = “fold-hide”} cSDT &lt;- function(TP, TN, FP, FN){ HR &lt;- TP/(TP + FN) FAR &lt;- FP/(FP + TN) value &lt;- -(qnorm(HR) + qnorm(FAR))/2</p>
<p>return(value) }</p>
<pre><code>
```{r}
cSDT(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} cValue &lt;- cSDT(TP = TPvalue,                TN = TNvalue,                FP = FPvalue,                FN = FNvalue)</code></p>
</section>
<section id="bSDT" class="level3" data-number="80.9.35">
<h3 data-number="80.9.35" class="anchored" data-anchor-id="bSDT"><span class="header-section-number">80.9.35</span> <span class="math inline">\(b\)</span> (Non-Parametric) Bias from Signal Detection Theory</h3>
<p><span class="math inline">\(b\)</span> is a non-parametric index of bias from <a href="#sdt">signal detection theory</a>, as described by <span class="citation" data-cites="Zhang2005">(<a href="../../99-references.html#ref-Zhang2005" role="doc-biblioref"><strong>Zhang2005?</strong></a>)</span>. Smaller values reflect greater accuracy. The formula for calculating <span class="math inline">\(b\)</span> is in Equation @ref(eq:bSDT).</p>
<p><span class="math display">\[\begin{equation}
b =
\begin{cases}
\frac{5 - 4H}{1 + 4F} &amp; \text{if } F \leq 0.5 \leq H ; \\
\frac{H^2 + H}{H^2 + F} &amp; \text{if } F \leq H \leq 0.5 ;\\
\frac{(1 - F)^2 + (1 - H)}{(1 - F)^2 + (1 - F)} &amp; \text{if } 0.5 \leq F \leq H .
\end{cases}
(\#eq:bSDT)
\end{equation}\]</span></p>
<p>```{r, class.source = “fold-hide”} bSDT &lt;- function(TP, TN, FP, FN){ HR &lt;- TP/(TP + FN) FAR &lt;- FP/(FP + TN)</p>
<p>ifelse(FAR &lt;= .5 &amp; HR &gt;= .5, value &lt;-(5 - (4 * HR))/(1 + (4 * FAR)), NA) ifelse(FAR &lt;= HR &amp; HR &lt;= .5, value &lt;- (HR^2 + HR)/(HR^2 + FAR), NA) ifelse(FAR &gt;= .5 &amp; FAR &lt;= HR, value &lt;- ((1 - FAR)^2 + (1 - HR))/((1 - FAR)^2 + (1 - FAR)), NA)</p>
<p>return(value) }</p>
<pre><code>
```{r}
bSDT(
  TP = TPvalue,
  TN = TNvalue,
  FP = FPvalue,
  FN = FNvalue)</code></pre>
<p><code>{r, include = FALSE} bValue &lt;- bSDT(TP = TPvalue,                TN = TNvalue,                FP = FPvalue,                FN = FNvalue)</code></p>
</section>
<section id="miscalibration" class="level3" data-number="80.9.36">
<h3 data-number="80.9.36" class="anchored" data-anchor-id="miscalibration"><span class="header-section-number">80.9.36</span> Mean Difference between Predicted Versus Observed Values (Miscalibration)</h3>
<p>The mean difference between predicted values versus observed values at a given cutoff is an index of <a href="#calibration">miscalibration</a> of predictions at that cutoff. It is called “calibration-in-the-small” (as opposed to calibration-in-the-large, which spans all cutoffs). Values closer to zero reflect greater accuracy. Values above zero indicate that the predicted values are, on average, greater than the observed values. Values below zero indicate that the observed values are, on average, greater than the predicted values.</p>
<p>```{r, fig.show = “hide”, class.source = “fold-hide”} miscalibration &lt;- function(predicted, actual, cutoff, bins = 10){ data &lt;- data.frame(na.omit(cbind(predicted, actual)))</p>
<p>calibrationTable &lt;- mutate( data, bin = cut_number( predicted, n = 10)) %&gt;% group_by(bin) %&gt;% summarise( n = length(predicted), meanPredicted = mean(predicted, na.rm = TRUE), meanObserved = mean(actual, na.rm = TRUE), .groups = “drop”)</p>
<p>calibrationTable<span class="math inline">\(cutoffMin &lt;- as.numeric(str_replace_all(str_split(
    calibrationTable\)</span>bin, pattern = “,”, simplify = TRUE)[,1], “[<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>\-\.]”, ““)) calibrationTable<span class="math inline">\(cutoffMax &lt;- as.numeric(str_replace_all(str_split(
    calibrationTable\)</span>bin, pattern =”,“, simplify = TRUE)[,2],”[<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>\-\.]“,”“))</p>
<p>calibrationTable$inRange &lt;- with( calibrationTable, cutoff &gt;= cutoffMin &amp; cutoff &lt;= cutoffMax)</p>
<p>if(length(which(calibrationTable<span class="math inline">\(inRange == TRUE)) &gt; 0){
    nearestCutoff &lt;- calibrationTable\)</span>bin[min(which( calibrationTable<span class="math inline">\(inRange == TRUE))]
    calibrationAtNearestCutoff &lt;- calibrationTable[which(
      calibrationTable\)</span>bin == nearestCutoff),] calibrationAtNearestCutoff &lt;- as.data.frame(calibrationTable[max(which( calibrationTable$inRange == TRUE)),])</p>
<pre><code>meanPredicted &lt;- calibrationAtNearestCutoff[, "meanPredicted"]
meanObserved &lt;- calibrationAtNearestCutoff[, "meanObserved"]
differenceBetweenPredictedAndObserved &lt;- meanPredicted - meanObserved</code></pre>
<p>} else{ differenceBetweenPredictedAndObserved &lt;- NA }</p>
<p>return(differenceBetweenPredictedAndObserved) }</p>
<pre><code>
```{r, fig.show = "hide"}
miscalibration(
  predicted = mydataSDT$predictedProbability,
  actual = mydataSDT$disorder,
  cutoff = cutoff)</code></pre>
</section>
</section>
<section id="optimalCutoff" class="level2" data-number="80.10">
<h2 data-number="80.10" class="anchored" data-anchor-id="optimalCutoff"><span class="header-section-number">80.10</span> Optimal Cutoff Specification</h2>
<p>There are two ways to improve diagnostic performance <span class="citation" data-cites="Swets2000">(<a href="../../99-references.html#ref-Swets2000" role="doc-biblioref"><strong>Swets2000?</strong></a>)</span>. One way is to increase the diagnostic accuracy of the assessment. The second way is to increase the utility of the diagnostic decisions that are made, based on where we set the cutoff. The optimal cutoff depends on the differential costs of <a href="#falsePositive">false positives</a> versus <a href="#falseNegative">false negatives</a>, as applied in <a href="#decisionTheory">decision theory</a>. When differential costs of <a href="#falsePositive">false positives</a> versus <a href="#falseNegative">false negatives</a> cannot be specified, an alternative approach to specifying the optimal cutoff is to use <a href="#informationTheory">information theory</a>.</p>
<section id="decisionTheory" class="level3" data-number="80.10.1">
<h3 data-number="80.10.1" class="anchored" data-anchor-id="decisionTheory"><span class="header-section-number">80.10.1</span> Decision Theory</h3>
<p>According to the decision theory approach to picking the optimal cutoff, the optimal cutoff depends on the value/importance placed on each of the four decision outcomes [(<a href="#truePositive">true positives</a>, <a href="#trueNegative">true negatives</a>, <a href="#falsePositive">false positives</a>, <a href="#falseNegative">false negatives</a>); <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>]. Utility is the relative value placed on a specific decision-making outcome (i.e., user-perceived benefit or cost): utilities typically range between zero and one, where a value of zero represents the least desired outcome, and a value of one indicates the most desired outcome. According to the decision theory approach, the optimal cutoff is the cutoff with the highest overall utility.</p>
<section id="overallUtilityCutoff" class="level4" data-number="80.10.1.1">
<h4 data-number="80.10.1.1" class="anchored" data-anchor-id="overallUtilityCutoff"><span class="header-section-number">80.10.1.1</span> Overall utility of a specific cutoff value</h4>
<p>The overall utility of a specific cutoff value is a utilities-weighted sum of the probabilities of the four decision-making outcomes (<a href="#truePositive">hits</a>, <a href="#falseNegative">misses</a>, <a href="#trueNegative">correct rejections</a>, <a href="#falsePositive">false alarms</a>). That is, overall utility is the sum of the product of the probability of a particular outcome (TP, TN, FP, FN; e.g., <span class="math inline">\(\text{BR} \times \text{TP rate}\)</span>) and the utility of that outcome (e.g., how much we value <a href="#truePositive">TPs</a> relative to other outcomes). Higher values reflect greater utility, so you would pick the cutoff with the highest overall utility. The formula for calculating overall utility is in Equation @ref(eq:overallUtility):</p>
<p><span class="math display">\[
\begin{aligned}
  U_\text{overall} = \ &amp; (\text{BR})(\text{HR})(U_\text{H}) \\
  &amp;+ (\text{BR})(1 - \text{HR})(U_\text{M}) \\
  &amp;+ (1 - \text{BR})(\text{FAR})(U_\text{FA}) \\
  &amp;+ (1 - \text{BR})(1 - \text{FAR})(U_\text{CR})
\end{aligned}
(\#eq:overallUtility)
\]</span></p>
<p>where <span class="math inline">\(\text{BR} = \text{base rate}\)</span>, <span class="math inline">\(\text{HR} = \text{hit rate (true positive rate)}\)</span>, <span class="math inline">\(\text{FAR} = \text{false alarm rate (false positive rate)}\)</span>, <span class="math inline">\(U_\text{H} = \text{utility of hits (true positives)}\)</span>, <span class="math inline">\(U_\text{M} = \text{utility of misses (false negatives)}\)</span>, <span class="math inline">\(U_\text{FA} = \text{utility of false alarms (false positives)}\)</span>, <span class="math inline">\(U_\text{CR} = \text{utility of correct rejections (true negatives)}\)</span>.</p>
<p><code>{r, class.source = "fold-hide"} Uoverall &lt;- function(BR, HR, FAR, UH, UM, UCR, UFA){   (BR*HR*UH) + (BR*(1 - HR)*UM) + ((1 - BR)*FAR*UFA) + ((1 - BR)*(1 - FAR)*(UCR)) }</code></p>
<pre class="{r}"><code>Uoverall(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  HR = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  FAR = falsePositiveRate(
    TN = TNvalue,
    FP = FPvalue),
  UH = 1,
  UM = 0,
  UCR = 0.75,
  UFA = 0.25)

Uoverall(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  HR = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  FAR = falsePositiveRate(
    TN = TNvalue,
    FP = FPvalue),
  UH = 1,
  UM = 0,
  UCR = 1,
  UFA = 0)

Uoverall(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  HR = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  FAR = falsePositiveRate(
    TN = TNvalue,
    FP = FPvalue),
  UH = 0.75,
  UM = 0.25,
  UCR = 1,
  UFA = 0)</code></pre>
</section>
<section id="utilityRatio" class="level4" data-number="80.10.1.2">
<h4 data-number="80.10.1.2" class="anchored" data-anchor-id="utilityRatio"><span class="header-section-number">80.10.1.2</span> Utility ratio</h4>
<p>The utility ratio is the user-perceived relative importance of decisions about negative versus positive cases. If the utility ratio value is one, it indicates that identifying negative cases and positive cases is equally important. Values above one indicate greater relative importance of identifying negative cases than positive cases. Values below one indicate greater relative importance of identifying positive cases than negative cases. Values of one indicate that you are maximizing percent accuracy. The formula for calculating the utility ratio is in Equation @ref(eq:utilityRatio):</p>
<p><span class="math display">\[\begin{equation}
\text{Utility Ratio} = \frac{U_\text{CR} - U_\text{FA}}{U_\text{H} - U_\text{M}}
(\#eq:utilityRatio)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(U_\text{H} = \text{utility of hits (true positives)}\)</span>, <span class="math inline">\(U_\text{M} = \text{utility of misses (false negatives)}\)</span>, <span class="math inline">\(U_\text{FA} = \text{utility of false alarms (false positives)}\)</span>, <span class="math inline">\(U_\text{CR} = \text{utility of correct rejections (true negatives)}\)</span>.</p>
<p><code>{r, class.source = "fold-hide"} utilityRatio &lt;- function(UH, UM, UCR, UFA){   (UCR - UFA) / (UH - UM) }</code></p>
<pre class="{r}"><code>utilityRatio(UH = 1, UM = 0, UCR = 0.75, UFA = 0.25)
utilityRatio(UH = 1, UM = 0, UCR = 1, UFA = 0)
utilityRatio(UH = 0.75, UM = 0.25, UCR = 1, UFA = 0)</code></pre>
<p><a href="#decisionTheory">Decision theory</a> has key advantages, because it identifies the cutoff that would help you best achieve the goals/purpose of the assessment. However, it can be challenging to specify the relative costs of errors. If you cannot decide values for outcomes (relative importance between <a href="#falsePositive">FP</a> and <a href="#falseNegative">FN</a>), you can use <a href="#informationTheory">information theory</a> to identify the optimal cutoff.</p>
</section>
</section>
<section id="informationTheory" class="level3" data-number="80.10.2">
<h3 data-number="80.10.2" class="anchored" data-anchor-id="informationTheory"><span class="header-section-number">80.10.2</span> Information Theory</h3>
<p>When the user does not differentially weigh the value/importance of the four decision-making outcomes (<a href="#truePositive">hits</a>, <a href="#falseNegative">misses</a>, <a href="#trueNegative">correct rejections</a>, <a href="#falsePositive">false alarms</a>), the information theory approach can be useful for specifying the optimal cutoff. According to the information theory approach, the optimal cutoff is the cutoff that provides the greatest information gain <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>.</p>
<section id="informationGain" class="level4" data-number="80.10.2.1">
<h4 data-number="80.10.2.1" class="anchored" data-anchor-id="informationGain"><span class="header-section-number">80.10.2.1</span> Information Gain</h4>
<p>Information gain (<span class="math inline">\(I_\text{gain}\)</span>) is the reduction of uncertainty about the true classification of a case that results from administering an assessment or prediction measure <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>. Greater values reflect greater reduction of uncertainty, so the optimal cutoff can be specified as the cutoff with the highest information gain.</p>
<section id="IgainTreat2023" class="level5" data-number="80.10.2.1.1">
<h5 data-number="80.10.2.1.1" class="anchored" data-anchor-id="IgainTreat2023"><span class="header-section-number">80.10.2.1.1</span> Formula from <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span></h5>
<p>The formula from <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span> for calculating information gain is in Equation @ref(eq:informationGain1):</p>
<p><span class="math display">\[
\begin{aligned}
  I_\text{gain} = \ &amp; (\text{BR})(\text{HR})\bigg[\log_2\bigg(\frac{\text{HR}}{G}\bigg)\bigg] \\
  &amp;+ (\text{BR})(1 - \text{HR})\bigg[\log_2\bigg(\frac{1 - \text{HR}}{1 - G}\bigg)\bigg] \\
  &amp;+ (1 - \text{BR})(\text{FAR})\bigg[\log_2\bigg(\frac{\text{FAR}}{G}\bigg)\bigg] \\
  &amp;+ (1 - \text{BR})(1 - \text{FAR})\bigg[\log_2\bigg(\frac{1 - \text{FAR}}{1 - G}\bigg)\bigg]
\end{aligned}
(\#eq:informationGain1)
\]</span></p>
<p>where <span class="math inline">\(\text{BR} =\)</span> <a href="#baseRate">base rate</a>, <span class="math inline">\(\text{HR} =\)</span> <a href="#sensitivity">hit rate</a> (<a href="#sensitivity">true positive rate</a>), <span class="math inline">\(\text{FAR} =\)</span> <a href="#falsePositiveRate">false alarm rate</a> (<a href="#falsePositiveRate">false positive rate</a>), <span class="math inline">\(G =\)</span> <a href="#selectionRatio">selection ratio</a> <span class="math inline">\(= \text{BR} (\text{HR}) + (1 - \text{BR}) (\text{FAR})\)</span>, as reported in <span class="citation" data-cites="Somoza1989">(<a href="../../99-references.html#ref-Somoza1989" role="doc-biblioref"><strong>Somoza1989?</strong></a>)</span> (see below).</p>
<p>```{r, class.source = “fold-hide”} Igain &lt;- function(BR, HR, FAR){ G &lt;- BR<em>(HR) + (1 - BR)</em>(FAR)</p>
<p>(BR<em>HR</em>log2(HR/G)) + (BR<em>(1 - HR)</em>(log2((1 - HR)/(1 - G)))) + ((1 - BR)<em>FAR</em>(log2(FAR/G))) + ((1 - BR)<em>(1 - FAR)</em>(log2((1 - FAR)/(1 - G)))) }</p>
<pre><code>
```{r}
Igain(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  HR = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  FAR = falsePositiveRate(
    TN = TNvalue,
    FP = FPvalue))</code></pre>
</section>
<section id="IgainMetz1973" class="level5" data-number="80.10.2.1.2">
<h5 data-number="80.10.2.1.2" class="anchored" data-anchor-id="IgainMetz1973"><span class="header-section-number">80.10.2.1.2</span> Alternative formula from <span class="citation" data-cites="Metz1973">(<a href="../../99-references.html#ref-Metz1973" role="doc-biblioref"><strong>Metz1973?</strong></a>)</span></h5>
<p>The alternative formula from <span class="citation" data-cites="Metz1973">(<a href="../../99-references.html#ref-Metz1973" role="doc-biblioref"><strong>Metz1973?</strong></a>)</span> for calculating information gain is in Equation @ref(eq:informationGain2):</p>
<p><span class="math display">\[
\begin{aligned}
  I_\text{gain} = \ &amp; p(S \mid s) \cdot p(s) \cdot log_2\Bigg\{\frac{p(S \mid s)}{p(S \mid s) \cdot p(s) + p(S \mid n)[1 - p(s)]}\Bigg\} \\
  &amp;+ p(S \mid n)[1 - p(s)] \times log_2\Bigg\{\frac{p(S \mid n)}{p(S \mid s) \cdot p(s) + p(S \mid n)[1 - p(s)]}\Bigg\} \\
  &amp;+ [1 - p(S \mid s)] \cdot p(s) \times log_2\Bigg\{\frac{1 - p(S \mid s)}{1 - p(S \mid s) \cdot p(s) - p(S \mid n)[1 - p(s)]}\Bigg\} \\
  &amp;+ [1 - p(S \mid n)][1 - p(s)] \times log_2\Bigg\{\frac{1 - p(S \mid n)}{1 - p(S \mid s) \cdot p(s) - p(S \mid n)[1 - p(s)]}\Bigg\}
\end{aligned}
(\#eq:informationGain2)
\]</span></p>
<p>where <span class="math inline">\(p(S \mid s) =\)</span> <a href="#sensitivity">sensitivity</a> (<a href="#sensitivity">hit rate</a> or <a href="#sensitivity">true positive rate</a>); i.e., the <a href="#conditionalProbability">conditional probability</a> of deciding a signal is present (<span class="math inline">\(S\)</span>) when the signal is in fact present(<span class="math inline">\(s\)</span>), <span class="math inline">\(p(S \mid n) =\)</span> <a href="#falsePositiveRate">false positive rate</a> (<a href="#falsePositiveRate">false alarm rate</a>); i.e., the <a href="#conditionalProbability">conditional probability</a> of deciding a signal is present (<span class="math inline">\(S\)</span>) when the signal is in fact absent (<span class="math inline">\(n\)</span>), <span class="math inline">\(p(s) =\)</span> <a href="#baseRate">base rate</a>, i.e., the probability that the signal is in fact present (<span class="math inline">\(s\)</span>).</p>
<p><code>{r, class.source = "fold-hide"} Igain2 &lt;- function(BR, HR, FAR){   HR * BR * log2(HR / ((HR * BR) + (FAR * (1 - BR)))) +     FAR * (1 - BR) * log2(FAR / ((HR * BR) + (FAR * (1 - BR)))) +     (1 - HR) * BR * log2((1 - HR) / (1 - (HR * BR) - (FAR * (1 - BR)))) +     (1 - FAR) * (1 - BR) * log2((1 - FAR) / (1 - (HR * BR) - (FAR * (1 - BR)))) }</code></p>
<pre class="{r}"><code>Igain2(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  HR = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  FAR = falsePositiveRate(
    TN = TNvalue,
    FP = FPvalue))</code></pre>
</section>
<section id="IgainSomoza1989" class="level5" data-number="80.10.2.1.3">
<h5 data-number="80.10.2.1.3" class="anchored" data-anchor-id="IgainSomoza1989"><span class="header-section-number">80.10.2.1.3</span> Alternative formula from <span class="citation" data-cites="Somoza1989">(<a href="../../99-references.html#ref-Somoza1989" role="doc-biblioref"><strong>Somoza1989?</strong></a>)</span></h5>
<p>The alternative formula from <span class="citation" data-cites="Somoza1989">(<a href="../../99-references.html#ref-Somoza1989" role="doc-biblioref"><strong>Somoza1989?</strong></a>)</span> for calculating information gain is in Equation @ref(eq:informationGain3):</p>
<p><span class="math display">\[
\begin{aligned}
  I_\text{gain} = \ &amp; [(\text{TPR})(\text{Pr})] \times \log_2(\text{TPR}/G) \\
  &amp;+ [(\text{FPR})(1 - \text{Pr})] \times \log_2(\text{FPR}/G) \\
  &amp;+ [(1 - \text{TPR})(\text{Pr})] \times \log_2\bigg(\frac{1 - \text{TPR}}{1 - G}\bigg) \\
  &amp;+ [(1 - \text{FPR})(1 - \text{Pr})] \times \log_2\bigg(\frac{1 - \text{FPR}}{1 - G}\bigg)
\end{aligned}
(\#eq:informationGain3)
\]</span></p>
<p>where <span class="math inline">\(\text{TP} =\)</span> <a href="#sensitivity">true positive rate</a> (<a href="#sensitivity">hit rate</a>), <span class="math inline">\(\text{Pr} =\)</span> <a href="#baseRate">prevalence</a> (<a href="#baseRate">base rate</a>), <span class="math inline">\(\text{FP} =\)</span> <a href="#falsePositiveRate">false positive rate</a> (<a href="#falsePositiveRate">false alarm rate</a>), <span class="math inline">\(G = \text{Pr} (\text{TP}) + (1 - \text{Pr}) (\text{FP}) =\)</span> <a href="#selectionRatio">selection ratio</a></p>
<p>```{r, class.source = “fold-hide”} Igain3 &lt;- function(BR, HR, FAR){ G &lt;- BR<em>(HR) + (1 - BR)</em>(FAR)</p>
<p>((HR)<em>(BR))</em>log2((HR/G)) + ((FAR)<em>(1-BR))</em>log2((FAR/G)) + ((1-HR)<em>(BR))</em>log2((1-HR)/(1-G)) + ((1-FAR)<em>(1-BR))</em>log2((1-FAR)/(1-G)) }</p>
<pre><code>
```{r}
Igain3(
  BR = baseRate(
    TP = TPvalue,
    TN = TNvalue,
    FP = FPvalue,
    FN = FNvalue),
  HR = sensitivity(
    TP = TPvalue,
    FN = FNvalue),
  FAR = falsePositiveRate(
    TN = TNvalue,
    FP = FPvalue))</code></pre>
</section>
<section id="IgainExamples" class="level5" data-number="80.10.2.1.4">
<h5 data-number="80.10.2.1.4" class="anchored" data-anchor-id="IgainExamples"><span class="header-section-number">80.10.2.1.4</span> Examples</h5>
<p>Case A from Exhibit 38.2 <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>:</p>
<pre class="{r}"><code>Igain(HR = (911/1899), FAR = (509/4757), BR = (1899/6656))</code></pre>
<p>Case B from Exhibit 38.2 <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>:</p>
<pre class="{r}"><code>Igain(HR = (1597/3328), FAR = (356/3328), BR = (3328/6656))</code></pre>
<p>Case C from Exhibit 38.2 <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>:</p>
<pre class="{r}"><code>Igain(HR = (2040/3328), FAR = (654/3328), BR = (3328/6656))</code></pre>
<p>Case B from Exhibit 38.3 <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>:</p>
<pre class="{r}"><code>Igain(HR = (1164/1899), FAR = (935/4757), BR = (1899/6656))</code></pre>
</section>
<section id="baseRateEffectsIgain" class="level5" data-number="80.10.2.1.5">
<h5 data-number="80.10.2.1.5" class="anchored" data-anchor-id="baseRateEffectsIgain"><span class="header-section-number">80.10.2.1.5</span> Effect of Base Rate</h5>
<p>Information gain depends on the <a href="#baseRate">base rate</a> <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>, as depicted in Figure @ref(fig:informationGainBaseRate). The maximum reduction of uncertainty (i.e., greatest information) occurs when the <a href="#baseRate">base rate</a> is 0.5. A <a href="#baseRate">base rate</a> tells us little a priori about the condition if the probability of the condition is 50/50, so the measure can provide more benefit. If the <a href="#baseRate">base rate</a> is 0.3 or 0.7, we can do better than <a href="#predictingFromBaseRate">going with the base rate</a>. If the <a href="#baseRate">base rate</a> is 0.9 or 0.1, it is difficult for our measure to do better than <a href="#predictingFromBaseRate">going with the base rate</a>. If the <a href="#baseRate">base rate</a> is 0.05 of 0.95 (or more extreme), it is likely that our measure will do almost nothing in terms of information gain.</p>
<p>```{r informationGainBaseRate, echo = FALSE, results = “hide”, fig.height = 4, out.width = “100%”, fig.align = “center”, fig.cap = “Information Gain as a Function of the Base Rate (BR).”} possibleCutoffs &lt;- unique(na.omit(mydataSDT$testScore)) possibleCutoffs &lt;- possibleCutoffs[order(possibleCutoffs)] possibleCutoffs &lt;- c(possibleCutoffs, max(possibleCutoffs, na.rm = TRUE) + 0.01)</p>
<p>baseRates &lt;- c(.05, .1, .3, .5, .7, .9, .95)</p>
<p>possibleCutoffsBaseRates &lt;- expand_grid(baseRate = baseRates, cutoff = possibleCutoffs)</p>
<p>informationGainVars &lt;- c(“cutoff”,“TP”,“TN”,“FP”,“FN”)</p>
<p>informationGainStats &lt;- data.frame(matrix(nrow = length(possibleCutoffs), ncol = length(informationGainVars))) names(informationGainStats) &lt;- informationGainVars</p>
<p>for(i in 1:length(possibleCutoffs)){ cutoff &lt;- possibleCutoffs[i]</p>
<p>mydataSDT<span class="math inline">\(diagnosis &lt;- NA
  mydataSDT\)</span>diagnosis[mydataSDT<span class="math inline">\(testScore &lt; cutoff] &lt;- 0
  mydataSDT\)</span>diagnosis[mydataSDT$testScore &gt;= cutoff] &lt;- 1</p>
<p>informationGainStats[i, “cutoff”] &lt;- cutoff informationGainStats[i, “TP”] &lt;- length(which(mydataSDT<span class="math inline">\(diagnosis == 1 &amp; mydataSDT\)</span>disorder == 1)) informationGainStats[i, “TN”] &lt;- length(which(mydataSDT<span class="math inline">\(diagnosis == 0 &amp; mydataSDT\)</span>disorder == 0)) informationGainStats[i, “FP”] &lt;- length(which(mydataSDT<span class="math inline">\(diagnosis == 1 &amp; mydataSDT\)</span>disorder == 0)) informationGainStats[i, “FN”] &lt;- length(which(mydataSDT<span class="math inline">\(diagnosis == 0 &amp; mydataSDT\)</span>disorder == 1)) }</p>
<p>informationGainStats &lt;- full_join(possibleCutoffsBaseRates, informationGainStats, by = “cutoff”)</p>
<p>informationGainStats<span class="math inline">\(TPrate &lt;- sensitivity(TP = informationGainStats\)</span>TP, TN = informationGainStats<span class="math inline">\(TN, FP = informationGainStats\)</span>FP, FN = informationGainStats<span class="math inline">\(FN)
informationGainStats\)</span>FPrate &lt;- falsePositiveRate(TP = informationGainStats<span class="math inline">\(TP, TN = informationGainStats\)</span>TN, FP = informationGainStats<span class="math inline">\(FP, FN = informationGainStats\)</span>FN)</p>
<p>informationGainStats<span class="math inline">\(informationGain &lt;- Igain(BR = informationGainStats\)</span>baseRate, HR = informationGainStats<span class="math inline">\(TPrate, FAR = informationGainStats\)</span>FPrate) informationGainStats &lt;- na.omit(informationGainStats)</p>
<p>ggplot( data = informationGainStats, aes( x = cutoff, y = informationGain, group = as.factor(baseRate), color = as.factor(baseRate))) + geom_line(linewidth = 2) + scale_x_continuous(name = “Cutoff”) + scale_y_continuous(name = “Information Gain”) + scale_color_viridis( name = “Base Rate”, discrete = TRUE, option = “H”) + geom_label_repel( data = informationGainStats %&gt;% filter(cutoff == 0.5), aes(label = paste(“BR =”, baseRate, sep = ““)), nudge_x = 0.10, na.rm = TRUE) + theme_bw() + theme(legend.position =”none”)</p>
<pre><code>

## Accuracy at Every Possible Cutoff {#accuracyAtEveryPossibleCutoff}

### Specify utility of each outcome {#specifyUtility}


```{r}
utilityHits &lt;- 1
utilityMisses &lt;- 0
utilityCorrectRejections &lt;- 0.75
utilityFalseAlarms &lt;- 0.25</code></pre>
</section>
</section>
</section>
<section id="calculateAccuracyAtEveryPossibleCutoff" class="level3" data-number="80.10.3">
<h3 data-number="80.10.3" class="anchored" data-anchor-id="calculateAccuracyAtEveryPossibleCutoff"><span class="header-section-number">80.10.3</span> Calculate Accuracy</h3>
<p>```{r, class.source = “fold-hide”} possibleCutoffs &lt;- unique(na.omit(mydataSDT$testScore)) possibleCutoffs &lt;- possibleCutoffs[order(possibleCutoffs)] possibleCutoffs &lt;- c( possibleCutoffs, max(possibleCutoffs, na.rm = TRUE) + 0.01)</p>
<p>accuracyVariables &lt;- c( “cutoff”, “TP”, “TN”, “FP”, “FN”, “differenceBetweenPredictedAndObserved”)</p>
<p>accuracyStats &lt;- data.frame( matrix( nrow = length(possibleCutoffs), ncol = length(accuracyVariables))) names(accuracyStats) &lt;- accuracyVariables</p>
<p>for(i in 1:length(possibleCutoffs)){ cutoff &lt;- possibleCutoffs[i]</p>
<p>mydataSDT<span class="math inline">\(diagnosis &lt;- NA
  mydataSDT\)</span>diagnosis[mydataSDT<span class="math inline">\(testScore &lt; cutoff] &lt;- 0
  mydataSDT\)</span>diagnosis[mydataSDT$testScore &gt;= cutoff] &lt;- 1</p>
<p>accuracyStats[i, “cutoff”] &lt;- cutoff accuracyStats[i, “TP”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 1 &amp; mydataSDT\)</span>disorder == 1)) accuracyStats[i, “TN”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 0 &amp; mydataSDT\)</span>disorder == 0)) accuracyStats[i, “FP”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 1 &amp; mydataSDT\)</span>disorder == 0)) accuracyStats[i, “FN”] &lt;- length(which( mydataSDT<span class="math inline">\(diagnosis == 0 &amp; mydataSDT\)</span>disorder == 1))</p>
<p>accuracyStats[i, “differenceBetweenPredictedAndObserved”] &lt;- miscalibration( predicted = mydataSDT<span class="math inline">\(testScore,
      actual = mydataSDT\)</span>disorder, cutoff = cutoff) }</p>
<p>accuracyStats<span class="math inline">\(N &lt;- sampleSize(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>accuracyStats<span class="math inline">\(selectionRatio &lt;- selectionRatio(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>baseRate &lt;- baseRate( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN)</p>
<p>accuracyStats<span class="math inline">\(percentAccuracy &lt;- percentAccuracy(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>percentAccuracyByChance &lt;- percentAccuracyByChance( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(relativeImprovementOverChance &lt;- relativeImprovementOverChance(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>relativeImprovementOverPredictingFromBaseRate &lt;- relativeImprovementOverPredictingFromBaseRate( TP = accuracyStats<span class="math inline">\(TP,
    TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
    FN = accuracyStats\)</span>FN)</p>
<p>accuracyStats<span class="math inline">\(sensitivity &lt;- accuracyStats\)</span>TPrate &lt;- sensitivity( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(specificity &lt;- accuracyStats\)</span>TNrate &lt;- specificity( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(FNrate &lt;- falseNegativeRate(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>FPrate &lt;- falsePositiveRate( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN)</p>
<p>accuracyStats<span class="math inline">\(youdenJ &lt;- youdenJ(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>accuracyStats<span class="math inline">\(positivePredictiveValue &lt;- positivePredictiveValue(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>negativePredictiveValue &lt;- negativePredictiveValue( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(falseDiscoveryRate &lt;- falseDiscoveryRate(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>falseOmissionRate &lt;- falseOmissionRate( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN)</p>
<p>accuracyStats<span class="math inline">\(balancedAccuracy &lt;- balancedAccuracy(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>f1Score &lt;- fScore( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(mcc &lt;- mcc(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>accuracyStats<span class="math inline">\(diagnosticOddsRatio &lt;- diagnosticOddsRatio(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>positiveLikelihoodRatio &lt;- positiveLikelihoodRatio( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(negativeLikelihoodRatio &lt;- negativeLikelihoodRatio(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>accuracyStats<span class="math inline">\(dPrimeSDT &lt;- dPrimeSDT(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>betaSDT &lt;- betaSDT( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(cSDT &lt;- cSDT(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats<span class="math inline">\(FN)
accuracyStats\)</span>ASDT &lt;- aSDT( TP = accuracyStats<span class="math inline">\(TP,
  TN = accuracyStats\)</span>TN, FP = accuracyStats<span class="math inline">\(FP,
  FN = accuracyStats\)</span>FN) accuracyStats<span class="math inline">\(bSDT &lt;- bSDT(
  TP = accuracyStats\)</span>TP, TN = accuracyStats<span class="math inline">\(TN,
  FP = accuracyStats\)</span>FP, FN = accuracyStats$FN)</p>
<p>accuracyStats<span class="math inline">\(overallUtility &lt;- Uoverall(
  BR = accuracyStats\)</span>baseRate, HR = accuracyStats<span class="math inline">\(TPrate,
  FAR = accuracyStats\)</span>FPrate, UH = utilityHits, UM = utilityMisses, UCR = utilityCorrectRejections, UFA = utilityFalseAlarms) accuracyStats<span class="math inline">\(utilityRatio &lt;- utilityRatio(
  UH = utilityHits,
  UM = utilityMisses,
  UCR = utilityCorrectRejections,
  UFA = utilityFalseAlarms)
accuracyStats\)</span>informationGain &lt;- Igain( BR = accuracyStats<span class="math inline">\(baseRate,
  HR = accuracyStats\)</span>TPrate, FAR = accuracyStats$FPrate)</p>
<p>#Replace NaN and INF values with NA is.nan.data.frame &lt;- function(x) do.call(cbind, lapply(x, is.nan))</p>
<p>accuracyStats[is.nan.data.frame(accuracyStats)] &lt;- NA accuracyStats &lt;- do.call( data.frame, lapply( accuracyStats, function(x) replace(x, is.infinite(x), NA)))</p>
<pre><code>

### All Accuracy Statistics {#allAccuracyStatistics}

The [`petersenlab`](https://github.com/DevPsyLab/petersenlab) package [@R-petersenlab] contains an R function that estimates the prediction accuracy at every possible cutoff.\index{petersenlab package}\index{cutoff}


```{r}
accuracyAtEachCutoff(
  predicted = mydataSDT$testScore,
  actual = mydataSDT$disorder,
  UH = utilityHits,
  UM = utilityMisses,
  UCR = utilityCorrectRejections,
  UFA = utilityFalseAlarms)</code></pre>
<p><code>{r, eval = knitr::is_html_output(excludes = "epub"), echo = knitr::is_html_output(excludes = "epub")} paged_table(accuracyStats)</code></p>
<p><code>{r, eval = knitr::is_latex_output(), echo = knitr::is_latex_output()} accuracyStats %&gt;%    head %&gt;%    t %&gt;%    round(., 2) %&gt;%    kable(.,       format = "latex",       booktabs = TRUE) %&gt;%   kable_styling(latex_options = "scale_down")</code></p>
<p><code>{r, eval = knitr::is_html_output(excludes = c("markdown","html","html4","html5","revealjs","s5","slideous","slidy","gfm")), echo = knitr::is_html_output(excludes = c("markdown","html","html4","html5","revealjs","s5","slideous","slidy","gfm"))} accuracyStats %&gt;%    head %&gt;%    t %&gt;%    round(., 2) %&gt;%    kable(., booktabs = TRUE)</code></p>
</section>
<section id="allAccuracyStatistics-youdenJ" class="level3" data-number="80.10.4">
<h3 data-number="80.10.4" class="anchored" data-anchor-id="allAccuracyStatistics-youdenJ"><span class="header-section-number">80.10.4</span> Youden’s J Statistic</h3>
<section id="allAccuracyStatistics-youdenJthreshold" class="level4" data-number="80.10.4.1">
<h4 data-number="80.10.4.1" class="anchored" data-anchor-id="allAccuracyStatistics-youdenJthreshold"><span class="header-section-number">80.10.4.1</span> Threshold</h4>
<p>Threshold at maximum combination of <a href="#sensitivity">sensitivity</a> and <a href="#specificity">specificity</a>:</p>
<p><span class="math inline">\(\text{max}(\text{sensitivity} + \text{specificity})\)</span></p>
<pre class="{r}"><code>youdenIndex &lt;- coords(roc(data = mydataSDT,
                          response = disorder,
                          predictor = testScore,
                          smooth = FALSE),
                      x = "best",
                      best.method = "youden")[[1]]

youdenIndex</code></pre>
</section>
<section id="allAccuracyStatistics-youdenJaccuracy" class="level4" data-number="80.10.4.2">
<h4 data-number="80.10.4.2" class="anchored" data-anchor-id="allAccuracyStatistics-youdenJaccuracy"><span class="header-section-number">80.10.4.2</span> Accuracy statistics at cutoff of Youden’s J Statistic</h4>
<pre class="{r}"><code>accuracyStats[head(which(
  accuracyStats$cutoff &gt;= youdenIndex), 1),]
accuracyStats[which(
  accuracyStats$youdenJ == max(accuracyStats$youdenJ, na.rm = TRUE)),]</code></pre>
</section>
</section>
<section id="allAccuracyStatistics-topLeftROC" class="level3" data-number="80.10.5">
<h3 data-number="80.10.5" class="anchored" data-anchor-id="allAccuracyStatistics-topLeftROC"><span class="header-section-number">80.10.5</span> Closest to the Top Left of the ROC Curve</h3>
<section id="allAccuracyStatistics-topLeftROCthreshold" class="level4" data-number="80.10.5.1">
<h4 data-number="80.10.5.1" class="anchored" data-anchor-id="allAccuracyStatistics-topLeftROCthreshold"><span class="header-section-number">80.10.5.1</span> Threshold</h4>
<p>Threshold where the ROC plot is closest to the Top Left:</p>
<pre class="{r}"><code>closestToTheTopLeft &lt;- coords(roc(
  data = mydataSDT,
  response = disorder,
  predictor = testScore,
  smooth = FALSE),
  x = "best",
  best.method = "closest.topleft")[[1]]</code></pre>
</section>
<section id="allAccuracyStatistics-topLeftROCaccuracy" class="level4" data-number="80.10.5.2">
<h4 data-number="80.10.5.2" class="anchored" data-anchor-id="allAccuracyStatistics-topLeftROCaccuracy"><span class="header-section-number">80.10.5.2</span> Accuracy stats at cutoff where the ROC plot is closest to the Top Left</h4>
<pre class="{r}"><code>accuracyStats[head(which(
  accuracyStats$cutoff &gt;= closestToTheTopLeft), 1),]</code></pre>
</section>
</section>
<section id="allAccuracyStatistics-cutoff" class="level3" data-number="80.10.6">
<h3 data-number="80.10.6" class="anchored" data-anchor-id="allAccuracyStatistics-cutoff"><span class="header-section-number">80.10.6</span> Cutoff that optimizes each of the following criteria:</h3>
<p>The <a href="https://github.com/DevPsyLab/petersenlab"><code>petersenlab</code></a> package <span class="citation" data-cites="R-petersenlab">(<a href="../../99-references.html#ref-R-petersenlab" role="doc-biblioref"><strong>R-petersenlab?</strong></a>)</span> contains an R function that identifies the cutoff that optimizes each of various accuracy estimates.</p>
<pre class="{r}"><code>optimalCutoff(
  predicted = mydataSDT$testScore,
  actual = mydataSDT$disorder,
  UH = utilityHits,
  UM = utilityMisses,
  UCR = utilityCorrectRejections,
  UFA = utilityFalseAlarms)</code></pre>
<section id="allAccuracyStatistics-cutoffPercentAccuracy" class="level4" data-number="80.10.6.1">
<h4 data-number="80.10.6.1" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffPercentAccuracy"><span class="header-section-number">80.10.6.1</span> Percent Accuracy</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$percentAccuracy == max(
    accuracyStats$percentAccuracy,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffPercentAccuracyByChance" class="level4" data-number="80.10.6.2">
<h4 data-number="80.10.6.2" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffPercentAccuracyByChance"><span class="header-section-number">80.10.6.2</span> Percent Accuracy by Chance</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$percentAccuracyByChance == max(
    accuracyStats$percentAccuracyByChance,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffROIC" class="level4" data-number="80.10.6.3">
<h4 data-number="80.10.6.3" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffROIC"><span class="header-section-number">80.10.6.3</span> Relative Improvement Over Chance (ROIC)</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$relativeImprovementOverChance == max(
    accuracyStats$relativeImprovementOverChance,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffRelativeImprovementOverPredictingFromBaseRate" class="level4" data-number="80.10.6.4">
<h4 data-number="80.10.6.4" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffRelativeImprovementOverPredictingFromBaseRate"><span class="header-section-number">80.10.6.4</span> Relative Improvement Over Predicting from the Base Rate</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$relativeImprovementOverPredictingFromBaseRate == max(
    accuracyStats$relativeImprovementOverPredictingFromBaseRate,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffSensitivity" class="level4" data-number="80.10.6.5">
<h4 data-number="80.10.6.5" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffSensitivity"><span class="header-section-number">80.10.6.5</span> Sensitivity</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$sensitivity == max(
    accuracyStats$sensitivity,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffSpecificity" class="level4" data-number="80.10.6.6">
<h4 data-number="80.10.6.6" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffSpecificity"><span class="header-section-number">80.10.6.6</span> Specificity</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$specificity == max(
    accuracyStats$specificity,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffPPV" class="level4" data-number="80.10.6.7">
<h4 data-number="80.10.6.7" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffPPV"><span class="header-section-number">80.10.6.7</span> Positive Predictive Value</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$positivePredictiveValue == max(
    accuracyStats$positivePredictiveValue,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffNPV" class="level4" data-number="80.10.6.8">
<h4 data-number="80.10.6.8" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffNPV"><span class="header-section-number">80.10.6.8</span> Negative Predictive Value</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$negativePredictiveValue == max(
    accuracyStats$negativePredictiveValue,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffYoudenJ" class="level4" data-number="80.10.6.9">
<h4 data-number="80.10.6.9" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffYoudenJ"><span class="header-section-number">80.10.6.9</span> Youden’s J Statistic</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$youdenJ == max(
    accuracyStats$youdenJ,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffBalancedAccuracy" class="level4" data-number="80.10.6.10">
<h4 data-number="80.10.6.10" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffBalancedAccuracy"><span class="header-section-number">80.10.6.10</span> Balanced Accuracy</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$balancedAccuracy == max(
    accuracyStats$balancedAccuracy,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffF1" class="level4" data-number="80.10.6.11">
<h4 data-number="80.10.6.11" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffF1"><span class="header-section-number">80.10.6.11</span> F1 Score</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$f1Score == max(
    accuracyStats$f1Score,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffMCC" class="level4" data-number="80.10.6.12">
<h4 data-number="80.10.6.12" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffMCC"><span class="header-section-number">80.10.6.12</span> Matthews Correlation Coefficient</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$mcc == max(
    accuracyStats$mcc,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffDOR" class="level4" data-number="80.10.6.13">
<h4 data-number="80.10.6.13" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffDOR"><span class="header-section-number">80.10.6.13</span> Diagnostic Odds Ratio</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$diagnosticOddsRatio == max(
    accuracyStats$diagnosticOddsRatio,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffPLR" class="level4" data-number="80.10.6.14">
<h4 data-number="80.10.6.14" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffPLR"><span class="header-section-number">80.10.6.14</span> Positive Likelihood Ratio</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$positiveLikelihoodRatio == max(
    accuracyStats$positiveLikelihoodRatio,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffNLR" class="level4" data-number="80.10.6.15">
<h4 data-number="80.10.6.15" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffNLR"><span class="header-section-number">80.10.6.15</span> Negative Likelihood Ratio</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$negativeLikelihoodRatio == min(
    accuracyStats$negativeLikelihoodRatio,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffDprime" class="level4" data-number="80.10.6.16">
<h4 data-number="80.10.6.16" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffDprime"><span class="header-section-number">80.10.6.16</span> <span class="math inline">\(d'\)</span> Sensitivity</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$dPrimeSDT == max(
    accuracyStats$dPrimeSDT,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffAsensitivity" class="level4" data-number="80.10.6.17">
<h4 data-number="80.10.6.17" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffAsensitivity"><span class="header-section-number">80.10.6.17</span> <span class="math inline">\(A\)</span> (Non-Parametric) Sensitivity</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$ASDT == max(
    accuracyStats$ASDT,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffBetaBias" class="level4" data-number="80.10.6.18">
<h4 data-number="80.10.6.18" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffBetaBias"><span class="header-section-number">80.10.6.18</span> <span class="math inline">\(\beta\)</span> Bias</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(abs(
  accuracyStats$betaSDT) == min(abs(
    accuracyStats$betaSDT),
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffCbias" class="level4" data-number="80.10.6.19">
<h4 data-number="80.10.6.19" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffCbias"><span class="header-section-number">80.10.6.19</span> <span class="math inline">\(c\)</span> Bias</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(abs(
  accuracyStats$cSDT) == min(abs(
    accuracyStats$cSDT),
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffBbias" class="level4" data-number="80.10.6.20">
<h4 data-number="80.10.6.20" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffBbias"><span class="header-section-number">80.10.6.20</span> <span class="math inline">\(b\)</span> (Non-Parametric) Bias</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(abs(
  accuracyStats$bSDT) == min(abs(
    accuracyStats$bSDT),
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffMiscalibration" class="level4" data-number="80.10.6.21">
<h4 data-number="80.10.6.21" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffMiscalibration"><span class="header-section-number">80.10.6.21</span> Mean difference between predicted and observed values (Miscalibration)</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(abs(
  accuracyStats$differenceBetweenPredictedAndObserved) == min(abs(
    accuracyStats$differenceBetweenPredictedAndObserved),
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffOverallUtility" class="level4" data-number="80.10.6.22">
<h4 data-number="80.10.6.22" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffOverallUtility"><span class="header-section-number">80.10.6.22</span> Overall Utility</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$overallUtility == max(
    accuracyStats$overallUtility,
    na.rm = TRUE))]</code></pre>
</section>
<section id="allAccuracyStatistics-cutoffIgain" class="level4" data-number="80.10.6.23">
<h4 data-number="80.10.6.23" class="anchored" data-anchor-id="allAccuracyStatistics-cutoffIgain"><span class="header-section-number">80.10.6.23</span> Information Gain</h4>
<p></p>
<pre class="{r}"><code>accuracyStats$cutoff[which(
  accuracyStats$informationGain == max(
    accuracyStats$informationGain,
    na.rm = TRUE))]</code></pre>
</section>
</section>
</section>
<section id="regression-prediction" class="level2" data-number="80.11">
<h2 data-number="80.11" class="anchored" data-anchor-id="regression-prediction"><span class="header-section-number">80.11</span> Regression for Prediction of Continuous Outcomes</h2>
<p>When predicting a continuous outcome, regression is particularly relevant (or multiple regression, when dealing with multiple predictors). Regression takes the general form in Equation @ref(eq:regression):</p>
<p><span class="math display">\[\begin{equation}
y = b_0 + b_1 \cdot x_1 + e
(\#eq:regression)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the outcome, <span class="math inline">\(b_0\)</span> is the intercept, <span class="math inline">\(b_1\)</span> is the slope of the association between the predictor (<span class="math inline">\(x_1\)</span>) and outcome, and <span class="math inline">\(e\)</span> is the error term.</p>
<p>```{r, echo = FALSE} regression1 &lt;- data.frame( “y” = c(7, 13, 29, 10), “x1” = c(1, 2, 7, 2))</p>
<p>regression2 &lt;- data.frame( “y” = c(7, 13, 29, 10), “x1” = c(1, 2, 7, 2), “x2” = c(3, 5, 1, 2))</p>
<p>regression1_model &lt;- lm( y ~ x1, data = regression1)</p>
<p>regression1_intercept &lt;- regression1_model<span class="math inline">\(coefficients[[1]]
regression1_slope &lt;- regression1_model\)</span>coefficients[[2]] regression1_rsquare &lt;- summary(regression1_model)$r.squared</p>
<p>regression2_model &lt;- lm(y ~ x1 + x2, data = regression2) regression2_intercept &lt;- regression2_model<span class="math inline">\(coefficients[[1]]
regression2_slope1 &lt;- regression2_model\)</span>coefficients[[2]] regression2_slope2 &lt;- regression2_model<span class="math inline">\(coefficients[[3]]
regression2_rsquare &lt;- summary(regression2_model)\)</span>r.squared</p>
<pre><code>

## Pseudo-Prediction {#pseudoPrediction}

Consider the following example where you have one predictor and one outcome, as shown in Table \@ref(tab:regression1).\index{multiple regression}


```{r regression1, echo = FALSE}
kable(regression1,
      col.names = c("y","x1"),
      caption = "Example Data of Predictor (x1) and Outcome (y) Used for Regression Model.",
      booktabs = TRUE)</code></pre>
<p>Using the data, the best fitting regression model is: <span class="math inline">\(y = `r apa(regression1_intercept, decimals = 2)` + `r apa(regression1_slope, decimals = 2)` \cdot x_1\)</span>. In this example, the <span class="math inline">\(R^2\)</span> is <span class="math inline">\(`r apa(regression1_rsquare, decimals = 2)`\)</span>. The equation is not a perfect prediction, but with a single predictor, it captures the majority of the variance in the outcome.</p>
<p>Now consider the following example where you add a second predictor to the data above, as shown in Table @ref(tab:regression2).</p>
<p><code>{r regression2, echo = FALSE} kable(regression2,       col.names = c("y","x1","x2"),       caption = "Example Data of Predictors (x1 and x2) and Outcome (y) Used for Regression Model.",       booktabs = TRUE)</code></p>
<p>With the second predictor, the best fitting regression model is: <span class="math inline">\(y = `r apa(regression2_intercept, decimals = 2)` + `r apa(regression2_slope1, decimals = 2)` \cdot x_1 + `r apa(regression2_slope2, decimals = 2)` \cdot x_2\)</span>. In this example, the <span class="math inline">\(R^2\)</span> is <span class="math inline">\(`r apa(regression2_rsquare, decimals = 2)`\)</span>. The equation with the second predictor provides a perfect prediction of the outcome.</p>
<p>Providing perfect prediction with the right set of predictors is the dream of multiple regression. So, in psychology, we often add predictors to incrementally improve prediction. Knowing how much variance would be accounted for by random chance follows Equation @ref(eq:predictionByChance):</p>
<p><span class="math display">\[\begin{equation}
E(R^2) = \frac{K}{n-1}
(\#eq:predictionByChance)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(E(R^2)\)</span> is the expected value of <span class="math inline">\(R^2\)</span> (the proportion of variance explained), <span class="math inline">\(K\)</span> is the number of predictors, and <span class="math inline">\(n\)</span> is the sample size. The formula demonstrates that the more predictors in the regression model, the more variance will be accounted for by chance. With many predictors and a small sample, you can account for a large share of the variance merely by chance—this would be an example of pseudo-prediction.</p>
<p>As an example, consider that we have 13 predictors to predict behavior problems for 43 children. Assume that, with 13 predictors, we explain 38% of the variance (<span class="math inline">\(R^2 = .38; r = .62\)</span>). Explaining more than 20–30% of the variance can be a big deal in psychology. We explained a lot of the variance in the outcome, but it is important to consider how much variance could have been explained by random chance: <span class="math inline">\(E(R^2) = \frac{K}{n-1} = \frac{13}{43 - 1} = .31\)</span>. We expect to explain 31% of the variance, by chance, in the outcome. So, 82% of the variance explained was likely spurious. As the sample size increases, the spuriousness decreases. Adjusted <span class="math inline">\(R^2\)</span> accounts for the number of predictors in the model, based on how much would be expected to be accounted for by chance. But adjusted <span class="math inline">\(R^2\)</span> also has its problems.</p>
<section id="multiCollinearity" class="level3" data-number="80.11.1">
<h3 data-number="80.11.1" class="anchored" data-anchor-id="multiCollinearity"><span class="header-section-number">80.11.1</span> Multicollinearity</h3>
<p><em>Multicollinearity</em> occurs when two or more predictors in a regression model are highly correlated. The problem is that it makes it challenging to estimate the regression coefficients accurately.</p>
<p>Multicollinearity in multiple regression is depicted conceptually in Figure @ref(fig:multipleRegressionMulticollinearity).</p>
<p><code>{r multipleRegressionMulticollinearity, out.width = "50%", fig.align = "center", fig.cap = "Conceptual Depiction of Multicollinearity in Multiple Regression.", echo = FALSE} knitr::include_graphics("./Images/multipleRegressionMulticollinearity.png")</code></p>
<p>Consider the following example where you have two predictors and one outcome, as shown in Table @ref(tab:regression3).</p>
<p><code>{r, echo = FALSE} regression3 &lt;- data.frame(   "y" = c(9, 11, 17, 3, 21, 13),   "x1" = c(2, 3, 4, 1, 5, 3.5),   "x2" = c(4, 6, 8, 2, 10, 7))</code></p>
<p><code>{r regression3, echo = FALSE} kable(regression3,       col.names = c("y","x1","x2"),       caption = "Example Data of Predictors (x1 and x2) and Outcome (y) Used for Regression Model.",       booktabs = TRUE)</code></p>
<p>The second measure is not very good—it is exactly twice the value of the first measure. This means that there are different prediction equation possibilities that are equally good—see Equations in @ref(eq:multicollinearity):</p>
<p><span class="math display">\[
\begin{aligned}
  2x_2 &amp;= y \\
  0x_1 + 2x_2 &amp;= y \\
  4x_1 &amp;= y \\
  4x_1 + 0x_2 &amp;= y \\
  2x_1 + 1x_2 &amp;= y \\
  5x_1 - 0.5x_2 &amp;= y \\
  ...
&amp;= y
\end{aligned}
(\#eq:multicollinearity)
\]</span></p>
<p>Then, what are the regression coefficients? We do not know, and we could come up with arbitrary estimates with an enormous standard error around each estimate. Any predictors that have a correlation above ~ <span class="math inline">\(r = .30\)</span> with each other could have an impact on the confidence interval of the regression coefficient. As the correlations among the predictors increase, the chance of getting an arbitrary answer increases, sometimes called “bouncing betas.” So, it is important to examine a correlation matrix of the predictors before putting them in the same regression model. You can also examine indices such as variance inflation factor (VIF).</p>
<p>Generalized VIF (GVIF) values are estimated below using the <code>car</code> package <span class="citation" data-cites="R-car">(<a href="../../99-references.html#ref-R-car" role="doc-biblioref"><strong>R-car?</strong></a>)</span>.</p>
<pre class="{r}"><code>set.seed(52242)
mydataSDT$collinearPredictor &lt;- mydataSDT$ndka + 
rnorm(nrow(mydataSDT), sd = 20)

collinearRegression_model &lt;- lm(
  s100b ~ ndka + gender + age + wfns + collinearPredictor,
  data = mydataSDT)

vif(collinearRegression_model)</code></pre>
<p>To address multicollinearity, you can drop a redundant predictor or you can also use <a href="#pca">principal component analysis</a> or <a href="#factorAnalysis">factor analysis</a> of the predictors to reduce the predictors down to a smaller number of meaningful predictors. For a meaningful answer in a regression framework that is precise and confident, you need a low level of intercorrelation among predictors, unless you have a very large sample size.</p>
<p>However, multicollinearity does not bias parameter estimates (i.e., multicollinearity does not lead to <a href="#meanError">mean error</a>). Instead, <a href="https://janhove.github.io/analysis/2019/09/11/collinearity">multicollinearity increases the uncertainty (i.e., standard errors) around the parameter estimates</a> (archived at https://perma.cc/DJ7L-TCUK), which makes it more challenging to detect an effect as statistically significant. <a href="https://statisticalhorizons.com/multicollinearity/">Some forms of multicollinearity are ignorable</a> (archived at https://perma.cc/2JV5-2QEZ), including when the multicollinearity is among (a) the control variables rather than the variables of interest, (b) the powers (e.g., quadratic term) or products (e.g., interaction term) of other variables, or (c) dummy-coded categories. Ultimately, <a href="https://janhove.github.io/analysis/2019/09/11/collinearity">it is important to examine the question of interest, even if that means inclusion of predictors that are inter-correlated in a regression model</a> (archived at https://perma.cc/DJ7L-TCUK). However, it would not make sense to include two predictors that are perfectly correlated, because they are redundant.</p>
</section>
</section>
<section id="waysToImprovePredictionAccuracy" class="level2" data-number="80.12">
<h2 data-number="80.12" class="anchored" data-anchor-id="waysToImprovePredictionAccuracy"><span class="header-section-number">80.12</span> Ways to Improve Prediction Accuracy</h2>
<p>On the whole, experts’ predictions are inaccurate. Experts’ predictions from many different domains tend to be inaccurate, including political scientists <span class="citation" data-cites="Tetlock2017">(<a href="../../99-references.html#ref-Tetlock2017" role="doc-biblioref"><strong>Tetlock2017?</strong></a>)</span>, physicians <span class="citation" data-cites="Koehler2002">(<a href="../../99-references.html#ref-Koehler2002" role="doc-biblioref"><strong>Koehler2002?</strong></a>)</span>, clinical psychologists <span class="citation" data-cites="Oskamp1965">(<a href="../../99-references.html#ref-Oskamp1965" role="doc-biblioref"><strong>Oskamp1965?</strong></a>)</span>, stock market traders and corporate financial officers <span class="citation" data-cites="Skala2008">(<a href="../../99-references.html#ref-Skala2008" role="doc-biblioref"><strong>Skala2008?</strong></a>)</span>, seismologists’ predictions of earthquakes <span class="citation" data-cites="Hough2016">(<a href="../../99-references.html#ref-Hough2016" role="doc-biblioref"><strong>Hough2016?</strong></a>)</span>, economists’ predictions about the economy <span class="citation" data-cites="Makridakis2009">(<a href="../../99-references.html#ref-Makridakis2009" role="doc-biblioref"><strong>Makridakis2009?</strong></a>)</span>, lawyers <span class="citation" data-cites="Koehler2002">(<a href="../../99-references.html#ref-Koehler2002" role="doc-biblioref"><strong>Koehler2002?</strong></a>)</span>, and business managers <span class="citation" data-cites="Russo1992">(<a href="../../99-references.html#ref-Russo1992" role="doc-biblioref"><strong>Russo1992?</strong></a>)</span>. The most common pattern of experts’ predictions is that they show overextremity, that is, their predictions have probability judgments that tend to be too extreme, as described in Section @ref(calibration). Overextremity of experts’ predictions likely reflects over-confidence. The degree of confidence of a person’s predictions is often not a good indicator of the accuracy of their predictions [and confidence and prediction accuracy are sometimes inversely associated; <span class="citation" data-cites="Silver2012">(<a href="../../99-references.html#ref-Silver2012" role="doc-biblioref"><strong>Silver2012?</strong></a>)</span>]. Cognitive biases including the anchoring bias <span class="citation" data-cites="Tversky1974">(<a href="../../99-references.html#ref-Tversky1974" role="doc-biblioref"><strong>Tversky1974?</strong></a>)</span>, the confirmation bias <span class="citation" data-cites="Hoch1985 Koriat1980">(<a href="../../99-references.html#ref-Hoch1985" role="doc-biblioref"><strong>Hoch1985?</strong></a>; <a href="../../99-references.html#ref-Koriat1980" role="doc-biblioref"><strong>Koriat1980?</strong></a>)</span>, and <a href="#baseRate">base rate</a> neglect <span class="citation" data-cites="Eddy1982 Koehler2002">(<a href="../../99-references.html#ref-Eddy1982" role="doc-biblioref"><strong>Eddy1982?</strong></a>; <a href="../../99-references.html#ref-Koehler2002" role="doc-biblioref"><strong>Koehler2002?</strong></a>)</span> could contribute to over-confidence of predictions. <a href="#calibration">Poorly calibrated</a> predictions are especially likely when the <a href="#baseRate">base rate</a> is very low (e.g., suicide), as is often the case in clinical psychology, or when the <a href="#baseRate">base rate</a> is very high <span class="citation" data-cites="Koehler2002">(<a href="../../99-references.html#ref-Koehler2002" role="doc-biblioref"><strong>Koehler2002?</strong></a>)</span>.</p>
<p>Nevertheless, there are some domains that have shown greater predictive accuracy, from which we may learn what practices may lead to greater accuracy. For instance, experts have shown stronger predictive accuracy in weather forecasting <span class="citation" data-cites="Murphy1984">(<a href="../../99-references.html#ref-Murphy1984" role="doc-biblioref"><strong>Murphy1984?</strong></a>)</span>, horse race betting <span class="citation" data-cites="Johnson2001">(<a href="../../99-references.html#ref-Johnson2001" role="doc-biblioref"><strong>Johnson2001?</strong></a>)</span>, and playing the card game of bridge <span class="citation" data-cites="Keren1987">(<a href="../../99-references.html#ref-Keren1987" role="doc-biblioref"><strong>Keren1987?</strong></a>)</span>, but see <span class="citation" data-cites="Koehler2002">(<a href="../../99-references.html#ref-Koehler2002" role="doc-biblioref"><strong>Koehler2002?</strong></a>)</span> for exceptions.</p>
<p>Here are some potential ways to improve the accuracy (and honesty) of predictions and judgments:</p>
<ul>
<li>Provide appropriate anchoring of your predictions to the <a href="#baseRate">base rate</a> of the phenomenon you are predicting. To the extent that the <a href="#baseRate">base rate</a> of the event you are predicting is low, more extreme evidence should be necessary to consistently and accurately predict that the event will occur. Applying <a href="#bayesTheorem">Bayes’ theorem</a> and Bayesian approaches can help you appropriately weigh <a href="#baseRate">base rate</a> and evidence.</li>
<li>Include multiple predictors, ideally from different measures and measurement methods. Include the predictors with the strongest validity based on theory of the causal process and based on <a href="#criterionValidity">criterion-related validity</a>.</li>
<li>When possible, aggregate multiple perspectives of predictions, especially predictions made independently (from different people/methods/etc.). The “wisdom of the crowd” is often more accurate than individuals’ predictions, including predictions by so-called “experts” <span class="citation" data-cites="Silver2012">(<a href="../../99-references.html#ref-Silver2012" role="doc-biblioref"><strong>Silver2012?</strong></a>)</span>.</li>
<li>A goal of prediction is to capture as much signal as possible and as little noise (error) as possible <span class="citation" data-cites="Silver2012">(<a href="../../99-references.html#ref-Silver2012" role="doc-biblioref"><strong>Silver2012?</strong></a>)</span>. Parsimony (i.e., not having too many predictors) can help reduce the amount of error variance captured by the prediction model. However, to accurately model complex systems like human behavior, the brain, etc., complex models may be necessary. Nevertheless, strong theory of the causal processes and dynamics may be necessary to develop accurate complex models.</li>
<li>Although incorporating theory can be helpful, provide more weight to empiricism than to theory, until our theories and measures are stronger. Ideally, we would use theory to design a model that mirrors the causal system, with accurate measures of each process in the system, so we could make accurate predictions. However, as described in Section @ref(theoryEmpiricism), our psychological theories of the causal processes that influence outcomes are not yet very strong. Until we have stronger theories that specify the causal process for a given outcome, and until we have accurate measures of those causal processes, <a href="#actuarialPrediction">actuarial</a> approaches are likely to be most accurate, as discussed in Chapter @ref(actuarial). At the same time, keep in mind that measures in psychology, and their resulting data, are often noisy. As a result, theoretically (conceptually) informed empirical approaches may lead to more accuracy than empiricism alone.</li>
<li>Use an empirically validated and cross-validated <a href="#actuarial">statistical algorithm</a> to combine information from the predictors in a formalized way. Give each predictor appropriate weight in the statistical algorithm, according to its strength of association with the outcome. Use measures with strong <a href="#reliability">reliability</a> and <a href="#validity">validity</a> for assessing these processes to be used in the algorithm. Cross-validation will help reduce the likelihood that your model is fitting to noise and will maximize the likelihood that the model predicts accurately when applied to new data (i.e., the model’s predictions accurately generalize), as described in Section @ref(modelAccuracy-actuarial).</li>
<li>When presenting your predictions, acknowledge what you do not know.</li>
<li>Express your predictions in terms of probabilistic estimates and present the uncertainty in your predictions with confidence intervals [even though bolder, more extreme predictions tend to receive stronger television ratings; <span class="citation" data-cites="Silver2012">(<a href="../../99-references.html#ref-Silver2012" role="doc-biblioref"><strong>Silver2012?</strong></a>)</span>].</li>
<li>Qualify your predictions by identifying and noting counter-examples that would not be well fit by your prediction model, such as extreme cases, edge cases, and “broken leg” <span class="citation" data-cites="Meehl1957">(<a href="../../99-references.html#ref-Meehl1957" role="doc-biblioref"><strong>Meehl1957?</strong></a>)</span> cases.</li>
<li>Provide clear, consistent, and timely feedback on the outcomes of the predictions to the people making the predictions <span class="citation" data-cites="Bolger2004">(<a href="../../99-references.html#ref-Bolger2004" role="doc-biblioref"><strong>Bolger2004?</strong></a>)</span>.</li>
<li>Be self-critical about your predictions. Update your judgments based on their accuracy, rather than trying to confirm your beliefs <span class="citation" data-cites="Atanasov2020">(<a href="../../99-references.html#ref-Atanasov2020" role="doc-biblioref"><strong>Atanasov2020?</strong></a>)</span>.</li>
<li>In addition to considering the accuracy of the prediction, consider the quality of the prediction <em>process</em>, especially when random chance is involved to a degree (such as in poker) <span class="citation" data-cites="Silver2012">(<a href="../../99-references.html#ref-Silver2012" role="doc-biblioref"><strong>Silver2012?</strong></a>)</span>.</li>
<li>Work to identify and mitigate potential blindspots; be aware of cognitive biases, such as confirmation bias and <a href="#baseRate">base rate</a> neglect.</li>
<li>Evaluate for the possibility of <a href="#bias">bias</a> in the predictions or in the tests from which the predictions are derived. Correct for any <a href="#bias">test bias</a>.</li>
</ul>
</section>
<section id="conclusion-prediction" class="level2" data-number="80.13">
<h2 data-number="80.13" class="anchored" data-anchor-id="conclusion-prediction"><span class="header-section-number">80.13</span> Conclusion</h2>
<p>Human behavior is challenging to predict. People commonly make cognitive pseudo-prediction errors, such as the <a href="#inverseFallacy">confusion of inverse probabilities</a>. People also tend to ignore <a href="#baseRate">base rates</a> when making predictions. When the <a href="#baseRate">base rate</a> of a behavior is very low or very high, you can be highly accurate in predicting the behavior by <a href="#predictingFromBaseRate">predicting from the base rate</a>. Thus, you cannot judge how accurate your prediction is until you know how accurate your predictions would be by <a href="#accuracyByChance">random chance</a>. Moreover, maximizing <a href="#percentAccuracy">percent accuracy</a> may not be the ultimate goal because <a href="#differentErrorsDifferentCosts">different errors have different costs</a>. Though there are many types of accuracy, there are two broad types: <a href="#discrimination">discrimination</a> and <a href="#calibration">calibration</a>—and they are orthogonal. <a href="#discrimination">Discrimination</a> accuracy is frequently evaluated with the <a href="#auc">area under the receiver operating characteristic curve</a>, or with <a href="#sensitivity">sensitivity</a> and <a href="#specificity">specificity</a>, or <a href="#standardizedRegressionCoefficient">standardized regression coefficients</a>. <a href="#calibration">Calibration</a> accuracy is frequently evaluated graphically and with various indices. <a href="#sensitivity">Sensitivity</a> and <a href="#specificity">specificity</a> <a href="#accuracyCutoff">depend on the cutoff</a>. Therefore, the <a href="#optimalCutoff">optimal cutoff</a> depends on the purposes of the assessment and how much one weights the various costs of the different types of errors: <a href="#falseNegative">false negatives</a> and <a href="#falsePositive">false positives</a>. It is important to evaluate both <a href="#discrimination">discrimination</a> and <a href="#calibration">calibration</a> when evaluating prediction accuracy.</p>
</section>
<section id="readings-prediction" class="level2" data-number="80.14">
<h2 data-number="80.14" class="anchored" data-anchor-id="readings-prediction"><span class="header-section-number">80.14</span> Suggested Readings</h2>
<p><span class="citation" data-cites="Steyerberg2010">(<a href="../../99-references.html#ref-Steyerberg2010" role="doc-biblioref"><strong>Steyerberg2010?</strong></a>)</span>; <span class="citation" data-cites="Meehl1955">(<a href="../../99-references.html#ref-Meehl1955" role="doc-biblioref"><strong>Meehl1955?</strong></a>)</span>; <span class="citation" data-cites="Treat2023">(<a href="../../99-references.html#ref-Treat2023" role="doc-biblioref"><strong>Treat2023?</strong></a>)</span>; <span class="citation" data-cites="Wiggins1973">(<a href="../../99-references.html#ref-Wiggins1973" role="doc-biblioref"><strong>Wiggins1973?</strong></a>)</span></p>
</section>
<section id="exercises-prediction" class="level2" data-number="80.15">
<h2 data-number="80.15" class="anchored" data-anchor-id="exercises-prediction"><span class="header-section-number">80.15</span> Exercises</h2>
<p><code>{r, include = FALSE} library("MOTE")</code></p>
<p>```{r, include = FALSE} # Load Data —————————————————————</p>
<p>titanic &lt;- read_csv(here(“Data”, “titanic.csv”))</p>
<pre><code>
```{r, include = FALSE}
# ROC Curve ---------------------------------------------------------------

rocCurve_ex &lt;- roc(data = titanic, response = survived, predictor = prediction, smooth = FALSE)
plot(rocCurve_ex, legacy.axes = TRUE)
coords(rocCurve_ex, x = "best", best.method = "youden") #Youden's index (max combination of sensitivity and specificity) is at threshold of 0.205, where sensitivity is 0.65 and specificity is 0.80
coords(rocCurve_ex, x = "best", best.method = "closest.topleft") #The point closest to the top-left part of the ROC plot with perfect sensitivity or specificity: min((1 - sensitivity)^2 + (1 - specificity)^2)

rocCurveSmooth_ex &lt;- roc(data = titanic, response = survived, predictor = prediction, smooth = TRUE)
plot(rocCurveSmooth_ex, legacy.axes = TRUE)</code></pre>
<p>```{r, include = FALSE} # Overall Prediction Accuracy ———————————————</p>
<p>meanError_ex &lt;- meanError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived) meanAbsoluteError_ex &lt;- meanAbsoluteError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived) meanSquaredError_ex &lt;- meanSquaredError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived) rootMeanSquaredError_ex &lt;- rootMeanSquaredError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived) meanPercentageError_ex &lt;- meanPercentageError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived, dropUndefined = TRUE) meanAbsolutePercentageError_ex &lt;- meanAbsolutePercentageError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived, dropUndefined = TRUE) symmetricMeanAbsolutePercentageError_ex &lt;- symmetricMeanAbsolutePercentageError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived) meanAbsoluteScaledError_ex &lt;- meanAbsoluteScaledError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived) rootMeanSquaredLogError_ex &lt;- rootMeanSquaredLogError(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived, dropUndefined = TRUE)</p>
<p>summary(lm(survived ~ prediction, data = titanic)) rsquared_ex &lt;- summary(lm(survived ~ prediction, data = titanic))<span class="math inline">\(r.squared
rsquaredAdj_ex &lt;- summary(lm(survived ~ prediction, data = titanic))\)</span>adj.r.squared predictiveRsquaredValue_ex &lt;- predictiveRSquared(predicted = titanic<span class="math inline">\(prediction, actual = titanic\)</span>survived)</p>
<pre><code>
```{r, include = FALSE}
#Discrimination: Area under the ROC curve (AUC)
rocCurve_ex$auc

auc_ex &lt;- rocCurve_ex$auc</code></pre>
<p><code>{r, include = FALSE} #Calibration Plot (see here: https://perma.cc/6J3J-69G7) val.prob(titanic$prediction, titanic$survived)</code></p>
<p>```{r, include = FALSE} g1_ex &lt;- mutate(titanic, bin = cut_number(prediction, 10)) %&gt;% # Bin prediction into 10ths group_by(bin) %&gt;% mutate(n = length(na.omit(prediction)), # Get ests and CIs bin_pred = mean(prediction, na.rm = TRUE), bin_prob = mean(survived, na.rm = TRUE), se = sd(survived, na.rm = TRUE) / sqrt(n), ul = bin_prob + qnorm(.975) * se, ll = bin_prob - qnorm(.975) * se) %&gt;% ungroup() %&gt;% ggplot(aes(x = bin_pred, y = bin_prob, ymin = ll, ymax = ul)) + geom_pointrange(size = 0.5, color = “black”) + scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + geom_abline() + # 45 degree line indicating perfect calibration geom_smooth(method = “lm”, se = FALSE, linetype = “dashed”, color = “black”, formula = y~-1 + x) + # straight line fit through estimates geom_smooth(aes(x = prediction, y = survived), color = “red”, se = FALSE, method = “loess”) + # loess fit through estimates xlab(““) + ylab(”Observed Probability”) + theme_minimal()+ xlab(“Predicted Probability”)</p>
<p>g2_ex &lt;- ggplot(titanic, aes(x = prediction)) + geom_histogram(fill = “black”, bins = 200) + scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + xlab(“Histogram of Predicted Probability”) + ylab(““) + theme_minimal() + theme(panel.grid.minor = element_blank())</p>
<p>g_ex &lt;- arrangeGrob(g1_ex, g2_ex, respect = TRUE, heights = c(1, 0.25), ncol = 1) grid.arrange(g_ex)</p>
<pre><code>
```{r, include = FALSE}
#Calibration: Brier Scores
val.prob(titanic$prediction, titanic$survived, pl = FALSE)["Brier"]

#Calibration: Hosler-Lemeshow Test
hoslem.test(titanic$survived, titanic$prediction, g = 2)
hoslem.test(titanic$survived, titanic$prediction, g = 4)
hoslem.test(titanic$survived, titanic$prediction, g = 6)
hoslem.test(titanic$survived, titanic$prediction, g = 8)
hoslem.test(titanic$survived, titanic$prediction, g = 10)

#Calibration: Spiegelhalter's z
val.prob(titanic$prediction, titanic$survived, pl = FALSE)["S:z"]; val.prob(titanic$prediction, titanic$survived, pl = FALSE)["S:p"]

calibrationZ_ex &lt;- val.prob(titanic$prediction, titanic$survived, pl = FALSE)["S:z"]
calibrationP_ex &lt;- val.prob(titanic$prediction, titanic$survived, pl = FALSE)["S:p"]</code></pre>
<p>```{r, include = FALSE} # Set a Cutoff ————————————————————</p>
<p>cutoff_ex &lt;- 0.5</p>
<p>titanic<span class="math inline">\(diagnosis &lt;- NA
titanic\)</span>diagnosis[titanic<span class="math inline">\(prediction &lt; cutoff_ex] &lt;- 0
titanic\)</span>diagnosis[titanic$prediction &gt;= cutoff_ex] &lt;- 1</p>
<pre><code>
```{r, include = FALSE}
# Prediction Accuracy at the Cutoff ---------------------------------------

table(titanic$diagnosis, titanic$survived)

TPvalue_ex &lt;- length(which(titanic$diagnosis == 1 &amp; titanic$survived == 1))
TNvalue_ex &lt;- length(which(titanic$diagnosis == 0 &amp; titanic$survived == 0))
FPvalue_ex &lt;- length(which(titanic$diagnosis == 1 &amp; titanic$survived == 0))
FNvalue_ex &lt;- length(which(titanic$diagnosis == 0 &amp; titanic$survived == 1))

Nvalue_ex &lt;- sampleSize(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

selectionRatioValue_ex &lt;- selectionRatio(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
baseRateValue_ex &lt;- baseRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

percentAccuracyValue_ex &lt;- percentAccuracy(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
percentAccuracyByChanceValue_ex &lt;- percentAccuracyByChance(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
percentAccuracyPredictingFromBaseRateValue_ex &lt;- percentAccuracyPredictingFromBaseRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
relativeImprovementOverChanceValue_ex &lt;- relativeImprovementOverChance(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
relativeImprovementOverPredictingFromBaseRateValue_ex &lt;- relativeImprovementOverPredictingFromBaseRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

sensitivityValue_ex &lt;- TPrate_ex &lt;- sensitivity(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
specificityValue_ex &lt;- TNrate_ex &lt;- specificity(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

FNrateValue_ex &lt;- falseNegativeRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
FPrateValue_ex &lt;- falsePositiveRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

positivePredictiveValueValue_ex &lt;- positivePredictiveValue(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
negativePredictiveValueValue_ex &lt;- negativePredictiveValue(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

falseDiscoveryRateValue_ex &lt;- falseDiscoveryRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
falseOmissionRateValue_ex &lt;- falseOmissionRate(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

diagnosticOddsRatioValue_ex &lt;- diagnosticOddsRatio(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
positiveLikelihoodRatioValue_ex &lt;- positiveLikelihoodRatio(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
negativeLikelihoodRatioValue_ex &lt;- negativeLikelihoodRatio(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

youdenJValue_ex &lt;- youdenJ(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
balancedAccuracyValue_ex &lt;- balancedAccuracy(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
f1ScoreValue_ex &lt;- fScore(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
mccValue_ex &lt;- mcc(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

dPrimeValue_ex &lt;- dPrimeSDT(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
betaValue_ex &lt;- betaSDT(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
cValue_ex &lt;- cSDT(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
AValue_ex &lt;- aSDT(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)
bValue_ex &lt;- bSDT(TP = TPvalue_ex, TN = TNvalue_ex, FP = FPvalue_ex, FN = FNvalue_ex)

predictingFromTheBaseRateValue_ex &lt;- max(baseRateValue_ex, 1 - baseRateValue_ex) * 100
increasedAccuracyValue_ex &lt;- percentAccuracyValue_ex - predictingFromTheBaseRateValue_ex

differenceBetweenPredictedAndObserved_ex &lt;- miscalibration(predicted = titanic$prediction, actual = titanic$survived, cutoff = cutoff_ex)</code></pre>
<p>```{r, include = FALSE} # Decision Theory Approach to Cutoff Specification ————————</p>
<p>#Overall utility of a specific cutoff value: utilities-weighted sum of the probabilities of the four decision-making outcomes</p>
<p>Uoverall(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex, UH = 1, UM = 0, UCR = 0.75, UFA = 0.25) Uoverall(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex, UH = 1, UM = 0, UCR = 1, UFA = 0) Uoverall(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex, UH = 0.75, UM = 0.25, UCR = 1, UFA = 0)</p>
<p>Uoverall(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex, UH = 1, UM = 0, UCR = 0.25, UFA = 0)</p>
<p>Uoverall_ex &lt;- Uoverall(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex, UH = 1, UM = 0, UCR = 0.25, UFA = 0)</p>
<pre><code>
```{r, include = FALSE}
#Utility ratio: user-perceived relative importance of decisions about negative versus positive cases

utilityRatio(UH = 1, UM = 0, UCR = (1/2), UFA = (1/2))
utilityRatio(UH = 1, UM = 0, UCR = (2/3), UFA = (1/3))
utilityRatio(UH = 1, UM = 0, UCR = 0.75, UFA = 0.25)

utilityRatio(UH = 1, UM = 0, UCR = 1, UFA = 0)

utilityRatio(UH = 0.75, UM = 0.25, UCR = 1, UFA = 0)
utilityRatio(UH = (2/3), UM = (1/3), UCR = 1, UFA = 0)
utilityRatio(UH = (1/2), UM = (1/2), UCR = 1, UFA = 0)

utilityRatio(UH = 1, UM = 0, UCR = (1/3), UFA = 0)
utilityRatio(UH = 1, UM = 0, UCR = 0.25, UFA = 0)

utilityRatio_ex &lt;- utilityRatio(UH = 1, UM = 0, UCR = 0.25, UFA = 0)</code></pre>
<p>```{r, include = FALSE} # Information Theory Approach to Cutoff Specification ———————</p>
<p>Igain(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex) Igain_ex &lt;- Igain(BR = baseRateValue_ex, HR = TPrate_ex, FAR = FPrateValue_ex)</p>
<pre><code>
```{r, include = FALSE}
# Accuracy at Every Possible Cutoff ---------------------------------------

#Specify utility of each outcome
utilityHits_ex &lt;- 1
utilityMisses_ex &lt;- 0
utilityCorrectRejections_ex &lt;- 0.25
utilityFalseAlarms_ex &lt;- 0

possibleCutoffs_ex &lt;- unique(na.omit(titanic$prediction))
possibleCutoffs_ex &lt;- possibleCutoffs_ex[order(possibleCutoffs_ex)]
possibleCutoffs_ex &lt;- c(possibleCutoffs_ex, max(possibleCutoffs_ex, na.rm = TRUE) + 0.01)

accuracyVariables_ex &lt;- c("cutoff", "TP", "TN", "FP", "FN", "differenceBetweenPredictedAndObserved")

accuracyStats_ex &lt;- data.frame(matrix(nrow = length(possibleCutoffs_ex), ncol = length(accuracyVariables_ex)))
names(accuracyStats_ex) &lt;- accuracyVariables_ex

for(i in 1:length(possibleCutoffs_ex)){
  cutoff &lt;- possibleCutoffs_ex[i]
  
  titanic$diagnosis &lt;- NA
  titanic$diagnosis[titanic$prediction &lt; cutoff] &lt;- 0
  titanic$diagnosis[titanic$prediction &gt;= cutoff] &lt;- 1
  
  accuracyStats_ex[i, "cutoff"] &lt;- cutoff
  accuracyStats_ex[i, "TP"] &lt;- length(which(titanic$diagnosis == 1 &amp; titanic$survived == 1))
  accuracyStats_ex[i, "TN"] &lt;- length(which(titanic$diagnosis == 0 &amp; titanic$survived == 0))
  accuracyStats_ex[i, "FP"] &lt;- length(which(titanic$diagnosis == 1 &amp; titanic$survived == 0))
  accuracyStats_ex[i, "FN"] &lt;- length(which(titanic$diagnosis == 0 &amp; titanic$survived == 1))
  
  accuracyStats_ex[i, "differenceBetweenPredictedAndObserved"] &lt;- miscalibration(predicted = titanic$prediction, actual = titanic$survived, cutoff = cutoff)
}

accuracyStats_ex$N &lt;- sampleSize(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$selectionRatio &lt;- selectionRatio(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$baseRate &lt;- baseRate(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$percentAccuracy &lt;- percentAccuracy(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$percentAccuracyByChance &lt;- percentAccuracyByChance(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$relativeImprovementOverChance &lt;- relativeImprovementOverChance(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$relativeImprovementOverPredictingFromBaseRate &lt;- relativeImprovementOverPredictingFromBaseRate(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$sensitivity &lt;- accuracyStats_ex$TPrate &lt;- sensitivity(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$specificity &lt;- accuracyStats_ex$TNrate &lt;- specificity(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$FNrate &lt;- falseNegativeRate(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$FPrate &lt;- falsePositiveRate(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$positivePredictiveValue &lt;- positivePredictiveValue(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$negativePredictiveValue &lt;- negativePredictiveValue(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$falseDiscoveryRate &lt;- falseDiscoveryRate(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$falseOmissionRate &lt;- falseOmissionRate(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$diagnosticOddsRatio &lt;- diagnosticOddsRatio(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$positiveLikelihoodRatio &lt;- positiveLikelihoodRatio(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$negativeLikelihoodRatio &lt;- negativeLikelihoodRatio(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$youdenJ &lt;- youdenJ(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$balancedAccuracy &lt;- balancedAccuracy(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$f1Score &lt;- fScore(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$mcc &lt;- mcc(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$dPrimeSDT &lt;- dPrimeSDT(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$betaSDT &lt;- betaSDT(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$cSDT &lt;- cSDT(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$ASDT &lt;- aSDT(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)
accuracyStats_ex$bSDT &lt;- bSDT(TP = accuracyStats_ex$TP, TN = accuracyStats_ex$TN, FP = accuracyStats_ex$FP, FN = accuracyStats_ex$FN)

accuracyStats_ex$overallUtility &lt;- Uoverall(BR = accuracyStats_ex$baseRate, HR = accuracyStats_ex$TPrate, FAR = accuracyStats_ex$FPrate, UH = utilityHits_ex, UM = utilityMisses_ex, UCR = utilityCorrectRejections_ex, UFA = utilityFalseAlarms_ex)
accuracyStats_ex$utilityRatio &lt;- utilityRatio(UH = utilityHits_ex, UM = utilityMisses_ex, UCR = utilityCorrectRejections_ex, UFA = utilityFalseAlarms_ex)
accuracyStats_ex$informationGain &lt;- Igain(BR = accuracyStats_ex$baseRate, HR = accuracyStats_ex$TPrate, FAR = accuracyStats_ex$FPrate)

#Replace NaN and INF values with NA
is.nan.data.frame &lt;- function(x)
  do.call(cbind, lapply(x, is.nan))

accuracyStats_ex[is.nan.data.frame(accuracyStats_ex)] &lt;- NA
accuracyStats_ex &lt;- do.call(data.frame, lapply(accuracyStats_ex, function(x) replace(x, is.infinite(x), NA)))

#All accuracy stats
accuracyStats_ex</code></pre>
<p>```{r, include = FALSE} #Youden Index (maximum combination of sensitivity and specificity) youdenIndex_ex &lt;- coords(roc(data = titanic, response = survived, predictor = prediction, smooth = FALSE), x = “best”, best.method = “youden”)[[1]] closestToTheTopLeft_ex &lt;- coords(roc(data = titanic, response = survived, predictor = prediction, smooth = FALSE), x = “best”, best.method = “closest.topleft”)[[1]]</p>
<p>#Accuracy stats at cutoff of Youden Index accuracyStats_ex[head(which(accuracyStats_ex<span class="math inline">\(cutoff &gt;= youdenIndex_ex), 1),]
accuracyStats_ex[which(accuracyStats_ex\)</span>youdenJ == max(accuracyStats_ex$youdenJ, na.rm = TRUE)),]</p>
<pre><code>
```{r, include = FALSE}
#Accuracy stats at cutoff where the ROC plot is closest to the Top Left
accuracyStats_ex[head(which(accuracyStats_ex$cutoff &gt;= closestToTheTopLeft_ex), 1),]</code></pre>
<p><code>{r, include = FALSE} #Cutoff that optimizes: percentAccuracyCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$percentAccuracy == max(accuracyStats_ex$percentAccuracy, na.rm = TRUE))] percentAccuracyByChanceCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$percentAccuracyByChance == max(accuracyStats_ex$percentAccuracyByChance, na.rm = TRUE))] relativeImprovementOverChanceCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$relativeImprovementOverChance == max(accuracyStats_ex$relativeImprovementOverChance, na.rm = TRUE))] relativeImprovementOverPredictingFromBaseRateCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$relativeImprovementOverPredictingFromBaseRate == max(accuracyStats_ex$relativeImprovementOverPredictingFromBaseRate, na.rm = TRUE))] sensitivityCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$sensitivity == max(accuracyStats_ex$sensitivity, na.rm = TRUE))] specificityCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$specificity == max(accuracyStats_ex$specificity, na.rm = TRUE))] positivePredictiveValueCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$positivePredictiveValue == max(accuracyStats_ex$positivePredictiveValue, na.rm = TRUE))] negativePredictiveValueCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$negativePredictiveValue == max(accuracyStats_ex$negativePredictiveValue, na.rm = TRUE))] diagnosticOddsRatioCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$diagnosticOddsRatio == max(accuracyStats_ex$diagnosticOddsRatio, na.rm = TRUE))] positiveLikelihoodRatioCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$positiveLikelihoodRatio == max(accuracyStats_ex$positiveLikelihoodRatio, na.rm = TRUE))] negativeLikelihoodRatioCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$negativeLikelihoodRatio == min(accuracyStats_ex$negativeLikelihoodRatio, na.rm = TRUE))] youdenJCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$youdenJ == max(accuracyStats_ex$youdenJ, na.rm = TRUE))] balancedAccuracyCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$balancedAccuracy == max(accuracyStats_ex$balancedAccuracy, na.rm = TRUE))] f1ScoreCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$f1Score == max(accuracyStats_ex$f1Score, na.rm = TRUE))] mccCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$mcc == max(accuracyStats_ex$mcc, na.rm = TRUE))] dPrimeSDTCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$dPrimeSDT == max(accuracyStats_ex$dPrimeSDT, na.rm = TRUE))] betaSDTCutoff_ex &lt;- accuracyStats_ex$cutoff[which(abs(accuracyStats_ex$betaSDT) == min(abs(accuracyStats_ex$betaSDT), na.rm = TRUE))] cSDTCutoff_ex &lt;- accuracyStats_ex$cutoff[which(abs(accuracyStats_ex$cSDT) == min(abs(accuracyStats_ex$cSDT), na.rm = TRUE))] ASDTCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$ASDT == max(accuracyStats_ex$ASDT, na.rm = TRUE))] bSDTCutoff_ex &lt;- accuracyStats_ex$cutoff[which(abs(accuracyStats_ex$bSDT) == min(abs(accuracyStats_ex$bSDT), na.rm = TRUE))] differenceBetweenPredictedAndObservedCutoff_ex &lt;- accuracyStats_ex$cutoff[which(abs(accuracyStats_ex$differenceBetweenPredictedAndObserved) == min(abs(accuracyStats_ex$differenceBetweenPredictedAndObserved), na.rm = TRUE))] overallUtilityCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$overallUtility == max(accuracyStats_ex$overallUtility, na.rm = TRUE))] informationGainCutoff_ex &lt;- accuracyStats_ex$cutoff[which(accuracyStats_ex$informationGain == max(accuracyStats_ex$informationGain, na.rm = TRUE))]</code></p>
<p>```{r, include = FALSE} # Positive and Negative Predictive Value ———————————-</p>
<p>sensitivity &lt;- .9 specificity &lt;- .95 baseRate &lt;- .05 positivePredictiveValue &lt;- (sensitivity<em>baseRate)/(sensitivity</em>baseRate+(1-specificity)<em>(1-baseRate)) negativePredictiveValue &lt;- (specificity</em>(1-baseRate))/(specificity<em>(1-baseRate)+(1-sensitivity)</em>baseRate)</p>
<p>prYouHadCovid &lt;- 1 - negativePredictiveValue prFriendHadCovid &lt;- positivePredictiveValue</p>
<pre><code>
```{r, include = FALSE}
# Bayes' Theorem ----------------------------------------------------------

#p(C \mid R)=(p(R \mid C)∙p(C))/(p(R))

#p(disease \mid positiveTest) = (p(positiveTest \mid disease)∙p(disease))/(p(positiveTest))

pDisease &lt;- .005
pPositiveTest &lt;- .02
pPositiveTestGivenDisease &lt;- .99

pDiseaseGivenPositiveTest &lt;- (pPositiveTestGivenDisease * pDisease)/pPositiveTest * 100

# Posttest Probability
probGivenTestA_ex &lt;- posttestProbability(pretestProb = .005, SN = .95, SP = .90)
probGivenTestAthenB_ex &lt;- posttestProbability(pretestProb = probGivenTestA_ex, SN = .80, SP = .95)

pctGivenTestA_ex &lt;- probGivenTestA_ex * 100
pctGivenTestAthenB_ex &lt;- probGivenTestAthenB_ex * 100</code></pre>
<section id="exercisesQuestions-prediction" class="level3" data-number="80.15.1">
<h3 data-number="80.15.1" class="anchored" data-anchor-id="exercisesQuestions-prediction"><span class="header-section-number">80.15.1</span> Questions</h3>
<p>Note: Several of the following questions use data from the survivorship of the Titanic accident. The data are publicly available (https://hbiostat.org/data/; archived at https://perma.cc/B4AV-YH4V). The Titanic data file for these exercises is located on the book’s page of the Open Science Framework (https://osf.io/3pwza) and in the GitHub repo (https://github.com/isaactpetersen/Principles-Psychological-Assessment/tree/main/Data). Every record in the data set represents a passenger—including the passenger’s age, sex, passenger class, number of siblings/spouses aboard (<code>sibsp</code>), number of parents/children aboard (<code>parch</code>) and, whether the passenger survived the accident. I used these variables to create a prediction model (based on a logistic regression model using Leave-10-out cross-validation) for whether the passenger survived the accident. The model’s prediction for the passenger’s likelihood of survival are in the variable called “prediction”.</p>
<ol type="1">
<li>What are the two main types of prediction accuracy? Define each. How can you quantify each? What is an example of an index that combines both main types of prediction accuracy?</li>
<li>Provide the following indexes of overall prediction accuracy for the prediction model in predicting whether a passenger survived the Titanic:
<ol type="a">
<li>Mean error (bias)</li>
<li>Mean absolute error (MAE)</li>
<li>Mean squared error (MSE)</li>
<li>Root mean squared error (RMSE)</li>
<li>Mean percentage error (MPE)</li>
<li>Mean absolute percentage error (MAPE)</li>
<li>Symmetric mean absolute percentage error (sMAPE)</li>
<li>Mean absolute scaled error (MASE)</li>
<li>Root mean squared log error (RMSLE)</li>
<li>Coefficient of determination (<span class="math inline">\(R^2\)</span>)</li>
<li>Adjusted <span class="math inline">\(R^2\)</span> (<span class="math inline">\(R^2_{adj}\)</span>)</li>
<li>Predictive <span class="math inline">\(R^2\)</span></li>
</ol></li>
<li>Based on the mean error for the prediction model you found in <code>2a</code>, what does this indicate?</li>
<li>Create two receiver operating characteristic (ROC) curves for the prediction model in predicting whether a passenger survived the Titanic: one empirical ROC curve and one smooth ROC curve.</li>
<li>What is the area under the ROC curve (AUC) for the prediction model in predicting whether a passenger survived the Titanic? What does this indicate?</li>
<li>Create a calibration plot. Are the predictions well-calibrated? Provide empirical evidence and support your inferences with interpretation of the calibration plot. If the predictions are miscalibrated, describe the type of miscalibration present.</li>
<li>You predict that a passenger survived the Titanic if their predicted probability of survival is .50 or greater. Create a confusion matrix (2x2 matrix of prediction accuracy) for Titanic survival using this threshold. Make sure to include the marginal cells. Label each cell. Enter the number and proportion in each cell.</li>
<li>Using the 2x2 prediction matrix, identify or calculate the following:
<ol type="a">
<li>Selection ratio</li>
<li>Base rate</li>
<li>Percent accuracy</li>
<li>Percent accuracy by chance</li>
<li>Percent accuracy predicting from the base rate</li>
<li>Relative improvement over chance (ROIC)</li>
<li>Relative improvement over predicting from the base rate</li>
<li>Sensitivity (true positive rate [TPR])</li>
<li>Specificity (true negative rate [TNR])</li>
<li>False negative rate (FNR)</li>
<li>False positive rate (FPR)</li>
<li>Positive predictive value (PPV)</li>
<li>Negative predictive value (NPV)</li>
<li>False discovery rate (FDR)</li>
<li>False omission rate (FOR)</li>
<li>Diagnostic odds ratio</li>
<li>Youden’s J statistic</li>
<li>Balanced accuracy</li>
<li><span class="math inline">\(F_1\)</span> score</li>
<li>Matthews correlation coefficient (MCC)</li>
<li>Positive likelihood ratio</li>
<li>Negative likelihood ratio</li>
<li><span class="math inline">\(d'\)</span> sensitivity</li>
<li><span class="math inline">\(A\)</span> (non-parametric) sensitivity</li>
<li><span class="math inline">\(\beta\)</span> bias</li>
<li><span class="math inline">\(c\)</span> bias<br>
aa. <span class="math inline">\(b\)</span> (non-parametric) bias<br>
ab. Miscalibration (mean difference between predicted and observed values; based on 10 groups)<br>
ac. Information gain</li>
</ol></li>
<li>In terms of percent accuracy, how much more accurate are the predictions compared to predicting from the base rate? What would happen to sensitivity and specificity if you raise the selection ratio? What would happen if you lower the selection ratio?</li>
<li>For your assessment goals, it is 4 times more important to identify survivors than to identify non-survivors. Consistent with these assessment goals, you specify the following utility for each of the four outcomes: hits: 1; misses: 0; correct rejections: 0.25; false alarms: 0. What is the utility ratio? What is the overall utility (<span class="math inline">\(U_\text{overall}\)</span>) of the current cutoff? What cutoff has the highest overall utility?</li>
<li>Find the optimal cutoff threshold that optimizes each of the following criteria:
<ol type="a">
<li>Youden’s J statistic</li>
<li>Closest to the top left of the ROC curve</li>
<li>Percent accuracy</li>
<li>Percent accuracy by chance</li>
<li>Relative improvement over chance (ROIC)</li>
<li>Relative improvement over predicting from the base rate</li>
<li>Sensitivity (true positive rate [TPR])</li>
<li>Specificity (true negative rate [TNR])</li>
<li>Positive predictive value (PPV)</li>
<li>Negative predictive value (NPV)</li>
<li>Diagnostic odds ratio</li>
<li>Balanced accuracy</li>
<li><span class="math inline">\(F_1\)</span> score</li>
<li>Matthews correlation coefficient (MCC)</li>
<li>Positive likelihood ratio</li>
<li>Negative likelihood ratio</li>
<li><span class="math inline">\(d'\)</span> sensitivity</li>
<li><span class="math inline">\(A\)</span> (non-parametric) sensitivity</li>
<li><span class="math inline">\(\beta\)</span> bias</li>
<li><span class="math inline">\(c\)</span> bias</li>
<li><span class="math inline">\(b\)</span> (non-parametric) bias</li>
<li>Miscalibration (mean difference between predicted and observed values; based on 10 groups)</li>
<li>Overall utility</li>
<li>Information gain</li>
</ol></li>
<li>A company develops a test that seeks to determine whether someone has been previously infected with a novel coronavirus (COVID-75) based on the presence of antibodies in their blood. You take the test and your test result is negative (i.e., the test says that you have not been infected). Your friend takes the test and their test result is positive for coronavirus (i.e., the test says that your friend has been infected). Assume the prevalence of the coronavirus is 5%, the sensitivity of the test is .90, and the specificity of the test is .95.
<ol type="a">
<li>What is the probability that you actually had the coronavirus?</li>
<li>What is the probability that your friend actually had the coronavirus?</li>
<li>Your friend thinks that, given their positive test, that they have the antibodies (and thus may have immunity). What is the problem with your friend’s logic?</li>
<li>What logical fallacy is your friend demonstrating?</li>
<li>Why is it challenging to interpret a positive test in this situation?</li>
</ol></li>
<li>You just took a screening test for a genetic disease. Your test result is positive (i.e., the tests says that you have the disease). Assume the probability of having the disease is 0.5%, the probability of a positive test is 2%, and the probability of a positive test if you have the disease is 99%. What is the probability that you have the genetic disease?</li>
<li>You just took a screening test (Test A) for a virus. Your test result is positive. Assume the base rate of the virus is .05%. Test A has a sensitivity of .95 and a specificity of .90.
<ol type="a">
<li>What is your probability of having the virus after testing positive on Test A?</li>
<li>After getting the results back from Test A, the physician wants greater confidence regarding whether you have the virus given its low base rate, so the physician orders a second test, Test B. You test positive on Test B. Test B has a sensitivity of .80 and a specificity of .95. Assuming the errors of the Tests A and B are independent, what is your updated probability of having the virus?</li>
</ol></li>
</ol>
</section>
<section id="exercisesAnswers-prediction" class="level3" data-number="80.15.2">
<h3 data-number="80.15.2" class="anchored" data-anchor-id="exercisesAnswers-prediction"><span class="header-section-number">80.15.2</span> Answers</h3>
<ol type="1">
<li>The two main types of prediction accuracy are discrimination and calibration. Discrimination refers to the ability of a prediction model to separate/differentiate data into classes (e.g., survived versus died). Calibration for a prediction model refers to how well the predicted probability of an event (e.g., survival) matches the true probability of an event. You can quantify discrimination with AUC; you can quantify various aspects of discrimination with sensitivity, specificity, positive predictive value, and negative predictive value). You can quantify degree of (poor) calibration with Spiegelhalter’s <span class="math inline">\(z\)</span>, though other metrics also exist (e.g., Brier scores and the Hosmer-Lemeshow goodness-of-fit statistic). <span class="math inline">\(R^2\)</span> is an overall index of accuracy that combines both discrimination and calibration.</li>
<li><ol type="a">
<li>Mean error (bias): <span class="math inline">\(`r format(round(meanError_ex, 4), scientific = FALSE)`\)</span></li>
<li>Mean absolute error (MAE): <span class="math inline">\(`r apa(meanAbsoluteError_ex, decimals = 2)`\)</span></li>
<li>Mean squared error (MSE): <span class="math inline">\(`r apa(meanSquaredError_ex, decimals = 2)`\)</span></li>
<li>Root mean squared error (RMSE): <span class="math inline">\(`r apa(rootMeanSquaredError_ex, decimals = 2)`\)</span></li>
<li>Mean percentage error (MPE): undefined, but when dropping undefined values: <span class="math inline">\(`r apa(meanPercentageError_ex, decimals = 2)`\%\)</span></li>
<li>Mean absolute percentage error (MAPE): undefined, but when dropping undefined values: <span class="math inline">\(`r apa(meanAbsolutePercentageError_ex, decimals = 2)`\%\)</span></li>
<li>Symmetric mean absolute percentage error (sMAPE): <span class="math inline">\(`r apa(symmetricMeanAbsolutePercentageError_ex, decimals = 2)`\%\)</span></li>
<li>Mean absolute scaled error (MASE): <span class="math inline">\(`r apa(meanAbsoluteScaledError_ex, decimals = 2)`\)</span></li>
<li>Root mean squared log error (RMSLE): <span class="math inline">\(`r apa(rootMeanSquaredLogError_ex, decimals = 2)`\)</span></li>
<li>Coefficient of determination (<span class="math inline">\(R^2\)</span>): <span class="math inline">\(`r apa(rsquared_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Adjusted <span class="math inline">\(R^2\)</span> (<span class="math inline">\(R^2_{adj}\)</span>): <span class="math inline">\(`r apa(rsquaredAdj_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Predictive <span class="math inline">\(R^2\)</span>: <span class="math inline">\(`r apa(predictiveRsquaredValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
</ol></li>
<li>The small mean error/bias <span class="math inline">\((`r format(round(meanError_ex, 4), scientific = FALSE)`)\)</span> indicates that predictions did not consistently under- or over-estimate the actual values to a considerable degree.</li>
<li>Empirical ROC curve:</li>
</ol>
<p><code>{r, echo = FALSE, fig.width = 8, fig.height = 8, fig.align = "center", fig.cap = c("Exercise 4: Empirical Receiver Operating Characteristic Curve.")} plot(rocCurve_ex, legacy.axes = TRUE, asp = NA)</code></p>
<p>Smooth ROC curve:</p>
<p><code>{r, echo = FALSE, fig.width = 8, fig.height = 8, fig.align = "center", fig.cap = c("Exercise 4: Smooth Receiver Operating Characteristic Curve.")} plot(rocCurveSmooth_ex, legacy.axes = TRUE, asp = NA)</code></p>
<ol start="5" type="1">
<li>The AUC is <span class="math inline">\(`r apa(auc_ex, decimals = 2, leading = FALSE)`\)</span>. AUC indicates the probability that a randomly selected case has a higher test result than a randomly selected control. Thus, the probability is <span class="math inline">\(`r as.integer(auc_ex * 100)`\%\)</span> that a randomly selected passenger who survived had a higher predicted probability of survival (based on the prediction model) than a randomly selected passenger who died. The AUC of <span class="math inline">\(`r apa(auc_ex, decimals = 2, leading = FALSE)`\)</span> indicates that the prediction model was moderately accurate in terms of discrimination.</li>
<li>Calibration plot:</li>
</ol>
<p><code>{r, echo = FALSE, fig.width = 8, fig.height = 8, fig.align = "center", fig.cap = c("Exercise 5: Calibration Plot of Predicted Probability Versus Observed Probability.")} grid.arrange(g_ex)</code></p>
<ol start="6" type="1">
<li><p>In general, the predictions are well-calibrated. There is not significant miscalibration according to Spiegehalter’s <span class="math inline">\(z\)</span> <span class="math inline">\((`r apa(calibrationZ_ex, decimals = 2)`, p = `r apa(calibrationP_ex, decimals = 2, leading = FALSE)`)\)</span>. This is verified graphically in the calibration plot, in which the predicted probabilities fall mostly near the actual/observed probabilities. However, based on the calibration plot, there does appear to be some miscalibration. When the predicted probability of survival was ~60%, the actual probability of survival was lower (~40%). This pattern of miscalibration is known as overprediction, as depicted in Figure 1 of <span class="citation" data-cites="Lindhiem2020">(<a href="../../99-references.html#ref-Lindhiem2020" role="doc-biblioref"><strong>Lindhiem2020?</strong></a>)</span>.</p></li>
<li><p>The 2x2 prediction matrix is below:</p></li>
</ol>
<p><code>{r twoByTwoMatrix, out.width = "100%", fig.align = "center", fig.cap = "Exercise 6: 2x2 Prediction Matrix. TP = true positives; TN = true negatives; FP = false positives; FN = false negatives; BR = base rate; SR = selection ratio.", echo = FALSE} knitr::include_graphics("./Images/2x2-Matrix.png")</code></p>
<ol start="8" type="1">
<li><ol type="a">
<li>Selection ratio: <span class="math inline">\(`r apa(selectionRatioValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Base rate: <span class="math inline">\(`r apa(baseRateValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Percent accuracy: <span class="math inline">\(`r as.integer(percentAccuracyValue_ex)`\%\)</span></li>
<li>Percent accuracy by chance: <span class="math inline">\(`r as.integer(percentAccuracyByChanceValue_ex)`\%\)</span></li>
<li>Percent accuracy predicting from the base rate: <span class="math inline">\(`r as.integer(percentAccuracyPredictingFromBaseRateValue_ex)`\%\)</span></li>
<li>Relative improvement over chance (ROIC): <span class="math inline">\(`r apa(relativeImprovementOverChanceValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Relative improvement over predicting from the base rate: <span class="math inline">\(`r apa(relativeImprovementOverPredictingFromBaseRateValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Sensitivity (true positive rate [TPR]): <span class="math inline">\(`r apa(sensitivityValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Specificity (true negative rate [TNR]): <span class="math inline">\(`r apa(specificityValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>False negative rate (FNR): <span class="math inline">\(`r apa(FNrateValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>False positive rate (FPR): <span class="math inline">\(`r apa(FPrateValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Positive predictive value (PPV): <span class="math inline">\(`r apa(positivePredictiveValueValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Negative predictive value (NPV): <span class="math inline">\(`r apa(negativePredictiveValueValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>False discovery rate (FDR): <span class="math inline">\(`r apa(falseDiscoveryRateValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>False omission rate (FOR): <span class="math inline">\(`r apa(falseOmissionRateValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Diagnostic odds ratio: <span class="math inline">\(`r apa(diagnosticOddsRatioValue_ex, decimals = 2, leading = TRUE)`\)</span></li>
<li>Youden’s J statistic: <span class="math inline">\(`r apa(youdenJValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Balanced accuracy: <span class="math inline">\(`r apa(balancedAccuracyValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li><span class="math inline">\(F_1\)</span> score: <span class="math inline">\(`r apa(f1ScoreValue_ex, decimals = 2, leading = TRUE)`\)</span></li>
<li>Matthews correlation coefficient (MCC): <span class="math inline">\(`r apa(mccValue_ex, decimals = 2, leading = FALSE)`\)</span></li>
<li>Positive likelihood ratio: <span class="math inline">\(`r apa(positiveLikelihoodRatioValue_ex, decimals = 2, leading = TRUE)`\)</span></li>
<li>Negative likelihood ratio: <span class="math inline">\(`r apa(negativeLikelihoodRatioValue_ex, decimals = 2, leading = TRUE)`\)</span></li>
<li><span class="math inline">\(d'\)</span> sensitivity: <span class="math inline">\(`r apa(dPrimeValue_ex, decimals = 2)`\)</span></li>
<li><span class="math inline">\(A\)</span> (non-parametric) sensitivity: <span class="math inline">\(`r apa(AValue_ex, decimals = 2)`\)</span></li>
<li><span class="math inline">\(\beta\)</span> bias: <span class="math inline">\(`r apa(betaValue_ex, decimals = 2)`\)</span></li>
<li><span class="math inline">\(c\)</span> bias: <span class="math inline">\(`r apa(cValue_ex, decimals = 2)`\)</span> aa. <span class="math inline">\(b\)</span> (non-parametric) bias: <span class="math inline">\(`r apa(bValue_ex, decimals = 2)`\)</span> ab. Miscalibration (mean difference between predicted and observed values): <span class="math inline">\(`r apa(differenceBetweenPredictedAndObserved_ex, decimals = 2, leading = TRUE)`\)</span> ac. Information gain: <span class="math inline">\(`r apa(Igain_ex, decimals = 2, leading = TRUE)`\)</span></li>
</ol></li>
<li><p>Predicting from the base rate would have a percent accuracy of <span class="math inline">\(`r as.integer(predictingFromTheBaseRateValue_ex)`\%\)</span>. So, the predictions increase the percent accuracy by <span class="math inline">\(`r as.integer(increasedAccuracyValue_ex)`\%\)</span>. If you raise the selection ratio (i.e., predict more people survived) sensitivity will increase whereas specificity will decrease. If you lower the selection ratio, specificity will increase and sensitivity will decrease.</p></li>
<li><p>The utility ratio is <span class="math inline">\(`r apa(utilityRatio_ex, decimals = 2)`\)</span>. The overall utility (<span class="math inline">\(U_\text{overall}\)</span>) of the cutoff is <span class="math inline">\(`r apa(Uoverall_ex, decimals = 2)`\)</span>. The cutoff with the highest overall utility is <span class="math inline">\(`r apa(overallUtilityCutoff_ex, decimals = 3)`\)</span>.</p></li>
<li><p>The cutoff that optimizes each of the following criteria:</p>
<ol type="a">
<li>Youden’s J statistic: <span class="math inline">\(`r apa(youdenIndex_ex, decimals = 3)`\)</span></li>
<li>Closest to the top left of the ROC curve: <span class="math inline">\(`r apa(closestToTheTopLeft_ex, decimals = 3)`\)</span></li>
<li>Percent accuracy: <span class="math inline">\(`r apa(percentAccuracyCutoff_ex, decimals = 3)`\)</span></li>
<li>Percent accuracy by chance: 1 (i.e., predicting from the base rate—that nobody will survive)</li>
<li>Relative improvement over chance (ROIC): <span class="math inline">\(`r apa(relativeImprovementOverChanceCutoff_ex, decimals = 3, leading = FALSE)`\)</span></li>
<li>Relative improvement over predicting from the base rate: <span class="math inline">\(`r apa(relativeImprovementOverPredictingFromBaseRateCutoff_ex, decimals = 3, leading = FALSE)`\)</span></li>
<li>Sensitivity (true positive rate [TPR]): 0 (i.e., predicting that everyone will survive will minimize false negatives)</li>
<li>Specificity: 1 (i.e., predicting that nobody will survive will minimize false positives)</li>
<li>Positive predictive value (PPP): <span class="math inline">\(`r apa(positivePredictiveValueCutoff_ex, decimals = 3)`\)</span></li>
<li>Negative predictive value (NPV): <span class="math inline">\(`r apa(negativePredictiveValueCutoff_ex, decimals = 3)`\)</span></li>
<li>Diagnostic odds ratio: <span class="math inline">\(`r apa(diagnosticOddsRatioCutoff_ex, decimals = 3)`\)</span></li>
<li>Balanced accuracy: <span class="math inline">\(`r apa(balancedAccuracyCutoff_ex, decimals = 3)`\)</span></li>
<li><span class="math inline">\(F_1\)</span> score: <span class="math inline">\(`r apa(f1ScoreCutoff_ex, decimals = 3)`\)</span></li>
<li>Matthews correlation coefficient (MCC): <span class="math inline">\(`r apa(mccCutoff_ex, decimals = 3)`\)</span></li>
<li>Positive likelihood ratio: <span class="math inline">\(`r apa(positiveLikelihoodRatioCutoff_ex, decimals = 3)`\)</span></li>
<li>Negative likelihood ratio: <span class="math inline">\(`r apa(negativeLikelihoodRatioCutoff_ex, decimals = 3)`\)</span></li>
<li>Miscalibration (mean difference between predicted and observed values): <span class="math inline">\(`r apa(min(differenceBetweenPredictedAndObservedCutoff_ex), decimals = 3)`–`r apa(max(differenceBetweenPredictedAndObservedCutoff_ex), decimals = 3)`\)</span></li>
<li><span class="math inline">\(d'\)</span> sensitivity: <span class="math inline">\(`r apa(dPrimeSDTCutoff_ex, decimals = 3)`\)</span></li>
<li><span class="math inline">\(A\)</span> (non-parametric) sensitivity <span class="math inline">\(`r apa(ASDTCutoff_ex, decimals = 3)`\)</span></li>
<li><span class="math inline">\(\beta\)</span> bias <span class="math inline">\(`r apa(betaSDTCutoff_ex, decimals = 3)`\)</span></li>
<li><span class="math inline">\(c\)</span> bias <span class="math inline">\(`r apa(cSDTCutoff_ex, decimals = 3)`\)</span></li>
<li><span class="math inline">\(b\)</span> (non-parametric) bias <span class="math inline">\(`r apa(bSDTCutoff_ex, decimals = 3)`\)</span></li>
<li>Overall utility: <span class="math inline">\(`r apa(overallUtilityCutoff_ex, decimals = 3)`\)</span></li>
<li>Information gain: <span class="math inline">\(`r apa(informationGainCutoff_ex, decimals = 3)`\)</span></li>
</ol></li>
<li><ol type="a">
<li>Based on negative predictive value (i.e., the probability of no disease given a negative test), the probability that you actually had the coronavirus is less than 1 in 100 <span class="math inline">\((`r apa(prYouHadCovid, decimals = 3, leading = FALSE)`)\)</span>.</li>
<li>Based on positive predictive value (i.e., the probability of disease given a positive test), the probability that your friend actually had the coronavirus is less than 50% <span class="math inline">\((`r apa(prFriendHadCovid, decimals = 2, leading = FALSE)`)\)</span>.</li>
<li>The problem with your friend’s logic is that your friend is assuming they have the antibodies when chances are more likely that they do not.</li>
<li>Your friend is likely demonstrating the fallacy of base rate neglect.</li>
<li>A positive test on a screening device is hard to interpret in this situation because of the low base rate. “Even with a very accurate test, the fewer people in a population who have a condition, the more likely it is that an individual’s positive result is wrong.” For more info, see here: https://www.scientificamerican.com/article/coronavirus-antibody-tests-have-a-mathematical-pitfall/ (archived at https://perma.cc/GL9F-EVPH)</li>
</ol></li>
<li><p>According to Bayes’ theorem, the probability that you have the disease is <span class="math inline">\(`r apa(pDiseaseGivenPositiveTest, decimals = 2)`\%\)</span>. For more info, see here: https://www.scientificamerican.com/article/what-is-bayess-theorem-an/ (archived at https://perma.cc/GM6B-5MEP)</p></li>
<li><ol type="a">
<li>According to Bayes’ theorem, the probability that you have the virus after testing positive on Test A is <span class="math inline">\(`r apa(pctGivenTestA_ex, decimals = 1)`\%\)</span>.</li>
<li>According to Bayes’ theorem, the updated probability that you have the virus after testing positive on both Tests A and B is <span class="math inline">\(`r apa(pctGivenTestAthenB_ex, decimals = 1)`\%\)</span>.</li>
</ol></li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-petersen2024principles" class="csl-entry" role="listitem">
Petersen, I. T. (2024). <em>Principles of psychological assessment: With applied examples in R</em>. CRC Press.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>:alnum:<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>:alnum:<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/testing_psicologico\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/lgm/11_lgm_wais.html" class="pagination-link" aria-label="Lo Sviluppo dell'Intelligenza">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Lo Sviluppo dell’Intelligenza</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/networks/01_networks.html" class="pagination-link" aria-label="Network psicologici">
        <span class="nav-page-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Network psicologici</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Testing Psicologico</strong> è una dispensa scritta da Corrado Caudek.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>
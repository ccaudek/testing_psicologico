{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe5a77a2",
   "metadata": {},
   "source": [
    "# La revisione del modello {#sec-sem-revision}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20323a5",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "**Concetti e Competenze Chiave**\n",
    "\n",
    "**Preparazione del Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a26578",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "here::here(\"code\", \"_common.R\") |>\n",
    "    source()\n",
    "\n",
    "# Load packages\n",
    "if (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(lavaan, effectsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc3db0",
   "metadata": {},
   "source": [
    "## Introduzione\n",
    "\n",
    "I passi principali nella CFA e nei modelli SEM comprendono la specificazione del modello, la stima dei parametri, la valutazione del modello e dei parametri e la modificazione del modello. Questa sequenza può essere ripetuta molte volte fino a quando non si trovi un modello considerato accettabile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7e6ad",
   "metadata": {},
   "source": [
    "## Stima del modello \n",
    "\n",
    "Consideriamo qui un modello SEM con una sola variabile latente identificata da un insieme di indicatori, ovvero un modello CFA. L'obiettivo della CFA è ottenere stime per i parametro del modello (vale a dire, saturazioni fattoriali, varianze e covarianze fattoriali, varianze residue ed eventualmente covarianze degli errori) che sono in grado di produrre una matrice di covarianza prevista (denotata da $\\boldsymbol{\\Sigma}$) la quale è il più possibile simile alla matrice di covarianze campionarie (denotata da $\\boldsymbol{S}$). Questo processo di stima è basato sulla minimizzazione di una funzione che descrive la differenza tra $\\boldsymbol{\\Sigma}$ e $\\boldsymbol{S}$. Il metodo di stima più utilizzato nella CFA (e, in generale, nei modelli SEM) è la massima verosimiglianza (ML). \n",
    "\n",
    "## Massima verosimiglianza\n",
    "\n",
    "L'equazione fondamentale dell'analisi fattoriale è\n",
    "\n",
    "$$\n",
    "\\boldsymbol y = \\boldsymbol \\Lambda  \\boldsymbol x  + \\boldsymbol z, \n",
    "$$\n",
    "\n",
    "dove $\\boldsymbol{y}$ è un vettore di $p$ componenti (i punteggi osservati nel del test), $\\boldsymbol{x}$ è un vettore di $k < p$ componenti (i punteggi fattoriali),  $\\boldsymbol{\\Lambda}$ è una $p \\cdot k$ matrice (di saturazioni fattoriali), e $\\boldsymbol{z}$ è un vettore di $p$ componenti (la componenti dei punteggi del test non dovute all'effetto causale delle variabili comuni latenti). Per l'item $i$-esimo, in precedenza abbiamo scritto l'equazione precedente come\n",
    "\n",
    "$$\n",
    "y_i = \\lambda_{i1} \\xi_1 + \\dots + \\lambda_{ik} \\xi_k + \\delta_i. \n",
    "$$\n",
    "\n",
    "Dalle assunzioni del modello fattoriale deriva che\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda}\\boldsymbol{\\Phi}\\boldsymbol{\\Lambda}^\\prime + \\Psi,\n",
    "$$\n",
    "\n",
    "dove $\\boldsymbol{\\Phi}$ è la matrice delle inter-correlazioni fattoriali.\n",
    "\n",
    "Si assume che il vettore casuale $\\boldsymbol{y}$ abbia una distribuzione normale multivariata con matrice di covarianza $\\boldsymbol{\\Sigma}$ e che da tale distribuzione sia stato estratto un campione casuale di $n$ osservazioni $y_l, y_2, \\dots, y_n$. Il logaritmo della funzione di verosimiglianza per il campione è dato da\n",
    "\n",
    "$$\n",
    "\\log L = \\frac{1}{2}n [\\log | \\boldsymbol{\\Sigma}| + tr(\\boldsymbol{\\boldsymbol{S} \\Sigma}^{-1})].\n",
    "$$\n",
    "\n",
    "L'equazione precedente viene vista come funzione di $\\Lambda$ e $\\Psi$. Anziché massimizzare $\\log L$, è equivalente e più conveniente minimizzare \n",
    "\n",
    "$$\n",
    "F_{k}(\\Lambda, \\Psi) = \\log |\\boldsymbol{\\Sigma}| + tr[\\boldsymbol{S}\\boldsymbol{\\Sigma}^{-1}]  - \\log|\\boldsymbol{S}| – p,\n",
    "$$\n",
    "\n",
    "dove $|\\boldsymbol{S}|$ è il determinante della matrice di covarianza tra le variabili osservate, $|\\boldsymbol{\\Sigma}|$ è il determinante della matrice di covarianza prevista e $p$ è il numero di indicatori. \n",
    "\n",
    "L'obiettivo della stima di massima verosimiglianza della CFA è trovare le stime dei parametri che rendono più verosimili i dati osservati (o, al contrario, massimizzano la verosimiglianza dei parametri dati i dati). Le stime dei parametri in un modello CFA si ottengono con una procedura iterativa. Cioè, l'algoritmo inizia con una serie iniziale di stime dei parametri (denominate valori iniziali o stime iniziali, che possono essere generate automaticamente dal software o specificate dall'utente) e raffina ripetutamente queste stime nel tentativo di minimizzare la differenza tra $\\boldsymbol{\\Sigma}$ e $\\boldsymbol{S}$. Il programma effettua controlli interni per valutare i suoi progressi nell'ottenere stime dei parametri che al meglio riproducono  $\\boldsymbol{S}$. Si raggiunge la convergenza quando l'algoritmo produce una serie di stime dei parametri che non possono essere ulteriormente migliorate per ridurre la differenza tra $\\boldsymbol{\\Sigma}$ e $\\boldsymbol{S}$. \n",
    "\n",
    "## Identificabilità del modello\n",
    "\n",
    "Un modello CFA deve essere formulato in modo tale da garantire la risolvibilità matematica dello stesso, ovvero deve essere tale da consentire una stima univoca dei parametri del modello. Detto in altre parole, la specificazione del modello ne deve garantire l'dentificabilità.\n",
    "\n",
    "Il problema dell’identificazione richiede, innanzitutto, di chiarire il concetto di gradi di libertà (*degrees of freedom*). Nel presente contesto, per gradi di libertà ($dof$) intendiamo\n",
    "\n",
    "$$\n",
    "dof = \\# (\\text{unità di informazione}) - \\# (\\text{parametri da stimare}).\n",
    "$$\n",
    "\n",
    "I dati che vengono analizzati da un modello CFA sono contenuti in una matrice di covarianza. Per una matrice di covarianza di ordine $p$, il numero di unità di informazione è\n",
    "\n",
    "$$\n",
    "\\frac{p (p+1)}{2}.\n",
    "$$\n",
    "\n",
    "Affinché il modello sia identificabile, devono essere soddisfatte le seguenti condizioni.\n",
    "\n",
    "1. Indipendentemente dalla complessità del modello (ad es. modelli ad un fattore rispetto a più fattori), l'unità di misura delle variabili latenti deve essere specificata (di solito fissandola a un valore di 1);\n",
    "2. Indipendentemente dalla complessità del modello, il numero di unità di informazione  (es. la matrice di covarianza degli indicatori) deve essere uguale o superiore al numero di parametri da stimare (es. saturazioni fattoriali, specificità, covarianze degli errori dell'indicatore, covarianze tra i fattori);\n",
    "3. Nel caso di modelli ad un fattore è richiesto un minimo di tre indicatori. Quando vengono utilizzati tre indicatori, la soluzione a un fattore si dice \"appena identificata\" (*just-identified*); in tali condizioni non è possibile valutare la bontà dell'adattamento.\n",
    "4. Nel caso di modelli a due o più fattori e due indicatori per costrutto latente, la soluzione è sovraidentificata, a condizione che ogni variabile latente sia correlata con almeno un'altra variabile latente e gli errori tra gli indicatori siano tra loro incorrelati. Tuttavia, poiché tali soluzioni sono suscettibili di scarsa identificazione empirica, viene raccomandato un minimo di tre indicatori per variabile latente.\n",
    "\n",
    "In conclusione, una semplice e necessaria condizione per l'identificazione di un modello CFA è che vi siano più unità di informazione che parametri da stimare. Dunque, abbiamo che:\n",
    "\n",
    "- se $dof < 0$, il modello *non è identificato* e, in questo caso, non è possibile stimare i parametri;\n",
    "- se $dof = 0$, il modello è *appena identificato* o \"saturo\"; in questo caso, la matrice di covarianza riprodotta coincide con la matrice di covarianza delle variabili osservate e, di conseguenza, non esiste un residuo attraverso cui valutare la bontà dell'adattamento del modello;\n",
    "- se $dof > 0$, il modello è *sovra-identificato* ed esistono le condizioni per valutare la bontà dell'adattamento.\n",
    "\n",
    "Le considerazioni precedenti ci fanno capire perché non si può fare un'analisi fattoriale con solo due indicatori e un fattore; in tali circostanze, infatti, ci sono $(2 \\cdot 3)/2 = 3$ gradi di libertà, ma 4 parametri da stimare (due saturazioni fattoriali e due specificità). Il caso di tre item e un fattore definisce un modello \"appena identificato\", ovvero, il caso in cui ci sono zero gradi di libertà. In tali circostanze è possibile stimare i parametri (ricordiamo il metodo dell'annullamento della tetrade), ma non è possibile un test di bontà dell'adattamento. Questo vuol dire, in pratica, che per un modello SEM ad un solo fattore comune latente è necessario disporre di almeno quattro indicatori. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7e0c702",
   "metadata": {},
   "source": [
    "## Un Esempio Concreto\n",
    "\n",
    "Nell'approfondire la tematica dei Modelli di Equazioni Strutturali, è utile considerare alcune problematiche comuni che possono emergere nella fase di adattamento del modello ai dati. Facendo riferimento agli esempi discussi da @brown2015confirmatory nel contesto dell'analisi fattoriale confermativa (CFA), possiamo identificare diverse potenziali cause di inadeguato adattamento. Queste cause possono essere di natura sia teorica che tecnica e spesso richiedono un'attenta riflessione e analisi per essere risolte. Esaminiamo alcune delle questioni più rilevanti:\n",
    "\n",
    "1. **Numero Errato di Fattori Comuni Latenti:**\n",
    "   - Uno degli errori più comuni è ipotizzare un numero di fattori latenti che non riflette adeguatamente la struttura sottostante dei dati. Un numero insufficiente di fattori può portare a un modello semplificato eccessivamente, mentre un numero eccessivo può causare sovra-aggiustamento e complessità non necessaria.\n",
    "\n",
    "2. **Item che Saturano su Fattori Multipli:**\n",
    "   - In alcuni casi, un item può essere erroneamente ipotizzato per saturare su un singolo fattore comune, mentre in realtà ha relazioni significative con più fattori. Questo errore nella specificazione del modello può portare a stime imprecise e a un adattamento inadeguato.\n",
    "\n",
    "3. **Assegnazione Errata degli Item ai Fattori:**\n",
    "   - Un'altra possibile causa di inadeguato adattamento riguarda l'errata assegnazione di un item al fattore comune sbagliato. Tale errore può derivare da una comprensione insufficiente delle dimensioni teoriche che si stanno misurando o da una cattiva interpretazione dei dati empirici.\n",
    "\n",
    "4. **Correlazioni Residue Non Considerate:**\n",
    "   - Infine, le correlazioni residue non incorporate nel modello possono giocare un ruolo significativo nell'adattamento del modello. Queste correlazioni possono indicare relazioni non catturate dai fattori comuni, suggerendo la necessità di rivedere l'ipotesi di base del modello o di aggiungere percorsi specifici per accomodare queste correlazioni.\n",
    "\n",
    "In sintesi, l'adattamento del modello SEM ai dati è un processo complesso che richiede una profonda comprensione sia della teoria sottostante che della natura dei dati. Ogni volta che un modello non si adatta adeguatamente, è essenziale esaminare criticamente questi e altri potenziali fattori per identificare e correggere le cause alla base di tale inadeguatezza. Questo processo non solo migliora l'adattamento del modello, ma può anche fornire intuizioni preziose sulla struttura dei dati e sulla validità delle teorie sottostanti.\n",
    "\n",
    "@brown2015confirmatory mostra come il ricercatore possa usare i *Modification Indices* per valutare le cause del mancato adattamento del modello ai dati. I Modification Indices sono una misura utilizzata per identificare le covariate tra le variabili del modello che potrebbero migliorare l'aderenza del modello ai dati. I modification indices indicano quale sarebbe il miglioramento nell'aderenza del modello, ad esempio, se venisse permessa la correlazione tra due variabili che attualmente non sono considerate correlate. Ciò consente di identificare le relazioni nascoste tra le variabili e può aiutare a migliorare la precisione e l'accuratezza del modello.\n",
    "\n",
    "Tuttavia, è importante tenere presente che i *modification indices* da soli non dovrebbero essere usati per prendere decisioni definitive sulle modifiche del modello. Invece, dovrebbero essere considerati insieme ad altre informazioni, come la conoscenza teorica, l'esperienza e altre tecniche di analisi dei dati per determinare se una modifica del modello è giustificata e in che modo.\n",
    "\n",
    "## Un numero di fattori troppo piccolo\n",
    "\n",
    "Una delle possibili fonti di mancanza di adattamento del modello può dipendere dal fatto che è stato ipotizzato un numero insufficiente di fattori latenti comuni. @brown2015confirmatory discute il caso nel quale si confrontano gli indici di bontà di adattamento di un modello ad un solo fattore comune e un modello a due fattori comuni. L'esempio riguarda i dati già in precedenza discussi e relativi relativi a otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti:\n",
    "\n",
    "- anxiety (N1), \n",
    "- hostility (N2), \n",
    "- depression (N3), \n",
    "- self-consciousness (N4), \n",
    "- warmth (E1), \n",
    "- gregariousness (E2), \n",
    "- assertiveness (E3), \n",
    "- positive emotions (E4). \n",
    "\n",
    "Leggiamo i dati in $\\mathsf{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a142e16",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "varnames <- c(\"N1\", \"N2\", \"N3\", \"N4\", \"E1\", \"E2\", \"E3\", \"E4\")\n",
    "\n",
    "sds <- c(5.7,  5.6,  6.4,  5.7,  6.0,  6.2,  5.7,  5.6)\n",
    "\n",
    "cors <- '\n",
    " 1.000\n",
    " 0.767  1.000 \n",
    " 0.731  0.709  1.000 \n",
    " 0.778  0.738  0.762  1.000 \n",
    "-0.351  -0.302  -0.356  -0.318  1.000 \n",
    "-0.316  -0.280  -0.300  -0.267  0.675  1.000 \n",
    "-0.296  -0.289  -0.297  -0.296  0.634  0.651  1.000 \n",
    "-0.282  -0.254  -0.292  -0.245  0.534  0.593  0.566  1.000'\n",
    "\n",
    "psychot_cor_mat <- getCov(cors, names = varnames)\n",
    "\n",
    "n <- 250"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c286d961",
   "metadata": {},
   "source": [
    "Supponiamo di adattare ai dati il modello \"sbagliato\" che include un unico fattore comune.  Svolgiamo qui l'analisi *fattoriale esplorativa* usando la funzione sperimentale `efa()` di `lavaan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9776261a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1-factor model\n",
    "f1 <- '\n",
    "  efa(\"efa\")*f1 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4\n",
    "'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c08d7e",
   "metadata": {},
   "source": [
    " Adattiamo il modello ai dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7b57c9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "efa_f1 <-\n",
    "  cfa(\n",
    "    model = f1,\n",
    "    sample.cov = psychot_cor_mat,\n",
    "    sample.nobs = 250,\n",
    "    rotation = \"oblimin\"\n",
    "  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d93c5e9",
   "metadata": {},
   "source": [
    "Consideriamo ora un modello a due fattori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20219ff",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "f2 <- '\n",
    "  efa(\"efa\")*f1 +\n",
    "  efa(\"efa\")*f2 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4\n",
    "'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f789ccf8",
   "metadata": {},
   "source": [
    "Adattiamo il modello ai dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045eb959",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "efa_f2 <-\n",
    "  cfa(\n",
    "    model = f2,\n",
    "    sample.cov = psychot_cor_mat,\n",
    "    sample.nobs = 250,\n",
    "    rotation = \"oblimin\"\n",
    "  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "193c6c49",
   "metadata": {},
   "source": [
    "Esaminiamo gli indici di bontà di adattamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998b4117",
   "metadata": {
    "lines_to_next_cell": 2,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 x 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>chisq</th><th scope=col>df</th><th scope=col>pvalue</th><th scope=col>cfi</th><th scope=col>tli</th><th scope=col>rmsea</th><th scope=col>srmr</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>375</td><td>20</td><td><span style=white-space:pre-wrap>&lt; .001           </span></td><td>0.71</td><td>0.594</td><td>0.267</td><td>0.187</td></tr>\n",
       "\t<tr><td> 10</td><td>13</td><td>0.709310449320098</td><td>1.00</td><td>1.006</td><td>0.000</td><td>0.010</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 x 7\n",
       "\\begin{tabular}{lllllll}\n",
       " chisq & df & pvalue & cfi & tli & rmsea & srmr\\\\\n",
       " <dbl> & <int> & <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 375 & 20 & < .001            & 0.71 & 0.594 & 0.267 & 0.187\\\\\n",
       "\t  10 & 13 & 0.709310449320098 & 1.00 & 1.006 & 0.000 & 0.010\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 x 7\n",
       "\n",
       "| chisq &lt;dbl&gt; | df &lt;int&gt; | pvalue &lt;chr&gt; | cfi &lt;dbl&gt; | tli &lt;dbl&gt; | rmsea &lt;dbl&gt; | srmr &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 375 | 20 | &lt; .001            | 0.71 | 0.594 | 0.267 | 0.187 |\n",
       "|  10 | 13 | 0.709310449320098 | 1.00 | 1.006 | 0.000 | 0.010 |\n",
       "\n"
      ],
      "text/plain": [
       "  chisq df pvalue            cfi  tli   rmsea srmr \n",
       "1 375   20 < .001            0.71 0.594 0.267 0.187\n",
       "2  10   13 0.709310449320098 1.00 1.006 0.000 0.010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the fit measures\n",
    "fit_measures_robust <- c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\")\n",
    "\n",
    "# collect them for each model\n",
    "rbind(\n",
    "  fitmeasures(efa_f1, fit_measures_robust),\n",
    "  fitmeasures(efa_f2, fit_measures_robust)\n",
    ") %>%\n",
    "  # wrangle\n",
    "  data.frame() %>%\n",
    "  mutate(\n",
    "    chisq = round(chisq, digits = 0),\n",
    "    df = as.integer(df),\n",
    "    pvalue = ifelse(pvalue == 0, \"< .001\", pvalue)\n",
    "  ) %>%\n",
    "  mutate_at(vars(cfi:srmr), ~ round(., digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05812cf9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name     Value Threshold Interpretation\n",
      "1    GFI 0.6713421      0.95           poor\n",
      "2   AGFI 0.4084158      0.90           poor\n",
      "3    NFI 0.7006460      0.90           poor\n",
      "4   NNFI 0.5941736      0.90           poor\n",
      "5    CFI 0.7101240      0.90           poor\n",
      "6  RMSEA 0.2665811      0.05           poor\n",
      "7   SRMR 0.1873289      0.08           poor\n",
      "8    RFI 0.5809044      0.90           poor\n",
      "9   PNFI 0.5004614      0.50   satisfactory\n",
      "10   IFI 0.7120036      0.90           poor\n"
     ]
    }
   ],
   "source": [
    "print(effectsize::interpret(efa_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "510e9730",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name       Value Threshold Interpretation\n",
      "1    GFI 0.990554109      0.95   satisfactory\n",
      "2   AGFI 0.973842148      0.90   satisfactory\n",
      "3    NFI 0.992174918      0.90   satisfactory\n",
      "4   NNFI 1.005603388      0.90   satisfactory\n",
      "5    CFI 1.000000000      0.90   satisfactory\n",
      "6  RMSEA 0.000000000      0.05   satisfactory\n",
      "7   SRMR 0.009907613      0.08   satisfactory\n",
      "8    RFI 0.983145977      0.90   satisfactory\n",
      "9   PNFI 0.460652640      0.50           poor\n",
      "10   IFI 1.002570123      0.90   satisfactory\n"
     ]
    }
   ],
   "source": [
    "print(effectsize::interpret(efa_f2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3aa2814a",
   "metadata": {},
   "source": [
    "I risultati mostrano come, in un modello EFA, una soluzione a due fattori produca un adattamento adeguato, mentre ciò non si verifica con un modello ad un solo fattore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82acad08",
   "metadata": {},
   "source": [
    "## Specificazione errata delle relazioni tra indicatori e fattori latenti\n",
    "\n",
    "Un'altra potenziale fonte di errata specificazione del modello CFA è una designazione errata delle relazioni tra indicatori e fattori latenti.\n",
    "\n",
    "In questo esempio, un ricercatore ha sviluppato un questionario di 12 item (gli item sono valutati su scale da 0 a 8) progettato per valutare le motivazioni dei giovani adulti a consumare bevande alcoliche (Cooper, 1994). La misura aveva lo scopo di valutare tre aspetti di questo costrutto (4 item ciascuno): (1) motivazioni di coping (item 1–4), (2) motivazioni sociali (item 5–8) e (3) motivazioni di miglioramento (item 9 –12). I dati sono i seguenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d6a1ea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sds <- c(2.06, 1.52, 1.92, 1.41, 1.73, 1.77, 2.49, 2.27, 2.68, 1.75, 2.57, 2.66)\n",
    "\n",
    "cors <- '\n",
    "  1.000 \n",
    "  0.300  1.000 \n",
    "  0.229  0.261  1.000 \n",
    "  0.411  0.406  0.429  1.000 \n",
    "  0.172  0.252  0.218  0.481  1.000 \n",
    "  0.214  0.268  0.267  0.579  0.484  1.000 \n",
    "  0.200  0.214  0.241  0.543  0.426  0.492  1.000 \n",
    "  0.185  0.230  0.185  0.545  0.463  0.548  0.522  1.000 \n",
    "  0.134  0.146  0.108  0.186  0.122  0.131  0.108  0.151  1.000 \n",
    "  0.134  0.099  0.061  0.223  0.133  0.188  0.105  0.170  0.448  1.000 \n",
    "  0.160  0.131  0.158  0.161  0.044  0.124  0.066  0.061  0.370  0.350  1.000 \n",
    "  0.087  0.088  0.101  0.198  0.077  0.177  0.128  0.112  0.356  0.359  0.507  1.000'\n",
    "\n",
    "covs <- getCov(cors, sds = sds, names = paste(\"x\", 1:12, sep = \"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d62fe27",
   "metadata": {},
   "source": [
    "Iniziamo con un modello che ipotizza tre fattori comuni latenti correlati, coerentemente con la motivazione che stava alla base della costruzione dello strumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6315929f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model1 <- '\n",
    "  copingm  =~ x1 + x2 + x3 + x4\n",
    "  socialm  =~ x5 + x6 + x7 + x8\n",
    "  enhancem =~ x9 + x10 + x11 + x12\n",
    "'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2e929d3",
   "metadata": {},
   "source": [
    "Adattiamo il modello ai dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a031da6e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step05_samplestats():  \n",
      "   sample.mean= argument is missing, but model contains mean/intercept \n",
      "   parameters.\"\n"
     ]
    }
   ],
   "source": [
    "fit1 <- cfa(\n",
    "  model1, \n",
    "  sample.cov = covs, \n",
    "  sample.nobs = 500, \n",
    "  mimic = \"mplus\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a3f753a",
   "metadata": {},
   "source": [
    "Esaminando le misure di adattamento potremmo concludere che il modello è adeguato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "639bdcfe",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name      Value Threshold Interpretation\n",
      "1    GFI 0.97009178      0.95   satisfactory\n",
      "2   AGFI 0.94722078      0.90   satisfactory\n",
      "3    NFI 0.94785001      0.90   satisfactory\n",
      "4   NNFI 0.97102541      0.90   satisfactory\n",
      "5    CFI 0.97761054      0.90   satisfactory\n",
      "6  RMSEA 0.03745791      0.05   satisfactory\n",
      "7   SRMR 0.03438699      0.08   satisfactory\n",
      "8    RFI 0.93251177      0.90   satisfactory\n",
      "9   PNFI 0.73242955      0.50   satisfactory\n",
      "10   IFI 0.97781875      0.90   satisfactory\n"
     ]
    }
   ],
   "source": [
    "print(effectsize::interpret(fit1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e247c38",
   "metadata": {},
   "source": [
    "Tuttavia, un esame più attento mette in evidenza un comportamento anomalo dell'item `x4` e alcune caratteristiche anomale del modello in generale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7782fea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lhs op      rhs est.std    se      z pvalue ci.lower ci.upper\n",
      "1   copingm =~       x1   0.432 0.039 11.030   0.00    0.355    0.508\n",
      "2   copingm =~       x2   0.436 0.039 11.174   0.00    0.359    0.512\n",
      "3   copingm =~       x3   0.451 0.038 11.730   0.00    0.376    0.527\n",
      "4   copingm =~       x4   0.953 0.024 38.967   0.00    0.905    1.001\n",
      "5   socialm =~       x5   0.633 0.032 20.064   0.00    0.571    0.695\n",
      "6   socialm =~       x6   0.748 0.025 29.363   0.00    0.698    0.798\n",
      "7   socialm =~       x7   0.690 0.029 24.154   0.00    0.634    0.746\n",
      "8   socialm =~       x8   0.729 0.026 27.519   0.00    0.677    0.781\n",
      "9  enhancem =~       x9   0.602 0.039 15.581   0.00    0.526    0.678\n",
      "10 enhancem =~      x10   0.597 0.039 15.397   0.00    0.521    0.673\n",
      "11 enhancem =~      x11   0.661 0.037 17.982   0.00    0.589    0.733\n",
      "12 enhancem =~      x12   0.665 0.037 18.167   0.00    0.593    0.737\n",
      "13       x1 ~~       x1   0.814 0.034 24.085   0.00    0.747    0.880\n",
      "14       x2 ~~       x2   0.810 0.034 23.837   0.00    0.744    0.877\n",
      "15       x3 ~~       x3   0.796 0.035 22.938   0.00    0.728    0.864\n",
      "16       x4 ~~       x4   0.091 0.047  1.959   0.05    0.000    0.183\n",
      "17       x5 ~~       x5   0.599 0.040 14.985   0.00    0.521    0.677\n",
      "18       x6 ~~       x6   0.441 0.038 11.573   0.00    0.366    0.515\n",
      "19       x7 ~~       x7   0.524 0.039 13.293   0.00    0.447    0.601\n",
      "20       x8 ~~       x8   0.469 0.039 12.151   0.00    0.393    0.545\n",
      "21       x9 ~~       x9   0.638 0.047 13.707   0.00    0.546    0.729\n",
      "22      x10 ~~      x10   0.643 0.046 13.875   0.00    0.552    0.734\n",
      "23      x11 ~~      x11   0.563 0.049 11.605   0.00    0.468    0.659\n",
      "24      x12 ~~      x12   0.558 0.049 11.447   0.00    0.462    0.653\n",
      "25  copingm ~~  copingm   1.000 0.000     NA     NA    1.000    1.000\n",
      "26  socialm ~~  socialm   1.000 0.000     NA     NA    1.000    1.000\n",
      "27 enhancem ~~ enhancem   1.000 0.000     NA     NA    1.000    1.000\n",
      "28  copingm ~~  socialm   0.799 0.031 26.150   0.00    0.739    0.859\n",
      "29  copingm ~~ enhancem   0.322 0.051  6.336   0.00    0.222    0.422\n",
      "30  socialm ~~ enhancem   0.268 0.056  4.817   0.00    0.159    0.377\n",
      "31       x1 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "32       x2 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "33       x3 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "34       x4 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "35       x5 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "36       x6 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "37       x7 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "38       x8 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "39       x9 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "40      x10 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "41      x11 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "42      x12 ~1            0.000 0.045  0.000   1.00   -0.088    0.088\n",
      "43  copingm ~1            0.000 0.000     NA     NA    0.000    0.000\n",
      "44  socialm ~1            0.000 0.000     NA     NA    0.000    0.000\n",
      "45 enhancem ~1            0.000 0.000     NA     NA    0.000    0.000\n"
     ]
    }
   ],
   "source": [
    "print(standardizedSolution(fit1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff3c959f",
   "metadata": {},
   "source": [
    "In particolare, l'item `x4` mostra una saturazione molto forte sul fattore Motivi di coping (.955) ed emerge una correlazione molto alta tra i fattori Motivi di coping e Motivi sociali (.798).\n",
    "\n",
    "{cite:t}`brown2015confirmatory` suggerisce di esaminare i *Modification Indices*. Tale esame mostra che il MI associato a `x4` è molto alto, 18.916."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b263e23",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox\n",
      "46   copingm =~  x5  0.030 -0.030  -0.027   -0.015   -0.015\n",
      "47   copingm =~  x6  0.484  0.127   0.113    0.064    0.064\n",
      "48   copingm =~  x7  0.780  0.220   0.196    0.079    0.079\n",
      "49   copingm =~  x8  1.962 -0.323  -0.287   -0.127   -0.127\n",
      "50   copingm =~  x9  0.101  0.044   0.039    0.015    0.015\n",
      "51   copingm =~ x10  2.016  0.129   0.114    0.065    0.065\n",
      "52   copingm =~ x11  1.870 -0.181  -0.161   -0.063   -0.063\n",
      "53   copingm =~ x12  0.040 -0.027  -0.024   -0.009   -0.009\n",
      "54   socialm =~  x1  6.927 -0.520  -0.569   -0.277   -0.277\n",
      "55   socialm =~  x2  0.052 -0.033  -0.036   -0.024   -0.024\n",
      "56   socialm =~  x3  2.058 -0.267  -0.292   -0.152   -0.152\n",
      "57   socialm =~  x4 18.916  1.300   1.423    1.010    1.010\n",
      "58   socialm =~  x9  0.338  0.067   0.073    0.027    0.027\n",
      "59   socialm =~ x10  2.884  0.128   0.140    0.080    0.080\n",
      "60   socialm =~ x11  4.357 -0.229  -0.251   -0.098   -0.098\n",
      "61   socialm =~ x12  0.001  0.004   0.004    0.002    0.002\n",
      "62  enhancem =~  x1  1.954  0.093   0.149    0.072    0.072\n",
      "63  enhancem =~  x2  0.863  0.045   0.073    0.048    0.048\n",
      "64  enhancem =~  x3  0.380  0.038   0.061    0.032    0.032\n",
      "65  enhancem =~  x4  3.102 -0.104  -0.168   -0.119   -0.119\n",
      "66  enhancem =~  x5  0.596 -0.039  -0.063   -0.036   -0.036\n",
      "67  enhancem =~  x6  2.495  0.078   0.125    0.071    0.071\n",
      "68  enhancem =~  x7  0.539 -0.052  -0.084   -0.034   -0.034\n",
      "69  enhancem =~  x8  0.093 -0.019  -0.031   -0.014   -0.014\n",
      "70        x1 ~~  x2 10.299  0.379   0.379    0.149    0.149\n",
      "71        x1 ~~  x3  0.986  0.147   0.147    0.046    0.046\n",
      "72        x1 ~~  x4  0.016 -0.015  -0.015   -0.019   -0.019\n",
      "73        x1 ~~  x5  0.452 -0.080  -0.080   -0.032   -0.032\n",
      "74        x1 ~~  x6  0.484 -0.078  -0.078   -0.036   -0.036\n",
      "75        x1 ~~  x7  0.290 -0.089  -0.089   -0.027   -0.027\n",
      "76        x1 ~~  x8  1.535 -0.181  -0.181   -0.063   -0.063\n",
      "77        x1 ~~  x9  0.468  0.133   0.133    0.034    0.034\n",
      "78        x1 ~~ x10  0.067  0.033   0.033    0.013    0.013\n",
      "79        x1 ~~ x11  4.030  0.364   0.364    0.102    0.102\n",
      "80        x1 ~~ x12  1.504 -0.229  -0.229   -0.062   -0.062\n",
      "81        x2 ~~  x3  3.508  0.205   0.205    0.088    0.088\n",
      "82        x2 ~~  x4  6.780 -0.229  -0.229   -0.393   -0.393\n",
      "83        x2 ~~  x5  1.449  0.106   0.106    0.058    0.058\n",
      "84        x2 ~~  x6  0.102  0.026   0.026    0.016    0.016\n",
      "85        x2 ~~  x7  1.144 -0.130  -0.130   -0.053   -0.053\n",
      "86        x2 ~~  x8  0.366 -0.065  -0.065   -0.031   -0.031\n",
      "87        x2 ~~  x9  1.877  0.196   0.196    0.067    0.067\n",
      "88        x2 ~~ x10  0.434 -0.062  -0.062   -0.032   -0.032\n",
      "89        x2 ~~ x11  1.599  0.169   0.169    0.064    0.064\n",
      "90        x2 ~~ x12  0.726 -0.117  -0.117   -0.043   -0.043\n",
      "91        x3 ~~  x4  0.107 -0.037  -0.037   -0.051   -0.051\n",
      "92        x3 ~~  x5  0.024  0.017   0.017    0.008    0.008\n",
      "93        x3 ~~  x6  0.211  0.048   0.048    0.024    0.024\n",
      "94        x3 ~~  x7  0.009  0.015   0.015    0.005    0.005\n",
      "95        x3 ~~  x8  5.281 -0.310  -0.310   -0.117   -0.117\n",
      "96        x3 ~~  x9  0.031  0.031   0.031    0.009    0.009\n",
      "97        x3 ~~ x10  3.545 -0.221  -0.221   -0.092   -0.092\n",
      "98        x3 ~~ x11  5.967  0.408   0.408    0.124    0.124\n",
      "99        x3 ~~ x12  0.055 -0.040  -0.040   -0.012   -0.012\n",
      "100       x4 ~~  x5  0.063 -0.016  -0.016   -0.028   -0.028\n",
      "101       x4 ~~  x6  0.052  0.015   0.015    0.029    0.029\n",
      "102       x4 ~~  x7  2.114  0.131   0.131    0.170    0.170\n",
      "103       x4 ~~  x8  0.208  0.037   0.037    0.057    0.057\n",
      "104       x4 ~~  x9  0.887 -0.091  -0.091   -0.100   -0.100\n",
      "105       x4 ~~ x10  1.063  0.065   0.065    0.109    0.109\n",
      "106       x4 ~~ x11  2.637 -0.149  -0.149   -0.181   -0.181\n",
      "107       x4 ~~ x12  0.169  0.039   0.039    0.046    0.046\n",
      "108       x5 ~~  x6  0.370  0.057   0.057    0.036    0.036\n",
      "109       x5 ~~  x7  0.292 -0.072  -0.072   -0.030   -0.030\n",
      "110       x5 ~~  x8  0.007  0.010   0.010    0.005    0.005\n",
      "111       x5 ~~  x9  0.822  0.133   0.133    0.047    0.047\n",
      "112       x5 ~~ x10  0.339  0.056   0.056    0.030    0.030\n",
      "113       x5 ~~ x11  1.126 -0.145  -0.145   -0.056   -0.056\n",
      "114       x5 ~~ x12  1.143 -0.151  -0.151   -0.057   -0.057\n",
      "115       x6 ~~  x7  2.528 -0.215  -0.215   -0.101   -0.101\n",
      "116       x6 ~~  x8  0.053  0.029   0.029    0.016    0.016\n",
      "117       x6 ~~  x9  1.056 -0.141  -0.141   -0.056   -0.056\n",
      "118       x6 ~~ x10  0.598  0.069   0.069    0.042    0.042\n",
      "119       x6 ~~ x11  0.248  0.064   0.064    0.028    0.028\n",
      "120       x6 ~~ x12  1.667  0.170   0.170    0.073    0.073\n",
      "121       x7 ~~  x8  1.431  0.206   0.206    0.074    0.074\n",
      "122       x7 ~~  x9  0.032 -0.036  -0.036   -0.009   -0.009\n",
      "123       x7 ~~ x10  1.521 -0.163  -0.163   -0.065   -0.065\n",
      "124       x7 ~~ x11  0.263 -0.097  -0.097   -0.028   -0.028\n",
      "125       x7 ~~ x12  0.637  0.156   0.156    0.044    0.044\n",
      "126       x8 ~~  x9  1.621  0.227   0.227    0.068    0.068\n",
      "127       x8 ~~ x10  1.311  0.134   0.134    0.061    0.061\n",
      "128       x8 ~~ x11  2.144 -0.244  -0.244   -0.081   -0.081\n",
      "129       x8 ~~ x12  0.591 -0.132  -0.132   -0.043   -0.043\n",
      "130       x9 ~~ x10 19.846  0.862   0.862    0.288    0.288\n",
      "131       x9 ~~ x11  2.908 -0.518  -0.518   -0.126   -0.126\n",
      "132       x9 ~~ x12  7.696 -0.876  -0.876   -0.207   -0.207\n",
      "133      x10 ~~ x11  7.331 -0.534  -0.534   -0.197   -0.197\n",
      "134      x10 ~~ x12  5.572 -0.484  -0.484   -0.174   -0.174\n",
      "135      x11 ~~ x12 26.947  1.711   1.711    0.447    0.447\n"
     ]
    }
   ],
   "source": [
    "print(modindices(fit1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2c1efc3",
   "metadata": {},
   "source": [
    "Le considerazioni precedenti, dunque, suggeriscono che il modello potrebbe non avere descritto in maniera adeguata le relazioni tra `x4` e i fattori comuni latenti.  In base a considerazioni teoriche, supponiamo che abbia senso pensare che `x4` saturi non solo sul fattore Motivi di coping ma anche sul fattore di Motivi Sociali. Specifichiamo dunque un nuovo modello nel modo seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f847670b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model2 <- '\n",
    "  copingm  =~ x1 + x2 + x3 + x4\n",
    "  socialm  =~ x4 + x5 + x6 + x7 + x8\n",
    "  enhancem =~ x9 + x10 + x11 + x12\n",
    "'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49f7785d",
   "metadata": {},
   "source": [
    "Adattiamo il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6f003d0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step05_samplestats():  \n",
      "   sample.mean= argument is missing, but model contains mean/intercept \n",
      "   parameters.\"\n"
     ]
    }
   ],
   "source": [
    "fit2 <- cfa(\n",
    "  model2, \n",
    "  sample.cov = covs, \n",
    "  sample.nobs = 500, \n",
    "  mimic = \"mplus\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50a7a3ae",
   "metadata": {},
   "source": [
    "Esaminiamo gli indici di bontà di adattamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e066077f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name      Value Threshold Interpretation\n",
      "1    GFI 0.97684139      0.95   satisfactory\n",
      "2   AGFI 0.95831451      0.90   satisfactory\n",
      "3    NFI 0.95826773      0.90   satisfactory\n",
      "4   NNFI 0.98393923      0.90   satisfactory\n",
      "5    CFI 0.98783275      0.90   satisfactory\n",
      "6  RMSEA 0.02788804      0.05   satisfactory\n",
      "7   SRMR 0.02887855      0.08   satisfactory\n",
      "8    RFI 0.94491340      0.90   satisfactory\n",
      "9   PNFI 0.72596040      0.50   satisfactory\n",
      "10   IFI 0.98795337      0.90   satisfactory\n"
     ]
    }
   ],
   "source": [
    "print(effectsize::interpret(fit2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2543208",
   "metadata": {},
   "source": [
    "La bontà di adattamento è migliorata.\n",
    "\n",
    "Esaminiamo la soluzione standardizzata. Vediamo ora che sono scomparse le due anomalie trovate in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11348752",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lhs op      rhs est.std    se      z pvalue ci.lower ci.upper\n",
      "1   copingm =~       x1   0.514 0.043 12.034      0    0.430    0.597\n",
      "2   copingm =~       x2   0.515 0.043 12.072      0    0.431    0.599\n",
      "3   copingm =~       x3   0.516 0.043 12.106      0    0.432    0.600\n",
      "4   copingm =~       x4   0.538 0.062  8.660      0    0.416    0.660\n",
      "5   socialm =~       x4   0.439 0.061  7.204      0    0.320    0.558\n",
      "6   socialm =~       x5   0.632 0.032 19.995      0    0.570    0.694\n",
      "7   socialm =~       x6   0.746 0.025 29.279      0    0.696    0.796\n",
      "8   socialm =~       x7   0.691 0.028 24.235      0    0.635    0.746\n",
      "9   socialm =~       x8   0.731 0.026 27.762      0    0.679    0.782\n",
      "10 enhancem =~       x9   0.603 0.039 15.625      0    0.527    0.678\n",
      "11 enhancem =~      x10   0.595 0.039 15.308      0    0.519    0.671\n",
      "12 enhancem =~      x11   0.665 0.037 18.188      0    0.593    0.737\n",
      "13 enhancem =~      x12   0.663 0.037 18.103      0    0.591    0.735\n",
      "14       x1 ~~       x1   0.736 0.044 16.786      0    0.650    0.822\n",
      "15       x2 ~~       x2   0.735 0.044 16.729      0    0.649    0.821\n",
      "16       x3 ~~       x3   0.734 0.044 16.678      0    0.647    0.820\n",
      "17       x4 ~~       x4   0.230 0.037  6.292      0    0.158    0.301\n",
      "18       x5 ~~       x5   0.601 0.040 15.043      0    0.522    0.679\n",
      "19       x6 ~~       x6   0.443 0.038 11.634      0    0.368    0.517\n",
      "20       x7 ~~       x7   0.523 0.039 13.292      0    0.446    0.600\n",
      "21       x8 ~~       x8   0.466 0.038 12.106      0    0.390    0.541\n",
      "22       x9 ~~       x9   0.637 0.046 13.701      0    0.546    0.728\n",
      "23      x10 ~~      x10   0.646 0.046 13.990      0    0.556    0.737\n",
      "24      x11 ~~      x11   0.558 0.049 11.474      0    0.463    0.653\n",
      "25      x12 ~~      x12   0.561 0.049 11.546      0    0.465    0.656\n",
      "26  copingm ~~  copingm   1.000 0.000     NA     NA    1.000    1.000\n",
      "27  socialm ~~  socialm   1.000 0.000     NA     NA    1.000    1.000\n",
      "28 enhancem ~~ enhancem   1.000 0.000     NA     NA    1.000    1.000\n",
      "29  copingm ~~  socialm   0.610 0.057 10.744      0    0.498    0.721\n",
      "30  copingm ~~ enhancem   0.350 0.059  5.964      0    0.235    0.465\n",
      "31  socialm ~~ enhancem   0.265 0.055  4.794      0    0.156    0.373\n",
      "32       x1 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "33       x2 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "34       x3 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "35       x4 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "36       x5 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "37       x6 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "38       x7 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "39       x8 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "40       x9 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "41      x10 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "42      x11 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "43      x12 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "44  copingm ~1            0.000 0.000     NA     NA    0.000    0.000\n",
      "45  socialm ~1            0.000 0.000     NA     NA    0.000    0.000\n",
      "46 enhancem ~1            0.000 0.000     NA     NA    0.000    0.000\n"
     ]
    }
   ],
   "source": [
    "print(standardizedSolution(fit2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd49aee0",
   "metadata": {},
   "source": [
    "Esaminando i MI, notiamo che il modello potrebbe migliorare se introduciamo una correlazione tra le specificità `x11` e `x12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e08a4d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox\n",
      "47   copingm =~  x5  0.076  0.032   0.034    0.020    0.020\n",
      "48   copingm =~  x6  1.413  0.143   0.151    0.086    0.086\n",
      "49   copingm =~  x7  0.245  0.083   0.088    0.035    0.035\n",
      "50   copingm =~  x8  3.668 -0.295  -0.311   -0.137   -0.137\n",
      "51   copingm =~  x9  0.243  0.066   0.069    0.026    0.026\n",
      "52   copingm =~ x10  0.566  0.065   0.069    0.040    0.040\n",
      "53   copingm =~ x11  0.119 -0.044  -0.046   -0.018   -0.018\n",
      "54   copingm =~ x12  0.598 -0.102  -0.108   -0.041   -0.041\n",
      "55   socialm =~  x1  1.948 -0.396  -0.245   -0.119   -0.119\n",
      "56   socialm =~  x2  0.718  0.177   0.110    0.072    0.072\n",
      "57   socialm =~  x3  0.298  0.144   0.089    0.047    0.047\n",
      "58   socialm =~  x9  0.316  0.114   0.071    0.026    0.026\n",
      "59   socialm =~ x10  3.169  0.236   0.146    0.084    0.084\n",
      "60   socialm =~ x11  4.927 -0.430  -0.266   -0.104   -0.104\n",
      "61   socialm =~ x12  0.017  0.026   0.016    0.006    0.006\n",
      "62  enhancem =~  x1  0.314  0.040   0.064    0.031    0.031\n",
      "63  enhancem =~  x2  0.003  0.003   0.004    0.003    0.003\n",
      "64  enhancem =~  x3  0.037 -0.013  -0.020   -0.011   -0.011\n",
      "65  enhancem =~  x4  0.106 -0.013  -0.021   -0.015   -0.015\n",
      "66  enhancem =~  x5  0.464 -0.034  -0.055   -0.032   -0.032\n",
      "67  enhancem =~  x6  2.703  0.079   0.128    0.072    0.072\n",
      "68  enhancem =~  x7  0.467 -0.048  -0.077   -0.031   -0.031\n",
      "69  enhancem =~  x8  0.095 -0.019  -0.031   -0.014   -0.014\n",
      "70        x1 ~~  x2  1.966  0.187   0.187    0.081    0.081\n",
      "71        x1 ~~  x3  2.042 -0.241  -0.241   -0.083   -0.083\n",
      "72        x1 ~~  x4  0.775  0.098   0.098    0.082    0.082\n",
      "73        x1 ~~  x5  0.238 -0.058  -0.058   -0.024   -0.024\n",
      "74        x1 ~~  x6  0.187 -0.048  -0.048   -0.023   -0.023\n",
      "75        x1 ~~  x7  0.019 -0.022  -0.022   -0.007   -0.007\n",
      "76        x1 ~~  x8  0.366 -0.087  -0.087   -0.032   -0.032\n",
      "77        x1 ~~  x9  0.155  0.076   0.076    0.020    0.020\n",
      "78        x1 ~~ x10  0.104  0.041   0.041    0.016    0.016\n",
      "79        x1 ~~ x11  2.019  0.255   0.255    0.075    0.075\n",
      "80        x1 ~~ x12  1.911 -0.257  -0.257   -0.073   -0.073\n",
      "81        x2 ~~  x3  0.035 -0.023  -0.023   -0.011   -0.011\n",
      "82        x2 ~~  x4  3.029 -0.144  -0.144   -0.163   -0.163\n",
      "83        x2 ~~  x5  2.503  0.138   0.138    0.079    0.079\n",
      "84        x2 ~~  x6  0.509  0.058   0.058    0.038    0.038\n",
      "85        x2 ~~  x7  0.471 -0.082  -0.082   -0.035   -0.035\n",
      "86        x2 ~~  x8  0.015  0.013   0.013    0.006    0.006\n",
      "87        x2 ~~  x9  1.289  0.161   0.161    0.058    0.058\n",
      "88        x2 ~~ x10  0.467 -0.064  -0.064   -0.035   -0.035\n",
      "89        x2 ~~ x11  0.338  0.077   0.077    0.031    0.031\n",
      "90        x2 ~~ x12  0.970 -0.135  -0.135   -0.052   -0.052\n",
      "91        x3 ~~  x4  1.095  0.109   0.109    0.098    0.098\n",
      "92        x3 ~~  x5  0.169  0.045   0.045    0.021    0.021\n",
      "93        x3 ~~  x6  0.681  0.085   0.085    0.044    0.044\n",
      "94        x3 ~~  x7  0.315  0.085   0.085    0.029    0.029\n",
      "95        x3 ~~  x8  3.075 -0.235  -0.235   -0.092   -0.092\n",
      "96        x3 ~~  x9  0.022 -0.026  -0.026   -0.008   -0.008\n",
      "97        x3 ~~ x10  3.825 -0.230  -0.230   -0.100   -0.100\n",
      "98        x3 ~~ x11  3.498  0.313   0.313    0.099    0.099\n",
      "99        x3 ~~ x12  0.079 -0.049  -0.049   -0.015   -0.015\n",
      "100       x4 ~~  x5  0.337 -0.037  -0.037   -0.041   -0.041\n",
      "101       x4 ~~  x6  0.033 -0.012  -0.012   -0.015   -0.015\n",
      "102       x4 ~~  x7  1.053  0.094   0.094    0.077    0.077\n",
      "103       x4 ~~  x8  0.071 -0.022  -0.022   -0.021   -0.021\n",
      "104       x4 ~~  x9  0.541 -0.070  -0.070   -0.048   -0.048\n",
      "105       x4 ~~ x10  1.128  0.066   0.066    0.070    0.070\n",
      "106       x4 ~~ x11  1.313 -0.102  -0.102   -0.079   -0.079\n",
      "107       x4 ~~ x12  0.322  0.052   0.052    0.039    0.039\n",
      "108       x5 ~~  x6  0.504  0.066   0.066    0.042    0.042\n",
      "109       x5 ~~  x7  0.262 -0.068  -0.068   -0.028   -0.028\n",
      "110       x5 ~~  x8  0.004  0.008   0.008    0.004    0.004\n",
      "111       x5 ~~  x9  0.850  0.135   0.135    0.047    0.047\n",
      "112       x5 ~~ x10  0.288  0.052   0.052    0.027    0.027\n",
      "113       x5 ~~ x11  1.019 -0.138  -0.138   -0.054   -0.054\n",
      "114       x5 ~~ x12  1.224 -0.157  -0.157   -0.059   -0.059\n",
      "115       x6 ~~  x7  2.404 -0.209  -0.209   -0.099   -0.099\n",
      "116       x6 ~~  x8  0.034  0.023   0.023    0.012    0.012\n",
      "117       x6 ~~  x9  0.978 -0.135  -0.135   -0.054   -0.054\n",
      "118       x6 ~~ x10  0.524  0.065   0.065    0.039    0.039\n",
      "119       x6 ~~ x11  0.341  0.074   0.074    0.033    0.033\n",
      "120       x6 ~~ x12  1.520  0.163   0.163    0.069    0.069\n",
      "121       x7 ~~  x8  1.171  0.186   0.186    0.067    0.067\n",
      "122       x7 ~~  x9  0.020 -0.028  -0.028   -0.007   -0.007\n",
      "123       x7 ~~ x10  1.593 -0.167  -0.167   -0.066   -0.066\n",
      "124       x7 ~~ x11  0.175 -0.079  -0.079   -0.023   -0.023\n",
      "125       x7 ~~ x12  0.586  0.149   0.149    0.042    0.042\n",
      "126       x8 ~~  x9  1.808  0.239   0.239    0.072    0.072\n",
      "127       x8 ~~ x10  1.267  0.131   0.131    0.060    0.060\n",
      "128       x8 ~~ x11  1.791 -0.222  -0.222   -0.075   -0.075\n",
      "129       x8 ~~ x12  0.595 -0.132  -0.132   -0.043   -0.043\n",
      "130       x9 ~~ x10 20.103  0.864   0.864    0.288    0.288\n",
      "131       x9 ~~ x11  3.658 -0.582  -0.582   -0.142   -0.142\n",
      "132       x9 ~~ x12  7.229 -0.845  -0.845   -0.199   -0.199\n",
      "133      x10 ~~ x11  7.617 -0.543  -0.543   -0.201   -0.201\n",
      "134      x10 ~~ x12  4.512 -0.431  -0.431   -0.154   -0.154\n",
      "135      x11 ~~ x12 26.071  1.680   1.680    0.440    0.440\n"
     ]
    }
   ],
   "source": [
    "print(modindices(fit2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "accbe95c",
   "metadata": {},
   "source": [
    "Il nuovo modello diventa dunque il seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c824e5b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model3 <- '\n",
    "  copingm  =~ x1 + x2 + x3 + x4\n",
    "  socialm  =~ x4 + x5 + x6 + x7 + x8\n",
    "  enhancem =~ x9 + x10 + x11 + x12\n",
    "  x11 ~~ x12\n",
    "'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68cf8893",
   "metadata": {},
   "source": [
    "Adattiamo il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bfdfb3b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step05_samplestats():  \n",
      "   sample.mean= argument is missing, but model contains mean/intercept \n",
      "   parameters.\"\n"
     ]
    }
   ],
   "source": [
    "fit3 <- cfa(\n",
    "  model3, \n",
    "  sample.cov = covs, \n",
    "  sample.nobs = 500, \n",
    "  mimic = \"mplus\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bf58380",
   "metadata": {},
   "source": [
    "Un test basato sul rapporto di verosimiglianze conferma che il miglioramento di adattamento è sostanziale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed86ac3c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "     Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n",
      "fit3 49 23934 24107 44.955                                          \n",
      "fit2 50 23957 24125 69.444     24.488 0.21674       1  7.477e-07 ***\n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
     ]
    }
   ],
   "source": [
    "print(lavTestLRT(fit2, fit3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1714511d",
   "metadata": {},
   "source": [
    "Esaminiamo gli indici di bontà di adattamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bb610ec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-18 ended normally after 61 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        41\n",
      "\n",
      "  Number of observations                           500\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                                44.955\n",
      "  Degrees of freedom                                49\n",
      "  P-value (Chi-square)                           0.638\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                              1664.026\n",
      "  Degrees of freedom                                66\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    1.000\n",
      "  Tucker-Lewis Index (TLI)                       1.003\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)             -11926.170\n",
      "  Loglikelihood unrestricted model (H1)     -11903.692\n",
      "                                                      \n",
      "  Akaike (AIC)                               23934.339\n",
      "  Bayesian (BIC)                             24107.138\n",
      "  Sample-size adjusted Bayesian (SABIC)      23977.002\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.000\n",
      "  90 Percent confidence interval - lower         0.000\n",
      "  90 Percent confidence interval - upper         0.025\n",
      "  P-value H_0: RMSEA <= 0.050                    1.000\n",
      "  P-value H_0: RMSEA >= 0.080                    0.000\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.023\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "  copingm =~                                          \n",
      "    x1                1.000                           \n",
      "    x2                0.740    0.094    7.909    0.000\n",
      "    x3                0.933    0.118    7.903    0.000\n",
      "    x4                0.719    0.118    6.070    0.000\n",
      "  socialm =~                                          \n",
      "    x4                1.000                           \n",
      "    x5                1.771    0.273    6.485    0.000\n",
      "    x6                2.141    0.319    6.703    0.000\n",
      "    x7                2.784    0.421    6.611    0.000\n",
      "    x8                2.689    0.402    6.681    0.000\n",
      "  enhancem =~                                         \n",
      "    x9                1.000                           \n",
      "    x10               0.648    0.070    9.293    0.000\n",
      "    x11               0.776    0.093    8.340    0.000\n",
      "    x12               0.802    0.096    8.327    0.000\n",
      "\n",
      "Covariances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      " .x11 ~~                                              \n",
      "   .x12               1.460    0.300    4.873    0.000\n",
      "  copingm ~~                                          \n",
      "    socialm           0.398    0.071    5.603    0.000\n",
      "    enhancem          0.669    0.145    4.613    0.000\n",
      "  socialm ~~                                          \n",
      "    enhancem          0.320    0.084    3.783    0.000\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "   .x1                0.000    0.092    0.000    1.000\n",
      "   .x2                0.000    0.068    0.000    1.000\n",
      "   .x3                0.000    0.086    0.000    1.000\n",
      "   .x4                0.000    0.063    0.000    1.000\n",
      "   .x5                0.000    0.077    0.000    1.000\n",
      "   .x6                0.000    0.079    0.000    1.000\n",
      "   .x7                0.000    0.111    0.000    1.000\n",
      "   .x8                0.000    0.101    0.000    1.000\n",
      "   .x9                0.000    0.120    0.000    1.000\n",
      "   .x10               0.000    0.078    0.000    1.000\n",
      "   .x11               0.000    0.115    0.000    1.000\n",
      "   .x12               0.000    0.119    0.000    1.000\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "   .x1                3.117    0.230   13.546    0.000\n",
      "   .x2                1.694    0.125   13.527    0.000\n",
      "   .x3                2.705    0.200   13.536    0.000\n",
      "   .x4                0.454    0.070    6.502    0.000\n",
      "   .x5                1.794    0.130   13.835    0.000\n",
      "   .x6                1.384    0.115   12.015    0.000\n",
      "   .x7                3.240    0.248   13.089    0.000\n",
      "   .x8                2.393    0.194   12.352    0.000\n",
      "   .x9                3.958    0.400    9.895    0.000\n",
      "   .x10               1.710    0.170   10.063    0.000\n",
      "   .x11               4.657    0.371   12.545    0.000\n",
      "   .x12               4.997    0.398   12.561    0.000\n",
      "    copingm           1.118    0.217    5.158    0.000\n",
      "    socialm           0.380    0.110    3.469    0.001\n",
      "    enhancem          3.210    0.490    6.550    0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary(fit3, fit.measures = TRUE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99eeeefe",
   "metadata": {},
   "source": [
    "Gli indici di fit sono migliorati.\n",
    "\n",
    "Esaminiamo la soluzione standardizzata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9577e42",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lhs op      rhs est.std    se      z pvalue ci.lower ci.upper\n",
      "1   copingm =~       x1   0.514 0.043 12.016      0    0.430    0.598\n",
      "2   copingm =~       x2   0.515 0.043 12.055      0    0.431    0.599\n",
      "3   copingm =~       x3   0.514 0.043 12.037      0    0.431    0.598\n",
      "4   copingm =~       x4   0.540 0.063  8.609      0    0.417    0.663\n",
      "5   socialm =~       x4   0.438 0.061  7.129      0    0.317    0.558\n",
      "6   socialm =~       x5   0.632 0.032 20.004      0    0.570    0.694\n",
      "7   socialm =~       x6   0.746 0.025 29.291      0    0.697    0.796\n",
      "8   socialm =~       x7   0.690 0.029 24.206      0    0.634    0.746\n",
      "9   socialm =~       x8   0.731 0.026 27.800      0    0.680    0.783\n",
      "10 enhancem =~       x9   0.669 0.041 16.388      0    0.589    0.749\n",
      "11 enhancem =~      x10   0.664 0.041 16.243      0    0.584    0.744\n",
      "12 enhancem =~      x11   0.542 0.045 12.120      0    0.454    0.629\n",
      "13 enhancem =~      x12   0.541 0.045 12.083      0    0.453    0.628\n",
      "14      x11 ~~      x12   0.303 0.050  6.097      0    0.205    0.400\n",
      "15       x1 ~~       x1   0.736 0.044 16.757      0    0.650    0.822\n",
      "16       x2 ~~       x2   0.735 0.044 16.697      0    0.649    0.821\n",
      "17       x3 ~~       x3   0.735 0.044 16.726      0    0.649    0.822\n",
      "18       x4 ~~       x4   0.229 0.037  6.223      0    0.157    0.301\n",
      "19       x5 ~~       x5   0.601 0.040 15.043      0    0.522    0.679\n",
      "20       x6 ~~       x6   0.443 0.038 11.636      0    0.368    0.517\n",
      "21       x7 ~~       x7   0.524 0.039 13.307      0    0.447    0.601\n",
      "22       x8 ~~       x8   0.465 0.038 12.099      0    0.390    0.541\n",
      "23       x9 ~~       x9   0.552 0.055 10.104      0    0.445    0.659\n",
      "24      x10 ~~      x10   0.559 0.054 10.314      0    0.453    0.666\n",
      "25      x11 ~~      x11   0.706 0.048 14.582      0    0.611    0.801\n",
      "26      x12 ~~      x12   0.708 0.048 14.622      0    0.613    0.802\n",
      "27  copingm ~~  copingm   1.000 0.000     NA     NA    1.000    1.000\n",
      "28  socialm ~~  socialm   1.000 0.000     NA     NA    1.000    1.000\n",
      "29 enhancem ~~ enhancem   1.000 0.000     NA     NA    1.000    1.000\n",
      "30  copingm ~~  socialm   0.610 0.057 10.735      0    0.499    0.721\n",
      "31  copingm ~~ enhancem   0.353 0.060  5.844      0    0.235    0.472\n",
      "32  socialm ~~ enhancem   0.289 0.056  5.141      0    0.179    0.399\n",
      "33       x1 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "34       x2 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "35       x3 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "36       x4 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "37       x5 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "38       x6 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "39       x7 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "40       x8 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "41       x9 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "42      x10 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "43      x11 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "44      x12 ~1            0.000 0.045  0.000      1   -0.088    0.088\n",
      "45  copingm ~1            0.000 0.000     NA     NA    0.000    0.000\n",
      "46  socialm ~1            0.000 0.000     NA     NA    0.000    0.000\n",
      "47 enhancem ~1            0.000 0.000     NA     NA    0.000    0.000\n"
     ]
    }
   ],
   "source": [
    "print(standardizedSolution(fit3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df98dc03",
   "metadata": {},
   "source": [
    "Non ci sono ulteriori motivi di preoccupazione.  @brown2015confirmatory conclude che il modello più adeguato sia `model3`. \n",
    "\n",
    "Nel caso presente, a mio parare, l'introduzione della correlazione residua tra `x11` e `x12` si sarebbe anche potuta evitare, dato che il modello `model3` (con meno idiosincrasie legate al campione) si era già dimostrato adeguato.\n",
    "\n",
    "## Saturazione sul fattore sbagliato\n",
    "\n",
    "@brown2015confirmatory considera anche il caso opposto, ovvero quello nel quale il ricercatore ipotizza una saturazione spuria. Per i dati in discussione, si può avere la situazione presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4b1cb6e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model4 <- '\n",
    "  copingm  =~ x1 + x2 + x3 + x4\n",
    "  socialm  =~ x4 +x5 + x6 + x7 + x8 + x12\n",
    "  enhancem =~ x9 + x10 + x11\n",
    "'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7565a2e5",
   "metadata": {},
   "source": [
    "Adattiamo il modello ai dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "010de4b1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step05_samplestats():  \n",
      "   sample.mean= argument is missing, but model contains mean/intercept \n",
      "   parameters.\"\n"
     ]
    }
   ],
   "source": [
    "fit4 <- cfa(\n",
    "  model4, \n",
    "  sample.cov = covs, \n",
    "  sample.nobs = 500, \n",
    "  mimic = \"mplus\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f0e6cb0",
   "metadata": {},
   "source": [
    "Esaminiamo la soluzione ottenuta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a96b4df8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-18 ended normally after 59 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        40\n",
      "\n",
      "  Number of observations                           500\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                               212.717\n",
      "  Degrees of freedom                                50\n",
      "  P-value (Chi-square)                           0.000\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                              1664.026\n",
      "  Degrees of freedom                                66\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.898\n",
      "  Tucker-Lewis Index (TLI)                       0.866\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)             -12010.051\n",
      "  Loglikelihood unrestricted model (H1)     -11903.692\n",
      "                                                      \n",
      "  Akaike (AIC)                               24100.101\n",
      "  Bayesian (BIC)                             24268.685\n",
      "  Sample-size adjusted Bayesian (SABIC)      24141.723\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.081\n",
      "  90 Percent confidence interval - lower         0.070\n",
      "  90 Percent confidence interval - upper         0.092\n",
      "  P-value H_0: RMSEA <= 0.050                    0.000\n",
      "  P-value H_0: RMSEA >= 0.080                    0.554\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.073\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "  copingm =~                                          \n",
      "    x1                1.000                           \n",
      "    x2                0.741    0.093    7.925    0.000\n",
      "    x3                0.932    0.118    7.906    0.000\n",
      "    x4                0.699    0.117    5.995    0.000\n",
      "  socialm =~                                          \n",
      "    x4                1.000                           \n",
      "    x5                1.725    0.260    6.634    0.000\n",
      "    x6                2.098    0.305    6.879    0.000\n",
      "    x7                2.717    0.401    6.775    0.000\n",
      "    x8                2.619    0.382    6.848    0.000\n",
      "    x12               0.900    0.236    3.818    0.000\n",
      "  enhancem =~                                         \n",
      "    x9                1.000                           \n",
      "    x10               0.638    0.076    8.408    0.000\n",
      "    x11               0.767    0.094    8.153    0.000\n",
      "\n",
      "Covariances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "  copingm ~~                                          \n",
      "    socialm           0.410    0.072    5.663    0.000\n",
      "    enhancem          0.661    0.148    4.456    0.000\n",
      "  socialm ~~                                          \n",
      "    enhancem          0.347    0.089    3.902    0.000\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "   .x1                0.000    0.092    0.000    1.000\n",
      "   .x2                0.000    0.068    0.000    1.000\n",
      "   .x3                0.000    0.086    0.000    1.000\n",
      "   .x4                0.000    0.063    0.000    1.000\n",
      "   .x5                0.000    0.077    0.000    1.000\n",
      "   .x6                0.000    0.079    0.000    1.000\n",
      "   .x7                0.000    0.111    0.000    1.000\n",
      "   .x8                0.000    0.101    0.000    1.000\n",
      "   .x12               0.000    0.119    0.000    1.000\n",
      "   .x9                0.000    0.120    0.000    1.000\n",
      "   .x10               0.000    0.078    0.000    1.000\n",
      "   .x11               0.000    0.115    0.000    1.000\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "   .x1                3.106    0.230   13.478    0.000\n",
      "   .x2                1.686    0.125   13.449    0.000\n",
      "   .x3                2.698    0.200   13.477    0.000\n",
      "   .x4                0.463    0.069    6.719    0.000\n",
      "   .x5                1.805    0.130   13.886    0.000\n",
      "   .x6                1.378    0.115   12.022    0.000\n",
      "   .x7                3.255    0.248   13.143    0.000\n",
      "   .x8                2.418    0.194   12.455    0.000\n",
      "   .x12               6.740    0.430   15.673    0.000\n",
      "   .x9                3.891    0.436    8.933    0.000\n",
      "   .x10               1.724    0.183    9.435    0.000\n",
      "   .x11               4.662    0.371   12.579    0.000\n",
      "    copingm           1.129    0.218    5.170    0.000\n",
      "    socialm           0.397    0.111    3.566    0.000\n",
      "    enhancem          3.277    0.524    6.258    0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary(fit4, fit.measures = TRUE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae10aafe",
   "metadata": {},
   "source": [
    "È chiaro che il modello `model4` è inadeguato. Il problema emerge chiaramente anche esaminando i MI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68e8d86e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lhs op rhs      mi    epc sepc.lv sepc.all sepc.nox\n",
      "47   copingm =~  x5   0.090  0.036   0.038    0.022    0.022\n",
      "48   copingm =~  x6   0.554  0.090   0.096    0.054    0.054\n",
      "49   copingm =~  x7   0.107  0.055   0.059    0.024    0.024\n",
      "50   copingm =~  x8   3.919 -0.306  -0.325   -0.143   -0.143\n",
      "51   copingm =~ x12   6.109  0.499   0.530    0.199    0.199\n",
      "52   copingm =~  x9   0.390 -0.096  -0.102   -0.038   -0.038\n",
      "53   copingm =~ x10   0.027 -0.016  -0.017   -0.010   -0.010\n",
      "54   copingm =~ x11   0.823  0.123   0.131    0.051    0.051\n",
      "55   socialm =~  x1   1.990 -0.398  -0.251   -0.122   -0.122\n",
      "56   socialm =~  x2   0.638  0.166   0.105    0.069    0.069\n",
      "57   socialm =~  x3   0.372  0.160   0.101    0.053    0.053\n",
      "58   socialm =~  x9   0.315 -0.130  -0.082   -0.031   -0.031\n",
      "59   socialm =~ x10   1.423  0.179   0.113    0.064    0.064\n",
      "60   socialm =~ x11   0.520 -0.150  -0.094   -0.037   -0.037\n",
      "61  enhancem =~  x1   1.029  0.067   0.121    0.059    0.059\n",
      "62  enhancem =~  x2   0.232  0.023   0.042    0.028    0.028\n",
      "63  enhancem =~  x3   0.153 -0.024  -0.043   -0.023   -0.023\n",
      "64  enhancem =~  x4   0.745 -0.031  -0.056   -0.040   -0.040\n",
      "65  enhancem =~  x5   0.343 -0.028  -0.050   -0.029   -0.029\n",
      "66  enhancem =~  x6   0.103  0.015   0.027    0.015    0.015\n",
      "67  enhancem =~  x7   2.752 -0.110  -0.198   -0.080   -0.080\n",
      "68  enhancem =~  x8   0.129 -0.021  -0.038   -0.017   -0.017\n",
      "69  enhancem =~ x12 116.781  0.916   1.658    0.624    0.624\n",
      "70        x1 ~~  x2   1.709  0.177   0.177    0.077    0.077\n",
      "71        x1 ~~  x3   2.273 -0.257  -0.257   -0.089   -0.089\n",
      "72        x1 ~~  x4   0.850  0.103   0.103    0.086    0.086\n",
      "73        x1 ~~  x5   0.292 -0.064  -0.064   -0.027   -0.027\n",
      "74        x1 ~~  x6   0.188 -0.048  -0.048   -0.023   -0.023\n",
      "75        x1 ~~  x7   0.023 -0.025  -0.025   -0.008   -0.008\n",
      "76        x1 ~~  x8   0.419 -0.093  -0.093   -0.034   -0.034\n",
      "77        x1 ~~ x12   0.025 -0.034  -0.034   -0.007   -0.007\n",
      "78        x1 ~~  x9   0.011  0.020   0.020    0.006    0.006\n",
      "79        x1 ~~ x10   0.004  0.008   0.008    0.003    0.003\n",
      "80        x1 ~~ x11   1.804  0.259   0.259    0.068    0.068\n",
      "81        x2 ~~  x3   0.071 -0.034  -0.034   -0.016   -0.016\n",
      "82        x2 ~~  x4   2.979 -0.143  -0.143   -0.162   -0.162\n",
      "83        x2 ~~  x5   2.403  0.135   0.135    0.077    0.077\n",
      "84        x2 ~~  x6   0.551  0.060   0.060    0.040    0.040\n",
      "85        x2 ~~  x7   0.457 -0.081  -0.081   -0.035   -0.035\n",
      "86        x2 ~~  x8   0.012  0.011   0.011    0.006    0.006\n",
      "87        x2 ~~ x12   0.134 -0.058  -0.058   -0.017   -0.017\n",
      "88        x2 ~~  x9   1.033  0.145   0.145    0.056    0.056\n",
      "89        x2 ~~ x10   1.140 -0.100  -0.100   -0.058   -0.058\n",
      "90        x2 ~~ x11   0.323  0.081   0.081    0.029    0.029\n",
      "91        x3 ~~  x4   1.472  0.127   0.127    0.113    0.113\n",
      "92        x3 ~~  x5   0.140  0.041   0.041    0.019    0.019\n",
      "93        x3 ~~  x6   0.717  0.087   0.087    0.045    0.045\n",
      "94        x3 ~~  x7   0.317  0.086   0.086    0.029    0.029\n",
      "95        x3 ~~  x8   3.121 -0.237  -0.237   -0.093   -0.093\n",
      "96        x3 ~~ x12   0.001  0.006   0.006    0.001    0.001\n",
      "97        x3 ~~  x9   0.000  0.003   0.003    0.001    0.001\n",
      "98        x3 ~~ x10   4.165 -0.241  -0.241   -0.111   -0.111\n",
      "99        x3 ~~ x11   3.806  0.350   0.350    0.099    0.099\n",
      "100       x4 ~~  x5   0.316 -0.036  -0.036   -0.039   -0.039\n",
      "101       x4 ~~  x6   0.052 -0.015  -0.015   -0.019   -0.019\n",
      "102       x4 ~~  x7   1.182  0.099   0.099    0.081    0.081\n",
      "103       x4 ~~  x8   0.062 -0.021  -0.021   -0.020   -0.020\n",
      "104       x4 ~~ x12   0.033  0.020   0.020    0.011    0.011\n",
      "105       x4 ~~  x9   1.418 -0.115  -0.115   -0.086   -0.086\n",
      "106       x4 ~~ x10   0.914  0.061   0.061    0.068    0.068\n",
      "107       x4 ~~ x11   0.517 -0.068  -0.068   -0.047   -0.047\n",
      "108       x5 ~~  x6   0.611  0.073   0.073    0.046    0.046\n",
      "109       x5 ~~  x7   0.115 -0.045  -0.045   -0.019   -0.019\n",
      "110       x5 ~~  x8   0.079  0.034   0.034    0.016    0.016\n",
      "111       x5 ~~ x12   3.265 -0.302  -0.302   -0.087   -0.087\n",
      "112       x5 ~~  x9   0.203  0.066   0.066    0.025    0.025\n",
      "113       x5 ~~ x10   0.000  0.002   0.002    0.001    0.001\n",
      "114       x5 ~~ x11   2.312 -0.224  -0.224   -0.077   -0.077\n",
      "115       x6 ~~  x7   2.239 -0.200  -0.200   -0.094   -0.094\n",
      "116       x6 ~~  x8   0.073  0.033   0.033    0.018    0.018\n",
      "117       x6 ~~ x12   0.478  0.109   0.109    0.036    0.036\n",
      "118       x6 ~~  x9   1.251 -0.153  -0.153   -0.066   -0.066\n",
      "119       x6 ~~ x10   0.784  0.079   0.079    0.051    0.051\n",
      "120       x6 ~~ x11   0.370  0.083   0.083    0.033    0.033\n",
      "121       x7 ~~  x8   1.644  0.219   0.219    0.078    0.078\n",
      "122       x7 ~~ x12   0.433 -0.152  -0.152   -0.032   -0.032\n",
      "123       x7 ~~  x9   0.005 -0.015  -0.015   -0.004   -0.004\n",
      "124       x7 ~~ x10   1.836 -0.179  -0.179   -0.076   -0.076\n",
      "125       x7 ~~ x11   0.348 -0.119  -0.119   -0.031   -0.031\n",
      "126       x8 ~~ x12   2.680 -0.335  -0.335   -0.083   -0.083\n",
      "127       x8 ~~  x9   0.676  0.147   0.147    0.048    0.048\n",
      "128       x8 ~~ x10   0.337  0.068   0.068    0.033    0.033\n",
      "129       x8 ~~ x11   3.437 -0.330  -0.330   -0.098   -0.098\n",
      "130      x12 ~~  x9   7.051  0.713   0.713    0.139    0.139\n",
      "131      x12 ~~ x10   6.960  0.465   0.465    0.136    0.136\n",
      "132      x12 ~~ x11  68.717  2.238   2.238    0.399    0.399\n",
      "133       x9 ~~ x10   0.081  0.138   0.138    0.053    0.053\n",
      "134       x9 ~~ x11   0.166  0.209   0.209    0.049    0.049\n",
      "135      x10 ~~ x11   0.423 -0.211  -0.211   -0.075   -0.075\n"
     ]
    }
   ],
   "source": [
    "print(modindices(fit4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dc22bf1",
   "metadata": {},
   "source": [
    "Il MI relativo alla saturazione di `x12` su `enhancem` è uguale a 116.781. Chiaramente, in una revisione del modello, questo problema dovrebbe essere affrontato.\n",
    "\n",
    "## Commenti e considerazioni finali\n",
    "\n",
    "Gli esempi presentati da @brown2015confirmatory mostrano come l'applicazione dei MI, combinata con l'esame delle soluzioni fattoriali, rappresenti un approccio fondamentale per ottimizzare e perfezionare il modello proposto."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

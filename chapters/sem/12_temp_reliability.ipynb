{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affidabilità longitudinale {#sec-sem-longitudinal-reliability}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "**Concetti e Competenze Chiave**\n",
    "\n",
    "**Preparazione del Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "here::here(\"code\", \"_common.R\") |>\n",
    "    source()\n",
    "\n",
    "# Load packages\n",
    "if (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(semTools, lme4, tidyr, psych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione\n",
    "\n",
    "Nel @interrater-reliability abbiamo illustrato come calcolare l'affidabilità delle misure di un disegno longitudinale usando il framework della teoria della generalizzabilità. Questo capitolo affronta lo stesso problema usano i modelli di equazioni strutturali.\n",
    "\n",
    "Grazie ai progressi tecnologici, i metodi di raccolta dati longitudinali intensivi si sono sviluppati notevolmente. Tali dati possono ora essere raccolti in maniera meno invasiva, riducendo gli ostacoli per i partecipanti. Tradizionalmente, i dati longitudinali si caratterizzavano per un numero limitato di misurazioni ripetute con ampi intervalli temporali. Le nuove tecniche di raccolta dati, ad esempio tramite applicazioni per smartphone o tablet, hanno portato a dati con un maggior numero di occasioni di misurazione, vicine tra loro temporalmente. Questi dati longitudinali intensivi permettono di investigare la dinamica di processi variabili, come i cambiamenti quotidiani di vari stati psicologici. \n",
    "\n",
    "I dati raccolti con misure quotidiane presentano una struttura annidata, in quanto più occasioni di misurazione sono raggruppate all'interno della stessa persona. Attualmente, due tecniche sono comunemente impiegate per analizzare l'affidabilità con dati annidati: la teoria della generalizzabilità e l'approccio fattoriale. La teoria della generalizzabilità scompone la varianza totale in elementi di tempo, item e persona, valutando così l'affidabilità del cambiamento nel tempo a livello individuale. Nonostante i suoi vantaggi, questo approccio si basa su assunzioni che potrebbero non essere sempre verificate dai dati.\n",
    "\n",
    "L'approccio fattoriale è più flessibile e permette di modellare le associazioni degli item con il punteggio vero e le varianze degli errori. In particolare, l'analisi fattoriale confermativa multilivello (MCFA) viene utilizzata per ottenere elementi di varianza al fine di determinare l'affidabilità specifica per il tempo (a livello intra-individuale) e per la persona (a livello  inter-individuale). \n",
    "\n",
    "L'articolo di {cite:t}`van2022determining` descrive come sia possibile valutare l'affidabilità con dati longitudinali intensivi quotidiani. Nel loro tutorial, gli autori utilizzano dati empirici raccolti tramite una misura dello stress lavorativo quotidiano per insegnanti di scuola secondaria. Inoltre, {cite:t}`van2022determining` confrontano gli indici di affidabilità derivati dal metodo MCFA con quelli ottenuti tramite la teoria della generalizzabilità.\n",
    "\n",
    "## Affidabilità nei Modelli Fattoriali a Livello Singolo\n",
    "\n",
    "L'analisi fattoriale confermativa (CFA) è diventata lo standard per determinare la dimensionalità e l'affidabilità dei punteggi in psicologia. L'affidabilità, in dati con un singolo livello, può essere valutata mediante diversi indici. A differenza del coefficiente di consistenza interna $\\alpha$, l'indice $\\omega$ non assume che i diversi carichi fattoriali degli item contribuiscano equamente al costrutto latente.\n",
    "\n",
    "I valori di $\\omega$ variano da zero a uno, dove valori vicini a uno indicano una migliore affidabilità della scala. Il valore effettivo di $\\omega$ può essere interpretato come la proporzione di varianza nei punteggi della scala spiegata dalla variabile latente comune a tutti gli indicatori. \n",
    "\n",
    "L'affidabilità composita $\\omega$, per un costrutto misurato con $p$ item, è definita come:\n",
    "\n",
    "$$\n",
    "\\omega = \\frac{\\sum_{i=1}^{p} \\lambda_i^2 \\Phi}{\\sum_{i=1}^{p} \\lambda_i^2 \\Phi + \\sum_{i=1}^{p} \\theta_i},\n",
    "$$\n",
    "\n",
    "dove $i$ indica l'item, $\\lambda$ rappresenta un carico fattoriale, $\\Phi$ rappresenta la varianza del fattore, e $\\theta$ rappresenta la varianza residua dell'item. \n",
    "\n",
    "{cite:t}`van2022determining` propongono il seguente esempio. Consideriamo un modello unifattoriale in cui la varianza del fattore sia fissata a 1 per l'identificazione del modello, con saturazioni su tre indicatori pari a 0.7, 0.8 e 0.9. Le specificità saranno dunque 0.51, 0.36 e 0.19. Possiamo determinare l'affidabilità $\\omega$ della scala inserendo questi valori nell'equazione precedente, il che produce un'affidabilità di .84. \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\omega = \\frac{\\left(0.70 + 0.80 + 0.90\\right)^{2} 1}{\\left(0.70 + 0.80 + 0.90\\right)^{2} 1 + \\left(0.51 + 0.36 + 0.19\\right)}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Questo significa che l'84% della varianza totale nei punteggi della scala è spiegata dal fattore comune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affidabilità nei Modelli Fattoriali Multilivello\n",
    "\n",
    "Nella ricerca psicologica, i dati spesso presentano una struttura annidata, dove le unità di livello inferiore sono considerate annidate in unità di livello superiore. Ad esempio, gli studenti possono essere annidati nelle classi, o i pazienti negli ospedali. Con misure giornaliere degli individui su diversi giorni, le occasioni di misurazione sono annidate negli individui. Allo stesso modo, i dati empirici utilizzati nell'esempio presentato qui, sono raccolti dagli stessi insegnanti durante 15 occasioni di misurazione. Queste occasioni sono annidate all'interno di ciascun insegnante. L'analisi fattoriale multilivello consente modelli diversi per varianze e covarianze delle differenze intra-individuali e inter-individuali (Muthén, 1994). Nell'esempio discusso, {cite:t}`van2022determining` si concentrano su strutture con due livelli, costituiti da occasioni (Livello 1, o il livello interno) all'interno di individui (Livello 2, o il livello esterno).\n",
    "\n",
    "La Fig.{ref}`vanalphen-fig` fornisce una rappresentazione grafica di un modello fattoriale multilivello. In tale analisi fattoriale confermativa (CFA) a due livelli, i punteggi degli item sono decomposti in componenti (latenti) a livello interno ed esterno. La parte a livello esterno modella la struttura di covarianza a livello inter-individuale, spiegando le differenze tra gli individui. L'interpretazione di questa parte del modello è paragonabile a una CFA ad un singolo livello. La parte a livello interno modella la struttura di covarianza a livello delle occasioni di misurazione, spiegando le differenze all'interno degli individui tra i diversi punti temporali. In questo esempio, il livello dell'occasione è rappresentativo delle caratteristiche di stato degli individui, perché mostra i cambiamenti giornalieri delle condizioni degli individui. Il livello inter-individuale, quindi, si riferisce alle caratteristiche di tratto degli individui, poiché tali misure sono un aggregato delle misure giornaliere e rappresentano una misura più stabile (cioè, a lungo termine), simile a una misura della personalità.\n",
    "\n",
    "::: {#fig-like-se}\n",
    "![](../../figures/vanalphen_fig2.png){width=\"80%\"}\n",
    "\n",
    "Un modello configurale multilivello con i carichi fattoriali, varianze residuali e varianza del fattoriali dell'esempio discusso da @van2022determining.  (Figura tratta da @van2022determining)\n",
    ":::\n",
    "\n",
    "Geldhof et al. (2014) hanno esteso il metodo esistente per determinare ω a modelli a due livelli, risultando in indici di affidabilità a livello interno (ωw) e a livello esterno (ωb). Questo approccio è stato è stato poi sviluppato da Lai (2021). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo dell'Affidabilità della Scala con Dati Giornalieri\n",
    "\n",
    "@van2022determining considerano un dataset che include misure longitudinali intensive giornaliere sullo stress degli insegnanti. In questo contesto, il fattore comune a livello esterno può essere interpretato come la componente stabile del fattore stress, mentre il fattore comune a livello interno rappresenta la parte variabile nel tempo del fattore stress. Quando ci si concentra sulle componenti a livello interno ed esterno dello stesso fattore, il modello fattoriale multilivello è conosciuto come modello configurale (Stapleton et al., 2016). \n",
    "\n",
    "Nel modello fattoriale configurale multilivello, i fattori a livello interno ed esterno riflettono le componenti interne ed esterne della stessa variabile latente. Di conseguenza, la struttura fattoriale è la stessa per entrambi i livelli e i carichi fattoriali sono uguali tra i livelli (Asparouhov & Muthen, 2012). Lai (2021) ha fornito equazioni per calcolare stime di affidabilità a livello interno (ωw) ed esterno (ωb), specificamente per questi modelli configurali. @van2022determining forniscono un esempio di calcolo per entrambi questi indici di affidabilità.\n",
    "\n",
    "La seguente equazione viene utilizzata per determinare l'affidabilità a livello interno in un modello configurale:\n",
    "\n",
    "$$ \n",
    "\\omega_w = \\frac{\\sum (\\lambda_i^2 \\Phi_w)}{\\sum (\\lambda_i^2 \\Phi_w) + \\sum (\\theta_w)},\n",
    "$$\n",
    "\n",
    "dove il pedice $w$ si riferisce al livello interno. Si noti che i carichi fattoriali ($\\lambda$) non hanno un pedice specifico di livello perché sono vincolati ad essere uguali tra i livelli. \n",
    "\n",
    "Confrontando questa equazione omega al livello interno (2) con l'equazione utilizzata per determinare l'affidabilità utilizzando una CFA ad un livello singolo, si vede che la varianza fattoriale a livello interno ($\\Phi_w$) viene utilizzata al posto della varianza totale ($\\Phi$). In questo contesto multilivello, $\\theta_w$ rappresenta la varianza residua solo al livello interno. \n",
    "\n",
    "Inserendo i nostri valori esemplificativi della @vanalphen-fig nell'Equazione precedente si ottiene un'affidabilità a livello interno di 0.84. Ciò significa che il fattore comune a livello interno spiega l'84% della varianza totale nei punteggi di deviazione della scala a livello interno:\n",
    "\n",
    "$$ \n",
    "\\omega_w = \\frac{(0.70 + 0.80 + 0.90)^2}{(0.70 + 0.80 + 0.90)^2 + (0.51 + 0.36 + 0.19)} = 0.84. \n",
    "$$\n",
    "\n",
    "Con il pedice $b$ che si riferisce al livello esterno, l'equazione per l'affidabilità a livello esterno in un modello configurale diventa quindi:\n",
    "\n",
    "$$ \n",
    "\\omega_b = \\frac{\\sum (\\lambda_i^2 \\Phi_b)}{\\sum (\\lambda_i^2 (\\Phi_b + \\Phi_w/n)) + \\sum (\\theta_b + \\theta_w/n)},\n",
    "$$\n",
    "\n",
    "dove $n$ è il numero di misurazioni. In questa equazione, la varianza dell'errore di campionamento delle medie osservate a livello di persona viene aggiunta al denominatore aggiungendo $\\Phi_w/n$ e $\\Sigma \\theta_w/n$. Nel nostro esempio, useremo $n = 15$. Nel contesto di misure longitudinali, ciò significa che i dati sono stati raccolti in 15 occasioni. Inserendo i valori esemplificativi di @van2022determining, l'affidabilità a livello esterno è 0.90, indicando che il fattore comune a livello esterno spiega il 90% della varianza totale nelle medie osservate a livello di persona dei punteggi della scala:\n",
    "\n",
    "$$ \n",
    "\\omega_b = \\frac{(0.70 + 0.80 + 0.90)^2}{(0.70 + 0.80 + 0.90)^2(0.90 + 1/15) + (0.05 + 0.05 + 0.05) + ((0.51 + 0.36 + 0.19)/15)} = 0.90. \n",
    "$$\n",
    "\n",
    "Queste equazioni forniscono un metodo per valutare l'affidabilità delle componenti a livello interno ed esterno di una scala in studi longitudinali intensivi, consentendo ai ricercatori di distinguere tra variazioni stabili e temporanee all'interno dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto con la Teoria della Generalizzabilità\n",
    "\n",
    "@van2022determining hanno anche derivato le componenti di varianza per il calcolo del punteggio di affidabilità a livello interno e a livello esterno utilizzando la teoria della generalizzabilità. Per questi dati, @van2022determining trovano che la stima dell'affidabilità a livello interno è .87, molto simile alla stima ottenuta con l'approccio CFA multilivello. Tuttavia, la stima a livello esterno ottenuta con il metodo della generalizzabilità è 0.99, che è .11 più alta rispetto all'approccio analitico fattoriale. Questa differenza potrebbe essere causata dalle assunzioni più rigide fatte dal metodo della teoria della generalizzabilità. Tuttavia, @van2022determining notano che questi risultati sono specifici al dataset utilizzato e sarebbe necessario uno studio di simulazione per valutare, in generale, quali sono le differenze sistematiche tra le stime di affidabilità ottenute con i due diversi metodi.\n",
    "\n",
    "Qui sotto viene presentato il metodo SEM per il calcolo dell'affidabilità inter- e intra-persona usando gli script R forniti da @van2022determining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 x 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>day</th><th scope=col>school</th><th scope=col>ID</th><th scope=col>str1</th><th scope=col>str2</th><th scope=col>str3</th><th scope=col>str4</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td><ef><bb><bf>1</td><td>1</td><td> 1</td><td>26</td><td>NA</td><td>24</td><td>78</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1            </td><td>1</td><td>30</td><td>NA</td><td>24</td><td>24</td><td>50</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1            </td><td>1</td><td>55</td><td>NA</td><td>36</td><td>70</td><td>72</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1            </td><td>1</td><td>92</td><td>NA</td><td>37</td><td>34</td><td>41</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1            </td><td>2</td><td>20</td><td>24</td><td>NA</td><td>24</td><td>36</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1            </td><td>2</td><td>22</td><td>12</td><td>NA</td><td>18</td><td>39</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 x 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & day & school & ID & str1 & str2 & str3 & str4\\\\\n",
       "  & <chr> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & <ef><bb><bf>1 & 1 &  1 & 26 & NA & 24 & 78\\\\\n",
       "\t2 & 1             & 1 & 30 & NA & 24 & 24 & 50\\\\\n",
       "\t3 & 1             & 1 & 55 & NA & 36 & 70 & 72\\\\\n",
       "\t4 & 1             & 1 & 92 & NA & 37 & 34 & 41\\\\\n",
       "\t5 & 1             & 2 & 20 & 24 & NA & 24 & 36\\\\\n",
       "\t6 & 1             & 2 & 22 & 12 & NA & 18 & 39\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 x 7\n",
       "\n",
       "| <!--/--> | day &lt;chr&gt; | school &lt;int&gt; | ID &lt;int&gt; | str1 &lt;int&gt; | str2 &lt;int&gt; | str3 &lt;int&gt; | str4 &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | <ef><bb><bf>1 | 1 |  1 | 26 | NA | 24 | 78 |\n",
       "| 2 | 1             | 1 | 30 | NA | 24 | 24 | 50 |\n",
       "| 3 | 1             | 1 | 55 | NA | 36 | 70 | 72 |\n",
       "| 4 | 1             | 1 | 92 | NA | 37 | 34 | 41 |\n",
       "| 5 | 1             | 2 | 20 | 24 | NA | 24 | 36 |\n",
       "| 6 | 1             | 2 | 22 | 12 | NA | 18 | 39 |\n",
       "\n"
      ],
      "text/plain": [
       "  day           school ID str1 str2 str3 str4\n",
       "1 \\357\\273\\2771 1       1 26   NA   24   78  \n",
       "2 1             1      30 NA   24   24   50  \n",
       "3 1             1      55 NA   36   70   72  \n",
       "4 1             1      92 NA   37   34   41  \n",
       "5 1             2      20 24   NA   24   36  \n",
       "6 1             2      22 12   NA   18   39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "van_alphen <- read.table(\"../../data/data_van_alphen.dat\", na.strings = \"9999\")\n",
    "colnames(van_alphen) <- c(\"day\", \"school\", \"ID\", \"str1\", \"str2\", \"str3\", \"str4\")\n",
    "van_alphen |> head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 x 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>day</th><th scope=col>school</th><th scope=col>ID</th><th scope=col>str1</th><th scope=col>str2</th><th scope=col>str3</th><th scope=col>str4</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1264</th><td>15</td><td>6</td><td> 62</td><td>NA</td><td>66</td><td>57</td><td>61</td></tr>\n",
       "\t<tr><th scope=row>1265</th><td>15</td><td>6</td><td> 87</td><td>NA</td><td>42</td><td>59</td><td>83</td></tr>\n",
       "\t<tr><th scope=row>1266</th><td>15</td><td>6</td><td>115</td><td>53</td><td>NA</td><td>53</td><td>45</td></tr>\n",
       "\t<tr><th scope=row>1267</th><td>15</td><td>6</td><td>118</td><td>NA</td><td>16</td><td>32</td><td>16</td></tr>\n",
       "\t<tr><th scope=row>1268</th><td>15</td><td>6</td><td>123</td><td>23</td><td>22</td><td>23</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>1269</th><td>15</td><td>6</td><td>143</td><td>64</td><td>64</td><td>65</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 x 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & day & school & ID & str1 & str2 & str3 & str4\\\\\n",
       "  & <chr> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1264 & 15 & 6 &  62 & NA & 66 & 57 & 61\\\\\n",
       "\t1265 & 15 & 6 &  87 & NA & 42 & 59 & 83\\\\\n",
       "\t1266 & 15 & 6 & 115 & 53 & NA & 53 & 45\\\\\n",
       "\t1267 & 15 & 6 & 118 & NA & 16 & 32 & 16\\\\\n",
       "\t1268 & 15 & 6 & 123 & 23 & 22 & 23 & NA\\\\\n",
       "\t1269 & 15 & 6 & 143 & 64 & 64 & 65 & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 x 7\n",
       "\n",
       "| <!--/--> | day &lt;chr&gt; | school &lt;int&gt; | ID &lt;int&gt; | str1 &lt;int&gt; | str2 &lt;int&gt; | str3 &lt;int&gt; | str4 &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1264 | 15 | 6 |  62 | NA | 66 | 57 | 61 |\n",
       "| 1265 | 15 | 6 |  87 | NA | 42 | 59 | 83 |\n",
       "| 1266 | 15 | 6 | 115 | 53 | NA | 53 | 45 |\n",
       "| 1267 | 15 | 6 | 118 | NA | 16 | 32 | 16 |\n",
       "| 1268 | 15 | 6 | 123 | 23 | 22 | 23 | NA |\n",
       "| 1269 | 15 | 6 | 143 | 64 | 64 | 65 | NA |\n",
       "\n"
      ],
      "text/plain": [
       "     day school ID  str1 str2 str3 str4\n",
       "1264 15  6       62 NA   66   57   61  \n",
       "1265 15  6       87 NA   42   59   83  \n",
       "1266 15  6      115 53   NA   53   45  \n",
       "1267 15  6      118 NA   16   32   16  \n",
       "1268 15  6      123 23   22   23   NA  \n",
       "1269 15  6      143 64   64   65   NA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "van_alphen |> tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Step 5: calculating reliability indices\n",
    "\n",
    "model5 <- \"\n",
    "        level: 1\n",
    "            stress =~ L1*str1 + L2*str2 + L3*str3 + L4*str4\n",
    "            stress ~~ 1*stress\n",
    "\n",
    "            str1 ~~ tw1*str1\n",
    "            str2 ~~ tw2*str2\n",
    "            str3 ~~ tw3*str3\n",
    "            str4 ~~ tw4*str4\n",
    "\n",
    "        level: 2\n",
    "            stress =~ L1*str1 + L2*str2 + L3*str3 + L4*str4\n",
    "            stress ~~ fb*stress\n",
    "\n",
    "            str1 ~~ tb1*str1\n",
    "            str2 ~~ tb2*str2\n",
    "            str3 ~~ tb3*str3\n",
    "            str4 ~~ tb4*str4\n",
    "\n",
    "          # means\n",
    "            str1 + str2 + str3 + str4  ~ 1\n",
    "\n",
    "          # reliability calculations\n",
    "          lambda := L1 + L2 + L3 + L4\n",
    "          thetaw := tw1 + tw2 + tw3 + tw4\n",
    "          thetab := tb1 + tb2 + tb3 + tb4\n",
    "          omega_w := lambda^2 / (lambda^2 + thetaw)\n",
    "          omega_b := (lambda^2 * fb) / (lambda^2 * (1 / 15 + fb) + thetab + thetaw / 15)\n",
    "    \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"lavaan->lav_data_full():  \n",
      "   Level-1 variable \"str1\" has no variance within some clusters . The cluster \n",
      "   ids with zero within variance are: 124, 19, 47, 66, 88, 138, 94.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_data_full():  \n",
      "   Level-1 variable \"str2\" has no variance within some clusters . The cluster \n",
      "   ids with zero within variance are: 124, 83, 90, 19, 47, 66, 27, 51, 61, \n",
      "   106, 9, 53, 93, 94, 111.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_data_full():  \n",
      "   Level-1 variable \"str3\" has no variance within some clusters . The cluster \n",
      "   ids with zero within variance are: 124, 19, 47, 66, 94.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_data_full():  \n",
      "   Level-1 variable \"str4\" has no variance within some clusters . The cluster \n",
      "   ids with zero within variance are: 19, 47, 136, 94, 147, 135.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_data_full():  \n",
      "   some cases are empty and will be ignored: 48 98 189 199 348 577 660 793 \n",
      "   948 950 959 1001 1025 1207.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step11_estoptim():  \n",
      "   Model estimation FAILED! Returning starting values.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step11_estoptim():  \n",
      "   Model estimation FAILED! Returning starting values.\"\n",
      "Warning message:\n",
      "\"lavaan->lav_lavaan_step15_baseline():  \n",
      "   estimation of the baseline model failed.\"\n"
     ]
    }
   ],
   "source": [
    "fit.step5 <- lavaan(\n",
    "    model = model5, \n",
    "    data = van_alphen, \n",
    "    cluster = \"ID\",\n",
    "    auto.var = TRUE,\n",
    "    missing = \"fiml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-18 did not run (perhaps do.fit = FALSE)?\n",
      "** WARNING ** Estimates below are simply the starting values\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        21\n",
      "  Number of equality constraints                     4\n",
      "\n",
      "                                                  Used       Total\n",
      "  Number of observations                          1255        1269\n",
      "  Number of clusters [ID]                          151            \n",
      "  Number of missing patterns -- level 1              3            \n",
      "\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Observed\n",
      "  Observed information based on                Hessian\n",
      "\n",
      "\n",
      "Level 1 [within]:\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "  stress =~                                           \n",
      "    str1      (L1)    1.000       NA                  \n",
      "    str2      (L2)    0.814       NA                  \n",
      "    str3      (L3)    0.928       NA                  \n",
      "    str4      (L4)    0.889       NA                  \n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "    stress            1.000                           \n",
      "   .str1     (tw1)  434.798       NA                  \n",
      "   .str2     (tw2)  361.343       NA                  \n",
      "   .str3     (tw3)  415.584       NA                  \n",
      "   .str4     (tw4)  431.975       NA                  \n",
      "\n",
      "\n",
      "Level 2 [ID]:\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "  stress =~                                           \n",
      "    str1      (L1)    1.000       NA                  \n",
      "    str2      (L2)    0.814       NA                  \n",
      "    str3      (L3)    0.928       NA                  \n",
      "    str4      (L4)    0.889       NA                  \n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "   .str1             33.658       NA                  \n",
      "   .str2             26.361       NA                  \n",
      "   .str3             34.638       NA                  \n",
      "   .str4             34.939       NA                  \n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "    stress    (fb)    0.050       NA                  \n",
      "   .str1     (tb1)  434.798       NA                  \n",
      "   .str2     (tb2)  361.343       NA                  \n",
      "   .str3     (tb3)  415.584       NA                  \n",
      "   .str4     (tb4)  431.975       NA                  \n",
      "\n",
      "Defined Parameters:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)\n",
      "    lambda            3.631                           \n",
      "    thetaw         1643.701                           \n",
      "    thetab         1643.701                           \n",
      "    omega_w           0.008                           \n",
      "    omega_b           0.000                           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary(fit.step5) |> print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informazioni sull'Ambiente di Sviluppo {.unnumbered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 4.4.1 (2024-06-14)\n",
       "Platform: aarch64-apple-darwin20\n",
       "Running under: macOS 15.0\n",
       "\n",
       "Matrix products: default\n",
       "BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n",
       "LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n",
       "\n",
       "locale:\n",
       "[1] C\n",
       "\n",
       "time zone: Europe/Rome\n",
       "tzcode source: internal\n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "other attached packages:\n",
       " [1] lme4_1.1-35.5     Matrix_1.7-0      ggokabeito_0.1.0  viridis_0.6.5    \n",
       " [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n",
       " [9] patchwork_1.3.0   bayesplot_1.11.1  semTools_0.5-6    semPlot_1.1.6    \n",
       "[13] lavaan_0.6-18     psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n",
       "[17] knitr_1.48        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n",
       "[21] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n",
       "[25] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   here_1.0.1       \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       "  [1] rstudioapi_0.16.0  jsonlite_1.8.9     magrittr_2.0.3    \n",
       "  [4] TH.data_1.1-2      estimability_1.5.1 farver_2.1.2      \n",
       "  [7] nloptr_2.1.1       rmarkdown_2.28     vctrs_0.6.5       \n",
       " [10] minqa_1.2.8        base64enc_0.1-3    rstatix_0.7.2     \n",
       " [13] htmltools_0.5.8.1  broom_1.0.6        Formula_1.2-5     \n",
       " [16] htmlwidgets_1.6.4  plyr_1.8.9         sandwich_3.1-1    \n",
       " [19] emmeans_1.10.4     zoo_1.8-12         uuid_1.2-1        \n",
       " [22] igraph_2.0.3       mime_0.12          lifecycle_1.0.4   \n",
       " [25] pkgconfig_2.0.3    R6_2.5.1           fastmap_1.2.0     \n",
       " [28] shiny_1.9.1        digest_0.6.37      OpenMx_2.21.12    \n",
       " [31] fdrtool_1.2.18     colorspace_2.1-1   rprojroot_2.0.4   \n",
       " [34] Hmisc_5.1-3        fansi_1.0.6        timechange_0.3.0  \n",
       " [37] abind_1.4-8        compiler_4.4.1     withr_3.0.1       \n",
       " [40] glasso_1.11        htmlTable_2.4.3    backports_1.5.0   \n",
       " [43] carData_3.0-5      ggsignif_0.6.4     MASS_7.3-61       \n",
       " [46] corpcor_1.6.10     gtools_3.9.5       tools_4.4.1       \n",
       " [49] pbivnorm_0.6.0     foreign_0.8-87     zip_2.3.1         \n",
       " [52] httpuv_1.6.15      nnet_7.3-19        glue_1.7.0        \n",
       " [55] quadprog_1.5-8     promises_1.3.0     nlme_3.1-166      \n",
       " [58] lisrelToR_0.3      grid_4.4.1         pbdZMQ_0.3-13     \n",
       " [61] checkmate_2.3.2    cluster_2.1.6      reshape2_1.4.4    \n",
       " [64] generics_0.1.3     gtable_0.3.5       tzdb_0.4.0        \n",
       " [67] data.table_1.16.0  hms_1.1.3          car_3.1-2         \n",
       " [70] utf8_1.2.4         sem_3.1-16         pillar_1.9.0      \n",
       " [73] IRdisplay_1.1      rockchalk_1.8.157  later_1.3.2       \n",
       " [76] splines_4.4.1      lattice_0.22-6     survival_3.7-0    \n",
       " [79] kutils_1.73        tidyselect_1.2.1   miniUI_0.1.1.1    \n",
       " [82] pbapply_1.7-2      stats4_4.4.1       xfun_0.47         \n",
       " [85] qgraph_1.9.8       arm_1.14-4         stringi_1.8.4     \n",
       " [88] pacman_0.5.1       boot_1.3-31        evaluate_1.0.0    \n",
       " [91] codetools_0.2-20   mi_1.1             cli_3.6.3         \n",
       " [94] RcppParallel_5.1.9 IRkernel_1.3.2     rpart_4.1.23      \n",
       " [97] xtable_1.8-4       repr_1.1.7         munsell_0.5.1     \n",
       "[100] Rcpp_1.0.13        coda_0.19-4.1      png_0.1-8         \n",
       "[103] XML_3.99-0.17      parallel_4.4.1     jpeg_0.1-10       \n",
       "[106] mvtnorm_1.3-1      openxlsx_4.2.7.1   crayon_1.5.3      \n",
       "[109] rlang_1.1.4        multcomp_1.4-26    mnormt_2.1.1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionInfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi della Scala di Mokken {#sec-mokken}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "**Concetti e Competenze Chiave**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione\n",
    "\n",
    "L'Analisi delle Scale Mokken (MSA), così chiamata in onore del matematico e scienziato politico olandese Robert J. Mokken, è un insieme di metodi basati sulla Teoria Non Parametrica della Risposta agli Item (NIRT) che consente di valutare l'adeguatezza dei dati rispetto ai modelli non parametrici. Nella Teoria della Risposta agli Item (IRT), i costrutti psicologici sono considerati latenti, cioè non direttamente osservabili, ma si manifestano attraverso le risposte ai test. Le risposte degli individui agli item di un test riflettono la loro posizione su un continuum latente e indicano il grado in cui possiedono il costrutto oggetto di misurazione.\n",
    "\n",
    "Tuttavia, la relazione tra gli item di un test e le risposte dei partecipanti non sempre rappresenta fedelmente il costrutto in questione. I modelli della IRT offrono strumenti per esaminare la congruenza e la rilevanza degli item rispetto alla variabile latente sottostante. I modelli della MSA, in particolare, sono modelli probabilistici non parametrici basati su tratti latenti e giocano un ruolo fondamentale nella validazione degli strumenti psicometrici, ordinando sia i rispondenti che gli item lungo una scala ordinale. Applicabili sia a item dicotomici che politomici, i modelli MSA sono meno restrittivi rispetto ai modelli IRT parametrici, in quanto non assumono una forma specifica per la funzione di risposta agli item. Questa flessibilità rende i modelli MSA strumenti preziosi, pur comportando alcune limitazioni interpretative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling di Guttman \n",
    "\n",
    "La MSA trova le sue radici nello scaling di Guttman, sviluppato nel 1950 da Louis Guttman. Questo metodo, originariamente concepito per item dicotomici, mira a estrarre una singola dimensione dai dati, posizionando sia le persone che gli item su questa dimensione tramite valori numerici. Ad esempio, consideriamo cinque item di un test psicologico e cinque rispondenti ipotetici, A, B, C, D ed E, che rispondono a questi item. Le risposte vengono rappresentate in una tabella dove 1 indica una risposta corretta e 0 una errata.\n",
    "\n",
    "| Items | Esaminati | 1 | 2 | 3 | 4 | 5 |\n",
    "|-------|-----------|---|---|---|---|---|\n",
    "|       | A         | 1 | 1 | 1 | 1 | 1 |\n",
    "|       | B         | 1 | 1 | 1 | 1 | 0 |\n",
    "|       | C         | 1 | 1 | 1 | 0 | 0 |\n",
    "|       | D         | 1 | 1 | 0 | 0 | 0 |\n",
    "|       | E         | 1 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "In questa tabella, che rappresenta una scala di Guttman, gli item sono ordinati dal più facile al più difficile, e i rispondenti dall'abilità maggiore a quella minore. Si presume che un rispondente che ha risposto correttamente ad un item di difficoltà superiore abbia risposto correttamente anche a tutti gli item di difficoltà inferiore. Le deviazioni da questo modello sono considerate \"errori di Guttman\".\n",
    "\n",
    "La scala di Guttman, basandosi su un principio deterministico, non riesce sempre a catturare pienamente la complessità dei dati reali. Tuttavia, offre una rappresentazione chiara della relazione cumulativa o gerarchica tra gli item di un test e le abilità dei rispondenti. Questo modello suggerisce che, se una persona dimostra una competenza specifica, si presume che possieda anche tutte le competenze di base correlate.\n",
    "\n",
    "Tuttavia, quando emergono eccezioni a questa regola, ossia risposte corrette a item difficili ma errate a quelli più semplici, si potrebbe dedurre che il test richieda competenze multiple e non unicamente riconducibili a una dimensione unica. Questo fenomeno mette in luce la complessità e la multidimensionalità delle competenze umane.\n",
    "\n",
    "In conclusione, la MSA si adatta particolarmente a contesti dove i processi di risposta non sono completamente chiari (come quando la prestazione dipende da una struttura multidimensionale di abilità), consentendo di verificare se le risposte dei partecipanti rispettino i requisiti del modello e di ordinare persone e item su una scala ordinale, basandosi sui punteggi totali grezzi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi della Scala di Mokken\n",
    "\n",
    "L'Analisi delle Scale di Mokken (MSA) si basa sul modello di Guttman, ma introduce una prospettiva probabilistica che supera le limitazioni del modello deterministico originale. Il modello di Guttman si fonda sul principio di perfetta cumulatività, secondo cui un rispondente che risponde correttamente a un item più difficile dovrebbe rispondere correttamente anche a tutti gli item più semplici. Questo approccio si è dimostrato spesso troppo rigido per rappresentare fedelmente i dati empirici, che riflettono la complessità delle abilità umane e l’influenza di variabili esterne.\n",
    "\n",
    "La MSA consente una maggiore flessibilità nella gestione delle risposte ai test, permettendo alcune violazioni delle regole di cumulatività del modello di Guttman. In questo modo, la MSA risulta essere più adattabile ai dati reali, poiché accoglie la possibilità che i soggetti, pur mostrando un certo livello di abilità, possano occasionalmente rispondere in modo imprevisto agli item più semplici. L’approccio probabilistico della MSA, condiviso con il modello di Rasch, è meno restrittivo e più aderente ai dati empirici, rendendolo particolarmente utile per l'analisi di scale unidimensionali e la misurazione di variabili latenti con un numero limitato di item.\n",
    "\n",
    "## Assunzioni dell'Analisi delle Scale di Mokken (MSA)\n",
    "\n",
    "L'MSA, pur essendo non parametrica, condivide alcune assunzioni fondamentali con la Teoria Parametrica della Risposta agli Item (IRT). Tuttavia, l'MSA applica queste assunzioni in modo meno restrittivo, adattandole a un contesto non parametrico. Di seguito, vengono descritte le principali assunzioni della MSA.\n",
    "\n",
    "### 1. Unidimensionalità\n",
    "\n",
    "L'assunzione di unidimensionalità richiede che le risposte agli item possano essere spiegate da un singolo tratto latente (unidimensionale). Ciò implica che tutti gli item di una scala misurino lo stesso costrutto psicologico. Questo fattore latente rappresenta la variabile sottostante non osservabile che governa le risposte. Nella pratica, è preferibile costruire strumenti che misurano un tratto alla volta, poiché ciò semplifica l'interpretazione dei punteggi e riduce la complessità delle analisi statistiche.\n",
    "\n",
    "### 2. Indipendenza Locale\n",
    "\n",
    "L'indipendenza locale presuppone che, dato un livello fisso del tratto latente, le risposte agli item siano condizionalmente indipendenti. In altre parole, una volta considerato il tratto latente, la risposta a un determinato item non dovrebbe influenzare le risposte agli altri item. La probabilità che un individuo risponda correttamente a un item, dato il tratto latente , può essere formalizzata come segue:\n",
    "\n",
    "$$\n",
    "P(X = x | \\theta) = \\prod_{i=1}^k P(X_i = x_i \\mid \\theta).\n",
    "$$\n",
    "\n",
    "Questa assunzione implica che, una volta fissato $\\theta$, la covarianza tra due item qualsiasi dovrebbe essere pari a zero. Tuttavia, se il tratto latente varia, gli item saranno correlati poiché riflettono lo stesso fattore sottostante, generando una covarianza positiva.\n",
    "\n",
    "### 3. Monotonicità Latente\n",
    "\n",
    "La monotonicità latente richiede che, all'aumentare del tratto latente , la probabilità di rispondere correttamente a un item aumenti. Questa assunzione è valida sia per item dicotomici (giusto/sbagliato) sia per item politomici (ad esempio, scale Likert), in cui si esamina la probabilità di selezionare una categoria di risposta più alta man mano che il livello del tratto latente cresce:\n",
    "\n",
    "$$\n",
    "P_i(\\theta_a) \\leq P_i(\\theta_b) \\quad \\text{per} \\quad \\theta_a \\leq \\theta_b.\n",
    "$$\n",
    "\n",
    "In pratica, ciò implica che, con l'aumento del tratto latente, la probabilità di rispondere correttamente o di scegliere una risposta più elevata su una scala ordinale aumenta o rimane costante.\n",
    "\n",
    "#### Metodi per Verificare la Monotonicità\n",
    "\n",
    "La monotonicità può essere verificata mediante l'analisi dei restscore, che rappresenta il punteggio totale di un soggetto su tutti gli item, escluso quello in esame. Ad esempio, se il test ha 10 item e si analizza il comportamento dell'item 10, il restscore sarà calcolato sulla base dei primi 9 item. Questo punteggio è confrontato con la probabilità di rispondere correttamente a ciascun item. In un modello monotono, la probabilità di risposta corretta dovrebbe aumentare all'aumentare del restscore.\n",
    "\n",
    "Se i gruppi di restscore sono troppo piccoli per fornire stime affidabili, essi possono essere aggregati in gruppi più ampi per migliorare la precisione. L'analisi grafica delle Funzioni di Risposta agli Item (IRF) può essere utilizzata per rappresentare visivamente come varia la probabilità di rispondere correttamente in funzione del livello del tratto latente.\n",
    "\n",
    "#### Monotonicità e Coefficienti di Scalabilità\n",
    "\n",
    "Nell'MSA, la monotonicità è valutata anche attraverso i *coefficienti di scalabilità* ($H_i$ per singoli item e $H_{ij}$ per coppie di item). Per garantire la validità del Modello di Omogeneità Monotona (MHM), le covarianze tra tutte le coppie di item ($H_{ij}$) devono essere non negative. Tuttavia, la non negatività dei coefficienti di scalabilità non garantisce necessariamente che le IRF siano monotone. In pratica, item con valori di $H_i$ superiori a 0.30 sono considerati accettabili.\n",
    "\n",
    "### 4. Non-Intersezione delle Funzioni di Risposta\n",
    "\n",
    "L'assunzione di non-intersezione delle funzioni di risposta (IRF) prevede che le probabilità di successo su item più difficili non superino mai quelle relative a item più facili, per ogni livello del tratto latente. In altre parole, le IRF devono essere ordinate in modo che la probabilità di rispondere correttamente a un item più difficile sia sempre inferiore o uguale rispetto a un item meno difficile. Formalmente, questa proprietà può essere espressa come:\n",
    "\n",
    "$$\n",
    "P_1(\\theta) \\leq P_2(\\theta) \\leq ... \\leq P_k(\\theta) \\quad \\text{per ogni} \\ \\theta\n",
    "$$\n",
    "\n",
    "L'intersezione delle IRF comporterebbe una violazione dell'ordinamento degli item, il che renderebbe difficile interpretare i risultati della scala.\n",
    "\n",
    "---\n",
    "\n",
    "In sintesi, l'Analisi delle Scale di Mokken si basa su assunzioni chiave simili a quelle dell'IRT, ma le implementa in un contesto non parametrico. La verifica di queste assunzioni garantisce la validità delle scale costruite e la corretta interpretazione dei risultati, rendendo l'MSA uno strumento potente per la costruzione di scale psicometriche robuste.\n",
    "\n",
    "\n",
    "## Modelli della Mokken Scale Analysis\n",
    "\n",
    "Dalle suddette assunzioni derivano due modelli della Mokken Scale Analysis:\n",
    "\n",
    "1. **Modello di Monotonicità Omogenea** (Mokken, 1971): rispetta le prime tre assunzioni (unidimensionalità, indipendenza locale e monotonicità latente). Questo modello permette di ordinare i rispondenti in base al tratto latente.\n",
    "  \n",
    "2. **Modello di Doppia Monotonicità**: rispetta tutte e quattro le assunzioni (unidimensionalità, indipendenza locale, monotonicità latente e non-intersezione). Consente di ordinare non solo i rispondenti, ma anche gli item in termini di difficoltà.\n",
    "\n",
    "In conclusione, la MSA rappresenta un'evoluzione metodologica significativa rispetto allo scaling di Guttman, offrendo un approccio meno restrittivo e più adatto all'analisi dei dati empirici. Fornisce un quadro analitico efficace per l'indagine dettagliata delle risposte agli item e delle abilità dei rispondenti in contesti psicologici.\n",
    "\n",
    "## Coefficienti di Scalabilità\n",
    "\n",
    "Per verificare le assunzioni dei modelli di monotonicità omogenea e di doppia monotonicità, il principale indice utilizzato è il coefficiente di scalabilità di Loevinger *H* (Loevinger, 1948). Esistono tre indici principali per misurare la scalabilità:\n",
    "\n",
    "- **Coefficiente per singolo item ($H_j$)**: misura la capacità di discriminazione di un singolo item.\n",
    "  $$\n",
    "  H_j = \\frac{COV(X_j, R_{-j})}{COV(X_j, R_{-j})^{max}}\n",
    "  $$\n",
    "  dove $X_j$ è il punteggio dell'item e $R_{-j}$ è il *rest score* (la somma dei punteggi di tutti gli item, escluso l'item $j$). Un valore elevato di $H_j$ indica che l'item discrimina bene tra i rispondenti e contribuisce efficacemente all'ordinamento lungo il continuum latente. In generale, valori superiori a 0.30 sono considerati accettabili per un item.\n",
    "\n",
    "- **Coefficiente per coppie di item ($H_{ij}$)**: valuta la coerenza tra due item. \n",
    "  $$\n",
    "  H_{ij} = \\frac{COV(X_i , X_j)}{COV(X_i , X_j)^{max}}\n",
    "  $$\n",
    "  dove $X_i$ e $X_j$ sono i punteggi sommati degli item e il superscript $max$ indica la covarianza massima che i due item potrebbero avere in assenza di errori di Guttman. Valori positivi indicano che la coppia di item è coerente con il modello di omogeneità monotona, mentre valori negativi potrebbero indicare problemi di multidimensionalità o non monotonicità tra gli item.\n",
    "\n",
    "- **Coefficiente complessivo per il test ($H$)**: ornisce una misura della qualità complessiva della scala. \n",
    "  $$\n",
    "  H = \\frac{\\sum^J_{j=1} COV(X_j,R_{-j})}{\\sum^J_{j=1} COV(X_j,R_{-j})^{max}}\n",
    "  $$\n",
    "  Questo indice valutando in che misura la struttura dei dati segue un modello di Guttman. Valori di $H$ tra 0.30 e 0.40 indicano una scala debole, tra 0.40 e 0.50 una scala di qualità media, e superiori a 0.50 una scala forte.\n",
    "\n",
    "    L'indice $H$ varia tra -1 e 1, e i valori negativi indicano che gli item non sono adatti alla scala. Le assunzioni di unidimensionalità, indipendenza locale e monotonicità latente implicano che $0 ≤ H_{ij} ≤ 1$ per tutte le coppie di item $i ≠ j$, e che anche $H_j$ e $H$ dovrebbero essere superiori o uguali a zero. Quando l'indice $H$ è vicino a 1, ciò implica una perfetta conformità al modello di Guttman.\n",
    "\n",
    "In sintesi, i coefficienti di scalabilità nelle Scale Mokken ($H$, $H_j$ e $H_{ij}$) sono fondamentali per valutare la qualità degli item e del test complessivo. Essi misurano in che misura gli item e i punteggi dei rispondenti seguono un ordinamento coerente lungo il continuum latente, fornendo indicazioni su quanto bene gli item discriminano tra i rispondenti.\n",
    "\n",
    "Questi coefficienti vengono calcolati confrontando la covarianza osservata tra gli item con la covarianza massima teorica possibile in assenza di errori di Guttman. Un coefficiente $H$ vicino a 1 suggerisce che gli item si conformano al modello ideale, mentre valori vicini a zero indicano una presenza significativa di errori di Guttman, compromettendo la qualità della scala.\n",
    "\n",
    "Oltre a testare l'adattamento dei dati al modello di omogeneità monotona, la MSA fornisce anche informazioni importanti sulla validità di costrutto della scala. Ad esempio, sebbene valori elevati di $H_j$ e $H$ indichino una buona discriminazione, ciò non garantisce necessariamente che la scala copra in modo completo l'intero costrutto latente. Allo stesso modo, valori elevati di $H_{ij}$ tra coppie di item possono suggerire che uno degli item sia ridondante.\n",
    "\n",
    "In conclusione, i coefficienti di scalabilità sono strumenti cruciali per analizzare la precisione e la validità di una scala nel contesto dell'Analisi delle Scale Mokken. Oltre a valutare la qualità della misurazione e l'adeguatezza degli item, essi contribuiscono a migliorare la comprensione della struttura latente del test, fornendo informazioni essenziali per la selezione degli item nei contesti psicometrici, educativi e di ricerca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errori Standard \n",
    "\n",
    "Gli errori standard (SE) rivestono un ruolo cruciale nella corretta interpretazione dei coefficienti di scalabilità nelle Scale Mokken, poiché forniscono una misura dell'incertezza associata alle stime. Un errore standard elevato rispetto al coefficiente di scalabilità ($H_i$), ad esempio un SE di 0.08 per un $H_i$ di 0.30, suggerisce che il vero valore del coefficiente nella popolazione potrebbe essere sensibilmente inferiore a 0.30, mettendo in dubbio la scalabilità degli item. Questo implica che una stima elevata di $H_i$ potrebbe non riflettere accuratamente la realtà, segnalando potenziali problemi di validità della scala.\n",
    "\n",
    "La grandezza dell'errore standard è influenzata da due fattori principali: la dimensione del campione e la distribuzione dei punteggi degli item. In generale, campioni più grandi portano a errori standard più ridotti, aumentando così la precisione della stima del coefficiente di scalabilità. Tuttavia, distribuzioni asimmetriche dei punteggi degli item possono far aumentare l'errore standard, indipendentemente dalla dimensione del campione. Va sottolineato che, sebbene una dimensione campionaria ampia tenda a ridurre l'errore standard, non garantisce necessariamente stime precise dei coefficienti di scalabilità, in quanto altri fattori, come l'eterogeneità degli item, possono intervenire.\n",
    "\n",
    "Per quantificare la precisione delle stime dei coefficienti di scalabilità, è possibile calcolare gli intervalli di confidenza al 95% (CI) utilizzando la formula:\n",
    "\n",
    "$$\n",
    "\\text{95\\% CI} = H_i \\pm (1.96 \\times \\text{SE})\n",
    "$$\n",
    "\n",
    "Ad esempio, se $H_i = 0.30$ con un SE di 0.10, l'intervallo di confidenza sarà compreso tra 0.10 e 0.50. Un intervallo così ampio indica che il valore reale di $H_i$ potrebbe variare significativamente, rendendo il coefficiente meno affidabile. In un altro esempio, se $H_i = 0.15$ con un SE di 0.10, l'intervallo di confidenza sarà compreso tra -0.05 e 0.35. Questo suggerisce che il vero coefficiente potrebbe essere negativo o prossimo allo zero, segnalando che l'item in questione potrebbe non contribuire positivamente alla scala e, di conseguenza, potrebbe essere considerato per l'eliminazione.\n",
    "\n",
    "Mokken (1971) ha evidenziato che la monotonicità delle funzioni di risposta agli item (IRF) per tutti gli item che contribuiscono al punteggio totale $X^+$ è una condizione sufficiente per garantire l'utilità degli item nella classificazione dei rispondenti. Pertanto, item con coefficienti di scalabilità bassi vengono generalmente considerati inadatti e rimossi dalla scala, in quanto non forniscono un contributo significativo alla costruzione della gerarchia latente.\n",
    "\n",
    "Tuttavia, Crișan et al. (2020) hanno suggerito di evitare la rimozione automatica di item sulla base esclusiva di criteri psicometrici, a meno che non vi siano altre giustificazioni teoriche o di contenuto. Sebbene l'eliminazione di item possa migliorare l'affidabilità della scala e la capacità di discriminare i rispondenti, tali benefici potrebbero essere compensati da una riduzione nella copertura del costrutto o della validità predittiva. Di conseguenza, la decisione di mantenere o eliminare un item dovrebbe basarsi su una considerazione complessiva che includa sia aspetti teorici che psicometrici, piuttosto che affidarsi esclusivamente a regole empiriche o soglie prestabilite.\n",
    "\n",
    "In conclusione, l'analisi degli errori standard nei coefficienti di scalabilità delle Scale Mokken offre informazioni essenziali sull'affidabilità e sulla validità degli item all'interno della scala. Tuttavia, le decisioni riguardanti la rimozione o il mantenimento di specifici item dovrebbero essere guidate non solo da criteri psicometrici, ma anche dal contesto teorico e dai contenuti della scala, per garantire che il costrutto latente sia rappresentato in maniera adeguata. Un'interpretazione equilibrata dei coefficienti di scalabilità, accompagnata da considerazioni teoriche, permette di sviluppare strumenti di misurazione robusti e validi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estensione dell'Analisi delle Scale di Mokken agli Item Politomici\n",
    "\n",
    "L'Analisi delle Scale di Mokken (MSA), inizialmente sviluppata per item dicotomici, è stata estesa da Molenaar (1982a, 1997) per includere anche item politomici, come quelli comunemente utilizzati nelle scale Likert. Questa estensione preserva i principi fondamentali della MSA per gli item dicotomici, adattandoli però alle specificità degli item con più categorie di risposta.\n",
    "\n",
    "Nel contesto degli item politomici, l'analisi non si limita a esaminare le assunzioni del modello MSA sull'intero item, ma considera anche i singoli \"passaggi\" tra categorie di risposta consecutive. Prendendo ad esempio un item su scala Likert a cinque punti (da \"fortemente in disaccordo\" a \"fortemente d'accordo\"), ci sono quattro passaggi distinti tra le categorie. Ogni passaggio rappresenta una transizione tra due categorie adiacenti, e la probabilità di compiere ciascuna transizione dipende dal tratto latente ($\\theta$).\n",
    "\n",
    "Per ogni passaggio di un item politomico, si definisce una Funzione di Risposta del Passaggio dell'Item (ISRF, *Item Step Response Function*), che descrive la probabilità che un individuo scelga una specifica categoria o una categoria superiore in relazione al proprio livello del tratto latente $\\theta$. Le ISRF sono fondamentali per comprendere il funzionamento di ciascuna categoria di risposta e come queste si relazionino al tratto latente che l'item intende misurare.\n",
    "\n",
    "Affinché il modello di omogeneità monotona rimanga valido anche per item politomici, è necessario che le probabilità di selezionare una categoria di risposta k o superiore aumentino in modo monotono all'aumentare di $\\theta$. Questo implica che le categorie di risposta siano ordinate in modo significativo, riflettendo livelli progressivamente più alti del tratto latente. In altre parole, man mano che il tratto latente aumenta, la probabilità di scegliere una risposta superiore (es. \"d'accordo\" anziché \"neutrale\") deve crescere.\n",
    "\n",
    "Un elemento cruciale nell'analisi degli item politomici nella MSA è l'assunzione di **monotonicità**. Tale assunzione richiede che le ISRF siano funzioni crescenti rispetto a $\\theta$: man mano che il tratto latente cresce, deve crescere anche la probabilità di scegliere categorie di risposta più elevate. In questo modo, ogni transizione tra categorie rappresenta un avanzamento significativo lungo il continuum latente.\n",
    "\n",
    "In sintesi, l'estensione della MSA agli item politomici fornisce un approccio robusto per analizzare item con più categorie di risposta, consentendo una misurazione più dettagliata e sfumata del tratto latente. Questo rende la MSA particolarmente adatta in contesti in cui si utilizzano scale a più livelli di risposta, come nei questionari di valutazione del benessere psicologico, nei sondaggi di opinione o nelle valutazioni educative. Attraverso l'analisi dei singoli passaggi degli item, la MSA applicata agli item politomici permette di approfondire la comprensione delle modalità con cui gli individui interagiscono con le diverse opzioni di risposta, e di come queste scelte riflettano i loro livelli sul tratto latente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'Affidabilità nei Test\n",
    "\n",
    "L'affidabilità di un test psicometrico si riferisce alla sua capacità di produrre risultati coerenti nel tempo o attraverso somministrazioni ripetute. L'alfa di Cronbach è l'indicatore di affidabilità più comune, ma può presentare limitazioni, specialmente quando gli item non sono omogenei. Il coefficiente ρ di Mokken è una valida alternativa per valutare l'affidabilità in presenza di scale ordinarie e si basa su assunzioni meno restrittive rispetto all'alfa di Cronbach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedura di Selezione Automatica degli Item (AISP)\n",
    "\n",
    "La Procedura di Selezione Automatica degli Item (AISP) è una metodologia impiegata nell'Analisi delle Scale di Mokken (MSA) per selezionare item che aderiscano alle assunzioni del Modello di Mokken (MHM). A differenza di tecniche più comuni come l'analisi fattoriale o l'analisi parallela, l'AISP non cerca di determinare la dimensionalità dei dati in modo esplicito, ma utilizza un approccio basato sui coefficienti di scalabilità per identificare insiemi di item che misurano lo stesso costrutto latente. Questo processo permette di individuare sottoinsiemi di item scalabili che formano una o più scale.\n",
    "\n",
    "L'AISP segue un processo iterativo che inizia con la selezione dell'item più rappresentativo di una dimensione, utilizzando il coefficiente di scalabilità degli item ($H_i$). Successivamente, viene impiegato il coefficiente di scalabilità delle coppie di item ($H_{ij}$) per identificare il più ampio insieme di item che misurano lo stesso costrutto. Il criterio principale per l'inclusione di un item è che il suo coefficiente di scalabilità superi una soglia ($c$), solitamente impostata a 0.30, e che la covarianza tra ogni coppia di item inclusi nella scala ($H_{ij}$) sia positiva e superiore a questo valore. \n",
    "\n",
    "### Criteri di Selezione\n",
    "\n",
    "La procedura inizia selezionando due item con il più alto valore di $H_{ij}$ e continua aggiungendo nuovi item che rispettano i due criteri: (1) il coefficiente di scalabilità individuale dell'item ($H_i$) deve essere maggiore di $c$, e (2) la covarianza tra ogni coppia di item ($H_{ij}$) deve essere positiva e superiore al valore soglia scelto. Se un item non soddisfa questi requisiti, l'AISP tenterà di includerlo in una seconda scala. Questo processo si ripete finché non è più possibile assegnare altri item a nuove scale. Gli item che non soddisfano i criteri vengono identificati come non scalabili e, pertanto, esclusi.\n",
    "\n",
    "### Funzionalità dell'AISP\n",
    "\n",
    "Le scale risultanti dall'AISP sono progettate per misurare un tratto latente comune, e gli item inclusi devono essere in grado di ordinare in modo affidabile i rispondenti lungo tale continuum. Tuttavia, talvolta può capitare che un item con un valore di $H_i$ inferiore alla soglia $c$ venga incluso nella scala, il che potrebbe indicare che quell'item non contribuisce adeguatamente alla misurazione del tratto. In questi casi, è necessario rivedere attentamente la selezione degli item e, se necessario, escludere gli item inadatti.\n",
    "\n",
    "Un aspetto importante dell'AISP è che esso non è influenzato dalla difficoltà degli item, rendendolo adatto sia per item dicotomici che politomici. Inoltre, a differenza dell'analisi fattoriale, l'AISP non cerca di imporre una soluzione a prescindere dai dati: se nessuna coppia di item raggiunge il valore minimo di $H_{ij}$, la procedura non genera alcuna scala. Questo può essere un vantaggio in contesti in cui l'analisi fattoriale forzerebbe una soluzione, anche se non significativa o coerente con i dati.\n",
    "\n",
    "### Implicazioni della Soglia ($c$)\n",
    "\n",
    "La scelta del valore soglia ($c$) è un fattore determinante nel processo di selezione. Se il valore di $c$ è troppo alto, molti item potrebbero essere esclusi, portando alla formazione di scale con pochi item e riducendo la capacità di coprire adeguatamente il costrutto latente. Al contrario, se il valore di $c$ è troppo basso, è possibile che vengano inclusi troppi item, nascondendo la vera dimensionalità dei dati. Per questo motivo, il valore di $c$ deve essere scelto con attenzione, in base agli obiettivi specifici dello studio e alle caratteristiche dei dati.\n",
    "\n",
    "### Limiti e Considerazioni\n",
    "\n",
    "Sebbene l'AISP rappresenti una valida alternativa all'analisi fattoriale esplorativa, ha anche delle limitazioni. Studi di simulazione hanno dimostrato che l'AISP può essere meno efficace nel rilevare la vera dimensionalità dei dati quando le dimensioni sono correlate o quando gli item saturano su più dimensioni. Inoltre, l'AISP non tiene conto delle relazioni teoriche tra gli item, affidandosi unicamente a criteri statistici. Pertanto, la decisione di mantenere o rimuovere un item dalla scala non dovrebbe basarsi esclusivamente sui risultati dell'AISP, ma deve essere integrata da una valutazione teorica solida e da una riflessione sui contenuti.\n",
    "\n",
    "### Conclusioni\n",
    "\n",
    "L'AISP è uno strumento utile per la costruzione di scale di Mokken, in quanto consente di identificare insiemi di item scalabili senza imporre assunzioni troppo restrittive sui dati. Tuttavia, la scelta del valore soglia $c$ e l'interpretazione delle scale richiedono attenzione. In definitiva, l'AISP dovrebbe essere utilizzato come parte di un approccio più ampio alla validazione di strumenti di misura, tenendo conto sia delle evidenze statistiche sia delle considerazioni teoriche e pratiche che sottostanno alla costruzione della scala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinamento Invariante degli Item \n",
    "\n",
    "L'Ordinamento Invariante degli Item (IIO) è un concetto fondamentale nelle scale Mokken. L'IIO richiede che l'ordine di difficoltà degli item rimanga costante tra diversi sottogruppi di persone all'interno della popolazione target.\n",
    "\n",
    "Perché è importante?\n",
    "\n",
    "1. **Validità dei confronti**: Garantisce che le differenze nei punteggi totali tra gruppi siano significative e non dovute a variazioni nella percezione della difficoltà degli item.\n",
    "2. **Interpretazione coerente**: Permette un'interpretazione uniforme dei punteggi del test per tutti i partecipanti.\n",
    "3. **Rilevazione di bias**: Aiuta a identificare possibili bias o funzioni differenziali degli item (DIF) che potrebbero compromettere la validità della scala.\n",
    "\n",
    "Nei test psicologici (es. questionari sulla depressione o ansia) e nelle valutazioni educative, l'IIO implica che:\n",
    "\n",
    "- Un individuo con un punteggio totale più alto dovrebbe manifestare tutti i sintomi o le competenze di una persona con un punteggio inferiore, più eventuali sintomi o competenze aggiuntive.\n",
    "- La progressione degli item da facili a difficili dovrebbe essere valida per tutti gli esaminandi.\n",
    "\n",
    "L'IIO è cruciale quando si ordinano gli item di un test in base alla loro difficoltà. Questo ordinamento dovrebbe essere coerente per tutti i partecipanti, indipendentemente dal loro livello di abilità o dalle caratteristiche del gruppo di appartenenza.\n",
    "\n",
    "Per verificare la presenza dell'IIO, si utilizzano diverse tecniche:\n",
    "\n",
    "1. **Metodo dei gruppi di restscore**: Confronta l'ordine degli item tra gruppi formati in base ai punteggi totali, escludendo l'item in esame.\n",
    "2. **Metodo di divisione degli item**: Divide gli item in gruppi e confronta l'ordine di difficoltà tra questi gruppi.\n",
    "3. **Matrici delle proporzioni P(++)/P(--)**: Analizza le proporzioni di risposte positive e negative per coppie di item.\n",
    "4. **Metodo di divisione dei restscore**: Esamina la coerenza dell'ordine degli item attraverso diversi livelli di punteggio totale.\n",
    "\n",
    "Se l'IIO non è rispettato, si possono verificare diverse conseguenze:\n",
    "\n",
    "- Possibile presenza di DIF o bias negli item.\n",
    "- Difficoltà nell'interpretare e confrontare i punteggi totali tra gruppi diversi.\n",
    "- Messa in discussione della validità costruttuale della scala.\n",
    "\n",
    "In conclusione, l'IIO è un presupposto fondamentale per l'uso e l'interpretazione delle scale Mokken e, più in generale, degli strumenti di misurazione psicometrica. Nonostante la sua importanza, spesso non viene verificato empiricamente. La sua conferma è particolarmente cruciale in contesti di ricerca sui processi cognitivi evolutivi o nella pratica clinica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensione del Campione \n",
    "\n",
    "La determinazione della dimensione del campione è un aspetto cruciale nella ricerca psicometrica. Mentre questo campo è ben sviluppato per molti test statistici, rimane un'area relativamente inesplorata nell'Analisi delle Scale Mokken (MSA). Questa lacuna nella ricerca pone sfide significative per i ricercatori, in particolare quando si tratta di bilanciare la precisione dei risultati con le limitazioni di risorse e tempo.\n",
    "\n",
    "Un rischio nell'uso di campioni troppo piccoli è la \"capitalizzazione sul caso\". Questo fenomeno si verifica quando:\n",
    "\n",
    "1. Una scala di Mokken viene erroneamente identificata in un campione piccolo, quando in realtà non esiste nella popolazione.\n",
    "2. Una scala esistente non viene rilevata a causa della limitata dimensione del campione.\n",
    "\n",
    "Entrambi questi scenari possono portare a conclusioni errate e compromettere la validità della ricerca.\n",
    "\n",
    "### Studi Chiave sulla Dimensione del Campione\n",
    "\n",
    "Lo studio di Straat et al. (2014) ha esaminato le dimensioni minime del campione necessarie per due procedure cruciali nelle Scale Mokken: l'Automated Item Selection Procedure (AISP) e l'Algoritmo Genetico (GA). Sono stati considerati i seguenti fattori: la lunghezza del test, i valori approssimativi dei coefficienti di scalabilità (Hi) degli item e la correlazione tra le dimensioni nella scala. \n",
    "\n",
    "I risultati principali sono stati:\n",
    "\n",
    "1. Il valore di Hi è risultato essere il fattore più influente sulla dimensione del campione necessaria.\n",
    "2. Con l'aumento di Hi, erano sufficienti campioni più piccoli per classificare correttamente gli item.\n",
    "3. La lunghezza del test ha avuto un impatto minore sulla precisione della classificazione.\n",
    "4. Le correlazioni tra le dimensioni hanno mostrato effetti in combinazione con vari livelli di Hi.\n",
    "\n",
    "Sulla base di questi risultati, Straat et al. (2014) forniscono le seguenti linee guida per la Dimensione del Campione:\n",
    "\n",
    "- Per Hi ≈ 0.22:\n",
    "  - Precisione mediocre/adeguata: 750-1000 persone\n",
    "  - Precisione buona/eccellente: 1250-2500 persone\n",
    "- Per Hi ≈ 0.42:\n",
    "  - Precisione mediocre/adeguata: 50 persone\n",
    "  - Precisione buona/eccellente: almeno 250 persone\n",
    "\n",
    "Lo studio di Watson et al. (2018) ha analizzato l'impatto della dimensione del campione sui coefficienti di scalabilità utilizzando dati reali. Il campione originale era costituito da 7510 persone. Il questionario includeva 14 item con scala Likert a 5 punti. Le dimensioni dei campioni estratti sono state: 50, 250, 500, 600, 750, 1000 partecipanti. È stata utilizzata la tecnica del bootstrapping con 1000 campioni per ogni dimensione.\n",
    "\n",
    "I risultati chiave sono stati i seguenti:\n",
    "\n",
    "1. I valori medi di H e Hi non variavano significativamente tra le diverse dimensioni del campione.\n",
    "2. Gli intervalli di confidenza al 95% erano più ampi per campioni più piccoli.\n",
    "3. Per N=50, in 592 casi su 1000, il limite inferiore dell'intervallo di confidenza per Hi era inferiore a 0.30.\n",
    "4. Per N=1000, nessun caso presentava un limite inferiore dell'intervallo di confidenza per Hi inferiore a 0.30.\n",
    "\n",
    "Implicazioni per la Ricerca:\n",
    "\n",
    "1. **Stime Puntuali vs Intervalli di Confidenza**: Mentre le stime puntuali dei coefficienti di scalabilità possono rimanere stabili, la dimensione del campione influenza significativamente gli intervalli di confidenza.\n",
    "\n",
    "2. **Decisioni sulla Qualità degli Item**: Campioni più piccoli possono portare a decisioni errate sull'inclusione o esclusione degli item basate sugli errori standard.\n",
    "\n",
    "3. **Bilanciamento Risorse e Precisione**: È cruciale trovare un equilibrio tra la necessità di precisione e le limitazioni di risorse e tempo.\n",
    "\n",
    "4. **Considerazioni Pratiche**: In situazioni con risorse limitate, una scelta accurata della dimensione del campione può ottimizzare l'efficienza della ricerca.\n",
    "\n",
    "In conclusione, la determinazione della dimensione del campione nelle Scale Mokken richiede una considerazione attenta di molteplici fattori. Mentre campioni più grandi generalmente offrono maggiore precisione, non sempre sono necessari o pratici. La chiave sta nel bilanciare la necessità di risultati affidabili con le realtà pratiche della ricerca. Futuri studi in questo campo potrebbero fornire linee guida più dettagliate per aiutare i ricercatori a prendere decisioni informate sulla dimensione del campione ottimale per le loro specifiche applicazioni delle Scale Mokken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto tra il Modello di Rasch e l'MSA\n",
    "\n",
    "Il Modello di Rasch (RM) assume che la probabilità di risposta corretta a un item sia determinata dall'abilità della persona (θ) e dalla difficoltà dell'item (δ). La relazione tra la probabilità di una risposta corretta e θ è descritta da una funzione logistica, con IRFs parallele e dalla stessa pendenza. Questo modello è definito parametrico poiché utilizza una funzione parametrica specifica, la funzione logistica, per stabilire tale relazione.\n",
    "\n",
    "Il Modello di Rasch prevede che i punteggi grezzi totali siano sufficienti per stimare i parametri delle persone e degli item. È considerato il modello più restrittivo rispetto al Modello di Monotonicità Omogenea (MHM) e al Modello di Monotonicità Doppia (DMM) per le sue assunzioni aggiuntive.\n",
    "\n",
    "D'altra parte, l'Analisi della Scala di Mokken (MSA) appartiene alla categoria dei modelli non parametrici della IRT (NIRT), che non prevedono una funzione specifica per le IRFs. In questi modelli, il punteggio grezzo totale fornisce un ordine basato sulla variabile latente θ, poiché θ non è direttamente stimato. Questo approccio è meno restrittivo rispetto ai modelli parametrici e consente una maggiore flessibilità nell'analisi dei dati.\n",
    "\n",
    "Il MHM, il modello meno restrittivo tra i tre, si basa su tre assunzioni fondamentali: unidimensionalità, monotonicità e indipendenza locale. Questo modello permette di ordinare gli individui su una scala unidimensionale ordinale, mantenendo costante questo ordinamento attraverso tutti gli item. Il DMM, invece, aggiunge l'assunzione di IRF non intersecanti al MHM, producendo scale ordinali separate per persone e item.\n",
    "\n",
    "Un punto critico è che, mentre il Modello di Rasch crea una scala metrica comune per persone e item, consentendo misurazioni indipendenti da persone e item, il DMM genera scale ordinali distinte. Inoltre, i modelli NIRT, come la MSA, non richiedono la conformità degli item a una funzione logistica specifica, evitando così la necessità di scartare gli item che non seguono tale funzione, una limitazione dei modelli PIRT (Parametric Item Response Theory).\n",
    "\n",
    "In sintesi, mentre il Modello di Rasch offre un approccio più restrittivo ma preciso, basato su assunzioni specifiche e una scala metrica comune, la MSA offre una maggiore flessibilità e applicabilità a un'ampia gamma di dati, pur producendo scale ordinali distinte per persone e item. Questa differenza chiave tra i due approcci sottolinea l'importanza di scegliere il modello più adatto in base agli obiettivi specifici e alla natura dei dati in esame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto tra la Teoria Classica dei Test e l'MSA \n",
    "\n",
    "Esaminiamo ora le somiglianze e le differenze tra la Teoria Classica dei Test (CTT) e l'Analisi della Scala di Mokken (MSA).\n",
    "\n",
    "La CTT si basa su diverse assunzioni fondamentali:\n",
    "\n",
    "1. I punteggi osservati sono la somma dei punteggi veri e dei punteggi di errore, con l'aspettativa che i punteggi di errore abbiano una media di zero su prove ripetute.\n",
    "2. Non c'è correlazione tra i punteggi di errore e i punteggi veri.\n",
    "3. I punteggi veri in un test non sono correlati ai punteggi di errore in un altro test.\n",
    "4. I punteggi di errore in due test somministrati agli stessi soggetti sono non correlati.\n",
    "\n",
    "Nella CTT, i punteggi grezzi totali sono considerati indicatori delle posizioni delle persone sul continuum del tratto latente. La proporzione di item corretti (valore p) indica la facilità degli item, mentre la correlazione corretta tra item e punteggio totale misura la discriminazione degli item. La CTT enfatizza anche l'importanza dell'affidabilità, definita come la correlazione tra i punteggi osservati su due forme parallele del test.\n",
    "\n",
    "Confrontando la CTT con la MSA, troviamo alcune somiglianze nelle metodologie di calcolo degli indici di abilità delle persone e di difficoltà degli item. Nella MSA, il coefficiente di scalabilità dell'item Hi è analogo alle correlazioni corrette tra item e punteggio totale nella CTT. Analogamente, il coefficiente di scalabilità tra coppie di item Hij nella MSA corrisponde alle correlazioni tra coppie di item nella CTT, e il coefficiente di scalabilità complessivo H nella MSA è paragonabile agli indici di discriminazione media degli item nella CTT.\n",
    "\n",
    "Tuttavia, una differenza fondamentale tra la MSA e la CTT risiede nella testabilità dei modelli. I modelli MSA permettono di verificare empiricamente le loro assunzioni, come l'indipendenza locale, l'unidimensionalità e la monotonicità. Ad esempio, un coefficiente di scalabilità negativo nella MSA smentirebbe gli assiomi del Modello di Omogeneità Monotona (MHM). Questa capacità di testare empiricamente le sue assunzioni rende la MSA un modello particolarmente robusto e trasparente.\n",
    "\n",
    "In conclusione, mentre la CTT fornisce un quadro teorico solido per la comprensione e l'interpretazione dei punteggi dei test, la MSA offre un approccio più flessibile e testabile, particolarmente utile nell'analizzare la struttura dei dati dei test e nella valutazione della validità delle scale di misurazione. Queste caratteristiche rendono la MSA un complemento prezioso alla CTT nella pratica della misurazione psicologica ed educativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critiche alla MSA\n",
    "\n",
    "Negli anni '80, l'Analisi delle Scale Mokken (MSA) è stata criticata per la limitata applicabilità del coefficiente di scalabilità H, ritenuto dipendente dalle caratteristiche del campione e degli item, e non adeguato come misura di adattamento del modello. Ulteriori critiche hanno riguardato il coefficiente di scalabilità degli item Hi, accusato di selezionare solo item con IRF ripide e distanti, escludendo item validi e riducendo la varianza e l'affidabilità del test. I critici hanno anche messo in dubbio l'adeguatezza della MSA per l'ordinamento libero degli item secondo il rango latente, suggerendo una possibile necessità del modello di Rasch.\n",
    "\n",
    "In risposta, i difensori della MSA hanno sottolineato che le critiche si basano su una lettura selettiva e una mancata comprensione dei modelli non parametrici. Hanno ribadito che H e Hi sono intesi come misure dell'omogeneità monotona, e non come indici di doppia monotonia, e che la dipendenza di H dalla varianza della popolazione è in linea con le assunzioni del modello. Questo dibattito evidenzia l'importanza di valutare attentamente i metodi statistici come la MSA nel loro contesto di applicazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerazioni Conclusive \n",
    "\n",
    "Il tema centrale di questo capitolo è la messa in discussione dell'assunzione che i punteggi grezzi siano necessariamente dati ordinali. Questa supposizione, spesso data per scontata nella teoria classica dei test, richiede una verifica empirica. L'Analisi delle Scale Mokken (MSA) offre gli strumenti per effettuare tale verifica.\n",
    "\n",
    "1. **Evidenza di Unidimensionalità**: \n",
    "   I coefficienti di scalabilità (H, Hi, Hij) forniscono una solida prova che il test misura effettivamente il costrutto unidimensionale previsto.\n",
    "\n",
    "2. **Precisione della Misurazione**: \n",
    "   L'Ordinamento Invariante degli Item (IIO) assicura che il test misuri il costrutto con alta precisione per tutti i livelli di abilità.\n",
    "\n",
    "3. **Equità del Test**: \n",
    "   Riduce il rischio di bias, garantendo che il test sia equamente rappresentativo per tutti i partecipanti.\n",
    "\n",
    "4. **Interpretabilità dei Punteggi**: \n",
    "   La conformità all'IIO migliora la chiarezza e la trasparenza nell'interpretazione dei risultati del test.\n",
    "\n",
    "5. **Relazione Causale**: \n",
    "   Fornisce una base solida per affermare che le variazioni nei punteggi del test sono causate da variazioni nel costrutto misurato.\n",
    "\n",
    "6. **Flessibilità**: \n",
    "   L'MSA può essere applicata a una vasta gamma di tipi di dati e scale di risposta.\n",
    "\n",
    "In conclusione, l'Analisi delle Scale Mokken si rivela uno strumento estremamente utile e potente per la validazione di test in ambiti psicologici ed educativi. La sua capacità di confermare il modello di omogeneità monotona e di valutare l'ordinamento invariante degli item offre ai ricercatori e ai professionisti un metodo robusto per garantire la qualità e l'affidabilità dei loro strumenti di misurazione."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
